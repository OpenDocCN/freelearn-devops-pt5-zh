- en: How Did We Get Here?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们是如何走到今天的？
- en: A small percentage of companies live in the present. Most of us are stuck in
    the past, with obsolete technology and outdated processes. If we stay in the past
    for too long, we might lose our chance to come back to the present. We might move
    into an alternate timeline and cease to exist.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 很少有公司活在当下。我们大多数人仍然停留在过去，使用着过时的技术和过时的流程。如果我们停留在过去太久，可能会失去重新回到当下的机会。我们可能会进入一个平行时空，甚至不再存在。
- en: Every company is a software company. That applies even to those that do not
    yet realize it. We are all running and continuously increasing our speed. It's
    a race without a finish line. There are no winners but rather those that fall
    and do not get up. We live an era of an ever-increasing speed of change. Companies
    are created and destroyed overnight. No one is safe. No one can allow status quo.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 每家公司都是一家软件公司。这一点适用于那些还未意识到这一点的公司。我们都在奔跑，并且不断加速。这是一场没有终点的比赛。没有赢家，只有那些跌倒后没有站起来的人。我们生活在一个变化速度不断加快的时代。公司一夜之间可能会被创造或摧毁。没有人是安全的。没有人可以安于现状。
- en: Technology is changing so fast that it is very hard, if not impossible to follow.
    The moment we learn about a new technology, it is already obsolete and replaced
    with something else. Take containers as an example. Docker appeared only a few
    years ago, and everyone is already using it for a myriad of scenarios. Still,
    even though it is a very young product, it changed many times over. Just when
    we learned how to use `docker run`, we were told that it is obsolete and should
    be replaced with `docker-compose up`. We started converting all our `docker run`
    commands into Compose YAML format. The moment we finished the conversion, we learned
    that containers should not be run directly. We should use a container scheduler
    instead. To make things more complicated, we had to make a selection between Mesos
    and Marathon, Docker Swarm, or Kubernetes.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 技术变化如此之快，以至于很难（如果不是不可能）跟上。我们刚学习到一种新技术，它就已经过时，被其他东西取代了。以容器为例，Docker 只是几年前才出现，大家已经在各种场景中使用它。尽管它是一个非常年轻的产品，但它已经经历了多次变革。就在我们学会如何使用
    `docker run` 时，我们被告知它已经过时，应该用 `docker-compose up` 来代替。于是我们开始将所有的 `docker run`
    命令转换成 Compose 的 YAML 格式。等我们完成了转换，我们又得知容器不应该直接运行，而是应该使用容器调度器来替代。更复杂的是，我们还需要在 Mesos
    和 Marathon、Docker Swarm 或 Kubernetes 之间做选择。
- en: We can choose to ignore the trends but that would mean that we would fall behind
    the rest of the competition. There is no alternative to a constant struggle to
    be competitive. Once we drop our guard and stop learning and improving, the competition
    will take over our business. Everyone is under pressure to improve, even highly
    regulated industries. Innovation is impossible until we manage to get to the present
    tense. Only once we master what others are doing today, can we move forward and
    come up with something new. Today, container schedulers are a norm. They are not
    the thing of the future. They are the present. They are here to stay even though
    it is likely that they will change a lot in the coming months and years. Understanding
    container schedulers are paramount. Among them, Kubernetes is the most widely
    used and with a massive community behind it.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择忽视这些趋势，但那样意味着我们会落后于竞争对手。没有什么选择，只有不断地努力保持竞争力。一旦我们放松警惕，停止学习和改进，竞争对手就会接管我们的业务。每个人都面临改进的压力，即使是高度监管的行业也是如此。只有当我们设法回到现在，创新才有可能。只有当我们掌握了别人今天所做的事情，才能向前推进并提出新的想法。今天，容器调度器已经是常态。它们不再是未来的东西，它们是现在的事物。尽管它们很可能在接下来的几个月和几年中发生巨大变化，但它们已经存在，并且将一直存在。理解容器调度器至关重要。在这些调度器中，Kubernetes
    是最广泛使用的，并且拥有庞大的社区支持。
- en: Before we dive into Kubernetes, it might be worthwhile going through some history
    in an attempt to understand some of the problems we were trying to solve, as well
    as some of the challenges we were facing.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解 Kubernetes 之前，可能值得回顾一些历史，尝试理解我们当时试图解决的一些问题，以及我们面临的一些挑战。
- en: A glimpse from the past
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从过去的一瞥
- en: Picture a young boy. He just finished a few months worth of work. He's proud
    of what he accomplished but, at the same time, fearful whether it will work. He
    did not yet try it out on a "real" server. This will be the first time he'll deliver
    the fruits of his work.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个年轻男孩。他刚完成几个月的工作。他为自己取得的成就感到骄傲，但同时也担心它是否能正常运作。他还没有在“真实”的服务器上尝试过。这将是他第一次交付自己工作的成果。
- en: He takes a floppy disk out from a drawer, inserts it into his computer, and
    copies the files he compiled previously. He feels fortunate that perforated cards
    are a thing of the past.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 他从抽屉里拿出一张软盘，插入电脑，复制之前编译的文件。他庆幸打孔卡片已经成为过去的事情。
- en: He gets up from his desk, exits the office, and walks towards his car. It will
    take him over two hours to get to the building with servers. He's not happy with
    the prospect of having to drive for two hours, but there is no better alternative.
    He could have sent the floppy with a messenger, but that would do no good since
    he wants to install the software himself. He needs to be there. There is no remote
    option.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 他从桌子前站起来，走出办公室，朝着他的车走去。到达服务器所在的楼栋需要超过两个小时。他对于必须开车两个小时的前景感到不满，但没有更好的替代方案。他本可以让信使送去软盘，但那样没什么用，因为他想亲自安装软件。他必须亲自去那里，无法远程操作。
- en: A while later, he enters the room with the servers, inserts the floppy disk,
    and copies and installs the software. Fifteen minutes later, his face shows signs
    of stress. Something is not working as expected. There is an unforeseen problem.
    He's collecting outputs and writing notes. He's doing his best to stay calm and
    gather as much info as he can. He's dreading a long ride back to his computer
    and days, maybe even weeks, until he figures out what caused the problem and fixes
    it. He'll be back and install the fix. Perhaps it will work the second time. More
    likely it won't.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 过了一会儿，他进入了存放服务器的房间，插入软盘，复制并安装软件。十五分钟后，他的脸上显现出压力的迹象。事情没有按预期的方式运行。出现了一个意外问题。他正在收集输出并写下笔记。他尽力保持冷静，收集尽可能多的信息。他担心又要长时间开车回到电脑前，可能还需要几天，甚至几周，才能弄清楚问题所在并解决它。他会回去并安装修复程序，也许第二次会成功，但更可能不会。
- en: A short history of infrastructure management
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础设施管理的简史
- en: A long time ago in a galaxy far, far away...
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 很久以前，在一个遥远的星系里……
- en: We would order servers and wait for months until they arrive. To make our misery
    worse, even after they come, we'd wait for weeks, sometimes even months, until
    they are placed in racks and provisioned. Most of the time we were waiting for
    something to happen. Wait for servers, wait until they are provisioned, wait until
    you get approval to deploy, then wait some more. Only patient people could be
    software engineers. And yet, that was the time after perforated cards and floppy
    disks. We had internet or some other way to connect to machines remotely. Still,
    everything required a lot of waiting.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会订购服务器，然后等上几个月直到它们到货。更糟糕的是，即便它们到了，我们还要等上几周，有时甚至几个月，才能把它们放到机架上并完成配置。大多数时候我们只是一直在等待。等待服务器，等待配置完成，等待获得部署批准，然后继续等待。只有耐心的人才能成为软件工程师。尽管如此，那也是打孔卡片和软盘之后的时代。我们有互联网或其他方式远程连接到机器。尽管如此，一切仍然需要大量等待。
- en: Given how long it would take to have a fully functioning server, it came as
    no surprise that only a select few had access to them. If someone does something
    that should not be done, we could face an extended downtime. On top of that, nobody
    knew what was running on those servers. Since everything was being done manually,
    after a while, those servers would become a dumping ground. Things get accumulated
    over time. No matter how much effort is put into documentation, given enough time,
    the state of the servers would always diverge from the documentation. That is
    the nature of manual provisioning and installations. Sysadmin became a god-like
    person. He was the only one who knew everything or, more likely, faked that he
    does. He was the dungeon keeper. He had the keys to the kingdom. Everyone was
    replaceable but him.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于要让服务器完全投入使用需要的时间，只有少数人能接触到这些服务器也就不足为奇了。如果有人做了不该做的事情，我们可能会面临长时间的宕机。此外，没有人知道那些服务器上运行的是什么。由于一切都靠人工操作，过了一段时间后，这些服务器就成了垃圾场。东西随着时间积累。无论多少精力投入到文档中，只要给足时间，服务器的状态总会与文档偏离。这就是手动配置和安装的本质。系统管理员成了神一样的人物。他是唯一一个知道一切的人，或者更可能，他假装自己知道。他是地下城的守护者，拥有通往王国的钥匙。每个人都可以被替代，只有他不行。
- en: Then came configuration management tools. We got CFEngine. It was based on promise
    theory and was capable of putting a server into the desired state no matter what
    its actual state was. At least, that was the theory. Even with its shortcomings,
    CFEngine fulfilled its primary objective. It allowed us to specify the state of
    static infrastructure and have a reasonable guarantee that it will be achieved.
    Aside from its main goal, it was an advance towards documented servers setup.
    Instead of manual hocus-pocus type of actions which resulted in often significant
    discrepancies between documentation and the actual state, CFEngine allowed us
    to have a specification that (almost) entirely matches the actual state. Another
    big advantage it provided is the ability to have, more or less, the same setup
    for different environments. Servers dedicated to testing could be (almost) the
    same as those assigned to production. Unfortunately, usage of CFEngine and similar
    tools were not yet widespread. We had to wait for virtual machines before automated
    configuration management become a norm. However, CFEngine was not designed for
    virtual machines. They were meant to work with static, bare metal servers. Still,
    CFEngine was a massive contribution to the industry even though it failed to get
    widespread adoption.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然后出现了配置管理工具。我们得到了 CFEngine。它基于承诺理论，能够将服务器调整到期望的状态，无论其实际状态如何。至少，这是理论。即使有缺点，CFEngine
    也完成了其主要目标。它允许我们指定静态基础设施的状态，并有合理的保证能实现该状态。除了其主要目标，它还是服务器设置文档化的进步。与手动的花招式操作（通常导致文档与实际状态之间的显著差异）不同，CFEngine
    允许我们拥有一个几乎完全与实际状态匹配的规范。它提供的另一个大优势是，可以为不同的环境提供或多或少相同的设置。专用于测试的服务器可以（几乎）与分配给生产环境的服务器相同。不幸的是，CFEngine
    和类似工具的使用尚未得到广泛推广。我们不得不等待虚拟机的出现，直到自动化配置管理成为常态。然而，CFEngine 并非为虚拟机设计。它们是为静态的裸金属服务器而设计的。尽管如此，CFEngine
    依然是对行业的巨大贡献，尽管它未能广泛采用。
- en: After CFEngine came Chef, Puppet, Ansible, Salt, and other similar tools. Life
    was good until virtual machines came into being or, to be more precise, became
    widely used. We'll go back to those tools soon. For now, let's turn to the next
    evolutionary improvement.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在 CFEngine 之后，出现了 Chef、Puppet、Ansible、Salt 和其他类似工具。生活一度美好，直到虚拟机问世，或者更准确地说，直到虚拟机得到了广泛应用。我们很快会回到这些工具。现在，让我们转向下一个进化改进。
- en: Besides forcing us to be patient, physical servers were a massive waste in resource
    utilization. They came in predefined sizes and, since waiting time was considerable,
    we often opted for big ones. The bigger, the better. That meant that an application
    or a service usually required less CPU and memory than the server offered. Unless
    you do not care about costs, that meant that we'd deploy multiple applications
    to a single server. The result was a dependencies nightmare. We had to choose
    between freedom and standardization.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 除了迫使我们保持耐心，物理服务器在资源利用方面也是一种巨大的浪费。它们有预定义的规格，由于等待时间相当长，我们通常会选择大规格的服务器。越大，越好。这意味着一个应用或服务通常所需的
    CPU 和内存比服务器提供的要少。除非不在乎成本，否则这意味着我们会将多个应用部署到同一台服务器上。结果就是依赖关系的噩梦。我们必须在自由和标准化之间做出选择。
- en: Freedom meant that different applications could use different runtime dependencies.
    One service could require JDK3 while the other might need JDK4\. A third one might
    be compiled with C. You probably understand where this is going. The more applications
    we host on a single server, the more dependencies there are. More often than not,
    those dependencies were conflicting and would produce side effects no one expected.
    Thanks to our inherent need to convert any expertise into a separate department,
    those in charge of infrastructure were quick to dismiss freedom in favour of reliability.
    That translates into "the easier it is for me, the more reliable it is for you."
    Freedom lost, standardization won.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 自由意味着不同的应用可以使用不同的运行时依赖。一项服务可能需要 JDK3，而另一项可能需要 JDK4。第三个可能是用 C 语言编译的。你大概明白接下来会发生什么了。我们在一台服务器上托管的应用越多，依赖关系就越复杂。通常，这些依赖会发生冲突，产生一些没人预料到的副作用。由于我们天生有将任何专长转化为独立部门的需求，负责基础设施的人迅速放弃了自由，转而选择可靠性。这就意味着“对我越简单，对你越可靠”。自由败北，标准化获胜。
- en: Standardization starts with systems architects deciding the only right way to
    develop and deploy something. They are a curious bunch of people. With the risk
    of putting everyone in the same group and ridiculing the profession, I'll describe
    an average systems architect as a (probably experienced) coder that decided to
    climb his company's ladder. While on the subject of ladders, there are often two
    of those. One is the management ladder that requires an extensive knowledge of
    Microsoft Word and Excel. Expert knowledge of all MS Office tools is a bonus.
    Those who mastered MS Project were considered the ultimate experts. Oh, I forgot
    about email skills. They had to be capable of sending at least fifteen emails
    a day asking for status reports.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化从系统架构师决定唯一正确的开发和部署方式开始。他们是一群很有趣的人。冒着把所有人都放在同一个框里并讽刺这一职业的风险，我会描述一个普通的系统架构师为一个（可能经验丰富的）程序员，他决定爬升自己公司的阶梯。说到阶梯，通常有两种。一种是管理阶梯，需要广泛掌握Microsoft
    Word和Excel。精通所有MS Office工具是加分项。那些精通MS Project的人被认为是终极专家。哦，我忘了提到邮件技能。他们必须能够每天至少发送十五封邮件，询问状态报告。
- en: Most expert coders (old timers) would not choose that path. Many preferred to
    remain technical. That meant taking over systems architect role. The problem is
    that the "technical path" was often a deceit. Architects would still have to master
    all the management skills (for example, Word, Excel, and email) with the additional
    ability to draw diagrams. That wasn't easy. A systems architect had to know how
    to draw a rectangle, a circle, and a triangle. He had to be proficient in coloring
    them as well as in connecting them with lines. There were dotted and full lines.
    Some had to end like an arrow. Choosing the direction of an arrow was a challenge
    in itself so the lines would often end up with arrows at both ends.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数专家级程序员（老手）不会选择这条道路。许多人更愿意保持技术路线。这意味着接管系统架构师的角色。问题是，“技术路线”往往是一种欺骗。架构师仍然必须掌握所有管理技能（例如，Word、Excel和邮件），并具备绘制图表的额外能力。这并不容易。一个系统架构师必须知道如何画矩形、圆形和三角形。他必须精通着色，并且能把它们连接起来。图形有虚线和实线。有些线条必须像箭头一样结束。选择箭头的方向本身就是一个挑战，因此线条通常会在两端都有箭头。
- en: The important part of being an architect is that drawing diagrams and writing
    countless pages of Word documents was so time demanding, that coding stopped being
    something they do. They stopped learning and exploring beyond Google search and
    comparative tables. The net result is that the architecture would reflect knowledge
    an architect had before they jumped to the new position.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 成为架构师的重要部分是，绘制图表和编写无数页Word文档非常耗时，以至于编程不再是他们的工作内容。他们停止了学习和探索，除了Google搜索和比较表格之外没有其他来源。最终的结果是，架构设计反映了架构师在跳到新职位之前所掌握的知识。
- en: Why am I talking about architects? The reason is simple. They were in charge
    of standardization demanded by sysadmins. They would draw their diagrams and choose
    the stack, developers would use. Whatever that stack was, it was to be considered
    Bible and followed to the letter. Sysadmins were happy since there was a standard
    and a predefined way to set up a server. Architects were thrilled because their
    diagrams served a purpose. Since those stacks were supposed to last forever, developers
    were excited since there was no need for them to learn anything new. Standardization
    killed innovation, but everyone was happy. Happiness is necessary, isn't it? Why
    do we need Java 6 if JDK2 works great? It's been proven by countless diagrams.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我提到架构师？原因很简单。他们负责由系统管理员要求的标准化。他们会画出图表并选择开发人员使用的技术栈。不管那个栈是什么，都必须被视为“圣经”并严格遵守。系统管理员很高兴，因为有了标准和预定义的服务器设置方式。架构师们也很高兴，因为他们的图表有了实际用途。由于这些栈本应持续存在，开发人员也很兴奋，因为他们不需要学习任何新的东西。标准化扼杀了创新，但每个人都很开心。快乐是必须的，不是吗？如果JDK2运行得很好，为什么我们还需要Java
    6呢？这一点已经通过无数图表得到了验证。
- en: Then came Virtual machines and broke everyone's happiness.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然后出现了虚拟机，打破了每个人的快乐。
- en: '**Virtual machines** (**VMs**) were a massive improvement over bare metal infrastructure.
    They allowed us to be more precise with hardware requirements. They could be created
    and destroyed quickly. They could differ. One could host Java application, and
    the other could be dedicated to Ruby on Rails. We could get them in a matter of
    minutes, instead of waiting for months. Still, it took quite a while until "could"
    became "can". Even though the advantages brought by VMs were numerous, years passed
    until they were widely adopted. Even then, the adoption was usually wrong. Companies
    often moved the same practices used with bare metal servers into virtual machines.
    That is not to say that adopting VMs did not bring immediate value. Waiting time
    for servers dropped from months to weeks. If it wasn''t for administrative tasks,
    manual operations, and operational bottlenecks, they could have reduced waiting
    time to minutes. Still, waiting for weeks was better than waiting for months.
    Another benefit is that we could have identical servers in different environments.
    Companies started copying VMs. While that was much better than before, it did
    not solve the problem of missing documentation and the ability to create VMs from
    scratch. Still, multiple identical environments are better than one, even if that
    meant that we don''t know what''s inside.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**虚拟机**（**VM**）相比裸金属基础设施是一项巨大的进步。它们使我们能够更加精确地定义硬件需求。虚拟机可以快速创建和销毁。它们可以有不同的配置，一个可以运行Java应用程序，另一个可以专门用于Ruby
    on Rails。我们可以在几分钟内获得它们，而不需要等待数月。然而，即使虚拟机带来的好处是显而易见的，直到多年后它们才被广泛采用。即使如此，虚拟机的采用仍然存在很多问题。公司常常将裸金属服务器上使用的相同做法转移到虚拟机上。这并不是说虚拟机的采用没有带来即时的价值。服务器的等待时间从几个月减少到了几周。如果没有行政任务、手动操作和操作瓶颈，它们本可以将等待时间缩短到几分钟。尽管如此，等待几周总比等待几个月好。另一个好处是，我们可以在不同的环境中拥有相同的服务器。公司开始复制虚拟机。虽然这比以前好多了，但它并没有解决缺乏文档和从零创建虚拟机的能力问题。尽管如此，多个相同的环境总比一个环境好，即使我们不知道里面到底有什么。'
- en: While the adoption of VMs was increasing, so did the number of configuration
    management tools. We got Chef, Puppet, Ansible, Salt, and so on. Some of them
    might have existed before VMs. Still, virtual machines made them popular. They
    helped spread the adoption of "infrastructure as code" principles. However, those
    tools were based on the same principles as CFEngine. That means that they were
    designed with static infrastructure in mind. On the other hand, VMs opened the
    doors to dynamic infrastructure where VMs are continuously created and destroyed.
    Mutability and constant creation and destruction were clashing. Mutable infrastructure
    is well suited for static infrastructure. It does not respond well to challenges
    brought with dynamic nature of modern data centers. Mutability had to give way
    to immutability.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 随着虚拟机（VM）的采用逐渐增多，配置管理工具的数量也在增加。我们有了Chef、Puppet、Ansible、Salt等工具。虽然其中一些工具可能在虚拟机出现之前就存在，但虚拟机使得它们变得流行。它们帮助推广了“基础设施即代码”（Infrastructure
    as Code）原则。然而，这些工具的设计原理与CFEngine相同。也就是说，它们是以静态基础设施为设计基础的。另一方面，虚拟机为动态基础设施开辟了新的天地，其中虚拟机被不断创建和销毁。可变性和不断的创建与销毁发生了冲突。可变基础设施非常适合静态基础设施，但它无法有效应对现代数据中心的动态特性所带来的挑战。可变性最终不得不让位于不可变性。
- en: When ideas behind immutable infrastructure started getting traction, people
    began combining them with the concepts behind configuration management. However,
    tools available at that time were not fit for the job. They (Chef, Puppet, Ansible,
    and the like) were designed with the idea that servers are brought into the desired
    state at runtime. Immutable processes, on the other hand, assume that (almost)
    nothing is changeable at runtime. Artifacts were supposed to be created as immutable
    images. In case of infrastructure, that meant that VMs are created from images,
    and not changed at runtime. If an upgrade is needed, new image should be created
    followed with a replacement of old VMs with new ones based on the new image. Such
    processes brought speed and reliability. With proper tests in place, immutable
    is always more reliable than mutable.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当不可变基础设施的理念开始获得关注时，人们开始将其与配置管理的概念结合起来。然而，当时可用的工具并不适合这个工作。它们（如Chef、Puppet、Ansible等）是以“在运行时将服务器配置到期望状态”的理念设计的。另一方面，不可变的过程假设（几乎）没有东西可以在运行时改变。工件应该作为不可变的镜像创建。在基础设施的情况下，这意味着虚拟机是从镜像创建的，而不是在运行时进行更改。如果需要升级，应该创建新的镜像，并用基于新镜像的虚拟机替换旧的虚拟机。这样的过程带来了速度和可靠性。在适当的测试到位的情况下，不可变的方式总是比可变的方式更可靠。
- en: Hence, we got tools capable of building VM images. Today, they are ruled by
    Packer. Configuration management tools quickly jumped on board, and their vendors
    told us that they work equally well for configuring images as servers at runtime.
    However, that was not the case due to the logic behind those tools. They are designed
    to put a server that is in an unknown state into the desired state. They assume
    that we are not sure what the current state is. VM images, on the other hand,
    are always based on an image with a known state. If for example, we choose Ubuntu
    as a base image, we know what's inside it. Adding additional packages and configurations
    is easy. There is no need for things like "if this then that, otherwise something
    else." A simple shell script is as good as any configuration management tool when
    the current state is known. Creating a VM image is reasonably straightforward
    with Packer alone. Still, not all was lost for configuration management tools.
    We could still use them to orchestrate the creation of VMs based on images and,
    potentially, do some runtime configuration that couldn't be baked in. Right?
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们获得了能够构建虚拟机镜像的工具。今天，它们由Packer主导。配置管理工具迅速加入了这一行列，供应商告诉我们，它们在配置镜像和运行时配置服务器时同样有效。然而，事实并非如此，因为这些工具背后的逻辑不同。它们的设计目的是将处于未知状态的服务器配置到期望的状态。它们假设我们无法确认当前状态是什么。另一方面，虚拟机镜像总是基于具有已知状态的镜像。例如，如果我们选择Ubuntu作为基础镜像，我们知道它内部包含什么。添加额外的包和配置非常简单。不需要像“如果这样，则那样，否则做其他事情”这样的复杂逻辑。当当前状态已知时，简单的shell脚本就能与任何配置管理工具相媲美。仅使用Packer创建虚拟机镜像是相当直接的。尽管如此，配置管理工具并没有完全失去价值。我们仍然可以使用它们来协调基于镜像创建虚拟机的过程，并且可能执行一些不能预先配置的运行时配置，对吧？
- en: The way we orchestrate infrastructure had to change as well. A higher level
    of dynamism and elasticity was required. That became especially evident with the
    emergence of cloud hosting providers like **Amazon Web Services** (**AWS**) and,
    later on, Azure and GCE. They showed us what can be done. While some companies
    embraced the cloud, others went into defensive positions. "We can build an internal
    cloud", "AWS is too expensive", "I would, but I can't because of legislation",
    and "our market is different", are only a few ill-conceived excuses often given
    by people who are desperately trying to maintain status quo. That is not to say
    that there is no truth in those statements but that, more often than not, they
    are used as an excuse, not for real reasons.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们协调基础设施的方式也必须发生变化。需要更高水平的动态性和弹性。随着像**亚马逊云服务**（**AWS**）这样的云托管提供商的出现，这一点变得尤为明显，后来还有Azure和GCE。他们向我们展示了什么是可能实现的。虽然一些公司接受了云服务，其他公司则采取了防守的态度。“我们可以建立一个内部云”，“AWS太贵”，“我想做，但由于法律原因做不到”，“我们的市场不同”，这些都是人们在极力维护现状时常用的几种错误理由。并不是说这些陈述没有一点道理，而是说它们更多时候被用作借口，而非真正的原因。
- en: Still, the cloud did manage to become the way to do things, and companies moved
    their infrastructure to one of the providers. Or, at least, started thinking about
    it. The number of companies that are abandoning on-premise infrastructure is continuously
    increasing, and we can safely predict that the trend will continue. Still, the
    question remains. How do we manage infrastructure in the cloud with all the benefits
    it gives us? How do we handle its highly dynamic nature? The answer comes in the
    form of vendor-specific tools like CloudFormation or agnostic solutions like Terraform.
    When combined with tools that allow us to create images, they represent a new
    generation of configuration management. We are talking about full automation backed
    by immutability.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，云计算仍然成功地成为了工作方式，企业将其基础设施迁移到某个云服务提供商那里，或者至少开始考虑这一点。越来越多的公司正在放弃本地基础设施，我们可以放心地预测这一趋势将继续下去。然而，问题依然存在。我们如何管理云中的基础设施，充分利用其带来的所有好处？我们如何应对其高度动态的特性？答案以供应商特定工具（如CloudFormation）或中立解决方案（如Terraform）的形式出现。结合能够帮助我们创建镜像的工具，它们代表了新一代的配置管理。我们所谈论的是由不变性支撑的完全自动化。
- en: We're living in an era without the need to SSH into servers.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生活在一个不再需要通过SSH连接到服务器的时代。
- en: Today, modern infrastructure is created from immutable images. Any upgrade is
    performed by building new images and performing rolling updates that will replace
    VMs one by one. Infrastructure dependencies are never changed at runtime. Tools
    like Packer, Terraform, CloudFormation, and the like are the answer to today's
    problems.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，现代基础设施是通过不变的镜像来创建的。任何升级都是通过构建新的镜像并进行滚动更新来逐一替换虚拟机。基础设施的依赖关系从不在运行时发生变化。像Packer、Terraform、CloudFormation等工具正是当今问题的答案。
- en: One of the inherent benefits behind immutability is a clear division between
    infrastructure and deployments. Until not long ago, the two meshed together into
    an inseparable process. With infrastructure becoming a service, deployment processes
    can be clearly separated, thus allowing different teams, individuals, and expertise
    to take control.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 不变性背后固有的一个好处是基础设施和部署之间的清晰划分。直到不久前，这两者融为一体，形成了一个不可分割的过程。随着基础设施成为一种服务，部署过程可以明确分开，从而让不同的团队、个人和专业人士能够各自掌控。
- en: We'll need to go back in time one more time and discuss the history of deployments.
    Did they change as much as infrastructure?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要回顾一下过去，讨论一下部署历史。它们的变化是否和基础设施一样大？
- en: A short history of deployment processes
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署过程的简短历史
- en: In the beginning, there were no package managers. There were no JAR, WAR, RPM,
    DEB, and other package formats. At best, we could zip files that form a release.
    More likely, we'd manually copy files from one place to another. When this practice
    is combined with bare-metal servers which were intended to last forever, the result
    was living hell. After some time, no one knew what was installed on the servers.
    Constant overwrites, reconfigurations, package installations, and mutable types
    of actions resulted in unstable, unreliable, and undocumented software running
    on top of countless OS patches.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在最初，没有包管理器。没有JAR、WAR、RPM、DEB和其他包格式。最多，我们可以将文件压缩成一个发布包。更常见的是，我们手动将文件从一个地方复制到另一个地方。当这种做法与旨在长期使用的裸金属服务器结合时，结果简直是生不如死。过了一段时间，没人知道服务器上安装了什么。不断的覆盖、重新配置、包安装以及可变类型的操作，导致了不稳定、不可靠且没有文档支持的软件运行在无数操作系统补丁之上。
- en: The emergence of configuration management tools (for example, CFEngine, Chef,
    Puppet, and so on) helped to decrease the mess. Still, they improved OS setups
    and maintenance, more than deployments of new releases. They were never designed
    to do that even though the companies behind them quickly realized that it would
    be financially beneficial to extend their scope.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 配置管理工具（例如CFEngine、Chef、Puppet等）的出现有助于减少混乱。尽管如此，它们更多的是改进了操作系统的设置和维护，而不是新版本的部署。即使这些工具背后的公司很快意识到扩大其范围将带来经济利益，它们也从未被设计用于此目的。
- en: Even with configuration management tools, the problems with having multiple
    services running on the same server persisted. Different services might have different
    needs, and sometimes those needs clash. One might need JDK6 and the other JDK7\.
    A new release of the first one might require JDK to be upgraded to a new version,
    but that might affect some other service on the same server. Conflicts and operational
    complexity were so common that many companies would choose to standardize. As
    we discussed, standardization is innovation killer. The more we standardize, the
    less room there is for coming up with better solutions. Even if that's not a problem,
    standardization with clear isolation means that it is very complicated to upgrade
    something. Effects could be unforeseen and the sheer work involved to upgrade
    everything at once is so significant that many choose not to upgrade for a long
    time (if ever). Many end up stuck with old stacks for a long time.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 即使有了配置管理工具，多个服务在同一台服务器上运行的问题依然存在。不同的服务可能有不同的需求，而这些需求有时会发生冲突。一方可能需要JDK6，另一方需要JDK7。第一个服务的新版本可能要求将JDK升级到新版本，但这可能会影响同一服务器上的其他服务。冲突和操作复杂性非常常见，以至于许多公司选择进行标准化。正如我们所讨论的，标准化是创新的杀手。我们标准化得越多，能够提出更好解决方案的空间就越小。即使这不是问题，标准化和明确的隔离意味着升级某个服务变得非常复杂。影响可能是不可预见的，而且一次性升级所有内容所需的工作量如此巨大，以至于许多人长时间（甚至永远）选择不升级。最终，许多公司被迫长时间使用旧的技术栈。
- en: We needed process isolation that does not require a separate VM for each service.
    At the same time, we had to come up with an immutable way to deploy software.
    Mutability was distracting us from our goal to have reliable environments. With
    the emergence of virtual machines, immutability became feasible. Instead of deploying
    releases by doing updates at runtime, we could create new VMs with not only OS
    and patches but also our own software baked in. Each time we wanted to release
    something, we could create a new image, and instantiate as many VMs as we need.
    We could do immutable rolling updates. Still, not many of us did that. It was
    too expensive, both regarding resources as well as time. The process was too long.
    Even if that would not matter, having a separate VM for each service would result
    in too much unused CPU and memory.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一种进程隔离的方式，而不需要为每个服务单独配置虚拟机。同时，我们必须想出一种不可变的方式来部署软件。可变性使我们无法实现可靠的环境。随着虚拟机的出现，不可变性变得可行。我们不再需要通过运行时更新来部署版本，而是可以创建新的虚拟机，不仅包括操作系统和补丁，还包括我们自己的软件。每次我们想发布新版本时，我们可以创建一个新的镜像，并实例化任意数量的虚拟机。我们可以进行不可变的滚动更新。尽管如此，实际上并没有多少公司在这样做。它太昂贵了，不仅在资源上，时间上也非常浪费。这个过程太长了。即使这不成问题，为每个服务配置一个单独的虚拟机会导致CPU和内存的浪费。
- en: Fortunately, Linux got namespaces, cgroups, and other things that are together
    known as containers. They were lightweight, fast, and cheap. They provided process
    isolation and quite a few other benefits. Unfortunately, they were not easy to
    use. Even though they've been around for a while, only a handful of companies
    had the know-how required for their beneficial utilization. We had to wait for
    Docker to emerge to make containers easy to use and thus accessible to all.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Linux引入了命名空间（namespaces）、控制组（cgroups）以及其他被统称为容器的技术。它们轻量、快速且廉价。它们提供了进程隔离以及其他许多好处。不幸的是，它们并不容易使用。尽管容器技术已经存在了一段时间，只有少数几家公司具备利用它们的专业知识。我们不得不等到Docker的出现，才使容器变得易于使用，并使其对所有人都可及。
- en: Today, containers are the preferable way to package and deploy services. They
    are the answer to immutability, we were so desperately trying to implement. They
    provide necessary isolation of processes, optimized resource utilization, and
    quite a few other benefits. And yet, we already realized that we need much more.
    It's not enough to run containers. We need to be able to scale them, to make them
    fault tolerant, to provide transparent communication across a cluster, and many
    other things. Containers are only a low-level piece of the puzzle. The real benefits
    are obtained with tools that sit on top of containers. Those tools are today known
    as container schedulers. They are our interface. We do not manage containers,
    they do.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，容器是打包和部署服务的首选方式。它们是我们曾经迫切想实现的不可变性问题的答案。容器提供了必要的进程隔离、优化的资源利用率和其他一些好处。然而，我们也意识到我们需要更多。仅仅运行容器是不够的。我们需要能够扩展它们，让它们具备容错能力，提供集群之间透明的通信，还有很多其他需求。容器只是这幅拼图中的一个低级部分。真正的好处是通过位于容器之上的工具来获得的。这些工具今天被称为容器调度器。它们是我们的接口。我们不管理容器，是它们管理我们。
- en: In case you are not already using one of the container schedulers, you might
    be wondering what they are.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有使用任何容器调度器，你可能会想知道它们是什么。
- en: What is a container scheduler?
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是容器调度器？
- en: Picture me as a young teenager. After school, we'd go a courtyard and play soccer.
    That was an exciting sight. A random number of us running around the yard without
    any orchestration. There was no offense and no defense. We'd just run after a
    ball. Everyone moves forward towards the ball, someone kicks it to the left, and
    we move in that direction, only to start running back because someone kicked the
    ball again. The strategy was simple. Run towards the ball, kick it if you can,
    wherever you can, repeat. To this day I do not understand how anyone managed to
    score. It was complete randomness applied to a bunch of kids. There was no strategy,
    no plan, and no understanding that winning required coordination. Even a goalkeeper
    would be in random locations on the field. If he caught the ball around the goal
    he's guarding, he'd continue running with the ball in front of him. Most of the
    goals were scored by shooting at an empty goal. It was an "every man for himself"
    type of ambition. Each one of us hoped to score and bring glory to his or her
    name. Fortunately, the main objective was to have fun so winning as a team did
    not matter that much. If we were a "real" team, we'd need a coach. We'd need someone
    to tell us what the strategy is, who should do what, and when to go on the offense
    or fall back to defend the goal. We'd need someone to orchestrate us. The field
    (a cluster) had a random number of people (services) with the common goal (to
    win). Since anyone could join the game at any time, the number of people (services)
    was continually changing.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下我还是个年轻的青少年。放学后，我们会去院子里踢足球。那是一个激动人心的场景。我们一群人随意地在院子里奔跑，完全没有组织。没有进攻，也没有防守。我们只会追着球跑。每个人都朝着球的方向跑，有人把球踢向左边，我们就朝那个方向跑，结果又因为有人把球踢了回来而开始向后跑。策略很简单。朝着球跑，能踢就踢，随便在哪踢，重复。这么多年过去了，我依然不明白有人是怎么进球的。那完全是随机的，适用于一群孩子。没有策略，没有计划，也没有意识到获胜需要协调。甚至守门员也总是出现在场地的随机位置。如果他在他守的门附近接到球，他会继续带着球跑。大部分进球都是踢向空门的。那是一种“每个人为自己”类型的野心。我们每个人都希望能进球，为自己争光。幸运的是，最主要的目标是玩得开心，所以团队的胜负并不那么重要。如果我们是一个“真正的”团队，我们就需要一个教练。我们需要有人告诉我们策略是什么，谁应该做什么，什么时候进攻，什么时候退守。我们需要有人来指挥我们。这个场地（集群）有着一个随机数量的人（服务），而他们有着共同的目标（获胜）。因为任何人都可以随时加入游戏，所以人数（服务）是不断变化的。
- en: Someone would be injured and would have to be replaced or, when there was no
    replacement, the rest of us would have to take over his tasks (self-healing).
    Those football games can be easily translated into clusters. Just as we needed
    someone to tell us what to do (a coach), clusters need something to orchestrate
    all the services and resources. Both need not only to make up-front decisions,
    but also to continuously watch the game/cluster, and adapt the strategy/scheduling
    depending on the internal and external influences. We needed a coach and clusters
    need a scheduler. They need a framework that will decide where a service should
    be deployed and make sure that it maintains the desired run-time specification.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 有人受伤并需要被替换，或者当没有替代者时，我们其余的人必须接管他的任务（自愈）。这些足球比赛可以很容易地转化为集群。就像我们需要有人告诉我们该做什么（教练），集群也需要某种东西来协调所有服务和资源。两者不仅需要做出事先决策，还需要不断观察比赛/集群，并根据内外部影响调整策略/调度。我们需要一个教练，而集群需要一个调度器。它们需要一个框架，来决定服务应该部署在哪里，并确保它保持期望的运行时规范。
- en: A cluster scheduler has quite a few goals. It's making sure that resources are
    used efficiently and within constraints. It's making sure that services are (almost)
    always running. It provides fault tolerance and high availability. It makes sure
    that the specified number of replicas are deployed. The list can go on for a while
    and varies from one solution to another. Still, no matter the exact list of cluster
    scheduler's responsibilities, they can be summarized through the primary goal.
    A scheduler is making sure that the desired state of a service or a node is (almost)
    always fulfilled. Instead of using imperative methods to achieve our goals, with
    schedulers we can be declarative. We can tell a scheduler what the desired state
    is, and it will do its best to ensure that our desire is (almost) always fulfilled.
    For example, instead of executing a deployment process five times hoping that
    we'll have five replicas of a service, we can tell a scheduler that our desired
    state is to have the service running with five replicas.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 集群调度器有许多目标。它确保资源得到高效利用并符合约束条件。它确保服务（几乎）始终运行。它提供容错和高可用性。它确保指定数量的副本被部署。这个列表可以持续一段时间，并且在不同的解决方案中有所不同。然而，不管集群调度器的具体责任列表如何，它们都可以通过主要目标进行概括。调度器确保服务或节点的期望状态（几乎）始终得到满足。与其使用命令式方法来实现目标，我们可以通过调度器采用声明式方法。我们可以告诉调度器期望的状态是什么，它将尽最大努力确保我们的期望（几乎）始终得到满足。例如，我们可以告诉调度器，我们的期望状态是让服务运行并具有五个副本，而不是执行五次部署过程，指望我们会有五个副本。
- en: The difference between imperative and declarative methods might seem subtle
    but, in fact, is enormous. With a declarative expression of the desired state,
    a scheduler can monitor a cluster and perform actions whenever the actual state
    does not match the desired. Compare that to an execution of a deployment script.
    Both will deploy a service and produce the same initial result. However, the script
    will not make sure that the result is maintained over time. If an hour later,
    one of the replicas fail, our system will be compromised. Traditionally, we were
    solving that problem with a combination of alerts and manual interventions. An
    operator would receive a notification that a replica failed, he'd login to the
    server, and restart the process. If the whole server is down, the operator might
    choose to create a new one, or he might deploy the failed replica to one of the
    other servers. But, before doing that, he'd need to check which server has enough
    available memory and CPU. All that, and much more, is done by schedulers without
    human intervention. Think of schedulers as operators who are continually monitoring
    the system and fixing discrepancies between the desired and the actual state.
    The difference is that schedulers are infinitely faster and more accurate. They
    do not get tired, they do not need to go to the bathroom, and they do not require
    paychecks. They are machines or, to be more precise, software running on top of
    them.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 命令式和声明式方法之间的差异看起来可能很微妙，但实际上差异巨大。通过声明期望状态的方式，调度器可以监控集群，并在实际状态与期望状态不匹配时执行操作。与执行部署脚本相比，两者都会部署服务并产生相同的初始结果。然而，脚本并不会确保结果在一段时间后得到保持。如果一个小时后，某个副本失败了，我们的系统就会受到影响。传统上，我们通过警报和人工干预来解决这个问题。操作员会收到副本失败的通知，然后登录服务器并重启进程。如果整个服务器宕机，操作员可能会选择创建一个新的服务器，或者将失败的副本部署到其他服务器之一。但在此之前，他需要检查哪个服务器有足够的可用内存和
    CPU。所有这些，甚至更多，都是由调度器在没有人工干预的情况下完成的。可以把调度器看作是持续监控系统并修复期望状态与实际状态之间差异的操作员。不同之处在于，调度器无比快速且精准。它们不会疲劳，不需要上厕所，也不需要工资。它们是机器，或者更准确地说，是在其上运行的软件。
- en: That leads us to container schedulers. How do they differ from schedulers in
    general?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了容器调度器。它们与一般调度器有何不同呢？
- en: Container schedulers are based on the same principles as schedulers in general.
    The significant difference is that they are using containers as the deployment
    units. They are deploying services packaged as container images. They are trying
    to collocate them depending on desired memory and CPU specifications. They are
    making sure that the desired number of replicas are (almost) always running. All
    in all, they do what other schedulers do but with containers as the lowest and
    the only packaging unit. And that gives them a distinct advantage. They do not
    care what's inside. From scheduler's point of view, all containers are the same.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 容器调度器与一般调度器基于相同的原则。其显著区别在于它们使用容器作为部署单元。它们部署的是以容器镜像打包的服务。它们根据所需的内存和 CPU 规格尝试将服务放置在一起。它们确保所需数量的副本（几乎）始终运行。总的来说，它们的工作方式与其他调度器相同，但容器是最小且唯一的打包单元。这给它们带来了明显的优势。它们不关心容器内部的内容。从调度器的角度来看，所有容器都是一样的。
- en: Containers provide benefits that other deployment mechanisms do not. Services
    deployed as containers are isolated and immutable. Isolation provides reliability.
    Isolation helps with networking and volume management. It avoids conflicts. It
    allows us to deploy anything, anywhere, without worrying whether that something
    will clash with other processes running on the same server. Schedulers, combined
    with containers and virtual machines, provide the ultimate cluster management
    nirvana. That will change in the future but, for now, container schedulers are
    the peak of engineering accomplishments. They allow us to combine the developer's
    necessity for rapid and frequent deployments with a sysadmin's goals of stability
    and reproducibility. And that leads us to Kubernetes.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 容器提供了其他部署机制无法提供的好处。作为容器部署的服务是隔离且不可变的。隔离提供了可靠性。隔离有助于网络和存储卷管理。它避免了冲突。它允许我们在任何地方部署任何东西，而不必担心这些东西是否会与同一服务器上运行的其他进程发生冲突。调度器结合容器和虚拟机提供了终极的集群管理理想状态。虽然未来这一点可能会发生变化，但目前为止，容器调度器是工程成就的巅峰。它们让我们能够结合开发者对快速和频繁部署的需求与系统管理员对稳定性和可复现性的目标。这就引出了
    Kubernetes。
- en: What is Kubernetes?
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 Kubernetes？
- en: To understand Kubernetes, it is important to realize that running containers
    directly is a bad option for most use cases. Containers are low-level entities
    that require a framework on top. They need something that will provide all the
    additional features we expect from services deployed to clusters. In other words,
    containers are handy but are not supposed to be run directly. The reason is simple.
    Containers, by themselves, do not provide fault tolerance. They cannot be deployed
    easily to the optimum spot in a cluster, and, to cut a long story short, are not
    operator friendly. That does not mean that containers by themselves are not useful.
    They are, but they require much more if we are to harness their real power. If
    we need to operate containers at scale and if we need them to be fault tolerant
    and self-healing, and have the other features we expect from modern clusters,
    we need more. We need at least a scheduler, probably more.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解 Kubernetes，重要的是要意识到直接运行容器对于大多数使用场景来说是一个糟糕的选择。容器是低级实体，需要一个框架来支撑它们。它们需要一些东西来提供我们期望从集群中部署的服务所需的所有附加功能。换句话说，容器很方便，但不应该直接运行。原因很简单，容器本身不提供容错能力。它们无法轻松地部署到集群中的最佳位置，并且，简而言之，不适合运维人员使用。这并不意味着容器本身没有用处。它们是有用的，但如果我们要充分发挥它们的真正潜力，它们还需要更多。如果我们需要在大规模操作容器，并且需要它们具备容错和自愈功能，以及我们期望现代集群所具备的其他功能，我们需要更多。我们至少需要一个调度器，可能还需要更多。
- en: Kubernetes was first developed by a team at Google. It is based on their experience
    from running containers at scale for years. Later on, it was donated to [**Cloud
    Native Computing Foundation** (**CNCF**)](https://www.cncf.io/) ([https://www.cncf.io/](https://www.cncf.io/)).
    It is a true open source project with probably the highest velocity in history.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 最初由 Google 的一个团队开发，基于他们多年在大规模运行容器的经验。后来，它被捐赠给了 [**云原生计算基金会** (**CNCF**)](https://www.cncf.io/)
    ([https://www.cncf.io/](https://www.cncf.io/))。它是一个真正的开源项目，可能是历史上发展最快的项目之一。
- en: Kubernetes is a container scheduler and quite a lot more. We can use it to deploy
    our services, to roll out new releases without downtime, and to scale (or de-scale)
    those services. It is portable. It can run on a public or private cloud. It can
    run on-premise or in a hybrid environment. Kubernetes, in a way, makes your infrastructure
    vendor agnostic. We can move a Kubernetes cluster from one hosting vendor to another
    without changing (almost) any of the deployment and management processes. Kubernetes
    can be easily extended to serve nearly any needs. We can choose which modules
    we'll use, and we can develop additional features ourselves and plug them in.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个容器调度器，功能远不止如此。我们可以使用它来部署我们的服务，进行无停机时间的发布更新，以及对这些服务进行扩展（或缩减）。它是可移植的，可以在公有云或私有云上运行，也可以在本地或混合环境中运行。从某种程度上说，Kubernetes
    使得你的基础设施与供应商无关。我们可以将一个 Kubernetes 集群从一个托管供应商迁移到另一个供应商，而几乎不需要改变任何部署和管理流程。Kubernetes
    可以轻松扩展，以满足几乎任何需求。我们可以选择使用哪些模块，还可以开发额外的功能并将其插入系统。
- en: If we choose to use Kubernetes, we decide to relinquish control. Kubernetes
    will decide where to run something and how to accomplish the state we specify.
    Such control allows Kubernetes to place replicas of a service on the most appropriate
    server, to restart them when needed, to replicate them, and to scale them. We
    can say that self-healing is a feature included in its design from the start.
    On the other hand, self-adaptation is coming as well. At the time of this writing,
    it is still in its infancy. Soon it will be an integral part of the system.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择使用 Kubernetes，我们就决定放弃控制权。Kubernetes 将决定在哪里运行某些东西以及如何实现我们指定的状态。这种控制允许 Kubernetes
    将服务的副本放置在最合适的服务器上，在需要时重启它们，进行复制，并对它们进行扩展。我们可以说，自愈能力是其设计初衷的一部分。另一方面，自适应功能也在逐步实现中。到目前为止，它仍处于初期阶段，但很快将成为系统的一个核心部分。
- en: Zero-downtime deployments, fault tolerance, high availability, scaling, scheduling,
    and self-healing should be more than enough to see the value in Kubernetes. Yet,
    that is only a fraction of what it provides. We can use it to mount volumes for
    stateful applications. It allows us to store confidential information as secrets.
    We can use it to validate the health of our services. It can load balance requests
    and monitor resources. It provides service discovery and easy access to logs.
    And so on and so forth. The list of what Kubernetes does is long and rapidly increasing.
    Together with Docker, it is becoming a platform that envelops whole software development
    and deployment lifecycle.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 零停机部署、容错、高可用性、扩展、调度和自我修复，应该足以让你看到 Kubernetes 的价值。然而，这仅仅是它所提供的一部分功能。我们可以使用它为有状态应用程序挂载存储卷。它允许我们将机密信息存储为秘密。我们可以使用它验证服务的健康状况。它可以负载均衡请求并监控资源。它提供服务发现和便捷的日志访问，等等。Kubernetes
    所能做的事情清单很长，而且在迅速增加。与 Docker 一起，它正逐渐成为一个涵盖整个软件开发和部署生命周期的平台。
- en: The Kubernetes project has just started. It is in its infancy, and we can expect
    vast improvements and new features coming soon. Still, do not be fooled with "infancy".
    Even though the project is young, it has one of the biggest communities behind
    it and is used in some of the biggest clusters in the world. Do not wait. Adopt
    it now!
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 项目刚刚起步。它还处于初期阶段，我们可以期待很快会有大量改进和新功能推出。尽管如此，不要被“初期阶段”所迷惑。即使这个项目还年轻，它背后拥有世界上最大的社区之一，并且已被用于一些全球最大规模的集群。不要再等了，现在就采用它吧！
