- en: '*Chapter 5*: Services and Ingress – Communicating with the Outside World'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 5 章*：服务和 Ingress——与外界通信'
- en: This chapter contains a comprehensive discussion of the methods that Kubernetes
    provides to allow applications to communicate with each other, and with resources
    outside the cluster. You'll learn about the Kubernetes Service resource and all
    its possible types – ClusterIP, NodePort, LoadBalancer, and ExternalName – as
    well as how to implement them. Finally, you'll learn how to use Kubernetes Ingress.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含了 Kubernetes 提供的允许应用程序彼此通信，以及与集群外部资源通信的方法的全面讨论。你将学习到 Kubernetes 服务资源及其所有可能的类型——ClusterIP、NodePort、LoadBalancer
    和 ExternalName——以及如何实现它们。最后，你将学习如何使用 Kubernetes Ingress。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Understanding Services and cluster DNS
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 Services 和集群 DNS
- en: Implementing ClusterIP
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现 ClusterIP
- en: Using NodePort
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 NodePort
- en: Setting up a LoadBalancer Service
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置 LoadBalancer 服务
- en: Creating an ExternalName Service
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 ExternalName 服务
- en: Configuring Ingress
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置 Ingress
- en: Technical requirement
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In order to run the commands detailed in this chapter, you will need a computer
    that supports the `kubectl` command-line tool along with a working Kubernetes
    cluster. Review [*Chapter 1*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016),
    *Communicating with Kubernetes*, to see several methods for getting up and running
    with Kubernetes quickly, and for instructions on how to install the `kubectl`
    tool.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行本章中详细说明的命令，你需要一台支持 `kubectl` 命令行工具并且有一个正常工作的 Kubernetes 集群的计算机。查看 [*第 1
    章*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016)，*与 Kubernetes 通信*，以了解几种快速启动和运行
    Kubernetes 的方法，并查看如何安装 `kubectl` 工具的说明。
- en: The code used in this chapter can be found in the book's GitHub repository at
    [https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter5](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter5).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的代码可以在本书的 GitHub 仓库中找到，网址为 [https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter5](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter5)。
- en: Understanding Services and cluster DNS
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 Services 和集群 DNS
- en: In the last few chapters, we've talked about how to run applications effectively
    on Kubernetes using resources including Pods, Deployments, and StatefulSets. However,
    many applications, such as web servers, need to be able to accept network requests
    from outside their containers. These requests could come either from other applications
    or from devices accessing the public internet.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们讨论了如何使用包括 Pods、Deployments 和 StatefulSets 在内的资源，在 Kubernetes 上有效运行应用程序。然而，许多应用程序（如
    web 服务器）需要能够接受来自其容器外部的网络请求。这些请求可能来自其他应用程序或从设备访问公共互联网。
- en: Kubernetes provides several types of resources to handle various scenarios when
    it comes to allowing resources outside and inside the cluster to access applications
    running on Pods, Deployments, and more.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 提供了多种资源类型，用于处理允许集群外部和内部资源访问运行在 Pods、Deployments 等上的应用程序的各种场景。
- en: 'These fall into two major resource types, Services and Ingress:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些分为两大资源类型：Services 和 Ingress：
- en: '**Services** have several subtypes – ClusterIP, NodePort, and LoadBalancer
    – and are generally used to provide simple access to a single application from
    inside or outside the cluster.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务**有多个子类型——ClusterIP、NodePort 和 LoadBalancer——通常用于从集群内部或外部提供对单一应用程序的简单访问。'
- en: '**Ingress** is a more advanced resource that creates a controller that takes
    care of pathname- and hostname-based routing to various resources running inside
    the cluster. Ingress works by using rules to forward traffic to Services. You
    need to use Services to use Ingress.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ingress** 是一种更高级的资源，它创建一个控制器，用于处理基于路径名和主机名的路由，指向集群内部运行的各种资源。Ingress 通过使用规则将流量转发到
    Services。你需要使用 Services 来使用 Ingress。'
- en: Before we get started with our first type of Service resource, let's review
    how Kubernetes handles DNS inside the cluster.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始介绍我们第一种服务资源类型之前，让我们先回顾一下 Kubernetes 如何在集群内部处理 DNS。
- en: Cluster DNS
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集群 DNS
- en: Let's start by discussing which resources in Kubernetes get their own DNS names
    by default. DNS names in Kubernetes are restricted to Pods and Services. Pod DNS
    names contain several parts structured as subdomains.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先讨论 Kubernetes 中哪些资源默认会获得自己的 DNS 名称。Kubernetes 中的 DNS 名称仅限于 Pods 和 Services。Pod
    的 DNS 名称包含多个部分，结构类似子域名。
- en: 'A typical **Fully Qualified Domain Name** (**FQDN**) for a Pod running in Kubernetes
    looks like this:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中运行的 Pod 的典型 **完全限定域名** (**FQDN**) 如下所示：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s break it down, starting from the rightmost side:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从最右边开始逐步分解：
- en: '`my-cluster-domain.example` corresponds to the configured DNS name for the
    Cluster API itself. Depending on the tool used to set up the cluster, and the
    environment that it runs in, this can be an external domain name or an internal
    DNS name.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`my-cluster-domain.example` 对应于集群 API 自身配置的 DNS 名称。根据用于设置集群的工具和其运行的环境，这可以是外部域名或内部
    DNS 名称。'
- en: '`svc` is a section that will occur even in a Pod DNS name – so we can just
    assume it will be there. However, as you will see shortly, you won''t generally
    be accessing Pods or Services through their FQDNs.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`svc` 是一个部分，即使在 Pod DNS 名称中也会出现 - 所以我们可以假设它会出现。然而，正如您很快将看到的那样，您通常不会通过它们的完全限定域名访问
    Pod 或服务。'
- en: '`my-namespace` is pretty self-explanatory. This section of the DNS name will
    be whatever namespace your Pod is operating in.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`my-namespace` 是相当不言自明的。DNS 名称的这一部分将是您的 Pod 操作所在的任意命名空间。'
- en: '`my-subdomain` corresponds to the `subdomain` field in the Pod spec. This field
    is completely optional.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`my-subdomain` 对应于 Pod 规范中的 `subdomain` 字段。该字段完全是可选的。'
- en: Finally, `my-hostname` will be set to whatever the name of the Pod is in the
    Pod metadata.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，`my-hostname` 将设置为 Pod 元数据中 Pod 名称。
- en: Together, this DNS name allows other resources in the cluster to access a particular
    Pod. This generally isn't very helpful by itself, especially if you're using Deployments
    and StatefulSets that generally have multiple Pods. This is where Services come
    in.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这个 DNS 名称允许集群中的其他资源访问特定的 Pod。单独来看并不是特别有帮助，特别是当您使用通常具有多个 Pod 的部署和有状态集时。这就是服务的用武之地。
- en: 'Let''s take a look at the A record DNS name for a Service:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下服务的 A 记录 DNS 名称：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As you can see, it's very similar to the Pod DNS name, with the difference that
    we only have one value to the left of our namespace – which is the Service name
    (again, as with Pods, this is generated based on the metadata name).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这与 Pod DNS 名称非常相似，不同之处在于在我们的命名空间左侧仅有一个值 - 这是服务名称（与 Pod 一样，这是基于元数据名称生成的）。
- en: One result of how these DNS names are handled is that within a namespace, you
    can access a Service or Pod via just its Service (or Pod) name, and the subdomain.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 DNS 名称处理的结果之一是，在命名空间内部，您可以仅通过其服务（或 Pod）名称和子域名访问服务或 Pod。
- en: For instance, take our previous Service DNS name. From within the `my-namespace`
    namespace, the Service can be accessed simply by the DNS name `my-svc`. From outside
    the `my-namespace` namespace, you can access the Service via `my-svc.my-namespace`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，取我们之前的服务 DNS 名称。从 `my-namespace` 命名空间内部，可以通过 DNS 名称 `my-svc` 简单访问服务。从 `my-namespace`
    命名空间外部，可以通过 `my-svc.my-namespace` 访问服务。
- en: Now that we've learned how in-cluster DNS works, we can discuss how that translates
    to the Service proxy.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了如何在集群内部使用 DNS，我们可以讨论如何将其转换为服务代理。
- en: Service proxy types
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务代理类型
- en: Services, explained as simply as possible, provide an abstraction to forward
    requests to one or more Pods that are running an application.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Services，尽可能简单地解释，提供了一个抽象层，用于将请求转发到运行应用程序的一个或多个 Pod。
- en: When creating a Service, we define a selector that tells the Service which Pods
    to forward requests to. Through functionality in the `kube-proxy` component, when
    requests hit a Service, they will be forwarded to the various Pods that match
    the Service's selector.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建服务时，我们定义一个选择器，告诉服务将请求转发到哪些符合服务选择器的 Pod。通过 `kube-proxy` 组件的功能，在请求到达服务时，它们将被转发到匹配服务选择器的各个
    Pod。
- en: 'There are three possible proxy modes that you can use in Kubernetes:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 中有三种可能的代理模式可以使用：
- en: '**Userspace proxy mode**: The oldest proxy mode, available since Kubernetes
    version 1.0\. This proxy mode will forward requests to the matched Pods in a round-robin
    fashion.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户空间代理模式**：最古老的代理模式，自 Kubernetes 版本 1.0 起可用。该代理模式将以轮询方式将请求转发到匹配的 Pod。'
- en: '**Iptables proxy mode**: Available since 1.1, and the default since 1.2\. This
    offers a lower overhead than userspace mode and can use round robin or random
    selection.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Iptables 代理模式**：自 1.1 版本起可用，并且自 1.2 版本起成为默认选项。与用户空间模式相比，这种模式的开销更低，可以使用轮询或随机选择。'
- en: '**IPVS proxy mode**: The newest option, available since 1.8\. This proxy mode
    allows other load balancing options (not just Round Robin):'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IPVS 代理模式**：自 1.8 版本起提供的最新选项。该代理模式允许使用其他负载均衡选项（不仅限于轮询）：'
- en: a. Round Robin
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 轮询
- en: b. Least Connection (the least number of open connections)
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 最少连接（最少数量的开放连接）
- en: c. Source Hashing
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. 源哈希
- en: d. Destination Hashing
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. 目标哈希
- en: e. Shortest Expected Delay
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e. 最短预期延迟
- en: f. Never Queue
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: f. 永不排队
- en: Relevant to this list is a discussion of what round-robin load balancing is,
    for those not familiar.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不熟悉循环负载均衡的人，相关讨论将解释什么是循环负载均衡。
- en: 'Round-robin load balancing involves looping through the potential list of Service
    endpoints from beginning to end, per network request. The following diagram shows
    a simplified view of this process it pertains to Kubernetes Pods behind a Service:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 循环负载均衡涉及从头到尾遍历服务端点的潜在列表，每次网络请求都会进行一次遍历。下图展示了这一过程的简化视图，它与 Kubernetes 中服务背后的 Pod
    相关：
- en: '![Figure 5.1 – A Service load-balancing to Pods](img/B14790_05_001.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.1 – 服务负载均衡到 Pods](img/B14790_05_001.jpg)'
- en: Figure 5.1 – A Service load-balancing to Pods
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 – 服务负载均衡到 Pods
- en: As you can see, the Service alternates which Pod it sends requests to. The first
    request goes to Pod A, the second goes to Pod B, the third goes to Pod C, and
    then it loops around. Now that we know how Services actually handle requests,
    let's review the major types of Services, starting with ClusterIP.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，服务会交替发送请求到不同的 Pod。第一个请求发送到 Pod A，第二个请求发送到 Pod B，第三个请求发送到 Pod C，然后它会循环往复。现在我们知道服务是如何处理请求的，让我们从
    ClusterIP 开始，回顾主要的服务类型。
- en: Implementing ClusterIP
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现 ClusterIP
- en: 'ClusterIP is a simple type of Service exposed on an internal IP inside the
    cluster. This type of Service is not reachable from outside of the cluster. Let''s
    take a look at the YAML file for our Service:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ClusterIP 是一种简单的服务类型，暴露在集群内的内部 IP 上。这种类型的服务无法从集群外部访问。让我们来看一下服务的 YAML 文件：
- en: clusterip-service.yaml
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: clusterip-service.yaml
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As with other Kubernetes resources, we have our metadata block with our `name`
    value. As you can recall from our discussion on DNS, this `name` value is how
    you can access your Service from elsewhere in the cluster. For this reason, ClusterIP
    is a great option for Services that only need to be accessed by other Pods within
    a cluster.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他 Kubernetes 资源一样，我们有 `metadata` 块，其中包含我们的 `name` 值。正如我们在讨论 DNS 时提到的，`name`
    值是你可以从集群中的其他地方访问服务的方式。正因如此，ClusterIP 是一个很好的选择，适用于仅需通过集群内其他 Pods 访问的服务。
- en: 'Next, we have our `Spec`, which consists of three major pieces:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有 `Spec`，它由三大部分组成：
- en: First, we have our `type`, which corresponds to the type of our Service. Since
    the default type is `ClusterIP`, you don't actually need to specify a type if
    you want a ClusterIP Service.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们有 `type`，它对应于我们的服务类型。由于默认类型是 `ClusterIP`，如果您想使用 ClusterIP 服务，实际上不需要指定类型。
- en: Next, we have our `selector`. Our `selector` consists of key-value pairs that
    must match labels in the metadata of the Pods in question. In this case, our Service
    will look for Pods with `app=web-application` and `environment=staging` to forward
    traffic to.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们有 `selector`。我们的 `selector` 由键值对组成，这些键值对必须与相关 Pods 元数据中的标签匹配。在这种情况下，我们的服务将寻找标签为
    `app=web-application` 和 `environment=staging` 的 Pods 来转发流量。
- en: Finally, we have our `ports` block, where we can map ports on our Service to
    `targetPort` numbers on our Pods. In this case, port `80` (the HTTP port) on our
    Service will map to port `8080` on our application Pod. More than one port can
    be opened on our Service, but the `name` field is required when opening multiple
    ports.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们有 `ports` 块，在这里我们可以将服务上的端口映射到 Pods 上的 `targetPort` 号。在这种情况下，服务上的端口 `80`（HTTP
    端口）将映射到应用程序 Pod 上的端口 `8080`。可以在服务上打开多个端口，但当打开多个端口时，`name` 字段是必需的。
- en: Next, let's review the `protocol` options in depth, since these are important
    to our discussion of Service ports.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们深入了解 `protocol` 选项，因为这些对我们讨论服务端口非常重要。
- en: Protocol
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协议
- en: 'In the case of our previous ClusterIP Service, we chose `TCP` as our protocol.
    Kubernetes currently (as of version 1.19) supports several protocols:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的 ClusterIP 服务中，我们选择了 `TCP` 作为协议。Kubernetes 当前（截至版本 1.19）支持几种协议：
- en: '**TCP**'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TCP**'
- en: '**UDP**'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**UDP**'
- en: '**HTTP**'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HTTP**'
- en: '**PROXY**'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PROXY**'
- en: '**SCTP**'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SCTP**'
- en: This is an area where new features are likely coming, especially where HTTP
    (L7) services are concerned. Currently, there is not full support of all of these
    protocols across environments or cloud providers.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可能会引入新功能的领域，特别是在涉及 HTTP（L7）服务时。目前，所有这些协议在不同环境或云服务提供商中并未完全得到支持。
- en: Important note
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: For more information, you can check the main Kubernetes documentation ([https://kubernetes.io/docs/concepts/services-networking/service/](https://kubernetes.io/docs/concepts/services-networking/service/))
    for the current state of Service protocols.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 若要了解更多信息，您可以查阅 Kubernetes 的官方文档（[https://kubernetes.io/docs/concepts/services-networking/service/](https://kubernetes.io/docs/concepts/services-networking/service/)），以了解当前的服务协议状态。
- en: Now that we've discussed the specifics of Service YAMLs with Cluster IP, we
    can move on to the next type of Service – NodePort.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了带有 Cluster IP 的服务 YAML 文件的具体细节，接下来可以讨论下一个服务类型——NodePort。
- en: Using NodePort
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 NodePort
- en: NodePort is an external-facing Service type, which means that it can actually
    be accessed from outside the Cluster. When creating a NodePort Service, a ClusterIP
    Service of the same name will automatically be created and routed to by the NodePort,
    so you will still be able to access the Service from inside the cluster. This
    makes NodePort a good option for external access to applications when a LoadBalancer
    Service is not feasible or possible.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: NodePort 是一个面向外部的服务类型，这意味着它实际上可以从集群外部进行访问。在创建 NodePort 服务时，会自动创建一个具有相同名称的 ClusterIP
    服务，并通过 NodePort 进行路由，因此你仍然可以从集群内部访问该服务。这使得 NodePort 成为在负载均衡器服务不可行或无法使用时，对外部应用程序进行访问的一个不错的选择。
- en: NodePort sounds like what it is – this type of Service opens a port on every
    Node in the cluster on which the Service can be accessed. This port will be in
    a range that is by default between `30000`-`32767` and will be linked automatically
    on Service creation.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: NodePort 听起来就像它的名字——这种类型的服务在集群中的每个节点上打开一个端口，可以通过该端口访问服务。该端口默认位于`30000`-`32767`范围内，并且在创建服务时会自动链接。
- en: 'Here''s what our NodePort Service YAML looks like:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们 NodePort 服务的 YAML 文件：
- en: nodeport-service.yaml
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: nodeport-service.yaml
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you can tell, the only difference from the ClusterIP Service is the Service
    type – however, it is important to note that our intended port `80` in the `ports`
    section will only be used when accessing the automatically created ClusterIP version
    of the Service. From outside the cluster, we'll need to see what the generated
    port link is to access the Service on our Node IP.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，与 ClusterIP 服务的唯一区别是服务类型——然而，值得注意的是，我们在 `ports` 部分指定的端口 `80` 只会在访问自动创建的
    ClusterIP 版本的服务时使用。要从集群外部访问服务，我们需要查看生成的端口链接，以便在节点 IP 上访问该服务。
- en: 'To do this, we can create our Service with the following command:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，我们可以使用以下命令创建服务：
- en: '[PRE4]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And then run this command:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然后运行以下命令：
- en: '[PRE5]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result of the preceding command will be the following output:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 前面命令的结果将是以下输出：
- en: '[PRE6]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: From this output, we look to the `NodePort` line to see that our assigned port
    for this Service is `31598`. Thus, this Service can be accessed on any node at
    `[NODE_IP]:[ASSIGNED_PORT]`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中，我们查看 `NodePort` 行，看到为此服务分配的端口是 `31598`。因此，可以通过 `[NODE_IP]:[ASSIGNED_PORT]`
    在任何节点上访问该服务。
- en: 'Alternatively, we can manually assign a NodePort IP to the Service. The YAML
    for a manually assigned NodePort is as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以手动为服务分配一个 NodePort IP。手动分配 NodePort 的 YAML 文件如下：
- en: manual-nodeport-service.yaml
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: manual-nodeport-service.yaml
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As you can see, we have chosen a `nodePort` in the range `30000`-`32767`, in
    this case, `31233`. To see exactly how this NodePort Service works across Nodes,
    take a look at the following diagram:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们选择了一个位于 `30000`-`32767` 范围内的 `nodePort`，在此情况下为 `31233`。要查看这个 NodePort
    服务如何在节点之间工作，可以查看下面的示意图：
- en: '![Figure 5.2 – NodePort Service](img/B14790_05_002.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.2 – NodePort 服务](img/B14790_05_002.jpg)'
- en: Figure 5.2 – NodePort Service
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – NodePort 服务
- en: As you can see, though the Service is accessible at every Node in the cluster
    (Node A, Node B, and Node C), network requests are still load-balanced across
    the Pods in all Nodes (Pod A, Pod B, and Pod C), not just the Node that is accessed.
    This is an effective way to ensure that the application can be accessed from any
    Node. When using cloud services, however, you already have a range of tools to
    spread requests between servers. The next type of Service, LoadBalancer, lets
    us use those tools in the context of Kubernetes.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，虽然服务可以在集群中的每个节点（节点 A、节点 B 和节点 C）上访问，但网络请求仍会在所有节点的 Pods（Pod A、Pod B 和 Pod
    C）之间进行负载均衡，而不仅仅是访问的节点。这是一种有效的方式，确保应用程序可以从任何节点进行访问。然而，在使用云服务时，你已经有了一系列工具来在服务器之间分发请求。下一个服务类型
    LoadBalancer 让我们可以在 Kubernetes 上使用这些工具。
- en: Setting up a LoadBalancer Service
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 LoadBalancer 服务
- en: LoadBalancer is a special Service type in Kubernetes that provisions a load
    balancer based on where your cluster is running. For instance, in AWS, Kubernetes
    will provision an Elastic Load Balancer.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: LoadBalancer 是 Kubernetes 中一种特殊的服务类型，它根据集群运行的位置配置一个负载均衡器。例如，在 AWS 中，Kubernetes
    会配置一个弹性负载均衡器。
- en: Important note
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: For a full list of LoadBalancer services and configurations, check the documentation
    for Kubernetes Services at [https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看所有负载均衡服务及其配置，请查看Kubernetes服务文档中的[https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer)。
- en: 'Unlike with `ClusterIP` or NodePort, we can amend the functionality of a LoadBalancer
    Service in cloud-specific ways. Generally, this is done using an annotations block
    in the Service YAML file – which, as we''ve discussed before, is just a set of
    keys and values. To see how this is done for AWS, let''s review the spec for a
    LoadBalancer Service:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 与`ClusterIP`或NodePort不同，我们可以以云特定的方式修改负载均衡服务的功能。通常，这是通过在服务的YAML文件中使用注释块来完成的——正如我们之前讨论过的，这只是一些键值对。要查看AWS的配置方式，我们来看一下负载均衡服务的规格：
- en: loadbalancer-service.yaml
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: loadbalancer-service.yaml
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Though we can create a LoadBalancer without any annotations, the supported AWS-specific
    annotations give us the ability (as seen in the preceding YAML code) to specify
    which TLS certificate (via its ARN in Amazon Certificate Manager) we want to be
    attached to our load balancer. AWS annotations also allow configuring logs for
    load balancers, and more.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以在没有任何注释的情况下创建负载均衡器，但支持的AWS特定注释使我们能够（如前面的YAML代码所示）指定我们希望附加到负载均衡器的TLS证书（通过其在Amazon证书管理器中的ARN）。AWS的注释还允许配置负载均衡器的日志等。
- en: 'Here are a few key annotations supported by the AWS Cloud Provider as of the
    writing of this book:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是截至本书写作时，AWS云提供商支持的一些关键注释：
- en: '`service.beta.kubernetes.io/aws-load-balancer-ssl-cert`'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`service.beta.kubernetes.io/aws-load-balancer-ssl-cert`'
- en: '`service.beta.kubernetes.io/aws-load-balancer-proxy-protocol`'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`service.beta.kubernetes.io/aws-load-balancer-proxy-protocol`'
- en: '`service.beta.kubernetes.io/aws-load-balancer-ssl-ports`'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`service.beta.kubernetes.io/aws-load-balancer-ssl-ports`'
- en: Important note
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要说明
- en: A full list of annotations and explanations for all providers can be found on
    the **Cloud Providers** page in the official Kubernetes documentation, at [https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/).
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以在Kubernetes官方文档的**云提供商**页面上找到所有提供商的完整注释列表及解释，[https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/)。
- en: 'Finally, with LoadBalancer Services, we''ve covered the Service types you will
    likely use the most. However, for special cases where the Service itself runs
    outside of Kubernetes, we can use another Service type: ExternalName.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过负载均衡服务，我们已经覆盖了你可能最常用的服务类型。然而，对于那些服务本身运行在Kubernetes外部的特殊情况，我们可以使用另一种服务类型：ExternalName。
- en: Creating an ExternalName Service
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建ExternalName服务
- en: Services of type ExternalName can be used to proxify applications that are not
    actually running on your cluster, while still keeping the Service as a layer of
    abstraction that can be updated at any time.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 类型为ExternalName的服务可以用来代理那些实际上并没有在你的集群中运行的应用程序，同时仍然保持服务作为一个抽象层，可以随时更新。
- en: 'Let''s set the scene: you have a legacy production application running on Azure
    that you want to access from within your cluster. You can access this legacy application
    at `myoldapp.mydomain.com`. However, your team is currently working on containerizing
    this application and running it on Kubernetes, and that new version is currently
    working in your `dev` namespace environment on your cluster.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设定一下场景：你有一个在Azure上运行的遗留生产应用程序，你希望从集群内访问它。你可以通过`myoldapp.mydomain.com`来访问这个遗留应用程序。然而，你的团队目前正在将这个应用程序容器化，并在Kubernetes上运行，而这个新版本现在正在你的`dev`命名空间环境中工作。
- en: Instead of asking your other applications to talk to different places depending
    on the environment, you can always point to a Service called `my-svc` in both
    your production (`prod`) and development (`dev`) namespaces.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 不必让你的其他应用程序根据环境与不同的地方进行通信，你可以始终指向一个名为`my-svc`的服务，无论是在生产（`prod`）命名空间还是开发（`dev`）命名空间中。
- en: 'In `dev`, this Service could be a `ClusterIP` Service that leads to your newly
    containerized application on Pods. The following YAML shows how the in-development,
    containerized Service should work:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在`dev`中，这个服务可以是一个`ClusterIP`服务，指向你新容器化的应用程序所在的Pod。以下YAML展示了正在开发中的、容器化服务应该如何工作：
- en: clusterip-for-external-service.yaml
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: clusterip-for-external-service.yaml
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the `prod` namespace, this Service would instead be an `ExternalName` Service:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在`prod`命名空间中，这个服务将成为一个`ExternalName`服务：
- en: externalname-service.yaml
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: externalname-service.yaml
- en: '[PRE10]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Since our `ExternalName` Service is not actually forwarding requests to Pods,
    we don't need a selector. Instead, we specify an `ExternalName`, which is the
    DNS name we want the Service to direct to.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的`ExternalName`服务实际上并没有将请求转发到Pod，因此我们不需要选择器。相反，我们指定一个`ExternalName`，即我们希望服务指向的DNS名称。
- en: 'The following diagram shows how an `ExternalName` Service could be used in
    this pattern:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了`ExternalName`服务如何在此模式中使用：
- en: '![Figure 5.3 – ExternalName Service configuration](img/B14790_05_003.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图5.3 – ExternalName服务配置](img/B14790_05_003.jpg)'
- en: Figure 5.3 – ExternalName Service configuration
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – ExternalName服务配置
- en: In the preceding diagram, our **EC2 Running Legacy Application** is an AWS VM,
    external to the cluster. Our **Service B** of type **ExternalName** will route
    requests out to the VM. That way, our **Pod C** (or any other Pod in the cluster)
    can access our external legacy application simply through the ExternalName services'
    Kubernetes DNS name.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图示中，我们的**EC2运行传统应用程序**是一个外部AWS虚拟机，位于集群外部。我们的**Service B**类型是**ExternalName**，将请求路由到该虚拟机。这样，我们的**Pod
    C**（或者集群中的任何其他Pod）可以通过ExternalName服务的Kubernetes DNS名称，轻松访问外部的传统应用程序。
- en: With `ExternalName`, we've finished our review of all the Kubernetes Service
    types. Let's move on to a more complex method of exposing applications – the Kubernetes
    Ingress resource.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`ExternalName`，我们已经完成了对所有Kubernetes服务类型的回顾。接下来，我们将介绍一种更复杂的应用暴露方式——Kubernetes
    Ingress资源。
- en: Configuring Ingress
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置Ingress
- en: As mentioned at the beginning of the chapter, Ingress provides a granular mechanism
    for routing requests into a cluster. Ingress does not replace Services but augments
    them with capabilities such as path-based routing. Why is this necessary? There
    are plenty of reasons, including cost. An Ingress with 10 paths to `ClusterIP`
    Services is a lot cheaper than creating a new LoadBalancer Service for each path
    – plus it keeps things simple and easy to understand.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章开头所提到的，Ingress提供了一种细粒度的机制，用于将请求路由到集群内。Ingress并不取代服务，而是增强它们的功能，如基于路径的路由。为什么需要这个？有很多原因，包括成本。一个包含10条路径指向`ClusterIP`服务的Ingress，比为每条路径创建一个新的负载均衡器服务便宜得多——而且它保持了简单易懂。
- en: 'Ingresses do not work like other Services in Kubernetes. Just creating the
    Ingress itself will do nothing. You need two additional components:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress与Kubernetes中的其他服务不同。仅创建Ingress本身不会做任何事情。你需要两个额外的组件：
- en: 'An Ingress controller: you can choose from many implementations, built on tools
    such as Nginx or HAProxy.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个Ingress控制器：你可以从多种实现中选择，通常是基于Nginx或HAProxy等工具构建的。
- en: ClusterIP or NodePort Services for the intended routes.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对目标路由的ClusterIP或NodePort服务。
- en: First, let's discuss how to configure the Ingress controller.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们讨论如何配置Ingress控制器。
- en: Ingress controllers
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ingress控制器
- en: Generally, clusters will not come configured with any pre-existing Ingress controllers.
    You'll need to select and deploy one to your cluster. `ingress-nginx` is likely
    the most popular choice, but there are several others – see [https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/)
    for a full list.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，集群不会预配置任何现有的Ingress控制器。你需要选择并将其部署到集群中。`ingress-nginx`可能是最受欢迎的选择，但还有其他几个——可以参见[https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/)查看完整列表。
- en: Let's learn how to deploy an Ingress controller - for the purposes of this book,
    we'll stick with the Nginx Ingress controller created by the Kubernetes community,
    `ingress-nginx`.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们学习如何部署Ingress控制器——为了本书的目的，我们将使用Kubernetes社区创建的Nginx Ingress控制器，`ingress-nginx`。
- en: 'Installation may differ from controller to controller, but for `ingress-nginx`
    there are two main parts. First, to deploy the main controller itself, run the
    following command, which may change depending on the target environment and newest
    Nginx Ingress version:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 安装可能因控制器不同而有所不同，但对于`ingress-nginx`来说，主要有两个部分。首先，要部署主控制器本身，可以运行以下命令，具体命令可能会根据目标环境和最新的Nginx
    Ingress版本有所变化：
- en: '[PRE11]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Secondly, we may need to configure our Ingress depending on which environment
    we're running in. For a cluster running on AWS, we can configure the Ingress entry
    point to use an Elastic Load Balancer that we create in AWS.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们可能需要根据运行环境配置Ingress。对于运行在AWS上的集群，我们可以配置Ingress入口点，使用我们在AWS中创建的弹性负载均衡器。
- en: Important note
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: To see all environment-specific setup instructions, see the `ingress-nginx`
    docs at [https://kubernetes.github.io/ingress-nginx/deploy/](https://kubernetes.github.io/ingress-nginx/deploy/).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看所有特定环境的设置说明，请参阅 `ingress-nginx` 文档：[https://kubernetes.github.io/ingress-nginx/deploy/](https://kubernetes.github.io/ingress-nginx/deploy/)。
- en: The Nginx ingress controller is a set of Pods that will auto-update the Nginx
    configuration whenever a new Ingress resource (a custom Kubernetes resource) is
    created. In addition to the Ingress controller, we will need a way to route requests
    to the Ingress controller – known as the entry point.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Nginx ingress 控制器是一组 Pods，每当创建一个新的 Ingress 资源（一个自定义的 Kubernetes 资源）时，它会自动更新
    Nginx 配置。除了 Ingress 控制器，我们还需要一种方式将请求路由到 Ingress 控制器——这被称为入口点。
- en: Ingress entry point
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Ingress 入口点
- en: The default `nginx-ingress` install will also create a singular Service that
    serves requests to the Nginx layer, at which point the Ingress rules take over.
    Depending on how you configure your Ingress, this can be a LoadBalancer or NodePort
    Service. In a cloud environment, you will likely use a cloud LoadBalancer Service
    as the entry point to the cluster Ingress.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的 `nginx-ingress` 安装还会创建一个单一的 Service，用于将请求发送到 Nginx 层，在此时 Ingress 规则接管。根据你配置
    Ingress 的方式，这可以是一个 LoadBalancer 或 NodePort Service。在云环境中，你可能会使用云 LoadBalancer
    Service 作为集群 Ingress 的入口点。
- en: Ingress rules and YAML
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Ingress 规则和 YAML
- en: Now that we have our Ingress controller up and running, we can start configuring
    our Ingress rules.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经启动了 Ingress 控制器，可以开始配置我们的 Ingress 规则了。
- en: 'Let''s start with a simple example. We have two Services, `service-a` and `service-b`,
    that we want to expose on different paths via our Ingress. Once your Ingress controller
    and any associated Elastic Load Balancers are created (assuming we''re running
    on AWS), let''s first create our Services by working through the following steps:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个简单的示例开始。我们有两个服务，`service-a` 和 `service-b`，我们希望通过 Ingress 在不同的路径上公开它们。一旦你的
    Ingress 控制器和任何相关的弹性负载均衡器（假设我们在 AWS 上运行）创建完成，首先让我们通过以下步骤创建我们的服务：
- en: 'First, let''s look at how to create Service A in YAML. Let''s call the file
    `service-a.yaml`:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们看一下如何在 YAML 中创建 Service A。我们将文件命名为`service-a.yaml`：
- en: '[PRE12]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can create our Service A by running the following command:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以通过运行以下命令创建我们的 Service A：
- en: '[PRE13]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, let''s create our Service B, for which the YAML code looks very similar:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们创建我们的 Service B，其 YAML 代码与之前非常相似：
- en: '[PRE14]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create our Service B by running the following command:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令创建我们的 Service B：
- en: '[PRE15]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, we can create our Ingress with rules for each path. Here is the YAML
    code for our Ingress that will split requests as necessary based on path-based
    routing rules:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以创建我们的 Ingress，并为每个路径设置路由规则。以下是我们 Ingress 的 YAML 代码，它将根据基于路径的路由规则分配请求：
- en: ingress.yaml
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ingress.yaml
- en: '[PRE16]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In our preceding YAML, the ingress has a singular `host` value, which would
    correspond to the host request header for traffic coming through the Ingress.
    Then, we have two paths, `/a` and `/b`, which lead to our two previously created
    `ClusterIP` Services. To put this configuration in a graphical format, let''s
    take a look at the following diagram:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们前面的 YAML 配置中，ingress 有一个单一的 `host` 值，这将对应通过 Ingress 传入流量的 host 请求头。然后，我们有两个路径，`/a`
    和 `/b`，它们分别指向我们之前创建的两个 `ClusterIP` 服务。为了以图形化的方式展示这个配置，我们来看一下下图：
- en: '![Figure 5.4 – Kubernetes Ingress example](img/B14790_05_004.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.4 – Kubernetes Ingress 示例](img/B14790_05_004.jpg)'
- en: Figure 5.4 – Kubernetes Ingress example
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 – Kubernetes Ingress 示例
- en: As you can see, our simple path-based rules result in network requests getting
    routed directly to the proper Pods. This is because `nginx-ingress` uses the Service
    selector to get a list of Pod IPs, but does not directly use the Service to communicate
    with the Pods. Rather, the Nginx (in this case) config is automatically updated
    as new Pod IPs come online.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们简单的基于路径的规则使得网络请求能够直接路由到正确的 Pods。这是因为`nginx-ingress`使用 Service 选择器获取 Pod
    IP 列表，但并不直接通过 Service 与 Pods 通信。而是，Nginx（在这种情况下）的配置会随着新的 Pod IP 上线而自动更新。
- en: 'The `host` value isn''t actually required. If you leave it out, any traffic
    that comes through the Ingress, regardless of the host header (unless it matches
    a different rule that specifies a host) will be routed according to the rule.
    The following YAML shows this:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`host` 值其实并不是必需的。如果你省略它，任何通过 Ingress 传入的流量，无论 host 请求头是什么（除非它匹配其他指定 host 的规则），都会按照规则路由。以下
    YAML 显示了这种情况：'
- en: ingress-no-host.yaml
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ingress-no-host.yaml
- en: '[PRE17]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This previous Ingress definition will flow traffic to the path-based routing
    rules even if there is no host header value.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 即使没有主机头值，之前的 Ingress 定义仍会将流量引导到基于路径的路由规则。
- en: 'Similarly, it is possible to split traffic into multiple separate branching
    paths based on the host header, like this:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你也可以根据主机头（host header）将流量拆分成多个独立的分支路径，如下所示：
- en: ingress-branching.yaml
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ingress-branching.yaml
- en: '[PRE18]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Finally, you can also secure your Ingress with TLS in many cases, though this
    functionality differs on a per Ingress controller basis. For Nginx, this can be
    done by using a Kubernetes Secret. We''ll get to this functionality in the next
    chapter but for now, check out the configuration on the Ingress side:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在许多情况下，你还可以通过 TLS 加密来保护你的 Ingress，尽管这一功能因不同的 Ingress 控制器而有所不同。对于 Nginx，可以通过使用
    Kubernetes Secret 来实现。我们将在下一章详细讨论这个功能，但现在可以先查看 Ingress 侧的配置：
- en: ingress-secure.yaml
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ingress-secure.yaml
- en: '[PRE19]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This configuration will look for a Kubernetes Secret named `my-tls-secret` in
    the default namespace to attach to the Ingress for TLS.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 该配置将在默认命名空间中查找名为 `my-tls-secret` 的 Kubernetes Secret，并将其附加到 Ingress 上以进行 TLS
    加密。
- en: That ends our discussion of Ingress. A lot of Ingress functionality can be specific
    to which Ingress controller you decide to use, so check out the documentation
    for your chosen implementation.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们对 Ingress 的讨论。许多 Ingress 功能可能与您选择的 Ingress 控制器相关，因此请查看您所选择实现的文档。
- en: Summary
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we reviewed the various methods that Kubernetes provides in
    order to expose applications running on the cluster to the outside world. The
    major methods are Services and Ingress. Within Services, you can use ClusterIP
    Services for in-cluster routing and NodePort for access to a Service directly
    via ports on Nodes. LoadBalancer Services let you use existing cloud load-balancing
    systems, and ExternalName Services let you route requests out of the cluster to
    external resources.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了 Kubernetes 提供的各种方法，用于将运行在集群上的应用程序暴露给外部世界。主要的方法是 Services 和 Ingress。在
    Services 中，你可以使用 ClusterIP Services 进行集群内路由，使用 NodePort 直接通过节点的端口访问服务。LoadBalancer
    Services 允许你使用现有的云负载均衡系统，而 ExternalName Services 则允许你将请求路由到集群外部的资源。
- en: Finally, Ingress provides a powerful tool to route requests in the cluster by
    path. To implement Ingress you need to install a third-party or open source Ingress
    controller on your cluster.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Ingress 提供了一个强大的工具，可以通过路径在集群中路由请求。要实现 Ingress，你需要在集群上安装一个第三方或开源的 Ingress
    控制器。
- en: 'In the next chapter, we''ll talk about how to inject configuration information
    into your applications running on Kubernetes using two resource types: ConfigMap
    and Secret.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何使用两种资源类型（ConfigMap 和 Secret）将配置信息注入到运行在 Kubernetes 上的应用程序中。
- en: Questions
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What type of Service would you use for applications that are only accessed internally
    in a cluster?
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于仅在集群内访问的应用程序，你会使用哪种类型的 Service？
- en: How can you tell which port a NodePort Service is active on?
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何判断一个 NodePort 服务在哪个端口上激活？
- en: Why can Ingress be more cost-effective than purely Services?
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么 Ingress 比单纯使用 Services 更具成本效益？
- en: Other than supporting legacy applications, how might ExternalName Services be
    useful on a cloud platform?
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了支持遗留应用程序外，ExternalName Services 在云平台上还有什么用处？
- en: Further reading
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Information on cloud providers, from the Kubernetes documentation: [https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自 Kubernetes 文档的云服务提供商信息：[https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/)
