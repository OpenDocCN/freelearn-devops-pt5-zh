- en: Appendix A. Docker Flow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录 A. Docker Flow
- en: Docker Flow is a project aimed towards creating an easy to use continuous deployment
    flow. It depends on Docker Engine, Docker Compose, Consul, and Registrator. Each
    of those tools is proven to bring value and are recommended for any Docker deployment.
    If you read the whole book, you should be familiar those tools as well as the
    process we're about to explore.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Flow 是一个旨在创建易于使用的持续部署流程的项目。它依赖于 Docker Engine、Docker Compose、Consul 和
    Registrator。这些工具已被证明能够带来价值，并且建议在任何 Docker 部署中使用。如果你读完了整本书，你应该熟悉这些工具以及我们即将探讨的过程。
- en: The goal of the project is to add features and processes that are currently
    missing inside the Docker ecosystem. The project, at the moment, solves the problems
    of blue-green deployments, relative scaling, and proxy service discovery and reconfiguration.
    Many additional features will be added soon.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目的目标是为当前 Docker 生态系统中缺失的功能和流程提供补充。目前，该项目解决了蓝绿部署、相对扩展以及代理服务发现与重新配置的问题。未来会增加许多附加功能。
- en: 'The current list of features is as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的功能列表如下：
- en: Blue-green deployment
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝绿部署
- en: Relative scaling
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相对扩展
- en: Proxy reconfiguration
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理重新配置
- en: The latest release can be found at [https://github.com/vfarcic/docker-flow/releases/tag/v1.0.2](https://github.com/vfarcic/docker-flow/releases/tag/v1.0.2).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最新的发布版本可以在[https://github.com/vfarcic/docker-flow/releases/tag/v1.0.2](https://github.com/vfarcic/docker-flow/releases/tag/v1.0.2)找到。
- en: The Background
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景
- en: While working with different clients as well as writing the examples for this
    book, I realized that I end up writing different flavours of the same scripts.
    Some written in *Bash*, others as *Jenkins Pipeline*, some in *Go*, and so on.
    So, as soon as I finished writing the book, I decided to start a project that
    will envelop many of the practices we explored. The result is the Docker Flow
    project.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在与不同客户合作以及为本书编写示例的过程中，我意识到我最终会编写不同版本的相同脚本。有些是用 *Bash* 编写的，有些是用 *Jenkins Pipeline*
    编写的，还有一些是用 *Go* 编写的，等等。因此，当我完成这本书时，我决定启动一个项目，涵盖我们所探讨的许多实践。结果就是 Docker Flow 项目。
- en: The Standard Setup
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标准设置
- en: We'll start by exploring a typical Swarm cluster setup and discuss some of the
    problems we might face when using it as the cluster orchestrator. If you are already
    familiar with Docker Swarm, feel free to skip this section and jump straight into
    The Problems.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从探索典型的 Swarm 集群设置开始，并讨论在将其作为集群协调器时可能遇到的一些问题。如果你已经熟悉 Docker Swarm，可以跳过这一部分，直接进入“问题”部分。
- en: As a minimum, each node inside a Swarm cluster has to have Docker Engine and
    the Swarm container running. The later container should act as a node. On top
    of the cluster, we need at least one Swarm container running as master, and all
    Swarm nodes should announce their existence to it.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 至少，Swarm 集群中的每个节点必须安装 Docker Engine 并运行 Swarm 容器。后者容器应该充当节点。在集群之上，我们需要至少一个作为主节点运行的
    Swarm 容器，所有 Swarm 节点应向它宣布其存在。
- en: A combination of Swarm master(s) and nodes are a minimal setup that, in most
    cases, is far from sufficient. Optimum utilization of a cluster means that we
    are not in control anymore. Swarm is. It will decide which node is the most appropriate
    place for a container to run. That choice can be as simple as a node with the
    least number of containers running, or can be based on a more complex calculation
    that involves the amount of available CPU and memory, type of hard disk, affinity,
    and so on. No matter the strategy we choose, the fact is that we will not know
    where a container will run. On top of that, we should not specify ports our services
    should expose. "Hard-coded" ports reduce our ability to scale services and can
    result in conflicts. After all, two separate processes cannot listen to the same
    port. Long story short, once we adopt Swarm, both IPs and ports of our services
    will become unknown. So, the next step in setting up a Swarm cluster is to create
    a mechanism that will detect deployed services and store their information in
    a distributed registry so that the information is easily available.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm master和节点的组合是最小化的设置，在大多数情况下，这远远不够。集群的最佳利用意味着我们不再掌控一切，Swarm会。它将决定哪个节点是运行容器的最合适位置。这个选择可以像选择一个运行容器最少的节点那样简单，也可以基于一个更复杂的计算，涉及到可用CPU和内存的数量、硬盘类型、亲和性等。不管我们选择什么策略，事实是我们无法知道容器会在哪里运行。此外，我们不应指定我们的服务应该暴露的端口。"硬编码"端口会降低我们扩展服务的能力，并可能导致冲突。毕竟，两个独立的进程不能监听相同的端口。简而言之，一旦我们采用Swarm，服务的IP和端口将变得不可知。因此，设置Swarm集群的下一步是创建一个机制，用来检测已部署的服务并将其信息存储在分布式注册表中，以便轻松获取。
- en: 'Registrator is one of the tools that we can use to monitor Docker Engine events
    and send the information about deployed or stopped containers to a service registry.
    While there are many different service registries we can use, Consul proved to
    be, currently, the best one. Please read the Service Discovery: The Key to Distributed
    Services chapter for more information.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Registrator是我们可以用来监控Docker引擎事件并将已部署或已停止的容器信息发送到服务注册表的工具之一。虽然有许多不同的服务注册表可以使用，但目前证明Consul是最好的。有关更多信息，请阅读《服务发现：分布式服务的关键》一章。
- en: 'With `Registrator` and `Consul`, we can obtain information about any of the
    services running inside the Swarm cluster. A diagram of the setup we discussed,
    is as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Registrator`和`Consul`，我们可以获取运行在Swarm集群内的任何服务的信息。我们讨论过的设置的示意图如下：
- en: '![The Standard Setup](img/B05848_App_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![标准设置](img/B05848_App_01.jpg)'
- en: Swarm cluster with basic service discovery
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 含基本服务发现的Swarm集群
- en: Please note that anything but a small cluster would have multiple Swarm masters
    and Consul instances thus preventing any loss of information or downtime in case
    one of them fails.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，除了小型集群外，其他集群将会有多个Swarm master和Consul实例，从而防止在其中一个出现故障时丢失信息或造成停机。
- en: 'The process of deploying containers, in such a setup, is as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种设置下，部署容器的过程如下：
- en: The operator sends a request to `Swarm master` to deploy a service consisting
    of one or multiple containers. This request can be sent through `Docker CLI` by
    defining the `DOCKER_HOST` environment variable with the IP and the port of the
    `Swarm master`.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作员向`Swarm master`发送请求，部署一个由一个或多个容器组成的服务。此请求可以通过`Docker CLI`发送，并通过定义`DOCKER_HOST`环境变量，指定`Swarm
    master`的IP和端口。
- en: Depending on criteria sent in the request (CPU, memory, affinity, and so on),
    `Swarm master` makes the decision where to run the containers and sends requests
    to chosen `Swarm nodes`.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据请求中发送的标准（如CPU、内存、亲和性等），`Swarm master`决定容器运行的位置，并向选定的`Swarm nodes`发送请求。
- en: '`Swarm node`, upon receiving the request to run (or stop) a container, invokes
    local *Docker Engine*, which, in turn, runs (or stops) the desired container and
    publishes the result as an event.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Swarm node`在接收到运行（或停止）容器的请求时，会调用本地的*Docker Engine*，后者运行（或停止）所需的容器，并将结果作为事件发布。'
- en: '*Registrator* monitors *Docker Engine* and, upon detecting a new event, sends
    the information to *Consul*.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Registrator*监控*Docker Engine*，并在检测到新事件时将信息发送到*Consul*。'
- en: Anyone interested in data about containers running inside the cluster can consult
    *Consul*.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何对集群内运行的容器数据感兴趣的人都可以查询*Consul*。
- en: While this process is a vast improvement when compared to the ways we were operating
    clusters in the past, it is far from complete and creates quite a few problems
    that should be solved.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然与我们过去操作集群的方式相比，这个过程是一次巨大的改进，但它仍然远远不完整，并且会产生一些应该解决的问题。
- en: The Problems
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: In this chapter, I will focus on three major problems or, to be more precise,
    features missing in the previously described setup.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将重点介绍之前描述的设置中缺失的三个主要问题，或者更准确地说，缺失的功能。
- en: Deploying Without Downtime
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无停机部署
- en: When a new release is pulled, running `docker-compose up` will stop the containers
    running the old release and run the new one in their place. The problem with that
    approach is downtime. Between stopping the old release and running the new in
    its place, there is downtime. No matter whether it is one millisecond or a full
    minute, a new container needs to start, and the service inside it needs to initialize.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当拉取新版本时，运行 `docker-compose up` 会停止运行旧版本的容器，并用新版本替换它们。这个方法的问题在于停机时间。在停止旧版本和运行新版本之间，会有停机时间。无论是毫秒级别还是整整一分钟，新的容器都需要启动，并且其中的服务需要初始化。
- en: We can solve this by setting up a proxy with health checks. However, that would
    still require running multiple instances of the service (as you definitely should).
    The process would be to stop one instance and bring the new release in its place.
    During the downtime of that instance, the proxy would redirect the requests to
    one of the other instances. Then, when the first instance is running the new release
    and the service inside it is initialized, we would continue repeating the process
    with the other instances. This process can become very complicated and would prevent
    you from using Docker Compose `scale` command.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过设置带有健康检查的代理来解决这个问题。然而，这仍然需要运行多个服务实例（因为你绝对应该这么做）。过程是停止一个实例，并将新版本部署到其位置。在该实例的停机期间，代理会将请求重定向到其他实例中的一个。然后，当第一个实例运行新版本并且其中的服务初始化完成后，我们会继续对其他实例重复这一过程。这个过程可能会变得非常复杂，并且会阻止你使用
    Docker Compose 的 `scale` 命令。
- en: The better solution is to deploy the new release using the *blue-green* deployment
    process. If you are unfamiliar with it, please read the [Chapter 13](ch13.html
    "Chapter 13. Blue-Green Deployment"), *Blue-Green* *Deployment*. In a nutshell,
    the process deploys the new release in parallel with the old one. Throughout the
    process, the proxy should continue sending all requests to the old release. Once
    the deployment is finished and the service inside the container is initialized,
    the proxy should be reconfigured to send all the requests to the new release and
    the old one can be stopped. With a process like this, we can avoid downtime. The
    problem is that Swarm does not support *blue-green* deployment.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的解决方案是使用 *蓝绿* 部署过程来部署新版本。如果你不熟悉它，请阅读[第13章](ch13.html "第13章 蓝绿部署")，*蓝绿* *部署*。简而言之，过程是将新版本与旧版本并行部署。在整个过程中，代理应该继续将所有请求发送到旧版本。一旦部署完成并且容器内的服务初始化完成，代理应重新配置以将所有请求发送到新版本，而旧版本可以停止。通过这种方式，我们可以避免停机。问题是
    Swarm 不支持 *蓝绿* 部署。
- en: Scaling Containers using Relative Numbers
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用相对数字扩展容器
- en: '*Docker Compose* makes it very easy to scale services to a fixed number. We
    can specify how many instances of a container we want to run and watch the magic
    unfold. When combined with Docker Swarm, the result is an easy way to manage containers
    inside a cluster. Depending on how many instances are already running, Docker
    Compose will increase (or decrease) the number of running containers so that the
    desired result is achieved.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*Docker Compose* 使得将服务扩展到固定数量变得非常容易。我们可以指定要运行多少个容器实例，并观察魔法的展开。当与 Docker Swarm
    结合使用时，结果是管理集群中容器的简单方法。根据当前正在运行的实例数量，Docker Compose 会增加（或减少）运行中的容器数量，以便实现预期结果。'
- en: The problem is that Docker Compose always expects a fixed number as the parameter.
    That can be very limiting when dealing with production deployments. In many cases,
    we do not want to know how many instances are already running but send a signal
    to increase (or decrease) the capacity by some factor. For example, we might have
    an increase in traffic and want to increase the capacity by three instances. Similarly,
    if the demand for some service decreases, we might want the number of running
    instances to decrease by some factor and, in that way, free resources for other
    services and processes. This necessity is even more evident when we move towards
    autonomous and automated [Chapter 13](ch13.html "Chapter 13. Blue-Green Deployment"),
    *Self-Healing Systems* where human interactions are reduced to a minimum.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于 Docker Compose 总是期望参数是一个固定的数字。当处理生产环境部署时，这会非常有限制。在许多情况下，我们并不希望知道已经运行了多少实例，而是希望通过某种因素发出信号来增加（或减少）容量。例如，我们可能会遇到流量增加的情况，并希望将容量增加三个实例。类似地，如果某个服务的需求下降，我们可能希望减少运行的实例数量，并以此释放资源供其他服务和进程使用。当我们朝着自主和自动化的[第13章](ch13.html
    "第13章. 蓝绿部署")、*自愈系统*迈进时，这种需求更加明显，人工干预降到最低。
- en: On top of the lack of relative scaling, *Docker Compose* does not know how to
    maintain the same number of running instances when a new container is deployed.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 除了缺乏相对扩展外，*Docker Compose* 还不知道如何在部署新容器时保持相同数量的运行实例。
- en: Proxy Reconfiguration after the New Release Is Tested
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新版本测试后的代理重新配置
- en: The need for dynamic reconfiguration of the proxy becomes evident soon after
    we adopt microservices architecture. Containers allow us to pack them as immutable
    entities and Swarm lets us deploy them inside a cluster. The adoption of immutability
    through containers and cluster orchestrators like Swarm resulted in a huge increase
    in interest and adoption of microservices and, with them, the increase in deployment
    frequency. Unlike monolithic applications that forced us to deploy infrequently,
    now we can deploy often. Even if you do not adopt continuous deployment (each
    commit goes to production), you are likely to start deploying your microservices
    more often. That might be once a week, once a day, or multiple times a day. No
    matter the frequency, there is a high need to reconfigure the proxy every time
    a new release is deployed. Swarm will run containers somewhere inside the cluster,
    and proxy needs to be reconfigured to redirect requests to all the instances of
    the new release. That reconfiguration needs to be dynamic. That means that there
    must be a process that retrieves information from the service registry, changes
    the configuration of the proxy and, finally, reloads it.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们采用微服务架构，代理的动态重新配置需求便变得显而易见。容器让我们能够将它们打包为不可变的实体，而 Swarm 使我们能够将它们部署到集群中。通过容器和像
    Swarm 这样的集群编排工具实现不可变性，极大地推动了微服务的兴趣和采用，同时也增加了部署的频率。与强制我们不频繁部署的单体应用不同，现在我们可以更频繁地部署。即使你不采用持续部署（每次提交都会发布到生产环境），你也可能开始更频繁地部署你的微服务。可能是每周一次，每天一次，甚至一天多次。无论频率如何，每次发布新版本时，都需要重新配置代理。Swarm
    会将容器部署到集群中的某个地方，代理需要重新配置以将请求重定向到所有新版本的实例。这种重新配置需要是动态的。这意味着必须有一个进程从服务注册表中获取信息，改变代理的配置，并最终重新加载它。
- en: There are several commonly used approaches to this problem.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题有几种常用的方法。
- en: Manual proxy reconfiguration should be discarded for obvious reasons. Frequent
    deploys mean that there is no time for an operator to change the configuration
    manually. Even if time is not of the essence, manual reconfiguration adds "human
    factor" to the process, and we are known to make mistakes.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于显而易见的原因，手动代理重新配置应该被摒弃。频繁的部署意味着操作员没有时间手动更改配置。即使时间不是关键，手动重新配置也会将“人为因素”引入到过程中，而我们都知道人类会犯错。
- en: There are quite a few tools that monitor Docker events or entries to the registry
    and reconfigure proxy whenever a new container is run or an old one is stopped.
    The problem with those tools is that they do not give us enough time to test the
    new release. If there is a bug or a feature is not entirely complete, our users
    will suffer. Proxy reconfiguration should be performed only after a set of tests
    is run, and the new release is validated.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多工具可以监控 Docker 事件或注册表中的条目，并在新容器启动或旧容器停止时重新配置代理。这些工具的问题在于，它们没有给我们足够的时间来测试新版本。如果出现
    bug 或功能尚未完全完成，用户将受到影响。代理的重新配置应该仅在一系列测试运行并验证新版本之后进行。
- en: We can use tools like `Consul Template` or `ConfD` into our deployment scripts.
    Both are great and work well but require quite a lot of plumbing before they are
    truly incorporated into the deployment process.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在部署脚本中使用 `Consul Template` 或 `ConfD` 等工具。它们都非常好用，效果也不错，但在完全融入部署过程中之前，需要做很多配置工作。
- en: Solving The Problems
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决问题
- en: Docker Flow is the project that solves the problems we discussed. Its goal is
    to provide features that are not currently available in the Docker's ecosystem.
    It does not replace any of the ecosystem's features but builds on top of them.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Flow 是解决我们讨论过的问题的项目。它的目标是提供当前 Docker 生态系统中尚不可用的功能。它并不取代生态系统中的任何功能，而是建立在其基础之上。
- en: Docker Flow Walkthrough
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker Flow 使用指南
- en: The examples that follow will use Vagrant to simulate a Docker Swarm cluster.
    That does not mean that the usage of Docker Flow is limited to Vagrant. You can
    use it with a single Docker Engine or a Swarm cluster set up in any other way.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的示例将使用 Vagrant 来模拟 Docker Swarm 集群。这并不意味着 Docker Flow 的使用仅限于 Vagrant。你可以在任何其他方式设置的单个
    Docker 引擎或 Swarm 集群中使用它。
- en: For similar examples based on Docker Machine (tested on Linux and OS X), please
    read the project ([https://github.com/vfarcic/docker-flow](https://github.com/vfarcic/docker-flow)).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 关于基于 Docker Machine 的类似示例（在 Linux 和 OS X 上测试过），请阅读项目（[https://github.com/vfarcic/docker-flow](https://github.com/vfarcic/docker-flow)）。
- en: Setting it up
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置过程
- en: Before jumping into examples, please make sure that Vagrant is installed. You
    will not need anything else since the Ansible playbooks we are about to run will
    make sure that all the tools are correctly provisioned.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始示例之前，请确保已安装 Vagrant。你不需要其他任何东西，因为我们即将运行的 Ansible playbooks 会确保所有工具都已正确配置。
- en: 'Please clone the code from the `vfarcic/docker-flow` repository:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 请从 `vfarcic/docker-flow` 仓库克隆代码：
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'With the code downloaded, we can run Vagrant and create the cluster we''ll
    use throughout this chapter:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下载代码后，我们可以运行 Vagrant 并创建本章中将使用的集群：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once VMs are created and provisioned, the setup will be the same as explained
    in *The Standard Setup* section of this chapter. The `master` server will contain
    `Swarm master` while nodes `1` and `2` will form the cluster. Each of those nodes
    will have `Registrator` pointing to the `Consul` instance running in the `proxy`
    server:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦虚拟机（VM）创建并配置完成，设置过程将与本章中*标准设置*部分所述相同。`master` 服务器将包含 `Swarm master`，而节点 `1`
    和 `2` 将组成集群。每个节点将有指向 `proxy` 服务器中运行的 `Consul` 实例的 `Registrator`：
- en: '![Setting it up](img/B05848_App_02.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![设置过程](img/B05848_App_02.jpg)'
- en: Swarm cluster setup through Vagrant
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 Vagrant 设置 Swarm 集群
- en: Please note that this setup is for demo purposes only. While the same principle
    should be applied in production, you should aim at having multiple Swarm masters
    and Consul instances to avoid potential downtime in case one of them fails.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个设置仅用于演示目的。虽然在生产环境中应应用相同的原则，但你应该确保有多个 Swarm 主节点和 Consul 实例，以避免其中一个失败时可能带来的停机时间。
- en: 'Once the `vagrant up` command is finished, we can enter the `proxy` VM and
    see *Docker Flow* in action:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 `vagrant up` 命令完成，我们可以进入 `proxy` 虚拟机，看到*Docker Flow*的实际运行：
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We'll run all the examples from the `proxy` machine. However, in production,
    you should run deployment commands from a separate machine (even your laptop).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从 `proxy` 机器运行所有示例。然而，在生产环境中，你应该从一台单独的机器（甚至是你的笔记本电脑）运行部署命令。
- en: The latest release of *docker-flow* binary has been downloaded and ready to
    use, and the `/books-ms` directory contains the `docker-compose.yml` file we'll
    use in the examples that follow.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 最新版本的 *docker-flow* 二进制文件已下载并准备好使用，且 `/books-ms` 目录包含了我们将在接下来的示例中使用的 `docker-compose.yml`
    文件。
- en: 'Let''s enter the directory:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入目录：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Reconfiguring Proxy after Deployment
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署后重新配置 Proxy
- en: Docker Flow requires the address of the Consul instance as well as the information
    about the node the proxy is (or will be) running on. It allows three ways to provide
    the necessary information. We can define arguments inside the `docker-flow.yml`
    file, as environment variables, or as command line arguments. In this example,
    we'll use all three input methods so that you can get familiar with them and choose
    the combination that suits you needs.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Flow需要Consul实例的地址以及代理正在（或将要）运行的节点信息。它提供了三种方式来提供必要的信息。我们可以在`docker-flow.yml`文件中定义参数、作为环境变量，或作为命令行参数。在这个示例中，我们将使用这三种输入方法，这样你可以熟悉它们并选择适合你需求的组合。
- en: 'Let''s start by defining proxy and Consul data through environment variables:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从通过环境变量定义代理和Consul数据开始：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `FLOW_PROXY_HOST` variable is the IP of the host where the proxy is running
    while the `FLOW_CONSUL_ADDRESS` represents the full address of the Consul API.
    The `FLOW_PROXY_DOCKER_HOST` is the host of the Docker Engine running on the server
    where the proxy container is (or will be) running. The last variable (`DOCKER_HOST`)
    is the address of the `Swarm master`. Docker Flow is designed to run operations
    on multiple servers at the same time, so we need to provide all the information
    it needs to do its tasks. In the examples we are exploring, it will deploy containers
    on the Swarm cluster, use Consul instance to store and retrieve information, and
    reconfigure the proxy every time a new service is deployed. Finally, we set the
    environment variable `BOOKS_MS_VERSION` to *latest*. The `docker-compose.yml`
    uses it do determine which version we want to run.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`FLOW_PROXY_HOST`变量是代理运行所在主机的IP，而`FLOW_CONSUL_ADDRESS`代表Consul API的完整地址。`FLOW_PROXY_DOCKER_HOST`是Docker引擎的主机，运行在代理容器（或将要运行的代理容器）所在的服务器上。最后一个变量（`DOCKER_HOST`）是`Swarm
    master`的地址。Docker Flow旨在同时在多个服务器上执行操作，因此我们需要提供所有它所需的信息，以便它能够完成任务。在我们正在探索的示例中，它将部署容器到Swarm集群，使用Consul实例来存储和检索信息，并在每次部署新服务时重新配置代理。最后，我们将环境变量`BOOKS_MS_VERSION`设置为*latest*。`docker-compose.yml`使用它来确定我们要运行的版本。'
- en: 'Now we are ready to deploy the first release of our sample service:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备部署我们示例服务的第一个版本：
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We instructed `docker-flow` to use the *blue-green deployment* process and that
    the target (defined in `docker-compose.yml`) is `app`. We also told it that the
    service exposes an API on the address `/api/v1/books` and that it requires a side
    (or secondary) target `db`. Finally, through the `--flow` arguments we specified
    that the we want it to *deploy* the targets and reconfigure the `proxy`. A lot
    happened in that single command so we'll explore the result in more detail.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们指示`docker-flow`使用*蓝绿部署*流程，并且目标（在`docker-compose.yml`中定义）是`app`。我们还告诉它该服务在`/api/v1/books`地址上公开API，并且它需要一个副目标`db`。最后，通过`--flow`参数，我们指定希望它*部署*目标并重新配置`proxy`。在那个单一的命令中发生了很多事情，所以我们将更详细地探讨结果。
- en: 'Let''s take a look at our servers and see what happened. We''ll start with
    the Swarm cluster:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的服务器，看看发生了什么。我们从Swarm集群开始：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output of the `ps` command is as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`ps`命令的输出如下：'
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Docker Flow run our main target `app` together with the side target named books-ms-db.
    Both targets are defined in `docker-compose.yml`. Container names depend on many
    different factors, some of which are the Docker Compose project (defaults to the
    current directory as in the case of the `app` target) or can be specified inside
    the `docker-compose.yml` through the `container_name` argument (as in the case
    of the `db` target). The first difference you'll notice is that *Docker Flow*
    added *blue* to the container name. The reason behind that is in the `--blue-green`
    argument. If present, `Docker Flow` will use the *blue-green* process to run the
    primary target. Since this was the first deployment, *Docker Flow* decided that
    it will be called *blue*. If you are unfamiliar with the process, please read
    the [Chapter 13](ch13.html "Chapter 13. Blue-Green Deployment"), *Blue-Green Deployment*
    for general information.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Flow将我们的主要目标`app`与名为books-ms-db的副目标一起运行。两个目标都在`docker-compose.yml`中定义。容器的名称取决于许多不同的因素，其中一些因素是Docker
    Compose项目（默认使用当前目录，如`app`目标的情况）或可以通过`docker-compose.yml`中的`container_name`参数来指定（如`db`目标）。你会注意到的第一个区别是*Docker
    Flow*在容器名称中添加了*blue*。其背后的原因是`--blue-green`参数。如果存在，`Docker Flow`将使用*blue-green*流程来运行主要目标。由于这是第一次部署，*Docker
    Flow*决定它将被称为*blue*。如果你不熟悉这个过程，请阅读[第13章](ch13.html "第13章：蓝绿部署")，以了解有关*蓝绿部署*的一般信息。
- en: 'Let''s take a look at the `proxy` node as well:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也看一下 `proxy` 节点：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output of the `ps` command is as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`ps` 命令的输出如下：'
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Docker Flow detected that there was no `proxy` on that node and run it for
    us. The `docker-flow-proxy` container contains *HAProxy* together with custom
    code that reconfigures it every time a new service is run. For more information
    about the *Docker Flow: Proxy*, please read the project ([https://github.com/vfarcic/docker-flow-proxy](https://github.com/vfarcic/docker-flow-proxy)).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 'Docker Flow 检测到该节点上没有 `proxy`，并为我们运行了它。`docker-flow-proxy` 容器包含了 *HAProxy*，以及每次运行新服务时重新配置它的自定义代码。有关
    *Docker Flow: Proxy* 的更多信息，请阅读该项目（[https://github.com/vfarcic/docker-flow-proxy](https://github.com/vfarcic/docker-flow-proxy)）。'
- en: 'Since we instructed Swarm to deploy the service somewhere inside the cluster,
    we could not know in advance which server will be chosen. In this particular case,
    our service ended up running inside the `node-2`. Moreover, to avoid potential
    conflicts and allow easier scaling, we did not specify which port the service
    should expose. In other words, both the IP and the port of the service were not
    defined in advance. Among other things, *Docker Flow* solves this by running `Docker
    Flow: Proxy` and instructing it to reconfigure itself with the information gathered
    after the container is run. We can confirm that the proxy reconfiguration was
    indeed successful by sending an HTTP request to the newly deployed service:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '由于我们指示 Swarm 在集群中的某个地方部署该服务，我们无法预先知道将选择哪个服务器。在这个特定的案例中，我们的服务最终运行在了 `node-2`
    上。此外，为了避免潜在的冲突并允许更容易的扩展，我们没有指定服务应该暴露哪个端口。换句话说，服务的 IP 和端口在部署前没有定义。除此之外，*Docker
    Flow* 通过运行 `Docker Flow: Proxy` 并指示它在容器运行后使用收集到的信息重新配置自己来解决这个问题。我们可以通过向新部署的服务发送
    HTTP 请求来确认代理的重新配置是否成功：'
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output of the `curl` command is as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`curl` 命令的输出如下：'
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The flow of the events was as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 事件流如下：
- en: Docker Flow inspected Consul to find out which release (blue or green) should
    be deployed next. Since this is the first deployment and no release was running,
    it decided to deploy it as blue.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 检查了 Consul，以确定接下来应该部署哪个版本（蓝色或绿色）。由于这是第一次部署且没有版本在运行，因此决定将其部署为蓝色版本。
- en: Docker Flow sent the request to deploy the blue release to Swarm Master, which,
    in turn, decided to run the container in the node-2\. Registrator detected the
    new event created by Docker Engine and registered the service information in Consul.
    Similarly, the request was sent to deploy the side target db.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 向 Swarm Master 发送了部署蓝色发布的请求，Swarm Master 决定在 node-2 上运行容器。Registrator
    检测到了 Docker 引擎创建的新事件，并在 Consul 中注册了服务信息。同样，部署侧目标数据库的请求也被发送。
- en: Docker Flow retrieved the service information from Consul.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 从 Consul 获取了服务信息。
- en: Docker Flow inspected the server that should host the proxy, realized that it
    is not running, and deployed it.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 检查了应该托管代理的服务器，发现该服务器没有运行，然后进行了部署。
- en: Docker Flow updated HAProxy with service information.![Reconfiguring Proxy after
    Deployment](img/B05848_App_03.jpg)
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 更新了 HAProxy，并加入了服务信息。![部署后重新配置代理](img/B05848_App_03.jpg)
- en: The first deployment through Docker Flow
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过 Docker Flow 的第一次部署
- en: Even though our service is running in one of the servers chosen by Swarm and
    is exposing a random port, the proxy was reconfigured, and our users can access
    it through the fixed IP and without a port (to be more precise through the standard
    HTTP port `80` or HTTPS port `443`).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的服务运行在 Swarm 选择的服务器之一，并且暴露了一个随机端口，代理已经重新配置，我们的用户可以通过固定的 IP 访问它，而且不需要端口（更精确地说，通过标准的
    HTTP 端口 `80` 或 HTTPS 端口 `443`）。
- en: '![Reconfiguring Proxy after Deployment](img/B05848_App_04.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![部署后重新配置代理](img/B05848_App_04.jpg)'
- en: Users can access the service through the proxy
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以通过代理访问服务。
- en: Let's see what happens when the second release is deployed.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当第二个版本被部署时会发生什么。
- en: Deploying a New Release without Downtime
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无停机时间的发布新版本
- en: After some time, a developer will push a new commit, and we'll want to deploy
    a new release of the service. We do not want to have any downtime so we'll continue
    using the *blue-green* process. Since the current release is *blue*, the new one
    will be named *green*. Downtime will be avoided by running the new release (*green*)
    in parallel with the old one (*blue*) and, after it is fully up and running, reconfigure
    the proxy so that all requests are sent to the new release. Only after the proxy
    is reconfigured, we want the old release to stop running and free the resources
    it was using. We can accomplish all that by running the same `docker-flow` command.
    However, this time, we'll leverage the `docker-flow.yml` file that already has
    some of the arguments we used before.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一段时间后，开发者将推送新的提交，我们将希望部署服务的新版本。为了避免停机，我们将继续使用 *蓝绿* 部署流程。由于当前版本是 *蓝色*，新的版本将命名为
    *绿色*。通过使新版本（*绿色*）与旧版本（*蓝色*）并行运行，在新版本完全启动后，我们会重新配置代理，将所有请求发送到新版本。只有在代理重新配置完成后，我们才希望停止旧版本的运行并释放其占用的资源。我们可以通过运行相同的
    `docker-flow` 命令来完成所有这些操作。不过，这次我们将利用已经包含一些之前使用过的参数的 `docker-flow.yml` 文件。
- en: 'The content of the `docker-flow.yml` is as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker-flow.yml` 的内容如下：'
- en: '[PRE12]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s run the new release:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行新版本：
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Just like before, let''s explore Docker processes and see the result:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 就像之前一样，让我们探索 Docker 进程并查看结果：
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output of the `ps` command is as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`ps`命令的输出如下：'
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: From the output, we can observe that the new release (*green*) is running and
    that the old (*blue*) was stopped. The reason the old release was only stopped
    and not entirely removed lies in potential need to rollback quickly in case a
    problem is discovered at some later moment in time.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中，我们可以看到新版本（*绿色*）正在运行，旧版本（*蓝色*）已停止。旧版本之所以仅被停止而不是完全移除，是因为在稍后发现问题时可能需要快速回滚。
- en: 'Let''s confirm that the proxy was reconfigured as well:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确认代理是否也已经重新配置：
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output of the curl command is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`curl`命令的输出如下：'
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The flow of the events was as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 事件的流程如下：
- en: Docker Flow inspected Consul to find out which release (blue or green) should
    be deployed next. Since the previous release was blue, it decided to deploy it
    as green.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 检查了 Consul，以找出应该部署下一个版本（蓝色或绿色）。由于之前的版本是蓝色，它决定将其作为绿色版本进行部署。
- en: Docker Flow sent the request to Swarm Master to deploy the green release, which,
    in turn, decided to run the container in the node-1\. Registrator detected the
    new event created by Docker Engine and registered the service information in Consul.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 向 Swarm Master 发送请求部署绿色版本，Swarm Master 决定在 node-1 上运行该容器。Registrator
    检测到 Docker Engine 创建的新事件，并将服务信息注册到 Consul 中。
- en: Docker Flow retrieved the service information from Consul.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 从 Consul 获取了服务信息。
- en: Docker Flow updated HAProxy with service information.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 更新了 HAProxy 的服务信息。
- en: Docker Flow stopped the old release.![Deploying a New Release without Downtime](img/B05848_App_05.jpg)
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 停止了旧版本。![无停机时间部署新版本](img/B05848_App_05.jpg)
- en: The second deployment through Docker Flow
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过 Docker Flow 进行的第二次部署
- en: 'Throughout the first three steps of the flow, HAProxy continued sending all
    requests to the old release. As the result, users were oblivious that deployment
    is in progress:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在流程的前三个步骤中，HAProxy 继续将所有请求发送到旧版本。因此，用户并未察觉到部署正在进行：
- en: '![Deploying a New Release without Downtime](img/B05848_App_06.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![无停机时间部署新版本](img/B05848_App_06.jpg)'
- en: During the deployment, users continue interacting with the old release
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署过程中，用户继续与旧版本进行交互
- en: 'Only after the deployment is finished, HAProxy was reconfigured, and users
    were redirected to the new release. As the result, there was no downtime caused
    by deployment:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在部署完成后，HAProxy 才被重新配置，用户才被重定向到新版本。因此，部署没有造成停机：
- en: '![Deploying a New Release without Downtime](img/B05848_App_07.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![无停机时间部署新版本](img/B05848_App_07.jpg)'
- en: After the deployment, users are redirected to the new release
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 部署完成后，用户被重定向到新版本
- en: Now that we have a safe way to deploy new releases, let us turn our attention
    to relative scaling.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一种安全的方式来部署新版本，让我们将注意力转向相对扩展。
- en: Scaling the service
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 扩展服务
- en: One of the great benefits *Docker Compose* provides is scaling. We can use it
    to scale to any number of instances. However, it allows only absolute scaling.
    We cannot instruct *Docker Compose* to apply relative scaling. That makes the
    automation of some of the processes difficult. For example, we might have an increase
    in traffic that requires us to increase the number of instances by two. In such
    a scenario, the automation script would need to obtain the number of instances
    that are currently running, do some simple math to get to the desired number,
    and pass the result to Docker Compose. On top of all that, proxy still needs to
    be reconfigured as well. *Docker Flow* makes this process much easier.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*Docker Compose* 提供的一个巨大优势是可扩展性。我们可以使用它来扩展到任意数量的实例。然而，它只支持绝对扩展。我们无法指示 *Docker
    Compose* 执行相对扩展。这使得某些过程的自动化变得困难。例如，可能会有流量增加的情况，要求我们将实例数量增加两个。在这种情况下，自动化脚本需要获取当前运行的实例数量，进行简单的数学计算以得到所需的数量，并将结果传递给
    Docker Compose。除此之外，代理仍然需要重新配置。*Docker Flow* 使这个过程变得更加容易。'
- en: 'Let''s see it in action:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是如何运作的：
- en: '[PRE18]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The scaling result can be observed by listing the currently running Docker
    processes:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 通过列出当前运行的 Docker 进程，可以观察到扩展结果：
- en: '[PRE19]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output of the `ps` command is as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`ps` 命令的输出如下：'
- en: '[PRE20]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The number of instances was increased by two. While only one instance was running
    before, now we have three.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 实例数量增加了两个。在之前只有一个实例运行的情况下，现在我们有三个实例。
- en: Similarly, the proxy was reconfigured as well and, from now on, it will load
    balance all requests between those three instances.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，代理也进行了重新配置，从现在开始，它将在这三个实例之间进行负载均衡所有请求。
- en: 'The flow of the events was as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 事件的流程如下：
- en: Docker Flow inspected Consul to find out how many instances are currently running.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 检查了 Consul，找出了当前正在运行的实例数量。
- en: Since only one instance was running and we specified that we want to increase
    that number by two, Docker Flow sent the request to Swarm Master to scale the
    green release to three, which, in turn, decided to run one container on node-1
    and the other on node-2\. Registrator detected the new events created by Docker
    Engine and registered two new instances in Consul.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于只有一个实例在运行，并且我们指定要将该数量增加两个，Docker Flow 向 Swarm Master 发送请求，将绿色发布扩展到三个实例，Swarm
    Master 决定在 node-1 上运行一个容器，在 node-2 上运行另一个容器。Registrator 检测到 Docker Engine 创建的新事件，并将两个新实例注册到
    Consul 中。
- en: Docker Flow retrieved the service information from Consul.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 从 Consul 中获取了服务信息。
- en: Docker Flow updated HAProxy with the service information and set it up to perform
    load balancing among all three instances.![Scaling the service](img/B05848_App_08.jpg)
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 更新了 HAProxy 的服务信息，并将其配置为在三个实例之间执行负载均衡。![Scaling the service](img/B05848_App_08.jpg)
- en: Relative scaling through Docker Flow
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过 Docker Flow 实现相对扩展
- en: 'From the users perspective, they continue receiving responses from the current
    release but, this time, their requests are load balanced among all instances of
    the service. As a result, service performance is improved:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 从用户的角度来看，他们继续从当前版本接收响应，但这一次，他们的请求在所有服务实例之间进行负载均衡。因此，服务性能得到了提升：
- en: '![Scaling the service](img/B05848_App_09.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![Scaling the service](img/B05848_App_09.jpg)'
- en: Users requests are load balanced across all instances of the service
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 用户请求在所有服务实例之间进行负载均衡。
- en: 'We can use the same method to de-scale the number of instances by prefixing
    the value of the `--scale` argument with the minus sign (`-`). Following the same
    example, when the traffic returns to normal, we can de-scale the number of instances
    to the original amount by running the following command:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用相同的方法，通过在`--scale`参数值前加上减号（`-`）来减少实例数量。按照相同的例子，当流量恢复正常时，我们可以通过运行以下命令将实例数量恢复到原来的数量：
- en: '[PRE21]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Testing Deployments to Production
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试生产环境部署
- en: The major downside of the proxy examples we run by now is the inability to verify
    the release before reconfiguring the proxy. Ideally, we should use the *blue-green*
    process to deploy the new release in parallel with the old one, run a set of tests
    that validate that everything is working as expected, and, finally, reconfigure
    the proxy only if all tests were successful. We can accomplish that easily by
    running `docker-flow` twice.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们运行的代理示例的主要缺点是无法在重新配置代理之前验证发布版本。理想情况下，我们应该使用 *blue-green* 过程，将新版本与旧版本并行部署，运行一系列验证一切正常的测试，最后只有在所有测试成功的情况下才重新配置代理。我们可以通过运行
    `docker-flow` 两次轻松实现这一目标。
- en: Many tools aim at providing zero-downtime deployments but only a few of them
    (if any), take into account that a set of tests should be run before the proxy
    is reconfigured.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 许多工具旨在提供零停机时间的部署，但只有少数工具（如果有的话）考虑到在重新配置代理之前应该运行一系列测试。
- en: 'First, we should deploy the new version:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们应该部署新版本：
- en: '[PRE22]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let''s list the Docker processes:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 列出Docker进程：
- en: '[PRE23]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output of the `ps` command is as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`ps`命令的输出如下：'
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: At this moment, the new release (*blue*) is running in parallel with the old
    release (*green*). Since we did not specify the *--flow=proxy* argument, the proxy
    is left unchanged and still redirects to all the instances of the old release.
    What this means is that the users of our service still see the old release, while
    we have the opportunity to test it. We can run integration, functional, or any
    other type of tests and validate that the new release indeed meets the expectations
    we have. While testing in production does not exclude testing in other environments
    (e.g. staging), this approach gives us greater level of trust by being able to
    validate the software under the same circumstances our users will use it, while,
    at the same time, not affecting them during the process (they are still oblivious
    to the existence of the new release).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，新版本（*蓝色*）与旧版本（*绿色*）并行运行。由于我们没有指定*--flow=proxy*参数，代理保持不变，仍然将请求重定向到旧版本的所有实例。这意味着我们的服务用户仍然看到旧版本，而我们则有机会进行测试。我们可以进行集成测试、功能测试或任何其他类型的测试，并验证新版本确实符合我们的预期。虽然在生产环境中进行测试并不排除在其他环境（例如预发布环境）中进行测试，但这种方法通过能够在用户将使用相同环境下验证软件，从而给予我们更高的信任，同时，在此过程中不影响用户（他们仍然不知道新版本的存在）。
- en: Note
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Please note that even though we did not specify the number of instances that
    should be deployed, *Docker Flow* deployed the new release and scaled it to the
    same number of instances as we had before.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，尽管我们没有指定应部署的实例数量，*Docker Flow*仍然部署了新版本并将其扩展到与之前相同的实例数量。
- en: 'The flow of the events was as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 事件的流程如下：
- en: Docker Flow inspected Consul to find out the color of the current release and
    how many instances are currently running.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow检查Consul以查找当前版本的颜色以及当前正在运行的实例数量。
- en: Since two instances of the old release (*green*) were running and we didn't
    specify that we want to change that number, Docker Flow sent the request to *Swarm
    Master* to deploy the new release (*blue*) and scale it to two instances.![Testing
    Deployments to Production](img/B05848_App_10.jpg)
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于旧版本（*绿色*）有两个实例在运行，并且我们没有指定要更改该数量，Docker Flow向*Swarm Master*发送请求，部署新版本（*蓝色*）并将其扩展到两个实例。![部署测试到生产环境](img/B05848_App_10.jpg)
- en: Deployment without reconfiguring proxy
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 无需重新配置代理的部署
- en: 'From the users perspective, they continue receiving responses from the old
    release since we did not specify that we want to reconfigure the proxy:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 从用户的角度来看，由于我们没有指定要重新配置代理，他们继续收到旧版本的响应：
- en: '![Testing Deployments to Production](img/B05848_App_11.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![部署测试到生产环境](img/B05848_App_11.jpg)'
- en: Users requests are still redirected to the old release
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 用户请求仍然被重定向到旧版本
- en: From this moment, you can run tests in production against the new release. Assuming
    that you do not overload the server (e.g. stress tests), tests can run for any
    period without affecting users.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一刻起，你可以在生产环境中对新版本进行测试。假设你没有过度负载服务器（例如压力测试），测试可以在任何时间段内运行而不影响用户。
- en: 'After the tests execution is finished, there are two paths we can take. If
    one of the tests failed, we can just stop the new release and fix the problem.
    Since the proxy is still redirecting all requests to the old release, our users
    would not be affected by a failure, and we can dedicate our time towards fixing
    the problem. On the other hand, if all tests were successful, we can run the rest
    of the `flow` that will reconfigure the proxy and stop the old release:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 测试执行完成后，我们有两条路径可选择。如果某个测试失败，我们可以停止新版本并修复问题。由于代理仍然将所有请求重定向到旧版本，用户不会受到影响，我们可以专注于解决问题。另一方面，如果所有测试都成功，我们可以运行剩余的`flow`，重新配置代理并停止旧版本：
- en: '[PRE25]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The command reconfigured the proxy and stopped the old release.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令重新配置了代理并停止了旧版本。
- en: 'The flow of the events was as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 事件的流程如下：
- en: Docker Flow inspected Consul to find out the color of the current release and
    how many instances are running.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow检查Consul以查找当前版本的颜色以及正在运行的实例数量。
- en: Docker Flow updated the proxy with service information.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 更新了代理服务的信息。
- en: Docker Flow stopped the old release.![Testing Deployments to Production](img/B05848_App_12.jpg)
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Flow 停止了旧版本。![测试部署到生产环境](img/B05848_App_12.jpg)
- en: Proxy reconfiguration without deployment
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代理重新配置而无需部署。
- en: 'From the user''s perspective, all new requests are redirected to the new release:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 从用户的角度来看，所有新的请求都被重定向到了新版本：
- en: '![Testing Deployments to Production](img/B05848_App_13.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![测试部署到生产环境](img/B05848_App_13.jpg)'
- en: Users requests are redirected to the new release
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 用户请求被重定向到了新版本。
- en: That concludes the quick tour through some of the features *Docker Flow* provides.
    Please explore the *Usage* section for more details.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是对*Docker Flow*一些功能进行快速浏览的结尾。请查看*使用*部分以获取更多详细信息。
