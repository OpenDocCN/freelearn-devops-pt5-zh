- en: Monitoring and Troubleshooting an App Running in Production
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产环境中应用的监控与故障排除
- en: In the previous chapter, we learned how to deploy a multi-service application
    into a Kubernetes cluster. We configured application-level routing for the application
    and updated its services using a zero-downtime strategy. Finally, we provided
    confidential data to the running services by using Kubernetes Secrets.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何将一个多服务应用部署到Kubernetes集群中。我们为该应用配置了应用级路由，并使用零停机策略更新了其服务。最后，我们通过Kubernetes
    Secrets向运行中的服务提供了机密数据。
- en: In this chapter, you will learn the different techniques used to monitor an
    individual service or a whole distributed application running on a Kubernetes
    cluster. You will also learn how you can troubleshoot an application service that
    is running in production, without altering the cluster or the cluster nodes on
    which the service is running.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，你将学习如何监控单个服务或运行在Kubernetes集群上的整个分布式应用。你还将学习如何在不更改集群或服务运行所在节点的情况下，故障排除生产环境中运行的应用服务。
- en: 'The chapter covers the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: Monitoring an individual service
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控单个服务
- en: Using Prometheus to monitor your distributed application
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Prometheus监控你的分布式应用
- en: Troubleshooting a service running in production
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产环境中服务的故障排除
- en: 'After working through this chapter, you will be able to do the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章内容后，你将能够做到以下几点：
- en: Configure application-level monitoring for a service.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置服务的应用级监控。
- en: Use Prometheus to collect and centrally aggregate relevant application metrics.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Prometheus收集并集中聚合相关的应用度量。
- en: Troubleshoot a service running in production using a special tools container.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用专门的工具容器故障排除生产环境中运行的服务。
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we're going to use Minikube on our local computer. Please refer
    to [Chapter 2](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml), *Setting Up a Working
    Environment*, for more information on how to install and use Minikube.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将在本地计算机上使用Minikube。有关如何安装和使用Minikube的更多信息，请参见[第2章](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml)，*设置工作环境*。
- en: 'The code for this chapter can be found at: [https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch17](https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch17)[.](https://github.com/fundamentalsofdocker/labs/tree/2nd-edition/ch16/probes)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在以下网址找到：[https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch17](https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch17)[.](https://github.com/fundamentalsofdocker/labs/tree/2nd-edition/ch16/probes)
- en: Please make sure you have cloned the GitHub repository as described in [Chapter
    2](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml), *Setting Up a Working Environment*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保你已按照[第2章](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml)，*设置工作环境*中描述的方法克隆了GitHub仓库。
- en: In your Terminal, navigate to the `~/fod/ch17` folder.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端中，导航到`~/fod/ch17`文件夹。
- en: Monitoring an individual service
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控单个服务
- en: When working with a distributed mission-critical application in production or
    in any production-like environment, then it is of utmost importance to gain as
    much insight as possible into the inner workings of those applications. Have you
    ever had a chance to look into the cockpit of an airplane or the command center
    of a nuclear power plant? Both the airplane and the power plant are samples of
    highly complex systems that deliver mission-critical services. If a plane crashes
    or a power plant shuts down unexpectedly, a lot of people are negatively affected,
    to say the least. Thus the cockpit and the command center are full of instruments
    showing the current or past state of some part of the system. What you see is
    the visual representation of some sensors that are placed in strategic parts of
    the system, and constantly collect data such as the temperature or the flow rate.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境或任何类似生产的环境中使用分布式关键任务应用时，获得尽可能多的应用内部工作情况的洞察至关重要。你有没有机会查看过飞机的驾驶舱或核电站的指挥中心？飞机和核电站都是高度复杂的系统，提供关键任务服务。如果飞机坠毁或核电站突然停运，至少会影响很多人。因此，驾驶舱和指挥中心充满了仪器，显示系统某部分的当前或过去状态。你看到的就是一些传感器的视觉表示，这些传感器被放置在系统的战略位置，不断收集诸如温度或流量等数据。
- en: Similar to the airplane or the power plant, our application needs to be instrumented
    with "sensors" that can feel the "temperature" of our application services or
    the infrastructure they run on. I put the temperature in double quotes since it
    is only a placeholder for things that matter in an application, such as the number
    of requests per second on a given RESTful endpoint, or the average latency of
    request to the same endpoint.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于飞机或发电厂，我们的应用程序需要通过“传感器”进行监控，这些传感器能够感知我们应用程序服务的“温度”或它们运行的基础设施的状态。我将“温度”加上双引号，因为它只是一个占位符，代表在应用程序中重要的事情，例如某个RESTful端点每秒的请求数，或请求到同一端点的平均延迟。
- en: The resulting values or readings that we collect, such as the average latency
    of requests, are often called metrics. It should be our goal to expose as many
    meaningful metrics as possible of the application services we build. Metrics can
    be both functional and non-functional. Functional metrics are values that say
    something business-relevant about the application service, such as how many checkouts
    are performed per minute if the service is part of an e-commerce application,
    or which are the five most popular songs over the last 24 hours if we're talking
    about a streaming application.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集到的结果值或读数，例如请求的平均延迟，通常被称为指标。我们的目标应该是暴露尽可能多的应用程序服务的有意义指标。指标可以是功能性和非功能性的。功能性指标是那些对应用程序服务的业务相关性有描述的值，例如在电子商务应用程序中每分钟进行的结账次数，或者在流媒体应用程序中过去24小时内最受欢迎的五首歌曲。
- en: Non-functional metrics are important values that are not specific to the kind
    of business the application is used for, such as what is the average latency of
    a particular web request or how many `4xx` status codes are returned per minute
    by another endpoint, or how much RAM or how many CPU cycles a given service is
    using.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 非功能性指标是一些不特定于应用程序业务类型的关键值，例如某个特定网页请求的平均延迟是多少，或者每分钟某个端点返回多少个`4xx`状态码，或者某个服务使用了多少RAM或多少CPU周期。
- en: In a distributed system where each part is exposing metrics, some overarching
    service should be collecting and aggregating the values periodically from each
    component. Alternatively, each component should forward its metrics to a central
    metrics server. Only if the metrics for all components of our highly distributed
    system are available for inspection in a central location are they of any value.
    Otherwise, monitoring the system becomes impossible. That's why pilots of an airplane
    never have to go and inspect individual and critical parts of the airplane in
    person during a flight; all necessary readings are collected and displayed in
    the cockpit.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个分布式系统中，每个部分都暴露指标时，应该有一个统一的服务定期从每个组件收集并汇总这些值。或者，允许每个组件将其指标转发到一个中央指标服务器。只有当我们高度分布式系统中所有组件的指标都可以在一个中央位置检查时，这些指标才有价值。否则，监控系统将变得不可能。因此，飞机的飞行员在飞行过程中不需要亲自检查飞机的各个关键部件；所有必要的读数都会收集并显示在驾驶舱里。
- en: Today one of the most popular services that is used to expose, collect, and
    store metrics is Prometheus. It is an open source project and has been donated
    to the **Cloud Native Computing Foundation** (**CNCF**). Prometheus has first-class
    integration with Docker containers, Kubernetes, and many other systems and programming
    platforms. In this chapter, we will use Prometheus to demonstrate how to instrument
    a simple service that exposes important metrics.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，最流行的用于暴露、收集和存储指标的服务之一是Prometheus。它是一个开源项目，已经捐赠给**云原生计算基金会**(**CNCF**)。Prometheus与Docker容器、Kubernetes以及许多其他系统和编程平台有着一流的集成。在本章中，我们将使用Prometheus演示如何监控一个暴露重要指标的简单服务。
- en: Instrumenting a Node.js-based service
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对基于Node.js的服务进行监控
- en: 'In this section, we want to learn how to instrument a microservice authored
    in Node Express.js by following these steps:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中，我们将学习如何通过以下步骤对用Node Express.js编写的微服务进行监控：
- en: 'Create a new folder called `node` and navigate to it:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`node`的新文件夹，并进入该文件夹：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Run `npm init` in this folder, and accept all defaults except the **entry point**,
    which you change from the `index.js` default to `server.js`.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此文件夹中运行`npm init`，并接受所有默认设置，除了**入口点**，将其从默认的`index.js`更改为`server.js`。
- en: 'We need to add `express` to our project with the following:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要通过以下方式将`express`添加到我们的项目中：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now we need to install the Prometheus adapter for Node Express with the following:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要通过以下方式为Node Express安装Prometheus适配器：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Add a file called `server.js` to the folder with this content:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向该文件夹添加一个名为 `server.js` 的文件，内容如下：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This is a very simple Node Express app with a single endpoint: `/hello`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常简单的 Node Express 应用，只有一个端点：`/hello`。
- en: 'To the preceding code, add the following snippet to initialize the Prometheus
    client:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前面的代码中，添加以下代码片段来初始化 Prometheus 客户端：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, add an endpoint to expose the metrics:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，添加一个端点来暴露这些指标：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now let''s run this sample microservice:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们运行这个示例微服务：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can see in the preceding output that the service is listening at port `3000`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在前面的输出中看到服务正在 `3000` 端口监听。
- en: 'Let''s now try to access the metrics at the `/metrics` endpoint, as we defined
    in the code:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们尝试访问我们在代码中定义的 `/metrics` 端点的指标：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: What we get as output is a pretty long list of metrics, ready for consumption
    by a Prometheus server.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的输出是一长串指标，准备供 Prometheus 服务器使用。
- en: This was pretty easy, wasn't it? By adding a node package and adding a few trivial
    lines of code to our application startup, we have gained access to a plethora
    of system metrics.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这挺简单的，不是吗？通过添加一个节点包并在应用程序启动时添加几行简单的代码，我们就获得了大量的系统指标。
- en: 'Now let''s define our own custom metric. Let it be a `Counter` object:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们定义我们自己的自定义指标。它将是一个 `Counter` 对象：
- en: 'Add the following code snippet to `server.js` to define a custom counter called
    `my_hello_counter`:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下代码片段添加到 `server.js` 中，定义一个名为 `my_hello_counter` 的自定义计数器：
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To our existing `/hello` endpoint, add code to increase the counter:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在现有的 `/hello` 端点中，添加代码以增加计数器：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Rerun the application with `npm start`.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm start` 重新运行应用程序。
- en: 'To test the new counter, let''s access our `/hello` endpoint twice:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了测试新的计数器，让我们访问 `/hello` 端点两次：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We will get this output when accessing the `/metrics` endpoint:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 `/metrics` 端点时，我们将获得以下输出：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The counter we defined in code clearly works and is output with the `HELP` text
    we added.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在代码中定义的计数器显然起作用了，并且输出了我们添加的 `HELP` 文本。
- en: Now that we know how to instrument a Node Express application, let's do the
    same for a .NET Core-based microservice.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何为 Node Express 应用进行监控了，让我们为基于 .NET Core 的微服务做同样的事情。
- en: Instrumenting a .NET Core-based service
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对基于 .NET Core 的服务进行监控
- en: Let's start by creating a simple .NET Core microservice based on the Web API
    template.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建一个基于 Web API 模板的简单 .NET Core 微服务开始。
- en: 'Create a new `dotnet` folder, and navigate to it:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的 `dotnet` 文件夹，并进入该文件夹：
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Use the `dotnet` tool to scaffold a new microservice called `sample-api:`
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `dotnet` 工具生成一个新的微服务，名为 `sample-api`：
- en: '[PRE13]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We will use the Prometheus adapter for .NET, which is available to us as a
    NuGet package called `prometheus-net.AspNetCore`. Add this package to the `sample-api`
    project, with the following command:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用 Prometheus 的 .NET 适配器，它作为一个 NuGet 包 `prometheus-net.AspNetCore` 提供。使用以下命令将此包添加到
    `sample-api` 项目中：
- en: '[PRE14]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Open the project in your favorite code editor; for example, when using VS Code
    execute the following:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开项目到你喜欢的代码编辑器中；例如，当使用 VS Code 时，执行以下命令：
- en: '[PRE15]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Locate the `Startup.cs` file, and open it. At the beginning of the file, add
    a `using` statement:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到 `Startup.cs` 文件并打开它。在文件开头，添加一个 `using` 语句：
- en: '[PRE16]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Then in the `Configure` method add the `endpoints.MapMetrics()` statement to
    the mapping of the endpoints. Your code should look as follows:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后在 `Configure` 方法中，将 `endpoints.MapMetrics()` 语句添加到端点映射中。你的代码应该如下所示：
- en: '[PRE17]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note that the above is valid for version 3.x of .NET Core. If you're on an earlier
    version, the configuration looks slightly different. Consult the following repo
    for more details, at [https://github.com/prometheus-net/prometheus-net.](https://github.com/prometheus-net/prometheus-net)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，以上内容适用于 .NET Core 版本 3.x。如果你使用的是早期版本，配置会稍有不同。有关更多详细信息，请查看以下仓库：[https://github.com/prometheus-net/prometheus-net.](https://github.com/prometheus-net/prometheus-net)
- en: 'With this, the Prometheus component will start publishing the request metrics
    of ASP.NET Core. Let''s try it. First, start the application with the following:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有了这个，Prometheus 组件将开始发布 ASP.NET Core 的请求指标。我们来试试。首先，使用以下命令启动应用：
- en: '[PRE18]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The preceding output tells us that the microservice is listening at `https://localhost:5001`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的输出告诉我们微服务正在 `https://localhost:5001` 上监听。
- en: 'We can now use `curl` to call the metrics endpoint of the service:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以使用 `curl` 调用服务的指标端点：
- en: '[PRE19]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'What we get is a list of system metrics for our microservice. That was easy:
    we only needed to add a NuGet package and a single line of code to get our service
    instrumented!'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的是微服务的系统指标列表。很简单：我们只需要添加一个 NuGet 包和一行代码，就可以让我们的服务进行监控！
- en: 'What if we want to add our own (functional) metrics? This is equally straightforward.
    Assume we want to measure the number of concurrent accesses to our `/weatherforecast `endpoint.
    To do this, we define a `gauge` and use it to wrap the logic in the appropriate
    endpoint with this gauge. We can do this by following these steps:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要添加自定义的（功能性）指标呢？这同样简单。假设我们想要衡量对 `/weatherforecast` 端点的并发访问次数。为此，我们定义一个
    `gauge`，并用它来包装该端点中适当的逻辑。我们可以按照以下步骤来完成：
- en: Locate the `Controllers/WeatherForecastController.cs` class.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定位到 `Controllers/WeatherForecastController.cs` 类。
- en: Add `using Prometheus;` to the top of the file.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在文件顶部添加 `using Prometheus;`。
- en: 'Define a private instance variable of the `Gauge `type in the `WeatherForecastController`
    class:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `WeatherForecastController` 类中定义一个 `Gauge` 类型的私有实例变量：
- en: '[PRE20]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Wrap the logic of the `Get` method with a `using` statement:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用 `using` 语句包装 `Get` 方法的逻辑：
- en: '[PRE21]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Restart the microservice.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重启微服务。
- en: 'Call the `/weatherforecast` endpoint a couple of times using `curl`:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `curl` 多次调用 `/weatherforecast` 端点：
- en: '[PRE22]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Use `curl` to get the metrics, as earlier in this section:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `curl` 获取指标，方法与本节前面相同：
- en: '[PRE23]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: You will notice that there is now a new metric called `myapp_weather_forecasts_in_progress`
    available in the list. Its value will be zero, since currently you are not running
    any requests against the tracked endpoint, and a `gauge` type metric is only measuring
    the number of ongoing requests.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，现在列表中有一个名为 `myapp_weather_forecasts_in_progress` 的新指标。它的值为零，因为目前你并没有对跟踪的端点发出任何请求，且
    `gauge` 类型的指标仅测量正在进行的请求数。
- en: Congratulations, you have just defined your first functional metric. This is
    only a start; many more sophisticated possibilities are readily available to you.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，你刚刚定义了你的第一个功能性指标。这只是一个开始，许多更复杂的可能性已经触手可及。
- en: Node.js or .NET Core-based application services are by no means special. It
    is just as straightforward and easy to instrument services written in other languages,
    such as Java, Python, or Go.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 Node.js 或 .NET Core 的应用服务并不特别。用其他语言编写的服务，比如 Java、Python 或 Go，也可以同样简单直接地进行监控。
- en: Having learned how to instrument an application service so that it exposes important
    metrics, let's now have a look how we can use Prometheus to collect and aggregate
    those values to allow us to monitor a distributed application.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习了如何对应用服务进行监控并暴露重要指标之后，让我们看一下如何使用 Prometheus 收集并聚合这些值，从而使我们能够监控分布式应用程序。
- en: Using Prometheus to monitor a distributed application
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Prometheus 监控分布式应用
- en: Now that we have learned how to instrument an application service to expose
    Prometheus metrics, it's time to show how we can collect the metrics and forward
    them to a Prometheus server where all metrics will be aggregated and stored. We
    can then either use the (simple) web UI of Prometheus or a more sophisticated
    solution like Grafana to display important metrics on a dashboard.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了如何对应用服务进行监控并暴露 Prometheus 指标，接下来是展示如何收集这些指标并将它们转发到 Prometheus 服务器，在那里所有指标将被汇总和存储。然后我们可以使用
    Prometheus 的（简单）Web UI，或者像 Grafana 这样的更复杂的解决方案，在仪表板上展示重要的指标。
- en: Unlike most other tools that are used to collect metrics from application services
    and infrastructure components, the Prometheus server takes the load of work and
    periodically scrapes all the defined targets. This way applications and services
    don't need to worry about forwarding data. You can also describe this as pulling
    metrics versus pushing them. This makes Prometheus servers an excellent fit for
    our case.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数用于从应用服务和基础设施组件收集指标的工具不同，Prometheus 服务器承担了工作负载，并定期抓取所有定义的目标。这样，应用程序和服务就无需担心转发数据。你也可以把这描述为拉取指标而非推送指标。这使得
    Prometheus 服务器非常适合我们的案例。
- en: We will now discuss how to deploy Prometheus to Kubernetes, followed by our
    two sample application services. Finally, we will deploy Grafana to the cluster,
    and use it to display our customer metrics on a dashboard.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将讨论如何将 Prometheus 部署到 Kubernetes，然后是我们的两个示例应用服务。最后，我们将把 Grafana 部署到集群中，并使用它在仪表板上展示我们的客户指标。
- en: Architecture
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构
- en: 'Let''s have a quick overview of the architecture of the planned system. As
    mentioned before, we have our microservices, the Prometheus server, and Grafana.
    Furthermore, everything will be deployed to Kubernetes. The following diagram
    shows the relationships:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速了解一下计划系统的架构。如前所述，我们有微服务、Prometheus 服务器和 Grafana。此外，所有内容都将部署到 Kubernetes
    上。下图展示了它们之间的关系：
- en: '![](img/567104a5-741d-48cd-9a0f-c6cb04042413.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/567104a5-741d-48cd-9a0f-c6cb04042413.png)'
- en: High-level overview of an application using Prometheus and Grafana for monitoring
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Prometheus和Grafana进行监控的应用程序高级概述
- en: In the top center of the diagram, we have Prometheus, which periodically scrapes
    metrics from Kubernetes, shown on the left. It also periodically scrapes metrics
    from the services, in our case from the Node.js and the .NET sample services we
    created and instrumented in the previous section. Finally, on the right-hand side
    of the diagram, we have Grafana that is pulling data periodically from Prometheus
    to then display it on graphical dashboards.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在图表的顶部中央，我们有Prometheus，它定期从Kubernetes中抓取指标，显示在左侧。它还定期从服务中抓取指标，在我们的例子中是从我们在前一部分创建并加了监控的Node.js和.NET示例服务中抓取。最后，在图表的右侧，我们有Grafana，它定期从Prometheus中拉取数据，然后在图形化的仪表板上展示出来。
- en: Deploying Prometheus to Kubernetes
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Prometheus部署到Kubernetes中
- en: 'As indicated, we start by deploying Prometheus to Kubernetes. Let''s first
    define the Kubernetes YAML file that we can use to do so. First, we need to define
    a Kubernetes `Deployment` that will create a `ReplicaSet` of Prometheus server
    instances, and then we will define a Kubernetes service to expose Prometheus to
    us, so that we can access it from within a browser tab or that Grafana can access
    it. Let''s do it:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们首先将Prometheus部署到Kubernetes中。让我们首先定义一个Kubernetes YAML文件，用来进行部署。首先，我们需要定义一个Kubernetes
    `Deployment`，它将创建一个Prometheus服务器实例的`ReplicaSet`，然后我们将定义一个Kubernetes服务来暴露Prometheus，以便我们可以从浏览器标签中访问它，或者Grafana可以访问它。让我们开始：
- en: 'Create a `ch17/kube` folder, and navigate to it:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`ch17/kube`文件夹，并进入该文件夹：
- en: '[PRE24]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Add a file called `prometheus.yaml` to this folder.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此文件夹中添加一个名为`prometheus.yaml`的文件。
- en: 'Add the following code snippet to this file; it defines `Deployment` for Prometheus:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下代码片段添加到此文件中；它定义了Prometheus的`Deployment`：
- en: '[PRE25]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We are defining a replica set with two instances of Prometheus. Each instance
    is assigned the two labels: `app: prometheus` and `purpose: monitoring-demo` for
    identification purposes. The interesting part is in the `volumeMounts` of container
    spec. There we mount a Kubernetes `ConfigMap` object, called `prometheus-cm` containing
    the Prometheus configuration, into the container to the location where Prometheus
    expects its configuration file(s). The volume of the `ConfigMap` type is defined
    on the last four lines of the above code snippet.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '我们正在定义一个副本集，包含两个Prometheus实例。每个实例都被分配了两个标签：`app: prometheus`和`purpose: monitoring-demo`，用于标识。关键部分在于容器规格中的`volumeMounts`。在这里，我们将一个名为`prometheus-cm`的Kubernetes
    `ConfigMap`对象（它包含Prometheus的配置）挂载到容器中，挂载到Prometheus期望其配置文件的位置。`ConfigMap`类型的卷在上面的代码片段最后四行定义。'
- en: Note that we will define the `config` map later on.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们稍后将定义`config`映射。
- en: 'Now let''s define the Kubernetes service for Prometheus. Append this snippet
    to the file:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们定义Prometheus的Kubernetes服务。将这个片段追加到文件中：
- en: '[PRE26]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Please note the three dashes (`---`) at the beginning of the snippet are needed
    to separate individual object definitions in our YAML file.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，代码片段开头的三个破折号（`---`）用于分隔YAML文件中各个对象的定义。
- en: We call our service `prometheus-svc` and make it a `NodePort` (and not just
    a service of the `ClusterIP` type) to be able to access the Prometheus web UI
    from the host.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将服务命名为`prometheus-svc`，并将其设置为`NodePort`（而不是`ClusterIP`类型的服务），这样就可以从主机访问Prometheus的Web
    UI。
- en: 'Now we can define a simple configuration file for Prometheus. This file basically
    instructs the Prometheus server which services to scrape metrics from and how
    often to do so. First, create a `ch17/kube/config` folder:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以为Prometheus定义一个简单的配置文件。这个文件基本上指示Prometheus服务器从哪些服务抓取指标，以及抓取的频率。首先，创建一个`ch17/kube/config`文件夹：
- en: '[PRE27]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Please add a file called `prometheus.yml` to the last folder, and add the following
    content to it:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请在最后一个文件夹中添加一个名为`prometheus.yml`的文件，并在其中添加以下内容：
- en: '[PRE28]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'In the preceding file, we define three jobs for Prometheus:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的文件中，我们为Prometheus定义了三个任务：
- en: The first one called `prometheus` scrapes metrics every five seconds from the
    Prometheus server itself. It finds those metrics the at `localhost:9090` target.
    Note that by default the metrics should be exposed at the `/metrics` endpoint.
  id: totrans-122
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个名为`prometheus`的抓取任务每5秒从Prometheus服务器自身抓取一次指标。它从`localhost:9090`目标中找到这些指标。请注意，默认情况下，指标应该暴露在`/metrics`端点。
- en: The second job called `dotnet` scrapes metrics from a service found at `dotnet-api-svc:5000`,
    which will be our .NET Core service that we have defined and instrumented previously.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个任务叫做 `dotnet`，它从位于 `dotnet-api-svc:5000` 的服务中抓取指标，这将是我们之前定义并做了监控的 .NET Core
    服务。
- en: 'Finally, the third job does the same for our Node service. Note that we also
    have added a `group: ''production''` label to this job. This allows for further
    grouping of jobs or tasks.'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '最后，第三个任务对我们的 Node 服务执行相同的操作。请注意，我们还为该任务添加了一个 `group: ''production''` 标签。这允许对任务或任务进行进一步分组。'
- en: 'Now we can define the `ConfigMap` object in our Kubernetes cluster, with the
    next command. From within the `ch17/kube` folder execute the following:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用以下命令在 Kubernetes 集群中定义 `ConfigMap` 对象。进入 `ch17/kube` 文件夹并执行以下命令：
- en: '[PRE29]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can now deploy Prometheus to our Kubernetes server with the following:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以将 Prometheus 部署到我们的 Kubernetes 服务器，命令如下：
- en: '[PRE30]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Let''s double-check that the deployment succeeded:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们再检查一下部署是否成功：
- en: '[PRE31]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Keep a close eye on the list of pods, and make sure they are all up and running.
    Please also note the port mapping of the `prometheus-svc` object. In my case,
    the `9090` port is mapped to the `31962` host port. In your case, the latter may
    be different, but it will also be in the `3xxxx` range.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 密切关注 Pod 列表，并确保它们都在运行。还请注意 `prometheus-svc` 对象的端口映射。在我的例子中，`9090` 端口映射到 `31962`
    主机端口。在你的例子中，后者可能不同，但它也会在 `3xxxx` 范围内。
- en: 'We can now access the web UI of Prometheus. Open a new browser tab, and navigate
    to `http://localhost:<port>/targets` where `<port>` in my case is `31962`. You
    should see something like this:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以访问 Prometheus 的网页 UI。打开一个新的浏览器标签页，导航到 `http://localhost:<port>/targets`，其中
    `<port>` 在我的例子中是 `31962`。你应该看到类似这样的页面：
- en: '![](img/75ab2089-88ea-4bb2-b5c3-37e6e7c90d18.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/75ab2089-88ea-4bb2-b5c3-37e6e7c90d18.png)'
- en: Prometheus web UI showing the configured targets
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 网页 UI 显示已配置的目标
- en: In the last screenshot, we can see that we defined three targets for Prometheus.
    Only the third one in the list is up and accessible by Prometheus. It is the endpoint
    we defined in the configuration file for the job that scrapes metrics from Prometheus
    itself. The other two services are not running at this time, and thus their state
    is down.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一张截图中，我们可以看到我们为 Prometheus 定义了三个目标。列表中的第三个目标是正在运行并且可以被 Prometheus 访问的。它是我们在配置文件中为从
    Prometheus 本身抓取指标的任务定义的端点。其他两个服务此时未运行，因此它们的状态是停机的。
- en: Now navigate to Graph by clicking on the respective link in the top menu of
    the UI.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在通过点击 UI 顶部菜单中的相应链接来导航到 Graph。
- en: 'Open the metrics drop-down list, and inspect all the listed metrics that Prometheus
    found. In this case, it is only the list of metrics defined by the Prometheus
    server itself:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开指标下拉列表，并检查 Prometheus 找到的所有列出的指标。在这种情况下，它仅显示由 Prometheus 服务器本身定义的指标列表：
- en: '![](img/73ba9c62-5f75-4962-8fff-84911faec999.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/73ba9c62-5f75-4962-8fff-84911faec999.png)'
- en: Prometheus web UI showing available metrics
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 网页 UI 显示可用的指标
- en: With that, we are ready to deploy the .NET and the Node sample services, we
    created earlier, to Kubernetes.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就准备将之前创建的 .NET 和 Node 示例服务部署到 Kubernetes。
- en: Deploying our application services to Kubernetes
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将我们的应用服务部署到 Kubernetes
- en: Before we can use the sample services we created earlier and deploy them to
    Kubernetes, we must create Docker images for them and push them to a container
    registry. In our case, we will just push them to Docker Hub.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以使用之前创建的示例服务并将它们部署到 Kubernetes 之前，我们必须为它们创建 Docker 镜像，并将它们推送到容器注册表。在我们的例子中，我们将它们推送到
    Docker Hub。
- en: 'Let''s start with the .NET Core sample:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 .NET Core 示例开始：
- en: Locate the `Program.cs` file in the .NET project and open it.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到 .NET 项目中的 `Program.cs` 文件并打开它。
- en: 'Modify the `CreateHostBuilder` method so it looks like this:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改 `CreateHostBuilder` 方法，使其如下所示：
- en: '[PRE32]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Add `Dockerfile` with the following content to the `ch17/dotnet/sample-api`
    project folder:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将包含以下内容的 `Dockerfile` 添加到 `ch17/dotnet/sample-api` 项目文件夹：
- en: '[PRE33]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Create a Docker image by using this command from within the `dotnet/sample-api`
    project folder:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在 `dotnet/sample-api` 项目文件夹中创建一个 Docker 镜像：
- en: '[PRE34]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Note that you may want to replace `fundamentalsofdocker` with your own Docker
    Hub username in the preceding and subsequent command.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，你可能需要将前面和后面的命令中的 `fundamentalsofdocker` 替换为你自己的 Docker Hub 用户名。
- en: 'Push the image to Docker Hub:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将镜像推送到 Docker Hub：
- en: '[PRE35]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now we do the same with the Node sample API:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对 Node 示例 API 做同样的操作：
- en: 'Add `Dockerfile` with the following content to the `ch17/node` project folder:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将包含以下内容的 `Dockerfile` 添加到 `ch17/node` 项目文件夹：
- en: '[PRE36]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Create a Docker image by using this command from within the `ch17/node` project
    folder:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用此命令在 `ch17/node` 项目文件夹内创建一个 Docker 镜像：
- en: '[PRE37]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Note once again that you may want to replace `fundamentalsofdocker` with your
    own Docker Hub username in the preceding and subsequent command.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 再次注意，你可能需要将前面和后面的命令中的 `fundamentalsofdocker` 替换为你自己的 Docker Hub 用户名。
- en: 'Push the image to Docker Hub:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将镜像推送到 Docker Hub：
- en: '[PRE38]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: With this, we are ready to define the necessary Kubernetes objects for the deployment
    of the two services. The definition is somewhat lengthy and can be found in the `~/fod/ch17/kube/app-services.yaml` file
    in the repository. Please open that file and analyze its content.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们就可以定义必要的 Kubernetes 对象来部署这两个服务了。定义较长，可以在仓库中的 `~/fod/ch17/kube/app-services.yaml`
    文件中找到。请打开该文件并分析其内容。
- en: 'Let''s use this file to deploy the services:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这个文件来部署服务：
- en: 'Use the following command:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令：
- en: '[PRE39]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Double-check that the services are up and running using the `kubectl get all` command.
    Make sure all the pods of the Node and .NET sample API services are up and running.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `kubectl get all` 命令再次检查服务是否正常运行。确保 Node 和 .NET 示例 API 服务的所有 Pod 都在运行。
- en: 'List all Kubernetes services to find out the host ports for each application
    service:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出所有 Kubernetes 服务，以查找每个应用服务的主机端口：
- en: '[PRE40]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: In my case, the .NET API is mapped to port `30822 `, and the Node API to port `31713`.
    Your ports may differ.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的例子中，.NET API 映射到端口 `30822`，而 Node API 映射到端口 `31713`。你的端口可能会有所不同。
- en: 'Use `curl` to access the `/metrics` endpoint for both services:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `curl` 访问两个服务的 `/metrics` 端点：
- en: '[PRE41]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Double-check the `/targets` endpoint in Prometheus to make sure the two microservices
    are now reachable:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 双重检查 Prometheus 中的 `/targets` 端点，确保这两个微服务现在可以访问：
- en: '![](img/9500692f-aabe-4ceb-822b-71ef7c743735.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9500692f-aabe-4ceb-822b-71ef7c743735.png)'
- en: Prometheus showing all targets are up and running
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 显示所有目标都已正常运行
- en: 'To make sure the custom metrics we defined for our Node.js and .NET services
    are defined and exposed, we need to access each service at least once. Thus use
    `curl` to access the respective endpoints a few times:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了确保我们为 Node.js 和 .NET 服务定义的自定义指标已经定义并暴露，我们需要至少访问每个服务一次。因此，使用 `curl` 多次访问相应的端点：
- en: '[PRE42]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The last step is to deploy Grafana to Kubernetes so that we have the ability
    to create sophisticated and graphically appealing dashboards displaying key metrics
    of our application services and/or infrastructure components.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将 Grafana 部署到 Kubernetes，这样我们就能创建复杂且图形化的仪表盘，显示我们应用服务和/或基础设施组件的关键指标。
- en: Deploying Grafana to Kubernetes
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 Grafana 部署到 Kubernetes
- en: Now let's also deploy Grafana to our Kubernetes cluster, so that we can manage
    this tool the same way as all the other components of our distributed application.
    As the tool that allows us to create dashboards for monitoring the application,
    Grafana can be considered mission-critical and thus warrants this treatment.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们也将 Grafana 部署到我们的 Kubernetes 集群中，这样我们就能像管理分布式应用的其他组件一样管理这个工具。作为一个可以帮助我们创建监控应用程序的仪表盘的工具，Grafana
    可以被认为是关键任务工具，因此需要这样对待。
- en: 'Deploying Grafana to the cluster is pretty straightforward. Let''s do it as
    follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Grafana 部署到集群中非常简单。我们按如下步骤进行：
- en: Add a new file called `grafana.yaml` to the `ch17/kube` folder.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `ch17/kube` 文件夹中添加一个名为 `grafana.yaml` 的新文件。
- en: 'To this file, add the definition for a Kubernetes `Deployment` for Grafana:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此文件中，添加一个 Grafana 的 Kubernetes `Deployment` 定义：
- en: '[PRE43]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: There are no surprises in that definition. In this example, we are running a
    single instance of Grafana, and it uses the `app` and `purpose` labels for identification,
    similar to what we used for Prometheus. No special volume mapping is needed this
    time since we are only working with defaults.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定义没有什么意外。在这个示例中，我们运行的是 Grafana 的单实例，并且它使用 `app` 和 `purpose` 标签进行标识，类似于我们为
    Prometheus 使用的标签。这次不需要特别的卷映射，因为我们仅使用默认设置。
- en: 'We also need to expose Grafana, and thus add the following snippet to the preceding
    file to define a service for Grafana:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还需要暴露 Grafana，因此将以下代码段添加到前面的文件中，以定义一个 Grafana 服务：
- en: '[PRE44]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Once again, we are using a service of the `NodePort` type to be able to access
    the Grafana UI from our host.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们使用 `NodePort` 类型的服务，以便从主机访问 Grafana UI。
- en: 'We can now deploy Grafana with this command:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以使用此命令来部署 Grafana：
- en: '[PRE45]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Let''s find out what the port number will be, over which we can access Grafana:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们找出可以访问 Grafana 的端口号：
- en: '[PRE46]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Open a new browser tab, and navigate to `http://localhost:<port>` where `<port>` is
    the port you identified in the previous step, and in my case is `32379`. You should
    see something like this:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的浏览器标签页，访问`http://localhost:<port>`，其中`<port>`是您在上一步确定的端口号，举例来说是`32379`。您应该看到类似以下内容：
- en: '![](img/bddbf845-8092-4f22-9777-19b297470767.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bddbf845-8092-4f22-9777-19b297470767.png)'
- en: Login screen of Grafana
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana登录界面
- en: Login with the default `admin` username, and the password is also `admin`. When
    asked to change the password click the Skip link for now. You will be redirected
    to the Home dashboard**.**
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用默认的`admin`用户名登录，密码也是`admin`。当系统要求您更改密码时，点击“跳过”链接。您将被重定向到主页仪表盘**。**
- en: On the Home Dashboard, click on Create your first data source, and select Prometheus
    from the list of data sources.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主页仪表盘上，点击“创建您的第一个数据源”，并从数据源列表中选择Prometheus。
- en: Add `http://prometheus-svc:9090` for the URL to Prometheus, and click the green Save
    & Testbutton.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为Prometheus的URL添加`http://prometheus-svc:9090`，然后点击绿色的“保存并测试”按钮。
- en: In Grafana, navigate back to the Home dashboard, and then select the New dashboard.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Grafana中，返回主页仪表盘，然后选择“新建仪表盘”。
- en: 'Click Add query, and then from the Metrics drop-down menu, select the custom
    metric we defined in the .NET sample service:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“添加查询”，然后在“度量”下拉菜单中，选择我们在.NET示例服务中定义的自定义度量：
- en: '![](img/cc959094-a62e-4d8d-9af7-fb6b43dcfcfe.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cc959094-a62e-4d8d-9af7-fb6b43dcfcfe.png)'
- en: Selecting the .NET custom metric in Grafana
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在Grafana中选择.NET自定义度量
- en: Change the value of Relative time from `1h` to `5m` ( five minutes).
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将相对时间的值从`1h`改为`5m`（五分钟）。
- en: Change the dashboard refresh rate found in the upper-right corner of the view
    to `5s` (five seconds).
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将仪表盘右上角的刷新率改为`5s`（五秒）。
- en: Repeat the same for the custom metric defined in the Node sample service, so
    that you will have two panels on your new dashboard.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对Node示例服务中定义的自定义度量执行相同操作，这样您的新仪表盘将有两个面板。
- en: Modify the dashboard and its panels to your liking by consulting the documentation
    at [https://grafana.com/docs/grafana/latest/guides/getting_started/](https://grafana.com/docs/grafana/latest/guides/getting_started/).
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改仪表盘及其面板以符合您的喜好，可以参考[https://grafana.com/docs/grafana/latest/guides/getting_started/](https://grafana.com/docs/grafana/latest/guides/getting_started/)上的文档。
- en: 'Use `curl` to access the two endpoints of the sample services, and observe
    the dashboard. It may look like this:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`curl`访问示例服务的两个端点，并观察仪表盘。它可能像这样：
- en: '![](img/40be8912-dc9f-4b36-a80b-970944799afa.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](img/40be8912-dc9f-4b36-a80b-970944799afa.png)'
- en: Grafana dashboard with our two custom metrics
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 显示我们的两个自定义度量的Grafana仪表盘
- en: Summarizing, we can say that Prometheus is a good fit to monitor our microservices
    because we just need to expose a metrics port, and thus don't need to add too
    much complexity or run additional services. Prometheus then is in charge of periodically
    scraping the configured targets, so that our services don't need to worry about
    emitting them.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们可以说Prometheus非常适合用来监控我们的微服务，因为我们只需要暴露一个度量端口，因此不需要添加过多的复杂性或运行额外的服务。然后，Prometheus负责定期抓取已配置的目标，因此我们的服务无需担心发送度量数据。
- en: Troubleshooting a service running in production
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 排查生产环境中运行的服务问题
- en: It is a recommended best practice to create minimal images for production that
    don't contain anything that is not absolutely needed. This includes common tools
    that are usually used to debug and troubleshoot an application, such as netcat,
    iostat, ip, or others. Ideally, a production system only has the container orchestration
    software such as Kubernetes installed on a cluster node with a minimal OS, such
    as Core OS. The application container in turn ideally only contains the binaries
    absolutely necessary to run. This minimizes the attack surface and the risk of
    having to deal with vulnerabilities. Furthermore, a small image has the advantage
    of being downloaded quickly, using less space on disk and in memory and showing
    faster startup times.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐的最佳实践是为生产环境创建最小化的镜像，避免包含不必要的内容。这包括常用的调试和故障排除工具，如netcat、iostat、ip等。理想情况下，生产系统的集群节点上仅安装容器编排软件（如Kubernetes）和一个最小化的操作系统，如Core
    OS。而应用容器则只包含运行所需的绝对必要的二进制文件。这可以最小化攻击面，减少处理漏洞的风险。此外，小镜像的优势在于下载速度快，占用磁盘和内存空间小，启动时间更短。
- en: But this can be a problem if one of the application services running on our
    Kubernetes cluster shows unexpected behavior and maybe even crashes. Sometimes
    we are not able to find the root cause of the problem just from the logs generated
    and collected, so we might need to troubleshoot the component on the cluster node
    itself.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果我们 Kubernetes 集群中的某个应用服务表现异常甚至崩溃，这可能会成为一个问题。有时候我们仅凭生成和收集的日志无法找到问题的根本原因，因此我们可能需要在集群节点本身进行故障排除。
- en: We may be tempted to SSH into the given cluster node and run some diagnostic
    tools. But this is not possible since the cluster node only runs a minimal Linux
    distro with no such tools installed. As a developer, we could now just ask the
    cluster administrator to install all the Linux diagnostic tools we intend to use.
    But that is not a good idea. First of all, this would open the door for potentially
    vulnerable software now residing on the cluster node, endangering all the other
    pods that run on that node, and also open a door to the cluster itself that could
    be exploited by hackers. Furthermore, it is always a bad idea to give developers
    direct access to nodes of a production cluster, no matter how much you trust your
    developers. Only a limited number of cluster administrators should ever be able
    to do so.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会倾向于通过 SSH 登录到指定的集群节点并运行一些诊断工具。但这是不可能的，因为集群节点仅运行一个最小化的 Linux 发行版，并没有安装这些工具。作为开发人员，我们现在可以请求集群管理员为我们安装所有打算使用的
    Linux 诊断工具。但这并不是一个好主意。首先，这样做会为潜在的脆弱软件打开大门，这些软件可能会驻留在集群节点上，危及所有在该节点上运行的其他 pod，并且还可能为集群本身打开一个漏洞，黑客可能会利用这个漏洞。此外，无论你多么信任开发人员，直接给予开发人员对生产集群节点的访问权限始终都是一个坏主意。只有少数集群管理员应该能够这样做。
- en: A better solution is to have the cluster admin run a so-called bastion container
    on behalf of the developers. This bastion or troubleshoot container has all the
    tools installed that we need to pinpoint the root cause of the bug in the application
    service. It is also possible to run the bastion container in the host's network
    namespace; thus, it will have full access to all the network traffic of the container
    host.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的解决方案是让集群管理员代表开发人员运行一个所谓的堡垒容器。这个堡垒容器或故障排除容器安装了我们需要的所有工具，用于定位应用服务中的 bug 根本原因。它还可以在主机的网络命名空间中运行，从而完全访问容器主机的所有网络流量。
- en: The netshoot container
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: netshoot 容器
- en: 'Nicola Kabar, a former Docker employee, has created a handy Docker image called
    `nicolaka/netshoot` that field engineers at Docker use all the time to troubleshoot
    applications running in production on Kubernetes or Docker Swarm. We created a
    copy of the image for this book, available at `fundamentalsofdocker/netshoot`.
    The purpose of this container in the words of the creator is as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 前 Docker 员工 Nicola Kabar 创建了一个实用的 Docker 镜像，名为 `nicolaka/netshoot`，这是 Docker
    的现场工程师们经常使用的工具，用于故障排除在 Kubernetes 或 Docker Swarm 上生产环境中运行的应用程序。我们为本书创建了该镜像的一个副本，名称为
    `fundamentalsofdocker/netshoot`。该容器的目的，正如创始人所言，如下：
- en: '"Purpose: Docker and Kubernetes network troubleshooting can become complex.
    With proper understanding of how Docker and Kubernetes networking works and the
    right set of tools, you can troubleshoot and resolve these networking issues.
    The `netshoot` container has a set of powerful networking troubleshooting tools
    that can be used to troubleshoot Docker networking issues."                   
                                                                                 
                                                                                 
                                                                                 
                                                                                 
     - *Nicola Kabar*'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '"目的：Docker 和 Kubernetes 网络故障排除可能变得复杂。通过正确理解 Docker 和 Kubernetes 网络的工作原理，并使用合适的工具集，你可以排查并解决这些网络问题。`netshoot`
    容器提供了一套强大的网络故障排除工具，可用于排查 Docker 网络问题。" - *Nicola Kabar*'
- en: 'To use this container for debugging purposes, we can proceed as follows:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 若要使用该容器进行调试，我们可以按以下步骤进行：
- en: 'Spin up a throwaway bastion container for debugging on Kubernetes, using the
    following command:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在 Kubernetes 上快速启动一个临时堡垒容器以进行调试：
- en: '[PRE47]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'You can now use tools such as `ip` from within this container:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你可以在这个容器内使用诸如`ip`之类的工具：
- en: '[PRE48]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'On my machine, this results in an output similar to the following if I run
    the pod on Docker for Windows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的机器上，如果我在 Docker for Windows 上运行 pod，输出结果大致如下：
- en: '[PRE49]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: To leave this troubleshoot container, just press *Ctrl* + *D* or type `exit`
    and then hit *Enter*.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要退出这个故障排除容器，只需按 *Ctrl* + *D* 或输入 `exit` 然后按 *Enter*。
- en: 'If we need to dig a bit deeper and run the container in the same network namespace
    as the Kubernetes host, then we can use this command instead:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们需要深入研究并将容器运行在与 Kubernetes 主机相同的网络命名空间中，那么我们可以使用以下命令：
- en: '[PRE50]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: If we run `ip` again in this container, we will see everything that the container
    host sees too, for example, all the `veth` endpoints.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们在这个容器中再次运行 `ip`，我们将看到容器主机所看到的所有内容，例如，所有 `veth` 端点。
- en: The `netshoot` container has all the usual tools installed that an engineer
    ever needs to troubleshoot network-related problems. Some of the more familiar
    ones are `ctop`, `curl`, `dhcping`, `drill`, `ethtool`, `iftop`, `iperf`, and `iproute2`.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '`netshoot` 容器安装了所有工程师需要的常用工具来故障排除与网络相关的问题。一些更常见的工具包括 `ctop`、`curl`、`dhcping`、`drill`、`ethtool`、`iftop`、`iperf`
    和 `iproute2`。'
- en: Summary
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned some techniques used to monitor an individual service
    or a whole distributed application running on a Kubernetes cluster. Furthermore,
    you investigated troubleshooting an application service that is running in production
    without having to alter the cluster or the cluster nodes on which the service
    is running.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了一些技术，如何监控在 Kubernetes 集群中运行的单个服务或整个分布式应用程序。此外，你还研究了如何故障排除在生产环境中运行的应用服务，而不需要更改集群或服务运行的集群节点。
- en: In the next and final chapter of this book, you will gain an overview of some
    of the most popular ways of running containerized applications in the cloud. The
    chapter includes samples on how to self-host and use hosted solutions and discuss
    their pros and cons. Fully managed offerings of vendors such as Microsoft Azure
    and Google Cloud Engine are briefly discussed.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的下一章也是最后一章，你将了解在云中运行容器化应用程序的几种最流行的方式。本章包括如何自托管和使用托管解决方案的示例，并讨论它们的优缺点。像微软Azure和谷歌云引擎这样的完全托管服务也会简要讨论。
- en: Questions
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'To assess your learning progress, please answer the following questions:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估你的学习进度，请回答以下问题：
- en: Why is it important to instrument your application services?
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么为你的应用服务添加监控非常重要？
- en: Can you describe to an interested layperson what Prometheus is?
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能向一个感兴趣的外行描述一下 Prometheus 是什么吗？
- en: Exporting Prometheus metrics is easy. Can you describe in simple words how you
    can do this for a Node.js application?
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导出 Prometheus 指标很简单。你能用简单的语言描述如何为 Node.js 应用程序做到这一点吗？
- en: You need to debug a service running on Kubernetes in production. Unfortunately,
    the logs produced by this service alone don't give enough information to pinpoint
    the root cause. You decide to troubleshoot the service directly on the respective
    Kubernetes cluster node. How do you proceed?
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要调试一个在生产环境中运行的 Kubernetes 服务。不幸的是，仅由该服务产生的日志不足以提供足够的信息来确定根本原因。你决定直接在相应的 Kubernetes
    集群节点上进行故障排除。你该如何进行？
- en: Further reading
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Here are a few links that provide additional information on the topics discussed
    in this chapter:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些链接，提供了有关本章讨论主题的额外信息：
- en: Kubernetes Monitoring with Prometheus*:* [https://sysdig.com/blog/kubernetes-monitoring-prometheus/](https://sysdig.com/blog/kubernetes-monitoring-prometheus/)
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Prometheus 监控 Kubernetes*：*[https://sysdig.com/blog/kubernetes-monitoring-prometheus/](https://sysdig.com/blog/kubernetes-monitoring-prometheus/)
- en: Prometheus Client Libraries*: *[https://prometheus.io/docs/instrumenting/clientlibs/](https://prometheus.io/docs/instrumenting/clientlibs/)
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus 客户端库*：*[https://prometheus.io/docs/instrumenting/clientlibs/](https://prometheus.io/docs/instrumenting/clientlibs/)
- en: The `netshoot` container*: *[https://github.com/nicolaka/netshoot](https://github.com/nicolaka/netshoot)
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`netshoot` 容器*：*[https://github.com/nicolaka/netshoot](https://github.com/nicolaka/netshoot)'
