- en: '*Chapter 8*'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: '*第八章*'
- en: Clustering with Docker Swarm
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Docker Swarm 进行集群管理
- en: In this chapter, we will be taking a look at Docker Swarm. With Docker Swarm,
    you can create and manage Docker clusters. Swarm can be used to distribute containers
    across multiple hosts and also has the ability to scale containers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍 Docker Swarm。通过 Docker Swarm，您可以创建和管理 Docker 集群。Swarm 可用于在多个主机上分发容器，并具有扩展容器的能力。
- en: 'We will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论以下主题：
- en: Introducing Docker Swarm
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 Docker Swarm
- en: Creating and managing a swarm
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和管理一个 swarm
- en: Docker Swarm services and stacks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Swarm 服务和堆栈
- en: Load balancing, overlays, and scheduling
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负载均衡、覆盖网络与调度
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: As in previous chapters, we will continue to use our local Docker installations.
    Again, the screenshots in this chapter will be from my preferred operating system,
    macOS. As before, the Docker commands we will be running will work on all three
    of the operating systems on which we have installed Docker so far. However, some
    of the supporting commands, which will be few and far between, may only apply
    to macOS- and Linux-based operating systems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 和前几章一样，我们将继续使用本地的 Docker 安装。本章中的截图将来自我偏好的操作系统 macOS。与之前一样，我们将运行的 Docker 命令适用于目前已安装
    Docker 的所有三种操作系统。不过，少数支持命令可能仅适用于基于 macOS 和 Linux 的操作系统。
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/334RE0A](https://bit.ly/334RE0A)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，看看代码如何运行：[https://bit.ly/334RE0A](https://bit.ly/334RE0A)
- en: Introducing Docker Swarm
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Docker Swarm
- en: Before we go any further, I should mention that there are two very different
    versions of Docker Swarm. There was a standalone version of Docker Swarm—this
    was supported up until Docker `1.12` and is no longer being actively developed;
    however, you may find some old documentation mentions it. Installation of the
    standalone Docker Swarm is not recommended as Docker ended support for version
    `1.11.x` in the first quarter of 2017.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入之前，我需要提到，Docker Swarm 有两个非常不同的版本。曾经有一个独立版 Docker Swarm——它在 Docker `1.12`
    之前被支持，但现在已经不再积极开发；然而，您可能会在一些旧文档中看到它的提及。由于 Docker 在 2017 年第一季度结束了对 `1.11.x` 版本的支持，因此不推荐安装独立版
    Docker Swarm。
- en: Docker version `1.12` introduced Docker Swarm mode. This introduced all of the
    functionality that was available in the standalone Docker Swarm version into the
    core Docker Engine, along with a significant number of additional features. As
    we are covering Docker 19.03 and higher in this book, we will be using Docker
    Swarm mode, which, for the remainder of the chapter, we will refer to as Docker
    Swarm.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 版本 `1.12` 引入了 Docker Swarm 模式。这将独立 Docker Swarm 版本中的所有功能集成到核心 Docker
    引擎中，并增加了大量新功能。由于本书讨论的是 Docker 19.03 及更高版本，我们将使用 Docker Swarm 模式，接下来我们将称之为 Docker
    Swarm。
- en: 'As you are already running a version of Docker with in-built support for Docker
    Swarm, there isn''t anything you need to do in order to install Docker Swarm.
    You can verify that Docker Swarm is available on your installation by running
    the following command:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您已安装支持 Docker Swarm 的 Docker 版本，因此无需额外操作来安装 Docker Swarm。您可以通过运行以下命令来验证 Docker
    Swarm 是否已在您的安装中启用：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You should see something that looks like the following Terminal output when
    running the command:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 运行该命令时，您应该看到如下的终端输出：
- en: '![Figure 8.1 – Viewing the help'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.1 – 查看帮助'
- en: '](img/Figure_8.01_B15659.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.01_B15659.jpg)'
- en: Figure 8.1 – Viewing the help
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – 查看帮助
- en: If you get an error, ensure that you are running Docker 19.03 or higher, the
    installation of which we covered in [*Chapter 1*](B15659_01_Final_JM_ePub.xhtml#_idTextAnchor046),
    *Docker Overview*. Now that we know that our Docker client supports Docker Swarm,
    what do we mean by a Swarm?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果遇到错误，请确保您正在运行 Docker 19.03 或更高版本，我们在[*第一章*](B15659_01_Final_JM_ePub.xhtml#_idTextAnchor046)中已经介绍了该版本的安装，*Docker
    概述*。现在我们知道 Docker 客户端支持 Docker Swarm，那么我们所说的 Swarm 是什么意思？
- en: A **Swarm** is a collection of hosts, all running Docker, which have been set
    up to interact with each other in a clustered configuration. Once configured,
    you will be able to use all of the commands we have been running so far when targeting
    a single host, and let Docker Swarm decide the placement of your containers by
    using a deployment strategy to decide the most appropriate host on which to launch
    your container. Docker Swarms are made up of two types of host. Let's take a look
    at these now.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swarm** 是一组运行 Docker 的主机，它们被配置为相互交互并组成集群。一旦配置完成，你就可以像在单个主机上操作一样使用我们之前执行过的所有命令，同时让
    Docker Swarm 根据部署策略决定容器的最适合运行主机。Docker Swarm 由两种类型的主机组成。我们现在来看一下这两种主机。'
- en: Roles within a Docker Swarm cluster
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker Swarm 集群中的角色
- en: Which roles are involved with Docker Swarm? Let's take a look at the two roles
    a host can assume when running within a Docker Swarm cluster.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 中涉及哪些角色？让我们来看一下在 Docker Swarm 集群中运行时，主机可以担任的两种角色。
- en: Swarm manager
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Swarm 管理器
- en: The **Swarm manager** is a host that is the central management point for all
    Swarm hosts. The Swarm manager is where you issue all your commands to control
    those nodes. You can switch between the nodes, join nodes, remove nodes, and manipulate
    those hosts.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swarm 管理器** 是一个主机，它是所有 Swarm 主机的中央管理点。Swarm 管理器是你发出所有命令以控制这些节点的地方。你可以在节点之间切换，加入节点，移除节点，并操作这些主机。'
- en: Each cluster can run several Swarm managers. For production, it is recommended
    that you run a minimum of five Swarm managers; this would mean that our cluster
    can take a maximum of two Swarm manager node failures before you start to encounter
    any errors. Swarm managers use the *Raft consensus algorithm* (see the *Further
    reading* section for more details) to maintain a consistent state across all of
    the manager nodes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 每个集群可以运行多个 Swarm 管理器。对于生产环境，建议至少运行五个 Swarm 管理器；这样我们的集群在出现最多两个 Swarm 管理器节点故障之前不会出现错误。Swarm
    管理器使用 *Raft 共识算法*（详见 *进一步阅读* 部分）来保持所有管理节点之间的一致状态。
- en: Swarm workers
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Swarm 工作节点
- en: 'The Swarm workers, which we have seen referred to earlier as Docker hosts,
    are those that run the Docker containers. Swarm workers are managed from the Swarm
    manager, and are depicted in the following diagram:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm 工作节点，之前我们提到的 Docker 主机，就是运行 Docker 容器的那些节点。Swarm 工作节点由 Swarm 管理器进行管理，并在下图中展示：
- en: '![Figure 8.2 – An overview of Swarm workers'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.2 – Swarm 工作节点概览'
- en: '](img/Figure_8.02_B15659.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.02_B15659.jpg)'
- en: Figure 8.2 – An overview of Swarm workers
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – Swarm 工作节点概览
- en: This is an illustration of all the Docker Swarm components. We see that the
    Docker Swarm manager talks to each Swarm host that has a Docker Swarm worker role.
    The workers do have some level of connectivity, which we will look at shortly.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一张所有 Docker Swarm 组件的示意图。我们看到 Docker Swarm 管理器与每个拥有 Docker Swarm 工作节点角色的主机进行通信。工作节点之间确实有一定的连接，我们稍后会进一步了解。
- en: Creating and managing a Swarm
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和管理 Swarm
- en: 'Let''s now take a look at using Swarm and how we can perform the following
    tasks:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下如何使用 Swarm，并执行以下任务：
- en: Creating a cluster
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建集群
- en: Joining workers
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加入工作节点
- en: Listing nodes
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出节点
- en: Managing a cluster
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理集群
- en: Creating the cluster hosts
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建集群主机
- en: 'Let''s start by creating a cluster of three machines. Since we are going to
    be creating a multi-node cluster on our local machine, we are going to use Multipass,
    which we covered in [*Chapter 6*](B15659_06_Final_JM_ePub.xhtml#_idTextAnchor187)*,
    Docker Machine, Vagrant, and Multipass*, to launch the hosts by running the following
    commands:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建一个包含三台机器的集群开始。由于我们将在本地机器上创建一个多节点集群，我们将使用之前在 [*第六章*](B15659_06_Final_JM_ePub.xhtml#_idTextAnchor187)
    中讲到的 Multipass，Docker Machine，Vagrant 和 Multipass，通过运行以下命令来启动主机：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This should give us three nodes; you can check this by just running the following
    command:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会为我们创建三个节点；你可以通过运行以下命令来检查：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You should see something similar to the following output:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能看到类似以下的输出：
- en: '![Figure 8.3 – Launching the nodes using Multipass'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.3 – 使用 Multipass 启动节点'
- en: '](img/Figure_8.03_B15659.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.03_B15659.jpg)'
- en: Figure 8.3 – Launching the nodes using Multipass
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – 使用 Multipass 启动节点
- en: 'You may remember from when we last used Multipass that bringing up a host doesn''t
    mean that Docker is installed; so, now, let''s install Docker and add the `ubuntu`
    user to the `docker` group so that when we use `multipass exec`, we don''t have
    to change user. To do this, run the following three commands:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得上次使用Multipass时，启动一个主机并不意味着Docker已经安装；所以，现在，让我们安装Docker，并将`ubuntu`用户添加到`docker`组中，这样当我们使用`multipass
    exec`时，就不需要切换用户了。为此，请运行以下三条命令：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now that we have our three cluster nodes ready, we can move on to the next step,
    which is adding a Swarm manager to the cluster.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的三个集群节点已经准备就绪，我们可以继续进行下一步，即将Swarm管理节点添加到集群中。
- en: Adding a Swarm manager to the cluster
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将Swarm管理节点添加到集群
- en: 'Let''s bootstrap our Swarm manager. To do this, we will pass the results of
    a few Docker Machine commands to our host. Before we create the Swarm manager,
    we need to get the IP address of `node1` as this is going to be our Swarm manager.
    If you are using macOS or Linux, then you can set an environment variable by running
    the following command:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们启动我们的Swarm管理节点。为此，我们将把一些Docker Machine命令的结果传递给我们的主机。在创建Swarm管理节点之前，我们需要获取`node1`的IP地址，因为它将成为我们的Swarm管理节点。如果你使用的是macOS或Linux，可以通过运行以下命令设置一个环境变量：
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If you are using Windows 10, then run `multipass list` and make a note of the
    IP address for `node1`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是Windows 10，请运行`multipass list`并记下`node1`的IP地址。
- en: 'The command to run in order to create our manager is shown in the following
    code snippet (if you are running Windows, replace `$IP` with the IP address you
    made a note of):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 用于创建我们管理节点的命令在以下代码片段中显示（如果你正在使用Windows，请将`$IP`替换为你记下的IP地址）：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You should receive a message similar to this one:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该收到类似以下的消息：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see from the output, once your manager is initialized, you are given
    a unique token.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以看到，一旦你的管理节点初始化完成，你将获得一个唯一的令牌。
- en: 'In the preceding example, the full token is this:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，完整的令牌是：
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This token will be needed for the worker nodes to authenticate themselves and
    join our cluster.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这个令牌将用于工作节点进行身份验证，并加入我们的集群。
- en: Joining Swarm workers to the cluster
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将Swarm工作节点加入集群
- en: 'Now it is time to add our two workers (`node2` and `node3`) to the cluster.
    First, let''s set an environment variable to hold our token, making sure that
    you replace the token with the one you received when initializing your own manager,
    as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候将我们的两个工作节点（`node2`和`node3`）添加到集群中了。首先，让我们设置一个环境变量来保存我们的令牌，确保你将令牌替换为在初始化管理节点时收到的令牌，如下所示：
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Again, Windows users need to make a note of the token and will have to replace
    both `$SWARM_TOKEN` and `$IP` in the command shown next with their respective
    values.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，Windows用户需要记下令牌，并且在接下来的命令中，需要将`$SWARM_TOKEN`和`$IP`分别替换为他们的实际值。
- en: 'Now, we can run the following command to add `node2` to the cluster:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以运行以下命令将`node2`添加到集群：
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'For `node3`, you need to run the following command:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`node3`，你需要运行以下命令：
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Both times, you should get confirmation that your node has joined the cluster,
    as illustrated in the following screenshot:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 每次操作，你都应该收到确认信息，表示你的节点已经加入集群，如以下截图所示：
- en: '![Figure 8.4 – Adding the workers to the cluster'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.4 – 将工作节点添加到集群'
- en: '](img/Figure_8.04_B15659.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.04_B15659.jpg)'
- en: Figure 8.4 – Adding the workers to the cluster
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 将工作节点添加到集群
- en: Listing nodes
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列出节点
- en: 'You can check the Swarm by running the following command:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过运行以下命令来检查Swarm：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This will connect to `node1`, which we have configured as the Swarm master,
    and query all of the nodes that form our cluster.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这将连接到`node1`，我们已经将其配置为Swarm主节点，并查询构成我们集群的所有节点。
- en: 'You should see that all three of our nodes are listed, as illustrated in the
    following screenshot:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到所有三个节点都被列出，如以下截图所示：
- en: '![Figure 8.5 – Listing the cluster nodes'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.5 – 列出集群节点'
- en: '](img/Figure_8.05_B15659.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.05_B15659.jpg)'
- en: Figure 8.5 – Listing the cluster nodes
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – 列出集群节点
- en: 'Now, we are going to move from the Docker client on our local machine to that
    on `node1`. To connect to the shell on `node1`, we just need to run the following
    command:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将从本地机器上的Docker客户端切换到`node1`上的Docker客户端。要连接到`node1`的Shell，我们只需运行以下命令：
- en: '[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This will leave us at a prompt on `node1`, where we are ready to start using
    our cluster.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把我们留在`node1`的命令行提示符下，准备开始使用我们的集群。
- en: Managing a cluster
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理集群
- en: Let's see how we can perform some management of all of these cluster nodes that
    we are creating.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何管理我们正在创建的所有集群节点。
- en: There are only two ways in which you can go about managing the containers within
    your cluster—these are by using the `docker service` and `docker stack` commands,
    which we are going to be covering in the next section of the chapter.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你管理集群中容器的方式只有两种——这两种方式是使用`docker service`和`docker stack`命令，我们将在本章的下一部分中介绍这两种方式。
- en: Before we look at launching containers in our cluster, let's have a look at
    managing the cluster itself, starting with how you can find out more information
    on it.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看如何在集群中启动容器之前，让我们先看一下如何管理集群本身，从了解如何获取集群的更多信息开始。
- en: Finding information on the cluster
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查找集群信息
- en: 'As we have already seen, we can list the nodes within the cluster using the
    Docker client installed on `node1`. To find out more information, we can simply
    type this to the command line of `node1`:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经看到的，我们可以使用安装在`node1`上的Docker客户端列出集群中的节点。要获取更多信息，我们只需在`node1`的命令行中输入以下内容：
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This will give us lots of information about the host, as you can see from the
    following output, which I have truncated:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这将提供关于主机的大量信息，如下所示（我已经截断了输出）：
- en: '[PRE14]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see, there is information about the cluster in the `Swarm` section;
    however, we are only able to run the `docker info` command against the host with
    which our client is currently configured to communicate. Luckily, the `docker
    node` command is cluster-aware, so we can use that to get information on each
    node within our cluster.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在`Swarm`部分有集群的信息；然而，我们只能对当前配置为与之通信的主机运行`docker info`命令。幸运的是，`docker node`命令是集群感知的，所以我们可以使用它来获取集群中每个节点的信息。
- en: TIP
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Assessing the `--pretty` flag with the `docker node inspect` command will render
    the output in the easy-to-read format you see next. If `--pretty` is left out,
    Docker will return the raw `JSON` object containing the results of the query the
    `inspect` command runs against the cluster.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`docker node inspect`命令的`--pretty`标志可以将输出以易读的格式呈现。如果省略`--pretty`，Docker将返回包含查询结果的原始`JSON`对象，这些查询是`inspect`命令针对集群运行的。
- en: 'Here is what we would need to run to get information on `node1`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们需要运行的命令，以获取关于`node1`的信息：
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This should provide the following information on our Swarm manager:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会提供有关我们Swarm管理节点的以下信息：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Run the same command, but this time targeting one of the worker nodes, as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 运行相同的命令，但这次针对其中一个工作节点，命令如下：
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This gives us similar information, as can be seen here:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们类似的信息，如下所示：
- en: '[PRE18]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: But as you can see, information about the state of the manager functionality
    is missing. This is because the worker nodes do not need to know about the status
    of the manager nodes; they just need to know that they are allowed to receive
    instructions from the managers.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 但正如你所看到的，关于管理节点功能状态的信息缺失。这是因为工作节点不需要知道管理节点的状态；它们只需要知道它们被允许接收来自管理节点的指令。
- en: In this way, we can see details about this host, such as the number of containers,
    the number of images on the host, and information about the **central processing
    unit** (**CPU**) and memory, along with other interesting information.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们可以看到关于此主机的详细信息，例如容器数量、主机上的镜像数量、**中央处理单元**（**CPU**）和内存信息，以及其他有趣的信息。
- en: Now that we know how to get information on the nodes that go to make up our
    cluster, let's take a look at how we can promote a node's role within the cluster.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何获取构成我们集群的节点信息后，让我们来看一下如何提升节点在集群中的角色。
- en: Promoting a worker node
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提升一个工作节点
- en: Say you wanted to perform some maintenance on your single manager node, but
    you wanted to maintain the availability of your cluster. No problem—you can promote
    a worker node to a manager node.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想对单个管理节点进行一些维护，但你希望保持集群的可用性。没问题——你可以将一个工作节点提升为管理节点。
- en: 'While we have our local three-node cluster up and running, let''s promote `node2`
    to be a new manager. To do this, run the following command:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的本地三节点集群已经启动并运行的情况下，让我们将`node2`提升为新的管理节点。为此，运行以下命令：
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You should receive a message confirming that your node has been promoted immediately
    after executing the command, as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 执行命令后，你应该会收到一条确认消息，表示你的节点已经被提升，消息如下：
- en: '[PRE20]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'List the nodes by running this command:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下命令列出节点：
- en: '[PRE21]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This should show you that you now have two nodes that display something in
    the `MANAGER STATUS` column, as illustrated in the following screenshot:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会显示出你现在有两个节点在`MANAGER STATUS`列中显示内容，如下图所示：
- en: '![Figure 8.6 – Checking the status of the nodes in the cluster'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.6 – 检查集群中节点的状态'
- en: '](img/Figure_8.06_B15659.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.06_B15659.jpg)'
- en: Figure 8.6 – Checking the status of the nodes in the cluster
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – 检查集群中节点的状态
- en: Our `node1` node is still the primary manager node, though. Let's look at doing
    something about that, and switch its role from manager to worker.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`node1`节点仍然是主要的管理节点，不过。让我们来处理一下这个问题，将其角色从管理节点切换为工作节点。
- en: Demoting a manager node
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 降级管理节点
- en: 'You may have already put two and two together, but to demote a manager node
    to a worker node, you simply need to run this command:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经猜到如何操作了，要将管理节点降级为工作节点，你只需运行以下命令：
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Again, you will receive immediate feedback stating the following:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，你将收到即时反馈，显示以下内容：
- en: '[PRE23]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now that we have demoted our node, you can check the status of the nodes within
    the cluster by running this command:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经降级了节点，你可以通过运行以下命令来检查集群中节点的状态：
- en: '[PRE24]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As we are connected to `node1`, which is the newly demoted node, you will receive
    a message stating the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们连接的是`node1`，即刚被降级的节点，你将收到以下消息：
- en: '[PRE25]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'To connect to our new Swarm manager, we need to be SSHd into `node2`. To do
    this, we simply need to disconnect from `node1` and connect to `node2` by running
    the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 要连接到我们的新 Swarm 管理节点，我们需要通过 SSH 连接到`node2`。为此，我们只需断开与`node1`的连接，并通过运行以下命令连接到`node2`：
- en: '[PRE26]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now that are connected to a manager node again, rerun this, as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们再次连接到一个管理节点，请按以下方式重新运行：
- en: '[PRE27]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'It should list the nodes as expected, as illustrated in the following screenshot:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 它应该如预期那样列出节点，以下截图展示了这一点：
- en: '![Figure 8.7 – Checking the status of the nodes in the cluster'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.7 – 检查集群中节点的状态'
- en: '](img/Figure_8.07_B15659.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.07_B15659.jpg)'
- en: Figure 8.7 – Checking the status of the nodes in the cluster
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – 检查集群中节点的状态
- en: This is all well and good, but how would we take a node out of the cluster so
    that we could perform maintenance on it? Let's now take a look at how we would
    drain a node.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都很顺利，但我们怎么才能将一个节点移出集群，以便对其进行维护呢？现在让我们看看如何排空一个节点。
- en: Draining a node
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 节点排空
- en: 'To temporarily remove a node from our cluster so that we can perform maintenance,
    we need to set the status of the node to `Drain`. Let''s look at draining our
    former manager node. To do this, we need to run the following command:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了临时将一个节点从集群中移除以便进行维护，我们需要将节点的状态设置为`Drain`。让我们看看如何排空我们原先的管理节点。为此，我们需要运行以下命令：
- en: '[PRE28]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This will stop any new tasks, such as new containers launching or being executed
    against the node we are draining. Once new tasks have been blocked, all running
    tasks will be migrated from the node we are draining to nodes with an `Active`
    status.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这将停止任何新任务的执行，例如启动或执行新容器，针对我们正在排空的节点。一旦新任务被阻止，所有正在运行的任务将从我们正在排空的节点迁移到状态为`Active`的节点。
- en: 'As you can see from the following Terminal output, listing the nodes now shows
    that `node1` is listed with a status of `Drain` in the `AVAILABILITY` column:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 从下面的终端输出可以看到，现在列出的节点显示`node1`在`AVAILABILITY`列中的状态是`Drain`：
- en: '![Figure 8.8 – Checking the status of our cluster'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.8 – 检查我们集群的状态'
- en: '](img/Figure_8.08_B15659.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.08_B15659.jpg)'
- en: Figure 8.8 – Checking the status of our cluster
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 – 检查我们集群的状态
- en: 'Now that our node is no longer accepting new tasks and all running tasks have
    been migrated to our two remaining nodes, we can safely perform our maintenance,
    such as rebooting the host. To reboot `node1`, run the following two commands
    on your main host in a second window:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的节点不再接受新任务，所有正在运行的任务都已迁移到剩余的两个节点，我们可以安全地进行维护，例如重启主机。要重启`node1`，在你的主机第二窗口中运行以下两个命令：
- en: '[PRE29]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Once the host has been rebooted, run this command on `node2`:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦主机重新启动，在`node2`上运行此命令：
- en: '[PRE30]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'It should show that the node has an `AVAILABILITY` status of `Drain`. To add
    the node back into the cluster, simply change the `AVAILABILITY` status to `Active`
    by running the following on `node2`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 它应该显示该节点的`AVAILABILITY`状态为`Drain`。要将节点重新加入集群，只需通过在`node2`上运行以下命令将`AVAILABILITY`状态更改为`Active`：
- en: '[PRE31]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'As you can see from the following Terminal output, our node is now active,
    meaning new tasks can be executed against it:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 从下面的终端输出可以看到，我们的节点现在处于活动状态，意味着可以在其上执行新任务：
- en: '![Figure 8.9 – Checking the status of our cluster'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.9 – 检查我们集群的状态'
- en: '](img/Figure_8.09_B15659.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.09_B15659.jpg)'
- en: Figure 8.9 – Checking the status of our cluster
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9 – 检查我们集群的状态
- en: Now that we have looked at how to create and manage a Docker Swarm cluster,
    we should look at how to run a task such as creating and scaling a service or
    launching a stack.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解如何创建和管理Docker Swarm集群，我们应该看看如何执行一些任务，比如创建和扩展服务或启动堆栈。
- en: Docker Swarm services and stacks
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker Swarm 服务和堆栈
- en: 'So far, we have looked at the following commands:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看过以下命令：
- en: '[PRE32]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'These two commands allow us to bootstrap and manage our Docker Swarm cluster
    from a collection of existing Docker hosts. The next two commands we are going
    to look at are as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个命令允许我们从现有的Docker主机集合中启动并管理Docker Swarm集群。接下来我们要看的是以下两个命令：
- en: '[PRE33]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The `service` and `stack` commands allow us to execute tasks that, in turn,
    launch, scale, and manage containers within our Swarm cluster.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`service`和`stack`命令允许我们执行任务，进而启动、扩展和管理我们Swarm集群中的容器。'
- en: Services
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务
- en: The `service` command is a way of launching containers that take advantage of
    the Swarm cluster. Let's look at launching a really basic single-container service
    on our Swarm cluster.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`service`命令是一种启动容器的方式，它利用了Swarm集群的优势。我们来看一下如何在Swarm集群上启动一个非常基础的单容器服务。'
- en: TIP
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Don't forget that the `docker` commands here need to be executed from your current
    Swarm manager. If you are following, that should be `node2`.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了，`docker`命令需要从你当前的Swarm管理节点执行。如果你跟随的话，应该是`node2`。
- en: 'To do this, run the following command:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，请运行以下命令：
- en: '[PRE34]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This will create a service called `cluster` that consists of a single container
    with port `80` mapped from the container to the host machine, and it will only
    be running on nodes that have the role of `worker`.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个名为`cluster`的服务，该服务由一个容器组成，容器的端口`80`从容器映射到主机机器，并且仅在具有`worker`角色的节点上运行。
- en: 'Before we look at doing more with the service, we can check whether it worked
    on our browser. To do this, we will need the IP address of our two worker nodes.
    First of all, we need to double-check which are the worker nodes by running this
    command:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解如何使用该服务之前，我们可以先检查它是否在浏览器中工作。为此，我们需要知道我们两个工作节点的IP地址。首先，我们需要通过运行以下命令来确认哪些是工作节点：
- en: '[PRE35]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Once we know which node has which role, you can find the IP addresses of your
    nodes by running this command in a second Terminal window on your host machine:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们知道每个节点的角色，你可以通过在主机机器上的第二个终端窗口中运行以下命令来找到节点的IP地址：
- en: '[PRE36]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Look at the following Terminal output:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下终端输出：
- en: '![Figure 8.10 – Creating a service and checking the IP addresses of the nodes'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.10 – 创建服务并检查节点的IP地址'
- en: '](img/Figure_8.10_B15659.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.10_B15659.jpg)'
- en: Figure 8.10 – Creating a service and checking the IP addresses of the nodes
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10 – 创建服务并检查节点的IP地址
- en: My worker nodes are `node1` and `node3`, whose IP addresses are `192.168.64.9`
    and `192.168.64.11`, respectively.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我的工作节点是`node1`和`node3`，它们的IP地址分别是`192.168.64.9`和`192.168.64.11`。
- en: 'Going to either of the IP addresses of your worker nodes, such as http://192.168.64.9/
    or http://192.168.64.11/, in a browser will show the output of the `russmckendrick/cluster`
    application, which is the Docker Swarm graphic and the hostname of the container
    the page is being served from. This is illustrated in the following screenshot:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在浏览器中访问你的工作节点的任一IP地址，例如 http://192.168.64.9/ 或 http://192.168.64.11/，将显示`russmckendrick/cluster`应用程序的输出，这包括Docker
    Swarm图形和提供页面的容器的主机名。以下截图中做了说明：
- en: '![Figure 8.11 – Our cluster application'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.11 – 我们的集群应用'
- en: '](img/Figure_8.11_B15659.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.11_B15659.jpg)'
- en: Figure 8.11 – Our cluster application
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.11 – 我们的集群应用
- en: 'Now that we have our service running on our cluster, we can start to find out
    more information about it. First of all, we can list the services again by running
    this command:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的服务已经在集群中运行，我们可以开始获取更多关于它的信息。首先，我们可以通过运行以下命令再次列出服务：
- en: '[PRE37]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In our case, this should return the single service we launched, called `cluster`,
    as illustrated in the following screenshot:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，这应该返回我们启动的单个服务，名为`cluster`，如下截图所示：
- en: '![Figure 8.12 – Listing the services'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.12 – 列出服务'
- en: '](img/Figure_8.12_B15659.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.12_B15659.jpg)'
- en: Figure 8.12 – Listing the services
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.12 – 列出服务
- en: 'As you can see, it is a `inspect` command, as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这是一个`inspect`命令，如下所示：
- en: '[PRE38]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This will return detailed information about the service, as illustrated in
    the following screenshot:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回有关服务的详细信息，如下截图所示：
- en: '![Figure 8.13 – Grabbing information on a service'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.13 – 获取服务信息'
- en: '](img/Figure_8.13_B15659.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.13_B15659.jpg)'
- en: Figure 8.13 – Grabbing information on a service
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.13 – 获取服务信息
- en: You may have noticed that so far, we haven't had to bother about which of our
    two worker nodes the service is currently running on. This is quite an important
    feature of Docker Swarm, as it completely removes the need for you to worry about
    the placement of individual containers.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，到目前为止，我们并不需要担心我们的两个工作节点中哪个节点正在运行服务。这是 Docker Swarm 的一个非常重要的功能，它完全消除了您需要担心单个容器位置的需求。
- en: 'Before we look at scaling our service, we can take a quick look at which host
    our single container is running on by executing these commands:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看如何扩展服务之前，我们可以快速查看我们的单个容器运行在哪个主机上，方法是执行以下命令：
- en: '[PRE39]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This will list the containers running on each of our hosts. By default, it
    will list the host the command is being targeted against, which in my case is
    `node1`, as illustrated in the following screenshot:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这将列出在每个主机上运行的容器。默认情况下，它将列出命令所针对的主机，在我的情况下是`node1`，如下所示的屏幕截图：
- en: '![Figure 8.14 – Finding the node our service is running on'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.14 – 查找我们的服务运行在哪个节点上'
- en: '](img/Figure_8.14_B15659.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.14_B15659.jpg)'
- en: Figure 8.14 – Finding the node our service is running on
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.14 – 查找我们的服务运行在哪个节点上
- en: 'Let''s look at scaling our service to six instances of our application container.
    Run the following commands to scale and check our service:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下如何将服务扩展为六个实例的应用容器。运行以下命令来扩展并检查我们的服务：
- en: '[PRE40]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We are only checking two of the nodes since we originally told our service
    to launch on worker nodes. As you can see from the following Terminal output,
    we now have three containers running on each of our worker nodes:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只检查了两个节点，因为我们最初告诉我们的服务在工作节点上启动。正如您从以下终端输出中看到的，我们现在在每个工作节点上都有三个容器在运行：
- en: '![Figure 8.15 – Checking the distribution of containers on our nodes'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.15 – 检查容器在我们的节点上的分布'
- en: '](img/Figure_8.15_B15659.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.15_B15659.jpg)'
- en: Figure 8.15 – Checking the distribution of containers on our nodes
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.15 – 检查容器在我们的节点上的分布
- en: 'Before we move on to look at stacks, let''s remove our service. To do this,
    run the following command:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续查看堆栈之前，让我们先删除我们的服务。为此，请运行以下命令：
- en: '[PRE41]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This will remove all of the containers, while leaving the downloaded image on
    the hosts.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这将删除所有容器，同时将下载的图像保留在主机上。
- en: Stacks
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 堆栈
- en: It is more than possible to create quite complex, highly available multi-container
    applications using Swarm services. In a non-Swarm cluster, manually launching
    each set of containers for a part of the application can start to become a little
    laborious and also makes it difficult to share services. To this end, Docker has
    created a functionality that allows you to define your services in Docker Compose
    files.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Swarm 服务，完全有可能创建相当复杂、高可用的多容器应用程序。在非 Swarm 集群中，手动启动应用程序的每一部分容器集可能会变得有些繁琐，并且也使共享服务变得困难。为此，Docker
    创建了一个功能，允许您在 Docker Compose 文件中定义您的服务。
- en: 'The following Docker Compose file, which is named `docker-compose.yml`, will
    create the same service we launched in the `services` section:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的 Docker Compose 文件，名为`docker-compose.yml`，将创建与我们在`services`部分启动的服务相同的服务：
- en: '[PRE42]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: As you can see, the stack can be made up of multiple services, each defined
    under the `services` section of the Docker Compose file.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，堆栈可以由多个服务组成，每个服务都在 Docker Compose 文件的`services`部分中定义。
- en: In addition to the normal Docker Compose commands, you can add a `deploy` section;
    this is where you define everything relating to the Swarm element of your stack.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 除了普通的 Docker Compose 命令，您还可以添加一个`deploy`部分；在这里，您可以定义与堆栈的 Swarm 元素相关的一切。
- en: In the previous example, we said we would like six replicas, which should be
    distributed across our two worker nodes. Also, we updated the default restart
    policy, which you saw when we inspected the service from the previous section,
    and it showed up as `paused`, so that if a container becomes unresponsive, it
    is always restarted.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的示例中，我们说过我们希望有六个副本，并且这些副本应分布在我们的两个工作节点上。同时，我们更新了默认的重启策略，您在检查前一部分中的服务时看到过，它显示为`paused`，这样如果容器变得无响应，它会始终被重新启动。
- en: 'To launch our stack, copy the previous content into the `docker-compose.yml`
    file, and then run the following command:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动我们的堆栈，请将之前的内容复制到`docker-compose.yml`文件中，然后运行以下命令：
- en: '[PRE43]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Docker will—as when launching containers with Docker Compose—create a new network
    and then launch your services on it. You can check the status of your stack by
    running this command:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 将—就像启动 Docker Compose 容器时一样—创建一个新的网络，然后在其上启动你的服务。你可以通过运行以下命令来检查堆栈的状态：
- en: '[PRE44]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This will show that a single service has been created. You can get details
    of the service created by the `stack` by running this command:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示一个服务已被创建。你可以通过运行以下命令获取由 `stack` 创建的服务的详细信息：
- en: '[PRE45]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Finally, running the following command will show where the containers within
    the stack are running:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，运行以下命令将显示堆栈中容器的运行位置：
- en: '[PRE46]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Take a look at the following Terminal output:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下终端输出：
- en: '![Figure 8.16 – Deploying our stack'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.16 – 部署我们的堆栈'
- en: '](img/Figure_8.16_B15659.jpg)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.16_B15659.jpg)'
- en: Figure 8.16 – Deploying our stack
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.16 – 部署我们的堆栈
- en: 'Again, you will be able to access the stack using the IP addresses of your
    nodes, and you will be routed to one of the running containers. To remove a stack,
    simply run this command:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你将能够使用节点的 IP 地址访问堆栈，系统将会将你路由到其中一个正在运行的容器。要删除堆栈，只需运行以下命令：
- en: '[PRE47]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This will remove all services and networks created by the stack when it is launched.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这将删除堆栈启动时创建的所有服务和网络。
- en: Deleting a Swarm cluster
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除一个 Swarm 集群
- en: 'Before moving on, as we no longer require it for the next section, you can
    delete your Swarm cluster by running the following command:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，由于接下来的部分不再需要它，你可以通过运行以下命令删除你的 Swarm 集群：
- en: '[PRE48]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Should you need to relaunch the Swarm cluster for any reason, simply follow
    the instructions from the start of the chapter to recreate a cluster.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你因某种原因需要重新启动 Swarm 集群，只需按照本章开头的说明重新创建集群。
- en: Load balancing, overlays, and scheduling
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 负载均衡、覆盖网络和调度
- en: In the last few sections, we looked at launching services and stacks. To access
    the applications we launched, we were able to use any of the host IP addresses
    in our cluster; how was this possible?
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几个部分中，我们查看了启动服务和堆栈的过程。要访问我们启动的应用程序，我们可以使用集群中任何主机的 IP 地址；这是怎么实现的呢？
- en: Ingress load balancing
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 入口负载均衡
- en: Docker Swarm has an ingress load balancer built in, making it easy to distribute
    traffic to our public-facing containers.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 内置了一个入口负载均衡器，使我们能够轻松地将流量分配到我们面向公共的容器。
- en: 'This means that you can expose applications within your Swarm cluster to services—for
    example, an external load balancer such as Amazon **Elastic Load Balancer** (**ELB**)—knowing
    that your request will be routed to the correct container(s) no matter which host
    happens to be currently hosting it, as demonstrated by the following diagram:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你可以将 Swarm 集群中的应用程序暴露给外部服务——例如，像 Amazon **Elastic Load Balancer**（**ELB**）这样的外部负载均衡器——并且你知道，无论当前哪个主机托管容器，您的请求都会被路由到正确的容器，如下图所示：
- en: '![Figure 8.17 – An overview of load balancing in a Swarm cluster'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.17 – Swarm 集群中负载均衡的概述'
- en: '](img/Figure_8.17_B15659.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.17_B15659.jpg)'
- en: Figure 8.17 – An overview of load balancing in a Swarm cluster
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.17 – Swarm 集群中负载均衡的概述
- en: This means that our application can be scaled up or down, fail, or be updated,
    all without the need to have the external load balancer reconfigured to talk to
    the individual containers, as Docker Swarm is handling that for us.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们的应用程序可以扩展、缩减、故障或更新，所有这些都无需重新配置外部负载均衡器与各个容器通信，因为 Docker Swarm 会为我们处理这些。
- en: Network overlays
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络覆盖
- en: In our example, we launched a simple service running a single application. Say
    we wanted to add a database layer in our application, which is typically a fixed
    point within the network; how could we do this?
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们启动了一个运行单个应用程序的简单服务。假设我们想在应用程序中添加一个数据库层，通常这是网络中的一个固定点；我们该怎么做呢？
- en: Docker Swarm's network overlay layer extends the network you launch your containers
    in across multiple hosts, meaning that each service or stack can be launched in
    its own isolated network. This means that our database container, running MongoDB,
    will be accessible to all other containers running on the same overlay network
    on port `27017`, no matter which of the hosts the containers are running on.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 的网络覆盖层扩展了你在多个主机上启动容器的网络，这意味着每个服务或堆栈都可以在其自己的隔离网络中启动。这意味着我们的数据库容器（运行
    MongoDB）将可以通过端口 `27017` 访问所有在同一覆盖网络上运行的其他容器，无论这些容器运行在哪个主机上。
- en: 'You may be thinking to yourself: *Hang on a minute. Does this mean I have to
    hardcode an IP address into my application''s configuration?* Well, that wouldn''t
    fit well with the problems Docker Swarm is trying to resolve, so no, you don''t.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会在心里想：*等一下，这是不是意味着我需要将 IP 地址硬编码到我的应用配置中？* 嗯，这与 Docker Swarm 想要解决的问题不太匹配，所以答案是否定的，你不需要这样做。
- en: Each overlay network has its own inbuilt `mongodb:27017`, and it will connect
    to our MongoDB container.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 每个覆盖网络都有自己的内建 `mongodb:27017`，它将连接到我们的 MongoDB 容器。
- en: 'This will make our diagram appear as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使我们的图表如下所示：
- en: '![Figure 8.18 – An overview of overlay networks in a Docker Swarm cluster'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.18 – Docker Swarm 集群中覆盖网络的概述'
- en: '](img/Figure_8.18_B15659.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_8.18_B15659.jpg)'
- en: Figure 8.18 – An overview of overlay networks in a Docker Swarm cluster
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.18 – Docker Swarm 集群中覆盖网络的概述
- en: There are some other considerations you will need to take into account when
    adopting this pattern, but we will cover those in [*Chapter 15*](B15659_15_Final_JM_ePub.xhtml#_idTextAnchor823)*,*
    *Docker Workflows*.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在采用这种模式时，你需要考虑一些其他因素，但我们将在[*第 15 章*](B15659_15_Final_JM_ePub.xhtml#_idTextAnchor823)中讨论这些问题，*Docker
    工作流*。
- en: Scheduling
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调度
- en: At the time of writing, there is only a single scheduling strategy available
    within Docker Swarm, called **spread**. What this strategy does is schedule tasks
    to be run against the least loaded node that meets any of the constraints you
    defined when launching the service or stack. For the most part, you should not
    need to add too many constraints to your services.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在写作时，Docker Swarm 中只有一种调度策略，叫做 **spread**。该策略的作用是将任务调度到负载最轻的节点，该节点满足你在启动服务或堆栈时定义的约束条件。通常情况下，你不需要为你的服务添加太多约束。
- en: One feature that is not currently supported by Docker Swarm is affinity and
    anti-affinity rules. While it is easy to get around using this constraint, I urge
    you not to overcomplicate things, as it is very easy to end up overloading hosts
    or creating single points of failure if you put too many constraints in place
    when defining your services.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 当前不支持的一项功能是亲和性和反亲和性规则。虽然可以通过使用这种约束来规避，但我建议你不要过于复杂化事情，因为在定义服务时，如果施加太多约束，很容易导致主机过载或创建单点故障。
- en: Summary
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored Docker Swarm. We took a look at how to install
    Docker Swarm and the Docker Swarm components that make up Docker Swarm. We took
    a look at how to use Docker Swarm, joining, listing, and managing Swarm manager
    and worker nodes. We reviewed the `service` and `stack` commands and how to use
    them, and spoke about the Swarm inbuilt ingress load balancer, overlay networks,
    and scheduler.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了 Docker Swarm。我们了解了如何安装 Docker Swarm 以及构成 Docker Swarm 的各个组件。我们还探讨了如何使用
    Docker Swarm，加入、列出和管理 Swarm 管理节点和工作节点。我们回顾了 `service` 和 `stack` 命令及其使用方法，并讲解了
    Swarm 内置的入口负载均衡器、覆盖网络和调度器。
- en: Now, Docker Swarm is in an interesting state at the time of writing, as Docker
    Swarm was one of the technologies acquired by Mirantis as part of the Docker Enterprise
    sale, and while Mirantis have said that they will offer support for existing Docker
    Swarm clusters for 2 years (that was in November 2019), they haven't given much
    information on the future of Docker Swarm.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Docker Swarm 在写作时处于一个有趣的状态，因为 Docker Swarm 是 Mirantis 在收购 Docker 企业版时获得的技术之一，尽管
    Mirantis 表示他们将在 2 年内为现有的 Docker Swarm 集群提供支持（这是在 2019 年 11 月），但他们并没有提供关于 Docker
    Swarm 未来发展的更多信息。
- en: This isn't surprising as Mirantis do a lot of work with another container cluster
    called Kubernetes, which we are going to be looking at in [*Chapter 11*](B15659_11_Final_JM_ePub.xhtml#_idTextAnchor294),
    *Docker and Kubernetes*. Before then, in the next chapter, we are going to take
    a look at a **graphical user interface** (**GUI**) for Docker called **Portainer**.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不令人惊讶，因为 Mirantis 在另一种容器集群 Kubernetes 上做了很多工作，而我们将在[*第 11 章*](B15659_11_Final_JM_ePub.xhtml#_idTextAnchor294)中讨论它，*Docker
    和 Kubernetes*。在此之前，在下一章中，我们将看一下 Docker 的**图形用户界面**（**GUI**）——**Portainer**。
- en: Questions
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'True or false: You should be running your Docker Swarm using the standalone
    Docker Swarm rather than the in-built Docker Swarm mode.'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 判断题：你应该使用独立的 Docker Swarm 运行 Docker Swarm，而不是使用内置的 Docker Swarm 模式。
- en: Which two things do you need after initiating your Docker Swarm manager to add
    your workers to your Docker Swarm cluster?
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在启动 Docker Swarm 管理节点后，您需要哪些两项内容来将工作节点添加到 Docker Swarm 集群？
- en: Which command would you use to find out the status of each of the nodes within
    your Docker Swarm cluster?
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会使用哪个命令来查找 Docker Swarm 集群中每个节点的状态？
- en: Which flag would you add to `docker node inspect` on Swarm manager to make it
    more readable?
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会在 Swarm 管理节点上为 `docker node inspect` 命令添加哪个标志，以使其更易读？
- en: How do you promote a node to be a manager?
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何将一个节点提升为管理节点？
- en: Which command can you use to scale your service?
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用哪个命令来缩放你的服务？
- en: Further reading
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: For a detailed explanation of the Raft consensus algorithm, I recommend working
    through the excellent presentation entitled *The Secret Lives of Data*, which
    can be found at [http://thesecretlivesofdata.com/raft/](http://thesecretlivesofdata.com/raft/).
    It explains all the processes taking place in the background on the manager nodes
    via an easy-to-follow animation.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 Raft 共识算法的详细解释，我推荐阅读一份优秀的演讲《*数据的秘密生活*》，可以在[http://thesecretlivesofdata.com/raft/](http://thesecretlivesofdata.com/raft/)找到。它通过一个易于跟随的动画解释了在管理节点上发生的所有后台过程。
