- en: Self-Adaptation Applied to Instrumented Services
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自适应应用于仪表化服务
- en: An [instrumented service](https://prometheus.io/docs/practices/instrumentation/)
    provides more detailed metrics then what we can scrape from [exporters](https://prometheus.io/docs/instrumenting/exporters/).
    The ability to add all the metrics we might need opens the doors that are often
    closed with exporters. That does not mean that they are any less useful but that
    we need to think of the nature of the resource we are observing.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '[仪表化服务](https://prometheus.io/docs/practices/instrumentation/)提供比我们从[exporters](https://prometheus.io/docs/instrumenting/exporters/)抓取的更多详细指标。添加我们可能需要的所有指标的能力打开了通常由exporters关闭的大门。这并不意味着exporters就不那么有用，而是我们需要考虑我们观察的资源的性质。'
- en: Hardware metrics should be scraped from exporters. After all, we cannot instrument
    CPU. Third-party services are another good example of a use-case where exporters
    are often a better option. If we use a database, we should look for an exporter
    that fetches metrics from it and transforms them into the Prometheus-friendly
    format. The same goes for proxies, gateways, and just about almost any other service
    that we did not develop.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件指标应从exporter中抓取。毕竟，我们无法对CPU进行仪表化。第三方服务是另一个很好的例子，在这些场景下，exporter通常是更好的选择。如果我们使用数据库，我们应该寻找一个从中获取指标并将其转换为Prometheus友好格式的exporter。代理、网关以及几乎所有其他非我们开发的服务也应如此。
- en: We might choose to [write an exporter](https://prometheus.io/docs/instrumenting/writing_exporters/)
    even for services we are in control of if we already invested a lot of time implementing
    metrics that are not in Prometheus format.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们已经投入了大量时间实现不符合Prometheus格式的指标，我们甚至可以选择为我们控制的服务[编写一个exporter](https://prometheus.io/docs/instrumenting/writing_exporters/)。
- en: Exporters can get us only half-way through. We can instruct the system to scale
    based on, for example, memory utilization. [cAdvisor](https://github.com/google/cadvisor)
    provides information about the containers running inside the cluster, but the
    metrics it provides are too generic. We cannot get service-specific data. Inability
    to fine-tune metrics on per-service basis leaves us with insufficient information
    that can be used only for basic alerts. Instrumentation provides the missing piece
    of the puzzle.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Exporter只能帮助我们走一半的路。我们可以指示系统根据内存使用情况进行扩展。[cAdvisor](https://github.com/google/cadvisor)提供有关集群内运行的容器的信息，但它提供的指标过于通用，无法获取服务特定的数据。无法针对每个服务进行指标微调，导致我们只能使用基本的警报，信息不足。仪表化填补了这一缺失的拼图。
- en: In cases we are willing to invest time to instrument our services, the results
    are impressive. We can get everything we need without compromises. We can accomplish
    almost any level of details and instrument services in a way that we can write
    reliable alerts that will notify the system with all the information it needs.
    The result is a step closer towards self-healing and, more importantly, self-adaptation.
    The reason I’m putting self-adaptation into the “more important” group lies in
    the fact that self-healing is already mostly solved by other tools. Schedulers
    (e.g. Docker Swarm) already do a decent job at self-healing services. If we exclude
    hardware from the scope, we are left with self-adaptation of services as the major
    obstacle left to solve.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们愿意投入时间对服务进行仪表化的情况下，结果是令人印象深刻的。我们可以在不做妥协的情况下获得所需的一切。我们可以完成几乎任何细节层级的任务，并以一种能够编写可靠警报的方式对服务进行仪表化，这些警报将以系统所需的所有信息通知系统。结果是向自愈更近了一步，更重要的是，向自适应更近了一步。我将自适应归为“更重要”的原因在于，自愈问题已经大部分通过其他工具解决了。调度程序（例如Docker
    Swarm）已经在自愈服务方面做得相当好。如果我们排除硬件范围，我们剩下的最大障碍是服务的自适应性。
- en: Setting Up The Objectives
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设定目标
- en: We need to define the scope of what we want to accomplish through instrumentation.
    We’ll keep it small by limiting ourselves to a single goal. We’ll scale services
    if their response times are over an upper limit and de-scale them if they’re below
    a lower limit. Any other alert will lead to a notification to Slack. That does
    not mean that Slack notifications should exist forever. Instead, they should be
    treated as a temporary solution until we find a way to translate manual corrective
    actions into automated responses performed by the system.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要定义通过仪表化想要实现的目标范围。我们将通过限制自己只关注一个目标来保持目标的简洁。如果服务的响应时间超过上限，我们将扩大其规模；如果低于下限，我们将缩小其规模。任何其他警报都将导致通知发送到Slack。并不意味着Slack通知应该永远存在。相反，它们应该被视为一种临时解决方案，直到我们找到将手动修正操作转化为由系统执行的自动响应的方法。
- en: A good example of alerts that are often treated manually are responses with
    errors (status codes 500 and above). We’ll send alerts whenever they reach a threshold
    over a specified period. They will result in Slack notifications that will become
    pending tasks for humans. An internal rule should be to fix the problem first,
    evaluate why it happened, and write a script that will repeat the same set of
    steps. With such a script, we’ll be able to instruct the system to do the same
    if the same alert is fired again. With such an approach, we (humans) can spend
    our time solving unexpected problems and leave machines to remedy those that are
    reoccurring.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经常手动处理的警报的好例子是错误响应（状态码500及以上）。当它们在指定的时间段内达到某个阈值时，我们会发送警报。它们会导致Slack通知，并成为待处理任务交给人工。一个内部规则应该是先修复问题，评估问题发生的原因，并编写一个脚本来重复相同的步骤。有了这样的脚本，如果相同的警报再次触发，我们就可以指示系统执行相同的操作。通过这种方法，我们（人类）可以将时间花费在解决意外问题上，把机器交给那些反复出现的问题。
- en: The summary of the objectives we’ll try to accomplish is as follows.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试完成的目标总结如下。
- en: Define maximum response time of a service and create the flow that will scale
    it.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义服务的最大响应时间并创建将其扩展的流程。
- en: Define minimum response time of a service and create the flow that will de-scale
    it.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义服务的最小响应时间并创建将其缩减的流程。
- en: Define thresholds based on responses with status codes 500 and above and send
    Slack notifications.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于状态码500及以上的响应定义阈值，并发送Slack通知。
- en: Please note that response time thresholds cannot rely only on milliseconds.
    We must define quantiles, rates, and a few other things. Also, we need to set
    the minimum and the maximum number of replicas of a service. Otherwise, we risk
    scaling to infinity or de-scaling to zero replicas. Once we start implementing
    the system, we’ll see whether those additional requirements are enough or we’ll
    need to extend the scope further.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，响应时间阈值不能仅依赖于毫秒。我们必须定义分位数、速率以及其他一些因素。此外，我们需要设置服务的最小和最大副本数量。否则，我们可能会面临无限扩展或缩减到零副本的风险。一旦我们开始实施系统，就可以查看这些额外的需求是否足够，或者是否需要进一步扩展范围。
- en: That was more than enough talk. Let’s move to the practical exploration of the
    subject.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 说的够多了，接下来让我们进入实际的主题探索。
- en: As always, the first step is to create a cluster and deploy a few services.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，第一步是创建一个集群并部署一些服务。
- en: Creating The Cluster And Deploying Services
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建集群并部署服务
- en: You know the drill. We’ll create a Swarm cluster and deploy a few stacks we
    are already familiar with. Once we’re done, we’ll have the base required for the
    exploration of the tasks at hand.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道该怎么做。我们将创建一个Swarm集群，并部署一些我们已经熟悉的栈。完成后，我们将拥有进行任务探索所需的基础。
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
