- en: Deploying, Updating, and Securing an Application with Kubernetes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kubernetes部署、更新和保护应用程序
- en: In the previous chapter, we learned about the basics of the container orchestrator,
    Kubernetes. We got a high-level overview of the architecture of Kubernetes and
    learned a lot about the important objects used by Kubernetes to define and manage
    a containerized application.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了容器编排工具Kubernetes的基础知识。我们对Kubernetes的架构有了高层次的了解，并学到了许多关于Kubernetes用来定义和管理容器化应用程序的重要对象。
- en: In this chapter, we will learn how to deploy, update, and scale applications
    into a Kubernetes cluster. We will also explain how zero downtime deployments
    are achieved to enable disruption-free updates and rollbacks of mission-critical
    applications. Finally, we will introduce Kubernetes secrets as a means to configure
    services and protect sensitive data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何将应用程序部署、更新和扩展到Kubernetes集群中。我们还将解释如何实现零停机部署，以便无干扰地更新和回滚关键任务应用程序。最后，我们将介绍Kubernetes
    secrets，作为配置服务和保护敏感数据的手段。
- en: 'This chapter covers the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下内容：
- en: Deploying a first application
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署第一个应用程序
- en: Defining liveness and readiness
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义活跃性和就绪性
- en: Zero downtime deployments
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零停机部署
- en: Kubernetes secrets
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes secrets
- en: 'After working through this chapter, you will be able to do the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章内容后，你将能够完成以下任务：
- en: Deploy a multi-service application into a Kubernetes cluster
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将多服务应用程序部署到Kubernetes集群中
- en: Define a liveness and readiness probe for your Kubernetes application service
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为你的Kubernetes应用程序服务定义活跃性和就绪性探针
- en: Update an application service running in Kubernetes without causing downtime
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes中更新应用程序服务而不造成停机
- en: Define secrets in a Kubernetes cluster
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes集群中定义secrets
- en: Configure an application service to use Kubernetes secrets
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置应用程序服务以使用Kubernetes secrets
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we're going to use Minikube on our local computer. Please refer
    to [Chapter 2](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml), *Setting Up a Working
    Environment*, for more information on how to install and use Minikube.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将在本地计算机上使用Minikube。关于如何安装和使用Minikube的详细信息，请参见[第2章](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml)，*设置工作环境*。
- en: 'The code for this chapter can be found here: [https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch16/probes](https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch16/probes).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在此处找到：[https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch16/probes](https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch16/probes)。
- en: Please make sure you have cloned this book's GitHub repository, as described
    in [Chapter 2](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml), *Setting Up a Working
    Environment*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保你已经克隆了本书的GitHub仓库，具体步骤请参见[第2章](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml)，*设置工作环境*。
- en: In your Terminal, navigate to the `~/fod/ch16` folder.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端中，导航到`~/fod/ch16`文件夹。
- en: Deploying a first application
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署第一个应用程序
- en: We will take our pets application, which we first introduced in [Chapter 11](412c6f55-a00b-447f-b22a-47b305453507.xhtml), *Docker
    Compose*, and deploy it into a Kubernetes cluster. Our cluster will be Minikube,
    which, as you know, is a single-node cluster. However, from the perspective of
    a deployment, it doesn't really matter how big the cluster is and where the cluster
    is located in the cloud, in your company's data center, or on your personal workstation.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把我们在[第11章](412c6f55-a00b-447f-b22a-47b305453507.xhtml)，*Docker Compose*中首次介绍的宠物应用程序，部署到Kubernetes集群中。我们的集群将是Minikube，它是一个单节点集群。尽管如此，从部署的角度来看，集群的大小和所在位置无关，是否位于云端、公司数据中心，或者个人工作站上都不重要。
- en: Deploying the web component
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署Web组件
- en: 'Just as a reminder, our application consists of two application services: the
    Node-based web component and the backing PostgreSQL database. In the previous
    chapter, we learned that we need to define a Kubernetes Deployment object for
    each application service we want to deploy. Let''s do this first for the web component.
    As always in this book, we will choose the declarative way of defining our objects.
    Here is the YAML defining a Deployment object for the web component:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，我们的应用程序由两个应用程序服务组成：基于Node的Web组件和后台的PostgreSQL数据库。在上一章中，我们学到我们需要为每个要部署的应用程序服务定义一个Kubernetes
    Deployment对象。首先我们为Web组件定义它。正如本书中一贯的做法，我们将选择声明式的方式来定义我们的对象。以下是定义Web组件的Deployment对象的YAML：
- en: '![](img/f43630a9-a410-44cf-a9f1-bcd87d583f54.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f43630a9-a410-44cf-a9f1-bcd87d583f54.png)'
- en: Kubernetes deployment definition for the web component
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 部署定义（web 组件）
- en: 'The preceding deployment definition can be found in the `web-deployment.yaml` file
    in the `~/fod/ch16` folder. The lines of code are as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 上述部署定义可以在 `~/fod/ch16` 文件夹中的 `web-deployment.yaml` 文件中找到。代码行如下：
- en: 'On line `4`: We define the name for our `Deployment` object as `web`.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 `4` 行：我们为 `Deployment` 对象定义了名称 `web`。
- en: 'On line `6`: We declare that we want to have one instance of the `web` component
    running.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 `6` 行：我们声明要运行一个 `web` 组件实例。
- en: 'From line `8` to `10`: We define which pods will be part of our deployment,
    namely those that have the `app` and `service` labels with values of `pets` and `web`,
    respectively.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从第 `8` 行到第 `10` 行：我们定义了哪些 pods 会成为我们部署的一部分，即那些拥有 `app` 和 `service` 标签，标签值分别为
    `pets` 和 `web` 的 pods。
- en: 'On line `11`: In the template for the pods starting at line `11`, we define
    that each pod will have the `app` and `service` labels applied to them.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 `11` 行：在从第 `11` 行开始的 pod 模板中，我们定义了每个 pod 都会应用 `app` 和 `service` 标签。
- en: 'From line `17`: We define the single container that will be running in the
    pod. The image for the container is our well-known `fundamentalsofdocker/ch11-web:2.0` image
    and the name of the container will be `web`.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从第 `17` 行：我们定义了将在 pod 中运行的唯一容器。该容器的镜像为我们熟知的 `fundamentalsofdocker/ch11-web:2.0`
    镜像，容器的名称为 `web`。
- en: '`ports`: Finally, we declare that the container exposes port `3000` for TCP-type
    traffic.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ports`：最后，我们声明容器暴露 `3000` 端口供 TCP 类型的流量使用。'
- en: Please make sure that you have set the context of kubectl to Minikube. See [Chapter
    2](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml), *Setting Up a Working Environment*, for
    details on how to do that.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保已经将 kubectl 的上下文设置为 Minikube。有关如何设置的详细信息，请参见 [第 2 章](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml)，*设置工作环境*。
- en: 'We can deploy this Deployment object using kubectl:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 kubectl 部署这个 Deployment 对象：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can double-check that the deployment has been created again using our Kubernetes
    CLI. We should see the following output:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Kubernetes CLI 再次确认部署是否已创建。我们应该看到以下输出：
- en: '![](img/b631548b-c83b-4421-a037-a931a77b9ba7.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b631548b-c83b-4421-a037-a931a77b9ba7.png)'
- en: Listing all resources running in Minikube
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 列出在 Minikube 上运行的所有资源
- en: In the preceding output, we can see that Kubernetes created three objects –
    the deployment, a pertaining ReplicaSet, and a single pod (remember that we specified
    that we want one replica only). The current state corresponds to the desired state
    for all three objects, so we are fine so far.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们可以看到 Kubernetes 创建了三个对象——部署（deployment）、相应的 ReplicaSet 和一个单独的 pod（记住我们指定了只需要一个副本）。当前状态与这三个对象的期望状态一致，所以到目前为止一切正常。
- en: 'Now, the web service needs to be exposed to the public. For this, we need to
    define a Kubernetes Service object of the `NodePort` type. Here is the definition,
    which can be found in the `web-service.yaml` file in the `~/fod/ch16` folder:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，网络服务需要向公众公开。为此，我们需要定义一个 `NodePort` 类型的 Kubernetes 服务对象。以下是定义，可以在 `~/fod/ch16`
    文件夹中的 `web-service.yaml` 文件中找到：
- en: '![](img/aa181850-9aab-492a-a132-e99ecbb7f102.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aa181850-9aab-492a-a132-e99ecbb7f102.png)'
- en: Definition of the Service object for our web component
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 web 组件的 Service 对象
- en: 'The preceding lines of codes are as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码行如下：
- en: 'On line `4`: We set the `name` of this Service object to `web`.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 `4` 行：我们将此 Service 对象的 `name` 设置为 `web`。
- en: 'On line `6`: We define the `type` of Service object we''re using. Since the web component
    has to be accessible from outside of the cluster, this cannot be a Service object
    of the `ClusterIP` type and must be either of the `NodePort` or `LoadBalancer` type.
    We discussed the various types of Kubernetes services in the previous chapter,
    so will not go into further detail about this. In our sample, we''re using a `NodePort` type
    of service.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第 `6` 行：我们定义了正在使用的 Service 对象的 `type`。由于 web 组件必须能够从集群外部访问，因此不能使用 `ClusterIP`
    类型的 Service 对象，必须是 `NodePort` 或 `LoadBalancer` 类型。我们在上一章已经讨论了各种 Kubernetes 服务类型，因此这里不再详细讲解。在我们的示例中，我们使用的是
    `NodePort` 类型的服务。
- en: 'On lines `8` and `9`: We specify that we want to expose port `3000` for access
    through the `TCP` protocol. Kubernetes will map container port `3000` automatically
    to a free host port in the range of 30,000 to 32,768\. Which port Kubernetes effectively
    chooses can be determined using the `kubectl` get service or `kubectl` describe command for
    the service after it has been created.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`8`行和第`9`行：我们指定要通过`TCP`协议公开`3000`端口供访问。Kubernetes 会自动将容器端口`3000`映射到 30,000
    到 32,768 范围内的一个空闲主机端口。Kubernetes 实际选择的端口可以通过`kubectl get service`或`kubectl describe`命令在服务创建后确定。
- en: 'From line `10` to `12`: We define the filter criteria for the pods that this
    service will be a stable endpoint for. In this case, it is all the pods that have
    the `app` and `service` labels with the `pets` and `web` values, respectively.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从第`10`行到`12`行：我们定义了该服务将作为稳定端点的 Pod 的过滤条件。在这种情况下，它是所有具有`app`和`service`标签，分别为`pets`和`web`值的
    Pod。
- en: 'Now that we have this specification for a Service object, we can create it
    using `kubectl`:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了这个 Service 对象的规范，可以使用`kubectl`创建它：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can list all the services to see the result of the preceding command:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以列出所有服务，查看上一个命令的结果：
- en: '![](img/68357689-66d7-4587-97d9-369552a5fe75.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/68357689-66d7-4587-97d9-369552a5fe75.png)'
- en: The Service object created for the web component
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为 Web 组件创建的 Service 对象
- en: In the preceding output, we can see that a service called `web` has been created.
    A unique clusterIP of `10.99.99.133` has been assigned to this service, and the
    container port `3000` has been published on port `31331` on all cluster nodes.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的输出中，我们可以看到一个名为`web`的服务已经被创建。此服务分配了一个唯一的`clusterIP`，值为`10.99.99.133`，并且容器端口`3000`已经在所有集群节点的`31331`端口上进行了发布。
- en: 'If we want to test this deployment, we need to find out what IP address Minikube
    has, and then use this IP address to access our web service. The following is
    the command that we can use to do this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想测试这个部署，我们需要找出 Minikube 的 IP 地址，然后使用该 IP 地址访问我们的 Web 服务。以下是我们可以用来执行此操作的命令：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: OK, the response is `Pets Demo Application`, which is what we expected. The
    web service is up and running in the Kubernetes cluster. Next, we want to deploy
    the database.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，响应是`Pets Demo Application`，这是我们期望的。Web 服务已经在 Kubernetes 集群中启动并运行。接下来，我们要部署数据库。
- en: Deploying the database
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署数据库
- en: A database is a stateful component and has to be treated differently to stateless
    components, such as our web component. We discussed the difference between stateful
    and stateless components in a distributed application architecture in detail in [Chapter
    9](bbbf480e-3d5a-4ad7-94e9-fae735b025ae.xhtml), *Distributed Application Architecture*, and [Chapter
    12](27c0d9ce-fab6-4ce9-9034-4f2fb62931e8.xhtml), *Orchestrators*.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库是一个有状态组件，必须与无状态组件（例如我们的 Web 组件）不同地进行处理。我们在[第 9 章](bbbf480e-3d5a-4ad7-94e9-fae735b025ae.xhtml)《*分布式应用架构*》和[第
    12 章](27c0d9ce-fab6-4ce9-9034-4f2fb62931e8.xhtml)《*调度器*》中详细讨论了分布式应用架构中有状态和无状态组件之间的区别。
- en: 'Kubernetes has defined a special type of `ReplicaSet` object for stateful components.
    The object is called a `StatefulSet`. Let''s use this kind of object to deploy
    our database. The definition can be found in the `~fod/ch16/db-stateful-set.yaml` file.
    The details are as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 为有状态组件定义了一种特殊类型的`ReplicaSet`对象。这个对象叫做`StatefulSet`。我们将使用这种对象来部署我们的数据库。其定义可以在`~fod/ch16/db-stateful-set.yaml`文件中找到。具体内容如下：
- en: '![](img/a0e35643-c85e-4f8d-8e9c-b62a372a42dd.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a0e35643-c85e-4f8d-8e9c-b62a372a42dd.png)'
- en: A StatefulSet for the DB component
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库组件的 StatefulSet
- en: OK, this looks a bit scary, but it isn't. It is a bit longer than the definition
    of the deployment for the `web` component due to the fact that we also need to
    define a volume where the PostgreSQL database can store the data. The volume claim
    definition is on lines `25` to `33`. We want to create a volume with the name `pets-data` that
    has a maximum size equal to `100 MB`. On lines `22` to `24`, we use this volume and mount
    it into the container at `/var/lib/postgresql/data`, where PostgreSQL expects
    it. On line `21`, we also declare that PostgreSQL is listening at port `5432`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这看起来有点吓人，但实际上并不是。由于我们还需要定义一个卷来存储 PostgreSQL 数据库的数据，这比定义 `web` 组件的部署稍长一些。卷声明定义在第`25`行到`33`行。我们想创建一个名为`pets-data`的卷，最大大小为`100
    MB`。在第`22`行到`24`行，我们使用这个卷并将其挂载到容器的`/var/lib/postgresql/data`路径下，这是 PostgreSQL
    期望的位置。在第`21`行，我们还声明 PostgreSQL 在端口`5432`监听。
- en: 'As always, we use kubectl to deploy the `StatefulSet`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我们使用`kubectl`来部署`StatefulSet`：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, if we list all the resources in the cluster, we will be able to see the
    additional objects that were created:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们列出集群中的所有资源，我们将能够看到已创建的附加对象：
- en: '![](img/65326383-101f-44f5-a370-5e936b3933fd.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/65326383-101f-44f5-a370-5e936b3933fd.png)'
- en: The StatefulSet and its pod
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`StatefulSet`及其pod'
- en: Here, we can see that a `StatefulSet` and a pod have been created. For both,
    the current state corresponds to the desired state and thus the system is healthy.
    But that doesn't mean that the web component can access the database at this time.
    Service discovery won't work so far. Remember that the web component wants to
    access the `db` service under the name `db`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到一个`StatefulSet`和一个pod已经创建。对于这两个对象，当前状态与期望状态相符，因此系统是健康的。但这并不意味着此时Web组件可以访问数据库。到目前为止，服务发现尚未生效。记住，Web组件想要在名为`db`的服务下访问数据库。
- en: 'To make service discovery work inside the cluster, we have to define a Kubernetes Service object
    for the database component too. Since the database should only ever be accessible
    from within the cluster, the type of Service object we need is `ClusterIP`. Here
    is the specification, which can be found in the `~/fod/ch16/db-service.yaml` file:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使服务发现能够在集群内部工作，我们还必须为数据库组件定义一个Kubernetes服务对象。由于数据库应该只能从集群内部访问，我们需要的服务对象类型是`ClusterIP`。以下是该规范，可以在`~/fod/ch16/db-service.yaml`文件中找到：
- en: '![](img/50834c86-6427-4c33-b811-089547e1aef2.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/50834c86-6427-4c33-b811-089547e1aef2.png)'
- en: Definition of the Kubernetes Service object for the database
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 定义数据库的Kubernetes服务对象
- en: 'The database component will be represented by this Service object and it can
    be reached by the name `db`, which is the name of the service, as defined on line
    `4`. The database component does not have to be publicly accessible, so we decided
    to use a Service object of the `ClusterIP` type. The selector on lines `10` to
    `12` defines that this service represents a stable endpoint for all the pods that
    have the according labels defined, that is, `app: pets` and `service: db`.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '数据库组件将由这个`Service`对象表示，它可以通过`db`这个名字访问，这个名字在第`4`行定义。数据库组件不需要公开访问，因此我们决定使用`ClusterIP`类型的`Service`对象。第`10`到`12`行的选择器定义了该服务表示所有具有相应标签的pod的稳定端点，也就是`app:
    pets`和`service: db`。'
- en: 'Let''s deploy this service with the following command:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下命令来部署该服务：
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we should be ready to test the application. We can use the browser this
    time to enjoy the beautiful animal images:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们应该准备好测试应用程序了。这次我们可以使用浏览器来欣赏美丽的动物图片：
- en: '![](img/5a43f3ff-7ac5-4b0e-af24-e2ceb59bf180.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5a43f3ff-7ac5-4b0e-af24-e2ceb59bf180.png)'
- en: Testing the pets application running in Kubernetes
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 测试在Kubernetes中运行的宠物应用程序
- en: '`172.29.64.78` is the IP address of my Minikube. Verify your address using
    the `minikube ip` command. Port number `32722` is the number that Kubernetes automatically
    selected for my `web` Service object. Replace this number with the port that Kubernetes
    assigned to your service. You can get the number by using the `kubectl get services` command.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`172.29.64.78`是我的Minikube的IP地址。使用`minikube ip`命令可以验证您的地址。端口号`32722`是Kubernetes自动为我的`web`服务对象选择的端口。请将此数字替换为Kubernetes分配给您服务的端口。您可以通过使用`kubectl
    get services`命令来获取该端口号。'
- en: 'Now, we have successfully deployed the pets application to Minikube, which
    is a single-node Kubernetes cluster. We had to define four artifacts to do so,
    which are as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经成功将宠物应用程序部署到Minikube，这是一个单节点的Kubernetes集群。我们为此定义了四个工件，具体如下：
- en: A Deployment and a Service object for the web component
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Web组件的`Deployment`和`Service`对象
- en: A StatefulSet and a Service object for the database component
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库组件的`StatefulSet`和`Service`对象
- en: 'To remove the application from the cluster, we can use the following small
    script:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要从集群中移除应用程序，我们可以使用以下小脚本：
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Next, we will be streamlining the deployment.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将精简部署。
- en: Streamlining the deployment
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精简部署
- en: So far, we have created four artifacts that needed to be deployed to the cluster.
    This is only a very simple application, consisting of two components. Imagine
    having a much more complex application. It would quickly become a maintenance
    nightmare. Luckily, we have several options as to how we can simplify the deployment.
    The method that we are going to discuss here is the possibility of defining all
    the components that make up an application in Kubernetes in a single file.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经创建了需要部署到集群的四个工件。这只是一个非常简单的应用，包含两个组件。想象一下，如果应用更加复杂，维护将变得非常麻烦。幸运的是，我们有几种方法可以简化部署。我们将在这里讨论的方法是将构成
    Kubernetes 应用的所有组件定义放在一个文件中。
- en: Other solutions that lie outside of the scope of this book would include the
    use of a package manager, such as Helm.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 本书范围之外的其他解决方案包括使用包管理器，例如 Helm。
- en: 'If we have an application consisting of many Kubernetes objects such as `Deployment` and `Service` objects,
    then we can keep them all in one single file and separate the individual object definitions by
    three dashes. For example, if we wanted to have the `Deployment` and the `Service`
    definition for the `web` component in a single file, this would look as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个由多个 Kubernetes 对象（如 `Deployment` 和 `Service` 对象）组成的应用，那么我们可以将它们全部放在一个文件中，并用三个破折号分隔每个对象定义。例如，如果我们想将
    `web` 组件的 `Deployment` 和 `Service` 定义放在一个文件中，文件内容将如下所示：
- en: '[PRE6]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here, we have collected all four object definitions for the `pets` application
    in the `~/fod/ch16/pets.yaml` file, and we can deploy the application in one go:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已经将 `pets` 应用的四个对象定义收集在 `~/fod/ch16/pets.yaml` 文件中，我们可以一次性部署该应用。
- en: '![](img/76a4ab56-40ed-4d1b-b372-5267d4702597.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/76a4ab56-40ed-4d1b-b372-5267d4702597.png)'
- en: Using a single script to deploy the pets application
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个脚本来部署宠物应用
- en: 'Similarly, we have created a script called `~/fod/ch16/remove-pets.sh` to remove
    all the artifacts of the pets application from the Kubernetes cluster:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们创建了一个名为`~/fod/ch16/remove-pets.sh`的脚本，用于从 Kubernetes 集群中删除所有与宠物应用相关的文件。
- en: '![](img/5670017a-1e32-4999-8ee1-79d171f3830b.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5670017a-1e32-4999-8ee1-79d171f3830b.png)'
- en: Removing pets from the Kubernetes cluster
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Kubernetes 集群中删除宠物
- en: With this, we have taken our pets application we introduced in [Chapter 11](412c6f55-a00b-447f-b22a-47b305453507.xhtml), *Docker
    Compose*, and defined all the Kubernetes objects that are necessary to deploy
    this application into a Kubernetes cluster. In each step, we have made sure that
    we got the expected result, and once all the artifacts existed in the cluster,
    we showed the running application.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这一点，我们已经将第[11章](412c6f55-a00b-447f-b22a-47b305453507.xhtml)中介绍的*Docker Compose*宠物应用程序，定义了部署该应用到
    Kubernetes 集群所需的所有 Kubernetes 对象。在每个步骤中，我们都确保达到了预期的结果，一旦所有工件存在于集群中，我们展示了正在运行的应用。
- en: Defining liveness and readiness
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义存活性和就绪性
- en: Container orchestration systems such as Kubernetes and Docker swarm make it
    significantly easier to deploy, run, and update highly distributed, mission-critical
    applications. The orchestration engine automates many of the cumbersome tasks
    such as scaling up or down, asserting that the desired state is maintained at
    all times, and more.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 像 Kubernetes 和 Docker Swarm 这样的容器编排系统使得部署、运行和更新高度分布式的关键任务应用程序变得更加容易。编排引擎自动化了许多繁琐的任务，例如扩展、确保始终保持期望的状态等。
- en: But, the orchestration engine cannot just do everything automagically. Sometimes,
    we developers need to support the engine with some information that only we can
    know about. So, what do I mean by that?
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，编排引擎并不能自动做所有事情。有时，我们开发者需要为引擎提供一些只有我们才能了解的信息。那么，我是什么意思呢？
- en: Let's look at a single application service. Let's assume it is a microservice
    and let's call it **service A**. If we run service A containerized on a Kubernetes
    cluster, then Kubernetes can make sure that we have the five instances that we
    require in the service definition running at all times. If one instance crashes,
    Kubernetes can quickly launch a new instance and thus maintain the desired state.
    But, what if an instance of the service does not crash, but is unhealthy or just
    not ready yet to serve requests? It is evident that Kubernetes should know about
    both situations. But it can't, since healthy or not from an application service
    perspective is outside of the knowledge of the orchestration engine. Only we application
    developers can know when our service is healthy and when it is not.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一个单一的应用服务。假设它是一个微服务，称之为**服务 A**。如果我们在 Kubernetes 集群上运行容器化的服务 A，那么 Kubernetes
    可以确保我们在服务定义中要求的五个实例始终在运行。如果其中一个实例崩溃，Kubernetes 可以迅速启动一个新实例，从而保持期望状态。但是，如果某个服务的实例没有崩溃，而是处于不健康状态，或者只是尚未准备好处理请求呢？显然，Kubernetes
    应该知道这两种情况。但它做不到，因为从应用服务的角度来看，健康或不健康是编排引擎无法知晓的。只有我们这些应用开发人员才能知道何时我们的服务是健康的，何时它是不健康的。
- en: The application service could, for example, be running, but its internal state
    could have been corrupted due to some bug, it could be in an endless loop, or
    in a deadlock situation. Similarly, only we application developers know if our
    service is ready to work, or if it is still initializing. Although it is highly
    recommended to keep the initialization phase of a microservice as short as possible,
    it often cannot be avoided if there is a significant time span needed by a particular
    service so that it's ready to operate. Being in this state of initialization is
    not the same thing as being unhealthy, though. The initialization phase is an
    expected part of the life cycle of a microservice or any other application service.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，应用服务可能正在运行，但由于某些 bug，它的内部状态可能已经被破坏，可能处于死循环或死锁状态。类似地，只有我们这些应用开发人员知道我们的服务是否已准备好工作，或者它是否仍在初始化阶段。尽管强烈建议将微服务的初始化阶段尽可能缩短，但如果某个服务需要较长时间才能准备好工作，这种情况通常是无法避免的。然而，处于初始化状态并不等同于不健康状态。初始化阶段是微服务或任何其他应用服务生命周期中的预期部分。
- en: Thus, Kubernetes should not try to kill our microservice if it is in the initialization
    phase. If our microservice is unhealthy, though, Kubernetes should kill it as
    quickly as possible and replace it with a fresh instance.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Kubernetes 不应尝试在我们的微服务处于初始化阶段时杀死它。如果我们的微服务不健康，Kubernetes 应该尽快将其终止，并替换为一个新的实例。
- en: Kubernetes has a concept of probes to provide the seam between the orchestration
    engine and the application developer. Kubernetes uses these probes to find out
    more about the inner state of the application service at hand. Probes are executed
    locally, inside each container. There is a probe for the health – also called
    liveness – of the service, a startup probe, and a probe for the readiness of the
    service. Let's look at them in turn.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 有一个探针的概念，用来提供编排引擎和应用开发人员之间的连接。Kubernetes 使用这些探针来获取更多关于应用服务内部状态的信息。探针是在每个容器内部本地执行的。这里有一个用于服务健康（也叫存活状态）的探针，一个启动探针，以及一个用于服务就绪性的探针。我们依次来看它们。
- en: Kubernetes liveness probe
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 存活探针
- en: 'Kubernetes uses the liveness probe to decide when a container needs to be killed
    and when another instance should be launched instead. Since Kubernetes operates
    at a pod level, the respective pod is killed if at least one of its containers
    reports as being unhealthy. Alternatively, we can say it the other way around:
    only if all the containers of a pod report to be healthy, is the pod considered
    to be healthy.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 使用存活探针来决定何时需要杀死一个容器，并启动另一个实例来替代它。由于 Kubernetes 在 pod 级别进行操作，如果 pod
    中的至少一个容器报告为不健康，则该 pod 会被终止。换句话说，只有当 pod 中的所有容器都报告为健康时，pod 才被认为是健康的。
- en: 'We can define the liveness probe in the specification for a pod as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 pod 的规范中定义存活探针，示例如下：
- en: '[PRE7]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The relevant part is in the `livenessProbe` section. First, we define a command
    that Kubernetes will execute as a probe inside the container. In our case, we
    have a PostresSQL container and use the `netcat` Linux tool to probe port `5432`
    over TCP. The `nc localhost 5432` command is successful once Postgres listens
    at it.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 相关部分位于`livenessProbe`部分。首先，我们定义Kubernetes将在容器内执行的命令作为探针。在我们的例子中，我们有一个PostgreSQL容器，并使用`netcat`
    Linux工具通过TCP探测端口`5432`。当Postgres监听该端口时，`nc localhost 5432`命令会成功。
- en: The other two settings, `initialDelaySeconds` and `periodSeconds`, define how
    long Kubernetes should wait after starting the container until it first executes
    the probe and how frequently the probe should be executed thereafter. In our case,
    Kubernetes waits for 10 seconds prior to executing the first probe and then executes
    a probe every 5 seconds.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 另外两个设置，`initialDelaySeconds`和`periodSeconds`，定义了Kubernetes在启动容器后需要等待多长时间才会执行第一次探针，以及之后执行探针的频率。在我们的案例中，Kubernetes在执行第一次探针之前等待10秒，然后每5秒执行一次探针。
- en: 'It is also possible to probe an HTTP endpoint instead of using a command. Let''s
    assume we''re running a microservice from an image, `acme.com/my-api:1.0`, with
    an API that has an endpoint called `/api/health` that returns status `200 (OK)`
    if the microservice is healthy, and `50x (Error)` if it is unhealthy. Here, we
    can define the liveness probe as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以探测HTTP端点，而不是使用命令。假设我们正在运行一个微服务，镜像为`acme.com/my-api:1.0`，该API有一个名为`/api/health`的端点，如果微服务健康，它返回状态`200
    (OK)`，如果不健康，则返回`50x (Error)`。在这种情况下，我们可以按如下方式定义活跃性探针：
- en: '[PRE8]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In the preceding snippet, I have defined the liveness probe so that it uses
    the HTTP protocol and executed a `GET` request to the `/api/health` endpoint on
    port `5000` of localhost. Remember, the probe is executed inside the container,
    which means I can use localhost.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我定义了活跃性探针，使用HTTP协议并执行一个`GET`请求，访问本地主机端口`5000`上的`/api/health`端点。记住，探针是在容器内部执行的，这意味着我可以使用localhost。
- en: 'We can also directly use the TCP protocol to probe a port on the container.
    But wait a second – didn''t we just do that in our first sample, where we used
    the generic liveness probe based on an arbitrary command? Yes, you''re right,
    we did. But we had to rely on the presence of the `netcat` tool in the container
    to do so. We cannot assume that this tool is always there. Thus, it is favorable
    to rely on Kubernetes to do the TCP-based probing for us out of the box. The modified
    pod spec looks like this:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以直接使用TCP协议探测容器上的端口。但等一下——难道我们在第一个示例中没有做过这件事吗？是的，你说得对，我们做过。但是我们必须依赖容器中存在`netcat`工具来执行这一操作。我们不能假设这个工具总是存在。因此，依赖Kubernetes默认为我们执行基于TCP的探测是更为可取的。修改后的Pod配置如下：
- en: '[PRE9]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This looks very similar. The only change is that the type of probe has been
    changed from `exec` to `tcpSocket` and that, instead of providing a command, we
    provide the `port` to probe.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来非常相似。唯一的变化是探针的类型从`exec`改为`tcpSocket`，并且我们不再提供命令，而是提供要探测的`port`。
- en: 'Let''s try this out:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试看：
- en: 'Navigate to the `~/fod/ch16/probes` folder and build the Docker image with
    the following command:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到`~/fod/ch16/probes`文件夹，并使用以下命令构建Docker镜像：
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Use `kubectl` to deploy the sample pod that''s defined in `probes-demo.yaml`:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl`部署在`probes-demo.yaml`中定义的示例Pod：
- en: '[PRE11]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Describe the pod and specifically analyze the log part of the output:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述Pod并特别分析输出的日志部分：
- en: '[PRE12]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'During the first half minute or so, you should get the following output:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在前半分钟左右，你应该看到以下输出：
- en: '![](img/fe42b23f-d21f-4e2a-bd16-6f14c31d71b4.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fe42b23f-d21f-4e2a-bd16-6f14c31d71b4.png)'
- en: Log output of the healthy pod
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 健康Pod的日志输出
- en: 'Wait at least 30 seconds and then describe the pod again. This time, you should
    see the following output:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待至少30秒，然后再次描述Pod。这时，你应该看到以下输出：
- en: '![](img/bb3c27de-375c-4cf1-8e23-81762ff9447f.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bb3c27de-375c-4cf1-8e23-81762ff9447f.png)'
- en: Log output of the pod after it has changed its state to `Unhealthy`
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Pod在状态变为`Unhealthy`后的日志输出
- en: The last two lines are indicating the failure of the probe and the fact that
    the pod is going to be restarted.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的两行表示探针失败，并且Pod将被重启。
- en: 'If you get the list of pods, you will see that the pod has been restarted a
    number of times:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看Pod列表，你会看到Pod已经重启了若干次：
- en: '[PRE13]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'When you''re done with the sample, delete the pod with the following command:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成示例后，使用以下命令删除Pod：
- en: '[PRE14]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Next, we will have a look at the Kubernetes readiness probe.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看Kubernetes的就绪探针。
- en: Kubernetes readiness probe
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 就绪探针
- en: Kubernetes uses a readiness probe to decide when a service instance, that is,
    a container, is ready to accept traffic. Now, we all know that Kubernetes deploys
    and runs pods and not containers, so it only makes sense to talk about the readiness
    of a pod. Only if all containers in a pod report to be ready is the pod considered
    to be ready itself. If a pod reports not to be ready, then Kubernetes removes
    it from the service load balancers.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 使用就绪探针来决定服务实例，即容器，何时准备好接收流量。现在我们都知道，Kubernetes 部署并运行的是 Pod，而不是容器，所以讨论
    Pod 的就绪性是更有意义的。只有当 Pod 中的所有容器都报告为就绪时，Pod 才被认为是就绪的。如果 Pod 报告为未就绪，Kubernetes 会将其从服务负载均衡器中移除。
- en: 'Readiness probes are defined exactly the same way as liveness probes: just
    switch the `livenessProbe` key in the pod spec to `readinessProbe`. Here is an
    example using our prior pod spec:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪探针的定义与存活探针完全相同：只需将 Pod 规格中的 `livenessProbe` 键更改为 `readinessProbe`。以下是使用我们之前
    Pod 规格的示例：
- en: '[PRE15]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note that, in this example, we don't really need an initial delay for the liveness
    probe anymore since we now have a readiness probe. Thus, I have replaced the initial
    delay entry for the liveness probe with an entry called `failureThreshold`, which
    is indicating how many times Kubernetes should repeat probing in case of a failure
    until it assumes that the container is unhealthy.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这个示例中，我们实际上不再需要为存活探针设置初始延迟，因为我们现在已经有了就绪探针。因此，我将存活探针的初始延迟项替换为一个叫做 `failureThreshold`
    的项，它表示在容器被认为不健康之前，Kubernetes 应该重复探测多少次失败。
- en: Kubernetes startup probe
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 启动探针
- en: It is often helpful for Kubernetes to know when a service instance has started.
    If we define a startup probe for a container, then Kubernetes does not execute
    the liveness or readiness probes, as long as the container's startup probe does
    not succeed. Once again, Kubernetes looks at pods and starts executing liveness
    and readiness probes on its containers if the startup probes of all the pod's
    containers succeed.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 通常需要知道服务实例何时启动。如果我们为容器定义了启动探针，则只要容器的启动探针没有成功，Kubernetes 就不会执行存活探针或就绪探针。一旦容器的所有启动探针都成功，Kubernetes
    就会开始对 Pod 中的容器执行存活探针和就绪探针。
- en: When would we use a startup probe, given the fact that we already have the liveness
    and readiness probes? There might be situations where we have to account for exceptionally
    long startup and initialization times, such as when containerizing a legacy application.
    We could technically configure the readiness or the liveness probes to account
    for this fact, but that would defeat the purpose of these probes. The latter probes
    are meant to provide quick feedback to Kubernetes on the health and availability
    of the container. If we configure for long initial delays or periods, then this
    would counter the desired outcome.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经有了存活探针和就绪探针，什么时候需要使用启动探针呢？可能会有一些情况，我们需要考虑异常长的启动和初始化时间，例如将遗留应用程序容器化。我们技术上可以配置就绪探针或存活探针来应对这种情况，但那样就违背了这些探针的目的。后者的探针旨在为
    Kubernetes 提供关于容器健康状态和可用性的快速反馈。如果我们配置了较长的初始延迟或时间段，那么这将与预期结果相悖。
- en: 'Unsurprisingly, the startup probe is defined exactly the same way as the readiness
    and liveness probes. Here is an example:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，启动探针的定义与就绪探针和存活探针完全相同。以下是一个示例：
- en: '[PRE16]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Make sure that you define the `failureThreshold * periodSeconds` product so
    that it's big enough to account for the worst startup time.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你定义的 `failureThreshold * periodSeconds` 结果足够大，以考虑最坏的启动时间。
- en: In our example, the max startup time should not exceed 150 seconds.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，最大启动时间不应超过 150 秒。
- en: Zero downtime deployments
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 零停机部署
- en: 'In a mission-critical environment, it is important that the application is
    always up and running. These days, we cannot afford any downtime anymore. Kubernetes
    gives us various means of achieving this. Performing an update on an application
    in the cluster that causes no downtime is called a zero downtime deployment. In
    this section, we will present two ways of achieving this. These are as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在关键任务环境中，确保应用程序始终在线和运行至关重要。现在我们不能再容忍任何停机时间。Kubernetes 提供了多种手段来实现这一目标。在集群中执行一个不会导致停机的应用程序更新被称为零停机部署。在这一部分中，我们将介绍实现这一目标的两种方式，具体如下：
- en: Rolling updates
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滚动更新
- en: Blue-green deployments
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝绿部署
- en: Let's start by discussing rolling updates.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先从滚动更新开始讨论。
- en: Rolling updates
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 滚动更新
- en: In the previous chapter, we learned that the Kubernetes Deployment object distinguishes
    itself from the ReplicaSet object in that it adds rolling updates and rollbacks
    on top of the latter's functionality. Let's use our web component to demonstrate
    this. Evidently, we will have to modify the manifest or description of the deployment
    for the web component.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解到 Kubernetes 的 Deployment 对象与 ReplicaSet 对象的区别在于，它在后者的功能基础上增加了滚动更新和回滚功能。让我们通过
    Web 组件来演示这一点。显然，我们将需要修改 Web 组件的清单或描述。
- en: 'We will use the same deployment definition as in the previous section, with
    one important difference – we will have five replicas of the web component running.
    The following definition can also be found in the `~/fod/ch16/web-deploy-rolling-v1.yaml` file:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与前一部分相同的部署定义，但有一个重要区别——我们将运行五个 Web 组件的副本。以下定义也可以在 `~/fod/ch16/web-deploy-rolling-v1.yaml`
    文件中找到：
- en: '[PRE17]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we can create this deployment as usual and also, at the same time, the
    service that makes our component accessible:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以像往常一样创建该部署，同时创建使我们组件可访问的服务：
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Once we have deployed the pods and the service, we can test our web component
    with the following command:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们部署了 pods 和服务，就可以通过以下命令测试我们的 Web 组件：
- en: '[PRE19]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As we can see, the application is up and running and returns the expected message, `Pets
    Demo Application`.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，应用程序正在运行并返回预期的消息：`Pets Demo Application`。
- en: 'Now. our developers have created a new version, 2.1, of the `web` component.
    The code of the new version of the `web` component can be found in the `~/fod/ch16/web` folder, and
    the only change is located on line `12` of the `server.js` file:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的开发人员已经创建了 Web 组件的 2.1 版本。新版本的 `web` 组件代码可以在 `~/fod/ch16/web` 文件夹中找到，唯一的变化位于
    `server.js` 文件的 `12` 行：
- en: '![](img/70fa34d3-69f4-4f3a-a7ae-593b02df74f6.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](img/70fa34d3-69f4-4f3a-a7ae-593b02df74f6.png)'
- en: Code change for version 2.0 of the web component
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Web 组件版本 2.0 的代码更改
- en: 'The developers have built the new image as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员已按照以下方式构建了新的镜像：
- en: '[PRE20]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Subsequently, they pushed the image to Docker Hub, as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，他们将镜像推送到 Docker Hub，如下所示：
- en: '[PRE21]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we want to update the image that''s used by our pods that are part of
    the web Deployment object. We can do this by using the `set image` command of `kubectl`:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们想要更新 Web Deployment 对象中 pods 使用的镜像。我们可以通过使用 `kubectl` 的 `set image` 命令来实现：
- en: '[PRE22]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If we test the application again, we''ll get a confirmation that the update
    has indeed happened:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再次测试应用程序，我们将得到确认，证明更新确实已经发生：
- en: '[PRE23]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, how do we know that there hasn''t been any downtime during this update? Did
    the update really happen in a rolling fashion? What does rolling update mean at
    all? Let''s investigate. First, we can get a confirmation from Kubernetes that
    the deployment has indeed happened and was successful by using the `rollout status` command:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们如何知道在此次更新过程中没有出现停机时间？更新是否确实以滚动方式进行？滚动更新到底是什么意思？让我们来调查一下。首先，我们可以通过使用 `rollout
    status` 命令，从 Kubernetes 获取确认，证明部署确实已发生并且成功：
- en: '[PRE24]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'If we describe the deployment web with `kubectl describe deploy/web`, we get
    the following list of events at the end of the output:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用 `kubectl describe deploy/web` 描述部署 Web 组件，我们将在输出的末尾看到以下事件列表：
- en: '![](img/5fd7c6ba-dbce-4d6e-8d77-f6296c87dc06.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5fd7c6ba-dbce-4d6e-8d77-f6296c87dc06.png)'
- en: List of events found in the output of the deployment description of the web
    component
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Web 组件部署描述的输出中找到的事件列表
- en: 'The first event tells us that, when we created the deployment, a ReplicaSet
    called `web-769b88f67` with five replicas was created. Then, we executed the update command.
    The second event in the list tells us that this meant creating a new ReplicaSet called `web-55cdf67cd` with,
    initially, one replica only. Thus, at that particular moment, six pods existed
    on the system: the five initial pods and one pod with the new version. But, since
    the desired state of the Deployment object states that we want five replicas only,
    Kubernetes now scales down the old ReplicaSet to four instances, which we can
    see in the third event.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个事件告诉我们，当我们创建部署时，创建了一个名为 `web-769b88f67` 的 ReplicaSet，包含五个副本。然后，我们执行了更新命令。列表中的第二个事件告诉我们，这意味着创建了一个名为
    `web-55cdf67cd` 的新 ReplicaSet，最初只有一个副本。因此，在那个特定时刻，系统中存在六个 pods：五个初始 pods 和一个新的版本的
    pod。但是，由于 Deployment 对象的期望状态要求我们只有五个副本，Kubernetes 现在将旧的 ReplicaSet 缩减为四个副本，我们可以在第三个事件中看到这一点。
- en: Then, again, the new ReplicaSet is scaled up to two instances and, subsequently,
    the old ReplicaSet scaled was down to three instances, and so on, until we had
    five new instances and all the old instances were decommissioned. Although we
    cannot see any precise time (other than 3 minutes) when that happened, the order
    of the events tells us that the whole update happened in a rolling fashion.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，新创建的ReplicaSet再次扩展到两个实例，随后，旧的ReplicaSet缩减到三个实例，以此类推，直到我们拥有五个新实例，所有旧实例都被停用。虽然我们无法看到具体的时间（除了3分钟）发生了什么，但事件的顺序告诉我们，整个更新是以滚动方式进行的。
- en: During a short time period, some of the calls to the web service would have
    had an answer from the old version of the component, and some calls would have
    received an answer from the new version of the component, but, at no time would
    the service have been down.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在短时间内，一些对web服务的调用会得到来自旧版本组件的响应，而另一些调用则会得到新版本组件的响应，但在任何时候，服务都不会宕机。
- en: 'We can also list the ReplicaSet objects in the cluster and will get confirmation
    of what I said in the preceding section:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以列出集群中的ReplicaSet对象，从而确认我在前面部分所说的内容：
- en: '![](img/3a04d23d-d8d2-4f3b-a4d2-4235bac45448.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3a04d23d-d8d2-4f3b-a4d2-4235bac45448.png)'
- en: Listing all the ReplicaSet objects in the cluster
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 列出集群中的所有ReplicaSet对象
- en: Here, we can see that the new ReplicaSet has five instances running and that
    the old one has been scaled down to zero instances. The reason that the old ReplicaSet object
    is still lingering is that Kubernetes provides us with the possibility of rolling
    back the update and, in that case, will reuse that ReplicaSet.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到新的ReplicaSet有五个实例正在运行，而旧的ReplicaSet已缩减到零实例。旧的ReplicaSet对象仍然存在的原因是Kubernetes提供了回滚更新的可能性，在这种情况下，它会重用该ReplicaSet。
- en: 'To roll back the update of the image in case some undetected bug sneaked into
    the new code, we can use the `rollout undo` command:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回滚图像更新，以防新代码中出现了某些未被发现的bug，我们可以使用`rollout undo`命令：
- en: '[PRE25]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'I have also listed the test command using `curl` in the preceding snippet to
    verify that the rollback indeed happened. If we list the ReplicaSets, we will
    see the following output:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我在前面的代码片段中也列出了使用`curl`的测试命令，以验证回滚确实已经发生。如果我们列出ReplicaSets，我们将看到以下输出：
- en: '![](img/7ef8b322-07e3-43e1-81a1-9bd7af4d1a3d.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7ef8b322-07e3-43e1-81a1-9bd7af4d1a3d.png)'
- en: Listing ReplicaSet objects after rollback
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 回滚后列出ReplicaSet对象
- en: This confirms that the old ReplicaSet (`web-769b88f67`) object has been reused
    and that the new one has been scaled down to zero instances.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这确认了旧的ReplicaSet（`web-769b88f67`）对象已被重用，并且新的ReplicaSet已缩减到零实例。
- en: Sometimes, though, we cannot, or do not want to, tolerate the mixed state of
    an old version coexisting with the new version. We want an *all-or-nothing* strategy.
    This is where blue-green deployments come into play, which we will discuss next.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时我们无法或不希望容忍旧版本与新版本共存的混合状态。我们希望采用*全有或全无*的策略。这时蓝绿部署就派上用场了，我们接下来将讨论这一点。
- en: Blue-green deployment
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 蓝绿部署
- en: 'If we want to do a blue-green style deployment for our component web of the
    pets application, then we can do so by using labels creatively. First, let''s
    remind ourselves how blue-green deployments work. Here is a rough step-by-step
    instruction:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望对宠物应用的组件web进行蓝绿部署，那么我们可以通过创造性地使用标签来实现。首先，让我们回顾一下蓝绿部署的工作原理。以下是大致的步骤说明：
- en: 'Deploy the first version of the `web` component as `blue`. We will label the
    pods with a label of `color: blue` to do so.'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '将web组件的第一个版本部署为`blue`。我们将通过为pod打上`color: blue`标签来实现这一点。'
- en: 'Deploy the Kubernetes service for these pods with the `color: blue` label in
    the selector section.'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '为这些具有`color: blue`标签的pod部署Kubernetes服务，在选择器部分进行配置。'
- en: 'Now, we can deploy version 2 of the web component, but, this time, the pods
    have a label of `color: green`.'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '现在，我们可以部署web组件的版本2，不过这次pod的标签为`color: green`。'
- en: We can test the green version of the service to check that it works as expected.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以测试绿色版本的服务，检查其是否按预期工作。
- en: 'Now, we flip traffic from blue to green by updating the Kubernetes service
    for the web component. We modify the selector so that it uses the `color: green` label.'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '现在，我们通过更新web组件的Kubernetes服务，将流量从蓝色切换到绿色。我们修改选择器，使其使用`color: green`标签。'
- en: 'Let''s define a Deployment object for version 1, blue:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为版本1定义一个Deployment对象，蓝色：
- en: '![](img/9f7a8ee5-54bb-4e8d-99f6-63deae81e7bd.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9f7a8ee5-54bb-4e8d-99f6-63deae81e7bd.png)'
- en: Specification of the blue deployment for the web component
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 为web组件指定蓝色部署
- en: 'The preceding definition can be found in the `~/fod/ch16/web-deploy-blue.yaml` file.
    Please take note of line `4`, where we define the name of the deployment as `web-blue` to
    distinguish it from the upcoming deployment, `web-green`. Also, note that we have
    added the label `color: blue` on lines `11` and `17`. Everything else remains
    the same as before.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '前面的定义可以在 `~/fod/ch16/web-deploy-blue.yaml` 文件中找到。请注意第 `4` 行，我们在此定义了部署名称为 `web-blue`，以便与即将到来的部署
    `web-green` 区分开来。还要注意，我们在第 `11` 行和 `17` 行添加了标签 `color: blue`。其他部分保持不变。'
- en: 'Now, we can define the Service object for the web component. It will be the
    same as the one we used before but with a minor change, as shown in the following
    screenshot:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以定义 web 组件的 Service 对象。它将与之前使用的相同，但有一个小的变化，如下截图所示：
- en: '![](img/7a1661a0-137e-402c-a664-a8ad9ea1df56.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7a1661a0-137e-402c-a664-a8ad9ea1df56.png)'
- en: Kubernetes service for the web component supporting blue-green deployments
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 支持蓝绿部署的 Kubernetes 服务
- en: 'The only difference regarding the definition of the service we used earlier
    in this chapter is line `13`, which adds the `color: blue` label to the selector.
    We can find the preceding definition in the `~/fod/ch16/web-svc-blue-green.yaml` file.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '关于我们在本章早些时候使用的服务定义，唯一的区别是第 `13` 行，它向选择器中添加了 `color: blue` 标签。我们可以在 `~/fod/ch16/web-svc-blue-green.yaml`
    文件中找到前面的定义。'
- en: 'Then, we can deploy the blue version of the web component with the following
    command:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用以下命令部署蓝色版本的 web 组件：
- en: '[PRE26]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Once the service is up and running, we can determine its IP address and port
    number and test it:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦服务启动并运行，我们就可以确定其 IP 地址和端口号并进行测试：
- en: '[PRE27]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'As expected, we get the response `Pets Demo Application`. Now, we can deploy
    the green version of the web component. The definition of its Deployment object
    can be found in the `~/fod/ch16/web-deploy-green.yaml` file and looks as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，我们得到了响应 `Pets Demo Application`。现在，我们可以部署绿色版本的 web 组件。其 Deployment 对象的定义可以在
    `~/fod/ch16/web-deploy-green.yaml` 文件中找到，如下所示：
- en: '![](img/b87b509f-c2ac-4dd6-bc19-5b7f55c9143a.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b87b509f-c2ac-4dd6-bc19-5b7f55c9143a.png)'
- en: Specification of the deployment green for the web component
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为 web 组件指定绿色部署
- en: 'The interesting lines are as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的行如下：
- en: 'Line `4`: Named `web-green` to distinguish it from `web-blue` and allow for
    parallel installation'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行 `4`：命名为 `web-green`，以区别于 `web-blue`，并允许并行安装
- en: 'Lines `11` and `17`: Have the color `green`'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行 `11` 和 `17`：具有 `green` 颜色
- en: 'Line `20`: Now using version `2.1` of the image'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行 `20`：现在使用版本 `2.1` 的镜像
- en: 'Now, we''re ready to deploy this green version of the service. It should run
    separately from the blue service:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备部署此绿色版本的服务。它应与蓝色服务分开运行：
- en: '[PRE28]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We can make sure that both deployments coexist like so:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下方式确保两个部署共存：
- en: '![](img/4bd95b70-62d5-4697-a3d4-e67b4383a4ae.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4bd95b70-62d5-4697-a3d4-e67b4383a4ae.png)'
- en: Displaying the list of Deployment objects running in the cluster
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 显示集群中运行的 Deployment 对象列表
- en: 'As expected, we have both blue and green running. We can verify that blue is
    still the active service:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，我们同时运行着蓝色和绿色版本。我们可以验证蓝色仍然是活动服务：
- en: '[PRE29]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now comes the interesting part. We can flip traffic from blue to green by editing
    the existing service for the web component. To do so, execute the following command:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在进入有趣的部分。我们可以通过编辑现有的 web 组件服务来切换流量，从蓝色版本切换到绿色版本。为此，执行以下命令：
- en: '[PRE30]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Change the value of the label color from `blue` to `green`. Then, save and
    quit the editor. The Kubernetes CLI will automatically update the service. When
    we now query the web service again, we get this:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 将标签 color 的值从 `blue` 改为 `green`，然后保存并退出编辑器。Kubernetes CLI 会自动更新服务。当我们再次查询 web
    服务时，我们会得到如下结果：
- en: '[PRE31]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This confirms that the traffic has indeed switched to the green version of the
    web component (note the `v2` at the end of the response to the `curl` command).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这确认了流量确实切换到了绿色版本的 web 组件（请注意响应中的 `curl` 命令末尾的 `v2`）。
- en: If we realize that something went wrong with our green deployment and the new
    version has a defect, we can easily switch back to the blue version by editing
    the service web again and replacing the value of the label color with blue. This
    rollback is instantaneous and should always work. Then, we can remove the buggy
    green deployment and fix the component. When we have corrected the problem, we
    can deploy the green version once again.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们发现绿色部署出现问题，新版本有缺陷，我们可以通过编辑服务web并将标签颜色值替换为蓝色，轻松切换回蓝色版本。这种回滚是即时的并且应始终有效。然后，我们可以移除有问题的绿色部署并修复组件。当我们修复问题后，我们可以再次部署绿色版本。
- en: 'Once the green version of the component is running as expected and performing
    well, we can decommission the blue version:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦绿色版本的组件按预期运行并表现良好，我们可以停用蓝色版本：
- en: '[PRE32]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: When we're ready to deploy a new version, 3.0, this one becomes the blue version.
    We update the `~/fod/ch16/web-deploy-blue.yaml` file accordingly and deploy it.
    Then, we flip the service web from `green` to `blue`, and so on.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们准备部署新版本3.0时，该版本将成为蓝色版本。我们相应地更新`~/fod/ch16/web-deploy-blue.yaml`文件并部署它。然后，我们将服务web从`green`切换到`blue`，依此类推。
- en: We have successfully demonstrated, with our component web of the pets application,
    how blue-green deployment can be achieved in a Kubernetes cluster.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功地展示了如何在Kubernetes集群中的pets应用程序的web组件中实现蓝绿部署。
- en: Kubernetes secrets
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes秘密信息
- en: Sometimes, services that we want to run in the Kubernetes cluster have to use
    confidential data such as passwords, secret API keys, or certificates, to name
    just a few. We want to make sure that this sensitive information can only ever
    be seen by the authorized or dedicated service. All other services running in
    the cluster should not have any access to this data.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们希望在Kubernetes集群中运行的服务必须使用诸如密码、秘密API密钥或证书等保密数据。我们希望确保这些敏感信息只能被授权或专用服务查看。集群中运行的所有其他服务都不应访问这些数据。
- en: For this reason, Kubernetes secrets have been introduced. A secret is a key-value
    pair where the key is the unique name of the secret and the value is the actual
    sensitive data. Secrets are stored in etcd. Kubernetes can be configured so that
    secrets are encrypted at rest, that is, in etcd, and in transit, that is, when
    the secrets are going over the wire from a master node to the worker nodes that
    the pods of the service using this secret are running on.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 出于这个原因，引入了Kubernetes秘密信息。秘密信息是一对键值对，其中键是秘密信息的唯一名称，值是实际的敏感数据。秘密信息存储在etcd中。可以配置Kubernetes，使秘密信息在休息时（即在etcd中）和传输时（即在传输到使用此秘密信息的服务的工作节点的主节点之间时）进行加密。
- en: Manually defining secrets
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手动定义秘密信息
- en: 'We can create a secret declaratively the same way as we can create any other
    object in Kubernetes. Here is the YAML for such a secret:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像在Kubernetes中创建任何其他对象一样，声明性地创建一个秘密信息。以下是这种秘密信息的YAML示例：
- en: '[PRE33]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The preceding definition can be found in the `~/fod/ch16/pets-secret.yaml` file.
    Now, you might be wondering what the values are. Are these the real (unencrypted)
    values? No, they are not. And they are also not really encrypted values, but just base64-encoded
    values. Thus, they are not really secure, since base64-encoded values can be easily
    reverted to clear text values. How did I get these values? That''s easy: follow
    these steps:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 前述定义可以在`~/fod/ch16/pets-secret.yaml`文件中找到。现在，你可能想知道这些值是什么。这些是真实的（未加密）值吗？不，它们不是。它们也不是真正的加密值，而只是Base64编码的值。因此，它们并不是真正安全的，因为Base64编码的值可以很容易地还原为明文值。我是如何获取这些值的？很简单：按照以下步骤操作：
- en: 'Use the `base64` tool as follows to encode the values:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`base64`工具如下编码值：
- en: '![](img/bbd59476-831a-40c9-b69e-96b1cacfe2f1.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bbd59476-831a-40c9-b69e-96b1cacfe2f1.png)'
- en: Creating base64-encoded values for the secret
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 为秘密信息创建Base64编码值
- en: 'Using the preceding values, we can create the secret and describe it:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用上述值，我们可以创建秘密信息并描述它：
- en: '![](img/df5c56b3-47a4-4ad5-9724-dc08beca28e5.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](img/df5c56b3-47a4-4ad5-9724-dc08beca28e5.png)'
- en: Creating and describing the Kubernetes secret
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 创建和描述Kubernetes秘密信息
- en: 'In the description of the secret, the values are hidden and only their length
    is given. So, maybe the secrets are safe now? No, not really. We can easily decode
    this secret using the `kubectl get` command:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在秘密信息的描述中，值被隐藏，只给出它们的长度。所以，现在秘密安全了吗？不，实际上并没有。我们可以轻松地使用`kubectl get`命令解码这个秘密信息。
- en: '![](img/75e781a7-6783-47aa-afe0-d26ff4e7e7b6.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![](img/75e781a7-6783-47aa-afe0-d26ff4e7e7b6.png)'
- en: Kubernetes secret decoded
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes秘密信息解码
- en: As we can see in the preceding screenshot, we have our original secret values
    back.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在前面的截图中所见，我们已恢复了原始的秘密值。
- en: 'Decode the values you got previously:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码之前获得的值：
- en: '[PRE34]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Thus, the consequences are that this method of creating a Kubernetes is not
    to be used in any environment other than development, where we deal with non-sensitive
    data. In all other environments, we need a better way to deal with secrets.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，结果是这种创建 Kubernetes 的方法不能在开发环境之外的任何环境中使用，因为我们处理的是非敏感数据。在所有其他环境中，我们需要一种更好的方式来处理秘密。
- en: Creating secrets with kubectl
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用kubectl创建秘密
- en: 'A much safer way to define secrets is to use `kubectl`. First, we create files containing
    the base64-encoded secret values similar to what we did in the preceding section,
    but, this time, we store the values in temporary files:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 定义秘密的更安全方式是使用`kubectl`。首先，我们创建包含 base64 编码的秘密值的文件，类似于我们在前一节中所做的，但这次我们将值存储在临时文件中：
- en: '[PRE35]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, we can use `kubectl` to create a secret from those files, as follows:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`kubectl`从这些文件创建一个秘密，如下所示：
- en: '[PRE36]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The secret can then be used the same way as the manually created secret.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，秘密可以像手动创建的秘密一样使用。
- en: Why is this method more secure than the other one, you might ask? Well, first
    of all, there is no YAML that defines a secret and is stored in some source code
    version control system, such as GitHub, which many people have access to and so
    can see and decode the secrets. Only the admin that is authorized to know the
    secrets ever sees their values and uses them to directly create the secrets in
    the (production) cluster. The cluster itself is protected by role-based access
    control so that no unauthorized persons have access to it, nor can they possibly
    decode the secrets defined in the cluster.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，为什么这种方法比另一种方法更安全？首先，没有定义秘密的 YAML 文件存储在某些源代码版本控制系统中（如 GitHub），这些系统许多人都有访问权限，因此可以查看并解码秘密。只有被授权知道秘密的管理员才能看到这些值，并用它们直接在（生产）集群中创建秘密。集群本身受角色访问控制保护，因此无授权人员无法访问它，也无法解码集群中定义的秘密。
- en: Now, let's see how we can actually use the secrets that we have defined.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何实际使用我们定义的秘密。
- en: Using secrets in a pod
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Pod 中使用秘密
- en: 'Let''s say we want to create a Deployment object where the web component uses
    our secret, `pets-secret`, that we introduced in the preceding section. We can
    use the following command to create the secret in the cluster:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们要创建一个`Deployment`对象，其中`web`组件使用我们在前一节中介绍的秘密`pets-secret`。我们可以使用以下命令在集群中创建秘密：
- en: '[PRE37]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In the `~/fod/ch16/web-deploy-secret.yaml` file, we can find the definition
    of the `Deployment` object. We had to add the part starting from line `23` to
    the original definition of the `Deployment` object:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在`~/fod/ch16/web-deploy-secret.yaml`文件中，我们可以找到`Deployment`对象的定义。我们不得不将从`23`行开始的部分添加到原始的`Deployment`对象定义中：
- en: '![](img/f52d1a33-412d-4270-8f9c-8bc86346e616.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f52d1a33-412d-4270-8f9c-8bc86346e616.png)'
- en: Deployment object for the web component with a secret
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 带有秘密的`web`组件的`Deployment`对象
- en: On lines `27` through `30`, we define a volume called `secrets` from our secret, `pets-secret`.
    Then, we use this volume in the container, as described on lines `23` through
    `26`. We mount the secrets in the container filesystem at `/etc/secrets` and we
    mount the volume in read-only mode. Thus, the secret values will be available
    to the container as files in the said folder. The names of the files will correspond
    to the key names, and the content of the files will be the values of the corresponding
    keys. The values will be provided in unencrypted form to the application running
    inside the container.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在`27`至`30`行中，我们定义了一个名为`secrets`的卷，来自我们的秘密`pets-secret`。然后，我们如`23`至`26`行所述，在容器中使用该卷。我们将秘密挂载到容器文件系统的`/etc/secrets`目录，并且以只读模式挂载该卷。因此，秘密值将作为文件提供给容器，存放在该文件夹中。这些文件的名称将对应于键名，文件的内容将是相应键的值。这些值将以未加密的形式提供给容器内运行的应用程序。
- en: 'In our case, since we have the `username` and `password` keys in the secret,
    we will find two files, named `username `and `password`, in the `/etc/secrets` folder
    in the container filesystem. The `username` file should contain the value `john.doe` and
    the `password` file should contain the value `sEcret-pasSw0rD`. Here is the confirmation:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，由于我们在秘密中有`username`和`password`键，因此我们将在容器文件系统中的`/etc/secrets`文件夹中找到两个文件，分别命名为`username`和`password`。`username`文件应该包含值`john.doe`，`password`文件应该包含值`sEcret-pasSw0rD`。以下是确认信息：
- en: '![](img/1c911dec-f905-45e6-adff-8df72c62b729.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1c911dec-f905-45e6-adff-8df72c62b729.png)'
- en: Confirming that secrets are available inside the container
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 确认密钥在容器内部可用
- en: On line `1` of the preceding output, we `exec` into the container where the
    web component runs. Then, on lines `2` to `5`, we list the files in the `/etc/secrets` folder,
    and, finally, on lines `6` to `8`, we show the content of the two files, which,
    unsurprisingly, show the secret values in clear text.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面输出的`1`行，我们`exec`进入运行 Web 组件的容器。然后，在`2`到`5`行中，我们列出了`/etc/secrets`文件夹中的文件，最后，在`6`到`8`行中，我们显示了这两个文件的内容，不出所料，显示了明文的密钥值。
- en: Since any application written in any language can read simple files, this mechanism
    of using secrets is very backward compatible. Even an old Cobol application can
    read clear text files from the filesystem.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 由于任何用任意语言编写的应用程序都可以读取简单文件，因此使用密钥的机制非常向后兼容。即使是旧的 Cobol 应用程序也能从文件系统中读取明文文件。
- en: Sometimes, though, applications expect secrets to be available in environment
    variables. Let's look at what Kubernetes offers us in this case.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时应用程序需要密钥在环境变量中可用。让我们看看 Kubernetes 在这种情况下为我们提供了什么。
- en: Secret values in environment variables
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 环境变量中的密钥值
- en: 'Let''s say our web component expects the username in the environment variable, `PETS_USERNAME`,
    and the password in `PETS_PASSWORD`. If this is the case, we can modify our deployment
    YAML so that it looks as follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的 Web 组件需要在环境变量`PETS_USERNAME`中获取用户名，在`PETS_PASSWORD`中获取密码。如果是这样，我们可以修改我们的部署
    YAML，使其如下所示：
- en: '![](img/30bcf71f-93a0-4fd9-855c-808380d22767.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![](img/30bcf71f-93a0-4fd9-855c-808380d22767.png)'
- en: Deployment mapping secret values to environment variables
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 部署映射密钥值到环境变量
- en: On lines `23` through `33`, we define the two environment variables, `PETS_USERNAME` and `PETS_PASSWORD`,
    and map the corresponding key-value pair of `pets-secret` to them.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在`23`到`33`行中，我们定义了两个环境变量，`PETS_USERNAME`和`PETS_PASSWORD`，并将`pets-secret`的相应键值对映射到这些环境变量中。
- en: 'Note that we don''t need a volume anymore; instead, we directly map the individual
    keys of our `pets-secret` into the corresponding environment variables that are
    valid inside the container. The following sequence of commands shows that the
    secret values are indeed available inside the container in the respective environment
    variables:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们不再需要卷；相反，我们直接将`pets-secret`的各个密钥映射到容器内部有效的相应环境变量。以下命令序列显示了密钥值确实可以在容器内部通过相应的环境变量访问：
- en: '![](img/e8372fc5-eb69-49c9-be2d-3fe7570f0b74.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e8372fc5-eb69-49c9-be2d-3fe7570f0b74.png)'
- en: Secret values are mapped to environment variables
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 密钥值映射到环境变量
- en: In this section, we have shown you how to define secrets in a Kubernetes cluster
    and how to use those secrets in containers running as part of the pods of a deployment.
    We have shown two variants of how secrets can be mapped inside a container, the
    first using files and the second using environment variables.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们向您展示了如何在 Kubernetes 集群中定义密钥，并如何在作为部署一部分的容器中使用这些密钥。我们展示了两种密钥映射到容器中的方式，第一种是使用文件，第二种是使用环境变量。
- en: Summary
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小结
- en: In this chapter, we have learned how to deploy an application into a Kubernetes
    cluster and how to set up application-level routing for this application. Furthermore,
    we have learned how to update application services running in a Kubernetes cluster
    without causing any downtime. Finally, we used secrets to provide sensitive information
    to application services running in the cluster.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们学习了如何将应用程序部署到 Kubernetes 集群中，以及如何为该应用程序设置应用级路由。此外，我们还学习了如何在不导致停机的情况下更新
    Kubernetes 集群中运行的应用服务。最后，我们使用密钥为运行在集群中的应用服务提供敏感信息。
- en: In the next chapter, we are going to learn about different techniques that are
    used to monitor an individual service or a whole distributed application running
    on a Kubernetes cluster. We will also learn how we can troubleshoot an application
    service that is running in production without altering the cluster or the cluster
    nodes that the service is running on. Stay tuned.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习用于监控在 Kubernetes 集群上运行的单个服务或整个分布式应用程序的不同技术。我们还将学习如何在不更改集群或服务运行的集群节点的情况下，排除在生产环境中运行的应用服务的问题。敬请期待。
- en: Questions
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'To assess your learning progress, please answer the following questions:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估您的学习进度，请回答以下问题：
- en: You have an application consisting of two services, the first one being a web
    API and the second one being a DB, such as Mongo DB. You want to deploy this application
    into a Kubernetes cluster. In a few short sentences, explain how you would proceed.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你有一个由两个服务组成的应用程序，第一个是 Web API，第二个是数据库，例如 Mongo DB。你想将此应用程序部署到 Kubernetes 集群中。简短地解释一下你会如何进行。
- en: Describe in your own words what components you need in order to establish layer
    7 (or application level) routing for your application.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用你自己的话描述建立应用程序的第七层（或应用层）路由所需的组件。
- en: List the main steps needed to implement a blue-green deployment for a simple
    application service. Avoid going into too much detail.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出实现简单应用服务的蓝绿部署所需的主要步骤。避免过多细节。
- en: Name three or four types of information that you would provide to an application
    service through Kubernetes secrets.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列举通过 Kubernetes secrets 提供给应用服务的三种或四种信息类型。
- en: Name the sources that Kubernetes accepts when creating a secret.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 命名 Kubernetes 创建 secret 时接受的源。
- en: Further reading
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Here are a few links that provide additional information on the topics that
    were discussed in this chapter:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些提供关于本章讨论主题的额外信息的链接：
- en: Performing a rolling update: [https://bit.ly/2o2okEQ](https://bit.ly/2o2okEQ)
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行滚动更新：[https://bit.ly/2o2okEQ](https://bit.ly/2o2okEQ)
- en: Blue-green deployment: [https://bit.ly/2r2IxNJ](https://bit.ly/2r2IxNJ)
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝绿部署：[https://bit.ly/2r2IxNJ](https://bit.ly/2r2IxNJ)
- en: Secrets in Kubernetes: [https://bit.ly/2C6hMZF](https://bit.ly/2C6hMZF)
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 中的 secrets：[https://bit.ly/2C6hMZF](https://bit.ly/2C6hMZF)
