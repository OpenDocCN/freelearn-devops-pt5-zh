- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Introducing Container Orchestration
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍容器编排
- en: In the previous chapter, we showed how container logs can be collected and shipped
    to a central location where the aggregated logs can then be parsed for useful
    information. We also learned how to instrument an application so that it exposes
    metrics and how those metrics can be scraped and shipped again to a central location.
    Finally, the chapter taught us how to convert those collected metrics into graphical
    dashboards that can be used to monitor a containerized application.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们展示了如何收集容器日志并将其发送到集中位置，在那里聚合的日志可以解析出有用信息。我们还学习了如何对应用程序进行监控，使其暴露出指标，并且这些指标可以被抓取并再次发送到集中位置。最后，本章教我们如何将这些收集到的指标转换为图形化的仪表盘，来监控容器化的应用程序。
- en: This chapter introduces the concept of orchestrators. It teaches us why orchestrators
    are needed, and how they work conceptually. This chapter will also provide an
    overview of the most popular orchestrators and list a few of their pros and cons.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了编排器的概念。它教我们为什么需要编排器，以及它们是如何在概念上工作的。本章还将概述一些最流行的编排器，并列出它们的优缺点。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: What are orchestrators and why do we need them?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是编排器，我们为什么需要它们？
- en: The tasks of an orchestrator
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编排器的任务
- en: Overview of popular orchestrators
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流行的编排器概述
- en: 'After finishing this chapter, you will be able to do the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章后，你将能够做以下事情：
- en: Name three to four tasks for which an orchestrator is responsible
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列举三到四个编排器负责的任务
- en: List two to three of the most popular orchestrators
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出两到三个最流行的编排器
- en: Explain to an interested lay person, in your own words, and with appropriate
    analogies, why we need container orchestrators
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用你自己的话向一个感兴趣的外行解释，并通过适当的类比说明为什么我们需要容器编排器
- en: What are orchestrators and why do we need them?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是编排器，我们为什么需要它们？
- en: In [*Chapter 9*](B19199_09.xhtml#_idTextAnchor194), *Learning about Distributed
    Application Architecture*, we learned which patterns and best practices are commonly
    used to successfully build, ship, and run a highly distributed application. Now,
    if our distributed application is containerized, then we’re facing the exact same
    problems or challenges that a non-containerized distributed application faces.
    Some of these challenges are those that were discussed in that chapter, namely
    service discovery, load balancing, scaling, and so on.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第9章*](B19199_09.xhtml#_idTextAnchor194)《学习分布式应用架构》中，我们了解了常用的构建、运输和运行高度分布式应用的模式和最佳实践。现在，如果我们的分布式应用是容器化的，那么我们将面临与非容器化分布式应用相同的问题或挑战。这些挑战中有一些是在那一章中讨论过的，诸如服务发现、负载均衡、扩展等。
- en: Similar to what Docker did with containers—standardizing the packaging and shipping
    of software with the introduction of those containers—we would like to have some
    tool or infrastructure software that handles all or most of the challenges mentioned.
    This software turns out to be what we call container orchestrators or, as we also
    call them, orchestration engines.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于Docker对容器所做的事情——通过引入容器标准化软件的打包和运输——我们希望有某种工具或基础设施软件来处理所有或大多数已经提到的挑战。这款软件就是我们所说的容器编排器，或者我们也称它们为编排引擎。
- en: If what I just said doesn’t make much sense to you yet, then let’s look at it
    from a different angle. Take an artist who plays an instrument. They can play
    wonderful music to an audience all on their own—just the artist and their instrument.
    But now take an orchestra of musicians. Put them all in a room, give them the
    notes of a symphony, ask them to play it, and leave the room. Without any director,
    this group of very talented musicians would not be able to play this piece in
    harmony; it would more or less sound like a cacophony. Only if the orchestra has
    a conductor, who orchestrates the group of musicians, will the resulting music
    of the orchestra be enjoyable to our ears.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我刚才说的内容对你来说还没有太大意义，那么让我们换个角度来看。想象一下一个演奏乐器的艺术家。他们可以单独为观众演奏美妙的音乐——只是艺术家和他们的乐器。但现在，假设有一支由多位音乐家组成的管弦乐队。把他们都放在一个房间里，给他们交代交响乐的乐谱，让他们演奏，并且离开房间。如果没有指挥，这群非常有才华的音乐家将无法和谐地演奏这首曲子；它听起来更像是一种杂音。只有当管弦乐队有一个指挥，来编排这些音乐家，乐队的音乐才能让我们的耳朵享受。
- en: Instead of musicians, we now have containers, and instead of different instruments,
    we have containers that have different requirements for the container hosts to
    run. And instead of the music being played at varying tempos, we have containers
    that communicate with each other in particular ways and have to scale up and scale
    down to account for changing load imposed on our applications. In this regard,
    a container orchestrator has very much the same role as a conductor in an orchestra.
    It makes sure that the containers and other resources in a cluster play together
    in harmony.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们不再是音乐家，而是容器；不再是各种乐器，而是具有不同运行需求的容器主机。与音乐在不同速度下演奏不同，我们的容器也以特定的方式相互通信，并且需要根据对应用程序的负载变化进行扩展或缩减。就此而言，容器调度器的角色与乐团指挥非常相似。它确保集群中的容器和其他资源协调一致地工作。
- en: I hope that you can now see more clearly what a container orchestrator is, and
    why we need one. Assuming that you understand this question, we can now ask ourselves
    how the orchestrator is going to achieve the expected outcome, namely, to make
    sure that all the containers in the cluster play in harmony. Well, the answer
    is that the orchestrator has to execute very specific tasks, similar to how the
    conductor of an orchestra also has a set of tasks that they execute to tame and,
    at the same time, elevate the orchestra.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你现在能更清楚地理解容器调度器是什么，以及为什么我们需要它。假设你已经明白了这个问题，我们现在可以问自己，调度器如何实现预期的结果，即确保集群中的所有容器和谐工作。答案是，调度器必须执行非常具体的任务，类似于乐团指挥也有一套任务，用来驾驭并同时提升乐团的表现。
- en: The tasks of an orchestrator
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调度器的任务
- en: So, what are the tasks that we expect an orchestrator worth its money to execute
    for us? Let’s look at them in detail. The following list shows the most important
    tasks that, at the time of writing, enterprise users typically expect from their
    orchestrator.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们期望一个值得投资的调度器为我们执行哪些任务呢？让我们详细看看。以下列表展示了在撰写时，企业用户通常期望从调度器获得的最重要任务。
- en: Reconciling the desired state
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整期望状态
- en: When using an orchestrator, you tell it, preferably in a declarative way, how
    you want it to run a given application or application service. We learned what
    declarative versus imperative means in [*Chapter 11*](B19199_11.xhtml#_idTextAnchor237),
    *Managing Container with Docker Compose*. Part of this declarative way of describing
    the application service that we want to run includes elements such as which container
    image to use, how many instances of this service to run, which ports to open,
    and more. This declaration of the properties of our application service is what
    we call the desired state.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用调度器时，你会告诉它（最好是以声明性方式）如何运行给定的应用程序或应用服务。我们在[*第11章*](B19199_11.xhtml#_idTextAnchor237)《使用
    Docker Compose 管理容器》中学习了什么是声明性和命令式的区别。描述我们要运行的应用服务的声明性方式包括元素，例如使用哪个容器镜像、运行多少实例、打开哪些端口等。我们称之为应用服务的声明属性，这就是所谓的期望状态。
- en: So, when we now tell the orchestrator to create a new application service based
    on the declaration for the first time, then the orchestrator makes sure to schedule
    as many containers in the cluster as requested. If the container image is not
    yet available on the target nodes of the cluster where the containers are supposed
    to run, then the scheduler makes sure that they’re first downloaded from the image
    registry. Next, the containers are started with all the settings, such as networks
    to attach to or ports to expose. The orchestrator works as hard as it can to exactly
    match, in reality, the cluster to the declaration.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，当我们首次告诉调度器基于声明创建一个新的应用服务时，调度器将确保根据请求在集群中调度足够多的容器。如果容器镜像在目标节点上尚不可用，调度器将确保从镜像仓库下载它们。接下来，容器将按照所有设置（如网络连接或暴露的端口）启动。调度器会尽力使集群的实际情况与声明完全匹配。
- en: Once our service is up and running as requested, that is, it is running in the
    desired state, then the orchestrator continues to monitor it. Every time the orchestrator
    discovers a discrepancy between the actual state of the service and its desired
    state, it again tries its best to reconcile the desired state.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的服务按要求启动并运行，也就是说，它已经在期望状态下运行，那么调度器将继续监控它。每当调度器发现服务的实际状态与期望状态不一致时，它将尽力再次调整，使实际状态与期望状态保持一致。
- en: 'What could such a discrepancy between the actual and desired states of an application
    service be? Well, let’s say one of the replicas of the service, that is, one of
    the containers, crashes due to, say, a bug; then the orchestrator will discover
    that the actual state differs from the desired state in terms of the number of
    replicas: there is one replica missing. The orchestrator will immediately schedule
    a new instance to another cluster node, which replaces the crashed instance. Another
    discrepancy could be that there are too many instances of the application service
    running if the service has been scaled down. In this case, the orchestrator will
    just randomly kill as many instances as needed in order to achieve parity between
    the actual and the desired number of instances. Yet another discrepancy can be
    when the orchestrator discovers that there is an instance of the application service
    running a wrong (maybe old) version of the underlying container image. By now,
    you should get the picture, right?'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，实际状态和期望状态之间可能出现什么样的差异呢？假设服务的一个副本，也就是其中一个容器，由于 bug 等原因崩溃了；那么编排器会发现实际状态与期望状态在副本数量上有所不同：少了一个副本。编排器会立即在另一个集群节点上调度一个新的实例来替代崩溃的实例。另一种差异可能是，如果服务被缩减了规模，应用服务可能会运行过多实例。在这种情况下，编排器会随机杀死需要的实例，以实现实际实例数量和期望数量之间的平衡。还有一种差异是，当编排器发现应用服务的某个实例正在运行一个错误的（可能是旧的）底层容器镜像版本时。到现在为止，你应该能理解了，对吧？
- en: Thus, instead of us actively monitoring our application’s services running in
    the cluster and correcting any deviations from the desired state, we delegate
    this tedious task to the orchestrator. This works very well provided that we use
    a declarative and not an imperative way of describing the desired state of our
    application services.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，取而代之的是我们主动监控集群中运行的应用服务并纠正任何与期望状态的偏差，我们将这一繁琐的任务委托给编排器。这在我们使用声明性方式而非命令式方式描述应用服务的期望状态时效果最好。
- en: Replicated and global services
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复制和全局服务
- en: 'There are two quite different types of services that we might want to run in
    a cluster that is managed by an orchestrator. They are replicated and global services.
    A **replicated service** is a service that is required to run across a specific
    number of instances, say 10\. A **global service**, in turn, is a service that
    is required to have exactly one instance running on every single worker node of
    the cluster. I have used the term worker node here. In a cluster that is managed
    by an orchestrator, we typically have two types of nodes: managers and workers.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在由编排器管理的集群中，我们可能会想要运行两种截然不同类型的服务。它们分别是复制服务和全局服务。**复制服务**是指要求在特定数量的实例上运行的服务，比如
    10 个实例。**全局服务**则是指要求在集群中的每个工作节点上恰好运行一个实例的服务。我在这里使用了“工作节点”这个术语。在由编排器管理的集群中，通常有两种类型的节点：管理节点和工作节点。
- en: A **manager node** is usually exclusively used by the orchestrator to manage
    the cluster and does not run any other workload. Worker nodes, in turn, run the
    actual applications. So, the orchestrator makes sure that, for a global service,
    an instance of it is running on every single worker node, no matter how many there
    are. We do not care about the number of instances but only that on each node,
    a single instance of the service is guaranteed to run.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**管理节点**通常是由编排器专门用于管理集群的，不运行任何其他工作负载。而工作节点则运行实际的应用程序。因此，编排器会确保对于全局服务，无论工作节点有多少，每个节点上都将运行一个实例。我们不关心实例的数量，而只关心每个节点上都必须保证运行一个实例。'
- en: Once again, we can fully rely on the orchestrator to handle this. In a replicated
    service, we will always be guaranteed to find the exact desired number of instances,
    while for a global service, we can be assured that on every worker node, exactly
    one instance of the service will always run. The orchestrator will always work
    as hard as it can to guarantee this desired state. In Kubernetes, a global service
    is also called a **DaemonSet**.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以再次完全依赖编排器来处理这个问题。在一个复制服务中，我们始终可以确保找到精确所需数量的实例，而在全局服务中，我们可以确保每个工作节点上都会运行恰好一个实例。编排器将始终尽最大努力来保证这个期望的状态。在
    Kubernetes 中，全局服务也被称为**DaemonSet**。
- en: Service discovery
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务发现
- en: When we describe an application service in a declarative way, we are never supposed
    to tell the orchestrator on which cluster nodes the different instances of the
    service have to run. We leave it up to the orchestrator to decide which nodes
    best fit this task.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们以声明性方式描述一个应用服务时，我们绝不应该告诉协调器不同实例应运行在哪些集群节点上。我们将让协调器决定哪个节点最适合执行这个任务。
- en: It is, of course, technically possible to instruct the orchestrator to use very
    deterministic placement rules, but this would be an anti-pattern and is not recommended
    at all, other than in very special edge cases.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，从技术上讲，可以指示协调器使用非常确定的放置规则，但这将是一种反模式，除非在非常特殊的边缘情况下，否则根本不推荐使用。
- en: So, if we now assume that the orchestration engine has complete and free will
    as to where to place individual instances of the application service and, furthermore,
    that instances can crash and be rescheduled by the orchestrator on different nodes,
    then we will realize that it is a futile task for us to keep track of where the
    individual instances are running at any given time. Even better, we shouldn’t
    even try to know this since it is not important.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果我们现在假设协调引擎完全自由地决定应用服务的各个实例放置的位置，而且实例可能会崩溃并由协调器重新调度到不同的节点，那么我们就会意识到，试图追踪各个实例在任何给定时刻的运行位置是徒劳的。更好的是，我们根本不应该尝试去了解这一点，因为这并不重要。
- en: OK, you might say, but what about if I have two services, A and B, and Service
    A relies on Service B; shouldn’t any given instance of Service A know where it
    can find an instance of Service B?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，你可能会说，如果我有两个服务，A和B，而服务A依赖于服务B；那么服务A的任何实例不应该知道它可以在哪里找到服务B的实例吗？
- en: Here, I have to say loudly and clearly—no, it shouldn’t. This kind of knowledge
    is not desirable in a highly distributed and scalable application. Rather, we
    should rely on the orchestrator to provide us with the information that we need
    in order to reach the other service instances that we depend on. It is a bit like
    in the old days of telephony, when we could not directly call our friends and
    had to call the phone company’s central office, where some operator would then
    route us to the correct destination. In our case, the orchestrator plays the role
    of the operator, routing a request coming from an instance of Service A to an
    available instance of Service B. This whole process is called service discovery.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我必须大声而清楚地说——不，应该不了。这种知识在高度分布式和可扩展的应用程序中并不理想。相反，我们应该依赖于协调器来提供我们所需的信息，以便访问我们依赖的其他服务实例。这有点像电话时代早期，我们不能直接拨打朋友的电话，而是必须拨打电话公司的总机，由接线员将我们转接到正确的目的地。在我们的案例中，协调器充当了接线员的角色，将来自服务A实例的请求路由到可用的服务B实例。整个过程被称为服务发现。
- en: Routing
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 路由
- en: We have learned so far that in a distributed application, we have many interacting
    services. When Service A interacts with Service B, this occurs through the exchange
    of data packets. These data packets need to somehow be funneled from Service A
    to Service B. This process of funneling the data packets from a source to a destination
    is also called *routing*. As authors or operators of an application, we do expect
    the orchestrator to take over this task of routing. As we will see in later chapters,
    routing can happen on different levels. It is like in real life. Suppose you’re
    working in a big company in one of its office buildings. Now, you have a document
    that needs to be forwarded to another employee in the company. The internal post
    service will pick up the document from your outbox and take it to the post office
    located in the same building. If the target person works in the same building,
    the document can then be directly forwarded to that person. If, on the other hand,
    the person works in another building of the same block, the document will be forwarded
    to the post office in that target building, from which it is then distributed
    to the receiver through the internal post service. Thirdly, if the document is
    targeted at an employee working in another branch of the company located in a
    different city or even a different country, then the document is forwarded to
    an external postal service such as UPS, which will transport it to the target
    location, from where, once again, the internal post service takes over and delivers
    it to the recipient.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解，在一个分布式应用程序中，我们有许多交互的服务。当服务A与服务B进行交互时，是通过数据包的交换来实现的。这些数据包需要以某种方式从服务A传输到服务B。将数据包从源头传输到目的地的过程也称为*路由*。作为应用程序的作者或操作员，我们期望调度器来承担这个路由任务。正如我们在后续章节中看到的，路由可以在不同的层级上进行。这就像现实生活中的情况。假设你在一家公司的一栋办公楼里工作。现在，你有一份文件需要转交给公司里的另一位员工。内部邮政服务会将文件从你的发件箱中取走，并送到同一建筑物内的邮局。如果目标人工作在同一栋楼，那么文件可以直接转交给该人。如果目标人则工作在同一区块的另一栋楼，文件将转交给目标楼的邮局，然后由内部邮政服务将其分发给收件人。第三种情况是，如果文件是送给在不同城市甚至不同国家的公司分支机构的员工，那么文件将被转交给外部邮政服务（如UPS），它将文件运输到目标地点，从那里，再次由内部邮政服务接管并将其送达收件人。
- en: Similar things happen when routing data packets between application services
    that are running in containers. The source and target containers can be located
    on the same cluster node, which corresponds to the situation in which both employees
    work in the same building.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器中运行的应用服务之间路由数据包时，也会发生类似的事情。源容器和目标容器可以位于同一个集群节点上，这相当于两名员工在同一栋建筑物中工作。
- en: The target container may run on a different cluster node, which corresponds
    to the situation in which the two employees work in different buildings on the
    same block. Finally, the third situation is when a data packet comes from outside
    of the cluster and has to be routed to the target container that is running inside
    the cluster.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 目标容器可能运行在不同的集群节点上，这相当于两名员工在同一区块的不同建筑物中工作。最后，第三种情况是，当数据包来自集群外部，必须路由到集群内部运行的目标容器。
- en: All these situations, and more, have to be handled by the orchestrator.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些情况，以及更多的情况，都必须由调度器来处理。
- en: Load balancing
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负载均衡
- en: In a highly available distributed application, all components have to be redundant.
    That means that every application service has to be run in multiple instances
    so that if one instance fails, the service as a whole is still operational.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在高可用的分布式应用中，所有组件都必须是冗余的。这意味着每个应用服务必须以多个实例运行，这样即使一个实例失败，整个服务仍然能够正常运行。
- en: To make sure that all instances of a service are actually doing work and are
    not just sitting around idle, you have to make sure that the requests for service
    are distributed equally to all the instances. This process of distributing the
    workload across service instances is called load balancing. Various algorithms
    exist that dictate how the workload can be distributed.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保所有服务实例都在实际工作，而不是空闲着，你需要确保服务请求被均等地分配到所有实例。将工作负载分配到服务实例的过程称为负载均衡。存在多种算法来决定如何分配工作负载。
- en: Usually, a load balancer works using the so-called round-robin algorithm, which
    makes sure that the workload is distributed equally across the instances using
    a cyclic algorithm. Once again, we expect the orchestrator to take care of the
    load-balancing requests from one service to another or from external sources to
    internal services.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，负载均衡器使用所谓的轮询算法，确保工作负载在实例间均匀分配，采用循环算法进行分配。我们再次期望调度器处理来自一个服务到另一个服务或从外部源到内部服务的负载均衡请求。
- en: Scaling
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展性
- en: When running our containerized, distributed application in a cluster that is
    managed by an orchestrator, we also want an easy way to handle expected or unexpected
    increases in workload. To handle an increased workload, we usually just schedule
    additional instances of a service that is experiencing this increased load. Load
    balancers will then automatically be configured to distribute the workload over
    more available target instances.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在由调度器管理的集群中运行容器化的分布式应用时，我们也希望能够轻松处理预期的或意外的工作负载增加。为了应对增加的工作负载，我们通常只是调度该服务的额外实例来应对增加的负载。负载均衡器随后会自动配置，以便在更多的可用目标实例上分配工作负载。
- en: But in real-life scenarios, the workload varies over time. If we look at a shopping
    site such as Amazon, it might have a high load during peak hours in the evening,
    when everyone is at home and shopping online; it may experience extreme loads
    during special days such as Black Friday; and it may experience very little traffic
    early in the morning. Thus, services need to not just be able to scale up but
    also to scale down when the workload goes down.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 但是在实际场景中，工作负载会随时间变化。如果我们看看像亚马逊这样的购物网站，它可能在晚上的高峰时段负载很高，因为那时每个人都在家在线购物；在像“黑色星期五”这样的特殊日子，负载可能会异常巨大；而在清晨，流量可能非常少。因此，服务不仅需要能够扩展，当工作负载减少时，也需要能够缩减。
- en: We also expect orchestrators to distribute service instances meaningfully when
    scaling up or down. It would not be wise to schedule all instances of the service
    on the same cluster node, since, if that node goes down, the whole service goes
    down. The scheduler of the orchestrator, which is responsible for the placement
    of the containers, needs to also consider not placing all instances in the same
    rack of computers since, if the power supply of the rack fails, again, the whole
    service is affected. Furthermore, service instances of critical services should
    also be distributed across data centers in order to avoid outages. All these decisions,
    and many more, are the responsibility of the orchestrator.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还期望调度器在扩展时能够合理地分配服务实例。当扩展时，将所有服务实例调度到同一个集群节点上并不是明智之举，因为如果该节点宕机，整个服务都会宕机。负责容器部署的调度器需要考虑避免将所有实例都放置在同一个计算机机架上，因为如果机架的电源供应出现故障，整个服务也会受到影响。此外，关键服务的实例应分布在多个数据中心，以避免因故障而导致服务中断。所有这些决策，以及更多的决策，都由调度器负责。
- en: In the cloud, instead of computer racks, the term “availability zones” is often
    used.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在云中，通常使用“可用区”一词，而不是计算机机架。
- en: Self-healing
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自愈
- en: These days, orchestrators are very sophisticated and can do a lot for us to
    maintain a healthy system. Orchestrators monitor all the containers that are running
    in the cluster and they automatically replace crashed or unresponsive ones with
    new instances. Orchestrators monitor the health of cluster nodes and take them
    out of the scheduler loop if a node becomes unhealthy or is down. A workload that
    was located on those nodes is automatically rescheduled to different available
    nodes.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，调度器已经非常复杂，可以为我们维护健康的系统做很多工作。调度器监控集群中所有运行的容器，并且会自动用新的实例替换崩溃或未响应的容器。调度器监控集群节点的健康状况，如果某个节点变得不健康或宕机，它会将该节点从调度循环中移除。原本在这些节点上的工作负载会自动重新调度到其他可用节点上。
- en: All these activities, where the orchestrator monitors the current state and
    automatically repairs the damage or reconciles the desired state, lead to a so-called
    self-healing system.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些活动，调度器监控当前状态并自动修复损坏或调节到期望状态，导致了所谓的自愈系统。
- en: We do not, in most cases, have to actively engage and repair the damage. The
    orchestrator will do this for us automatically. However, there are a few situations
    that the orchestrator cannot handle without our help. Imagine a situation where
    we have a service instance running in a container. The container is up and running
    and, from the outside, looks perfectly healthy, but the application running inside
    it is in an unhealthy state. The application did not crash; it just is not able
    to work as it was originally designed anymore. How could the orchestrator possibly
    know about this without us giving it a hint? It can’t! Being in an unhealthy or
    invalid state means something completely different for each application service.
    In other words, the health status is service-dependent. Only the authors of the
    service, or its operators, know what health means in the context of a service.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，我们不需要主动干预和修复损坏。调度器会自动为我们完成这一任务。然而，有一些情况是调度器在没有我们帮助的情况下无法处理的。设想一个场景，我们有一个服务实例运行在容器中。容器已经启动并运行，从外部看起来完全健康，但内部运行的应用程序处于不健康状态。应用程序没有崩溃；它只是无法按原设计正常工作了。调度器怎么可能知道这一点呢？它根本无法知道！每个应用服务的健康或无效状态意味着完全不同的事情。换句话说，健康状态是依赖于服务的。只有服务的开发者或运维人员才知道在该服务的上下文中，什么才算健康。
- en: 'Now, orchestrators define seams or probes, over which an application service
    can communicate to the orchestrator about what state it is in. Two fundamental
    types of probes exist:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，调度器定义了接缝或探针，应用服务可以通过这些与调度器通信，告知其所处的状态。探针主要有两种基本类型：
- en: The service can tell the orchestrator whether it is healthy or not
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务可以告知调度器它是否健康
- en: The service can tell the orchestrator whether it is ready or temporarily unavailable
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务可以告知调度器它是否准备就绪或暂时不可用
- en: How the service determines either of the preceding answers is totally up to
    the service. The orchestrator only defines how it is going to ask, for example,
    through an HTTP `GET` request, or what type of answers it is expecting, for example,
    `OK` or `NOT OK`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 服务如何确定前述问题的答案完全取决于该服务。调度器只定义了它将如何询问，比如通过 HTTP `GET` 请求，或它期望什么类型的答案，比如 `OK` 或
    `NOT OK`。
- en: If our services implement logic in order to answer the preceding health or availability
    questions, then we have a truly self-healing system since the orchestrator can
    kill unhealthy service instances and replace them with new healthy ones, and it
    can take service instances that are temporarily unavailable out of the load balancer’s
    round robin.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的服务实现了逻辑来回答前述的健康或可用性问题，那么我们就拥有了一个真正的自愈系统，因为调度器可以终止不健康的服务实例，并用新的健康实例替换它们，且可以将暂时不可用的服务实例从负载均衡器的轮询中移除。
- en: Data persistence and storage management
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据持久化和存储管理
- en: Data persistence and storage management are crucial aspects of container orchestration.
    They ensure that data is preserved across container restarts and failures, allowing
    applications to maintain their state and continue functioning as expected.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 数据持久化和存储管理是容器编排中的关键环节。它们确保数据在容器重启和故障后得以保留，使得应用能够维持其状态，并按预期继续运行。
- en: 'In a containerized environment, data storage can be divided into two main categories
    – ephemeral storage and persistent storage:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器化环境中，数据存储可以分为两大类——临时存储和持久存储：
- en: '**Ephemeral storage**: This type of storage is tied to the life cycle of the
    container. When a container is terminated or fails, the data stored in its ephemeral
    storage is lost. Ephemeral storage is useful for temporary data, caching, or other
    non-critical information that can be regenerated.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**临时存储**：这种存储与容器的生命周期相关。当容器终止或失败时，存储在临时存储中的数据将丢失。临时存储适用于临时数据、缓存或其他可以重新生成的非关键性信息。'
- en: '**Persistent storage**: Persistent storage decouples data from the container’s
    life cycle, allowing it to persist even after the container is terminated or fails.
    This type of storage is essential for preserving critical application data, such
    as user-generated content, database files, or configuration data.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持久存储**：持久存储将数据与容器的生命周期解耦，使得数据即使在容器终止或失败后仍能持久存在。这种存储类型对于保存关键应用数据至关重要，比如用户生成的内容、数据库文件或配置数据。'
- en: Container orchestration engines handle data persistence and storage management
    by providing mechanisms for attaching persistent storage to containers. These
    mechanisms usually involve the creation and management of storage volumes, which
    can be mounted to containers as needed.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 容器编排引擎通过提供将持久存储附加到容器的机制来处理数据持久性和存储管理。这些机制通常涉及存储卷的创建和管理，存储卷可以根据需要挂载到容器中。
- en: Most container orchestration engines support various types of storage backends,
    including block storage, file storage, and object storage. They also provide integrations
    with popular storage solutions, such as cloud-based storage services, network-attached
    storage, and distributed storage systems such as Ceph or GlusterFS.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数容器编排引擎支持多种类型的存储后端，包括块存储、文件存储和对象存储。它们还提供与流行存储解决方案的集成，如基于云的存储服务、网络附加存储和分布式存储系统（如Ceph或GlusterFS）。
- en: Additionally, container orchestration engines handle storage provisioning and
    management, automating tasks such as volume creation, resizing, and deletion.
    They also allow users to define storage classes and policies, making it easier
    to manage storage resources across a distributed environment.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，容器编排引擎处理存储的提供和管理，自动化执行如卷创建、调整大小和删除等任务。它们还允许用户定义存储类和策略，使得在分布式环境中管理存储资源变得更加容易。
- en: In summary, data persistence and storage management in container orchestration
    engines ensure that applications maintain their state across container restarts
    and failures. They provide mechanisms for attaching persistent storage to containers
    and automate storage provisioning and management tasks, simplifying the process
    of managing storage resources in a containerized environment.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，容器编排引擎中的数据持久性和存储管理确保应用程序在容器重启和故障期间保持其状态。它们提供将持久存储附加到容器的机制，并自动化存储提供和管理任务，从而简化了在容器化环境中管理存储资源的过程。
- en: Zero downtime deployments
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零停机时间部署
- en: These days, it gets harder and harder to justify downtime for a mission-critical
    application that needs to be updated. Not only does that mean missed opportunities
    but it can also result in a damaged reputation for the company. Customers using
    the application are no longer prepared to accept the inconvenience and will turn
    away quickly.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，对于需要更新的关键任务应用程序，停机时间越来越难以 justify。不仅意味着错失机会，还可能导致公司声誉受损。使用该应用程序的客户已不再愿意接受不便，并会迅速流失。
- en: Furthermore, our release cycles get shorter and shorter. Where, in the past,
    we would have one or two new releases per year, these days, a lot of companies
    update their applications multiple times a week, or even multiple times per day.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们的发布周期越来越短。在过去，我们每年只有一到两个新版本发布，而如今，许多公司每周甚至每天都会更新应用程序多次。
- en: The solution to that problem is to come up with a zero-downtime application
    update strategy. The orchestrator needs to be able to update individual application
    services, batch-wise. This is also referred to as rolling updates. At any given
    time, only one or a few of the total number of instances of a given service are
    taken down and replaced by the new version of the service. Only if the new instances
    are operational, and do not produce any unexpected errors or show any misbehavior,
    will the next batch of instances be updated. This is repeated until all instances
    are replaced with their new version. If, for some reason, the update fails, then
    we expect the orchestrator to automatically roll the updated instances back to
    their previous version.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的方法是提出一个零停机时间的应用更新策略。编排器需要能够批量更新单个应用服务。这也被称为滚动更新。在任何给定时间，只有某个服务的一个或少数几个实例被停用，并由该服务的新版本替换。只有在新实例正常运行，且没有出现任何意外错误或不良表现的情况下，才会更新下一批实例。这个过程会一直重复，直到所有实例都被替换为新版本。如果由于某种原因更新失败，我们期望编排器能自动将更新后的实例回滚到先前的版本。
- en: Other possible zero-downtime deployments are blue-green deployments and canary
    releases. In both cases, the new version of a service is installed in parallel
    with the current, active version. But initially, the new version is only accessible
    internally. Operations can then run smoke tests against the new version, and when
    the new version seems to be running just fine, then, in the case of a blue-green
    deployment, the router is switched from the current blue version to the new green
    version. For some time, the new green version of the service is closely monitored
    and, if everything is fine, the old blue version can be decommissioned. If, on
    the other hand, the new green version does not work as expected, then it is only
    a matter of setting the router back to the old blue version in order to achieve
    a complete rollback.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 其他可能的零停机时间部署方式包括蓝绿部署和金丝雀发布。在这两种情况下，服务的新版本将与当前的活跃版本并行安装。但最初，新版本仅在内部可访问。操作人员可以对新版本进行冒烟测试，当新版本似乎运行良好时，在蓝绿部署的情况下，路由器将从当前的蓝色版本切换到新的绿色版本。在一段时间内，新的绿色版本将受到密切监控，如果一切正常，旧的蓝色版本可以被停用。另一方面，如果新的绿色版本没有按预期工作，那么只需将路由器切换回旧的蓝色版本，就可以实现完全回滚。
- en: In the case of a canary release, the router is configured in such a way that
    it funnels a tiny percentage, say 1%, of the overall traffic through the new version
    of the service while 99% of the traffic is still routed through the old version.
    The behavior of the new version is closely monitored and compared to the behavior
    of the old version. If everything looks good, then the percentage of the traffic
    that is funneled through the new service is slightly increased. This process is
    repeated until 100% of the traffic is routed through the new service. If the new
    service has run for a while and everything looks good, then the old service can
    be decommissioned.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在金丝雀发布的情况下，路由器的配置方式是将1%的总体流量引导到服务的新版本，而99%的流量仍然经过旧版本。新版本的行为会被密切监控，并与旧版本的行为进行比较。如果一切正常，经过新服务的流量百分比会稍微增加。这个过程会重复，直到100%的流量都通过新服务。如果新服务运行了一段时间且一切正常，旧服务可以被停用。
- en: Most orchestrators support at least the rolling update type of zero-downtime
    deployment out of the box. Blue-green deployments and canary releases are often
    quite easy to implement.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数编排器至少支持开箱即用的滚动更新类型的零停机时间部署。蓝绿部署和金丝雀发布通常很容易实现。
- en: Affinity and location awareness
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亲和性和位置感知
- en: Sometimes, certain application services require the availability of dedicated
    hardware on the nodes on which they run. For example, I/O-bound services require
    cluster nodes with an attached high-performance **Solid-State Drive** (**SSD**),
    while some services that are used for machine learning, or similar, require an
    **Accelerated Processing** **Unit** (**APU**).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，某些应用服务需要在其运行的节点上有专用硬件的支持。例如，I/O密集型服务需要附加高性能**固态硬盘**（**SSD**）的集群节点，而一些用于机器学习等服务需要**加速处理单元**（**APU**）。
- en: Orchestrators allow us to define node affinities per application service. The
    orchestrator will then make sure that its scheduler only schedules containers
    on cluster nodes that fulfill the required criteria.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 编排器允许我们为每个应用服务定义节点亲和性。然后，编排器将确保其调度器仅在满足所需条件的集群节点上调度容器。
- en: Defining an affinity on a particular node should be avoided; this will introduce
    a single point of failure and thus compromise high availability. Always define
    a set of multiple cluster nodes as the target for an application service.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 应避免在特定节点上定义亲和性；这样做会引入单点故障，从而影响高可用性。始终将多个集群节点定义为应用服务的目标。
- en: Some orchestration engines also support what is called location awareness or
    geo awareness. What this means is that you can ask the orchestrator to equally
    distribute service instances across a set of different locations. You could, for
    example, define a data center label, with possible west, center, and east values,
    and apply the label to all of the cluster nodes with the value that corresponds
    to the geographical region in which the respective node is located. Then, you
    instruct the orchestrator to use this label for the geo awareness of a certain
    application service. In this case, if you request nine replicas of the service,
    then the orchestrator will make sure that three instances are deployed to the
    nodes in each of the three data centers—west, center, and east.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一些调度引擎还支持所谓的定位感知或地理感知。这意味着你可以要求调度器在一组不同的位置之间均匀分配服务实例。例如，你可以定义一个数据中心标签，可能包括西部、中心和东部值，并将该标签应用于所有集群节点，标签值对应各节点所在的地理区域。然后，你可以指示调度器使用该标签来实现特定应用服务的地理感知。在这种情况下，如果你请求该服务的九个副本，调度器将确保三个副本分别部署到三个数据中心的节点——西部、中心和东部。
- en: Geo awareness can even be defined hierarchically; for example, you can have
    a data center as the top-level discriminator, followed by the availability zone.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 地理感知甚至可以分层定义；例如，你可以将数据中心作为顶级区分符，然后是可用区。
- en: Geo awareness, or location awareness, is used to decrease the probability of
    outages due to power supply failures or data center outages. If the application
    instances are distributed across nodes, availability zones, or even data centers,
    it is extremely unlikely that everything will go down at once. One region will
    always be available.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 地理感知或位置感知用于减少由于电力供应故障或数据中心停机而导致的故障概率。如果应用实例分布在节点、可用区甚至数据中心之间，那么一切都同时宕机的可能性极小。总会有一个区域保持可用。
- en: Security
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安全
- en: These days, security in IT is a very hot topic. Cyber warfare is at an all-time
    high. Most high-profile companies have been victims of hacker attacks, with very
    costly consequences.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，IT安全是一个非常热门的话题。网络战争已经达到前所未有的高峰。大多数高知名度公司都曾成为黑客攻击的受害者，且代价非常高昂。
- en: One of the worst nightmares of every **chief information officer** (**CIO**)
    or **chief technology officer** (**CTO**) is to wake up in the morning and hear
    in the news that their company has become a victim of a hacker attack and that
    sensitive information has been stolen or compromised.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 每个**首席信息官**（**CIO**）或**首席技术官**（**CTO**）最怕的噩梦之一，就是早晨醒来听到新闻报道说他们的公司成为黑客攻击的受害者，敏感信息被盗或被泄露。
- en: To counter most of these security threats, we need to establish a secure software
    supply chain and enforce security defense in depth. Let’s look at some of the
    tasks that you can expect from an enterprise-grade orchestrator.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对大多数安全威胁，我们需要建立一个安全的软件供应链，并加强深度安全防御。让我们来看一下你可以期待企业级调度器的一些任务。
- en: Secure communication and cryptographic node identity
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安全通信和加密节点身份
- en: First and foremost, we want to make sure that our cluster that is managed by
    the orchestrator is secure. Only trusted nodes can join the cluster. Every node
    that joins the cluster gets a cryptographic node identity, and all communication
    between the nodes must be encrypted. For this, nodes can use **Mutual Transport
    Layer Security** (**MTLS**). In order to authenticate nodes of the cluster with
    each other, certificates are used. These certificates are automatically rotated
    periodically, or on request, to protect the system in case a certificate is leaked.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们要确保由调度器管理的集群是安全的。只有受信任的节点才能加入集群。每个加入集群的节点都会获得一个加密节点身份，节点之间的所有通信必须加密。为此，节点可以使用**互信传输层安全**（**MTLS**）。为了相互验证集群节点，使用证书。这些证书会定期自动轮换，或者根据请求轮换，以防止证书泄露时保护系统。
- en: 'The communication that happens in a cluster can be separated into three types.
    You talk about communication planes—management, control, and data planes:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 集群中发生的通信可以分为三种类型。你可以说有三种通信平面——管理平面、控制平面和数据平面：
- en: The management plane is used by the cluster managers, or masters, to, for example,
    schedule service instances, execute health checks, or create and modify any other
    resources in the cluster, such as data volumes, secrets, or networks.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理平面由集群管理器或主节点使用，用于例如调度服务实例、执行健康检查，或创建和修改集群中的任何其他资源，如数据卷、密钥或网络。
- en: The control plane is used to exchange important state information between all
    the nodes in a cluster. This kind of information is, for example, used to update
    the local IP tables on clusters, which are used for routing purposes.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制平面用于在集群中的所有节点之间交换重要的状态信息。例如，这些信息会用来更新集群中的本地IP表，以便进行路由。
- en: The data plane is where the actual application services communicate with each
    other and exchange data.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据平面是实际的应用服务相互通信和交换数据的地方。
- en: Normally, orchestrators mainly care about securing the management and control
    plane. Securing the data plane is left to the user, although the orchestrator
    may facilitate this task.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，编排器主要关注于确保管理和控制平面的安全。数据平面的安全则交由用户负责，尽管编排器可能会协助这一任务。
- en: Secure networks and network policies
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安全网络和网络策略
- en: When running application services, not every service needs to communicate with
    every other service in the cluster. Thus, we want the ability to sandbox services
    from each other and only run services in the same networking sandbox that absolutely
    need to communicate with each other. All other services and all network traffic
    coming from outside of the cluster should have no way to access the sandboxed
    services.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行应用服务时，并非每个服务都需要与集群中的其他所有服务进行通信。因此，我们希望能够将服务进行沙箱化，只在同一网络沙箱中运行那些必须互相通信的服务。所有其他服务以及来自集群外部的所有网络流量都应该无法访问这些沙箱化的服务。
- en: There are at least two ways in which this network-based sandboxing can happen.
    We can either use a **software-defined network** (**SDN**) to group application
    services or we can have one flat network and use network policies to control who
    does and does not have access to a particular service or group of services.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 至少有两种方式可以实现基于网络的沙箱化。我们可以使用**软件定义网络**（**SDN**）将应用服务分组，或者我们可以拥有一个平坦的网络，并使用网络策略来控制谁可以访问特定的服务或服务组。
- en: Role-based access control (RBAC)
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于角色的访问控制（RBAC）
- en: One of the most important tasks (next to security) that an orchestrator must
    fulfill in order to be enterprise-ready is to provide RBAC to the cluster and
    its resources.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 编排器必须履行的最重要任务之一（仅次于安全性）是为集群及其资源提供RBAC，以便其达到企业级的可用性。
- en: RBAC defines how subjects, users, or groups of users of the system, organized
    into teams, and so on, can access and manipulate the system. It makes sure that
    unauthorized personnel cannot do any harm to the system, nor can they see any
    of the available resources in the system that they’re not supposed to know of
    or see.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: RBAC定义了系统中的主体、用户或用户组（按团队等组织方式）如何访问和操作系统资源。它确保未授权的人员无法对系统造成任何损害，也不能看到他们不应该知道或不应访问的系统资源。
- en: A typical enterprise might have user groups such as Development, QA, and Prod,
    and each of those groups can have one or many users associated with it. John Doe,
    the developer, is a member of the Development group and, as such, can access resources
    that are dedicated to the development team, but he cannot access, for example,
    the resources of the Prod team, of which Ann Harbor is a member. She, in turn,
    cannot interfere with the Development team’s resources.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的企业可能有如开发、QA、生产等用户组，并且每个组可能有一个或多个用户。开发人员John Doe是开发组的成员，因此他可以访问专属于开发团队的资源，但他不能访问生产团队的资源，比如Ann
    Harbor的资源。反过来，Ann也无法干预开发团队的资源。
- en: One way of implementing RBAC is through the definition of grants. A grant is
    an association between a subject, a role, and a resource collection. Here, a role
    comprises a set of access permissions to a resource. Such permissions can be to
    create, stop, remove, list, or view containers; to deploy a new application service;
    to list cluster nodes or view the details of a cluster node; and many other things.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 实现RBAC的一种方式是通过定义授权。授权是主体、角色和资源集合之间的关联。这里，角色包含一组对资源的访问权限。这些权限可以是创建、停止、删除、列出或查看容器；部署新的应用服务；列出集群节点或查看集群节点的详细信息；以及其他许多操作。
- en: A resource collection is a group of logically related resources of the cluster,
    such as application services, secrets, data volumes, or containers.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 资源集合是集群中一组逻辑上相关的资源，例如应用服务、机密、数据卷或容器。
- en: Secrets
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机密
- en: In our daily life, we have loads of secrets. Secrets are information that is
    not meant to be publicly known, such as the username and password combination
    that you use to access your online bank account, or the code to your cell phone
    or your locker at the gym.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的日常生活中，我们有很多秘密。秘密是指那些不应公开的资料，比如你用来访问在线银行账户的用户名和密码组合，或者你手机的密码或健身房储物柜的密码。
- en: When writing software, we often need to use secrets, too. For example, we need
    a certificate to authenticate our application service with the external service
    that we want to access, or we need a token to authenticate and authorize our service
    when accessing some other API.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写软件时，我们也经常需要使用秘密。例如，我们需要一个证书来认证我们的应用服务与我们想要访问的外部服务，或者我们需要一个令牌来认证和授权我们的服务在访问某些API时。
- en: In the past, developers, for convenience, just hardcoded those values or put
    them in cleartext in some external configuration files. There, this very sensitive
    information was accessible to a broad audience, which, in reality, should never
    have had the opportunity to see those secrets.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 过去，为了方便，开发者通常会将这些值硬编码在代码中，或者放在一些外部配置文件中以明文形式存储。这样，这些非常敏感的信息就能被广泛的用户访问，而实际上，这些人根本不应该有机会看到这些秘密。
- en: Luckily, these days, orchestrators offer what’s called secrets to deal with
    sensitive information in a highly secure way. Secrets can be created by authorized
    or trusted personnel. The values of these secrets are then encrypted and stored
    in a highly available cluster state database. The secrets, since they are encrypted,
    are now secure at rest. Once a secret is requested by an authorized application
    service, the secret is only forwarded to the cluster nodes that actually run an
    instance of that particular service, and the secret value is never stored on the
    node but mounted into the container in a tmpfs RAM-based volume.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，如今的编排工具提供了所谓的“秘密”功能，以一种高度安全的方式处理敏感信息。秘密可以由授权或信任的人员创建。这些秘密的值会被加密并存储在高可用的集群状态数据库中。由于秘密是加密的，因此它们在静态存储时是安全的。一旦授权的应用服务请求一个秘密，该秘密只会被转发到实际运行该特定服务实例的集群节点，并且秘密值永远不会存储在节点上，而是以tmpfs基于RAM的卷的形式挂载到容器中。
- en: Only inside the respective container is the secret value available in clear
    text. We already mentioned that the secrets are secure at rest. Once they are
    requested by a service, the cluster manager, or master, decrypts the secret and
    sends it over the wire to the target nodes. So, what about the secrets remaining
    secure in transit? Well, we learned earlier that the cluster nodes use MTLS for
    their communication, and so the secret, although transmitted in clear text, is
    still secure since data packets will be encrypted by MTLS. Thus, secrets are secure
    both at rest and in transit. Only services that are authorized to use secrets
    will ever have access to those secret values.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在各自的容器内部，秘密值才以明文形式可用。我们已经提到过，秘密在静态存储时是安全的。一旦服务请求它们，集群管理器（或主节点）会解密秘密并通过网络将其发送到目标节点。那么，秘密在传输过程中如何保持安全呢？好吧，我们之前学习过，集群节点使用MTLS进行通信，因此，虽然秘密以明文传输，但由于数据包会被MTLS加密，秘密依然是安全的。因此，秘密在静态存储和传输过程中都是安全的。只有被授权使用秘密的服务才能访问这些秘密值。
- en: Secrets in Kubernetes
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes中的秘密
- en: Note that, although secrets used in Kubernetes are fairly safe, still, the documentation
    recommends using them in conjunction with an even safer service, namely a secrets
    manager such as AWS Secrets Manager or Hashicorp’s Vault.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，尽管Kubernetes中使用的秘密相对安全，但文档仍然建议将其与更加安全的服务结合使用，即像AWS Secrets Manager或Hashicorp的Vault这样的秘密管理器。
- en: Content trust
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内容信任
- en: For added security, we want to make sure that only trusted images run in our
    production cluster. Some orchestrators allow us to configure a cluster so that
    it can only ever run signed images. Content trust and signing images are all about
    making sure that the authors of the image are the ones that we expect them to
    be, namely, our trusted developers or, even better, our trusted CI server. Furthermore,
    with content trust, we want to guarantee that the image that we get is fresh,
    and is not an old and maybe vulnerable image. And finally, we want to make sure
    that the image cannot be compromised by malicious hackers in transit. The latter
    is often called a **man-in-the-middle** (**MITM**) attack.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增强安全性，我们希望确保只有受信任的镜像在我们的生产集群中运行。一些编排器允许我们配置集群，以便它只能运行签名的镜像。内容信任和镜像签名都关乎确保镜像的作者是我们期望的人，即我们信任的开发者或者更好的情况是我们信任的CI服务器。此外，通过内容信任，我们希望确保我们得到的镜像是新鲜的，并且不是旧的，可能存在漏洞的镜像。最后，我们希望确保在传输过程中镜像不能被恶意黑客篡改。后者通常称为**中间人攻击**（**MITM**攻击）。
- en: By signing images at the source and validating the signature at the target,
    we can guarantee that the images that we want to run are not compromised.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在源头签署镜像并在目标处验证签名，我们可以保证我们想要运行的镜像没有被篡改。
- en: Reverse uptime
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 反向正常运行时间
- en: The last point I want to discuss in the context of security is reverse uptime.
    What do we mean by that? Imagine that you have configured and secured a production
    cluster. On this cluster, you’re running a few mission-critical applications of
    your company. Now, a hacker has managed to find a security hole in one of your
    software stacks and has gained root access to one of your cluster nodes. That
    alone is already bad enough but, even worse, this hacker could now mask their
    presence on this node and pretend to be root on the machine, after all, and then
    use it as a base to attack other nodes in your cluster.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在安全上下文中，我想讨论的最后一点是反向正常运行时间。这是什么意思呢？想象一下，你已经配置并确保了一个生产集群的安全性。在这个集群上，你正在运行公司的几个关键应用程序。现在，一个黑客成功找到了你软件堆栈中的一个安全漏洞，并且已经获取了对一个集群节点的根访问权限。单单这已经够糟糕的了，更糟糕的是，这个黑客现在可以掩盖他们在这个节点上的存在，并假装是机器的根用户，然后利用它作为基础攻击集群中的其他节点。
- en: Root access in Linux or any Unix-type operating system means that you can do
    anything on that system. It is the highest level of access that someone can have.
    In Windows, the equivalent role is that of an administrator.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux或任何Unix类型的操作系统中，根访问权限意味着你可以在该系统上执行任何操作。这是一个人能够拥有的最高级别的访问权限。在Windows中，相当于这个角色的是管理员角色。
- en: But what if we leverage the fact that containers are ephemeral and cluster nodes
    are quickly provisioned, usually in a matter of minutes if fully automated? We
    just kill each cluster node after a certain uptime of, say, one day. The orchestrator
    is instructed to drain the node and then exclude it from the cluster. Once the
    node is out of the cluster, it is torn down and replaced by a freshly provisioned
    node.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果我们利用容器是短暂的，集群节点可以快速配置，通常情况下只需几分钟就能完成？我们只需在每个集群节点运行一定正常运行时间后，例如一天，就杀死它们。编排器被指示排空节点，然后将其从集群中排除。一旦节点离开集群，它将被拆除并由新配置的节点替换。
- en: That way, the hacker has lost their base and the problem has been eliminated.
    This concept is not yet broadly available, though, but to me, it seems to be a
    huge step toward increased security, and, as far as I have discussed it with engineers
    who are working in this area, it is not difficult to implement.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，黑客就失去了他们的基础，问题已被消除。尽管这个概念目前还没有广泛推广，但对我来说，这似乎是提高安全性的一个巨大步骤，并且据我与在这一领域工作的工程师讨论，实施起来并不困难。
- en: Introspection
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内省
- en: So far, we have discussed a lot of tasks for which the orchestrator is responsible
    and that it can execute in a completely autonomous way. However, there is also
    the need for human operators to be able to see and analyze what’s currently running
    on the cluster, and in what state or health the individual applications are. For
    all this, we need the possibility of introspection. The orchestrator needs to
    surface crucial information in a way that is easily consumable and understandable.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了很多编排器的责任和它完全自主执行的任务。然而，还需要人员操作者能够查看和分析集群上当前运行的内容，以及个别应用程序的状态或健康情况。为了做到这一点，我们需要introspection的可能性。编排器需要以易于消化和理解的方式展示关键信息。
- en: The orchestrator should collect system metrics from all the cluster nodes and
    make them accessible to the operators. Metrics include CPU, memory and disk usage,
    network bandwidth consumption, and more. The information should be easily available
    on a node-per-node basis, as well as in an aggregated form.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 协调器应当从所有集群节点收集系统指标，并使操作员可以访问这些数据。指标包括CPU、内存和磁盘使用情况、网络带宽消耗等。这些信息应该易于在每个节点的基础上获取，也可以以聚合的形式提供。
- en: We also want the orchestrator to give us access to logs that are produced by
    service instances or containers. Even more, the orchestrator should provide us
    with `exec` access to every container if we have the correct authorization to
    do so. With exec access to containers, you can then debug misbehaving containers.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还希望协调器能让我们访问由服务实例或容器生成的日志。更进一步，如果我们拥有正确的授权，协调器应该为我们提供`exec`权限，让我们可以访问每个容器。通过exec访问容器后，我们就可以调试表现异常的容器。
- en: In highly distributed applications, where each request to the application goes
    through numerous services until it is completely handled, tracing requests is
    a really important task.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在高度分布式的应用程序中，每个请求都会通过多个服务，直到完全处理完成，追踪请求是一个非常重要的任务。
- en: Ideally, the orchestrator supports us in implementing a tracing strategy or
    gives us some good guidelines to follow.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，协调器应支持我们实施追踪策略，或者为我们提供一些良好的指南。
- en: Finally, human operators can best monitor a system when working with a graphical
    representation of all the collected metrics and logging and tracing information.
    Here, we are speaking about dashboards. Every decent orchestrator should offer
    at least a basic dashboard with a graphical representation of the most critical
    system parameters.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，人类操作员在监控系统时，最好能使用一个图形化展示所有收集的指标、日志和跟踪信息的界面。这里我们指的是仪表盘。每个合格的协调器都应该提供至少一个基本的仪表盘，图形化展示最关键的系统参数。
- en: However, human operators are not the only ones concerned about introspection.
    We also need to be able to connect external systems with the orchestrator in order
    to consume this information. There needs to be an API available, over which external
    systems can access data such as the cluster state, metrics, and logs, and use
    this information to make automated decisions, such as creating pager or phone
    alerts, sending out emails, or triggering an alarm siren if certain thresholds
    are exceeded by the system.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，人类操作员并不是唯一关注自省的人。我们还需要能够将外部系统与协调器连接，以便消耗这些信息。需要有一个可用的API，通过它外部系统可以访问集群状态、指标和日志等数据，并使用这些信息做出自动化决策，比如创建呼叫器或电话警报、发送电子邮件，或者在系统超过某些阈值时触发警报。
- en: Overview of popular orchestrators
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流行编排器概述
- en: At the time of writing, there are many orchestration engines out there and in
    use, but there are a few clear winners. The number one spot is clearly held by
    Kubernetes, which reigns supreme. A distant second is Docker’s own SwarmKit, followed
    by others such as Apache Mesos, AWS **Elastic Container Service** (**ECS**), and
    Microsoft **Azure Container** **Service** (**ACS**).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 截至目前，市面上有许多编排引擎在使用，但也有一些明显的赢家。第一的位置无疑是Kubernetes，它遥遥领先。第二位是Docker的SwarmKit，其后是Apache
    Mesos、AWS的**Elastic Container Service**（**ECS**）和微软的**Azure Container** **Service**（**ACS**）。
- en: Kubernetes
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes
- en: Kubernetes was originally designed by Google and later donated to the **Cloud
    Native Computing Foundation** (**CNCF**). Kubernetes was modeled after Google’s
    proprietary Borg system, which has run containers on a supermassive scale for
    years. Kubernetes was Google’s attempt to go back to the drawing board, completely
    start over, and design a system that incorporates all the lessons that were learned
    with Borg.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes最初由谷歌设计，后来捐赠给了**Cloud Native Computing Foundation**（**CNCF**）。Kubernetes的设计借鉴了谷歌的专有系统Borg，Borg已经在超大规模的环境中运行容器多年。Kubernetes是谷歌尝试重新开始的结果，彻底从头开始设计一个系统，结合了Borg中所有学到的经验教训。
- en: Contrary to Borg, which is proprietary technology, Kubernetes was open sourced
    early on. This was a very wise choice by Google since it attracted a huge number
    of contributors from outside of the company and, over only a couple of years,
    an even more massive ecosystem evolved around Kubernetes. You can rightfully say
    that Kubernetes is the darling of the community in the container orchestration
    space. No other orchestrator has been able to produce so much hype and attract
    so many talented people who are willing to contribute in a meaningful way to the
    success of the project as contributors or early adopters.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Borg（一个专有技术）不同，Kubernetes 从一开始就开源了。谷歌做出这个选择非常明智，因为它吸引了大量来自公司外部的贡献者，并且在短短几年内，围绕
    Kubernetes 形成了一个更为庞大的生态系统。你可以理直气壮地说，Kubernetes 是容器编排领域的宠儿。没有其他编排工具能够产生如此大的热度，并吸引如此多的有才华的人们，他们愿意以贡献者或早期采纳者的身份为项目的成功做出有意义的贡献。
- en: In that regard, Kubernetes in the container orchestration space looks to me
    very much like what Linux has become in the server operating system space. Linux
    has become the de facto standard for server operating systems. All relevant companies,
    such as Microsoft, IBM, Amazon, Red Hat, and even Docker, have embraced Kubernetes.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，Kubernetes 在容器编排领域给我的感觉很像 Linux 在服务器操作系统领域的地位。Linux 已经成为服务器操作系统的事实标准。所有相关的公司，如微软、IBM、亚马逊、Red
    Hat，甚至 Docker，都已经接受了 Kubernetes。
- en: 'And there is one thing that cannot be denied: Kubernetes was designed from
    the very beginning for massive scalability. After all, it was designed with Google
    Borg in mind.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 有一点是不可否认的：Kubernetes 从一开始就是为大规模可扩展性而设计的。毕竟，它的设计是基于 Google Borg 的。
- en: One negative aspect that could be voiced against Kubernetes is that it is still
    complex to set up and manage, at least at the time of writing. There is a significant
    hurdle to overcome for newcomers. The first step is steep, but once you have worked
    with this orchestrator for a while, it all makes sense. The overall design is
    carefully thought through and executed very well.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可能对 Kubernetes 提出的负面意见是，它仍然很复杂，至少在写作时是这样。对于新手来说，存在一个显著的门槛。第一步陡峭，但一旦你与这个编排工具合作了一段时间，所有一切都会变得清晰。整体设计经过深思熟虑，并且执行得非常好。
- en: In release 1.10 of Kubernetes, whose **general availability** (**GA**) was enacted
    in March 2018, most of the initial shortcomings compared to other orchestrators
    such as Docker Swarm have been eliminated. For example, security and confidentiality
    are now not only an afterthought but an integral part of the system.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 1.10 版本中，其**正式发布**（**GA**）是在 2018 年 3 月，解决了与其他编排工具（如 Docker Swarm）相比的大多数初期不足之处。例如，安全性和保密性现在不仅仅是事后考虑，而是系统的核心部分。
- en: New features are implemented at a tremendous speed. New releases happen every
    3 months or so, more precisely, about every 100 days. Most of the new features
    are demand-driven, that is, companies using Kubernetes to orchestrate their mission-critical
    applications can voice their needs. This makes Kubernetes enterprise-ready. It
    would be wrong to assume that this orchestrator is only for start-ups and not
    for risk-averse enterprises. The contrary is the case. On what do I base this
    claim? Well, my claim is justified by the fact that companies such as Microsoft,
    Docker, and Red Hat, whose clients are mostly big enterprises, have fully embraced
    Kubernetes, and provide enterprise-grade support for it if it is used and integrated
    into their enterprise offerings.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 新功能以惊人的速度被实现。新版本大约每三个月发布一次，确切地说，大约每 100 天发布一次。大多数新功能都是由需求驱动的，也就是说，使用 Kubernetes
    编排其关键应用的公司可以提出他们的需求。这使得 Kubernetes 成为企业级可用的工具。如果认为这个编排工具仅适合初创公司，而不适合风险规避的大型企业，那就是错误的。恰恰相反。我的这个观点是基于这样的事实：像微软、Docker
    和 Red Hat 这样的公司，其客户大多是大型企业，已经完全接受了 Kubernetes，并为其提供企业级支持，特别是在其产品中使用并集成 Kubernetes。
- en: Kubernetes supports both Linux and Windows containers.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 支持 Linux 和 Windows 容器。
- en: Docker Swarm
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker Swarm
- en: It is well known that Docker popularized and commoditized software containers.
    Docker did not invent containers, but standardized them and made them broadly
    available, not least by offering the free image registry—Docker Hub. Initially,
    Docker focused mainly on the developer and the development life cycle. However,
    companies that started to use and love containers soon also wanted to use them
    not just during the development or testing of new applications but also to run
    those applications in production.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 众所周知，Docker 推广并使软件容器商品化。Docker 没有发明容器，但标准化了容器并使其广泛可用，尤其是通过提供免费的镜像仓库——Docker
    Hub。最初，Docker 主要关注开发者和开发生命周期。然而，开始使用并喜爱容器的公司，很快也希望不仅在新应用的开发或测试阶段使用它们，还希望在生产环境中运行这些应用。
- en: Initially, Docker had nothing to offer in that space, so other companies jumped
    into that vacuum and offered help to the users. But it didn’t take long, and Docker
    recognized that there was a huge demand for a simple yet powerful orchestrator.
    Docker’s first attempt was a product called Classic Swarm. It was a standalone
    product that enabled users to create a cluster of Docker host machines that could
    be used to run and scale their containerized applications in a highly available
    and self-healing way.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，Docker 在这个领域没有什么可以提供的，因此其他公司填补了这个空白，为用户提供帮助。但不久之后，Docker 认识到，市场上对一个简单而强大的编排工具有着巨大的需求。Docker
    的第一次尝试是推出名为 Classic Swarm 的产品。它是一个独立的产品，使用户能够创建一个 Docker 主机集群，用于以高度可用和自我修复的方式运行和扩展其容器化应用。
- en: The setup of Docker Classic Swarm, though, was hard. A lot of complicated manual
    steps were involved. Customers loved the product but struggled with its complexity.
    So, Docker decided it could do better. It went back to the drawing board and came
    up with SwarmKit.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Docker Classic Swarm 的设置过程非常困难，涉及很多复杂的手动步骤。客户非常喜欢这个产品，但却因其复杂性而感到困惑。因此，Docker
    决定做得更好。它重新开始设计并提出了 SwarmKit。
- en: SwarmKit was introduced at DockerCon 2016 in Seattle and was an integral part
    of the newest version of Docker Engine. Yes, you got that right; SwarmKit was,
    and still is to this day, an integral part of Docker Engine. Thus, if you install
    a Docker host, you automatically have SwarmKit available with it.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: SwarmKit 于 2016 年 DockerCon 在西雅图发布，并成为 Docker Engine 最新版本的一个组成部分。是的，你没听错，SwarmKit
    曾经是并且直到今天依然是 Docker Engine 的核心组成部分。因此，如果你安装了一个 Docker 主机，那么你就自动获得了 SwarmKit。
- en: SwarmKit was designed with simplicity and security in mind. The mantra was,
    and still is, that it has to be almost trivial to set up a swarm and that the
    swarm has to be highly secure out of the box. Docker Swarm operates on the assumption
    of least privilege.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: SwarmKit 的设计考虑了简易性和安全性。它的核心理念是，设置一个 Swarm 应该几乎是微不足道的，而且 Swarm 在默认情况下必须具有高度的安全性。Docker
    Swarm 假设最小权限原则。
- en: Installing a complete, highly available Docker swarm is literally as simple
    as starting with `docker swarm init` on the first node in the cluster, which becomes
    the so-called leader, and then `docker swarm join <join-token>` on all other nodes.
    `<join-token>` is generated by the leader during initialization. The whole process
    takes fewer than 5 minutes on a swarm with up to 10 nodes. If it is automated,
    it takes even less time.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 安装一个完整的、高可用性的 Docker Swarm 实际上非常简单，只需在集群中的第一个节点上运行 `docker swarm init`，该节点将成为所谓的领导节点，然后在其他所有节点上运行
    `docker swarm join <join-token>`。`<join-token>` 是在初始化时由领导节点生成的。在最多 10 个节点的 Swarm
    中，整个过程不到 5 分钟。如果自动化执行，所需时间更短。
- en: As I already mentioned, security was top on the list of must-haves when Docker
    designed and developed SwarmKit. Containers provide security by relying on Linux
    kernel namespaces and cgroups, as well as Linux syscall whitelisting (**seccomp**),
    and the support of Linux capabilities and the **Linux security module** (**LSM**).
    Now, on top of that, SwarmKit adds MTLS and secrets that are encrypted at rest
    and in transit.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前提到的，当 Docker 设计和开发 SwarmKit 时，安全性是最重要的需求之一。容器通过依赖 Linux 内核命名空间和 cgroups，以及
    Linux 系统调用白名单 (**seccomp**) 和支持 Linux 能力以及 **Linux 安全模块** (**LSM**) 来提供安全性。现在，在这些基础上，SwarmKit
    添加了 MTLS 和在静态和传输过程中都加密的密钥。
- en: Furthermore, Swarm defines the so-called **container network model** (**CNM**),
    which allows for SDNs that provide sandboxing for application services that are
    running on the swarm. Docker SwarmKit supports both Linux and Windows containers.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Swarm 定义了所谓的 **容器网络模型** (**CNM**)，该模型支持软件定义网络（SDN），为运行在 Swarm 上的应用服务提供沙箱功能。Docker
    SwarmKit 支持 Linux 和 Windows 容器。
- en: Apache Mesos and Marathon
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apache Mesos 和 Marathon
- en: Apache Mesos is an open source project, and was originally designed to make
    a cluster of servers or nodes look like one single big server from the outside.
    Mesos is software that makes the management of computer clusters simple. Users
    of Mesos do not have to care about individual servers but just assume they have
    a gigantic pool of resources at their disposal, which corresponds with the aggregate
    of all the resources of all the nodes in the cluster.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Mesos是一个开源项目，最初旨在让一群服务器或节点从外部看起来像一个单一的大型服务器。Mesos是一款简化计算机集群管理的软件。Mesos的用户不需要关心单个服务器，而只需假设他们拥有一个巨大的资源池，这些资源池对应着集群中所有节点的资源总和。
- en: Mesos, in IT terms, is already pretty old, at least compared to the other orchestrators.
    It was first publicly presented in 2009, but at that time, of course, it wasn’t
    designed to run containers since Docker didn’t even exist yet. Similar to what
    Docker does with containers, Mesos uses Linux cgroups to isolate resources such
    as CPU, memory, or disk I/O for individual applications or services.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在IT术语中，Mesos已经算是相当老旧了，至少与其他调度器相比是这样。它最早在2009年公开展示，但那时当然并没有设计用于运行容器，因为Docker当时还不存在。类似于Docker对容器的处理，Mesos使用Linux的cgroups来隔离资源，如CPU、内存或磁盘I/O，以供单个应用程序或服务使用。
- en: Mesos is really the underlying infrastructure for other interesting services
    built on top of it. From the perspective of containers specifically, Marathon
    is important. Marathon is a container orchestrator that runs on top of Mesos,
    which is able to scale to thousands of nodes.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos实际上是其他有趣的服务的底层基础设施，许多有意思的服务都是建立在它之上的。从容器的角度来看，Marathon非常重要。Marathon是一个运行在Mesos之上的容器调度器，能够扩展到数千个节点。
- en: Marathon supports multiple container runtimes, such as Docker or its own Mesos
    containers. It supports not only stateless but also stateful application services,
    for example, databases such as PostgreSQL or MongoDB. Similar to Kubernetes and
    Docker SwarmKit, it supports many of the features that were described earlier
    in this chapter, such as high availability, health checks, service discovery,
    load balancing, and location awareness, to name but a few of the most important
    ones.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Marathon支持多种容器运行时，例如Docker或它自有的Mesos容器。它不仅支持无状态的应用服务，还支持有状态的应用服务，例如PostgreSQL或MongoDB等数据库。类似于Kubernetes和Docker
    SwarmKit，它支持本章前面提到的许多特性，如高可用性、健康检查、服务发现、负载均衡和位置感知等，这些只是其中一些最重要的功能。
- en: Although Mesos and, to a certain extent, Marathon are rather mature projects,
    their reach is relatively limited. It seems to be most popular in the area of
    big data, that is, for running data-crunching services such as Spark or Hadoop.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Mesos，以及在某种程度上Marathon，是相当成熟的项目，但它们的应用范围相对有限。它似乎在大数据领域最为流行，也就是用于运行数据处理服务，如Spark或Hadoop。
- en: Amazon ECS
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊ECS
- en: 'If you are looking for a simple orchestrator and have already heavily bought
    into the AWS ecosystem, then Amazon’s ECS might be the right choice for you. It
    is important to point out one very important limitation of ECS: if you buy into
    this container orchestrator, then you lock yourself into AWS. You will not be
    able to easily port an application that is running on ECS to another platform
    or cloud.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在寻找一个简单的调度器，并且已经深度融入AWS生态系统，那么亚马逊的ECS可能是适合你的选择。值得指出的是ECS有一个非常重要的限制：如果你选择了这个容器调度器，那么你就会被锁定在AWS平台中。你将无法轻松地将运行在ECS上的应用程序移植到其他平台或云端。
- en: Amazon promotes its ECS service as a highly scalable, fast container management
    service that makes it easy to run, stop, and manage Docker containers on a cluster.
    Next to running containers, ECS gives direct access to many other AWS services
    from the application services that run inside the containers. This tight and seamless
    integration with many popular AWS services is what makes ECS compelling for users
    who are looking for an easy way to get their containerized applications up and
    running in a robust and highly scalable environment. Amazon also provides its
    own private image registry.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊将其ECS服务推广为一个高度可扩展、快速的容器管理服务，使得在集群中运行、停止和管理Docker容器变得更加容易。除了运行容器外，ECS还提供直接访问许多其他AWS服务，这些服务可以从运行在容器内部的应用程序服务中访问。这种与许多流行AWS服务的紧密无缝集成，使得ECS对于那些寻找简便方法以在一个强大且高度可扩展环境中启动和运行其容器化应用的用户非常有吸引力。亚马逊还提供了其自有的私人镜像注册表。
- en: With AWS ECS, you can use Fargate to have it fully manage the underlying infrastructure,
    allowing you to concentrate exclusively on deploying containerized applications,
    and you do not have to care about how to create and manage a cluster of nodes.
    ECS supports both Linux and Windows containers.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AWS ECS，您可以通过Fargate完全管理底层基础设施，使您能够专注于部署容器化应用程序，且无需关心如何创建和管理节点集群。ECS支持Linux和Windows容器。
- en: In summary, ECS is simple to use, highly scalable, and well integrated with
    other popular AWS services, but it is not as powerful as, say, Kubernetes or Docker
    SwarmKit, and it is only available on Amazon AWS.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，ECS简单易用、可扩展性强，并且与其他流行的AWS服务集成得很好，但它不如Kubernetes或Docker SwarmKit那样强大，而且仅在亚马逊AWS平台上可用。
- en: AWS EKS
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS EKS
- en: Amazon **Elastic Kubernetes Service** (**EKS**) is a managed Kubernetes service
    provided by AWS. It simplifies the deployment, management, and scaling of containerized
    applications using Kubernetes, allowing developers and operations teams to focus
    on building and running applications without the overhead of managing the Kubernetes
    control plane.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊**弹性Kubernetes服务**（**EKS**）是AWS提供的一项托管Kubernetes服务。它简化了使用Kubernetes进行容器化应用程序的部署、管理和扩展，使开发人员和运维团队能够专注于构建和运行应用程序，而无需管理Kubernetes控制平面的负担。
- en: EKS integrates seamlessly with various AWS services, such as Elastic Load Balancing,
    Amazon RDS, and Amazon S3, making it easy to build a fully managed, scalable,
    and secure infrastructure for containerized applications. It also supports the
    Kubernetes ecosystem, allowing users to leverage existing tools, plugins, and
    extensions to manage and monitor their applications.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: EKS与各种AWS服务无缝集成，例如弹性负载均衡、Amazon RDS和Amazon S3，使得构建一个完全托管、可扩展且安全的容器化应用程序基础设施变得轻而易举。它还支持Kubernetes生态系统，允许用户利用现有的工具、插件和扩展来管理和监控他们的应用程序。
- en: With Amazon EKS, the Kubernetes control plane is automatically managed by AWS,
    ensuring high availability, automatic updates, and security patches. Users are
    only responsible for managing their worker nodes, which can be deployed using
    Amazon EC2 instances or AWS Fargate.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 使用亚马逊EKS，Kubernetes控制平面由AWS自动管理，确保高可用性、自动更新和安全补丁。用户只需负责管理其工作节点，这些节点可以通过Amazon
    EC2实例或AWS Fargate进行部署。
- en: Microsoft ACS and AKS
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微软ACS和AKS
- en: 'Similar to what we said about ECS, we can claim the same for Microsoft’s ACS.
    It is a simple container orchestration service that makes sense if you are already
    heavily invested in the Azure ecosystem. I should say the same as I have pointed
    out for Amazon ECS: if you buy into ACS, then you lock yourself into the offerings
    of Microsoft. It will not be easy to move your containerized applications from
    ACS to any other platform or cloud.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前提到的ECS类似，我们可以对微软的ACS作出同样的评价。它是一个简单的容器编排服务，如果你已经深度投资于Azure生态系统，那么它是有意义的。我应该和我提到亚马逊ECS时一样说：如果你选择了ACS，那么你就把自己锁定在微软的产品中。从ACS迁移容器化应用程序到其他平台或云环境将并非易事。
- en: ACS is Microsoft’s container service, which supports multiple orchestrators
    such as Kubernetes, Docker Swarm, and Mesos DC/OS. With Kubernetes becoming more
    and more popular, the focus of Microsoft has clearly shifted to that orchestrator.
    Microsoft has even rebranded its service and called it **Azure Kubernetes Service**
    (**AKS**) in order to put the focus on Kubernetes.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ACS是微软的容器服务，支持多种编排器，如Kubernetes、Docker Swarm和Mesos DC/OS。随着Kubernetes的越来越流行，微软的关注焦点显然已转向该编排器。微软甚至重新品牌化其服务，并将其命名为**Azure
    Kubernetes Service**（**AKS**），以便将焦点集中在Kubernetes上。
- en: 'AKS manages a hosted Kubernetes, Docker Swarm, or DC/OS environment in Azure
    for you so that you can concentrate on the applications that you want to deploy,
    and you don’t have to worry about configuring the infrastructure. Microsoft, in
    its own words, claims the following:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: AKS在Azure中为您管理托管的Kubernetes、Docker Swarm或DC/OS环境，使您能够专注于您希望部署的应用程序，无需担心配置基础设施。微软用自己的话说如下：
- en: “AKS makes it quick and easy to deploy and manage containerized applications
    without container orchestration expertise. It also eliminates the burden of ongoing
    operations and maintenance by provisioning, upgrading, and scaling resources on
    demand, without taking your applications offline.”
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: “AKS使得部署和管理容器化应用程序变得快速且简单，无需容器编排的专业知识。它还通过按需提供、升级和扩展资源，消除了持续运营和维护的负担，而无需让您的应用程序停机。”
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter demonstrated why orchestrators are needed in the first place, and
    how they work conceptually. It pointed out which orchestrators are the most prominent
    ones at the time of writing, and discussed the main commonalities and differences
    between the various orchestrators.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了为何首先需要编排器，以及它们是如何在概念上工作的。它指出了在写作时最突出的编排器，并讨论了不同编排器之间的主要共性和差异。
- en: The next chapter will introduce Docker’s native orchestrator, SwarmKit. It will
    elaborate on all the concepts and objects that SwarmKit uses to deploy and run
    a distributed, resilient, robust, and highly available application in a cluster—on-premises
    or in the cloud.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将介绍Docker的原生编排器SwarmKit。它将详细讲解SwarmKit用来在集群中部署和运行分布式、弹性、稳健和高可用应用的所有概念和对象——无论是在本地还是在云中。
- en: Further reading
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: 'The following links provide some deeper insig[ht into orchestration-](https://kubernetes.Io/)related
    topics:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 以下链接提供了一些关于编排相关主题的深入见解：[https://kubernetes.Io/](https://kubernetes.Io/)
- en: '*Kubernetes—production-grade* *orchestration*: [https://kubernetes.io/](https://kubernetes.io/)'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kubernetes—生产级* *编排*: [https://kubernetes.io/](https://kubernetes.io/)'
- en: '*An overview of Docker Swarm* *mode*: [https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/)'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Docker Swarm* *模式概述*: [https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/)'
- en: '*Mesosphere—container orchestration* *services*: [http://bit.ly/2GMpko3](http://bit.ly/2GMpko3)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Mesosphere—容器编排* *服务*: [http://bit.ly/2GMpko3](http://bit.ly/2GMpko3)'
- en: '*Containers and orchestration* *explained*: [http://bit.ly/2DFoQgx](http://bit.ly/2DFoQgx)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*容器和编排* *解析*: [http://bit.ly/2DFoQgx](http://bit.ly/2DFoQgx)'
- en: Questions
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Answer the following questions to assess your learning progress:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 回答以下问题以评估你的学习进度：
- en: What is a container orchestration engine?
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是容器编排引擎？
- en: Why do we need container orchestration engines?
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们需要容器编排引擎？
- en: What are the main tasks of container orchestration engines?
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器编排引擎的主要任务是什么？
- en: What are some popular container orchestration engines?
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些流行的容器编排引擎有哪些？
- en: How does container orchestration improve application reliability?
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器编排如何提高应用的可靠性？
- en: How do container orchestration engines help with application scaling?
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器编排引擎如何帮助应用扩展？
- en: What are the main differences between Kubernetes and Docker Swarm?
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes和Docker Swarm之间的主要区别是什么？
- en: How do container orchestration engines handle service discovery?
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器编排引擎如何处理服务发现？
- en: Answers
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 答案
- en: 'Here are some possible answers to the questions:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些问题的可能答案：
- en: A container orchestration engine is a system that automates the deployment,
    scaling, management, and networking of containers. It helps developers and operations
    teams manage large numbers of containers, ensuring that they run efficiently and
    reliably across multiple hosts in a distributed environment.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器编排引擎是一个自动化部署、扩展、管理和网络化容器的系统。它帮助开发人员和运维团队管理大量容器，确保它们在分布式环境中跨多个主机高效可靠地运行。
- en: As the number of containers and services in an application grows, it becomes
    difficult to manage them manually. Container orchestration engines automate the
    process of managing containers, enabling efficient resource usage, high availability,
    fault tolerance, and seamless scaling of containerized applications.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随着应用中容器和服务数量的增加，手动管理变得越来越困难。容器编排引擎自动化了容器管理的过程，能够实现高效的资源利用、高可用性、容错能力以及容器化应用的无缝扩展。
- en: 'The main tasks of container orchestration engines include the following:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器编排引擎的主要任务包括以下几个方面：
- en: '**Container deployment**: Deploying containers to the appropriate hosts based
    on resource requirements and constraints'
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器部署**：根据资源需求和约束将容器部署到合适的主机'
- en: '**Scaling**: Automatically increasing or decreasing the number of containers
    based on application demand'
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩展**：根据应用需求自动增加或减少容器的数量'
- en: '**Load balancing**: Distributing network traffic across containers to ensure
    optimal performance'
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载均衡**：将网络流量分配到各个容器，确保最佳性能'
- en: '**Service discovery**: Enabling containers to find and communicate with each
    other'
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务发现**：使容器能够找到并与彼此通信'
- en: '**Health monitoring**: Monitoring container health and automatically replacing
    unhealthy containers'
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**健康监控**：监控容器健康状况并自动替换不健康的容器'
- en: '**Data persistence and storage management**: Managing storage volumes and ensuring
    data persistence across container restarts and failures'
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据持久性和存储管理**：管理存储卷并确保数据在容器重启和故障后保持持久性。'
- en: '**Security and access control**: Managing container security, network policies,
    and access control.'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性和访问控制**：管理容器安全、网络策略和访问控制。'
- en: Some popular container orchestration engines include Kubernetes, Docker Swarm,
    Apache Mesos, Microsoft ACS, Microsoft AKS, and Amazon ECS.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些流行的容器编排引擎包括 Kubernetes、Docker Swarm、Apache Mesos、Microsoft ACS、Microsoft AKS
    和 Amazon ECS。
- en: Container orchestration engines improve application reliability by ensuring
    that containers are deployed on appropriate hosts, monitoring container health,
    and automatically replacing unhealthy or failed containers. They also help maintain
    application availability by distributing network traffic across containers, allowing
    the system to handle failures and spikes in traffic gracefully.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器编排引擎通过确保容器部署在适当的主机上、监控容器健康状况，并自动替换不健康或失败的容器，从而提高应用程序的可靠性。它们还通过在容器之间分配网络流量来帮助保持应用程序的可用性，使系统能够优雅地处理故障和流量高峰。
- en: Container orchestration engines can automatically scale applications by adding
    or removing containers based on demand, resource usage, and predefined rules.
    This ensures that applications can handle varying levels of traffic and workload
    while optimizing resource usage.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器编排引擎可以根据需求、资源使用情况和预定义规则，自动扩展应用程序，添加或移除容器。这确保了应用程序能够处理不同级别的流量和工作负载，同时优化资源使用。
- en: 'Kubernetes and Docker Swarm are both container orchestration engines, but they
    have some key differences:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes 和 Docker Swarm 都是容器编排引擎，但它们有一些关键区别：
- en: Kubernetes is more feature-rich and flexible, offering a wide range of functionality
    and extensibility. Docker Swarm is simpler and easier to set up, focusing on ease
    of use and integration with the Docker ecosystem.
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 功能更丰富且灵活，提供广泛的功能和可扩展性。Docker Swarm 更简单，易于设置，注重易用性并与 Docker 生态系统的集成。
- en: Kubernetes uses a declarative approach, allowing users to describe the desired
    state of the system, while Docker Swarm uses a more imperative approach.
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 使用声明式方法，允许用户描述系统的期望状态，而 Docker Swarm 则使用更具命令式的方法。
- en: Kubernetes has a steeper learning curve compared to Docker Swarm, which has
    a shallower learning curve and is more straightforward for users already familiar
    with Docker.
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比 Docker Swarm，Kubernetes 的学习曲线更陡峭，而 Docker Swarm 的学习曲线较浅，对于已经熟悉 Docker 的用户来说更加简单直接。
- en: Kubernetes has a larger community, extensive documentation, and a broader range
    of third-party integrations compared to Docker Swarm.
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比 Docker Swarm，Kubernetes 拥有更大的社区、更广泛的文档和更多的第三方集成。
- en: Container orchestration engines handle service discovery by providing mechanisms
    for containers to find and communicate with each other. They usually assign unique
    network addresses or hostnames to containers and maintain a registry of these
    addresses. Containers can then use these addresses to communicate with other services
    within the application. Some orchestration engines also provide built-in load
    balancing and DNS-based service discovery to simplify this process.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器编排引擎通过提供容器间发现和通信的机制来处理服务发现。它们通常为容器分配唯一的网络地址或主机名，并维护这些地址的注册表。容器可以使用这些地址与应用程序中的其他服务进行通信。一些编排引擎还提供内置的负载均衡和基于
    DNS 的服务发现，简化这一过程。
