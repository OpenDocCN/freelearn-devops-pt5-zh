<html><head></head><body>
        <section>

            <header>
                <h1 class="header-title">Automating Continuous Deployment Flow with Jenkins</h1>
            </header>

            <article>
                
<div class="packt_quote CDPAlignCenter CDPAlign">     The most powerful tool we have as developers is automation.<br/>
                                                                        -Scott Hanselman</div>
<p>We already have all the commands required for a fully automated Continuous Deployment flow. Now we need a tool that will monitor changes in our code repository and trigger those commands every time a commit is detected.</p>
<p>There is a plethora of CI/CD tools on the market. We'll choose Jenkins. That does not mean that it is the only choice nor that it is the best one for all use cases. I won't compare different tools nor provide more details behind the decision to use Jenkins. That would require a chapter on its own or even a whole book. Instead, we'll start by discussing Jenkins architecture.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Jenkins architecture</h1>
            </header>

            <article>
                
<p>Jenkins is a monolithic application based on a combination of a master and agents.</p>
<p>Jenkins master can be described as an orchestrator. It monitors sources, triggers jobs when predefined conditions are met, stores logs and artifacts, and performs a myriad of other tasks related to CI/CD orchestration. It does not run actual tasks but makes sure that they are executed.</p>
<p>Jenkins agent, on the other hand, does the actual work. When master triggers a job execution, the actual work is performed by an agent.<br/>
We cannot scale Jenkins master. At least not in the same way as we scaled the <kbd>go-demo</kbd> service. We can create multiple Jenkins masters, but they cannot share the same file systems. Since Jenkins uses files to store its state, creating multiple instances would result in completely separate applications. Since the main reasons behind scaling are fault tolerance and performance benefits, none of those goals would be accomplished by scaling Jenkins master.</p>
<p>If Jenkins cannot be scaled, how do we meet performance requirements? We increase the capacity by adding agents. A single master can handle many agents. In most cases, an agent is a whole server (physical or virtual). It is not uncommon for a single master to have tens or even hundreds of agents (servers). In turn, each of those agents runs multiple executors that run tasks.</p>
<p>Traditionally, Jenkins master and agents would run on a dedicated server. That, in itself, poses a few problems. If Jenkins is running on a dedicated server, what happens when it fails? Remember, everything fails sooner or later.</p>
<p>For many organizations, Jenkins is mission critical. If it's not operational, new releases are not made, scheduled tasks are not run, software is not deployed, and so on. Typically, Jenkins failure would be fixed by moving the software together with the files that form its state to a healthy server. If that is done manually, and it usually is, the downtime can be substantial.</p>
<p>Throughout this chapter, we'll leverage the knowledge we obtained by now and try to make Jenkins fault tolerant. We might not be able to accomplish zero-downtime but, at least, we'll do our best to reduce it as much as possible. We'll also explore ways to apply what we learned to create a master and Jenkins agents in (almost) fully automated way. We'll try to make the master fault tolerant and agents scalable and dynamic.</p>
<p>Enough talk! Let's move towards more practical parts of the chapter.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Production environment setup</h1>
            </header>

            <article>
                
<p>We'll start by recreating the production cluster we used in the previous chapters.</p>
<p>All the commands from this chapter are available in the <kbd>06-jenkins.sh</kbd> (<a href="https://gist.github.com/vfarcic/9f9995f90c6b8ce136376e38afb14588">https://gist.github.com/vfarcic/9f9995f90c6b8ce136376e38afb14588</a>) Gist:</p>
<pre>
<strong>cd cloud-provisioning<br/><br/>git pull<br/><br/>scripts/dm-swarm.sh</strong>
</pre>
<p>We entered the <kbd>cloud-provisioning</kbd> repository we cloned earlier and pulled the latest code. Then we executed the <kbd>scripts/dm-swarm.sh</kbd> (<a href="https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/dm-swarm.sh">https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/dm-swarm.sh</a>) script that created the production cluster. It is the same script we used in the previous chapter.</p>
<p>Let's confirm that the cluster was indeed created correctly:</p>
<pre>
<strong>eval $(docker-machine env swarm-1)<br/><br/>docker node ls</strong>
</pre>
<p>The output of the <kbd>node ls</kbd> command is as follows (IDs are removed for brevity):</p>
<pre>
<strong>HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS<br/>swarm-2   Ready   Active        Reachable<br/>swarm-1   Ready   Active        Leader<br/>swarm-3   Ready   Active        Reachable</strong>
</pre>
<p>Now that the production cluster is up and running, we can create the Jenkins service.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Jenkins service</h1>
            </header>

            <article>
                
<p>Traditionally, we would run Jenkins in its own server. Even if we'd choose to share server's resources with other applications, the Deployment would still be static. We'd run a Jenkins instance (with or without Docker) and hope that it never fails. The problem with this approach is in the fact that every application fails sooner or later. Either the process will stop, or the whole node will die. Either way, Jenkins, like any other application, will stop working at some moment.</p>
<p>The problem is that Jenkins has become a critical application in many organizations. If we move the execution or, to be more precise, triggering of all automation into Jenkins, we create a strong dependency. If Jenkins is not running, our code is not built, it is not tested, and it is not deployed. Sure, when it fails, you can bring it up again. If the server on which it is running stops working, you can deploy it somewhere else. The downtime, assuming it happens during working hours, will not be long. An hour, maybe two, or even more time will pass since the moment it stops working, someone finds out, notifies someone else, that someone restarts the application or provisions a new server. Is that a long time? It depends on the size of your organization. The more people depend on something, the bigger the cost when that something doesn't work. Even if such a downtime and the cost it produces is not critical, we already have all the knowledge and the tools to avoid it. All we have to do is create another service and let Swarm take care of the rest.</p>
<div class="packt_tip"><strong>A note to Windows users</strong><br/>
Git Bash has a habit of altering file system paths. To stop this, execute the following before running the code block:<br/>
<kbd>export MSYS_NO_PATHCONV=1</kbd></div>
<p>Let's create a Jenkins service. Run the following commands from within the <kbd>cloud-provisioning</kbd> directory:</p>
<pre>
<strong>mkdir -p docker/jenkins<br/><br/>docker service create --name jenkins \<br/>    -p 8082:8080 \<br/>    -p 50000:50000 \ <br/>    -e JENKINS_OPTS="--prefix=/jenkins" \<br/>    --mount "type=bind,source=$PWD/docker/jenkins,target=/var/ \<br/>    jenkins_home"--reserve-memory 300m \<br/>    jenkins:2.7.4-alpine<br/><br/>docker service ps jenkins</strong>
</pre>
<div class="packt_tip"><strong>A note to Linux (example: Ubuntu) users</strong><br/>
Docker Machine mounts users directory from the host inside the VMs it creates. That allows us to share the files. However, that feature does not work in Docker Machine running on Linux. The easiest workaround is, for now, to remove the <kbd>--mount</kbd> argument. Later on, when we reach persistent storage, you'll see how to mount volumes more effectively.<br/>
The good news is that the problem will be fixed soon. Please see the <em>issue #1376</em> (<a href="https://github.com/docker/machine/issues/1376">https://g</a><a href="https://github.com/docker/machine/issues/1376">ithub.com/docker/machine/issues/1376</a>) for the discussion. Once the <em>pull request #2122</em> (<a href="https://github.com/docker/machine/pull/2122">https://github.com/docker/machine/pull/2122</a>) is merged, you will be able to use automatic mounting on Linux.</div>
<p>Jenkins stores its state in the file system. Therefore, we started by creating a directory <kbd>mkdir</kbd> on the host. It will be used as Jenkins home. Since we are inside one of the subdirectories of our host's user, the <kbd>docker/jenkins</kbd> directory is mounted on all the machines we created.</p>
<p>Next, we created the service. It exposes the internal port <kbd>8080</kbd> as <kbd>8082</kbd> as well as the port <kbd>50000</kbd>. The first one is used to access Jenkins UI and the second for master/agent communication. We also defined the URL prefix <kbd>as/jenkins</kbd> and mounted the <kbd>jenkins</kbd> home directory. Finally, we reserved <kbd>300m</kbd> of memory.</p>
<p>Once the image is downloaded, the output of the <kbd>service ps</kbd> command is as follows (IDs are removed for brevity):</p>
<pre>
<strong>NAME      IMAGE                NODE    DESIRED STATE CURRENT STATE          <br/>jenkins.1 jenkins:2.7.4-alpine swarm-1 Running       Running 52 seconds ago</strong>
</pre>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="193" src="assets/cd-environment-jenkins-only.png" width="210"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 6-1: Production cluster with the Jenkins service</div>
<p>Jenkins 2 changed the setup process. While the previous versions allowed us to run it without any mandatory configuration, the new Jenkins forces us to go through some steps manually. Unfortunately, at the time of this writing, there is no good API to help us automate the process. While there are some <em>tricks</em> we could use, the benefits are not high enough when compared with the additional complexity they introduce. After all, we'll setup Jenkins only once, so there is no big incentive to automate the process (at least until a configuration API is created).</p>
<p>Let's open the UI:</p>
<pre>
<strong>open "http://$(docker-machine ip swarm-1):8082/jenkins"</strong>
</pre>
<div class="packt_tip"><strong>A note to Windows users</strong><br/>
Git Bash might not be able to use the open command. If that's the case, execute <kbd>docker-machine ip &lt;SERVER_NAME&gt;</kbd> to find out the IP of the machine and open the URL directly in your browser of choice. For example, the command above should be replaced with the command that follows:<br/>
 <kbd>docker-machine ip swarm-1</kbd><br/>
If the output would be <kbd>1.2.3.4</kbd>, you should open <kbd>http://1.2.3.4:8082/jenkins</kbd> in your browser.</div>
<p>The first thing you will notice is that you are required to introduce the <span class="packt_screen">Administrator password</span>. Quite a few enterprise users requested security hardening. As a result, Jenkins cannot be accessed, anymore, without initializing a session. If you are new to Jenkins, or, at least, <em>version 2</em>, you might wonder what the password is. It is output to logs (in our case <kbd>stdout</kbd>) as well as to the file <kbd>secrets/initialAdminPassword</kbd>, which will be removed at the end of the setup process.</p>
<p>Let's see the content of the <kbd>secrets/initialAdminPassword</kbd> file:</p>
<pre>
<strong>cat docker/jenkins/secrets/initialAdminPassword</strong>
</pre>
<p>The output will be a <kbd>long</kbd> string that represents the temporary password. Please copy it, go back to the UI, paste it to the <span class="packt_screen">Administrator password</span> field, and click the <span class="packt_screen">Continue</span> button:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="274" src="assets/jenkins-setup-password.png" width="269"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 6-2: Unlock Jenkins screen</div>
<p>Once you unlock Jenkins, you will be presented with a choice to Install suggested plugins or select those that fit your needs. The recommended plugins fit most commonly used scenarios so we'll go with that option.</p>
<p>Please click the <span class="packt_screen">Install suggested plugins</span> button.</p>
<p>Once the plugins are downloaded and installed, we are presented with a screen that allows us to Create the first admin user. Please use <kbd>admin</kbd> as both the <span class="packt_screen">Username</span> and the <span class="packt_screen">Password</span>. Fill free to fill the rest of the fields with any value. Once you're done, click the <kbd>Save and Finish</kbd> button:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="172" src="assets/jenkins-setup-admin-user.png" width="238"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 6-3: Create First Admin User screen</div>
<p>Jenkins is ready. All that's left, for now, is to click the <kbd>Start using Jenkins</kbd> button.</p>
<p>Now we can test whether Jenkins failover works.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Jenkins failover</h1>
            </header>

            <article>
                
<p>Let's stop the service and observe Swarm in action. To do that, we need to find out the node it is running in, point our Docker client to it, and remove the container:</p>
<pre>
<strong>NODE=$(docker service ps \<br/>    -f desired-state=running jenkins \<br/>    | tail -n +2 | awk '{print $4}')<br/><br/>eval $(docker-machine env $NODE)<br/><br/>docker rm -f $(docker ps -qa \<br/>    -f label=com.docker.swarm.service.name=jenkins)</strong>
</pre>
<p>We listed Jenkins processes and applied the filter that will return only the one with the desired state running <kbd>docker service ps -f desired-state=running jenkins</kbd>. The output was piped to the tail command that removed the header <kbd>tail -n +2</kbd> and, later on, piped again to the <kbd>awk</kbd> command that limited the output to the fourth column <kbd>awk '{print $4}'</kbd> that contains the node the process is running in. The final result was stored in the <kbd>NODE</kbd> variable.</p>
<p>Later on, we used the eval command to create environment variables that will be used by our Docker client to operate the remote engine. Finally, we retrieved the image ID and removed the container with the combination of the <kbd>ps</kbd> and <kbd>rm</kbd> commands.</p>
<p>As we already learned in the previous chapters, if a container fails, Swarm will run it again somewhere inside the cluster. When we created the service, we told Swarm that the desired state is to have one instance running and Swarm is doing its best to make sure our expectations are fulfilled.</p>
<p>Let us confirm that the service is, indeed, running:</p>
<pre>
<strong>docker service ps jenkins</strong>
</pre>
<div class="CDPAlignLeft CDPAlign">
<p>If Swarm decided to re-run Jenkins on a different node, it might take a few moments until the image is pulled. After a while, the output of the <kbd>service ps</kbd> command should be as follows:</p>
</div>
<div class="CDPAlignCenter CDPAlign"><img height="60" src="assets/error.png" width="999"/></div>
<p>We can do a final confirmation by reopening the the UI:</p>
<pre>
<strong>open "http://$(docker-machine ip swarm-1):8082/jenkins"</strong>
</pre>
<div class="packt_tip"><strong>A note to Windows users</strong><br/>
Git Bash might not be able to use the open command. If that's the case, execute <kbd>docker-machine ip &lt;SERVER_NAME&gt;</kbd> to find out the IP of the machine and open the URL directly in your browser of choice. For example, the command above should be replaced with the command that follows:<br/>
<kbd>docker-machine ip swarm-1</kbd><br/>
If the output would be <kbd>1.2.3.4</kbd>, you should open <kbd>http://1.2.3.4:8082/jenkins</kbd> in your browser.</div>
<p>Since Jenkins does not allow unauthenticated users, you'll have to login. Please use <kbd>admin</kbd> as both the User and the Password.</p>
<p>You'll notice that, this time, we did not have to repeat the setup process. Even though a fresh new Jenkins image is run on a different node, the state is still preserved thanks to the host directory we mounted.</p>
<p>We managed to make Jenkins fault tolerant, but we did not manage to make it run without any downtime. Due to its architecture, Jenkins master cannot be scaled. As a result, when we simulated a failure by removing the container, there was no second instance to absorb the traffic. Even though Swarm re-scheduled it on a different node, there was some downtime. During a short period, the service was not accessible. While that is not a perfect situation, we managed to reduce downtime to a minimum. We made it fault tolerant, but could not make it run without downtime. Considering its architecture, we did the best we could.</p>
<p>Now is the time to hook up Jenkins agents that will run our Continuous Deployment flow.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Jenkins agent</h1>
            </header>

            <article>
                
<p>There are quite a few ways to run Jenkins agents. The problem with most of them is that they force us to add agents separately through Jenkins UI. Instead of adding agents one by one, we'll try to leverage Docker Swarms ability to scale services.</p>
<p>One way we can accomplish the quest for making scalable agents is the Jenkins Swarm Plugin (<a href="https://wiki.jenkins-ci.org/display/JENKINS/Swarm+Plugin">https://wiki.jenkins-ci.org/display/JENKINS/Swarm+Plugin</a>). Before you start making wrong conclusions, I must state that this plugin has nothing to do with Docker Swarm. The only thing they share is the word Swarm.</p>
<p>The Jenkins Swarm Plugin (<a href="https://wiki.jenkins-ci.org/display/JENKINS/Swarm+Plugin">https://wiki.jenkins-ci.org/display/JENKINS/Swarm+Plugin</a>) allows us to auto-discover nearby masters and join them automatically. We'll use it only for the second feature. We'll create a Docker Swarm service that will act as a Jenkins agent and join the master automatically.</p>
<p>First things first. We need to install the plugin.</p>
<p>Please open the Plugin Manager screen as shown in the following code:</p>
<pre>
<strong>open "http://$(docker-machine ip swarm-1):8082/jenkins/pluginManager/available"</strong>
</pre>
<div class="packt_tip"><strong>A note to Windows users</strong><br/>
Git Bash might not be able to use the open command. If that's the case, execute <kbd>docker-machine ip &lt;SERVER_NAME&gt;</kbd> to find out the IP of the machine and open the URL directly in your browser of choice. For example, the command above should be replaced with the command that follows:<br/>
<kbd>docker-machine ip swarm-1</kbd><br/>
If the output would be <kbd>1.2.3.4</kbd>, you should open <kbd>http://1.2.3.4:8082/jenkins/pluginManager/available</kbd> in your browser.</div>
<p>Next, we need to search for the <em>Self-Organizing Swarm Plug-in Modules plugin</em>. The easiest way to do that is by typing the plugin name inside the <span class="packt_screen">Filter</span> field located in the top-right corner of the screen. Once you locate the plugin, please select it and click the <kbd>Install without restart</kbd> button.</p>
<p>Now that the plugin is installed, we can set up our second cluster that will consist of three nodes. As before, we'll call it <kbd>swarm-test</kbd>. We'll use the script <kbd>scripts/dm-test-swarm-2.sh</kbd> (<a href="https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/dm-test-swarm-2.sh">https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/dm-test-swarm-2.sh</a>) to run all the commands required to create the machines and join them into the cluster.</p>
<pre>
<strong>scripts/dm-test-swarm-2.sh<br/><br/>eval $(docker-machine env swarm-test-1)<br/><br/>docker node ls</strong>
</pre>
<p>The output of the <kbd>node ls</kbd> command is as follows (IDs are removed for brevity):</p>
<pre>
<strong>HOSTNAME      STATUS  AVAILABILITY  MANAGER STATUS<br/>swarm-test-2  Ready   Active        Reachable<br/>swarm-test-1  Ready   Active        Leader<br/>swarm-test-3  Ready   Active        Reachable</strong>
</pre>
<p>The only significant difference between the script we just ran and the one we used before <kbd>dm-test-swarm.sh</kbd> is that this one adds a few labels. The first node is labeled <kbd>jenkins-agent</kbd>, while the other two are labeled <kbd>prod-like</kbd>. The reason behind those labels is that we're trying to differentiate nodes that will be used to run tasks like building and testing <kbd>jenkins-agent</kbd> from those that will be used to run services in the environment that simulate production <kbd>prod-like</kbd>.</p>
<p>Let's inspect the <kbd>swarm-test-1</kbd> node:</p>
<pre>
<strong>eval $(docker-machine env swarm-test-1)<br/><br/>docker node inspect swarm-test-1 --pretty</strong>
</pre>
<p>The output is as follows:</p>
<pre>
<strong>ID:             3rznbsuvvkw4wf7f4qa32cla3<br/>Labels:<br/> - env = jenkins-agent<br/>Hostname:           swarm-test-1<br/>Joined at:          2017-01-22 08:30:26.757026595 +0000 utc<br/>Status:<br/> State:         Ready<br/> Availability:      Active<br/>Manager Status:<br/> Address:           192.168.99.103:2377<br/> Raft Status:       Reachable<br/> Leader:            Yes<br/>Platform:<br/> Operating System:      linux<br/> Architecture:      x86_64<br/>Resources:<br/> CPUs:          1<br/> Memory:            492.5 MiB<br/>Plugins:<br/>  Network:          bridge, host, null, overlay<br/>  Volume:           local<br/>Engine Version:     1.13.0<br/>Engine Labels:<br/> - provider = virtualbox</strong>
</pre>
<p>As you can see, this node has the label with the key <kbd>env</kbd> and the value <kbd>jenkins-agent</kbd>. If you inspect the other two nodes, you will see that they are also labeled but, this time, with the value <kbd>prod-like</kbd>:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="222" src="assets/cd-environment-jenkins-both-clusters.png" width="627"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 6-4: Create First Admin User screen</div>
<p>Now that the <kbd>swarm-test</kbd> cluster is set up, we are ready to create the Jenkins agent service. However, before we do that, let's take a quick look at the definition of the image we are going to use. The <kbd>vfarcic/jenkins-swarm-agent Dockerfile</kbd> (<a href="https://github.com/vfarcic/docker-jenkins-slave-dind/blob/master/Dockerfile">https://github.com/vfarcic/docker-jenkins-slave-dind/blob/master/Dockerfile</a>) is as follows:</p>
<pre>
<strong>FROM docker:1.12.1<br/><br/>MAINTAINER Viktor Farcic &lt;viktor@farcic.com&gt;<br/><br/>ENV SWARM_CLIENT_VERSION 2.2<br/>ENV DOCKER_COMPOSE_VERSION 1.8.0<br/>ENV COMMAND_OPTIONS ""<br/><br/>RUN adduser -G root -D jenkins<br/>RUN apk --update add openjdk8-jre python py-pip git<br/><br/>RUN wget -q https://repo.jenkins-ci.org/releases/org/jenkins-ci/plugins/swarm-client/ \<br/>${SWARM_CLIENT_VERSION}/swarm-client-${SWARM_CLIENT_VERSION}-jar-with- \<br/>dependencies.jar -P /home/jenkins/<br/>RUN pip install docker-compose<br/><br/>COPY run.sh /run.sh<br/>RUN chmod +x /run.sh<br/><br/>CMD ["/run.sh"]</strong>
</pre>
<p>It uses <kbd>docker</kbd> as the base image followed by a few environment variables that define versions of the software that will be installed. Since Jenkins runs as a <kbd>jenkins user</kbd>, we added it as well. That is followed by the installation of OpenJDK, Python, and pip. JDK is required for the Jenkins Swarm client and the rest for Docker Compose. With all the prerequisites set, we download the Swarm JAR and use pip to install Docker Compose.</p>
<p>Finally, we copy the <kbd>run.sh</kbd> (<a href="https://github.com/vfarcic/docker-jenkins-slave-dind/blob/master/run.sh">https://github.com/vfarcic/docker-jenkins-slave-dind/blob/master/run.sh</a>) script, set its permissions to execute, and define the runtime command to run it. The script uses Java to run the Jenkins Swarm client.</p>
<p>Before we proceed with the Jenkins agents service, we'll need to create the <kbd>/workspace</kbd> directory in each of the hosts where the agents will run. At the moment, that is only the <kbd>swarm-test-1</kbd> node. Soon you'll see why we need this directory:</p>
<pre>
<strong>docker-machine ssh swarm-test-1<br/><br/>sudo mkdir /workspace &amp;&amp; sudo chmod 777 /workspace &amp;&amp; exit</strong>
</pre>
<p>We entered the node <kbd>swarm-test-1</kbd>, created the directory, gave it full permissions, and exited the machine.</p>
<p>Equipped with the understanding of the <kbd>vfarcic/jenkins-swarm-agent</kbd> image (or, at least, what it contains), we can move on and create the service:</p>
<div class="packt_tip"><strong>A note to Windows users</strong><br/>
For mounts used in the next command to work, you have to stop Git Bash from altering file system paths. Set this environment variable as follows:<br/>
<kbd>export MSYS_NO_PATHCONV=1</kbd></div>
<pre>
<strong>export USER=admin<br/><br/>export PASSWORD=admin<br/><br/>docker service create --name jenkins-agent \<br/>    -e COMMAND_OPTIONS="-master \<br/>    http://$(docker-machine ip swarm-1):8082/jenkins \<br/>    -username $USER -password $PASSWORD \<br/>    -labels 'docker' -executors 5" \<br/>    --mode global \<br/>    --constraint 'node.labels.env == jenkins-agent' \<br/>    --mount \<br/>    "type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock" \<br/>    --mount \<br/>    "type=bind,source=$HOME/.docker/machine/machines,target=/machines" \<br/>    --mount "type=bind,source=/workspace,target=/workspace" \<br/>    vfarcic/jenkins-swarm-agent</strong>
</pre>
<p>The <kbd>service create</kbd> command is, this time, a bit longer than what we're used to. The <kbd>COMMAND_OPTIONS</kbd> environment variable contains all the information the agent needs to connect to the master. We specified the address of the <kbd>master -master http://$(docker-machine ip swarm-1):8082/jenkins</kbd>, defined the <kbd>username</kbd> and <kbd>password</kbd> <kbd>-username $USER -password $PASSWORD</kbd>, labeled the agent <kbd>-labels 'docker'</kbd>, and set the number of executors <kbd>-executors 5</kbd>.</p>
<p>Further on, we declared the service to be global and constrained it to the <kbd>jenkins-agent</kbd> nodes. That means that it will run on every node that has the matching label. At the moment, that is only one server. Soon we'll see the benefits such a setup provides.</p>
<p>We mounted Docker socket. As a result, any command sent to the Docker client running inside the container will run against Docker Engine on the host (in this case Docker Machine). As a result, we'll avoid pitfalls that could be created by running <kbd>Docker inside Docker</kbd>  or  <kbd>DinD</kbd>. For more information, please read the article Using Docker-in-Docker for your CI or testing environment? Think twice (<a href="http://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/">http://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-</a><a href="http://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/">docker-for-ci/</a>).</p>
<p>We also mounted the host (laptop) directory that contains the keys. That will allow us to send requests to engines running inside the other cluster. The final mount exposes the host directory <kbd>/workspace</kbd> inside the container. All builds running inside Jenkins agents will use that directory:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/cd-environment-jenkins-agent.png"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 6-5: Jenkins agent run as a global service</div>
<p>Let's take a look at the service processes:</p>
<pre>
<strong>docker service ps jenkins-agent</strong>
</pre>
<div class="CDPAlignLeft CDPAlign">The output is as follows (IDs are removed for brevity):</div>
<div class="CDPAlignCenter CDPAlign"><img height="44" src="assets/output1.png" width="779"/></div>
<p>As you can see, the service is global, so the desired state is for it to run on every node. However, since we restricted it to the nodes with the label <kbd>jenkins-agent</kbd>, containers are running only inside those that have the matching label. In other words, the service is running only on <kbd>jenkins-agent</kbd> nodes.</p>
<p>Let's open the Jenkins screen that displays registered agents:</p>
<pre>
<strong>open "http://$(docker-machine ip swarm-1):8082/jenkins/computer/"</strong>
</pre>
<div class="packt_tip"><strong>A note to Windows users</strong><br/>
Git Bash might not be able to use the open command. If that’s the case, execute <kbd>docker-machine ip &lt;SERVER_NAME&gt;</kbd> to find out the IP of the machine and open the URL directly in your browser of choice. For example, the command above should be replaced with the command that follows:<br/>
<kbd>docker-machine ip swarm-1</kbd><br/>
If the output would be <kbd>1.2.3.4</kbd>, you should open <kbd>http://1.2.3.4:8082/jenkins/computer</kbd> in your browser.</div>
<p>As you can see, two agents are registered. The master agent is running by default with every Jenkins instance. On my machine, the agent running as the <kbd>jenkins-agent</kbd> service is identified as <kbd>e0961f7c1801-d9bf7835</kbd>:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/jenkins-agent.png"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 6-6: Jenkins Swarm agent added to the master</div>
<p>Since we used labels to restrict the service to the <kbd>swarm-test-1</kbd> node, at the moment we have only one agent registered (besides the master that, in most cases, should not be used).</p>
<p>The agent is configured to use five executors. That means that five builds can be executed in parallel. Please note that, in this case, the number of executors is artificially high. Each machine has only one CPU. Without any additional information, I would probably set the number of executors to be the same as the number of CPUs. That would be only the basic calculation that would change with time. If the tasks we're running through those executors are CPU demanding, we might lower the number of executors. However, for the purpose of this exercise, five executors should be <em>OK</em>. We have only one service, so we won't run builds in parallel.</p>
<p>Let's imagine that this is the real system with more builds running in parallel than the number of executors. In such a situation, some would be queued waiting for an executor to finish and free its resources. If this was a temporary case, we wouldn't need to do anything. The executing builds would end, free the resources, and run the queued builds. However, if this is a reoccurring situation, the number of queued builds would probably start increasing and everything would slow down. Since we already established that the speed is the critical element of Continuous Integration, Delivery, and Deployment processes, when things start to get in the way, we need to do something. In this case, that something is the increase of available executors and, consequently, the number of agents.</p>
<p>Let's imagine that we hit the limit and need to increase the number of agents. Knowing how global Swarm services work, all we have to do is create a new node:</p>
<pre>
<strong>docker-machine create -d virtualbox swarm-test-4<br/><br/>docker-machine ssh swarm-test-4<br/><br/>sudo mkdir /workspace &amp;&amp; sudo chmod 777 /workspace &amp;&amp; exit<br/><br/>TOKEN=$(docker swarm join-token -q worker)<br/><br/>eval $(docker-machine env swarm-test-4)<br/><br/>docker swarm join \<br/>    --token $TOKEN \<br/>    --advertise-addr $(docker-machine ip swarm-test-4) \<br/>    $(docker-machine ip swarm-test-1):2377</strong>
</pre>
<p>We created the <kbd>swarm-test-4</kbd> node and, inside it, the <kbd>/workspace</kbd> directory. Then we got the token and joined the newly created service to the cluster as a worker.<br/>
Let's confirm that the new node is, indeed, added to the cluster:</p>
<pre>
<strong>eval $(docker-machine env swarm-test-1)<br/><br/>docker node ls</strong>
</pre>
<p>The output of the <kbd>node ls</kbd> command is as follows (IDs are removed for brevity):</p>
<pre>
<strong>HOSTNAME      STATUS  AVAILABILITY  MANAGER STATUS<br/>swarm-test-3  Ready   Active        Reachable<br/>swarm-test-2  Ready   Active        Reachable<br/>swarm-test-1  Ready   Active        Leader<br/>swarm-test-4  Ready   Active</strong>
</pre>
<p>Is the Jenkins agent running inside the newly created node? Let’s take a look:</p>
<pre>
<strong>docker service ps jenkins-agent</strong>
</pre>
<p>The output of the <kbd>service ps</kbd> command is as follows (IDs are removed for brevity):</p>
<pre>
<strong>NAME             IMAGE                              NODE         <br/>jenkins-agent... vfarcic/jenkins-swarm-agent:latest swarm-test-1  <br/>----------------------------------------<br/></strong><strong>DESIRED STATE CURRENT STATE ERROR PORTS<br/>Running       Running</strong>
</pre>
<p>Since the node is not labeled as <kbd>jenkins-agent</kbd>, the agent is not running inside the <kbd>swarm-test-4</kbd> server.</p>
<p>Let's add the label:</p>
<pre>
<strong>docker node update \<br/>    --label-add env=jenkins-agent \<br/>    swarm-test-4<br/><br/>docker service ps jenkins-agent</strong>
</pre>
<p>This time, the output is a bit different (IDs are removed for brevity):</p>
<div class="CDPAlignCenter CDPAlign"><img height="47" src="assets/output4-1.png" width="849"/></div>
<p>Swarm detected the new label, run the container, and changed the state to running.<br/>
Let's go back to the Jenkins screen that lists the connected agents:</p>
<pre>
<strong>open "http://$(docker-machine ip swarm-1):8082/jenkins/computer"</strong>
</pre>
<div class="packt_tip"><strong>A note to Windows users</strong><br/>
Git Bash might not be able to use the open command. If that's the case, execute                      <kbd>docker-machine ip &lt;SERVER_NAME&gt;</kbd> to find out the IP of the machine and open the URL directly in your browser of choice. For example, the command above should be replaced with the command that follows:<br/>
<kbd>docker-machine ip swarm-1</kbd><br/>
If the output would be <kbd>1.2.3.4</kbd>, you should open <kbd>http://1.2.3.4:8082/jenkins/computer</kbd> in your browser.</div>
<p>As you can see, the new agent <span class="packt_screen">b76e943ffe6c-d9bf7835</span> was added to the list:</p>
<div class="CDPAlignCenter"><img class="image-border" height="157" src="assets/jenkins-agents.png" width="583"/></div>
<div class="packt_figref CDPAlignCenter">Figure 6-7: The second Jenkins Swarm agent added to the master</div>
<p>This was very easy, wasn't it? Usually, we'd need not only to create a new server but also to run the agent and add it to Jenkins configuration through the UI. By combining <em>Jenkins Swarm</em> plugin and <em>Docker Swarm</em> global services, we managed to automate most of the steps. All we have to do is create a new node and add it to the Swarm cluster.</p>
<p>Before we proceed and automate the Continuous Deployment flow through Jenkins, we should create the services in production and production-like environments.<br/></p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Creating services in production and production-like environments</h1>
            </header>

            <article>
                
<p>Since a service is created only once and updated whenever some of its aspects change (example:new image with the new release), there is no strong incentive to add service creation to the Continuous Deployment flow. All we'd get is increased complexity without any tangible benefit. Therefore, we'll create all the services manually and, later on, discuss how to automate the flow that will be triggered with each new release.</p>
<p>We already created <kbd>go-demo</kbd>, <kbd>go-demo-db</kbd>, <kbd>proxy</kbd>, <kbd>jenkins</kbd>, and <kbd>registry</kbd> services quite a few times so we'll skip the explanation and run <kbd>scripts/dm-swarm-services-2.sh</kbd> (<a href="https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/dm-swarm-services-2.sh">https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/dm-swarm-services-2.sh</a>) that will recreate the situation we had in the previous chapters:</p>
<pre>
<strong>scripts/dm-swarm-services-<span class="hljs-number">2</span>.sh<br/><br/><span class="hljs-built_in">eval</span> $(docker-machine env swarm-<span class="hljs-number">1</span>)<br/><br/>docker service ls</strong>
</pre>
<p>The output of the <kbd>service ls</kbd> command is as follows (IDs are removed for brevity):</p>
<pre>
<strong>NAME       MODE       REPLICAS IMAGE<br/>go<span class="hljs-attribute">-demo</span>    replicated <span class="hljs-number">3</span>/<span class="hljs-number">3</span>      vfarcic/go<span class="hljs-attribute">-demo</span>:<span class="hljs-number">1.0</span><br/>jenkins    replicated <span class="hljs-number">1</span>/<span class="hljs-number">1</span>      jenkins:<span class="hljs-number">2.7</span><span class="hljs-number">.4</span><span class="hljs-attribute">-alpine</span><br/>go<span class="hljs-attribute">-demo</span><span class="hljs-attribute">-db</span> replicated <span class="hljs-number">1</span>/<span class="hljs-number">1</span>      mongo:<span class="hljs-number">3.2</span><span class="hljs-number">.10</span><br/>registry   replicated <span class="hljs-number">1</span>/<span class="hljs-number">1</span>      registry:<span class="hljs-number">2.5</span><span class="hljs-number">.0</span><br/>proxy      replicated <span class="hljs-number">3</span>/<span class="hljs-number">3</span>      vfarcic/docker<span class="hljs-attribute">-flow</span><span class="hljs-attribute">-proxy</span>:latest</strong>
</pre>
<p>All the services are running. The only difference between the script we ran now and the one we used before <kbd>scripts/dm-swarm-services.sh</kbd> (<a href="https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/dm-swarm-services.sh">https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/dm-swarm-services.sh</a>) is that, this time, we added <kbd>registry</kbd> to the mix.</p>
<p>Now that the production environment is up and running, let's create the same set of services inside the <kbd>swarm-test</kbd> cluster. Since this cluster is shared between services running in the production-like environment as well as Jenkins agents, we'll constrain services to <kbd>prod-like</kbd> nodes.<br/>
As with the production cluster, we'll run the services through a script. This time we'll use <kbd>scripts/dm-test-swarm-services-2.sh</kbd> (<a href="https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/dm-test-swarm-services-2.sh">https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/dm-test-swarm-services-2.sh</a>):</p>
<pre>
<strong>scripts/dm-test-swarm-services-<span class="hljs-number">2</span>.sh<br/><br/><span class="hljs-built_in">eval</span> $(docker-machine env swarm-test-<span class="hljs-number">1</span>)<br/><br/>docker service ls</strong>
</pre>
<p>The output of the <kbd>service ls</kbd> command is as follows (IDs are removed for brevity):</p>
<pre>
<strong>NAME          MODE       REPLICAS IMAGE<br/>jenkins<span class="hljs-attribute">-agent</span> <span class="hljs-built_in">global</span>     <span class="hljs-number">2</span>/<span class="hljs-number">2</span>      vfarcic/jenkins<span class="hljs-attribute">-swarm</span><span class="hljs-attribute">-agent</span>:latest<br/>registry      replicated <span class="hljs-number">1</span>/<span class="hljs-number">1</span>      registry:<span class="hljs-number">2.5</span><span class="hljs-number">.0</span><br/>go<span class="hljs-attribute">-demo</span>       replicated <span class="hljs-number">2</span>/<span class="hljs-number">2</span>      vfarcic/go<span class="hljs-attribute">-demo</span>:<span class="hljs-number">1.0</span><br/>proxy         replicated <span class="hljs-number">2</span>/<span class="hljs-number">2</span>      vfarcic/docker<span class="hljs-attribute">-flow</span><span class="hljs-attribute">-proxy</span>:latest<br/>go<span class="hljs-attribute">-demo</span><span class="hljs-attribute">-db</span>    replicated <span class="hljs-number">1</span>/<span class="hljs-number">1</span>      mongo:<span class="hljs-number">3.2</span><span class="hljs-number">.10</span></strong>
</pre>
<p>Now that the services are running in both the production and production-like environments, we can proceed with the discussion about the approach we'll take for the CD flow automation with Jenkins.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Automating Continuous Deployment flow with Jenkins</h1>
            </header>

            <article>
                
<p>Jenkins is based on plugins. Almost every feature is a plugin. If we need to use Git, there is a plugin for it. If we want to use Active Directory for authentication, there is a plugin. You get the point. Almost everything is a plugin. Moreover, most plugins were created and are maintained by the community. When we are in doubt how to accomplish something, the <em>plugins directory</em> (<a href="https://wiki.jenkins-ci.org/display/JENKINS/Plugins">https://wiki.jenkins-ci.org/display/JENKINS/Plugins</a>) is usually the first place we start looking.</p>
<p>With more than <kbd>1200</kbd> plugins available, it's no wonder that, given such a huge variety, most users are compelled to use a plugin for almost any type of task. Jenkins old-timers would create a Freestyle job that, for example, clones the code and builds the binaries. It would be followed by another job that would run unit tests, another for running functional tests, and so on. All those Freestyle jobs would be connected. When the first is finished, it would invoke the second, the second would call the third, and so on. Freestyle jobs foment heavy plugins usage.<br/>
We would choose one appropriate for a given task, fill in some fields, and click save. Such an approach allows us to automate the steps without the need for the knowledge of how different tools work. Need to execute some Gradle tasks? Just choose the Gradle plugin, fill in a few fields, and off you go.</p>
<p>Such an approach based on heavy usage of plugins can be disastrous. Understanding automation and the tools behind it is essential. Moreover, the usage of <em>Freestyle</em> jobs breaks one of the fundamental principles in our industry. Everything should be stored in a code repository, be prone to code reviews, versioned, and so on. There is no good reason why coding practices should not apply to the automation code.</p>
<p>We'll take a different approach.</p>
<p>I am a huge believer that the steps that form a CI/CD Pipeline should be specified outside the tools like Jenkins. We should be able to define all the commands without CI/CD tools and, once we’re comfortable that everything works as expected, proceed by translating those commands to the CI/CD friendly format. In other words, automation comes first, and CI/CD tools later.</p>
<p>Fortunately, not long ago, Jenkins introduced a new concept called <em>Jenkins Pipeline</em>. Unlike <em>Freestyle</em> jobs that were defined through Jenkins UI, <em>Pipeline</em> allows us to define CD flow as code. Since we already have a well-defined set of commands, converting them into <em>Jenkins Pipeline</em> should be relatively straightforward.</p>
<p>Let's give it a try.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Creating Jenkins Pipeline jobs</h1>
            </header>

            <article>
                
<p>We’ll start by defining a few environment variables. The reason behind declaring those variables is that we want to have a single place where critical information is stored. That way, when something changes (example:entry point to the cluster) we can modify a variable or two, and the changes will be propagated throughout all jobs.</p>
<p>Off we go. First, we need to open Jenkins global configuration screen:</p>
<pre>
<strong>open <span class="hljs-string">"http://<span class="hljs-variable">$(docker-machine ip swarm-1)</span>:8082/jenkins/configure"</span></strong>
</pre>
<div class="packt_tip"><strong>A note to Windows users:</strong><br/>
Git Bash might not be able to use the open command. If that's the case, execute <kbd>docker-machine ip &lt;SERVER_NAME&gt;</kbd> to find out the IP of the machine and open the URL directly in your browser of choice. For example, the command above should be replaced with the command that follows:<br/>
<kbd>docker-machine ip swarm-1</kbd> If the output would be <kbd>1.2.3.4</kbd>, you should open <kbd>http://1.2.3.4:8082/jenkins/configure</kbd> in your browser.</div>
<p>Once inside the configuration screen, please click the <span class="packt_screen">Environment variables</span> checkbox followed with the <span class="packt_screen">Add</span> button. You will be presented with the fields <span class="packt_screen">Name</span> and <span class="packt_screen">Value</span>. The first variable we'll add will hold the production IP. However, before we type it, we need to find it out. The routing mesh redirects requests from any node to the destination service or, to be more precise, to the service that exposes the same port as the request. Therefore, we can use any server in the production cluster <kbd>swarm</kbd> as our entry point.</p>
<p>To get the IP of one of the nodes, we can use the <kbd>docker-machine ip</kbd> command:</p>
<pre>
<strong>docker-machine ip swarm-<span class="hljs-number">1</span></strong>
</pre>
<p>The result will differ from one case to another. On my laptop, the output is as follows:</p>
<pre>
<strong>192.168.99.107</strong>
</pre>
<p>Please copy the IP and go back to the Jenkins configuration screen. Type <kbd>PROD_IP</kbd> as <span class="packt_screen">Name</span> and paste the IP into the Value field. It is worth noting that we just introduced a single point of failure. If the <kbd>swarm-1</kbd> node fails, all our jobs that use this variable will fail as well. The good news is that we can fix that quickly by changing the value of this environment variable. The bad news is that we can do better, but not with Docker machines. If, for example, we were to use AWS, we'd be able to utilize Elastic IP. However, we have not reached the AWS chapter yet, so changing the variable is our best option.</p>
<p>Next, we should add another variable that will represent the name of the production node. We'll see the usage of this variable later. For now, please create a new variable with <kbd>PROD_NAME</kbd> as <span class="packt_screen">Name</span> and <span class="packt_screen">swarm-1</span> as value.<br/>
We'll need similar variables for our production-like cluster <kbd>swarm-test</kbd>. Please enter variables <kbd>PROD_LIKE_IP</kbd> with the IP of the <kbd>swarm-test-1</kbd> node <kbd>docker-machine ip swarm-test-1</kbd> and <kbd>PROD_LIKE_NAME</kbd> with the value <kbd>swarm-test-1</kbd>:</p>
<div class="CDPAlignCenter"><img class="image-border" height="281" src="assets/jenkins-configuration-variables.png" width="318"/></div>
<div class="packt_figref CDPAlignCenter">Figure 6-8: Jenkins global configuration screen with defined environment variables</div>
<p>Once done with the <span class="packt_screen">Environment variables</span>, please click the <span class="packt_screen">Save</span> button.</p>
<p>Now that the environment variables are defined, we can proceed and create a Jenkins Pipeline job that will automate the execution of the CD steps we practiced.</p>
<p>To create the new job, please click the New Item link located in the left-hand menu. Type <kbd>go-demo</kbd> as the item name, select Pipeline, and click the <span class="packt_screen">OK</span> button.</p>
<p>A Jenkins Pipeline definition contains three primary levels; node, stage, and step. We'll define the go-demo Pipeline code by going through these levels one by one.<br/></p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Defining Pipeline nodes</h1>
            </header>

            <article>
                
<p>In the Jenkins Pipeline DSL, a <em>node</em> is a step that does two things, typically by enlisting help from available executors on agents.</p>
<p>A node schedules the steps contained within it by adding them to the Jenkins build queue. That way, as soon as an executor slot is free on a node, the appropriate steps will be run.</p>
<p>It also creates a workspace, meaning a file directory specific to a particular job, where resource-intensive processing can occur without negatively impacting your Pipeline performance. Workspaces created by a node are automatically removed after all the steps contained inside the node declaration finish executing. It is a best practice to do all material work, such as building or running shell scripts, within nodes, because node blocks in a stage tell Jenkins that the steps within them are resource-intensive enough to be scheduled, request help from the agent pool, and lock a workspace only as long as they need it.</p>
<p>If that definition of the node confuses you, think of it as a location where the steps will run. It specifies a server (agent) that will execute tasks. That specification can be the name of the server (generally a bad idea, due to tight coupling of node configuration to agent), or a set of labels that must match those set inside an agent. If you recall the command we used to start the Jenkins Swarm agent service, you'll remember that we used <kbd>-labels docker</kbd> as one of the command options. Since Docker Engine and Compose are the only executables we need, that was the only label we needed as our node specification.</p>
<p>Please type the following code into the <span class="packt_screen">Pipeline script</span> field of the <span class="packt_screen">go-demo</span> job configuration and press the <span class="packt_screen">Save</span> button:</p>
<pre>
<strong><span class="hljs-function"><span class="hljs-title">node</span><span class="hljs-params">(<span class="hljs-string">"docker"</span>)</span> {<br/>}</span></strong>
</pre>
<p>We just wrote the first iteration of the Pipeline. Let's run it.</p>
<p>Please click the <span class="packt_screen">Build Now</span> button.</p>
<p>The job started running and displayed the message stating that <span class="packt_screen">This Pipeline has run successfully, but does not define any stages</span><em>.</em> We'll correct that in a moment. For now, let's take a look at the logs:</p>
<div class="CDPAlignCenter"><img class="image-border" height="329" src="assets/jenkins-pipeline-build-node.png" width="511"/></div>
<div class="packt_figref CDPAlignCenter">Figure 6-9: The first build of the Jenkins Pipeline job<span><br/></span></div>
<p>You can access the logs by clicking the icon in the shape of a ball next to the build number in this case <em><span class="packt_screen">#1</span></em>. Builds can be accessed from the <em>Build History</em> widget located in the left-hand side of the screen.</p>
<p>The output is as follows:</p>
<pre>
<strong>Started <span class="hljs-keyword">by</span> user admin<br/>[Pipeline] node<br/>Running <span class="hljs-keyword">on</span> be61529c010a-d9bf7835 <span class="hljs-keyword">in</span> /workspace/go-demo<br/>[Pipeline] <span class="hljs-comment">{<br/>[Pipeline] }</span><br/>[Pipeline] <span class="hljs-comment">// node</span><br/>[Pipeline] <span class="hljs-keyword">End</span> <span class="hljs-keyword">of</span> Pipeline<br/>Finished: SUCCESS</strong>
</pre>
<p>Not much happened in this build. Jenkins parsed the node definition and decided to use the agent <kbd>be61529c010a-d9bf7835</kbd> (one of the two Jenkins Swarm service instances) and run the steps inside the directory <kbd>/workspace/go-demo</kbd>. The directory structure is simple. All files generated by a build are located in a directory that matches the job name. In this case, the directory is <kbd>go-demo</kbd>.</p>
<p>Since we did not specify any step inside the node, the Pipeline finished executing almost immediately and the result was a success. Let's spice it up a bit with stages.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Defining Pipeline stages</h1>
            </header>

            <article>
                
<p>A <strong>stage</strong> is a logically distinct part of the execution of any task, with parameters for locking, ordering, and labeling its part of a process relative to other parts of the same process. Pipeline syntax is often comprised of stages. Each stage step can have one or more build steps within it. It is a best practice to work within stages because they help with organization by lending logical divisions to Pipelines, and because the Jenkins Pipeline visualization feature displays stages as unique segments of the Pipeline.</p>
<p>What would be the stages of the flow we practiced with manual commands? We could divide the commands we defined into the following groups:</p>
<ol>
<li>Pull the latest code from the repository.</li>
<li>Run unit tests and build the service and Docker images.</li>
<li>Deploy to staging environment and run tests.</li>
<li>Tag Docker images and push them to the registry.</li>
<li>Use the latest image to update the service running in production-like environment and run tests.</li>
<li>Use the latest image to update the service running in production environment and run tests.</li>
</ol>
<p>When those groups of tasks are translated into Pipeline stages, the code inside the node is as follows:</p>
<pre>
<strong><span class="hljs-function"><span class="hljs-title">stage</span><span class="hljs-params">(<span class="hljs-string">"Pull"</span>)</span> {<br/>}<br/><br/><span class="hljs-title">stage</span><span class="hljs-params">(<span class="hljs-string">"Unit"</span>)</span> {<br/>}<br/><br/><span class="hljs-title">stage</span><span class="hljs-params">(<span class="hljs-string">"Staging"</span>)</span> {<br/>}<br/><br/><span class="hljs-title">stage</span><span class="hljs-params">(<span class="hljs-string">"Publish"</span>)</span> {<br/>}<br/><br/><span class="hljs-title">stage</span><span class="hljs-params">(<span class="hljs-string">"Prod-like"</span>)</span> {<br/>}<br/><br/><span class="hljs-title">stage</span><span class="hljs-params">(<span class="hljs-string">"Production"</span>)</span> {<br/>}</span></strong>
</pre>
<p>We should combine the node we defined earlier with those stages. To be more precise, they should all be defined inside the node block.</p>
<p>Please replace the existing Pipeline definition by copying and pasting the code from <kbd>scripts/go-demo-stages.groovy</kbd> (<a href="https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/go-demo-stages.groovy">https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/go-demo-stages.groovy</a>). You can access the job configuration by clicking the <span class="packt_screen">go-demo</span> link inside breadcrumbs located in the top part of the screen. Once inside the main job page, please click the <span class="packt_screen">Configure</span> button located in the left-hand menu. Once you are done writing or pasting the new Pipeline definition, save it and re-run the job by clicking the <span class="packt_screen">Build Now</span> button.</p>
<p>We still do not execute any actions. However, this time, the <span class="packt_screen">Stage View</span> screen is much more informative. It displays the stages we defined earlier:</p>
<div class="CDPAlignCenter"><img class="image-border" height="257" src="assets/jenkins-pipeline-stage-view.png" width="443"/></div>
<div class="packt_figref CDPAlignCenter">Figure 6-10: The Jenkins Pipeline Stage View screen<span><br/></span></div>
<p>Now we are ready to define the steps that will be executed inside each of the stages.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Defining Pipeline steps</h1>
            </header>

            <article>
                
<p>Before we start writing the steps, I must, briefly, mention that there are a couple of different approaches people use to define Jenkins jobs. Some prefer to utilize Jenkins plugins to their maximum. When taken to an extreme, such approach results in every action being executed through a plugin. Do you need to run some Gradle tasks? There is a Gradle plugin (or two). Do you need to do something with Docker? There are roughly a dozen Docker plugins. How about configuration management with Ansible? There is a plugin as well.</p>
<p>I do not think that heavy reliance on plugins is a good thing. I believe that we should be capable of creating most, if not all the automation without Jenkins. After all, does it even make sense to use a plugin that would save us from writing a single line of command? I don't believe it does. That doesn't mean that we should not use plugins. We should, but only when they bring a real and tangible additional value. An example would be the Git plugin. It evaluates whether the code should be cloned or pulled. It manages authentication. It provides a few auto-populated environment variables we can use in conjunction with other steps.</p>
<p>Should we use the Git plugin always? We shouldn't. Let's say that all we have to do is perform a simple pull inside an already cloned repository, that we do not need authentication, and that there will be no usage of some of the pull information in later steps (example: commit ID). In such a case, the simplest solution possible might be the best choice. What is the easiest way to pull the code from a Git repository? Most likely that's git <kbd>pull</kbd> command executed through Shell.</p>
<p>Only once we know what we're doing and the process is done in a CI/CD tool agnostic way, we should proceed and tie it all together through Jenkins (or whatever is your tool of choice). That way we understand the process and have a firm handle on what should be done, not only from a pure automation perspective, but also as a choice of tools, processes, and architecture as well. All pieces need to work together in an organic and efficient way. If we manage to accomplish that, Jenkins acts as glue that ties it all together, and not as a base we start with.</p>
<p>Let's define the steps required for the first stage. The objective is very simple. Get the code from the Git repository. To make things slightly more complicated, we might need to clone or pull the code. The first build will have nothing so we must clone. All consecutive builds should only perform a pull into the already cloned code. While writing a script that performs that logic is relatively straightforward, this will be a good case of using a Jenkins plugin. To be more precise, we'll use Jenkins Pipeline step git that uses one of the Git plugins in the background.</p>
<p>The <kbd>Pull</kbd> stage stage of the Pipeline is as follows:</p>
<pre style="padding-left: 30px">
<strong>stage(<span class="hljs-string">"Pull"</span>) { \<br/>  git <span class="hljs-string">"https://github.com/vfarcic/go-demo.git" \</span><br/>}</strong>
</pre>
<p>The git step is one of the many available through Pipelines <strong>Domain Specific Language</strong> (<strong>DSL</strong>). It clones the code. If that action was already done, the code will be pulled instead. You can find more information in the <em>Pipeline Steps Reference</em> (<a href="https://jenkins.io/doc/pipeline/steps/">https://jenkins.io/doc/pipeline/steps/</a>) page.</p>
<p>Please note that in the real world situation we would create a webhook inside the code repository. It would trigger this job whenever a new commit is made. For now, we'll simulate a web hook by triggering the job execution manually.</p>
<p>Feel free to replace the existing Pipeline definition by copying and pasting the code from <kbd>scripts/go-demo-pull.groovy</kbd> (<a href="https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/go-demo-pull.groovy">https://github.com/vfarcic/cloud-provisioning/blob/master/scripts/go-demo-pull.groovy</a>). Once you're done, please run the job and observe the build log.</p>
<p>Let's move on.</p>
<p>The code that follows is the translation of the commands we used in the previous chapters to run unit tests and build a new Docker image:</p>
<pre>
<strong>withEnv([<br/>  "COMPOSE_FILE=docker-compose-test-local.yml"<br/>]) {<br/><br/>  stage("Unit") {<br/>    sh "docker-compose run --rm unit"<br/>    sh "docker-compose build app"<br/>  }<br/><br/>}</strong>
</pre>
<p>We enveloped the whole stage inside the <kbd>withEnv</kbd> block that defines the <kbd>COMPOSE_FILE</kbd> variable. That way, we won't need to repeat the <kbd>-f docker-compose-test-local.yml</kbd> argument every time we execute <kbd>docker-compose</kbd>. Please note that all the other stages we'll define soon should also be inside the <kbd>withEnv</kbd> block.</p>
<p>The steps inside the Unit stage are the same as those we practiced while we run the flow manually. The only difference is that, this time, we put the commands inside the <kbd>sh DSL</kbd> step. It's purpose is simple. It runs a shell command.</p>
<p>We'll skip running the job and proceed to the next stage:</p>
<pre>
<strong>stage(<span class="hljs-string">"Staging"</span>) {<br/><span class="hljs-keyword">try</span> {<br/>    sh <span class="hljs-string">"docker-compose up -d staging-dep"</span><br/>    sh <span class="hljs-string">"docker-compose run --rm staging"<br/></span>} <span class="hljs-keyword">catch</span>(e) {<br/>    error <span class="hljs-string">"Staging failed"</span><br/>  } <span class="hljs-keyword">finally</span> {<br/>    sh <span class="hljs-string">"docker-compose down"</span><br/>  }<br/>}</strong>
</pre>
<p>The Staging stage is a bit more complex. The commands are inside the <kbd>try/catch/finally</kbd> block. The reasons for such an approach is in the way Jenkins behaves when something fails. If one of the steps in the previous stage Unit should fail, the whole Pipeline build would be aborted. That suits us well when there are no additional actions to perform. However, in the case of the Staging steps, we want to remove all the dependency containers and free the resources for something else. In other words, <kbd>docker-compose down</kbd> should be executed no matter the outcome of the Staging tests. If you are a programmer, you probably already know that the finally statement is always executed regardless of whether the try statement produced an error or not. In our case, the finally statement will bring down all the containers that constitute this Docker Compose project.</p>
<p>Off we go to the <kbd>Publish</kbd> stage:</p>
<pre>
<strong>stage(<span class="hljs-string">"Publish"</span>) {<br/>  sh <span class="hljs-string">"docker tag go-demo \<br/>    localhost:5000/go-demo:2.<span class="hljs-variable">${env.BUILD_NUMBER}</span>"</span><br/>  sh <span class="hljs-string">"docker push \<br/>    localhost:5000/go-demo:2.<span class="hljs-variable">${env.BUILD_NUMBER}</span>"</span><br/>}</strong>
</pre>
<p>There's no mystery around this stage. We are repeating the same commands we executed in previous chapters. The image is tagged and pushed to the registry.</p>
<p>Please note that we are using <kbd>BUILD_NUMBER</kbd> to provide a unique release number to the tag. It is one of Jenkins built-in environment variables that holds the value of the currently executing build ID.</p>
<p>The <kbd>Prod-like</kbd> stage will introduce an additional caveat. It is as follows:</p>
<pre>
<strong>stage(<span class="hljs-string">"Prod-like"</span>) {<br/>  withEnv([<br/><span class="hljs-string">     "DOCKER_TLS_VERIFY=1"</span>,<br/><span class="hljs-string">     "DOCKER_HOST=tcp://<span class="hljs-variable">${env.PROD_LIKE_IP}</span>:2376"</span>,<br/><span class="hljs-string">     "DOCKER_CERT_PATH=/machines/<span class="hljs-variable">${env.PROD_LIKE_NAME}</span>"</span><br/>]) {<br/>    sh <span class="hljs-string">"docker service update \<br/>      --image localhost:5000/go-demo:2.<span class="hljs-variable">${env.BUILD_NUMBER}</span> \<br/>      go-demo"</span><br/>}<br/>withEnv([<span class="hljs-string">"HOST_IP=localhost"</span>]) { <br/><span class="hljs-keyword">     for</span> (i = <span class="hljs-number">0</span>; i &lt;<span class="hljs-number">10</span>; i++) {<br/>      sh <span class="hljs-string">"docker-compose run --rm production"</span><br/>    }<br/>  }<br/>}</strong>
</pre>
<p>Since we are using rolling updates to replace the old with the new release, we have to run tests throughout the whole process. We could create a script that would verify whether all instances are updated but I wanted to keep it simple (this time). Instead, we are running the tests ten times. You might need to tweak it a bit for your needs depending on the average duration of your tests and the time required to update all instances. For demonstration purposes, ten rounds of testing in the <kbd>production-like</kbd> environment should be enough.</p>
<p>To summarize, in this stage we are updating the service with the new release and running ten rounds of tests during the update process.</p>
<p>Please note that we declared a few more environment variables. Specifically, we defined all those required for the Docker client to connect to the Docker Engine running on a remote host.</p>
<p>We're almost done. Now that the service is tested in the <kbd>production-like</kbd> environment, we can deploy it to the production cluster.<br/>
The <kbd>Prod</kbd> stage is almost the same as <kbd>Prod-like</kbd>:</p>
<pre>
<strong>stage(<span class="hljs-string">"Production"</span>) {<br/>  withEnv([<br/><span class="hljs-string">    "DOCKER_TLS_VERIFY=1"</span>,<br/><span class="hljs-string">    "DOCKER_HOST=tcp://<span class="hljs-variable">${env.PROD_IP}</span>:2376"</span>,<br/><span class="hljs-string">    "DOCKER_CERT_PATH=/machines/<span class="hljs-variable">${env.PROD_NAME}</span>"<br/></span>]) {<br/>   sh <span class="hljs-string">"docker service update \<br/>    --image localhost:5000/go-demo:2.<span class="hljs-variable">${env.BUILD_NUMBER}</span> \<br/>    go-demo"</span><br/> }<br/> withEnv([<span class="hljs-string">"HOST_IP=<span class="hljs-variable">${env.PROD_IP}</span>"</span>]) {<br/><span class="hljs-keyword">   for</span> (i = <span class="hljs-number">0</span>; i &lt;<span class="hljs-number">10</span>; i++) { <br/>     sh <span class="hljs-string">"docker-compose run --rm production"</span><br/>   }<br/> }<br/>}</strong>
</pre>
<p>The only difference is that, this time, the <kbd>DOCKER_HOST</kbd> and <kbd>PROD_IP</kbd> variables point to one of the servers of the production cluster. The rest is the same as the <kbd>Prod-like</kbd> stage.</p>
<p>Feel free to replace the existing Pipeline definition with the code from <kbd>scripts/go-demo.groovy</kbd>. Once you're done, please run the job and observe the build log.</p>
<p>After a short while, the job will finish executing, and the new release will be running in the production cluster:</p>
<div class="CDPAlignCenter"><img class="image-border" height="201" src="assets/jenkins-pipeline-stage-view-2.png" width="434"/></div>
<div class="packt_figref CDPAlignCenter">Figure 6-11: The Jenkins Pipeline Stage View screen<span><br/></span></div>
<p>We can confirm that the service update with the new release was indeed successful by executing the <kbd>service ps</kbd> command:</p>
<pre>
<strong><span class="hljs-built_in">eval</span> $(docker-machine env swarm-<span class="hljs-number">1</span>)<br/><br/>docker service ps go-demo</strong>
</pre>
<div class="CDPAlignCenter CDPAlign">
<p>The output of the <kbd>service ps</kbd> command is as follows (IDs are removed for brevity):</p>
<p><img height="127" src="assets/ID-removed.png" width="847"/></p>
</div>
<p>That's it! We have a full Continuous Deployment Pipeline alive and kicking. If we'd add a webhook to the GitHub repository that hosts the code, the Pipeline would run every time a new commit is made. As a result, the new release would be deployed to production unless one of the steps in the Pipeline fails.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">What now?</h1>
            </header>

            <article>
                
<p>The ability to use the code to define the steps of a Continuous Deployment flow gives us more flexibility than we had before with <em>Freestyle</em> jobs. Docker Compose allowed us to run any type of tasks without the need to set up any special infrastructure. Anything can run as long as it is inside a container. Finally, Docker Swarm simplified the Deployment to production-like and production environments considerably.<br/>
We only scratched the surface of using Jenkins Pipeline to automate our Continuous Deployment flow. There are quite a few improvements we could do. For example, we might use the <em>Pipeline Shared Groovy Libraries Plugin</em> (<a href="https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Shared+Groovy+Libraries+Plugin">https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Shared+Groovy+Libraries+Plugin</a>) and move steps, or even whole stages into functions and reduce code repetition. We could also create a <em>Jenkinsfile</em> (<a href="https://jenkins.io/doc/book/pipeline/jenkinsfile/">https://jenkins.io/doc/book/pipeline/jenkinsfile/</a>) that would move the Pipeline definition from Jenkins into the service repository thus keeping everything related to a single service in one place. We could, also, run production tests continuously (not only when making a new release) and ensure that we are notified if a service is not working or if it does not perform as expected.</p>
<p>We'll leave those and other possible improvements for some other time. While not perfect nor optimum, the go-demo Pipeline should be good enough for now.</p>
<p>It is the time to take a break before diving into the next chapter. As before, we'll destroy the machines we created and start fresh:</p>
<pre>
<strong>docker-machine rm <span class="hljs-operator">-f</span> \<br/>    swarm-<span class="hljs-number">1</span> swarm-<span class="hljs-number">2</span> swarm-<span class="hljs-number">3</span> \<br/>    swarm-test-<span class="hljs-number">1</span> swarm-test-<span class="hljs-number">2 \</span> <br/>    swarm-test-<span class="hljs-number">3</span> swarm-test-<span class="hljs-number">4 </span></strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </body></html>