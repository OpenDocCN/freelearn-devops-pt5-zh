<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch05"/>Chapter 5. Configuring Service Discovery and Docker Networking</h1></div></div></div><p>In this chapter, we will be looking at two very important topics when working with containers. First, we will be looking at what is service discovery, why do we need it, and the different types of service discovery. The second topic we will cover is Docker networking. There are many ways to run container networks. There are some great technologies out there such<a id="id133" class="indexterm"/> as the CoreOS project flannel (<a class="ulink" href="https://coreos.com/flannel/docs/latest/">https://coreos.com/flannel/docs/latest/</a>). There is also Weave from <a id="id134" class="indexterm"/>Weave Works (<a class="ulink" href="http://weave.works/">http://weave.works/</a>), but we are going to use the native Docker networking stack released in engine version 1.9.1.</p><div><div><div><div><h1 class="title"><a id="ch05lvl1sec24"/>Service discovery</h1></div></div></div><p>This is a fairly important topic<a id="id135" class="indexterm"/> in the world of containers, when we start to move into multinode applications and Docker schedulers. The question is what is service discovery? Is it limited to containers? What are the types of service discovery for us to make smart design choices in our Puppet modules.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec32"/>The theory</h2></div></div></div><p>Service discovery is essential when we start to work with multinode applications, as it allows our applications to<a id="id136" class="indexterm"/> talk to each other as they move from node to node. So, as you can see in the world of containers, this is fairly important. We have a few choices when we choose a service discovery backend. The two big names in this <a id="id137" class="indexterm"/>space are <strong>etcd</strong> (<a class="ulink" href="https://coreos.com/etcd/">https://coreos.com/etcd/</a>), which again is from CoreOS, and <strong>Consul</strong> from HashiCorp (<a class="ulink" href="https://www.consul.io/">https://www.consul.io/</a>).</p><p>You might<a id="id138" class="indexterm"/> remember that we have already written a <code class="literal">consul</code> module. So for this chapter, we are going to choose the same, as we already have the written code. First, let's look at the architecture of Consul so we can understand how the backend works, how it handles failure, and what option do we get with our configuration of Consul.</p><p>So, let's talk about how Consul works. In Consul, we have two types of configuration that we can give to a server. First is a server role and the second is an agent role. Although the two interact, they serve different purposes. Lets dive into the server role first. The server's role is to participate in the RAFT quorum; this is to maintain the state of the cluster. In Consul, we have the idea of data centers. What is a data centre, you may ask? It is a group of logical servers and agents. For example, if you are an AWS, a data center could be an AZ or even<a id="id139" class="indexterm"/> a VPC. Consul allows connectivity between data centers; it is the role of the sever to look after the communications between data centers. Consul uses the gossip protocol to achieve this. The server also holds the key/value store and replicates it between the servers using the serf protocol. Let's look at a diagram of what we discussed:</p><div><img src="img/B05201_05_01.jpg" alt="The theory"/></div><p>The agent's role is to report to the server about the state of the machine and any health checks that may be assigned to it. Again, Consul will use the serf protocol to pass the communication.</p><p>Now that we have an understanding of what Consul is doing behind the scenes, let's look at the features that it has that we can take advantage of in our Puppet modules. The first feature we will take advantage of is DNS service discovery. In the container world, this is pretty important. As our containers move from node to node, we need to know how to connect to them. DNS service discovery solves this very neatly. So, let's look at an example to understand this.</p><p>In this example, we have a <strong>mario</strong> service and we have <strong>Docker swarm cluster</strong> of three nodes. When we hit the Docker API and swarm schedules the container, we don't know which of the three machines <strong>mario</strong> will end up on. But we have other services that will need to find <strong>mario</strong> as <a id="id140" class="indexterm"/>soon as he is up. If we tell the other services that <strong>mario</strong> is actually at <strong>mario.service.consul</strong>, no matter what node the container comes up on, it will resolve <strong>mario.service.consul</strong> to the right address. Refer to the following diagram to understand this in detail:</p><div><img src="img/B05201_05_02.jpg" alt="The theory"/></div><p>In this case, if we were to ping <strong>mario.service.consul</strong>, we would get <strong>192.168.100.11</strong>. Pending our scheduling configuration in swarm, if <strong>Server b</strong> fails, <strong>mario.service.consul</strong> could end up on <strong>Server d</strong>. So, the response to <strong>mario.service.consul</strong> would now come from <strong>192.168.100.13</strong>. This would take no human intervention and would be seamless to the applications. That is all the theory<a id="id141" class="indexterm"/> we will see for service discovery in this chapter; there is more that we will cover in the later chapters. Now, let's get to writing some code.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec33"/>The service discovery module</h2></div></div></div><p>In this module, we are going to write a module that uses consul as our DNS service discovery backend. As we <a id="id142" class="indexterm"/>already have a consul module, we won't start from scratch but add new features to the existing module. We will again write the module with manifests and Docker Compose. So, let's start with the manifests.</p><p>Our folder structure should look like this:</p><div><img src="img/B05201_05_03.jpg" alt="The service discovery module"/></div><p>Let's jump straight to <code class="literal">install.pp</code>. Without making any changes, it should look as shown in the following screenshot:</p><div><img src="img/B05201_05_04.jpg" alt="The service discovery module"/></div><p>Now, we are going to add one extra container that is going to be part of the plumbing for our DNS service discovery solution. We will need something to register our containers with Consul as they <a id="id143" class="indexterm"/>spawn. For this, we will use a golang application<a id="id144" class="indexterm"/> called <strong>registrator</strong> (<a class="ulink" href="https://github.com/gliderlabs/registrator">https://github.com/gliderlabs/registrator</a>). This is a fantastic app. I have been using it for over a year, and it has been faultless. So, let's make changes to our <code class="literal">params.pp</code> file to allow the new container. At the moment, <code class="literal">params.pp</code> looks like the one shown in the following screenshot:</p><div><img src="img/B05201_05_05.jpg" alt="The service discovery module"/></div><p>The first thing that we will do is make changes to the <code class="literal">docker_image</code> and <code class="literal">container_hostname</code> parameters. As we already have the convention of <code class="literal">consul_xxx</code>, we can carry on with that:</p><div><img src="img/B05201_05_06.jpg" alt="The service discovery module"/></div><p>Now, let's add the <a id="id145" class="indexterm"/>parameters for registrator:</p><div><img src="img/B05201_05_07.jpg" alt="The service discovery module"/></div><p>As you can see, we have <a id="id146" class="indexterm"/>added the parameter for the image as <code class="literal">$reg_docker_image = 'gliderlabs/registrator'</code> and the parameter for the hostname as <code class="literal">$reg_container_hostname = 'registrator'</code>. We have told the container to listen to the host's <code class="literal">$reg_net = 'host'</code> network. The next parameter will need some explaining. The registrator maps the Unix socket that the Docker daemon is bound to into its Unix socket. It does this to listen to any new services that get spawned and need to be registered in consul for discovery. As you can see, we do this with <code class="literal">$reg_volume = ['/var/run/docker.sock:/tmp/docker.sock']</code>. The last parameter tells registrator where to find <code class="literal">consul</code>. We are going to set that with <code class="literal">$reg_command = "consul://$::ipaddress_enp0s8:8500"</code>. Now, let's move over to our <code class="literal">init.pp</code> file.</p><p>Our <code class="literal">init.pp</code> file should look as shown in the following screenshot:</p><div><img src="img/B05201_05_08.jpg" alt="The service discovery module"/></div><p>Let's add our new <a id="id147" class="indexterm"/>parameters, as shown in the following screenshot:</p><div><img src="img/B05201_05_09.jpg" alt="The service discovery module"/></div><p>Now that we have all our parameters set up, we can go to our <code class="literal">install.pp</code> file to add our code in order to install registrator:</p><div><img src="img/B05201_05_10.jpg" alt="The service discovery module"/></div><p>As you can see in the preceding screenshot, we have added a new block of code at the bottom of our file. It's similar to our code that configures Consul; however, there are a few different parameters. We covered those earlier, so let's not repeat ourselves. Now that we've made a fair chunk of changes to our module, we should run it in Vagrant to check whether we have any issues. Before we can run Vagrant, we need to change our <code class="literal">servers.yaml</code> file in the<a id="id148" class="indexterm"/> root of our Vagrant repo so that it allows us to hit the Consul URL on port <code class="literal">8500</code>. We do this with the following change to the code:</p><div><img src="img/B05201_05_11.jpg" alt="The service discovery module"/></div><p>Now, let's open our terminal and change the directory to the root of our Vagrant repo. From there, we will just issue the <code class="literal">vagrant up</code> command. The output from our terminal should look as shown in the following screenshot:</p><div><img src="img/B05201_05_12.jpg" alt="The service discovery module"/></div><p>After this, let's open our browser and go to <code class="literal">127.0.0.1:8500</code>:</p><div><img src="img/B05201_05_13.jpg" alt="The service discovery module"/></div><p>You will notice now that there are a lot more services listed in the Consul web UI than when we ran the module in the last chapter. This is because now, registrator is listening on the Unix <a id="id149" class="indexterm"/>socket, and any container with a port mapped to the host will be registered. So the good news is that our module is working. Now, let's add an application to the module.</p><p>The easiest way to do this is to add another container module to our node. So, let's add our <code class="literal">bitbucket</code> module. We do this by adding the class to our <code class="literal">default.pp</code> file that lives in our <code class="literal">manifests</code> directory:</p><div><img src="img/B05201_05_14.jpg" alt="The service discovery module"/></div><p>We will also need to make some quick modifications to the <code class="literal">bitbucket</code> module so that we don't get duplicate declaration errors. Note that this is not something you would do in production. But it is good enough for our test lab. We need to comment out the top block of code as shown in the<a id="id150" class="indexterm"/> following screenshot:</p><div><img src="img/B05201_05_15.jpg" alt="The service discovery module"/></div><p>We can even comment out the code as shown in the following screenshot:</p><div><img src="img/B05201_05_16.jpg" alt="The service discovery module"/></div><p>This depends on whether<a id="id151" class="indexterm"/> you used the <code class="literal">manifest</code> module or the <code class="literal">compose</code> module. I used the <code class="literal">compose</code> module.</p><p>So, let's go back to our terminal in the root of our Vagrant repo and issue the <code class="literal">vagrant provision</code> command. The output of the terminal should look as shown in the following screenshot:</p><div><img src="img/B05201_05_17.jpg" alt="The service discovery module"/></div><p>Now, let's look at our<a id="id152" class="indexterm"/> browser again. We can see that our <code class="literal">bitbucket</code> services have been registered, as shown in this screenshot:</p><div><img src="img/B05201_05_18.jpg" alt="The service discovery module"/></div><p>We have the service discovery working; however, we still need to add another class to our module for DNS service discovery. So, let's go back to our <code class="literal">consul</code> module. We will add a new file called <code class="literal">package.pp</code>. In this file, we will install the bind package and add two templates, one to<a id="id153" class="indexterm"/> configure <code class="literal">named.conf</code> and the other to configure <code class="literal">consul.conf</code> in the directory named <code class="literal">/etc/</code>. Let's start coding. The first thing we will need to do is create our <code class="literal">package.pp</code> file in the <code class="literal">manifests</code> directory of our module:</p><div><img src="img/B05201_05_19.jpg" alt="The service discovery module"/></div><p>We will add the following code to the file:</p><div><img src="img/B05201_05_20.jpg" alt="The service discovery module"/></div><p>Now, let's create<a id="id154" class="indexterm"/> a <code class="literal">templates</code> folder. In this example, we are not parameterizing the files, and in a production instance, you would. That's why we are using the <code class="literal">templates</code> folder and not files:</p><div><img src="img/B05201_05_21.jpg" alt="The service discovery module"/></div><p>Now, let's create a file <a id="id155" class="indexterm"/>called <code class="literal">named.conf.erb</code> and add the following code to it:</p><div><img src="img/B05201_05_22.jpg" alt="The service discovery module"/></div><p>The code is just setting our DNS resolver to listen to <code class="literal">127.0.0.1</code>. Remember that we have set port forwarding<a id="id156" class="indexterm"/> on our Consul container to forward port <code class="literal">53</code>. That is how the host will connect to the container. Lastly, it will call our next template file <code class="literal">/etc/named/consul.conf</code>. Let's create that now:</p><div><img src="img/B05201_05_23.jpg" alt="The service discovery module"/></div><p>The code that we will add is as follows:</p><div><img src="img/B05201_05_24.jpg" alt="The service discovery module"/></div><p>You will note that <a id="id157" class="indexterm"/>we are forwarding port <code class="literal">8600</code>, which is the port that Consul uses for its DNS traffic, and removing port <code class="literal">53</code>. As TCP bind will use port <code class="literal">53</code>, we will forward the request to <code class="literal">8600</code>, as shown in the following piece of code:</p><div><img src="img/B05201_05_25.jpg" alt="The service discovery module"/></div><p>We need to make one more change before we can run Puppet. We need to add the new code of <code class="literal">package.pp</code> to our <code class="literal">init.pp</code> file. We can do so like this:</p><div><img src="img/B05201_05_26.jpg" alt="The service discovery module"/></div><p>Now, we can run our <a id="id158" class="indexterm"/>module. Let's go to the terminal and change to root of our Vagrant repo. We will issue the <code class="literal">vagrant up</code> command and if you already have a box running, just issue the <code class="literal">vagrant destroy -f &amp;&amp; vagrant up</code> command. Now, let's check the web UI (<code class="literal">127.0.0.1:8500</code>):</p><div><img src="img/B05201_05_28.jpg" alt="The service discovery module"/></div><p>As you can see in the preceding screenshot, we have a new service registered on port <code class="literal">8600</code> (<code class="literal">consul-8600</code>). Now, we need to make sure that our machines are listening to the right DNS servers on their interfaces. We are going to do this in <code class="literal">servers.yaml</code>, as I would usually add this configuration to my user data in AWS. You could very well control this with Puppet. So, in future, you can decide the right place for the configuration of your<a id="id159" class="indexterm"/> environment. The line we are going to add is <code class="literal">- { shell: 'echo -e "PEERDNS=no\nDNS1=127.0.0.1\nDNS2=8.8.8.8"&gt;&gt;/etc/sysconfig/network-scripts/ifcfg-enp0s3 &amp;&amp; systemctl restart network'}</code>. We will add it as shown in the following screenshot:</p><div><img src="img/B05201_05_29.jpg" alt="The service discovery module"/></div><p>Now, let's go to our terminal and issue the <code class="literal">vagrant up</code> command. If you have a box already running then issue the <code class="literal">vagrant destroy -f &amp;&amp; vagrant up</code> command. The terminal output should look like the one shown in the following screenshot:</p><div><img src="img/B05201_05_30.jpg" alt="The service discovery module"/></div><p>We can then log in to our vagrant box using <code class="literal">vagrant ssh</code> and test whether our DNS setup works. We can <a id="id160" class="indexterm"/>do this by selecting a service and trying to ping it. We are going to choose our <code class="literal">ping bitbucket-server-7990</code> service by entering the <code class="literal">ping bitbucket-server-7990.service.consul</code> command, and we should get the following results:</p><div><img src="img/B05201_05_31.jpg" alt="The service discovery module"/></div><p>As you can see in the preceding screenshot, it returns the echo response as the loopback, as the service is running locally on this host. If we were external of the host, it would return the IP of the host that is running the service. Now, we run our container schedulers, such as <a id="id161" class="indexterm"/>Docker swarm, that have multiple host. We now know how service discovery works.</p><p>Now, let's have a look at what this would look like using Docker Compose.</p><p>In order to not repeat ourselves, let's make our <code class="literal">init.pp</code> file the same as the module that uses the <code class="literal">manifests</code> method. We have to make one small change to the <code class="literal">params.pp</code> file; <code class="literal">docker-compose</code> expects that you pass it strings. So, we need to remove the brackets around <code class="literal">$reg_volume</code> as shown in the following screenshot:</p><div><img src="img/B05201_05_32.jpg" alt="The service discovery module"/></div><p>Then, we will add our <code class="literal">package.pp</code> file as we did earlier and also create the two templates for our <code class="literal">bind</code> config. Then, we need to update our <code class="literal">docker-compose.yml.erb</code> file in our <code class="literal">templates</code> directory. We need to add our second container, <code class="literal">regisrator</code>. We are going to use the same parameters as we did in the manifest module earlier in this chapter. The code for this should look as shown in the following screenshot:</p><div><img src="img/B05201_05_33.jpg" alt="The service discovery module"/></div><p>You will also note that <a id="id162" class="indexterm"/>we changed the ports on our Consul container as we did earlier in the chapter (we removed port <code class="literal">53</code> and added <code class="literal">8600 tcp/udp</code>). Now, we can go to our terminal, change to root of our Vagrant repo, and issue the <code class="literal">vagrant up</code> command. Our terminal should look like the one shown in the following screenshot:</p><div><img src="img/B05201_05_34.jpg" alt="The service discovery module"/></div><p>Again, we can also check our browser at <code class="literal">127.0.0.1:8500</code>:</p><div><img src="img/B05201_05_35.jpg" alt="The service discovery module"/></div><p>As you can see in the preceding screenshot, it looks the same as it did earlier in the chapter.</p><p>Let's log in to our box and test <a id="id163" class="indexterm"/>our DNS service discovery. For this, enter the <code class="literal">vagrant ssh</code> command and then ping a service. This time, we will choose something different. We will use the <code class="literal">ping consul-8500.service.consul</code> command. We should get the following response after this:</p><div><img src="img/B05201_05_36.jpg" alt="The service discovery module"/></div><p>So that's all for service discovery in this chapter. We will be picking it up again in the container scheduler chapter.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec25"/>Docker networking</h1></div></div></div><p>In this topic, we are going to look at the native networking stack that comes with Docker Engine. There is a wealth of knowledge that you can achieve by reading on this subject. I strongly suggest that <a id="id164" class="indexterm"/>you do, as there is a lot you can do with Docker networking. If you have not used it before, I would suggest that you start reading the guide at <a class="ulink" href="https://docs.docker.com/engine/userguide/networking/dockernetworks/">https://docs.docker.com/engine/userguide/networking/dockernetworks/</a>. From here, you can read<a id="id165" class="indexterm"/> about the different types of drivers, how to use VXLAN to separate your networks, and the best practices when designing your Docker network. We are going to cover the basics now and the more advanced features in later chapters.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec34"/>The prerequisites</h2></div></div></div><p>Before we can even start to code<a id="id166" class="indexterm"/> for our network, there are a few things we need. First, we need a key/value store. Docker will use this to map all the containers, IP addresses, and vxlans that are created. Seeing as there usually would be more than one host attached to a network, the key/value store is usually distributed to give it resiliency against failure. Luckily enough, we have already built a key/value store that we can take advantage of, it's Consul of course. The other configuration that you will need are extra args when we start our Docker Engine. This is to let Docker Engine know how to access the key/value store. These are the basic prerequisites that we need to get coding.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec35"/>The code</h2></div></div></div><p>Let's create our first<a id="id167" class="indexterm"/> Docker network. To do this, we are going to add to our <code class="literal">consul</code> module. I am not going to do this twice for both manifests and <code class="literal">docker-compose</code>, as the configuration can be ported between the two. I am going to use the <code class="literal">docker-compose</code> module for my example. If this is the first time that you are creating a Docker network, it would be a worth while exercise to port the configuration to both. So, lets' start. We are only going to make changes to our <code class="literal">install.pp</code> file. The first change that we are going to make is to our extra arguments for our <code class="literal">docker-engine</code> daemon. We do this by adding the code shown in the following screenshot:</p><div><img src="img/B05201_05_37.jpg" alt="The code"/></div><p>The code sets our key/value store's address and port. Then, it also tells other machines what interface and<a id="id168" class="indexterm"/> port we are advertising our networks on.</p><p>The next code we are going to add will create the network. We will create a new file called <code class="literal">network.pp</code>. Then, we will add the code shown in the following screenshot to it:</p><div><img src="img/B05201_05_38.jpg" alt="The code"/></div><p>The next thing we will have to do is make sure that our classes get installed in the correct order, as the Docker network is dependent on Consul being there. If Consul is not there, our catalogue will fail. So, we need to use the <code class="literal">contain</code> functionality built into Puppet. We do this by adding the code shown in the following screenshot:</p><div><img src="img/B05201_05_39.jpg" alt="The code"/></div><p>As you can see, we<a id="id169" class="indexterm"/> are just setting up a basic network. We could set things such as IP address range, gateway, and so on. If we do that, it would look like this:</p><div><img src="img/B05201_05_40.jpg" alt="The code"/></div><p>Now that we have our code, let's go to our terminal and issue the <code class="literal">vagrant up</code> command from root of our Vagrant repo. Our terminal output should look like the one shown in the following screenshot:</p><div><img src="img/B05201_05_41.jpg" alt="The code"/></div><p>Now, we can check<a id="id170" class="indexterm"/> to make sure that our network is there by logging in to our vagrant box (<code class="literal">vagrant ssh</code> from the root of our Vagrant repo). Once we log in to our box, we need to change to root (<code class="literal">sudo -i</code>) and then issue the <code class="literal">docker network ls</code> command. This will list the available networks on the box. The one we are looking for is <code class="literal">docker-internal</code> with the <code class="literal">overlay</code> driver:</p><div><img src="img/B05201_05_42.jpg" alt="The code"/></div><p>As you can see from the output of our terminal, we were successful and our network has been configured. That is all we are going to do with networking in this chapter. In the next chapter, we will be attaching containers and spanning our Docker network across multiple hosts.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec26"/>Summary</h1></div></div></div><p>In this chapter, you learned a lot about how the container ecosystem handles service discovery. I can't emphasize on how important it will be to understand this topic when you start using containers at scale. I would really suggest that you get a solid understanding of service discovery before moving on to further chapters. We also covered the basics of Docker networking. Don't worry, as in the next chapter, we will go into Docker networking in more depth as we will be building multihost applications.</p></div></body></html>