- en: Managing Containers with OpenShift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using a comprehensive suite of some of the best and most resilient open source
    tooling available, Kubernetes is rapidly changing the way that software applications
    are being built and deployed across organizations and in the cloud. Kubernetes
    brings with it lessons learned from deploying a containerized infrastructure across
    a company with one of the largest and most robust infrastructure footprints: Google.
    As we saw in the previous chapter, Kubernetes is an incredibly flexible and reliable
    platform for deploying containers at a very high scale, bringing with it the features
    and functionality to deploy highly available applications across clusters of servers,
    by running on top of native container engines such as `Docker`, `rkt`, and `Runc`.
    However, with the great power and flexibility Kubernetes brings, also comes great
    complexity. Arguably, one of the biggest downsides to deploying a containerized
    infrastructure using Kubernetes is the high degree of knowledge regarding the
    Kubernetes architecture that one must acquire prior to migrating workloads over
    to Kubernetes.'
  prefs: []
  type: TYPE_NORMAL
- en: There is a solution to the high degree of overhead and technical complexity
    that puts Kubernetes out of the reach of many organizations today. In recent years,
    Red Hat has developed an answer to the problem of simplifying Kubernetes concepts
    and making the platform more accessible for software developers and DevOps engineers
    to quickly deploy and rapidly build upon. OpenShift is a suite of tools developed
    by Red Hat that runs on top of the Red Hat distribution of Kubernetes that provides
    a sophisticated, yet easy to understand platform for automating and simplifying
    the deployment of containerized applications. The aim of OpenShift is to provide
    a reliable and secure Kubernetes environment that provides users with a streamlined
    web interface and command-line tool used for deploying, scaling, and monitoring
    applications running in Kubernetes. Furthermore, OpenShift is the second of the
    major cloud providers currently supported by the Ansible Container project (Kubernetes
    and OpenShift).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is OpenShift?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Minishift locally
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying containers from the web interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenShift web interface tips
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to the OpenShift CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenShift and Ansible Container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is OpenShift?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'OpenShift is a suite of products available from Red Hat for building a production-ready,
    reliable, and secure Kubernetes platform. Using OpenShift, developers have a tremendous
    amount of freedom when deploying containerized applications using the OpenShift
    API, or accessing the Kubernetes API to fine-tune functionality and features.
    Since OpenShift uses the same underlying container runtime environments, Docker
    containers can be developed locally and deployed to OpenShift, which leverages
    all of the Kubernetes primitives, such as namespaces, pods, and deployments, to
    expose services to the outside world. At the time of writing, Red Hat offers the
    OpenShift platform with the following configuration options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**OpenShift Origin**: A fully free and open source version of OpenShift that
    is community-supported. OpenShift Origin can be deployed locally using a project
    known as **Minishift**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenShift Online**: OpenShift Online is a fully hosted public cloud offering
    from Red Hat that allows individuals and organizations to take advantage of OpenShift
    Origin without committing hardware resources to deploying OpenShift on-premise.
    Users can sign up for OpenShift online free-tier accounts that allow for application
    deployments up to 1 gigabyte of RAM, and two vCPUs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenShift Dedicated/Container Platform**: OpenShift Dedicated and the OpenShift
    Container Platform provide robust and scalable deployments of OpenShift that are
    managed and supported by Red Hat either on-premises or through public cloud providers
    such as Google Cloud, Azure, or AWS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throughout the course of this chapter, and going forward into the next chapters,
    we will be using the fully free and open source OpenShift Origin to deploy a local
    Minishift cluster. Unlike the previous chapter, the free-tier version of OpenShift
    is unfortunately too limited to cover the breadth of examples this chapter is
    going to cover. In an effort to fully demonstrate the capabilities of OpenShift,
    I have opted to walk the user through a local installation of Minishift that is
    only limited by the hardware running on your local workstation. If you have been
    tracking with us thus far, Minishift is not much more complicated to set up on
    VirtualBox than the local Vagrant lab environment we have been using. However,
    if you want to use the free tier of OpenShift Online, most of these examples can
    replicated there, albeit in a more limited way than running Minishift in your
    local environment.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Minishift locally
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Minishift is a local OpenShift cluster that can be downloaded and run on your
    local PC to function as a development environment. The primary use case for Minishift
    is to provide a sandbox that gives developers a functional development environment
    that can be launched on your laptop. Minishift is also fully compatible with the
    **OpenShift Client** (**OC**) CLI that is used to work with OpenShift clusters
    using a command-line interface. In this portion of the chapter, we will learn
    how to install Minishift and the OC in order to get it running in your local environment.
    Before proceeding, you need to have VirtualBox installed on your PC; it will function
    as a hypervisor for launching the Minishift VM. For the purposes of this demonstration,
    we will be using Minishift version 1.7.0\. Since the time of writing, newer versions
    of Minishift will have undoubtedly been released. To have the best experience
    working with Minishift, I would suggest you download the 1.7.0 release, although
    newer releases will most likely work just as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, Minishift and the OC are available cross-platform on Windows,
    Linux, and macOS. This example is going to demonstrate downloading and installing
    Minishift on Linux. For more information about installing Minishift on other platforms,
    I have provided the following link: [https://docs.openshift.org/latest/minishift/getting-started/installing.html](https://docs.openshift.org/latest/minishift/getting-started/installing.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Installing the Minishift binaries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The proceeding steps should be executed on your local workstation (not the
    Vagrant lab VM) to install Minishift locally:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Download the Minishift binary**: The Minishift 1.7.0 binary can be downloaded
    from the following GitHub URL for all platforms ([https://github.com/minishift/minishift/releases/tag/v1.7.0](https://github.com/minishift/minishift/releases/tag/v1.7.0)).
    You may download this binary using a web browser, or by using `wget` as in this
    example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Unpack the Minishift archive**: Minishift comes packaged in an archive format
    compatible with your operating system. For Linux and OSX, this is a zipped tarball.
    For Windows, the format is a zipped archive:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Copy the Minishift binary to your executable path**: Copying the Minishift
    binary to your local executable path will ensure the `minishift` command can be
    executed from your command line in any context. In Linux, a common path location
    is `/usr/local/bin`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You may need to check the permissions on the binary to ensure they are set to
    executable, for example, `chmod +x /usr/local/bin/minishift`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Validate the installation**: Executing the `minishift version` command should
    return the relevant Minishift version details, in this case, 1.7.0:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Download the OC binary**: The OC can be downloaded for Windows, macOS, or
    Linux at the following URL: [https://mirror.openshift.com/pub/openshift-v3/clients/3.6.173.0.5/](https://mirror.openshift.com/pub/openshift-v3/clients/3.6.173.0.5/).
    For this demonstration, we will be using version 3.6 of the OC client. Similar
    to MiniShift, newer versions might have been released since the time of writing.
    For maximum compatibility with the examples, I suggest you use version 3.6:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**Extract the OC client archive**: After extracting this archive, a single
    binary, `oc`, will be extracted. This is the executable binary for the OC:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**Copy the OC to your executable path**: Similar to the Minishift installation,
    we will copy the OC binary to an executable path location:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**Validate installation**: Execute the `oc version` command to ensure the OC
    has been installed successfully and to return the relevant version details:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Start the Minishift cluster**: Now that Minishift and the OC are installed,
    we start the Minishift cluster using the `minishift start` command. By default,
    Minishift will start by expecting to use the KVM hypervisor and approximately
    2 GB of memory. We are going to modify this slightly to use the VirtualBox hypervisor,
    8 GB of RAM, and 50 GB of storage. Once the Minishift cluster has launched, it
    will return a URL you can use to access the OpenShift console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: If you do not have enough resources to allocate 8 GB of RAM to the Minishift
    deployment, most of these examples can be run using the default 2 GB of RAM.
  prefs: []
  type: TYPE_NORMAL
- en: '**Relax the default security permissions**: On the backend, OpenShift is a
    highly secured Kubernetes cluster that does not allow containers to run a local
    root user. Before we dive into our new Minishift installation, we need to first
    relax the default security context constraints so that we can run any Docker image.
    Since this is a development environment, this will give us more freedom to explore
    the platform and run different workloads. In order to do this, we will use the
    OC to log in as the system administrator. From there, we can use the `oc adm`
    command to add the `anyuid` security context constraint to all authenticated OpenShift
    users:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: It is always a best practice to not modify the OpenShift security context constraints
    in a production deployment. Container images should always be running as their
    own user inside of a Docker container. The unfortunate truth is that many developers
    use the default root user to build and deploy applications. We are relaxing the
    security permissions just so we can explore the platform more freely without the
    limitation of only running containers built and run using a dedicated user.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you have finished working in the Minishift environment, make sure you
    stop the Minishift VM using the `minishift stop` command, as shown in the following
    snippet. Unlike destroying your local Vagrant lab, the Minishift instance will
    retain running deployments and service artifacts the next time the VM is started:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Deploying containers using the web interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you may have noticed, when the `minishift start` command completed, it provided
    an IP address that you can use to access the web user interface. One of the biggest
    benefits of using OpenShift over standard Kubernetes is that OpenShift exposes
    almost all of Kubernetes'' core functionality through an intuitive web interface.
    The OpenShift console works in a similar way to other cloud or service dashboards
    you have used in the past. At a glance, you can see which deployments are running,
    triggered alarms caused by failed pods, or even new deployments that other users
    have triggered in the project. To access the web interface, simply copy and paste
    the IP address in the output of the `minishift start` command in any modern web
    browser installed on your local machine. You may then have to accept the self-signed
    SSL certificate that comes with Minishift by default, after which you will be
    prompted with a login screen similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15cb9fbf-7a8b-4b31-a7c3-ae53f29d09e7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: OpenShift login page'
  prefs: []
  type: TYPE_NORMAL
- en: The default credentials to access Minishift are the username `developer` and
    any password you want. It is not important to remember the password you enter,
    as each time you authenticate as the developer user, you can simply supply any
    password. Upon successfully logging in, you will be asked to access a project.
    The default project that Minishift provides for you is called My Project. For
    the sake of simplicity, we will use this project for the following lab examples,
    which you can follow along with.
  prefs: []
  type: TYPE_NORMAL
- en: 'The web interface is laid out by two primary navigation bars along the left
    and top of the screen, while the central portion of the interface is reserved
    for showing details about the environment you are currently accessing, modifying
    settings, or deleting resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e1a7b9ed-939f-42d8-94c7-d1b1d71f686b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Initial OpenShift project'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you are familiar with the OpenShift user interface, let''s create
    a deployment and see what it looks like when pods are running in the cluster.
    The functionality for creating new pods and deployments can be found towards the
    top of the screen by selecting the Add to Project drop-down box:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/46e15305-d61e-4472-911b-5656098738d2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Adding services to your project'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a new deployment in a variety of different ways. The default
    options OpenShift provides is to browse a catalog of pre-built images and services,
    deploy an image based on a container registry URL, or importing a YAML or JSON
    manifest that describes the services we are building. Let''s deploy one of the
    catalog services found in the web interface. Selecting the Browse Catalog option
    from the Add to Project drop-down will open a screen for the OpenShift catalog.
    Any of the OpenShift examples found in the catalog will run well in OpenShift,
    but for demonstration purposes let''s deploy the framework for a simple Python
    application. To do this, click on the catalog option for Python, then the Python
    3.5 Source Code Application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/715072cf-e8de-4da9-9397-2f8e44f58a93.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Creating a simple Python service from the OpenShift catalog'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the next screen, OpenShift will prompt you for options to deploy your application
    with, namely a source code repository, which contains Python source code, and
    an application name. You can choose any name for the Python application. For this
    example, I will name mine `oc-test-deployment`. Since we do not have a pre-developed
    Python application, we can click on the Try It link below the Git Repository URL
    textbox to use the demo application provided by OpenShift:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/544fad49-bc55-467e-a7c2-714fbe326997.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Modifying the attributes of the Python application'
  prefs: []
  type: TYPE_NORMAL
- en: If you are a Python developer and have a Django application you would like to
    deploy instead, feel free to use another Git repository in place of the demo one!
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on the blue Create button will initiate the deployment and launch
    the container. Depending on the specifications of your workstation, it might take
    a while for the service to fully deploy. While it is deploying, you can watch
    the various stages of the deployment by clicking through the pages of the user
    interface. For example, clicking on Pods in the sidebar will show pods as they
    are created and go through the various stages to become available in Kubernetes.
    OpenShift shows circular graphs that describe the state of the resources that
    are running. Pods that are healthy, responding to requests, and running as intended
    are shown by blue circles. Other Kubernetes resources that might not be running
    as intended, throwing errors or warnings instead, are represented by yellow or
    red circles. This provides an intuitive way to understand how the services are
    running at a glance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/916fb49b-38b7-49a9-98ff-b4a160403352.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: A successfully created test Python application'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the service has been deployed fully, OpenShift will provide a link to
    access the service. In OpenShift vernacular, this is known as a **route**. Routes
    function in a similar way to exposed services in Kubernetes, with the exception
    that they leverage `nip.io` DNS forwarding by default. You might notice that the
    service route pointing to the service we just created has the fully qualified
    domain name `servicename.ipaddress.nip.io`. This provides the user with routable
    access to reach the Kubernetes cluster without the hassle of configuring external
    load balancers or service proxies. Accessing that URL in a web browser should
    open a page that looks similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8526b6f0-3366-4ef2-b012-d0d266af1974.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Python application test page'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the default Python-Django index page for this simple demo application.
    If we click back on the OpenShift console, we can go into more detail regarding
    the pods that are running in this deployment. Similar to kubectl, OpenShift can
    give us details about the deployment, including running pods, log events, and
    even allow us to customize the deployment from the web user interface. To view
    these details, select Applications | Deployments and click on the deployment you
    wish to look up. In this case, we will look at the details of the only running
    deployment we have, `oc-test-deployment`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e02c7343-5efb-44fc-ae88-b16c5444282c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: OpenShift deployments page'
  prefs: []
  type: TYPE_NORMAL
- en: 'From this page, we can view the history of containers, modify the configuration,
    check or change environment variables, and view the most recent event logs from
    the deployment. In the upper-right corner of the screen, the Actions drop-down
    box gives us even more options for adding storage, autoscaling rules, and even
    modifying the Kubernetes manifest used to deploy this service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2e966335-4c18-499b-a38f-eeba5190afb9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Managing OpenShift applications and deployments'
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift provides a great interface for tweaking manifests and experimenting
    with changes in real time. The OpenShift user interface will give you feedback
    on changes you make and let you know when there are potential problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Information related to the running pods within the deployment can also be accessed
    through the web user interface. From the Applications menu, select Pods and click
    on the pod you wish to view information for. In this case, we have a single running
    pod, `oc-test-deployment-1-l18l8`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b49c4dbd-c722-4075-acd8-74720f610a54.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Viewing pods within application deployments'
  prefs: []
  type: TYPE_NORMAL
- en: 'On this page, we can view almost any pertinent detail regarding the pods that
    are running within any of our deployments. From this screen you can view environment
    configurations, access container logs in real time, and even log into containers
    through a fully functional terminal emulator:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e53f306-aab2-4a46-b24b-f98576bb09a2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Viewing pod-specific details in OpenShift'
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the Deployments menu, we can select the Actions drop-down menu from
    this screen as well to modify container settings in the YAML editor, or mount
    storage volumes inside the container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, using the OpenShift web interface, we can delete deployments and pods.
    Since OpenShift is essentially a layer that functions on top of Kubernetes, we
    need to apply many of the same concepts. In order to delete pods, we must first
    delete the deployment in order to set a new desired state within the Kubernetes
    API. Within OpenShift this can be accomplished by selecting Applications | Deployments
    | Your Deployment (oc-test-deployment). From the Actions drop-down menu, select
    Delete Deployment. OpenShift will prompt you to make sure this is something you
    really want to do; click Delete to finalize the operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/741a8898-5e82-46a9-9346-399fea7c69d7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Deleting deployments in OpenShift'
  prefs: []
  type: TYPE_NORMAL
- en: In a similar fashion, you will have to go to Applications | Service and then Applications |
    Routes in order to delete the services and routes that OpenShift created for the
    service. Once this is complete, the screen produced by clicking on the Overview
    button in the left menu bar will once again be blank, showing that nothing is
    currently running in the OpenShift cluster.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift web user interface tips
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The preceding example walked the user through some of the major OpenShift and
    Kubernetes workflow steps for creating a new deployment, managing the deployment,
    and ultimately deleting the deployment and other resources. OpenShift exposes
    far more functionality through the web user interface than this book has time
    to delve into; I suggest you take time to explore the web interface for yourself
    to truly become familiar with the features that OpenShift provides. For the sake
    of not being monotonous, I have provided a few key features to keep your eyes
    open for in the OpenShift web interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Overview dashboard**: The Overview dashboard can be accessed from the navigation
    bar on the left side of the screen. The overview dashboard shows information about
    the most recent activity inside the OpenShift cluster. This is useful for accessing
    the latest deployments and having single-click access to various cluster resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Applications menu**: The Applications menu is a single location to view or
    modify any deployments or pods that are running across the OpenShift cluster.
    From Applications, you can access information related to deployments, pods, stateful
    sets, services, and routes. Think of the Applications menu as a single stop for
    anything related to the configuration of containers running within the cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Builds dashboard**: The Builds dashboard features a light **continuous integration**
    **continuous** **delivery** (**CICD**) workflow for Kubernetes. This is useful
    for triggering image builds, establishing Jenkins-enabled workflow pipelines,
    and building automation into OpenShift projects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resources menu**: The Resources menu is used primarily to define quotas and
    user account privileges used to manage access and limits for users and projects
    within the OpenShift cluster. Also defined here is a lightweight secret storage
    interface, as well as config map options to define the configurations for containers
    within OpenShift projects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage dashboard**: The Storage dashboard is used to display information
    regarding persistent volume claims used by containers and deployments on the underlying
    hardware or VM OpenShift is running on. Volume claims can be created or deleted
    from this portion of the web interface, as well as managed or modified depending
    on new or changing requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring dashboard**: Finally, the Monitoring dashboard provides the user
    with details about running pods, triggered events, as well as the historical context
    regarding the changes in the environment leading up to the events listed. Monitoring
    can be easily tied to build a pipeline or even used to report on configured service
    health checks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leveraging the robust suite of tools provided by OpenShift helps to abstract
    and simplify many of the Kubernetes concepts we learned about in [Chapter 5](ccc07e61-25e7-4984-953b-586b28b12aab.xhtml), *Containers
    at Scale with Kubernetes*.
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to the OpenShift CLI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The second primary way that users can interact with the OpenShift platform
    is through the OpenShift command-line interface, OC (short for OpenShift Client).
    The OpenShift command-line interface uses many of the same concepts we explored
    in [Chapter 5](ccc07e61-25e7-4984-953b-586b28b12aab.xhtml), *Containers at Scale
    with Kubernetes*, using the `kubectl` command line interface for managing pods,
    deployments, and exposing services. However, the OpenShift client also supports
    many of the features that are specific to OpenShift, such as creating routes to
    expose deployments and working with integrated security context constraints for
    access control. Throughout this section, we will look at how to use the OC to
    accomplish some of the basic workflow concepts we explored through the web user
    interface, such as creating deployments, creating routes, and working with running
    containers. Finally, we will look at some tips for diving deeper with the OC and
    some of the more advanced features that are available. Before proceeding, ensure
    the OC is installed (see the beginning of this chapter for installation details):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Logging into OpenShift**: Similar to the web user interface, we can use the
    CLI to log into our local OpenShift cluster using the `oc login` command. The
    basic syntax for this command is `oc login URL:PORT`, where the user replaces
    the URL and port with the URL and port number of the OpenShift environment they
    are logging into. Upon successful login, the prompt will return `Login Successful`
    and grant you access to your default project. In this case, we will log into our
    local environment at `192.168.99.100`, using the `developer` username and anything
    as the password:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '**Check status using OC status**: The `oc status` command is used in a similar
    way to the Overview dashboard in the web user interface to show critical services
    deployed in the environment, running pods, or anything in the cluster that might
    be triggering an alarm. Simply typing `oc status` will not return anything, since
    we deleted the deployments, routes, and services we created through the web user
    interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '**Create an OpenShift deployment**: Deployments and other cluster resources
    can easily be created using the `oc create` command. Similar to `kubectl`, you
    can create deployments by using the `oc create deployment` command and referencing
    the name of the container image you wish to use. It should be noted that deployment
    names are sensitive to using special characters such as underscores and dashes.
    For the purposes of simplicity, let''s re-create our example from [Chapter 5](ccc07e61-25e7-4984-953b-586b28b12aab.xhtml), *Containers
    at Scale with Kubernetes*, and create a simple NGINX pod using the official NGINX
    Docker image using the `oc create` command and specifying the object as `deployment`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Another similarity to kubectl is that OpenShift supports creating deployments
    based on Kubernetes manifest files using the `-f` option.
  prefs: []
  type: TYPE_NORMAL
- en: '**List pods and view the OC status**: Now that we have a deployment and pod
    running in the OpenShift cluster, we can view running pods using the `oc get pods`
    command, and check the output of the `oc status` command to see an overview of
    the running pods in our cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '**View verbose output using** `oc describe`: Aside from simply listing objects
    that are created and available in the OpenShift cluster, verbose details about
    specific objects can be viewed using the `oc describe` command. Similar to `kubectl
    describe`, `oc describe` allows us to view pertinent details about almost any
    object defined in the cluster. For example, we can use the `oc describe deployment`
    command to view verbose details about the web server deployment we just created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '**Create an OpenShift service**: In order to expose pods that are running in
    the OpenShift cluster, we must first create a service. You may remember from [Chapter
    5](ccc07e61-25e7-4984-953b-586b28b12aab.xhtml), *Containers at Scale with Kubernetes*,
    that Kubernetes services are abstractions that work in a similar way to internal
    load balancers inside of the Kubernetes cluster. Essentially, we are creating
    a single internal (or external) IP address from which traffic from other pods
    or services can access any number of pods matched to a given selector. In OpenShift,
    we will create a service simply called `webserver` that will use an internally
    routed cluster IP address to intercept web server traffic and forward it to the
    web server pod we created as apart of our deployment. By naming our service `webserver`,
    it will by default use a selector criteria that matches the label `app=webserver`.
    This label was created by default when we created the deployment in OpenShift.
    Any number of labels or selector criteria can be created, which allows Kubernetes
    and OpenShift to select pods to load-balance traffic against. For the purposes
    of this example, we will use an internal cluster IP and map the selector criteria
    based on naming our service with the same name we named our deployment. Finally,
    we will select the ports we want to forward from our service externally, to the
    ports the service is listening on inside the container. To keep things simple,
    we will forward traffic destined to port `80` to the pod port `80`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check the service configuration using the `oc get services` command.
    We can see that our service was created with an internally routed cluster address
    of `172.30.136.131`. Yours will most likely differ as these addresses are pulled
    from the CNI subnet within Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '**Create a route to enable access**: Finally, we can create a route to access
    our service using the `oc expose` command, followed by the service name we are
    exposing (`webserver`). To make this routable from our workstation, OpenShift
    uses the `nip.io` DNS forwarding based on the IP address of the VM. We can enable
    this by specifying the `--hostname` flag to be any name we want the service to
    be accessed by, followed by the IP address of the VM, concluding with the suffix `nip.io`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing the `oc get routes` command will display the route we just created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'To ensure the route is working, we can use a web browser and navigate to the
    forwarded DNS address we assigned to the route. If everything is working, we will
    be able to see the NGINX welcome screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6706d81d-e841-4cca-94d7-d6012a7e7492.png)'
  prefs: []
  type: TYPE_IMG
- en: Feel free to continue on deploying more complex containerized applications using
    your local Minishift cluster. When you are finished, make sure you stop the Minishift
    instance using the `minishift stop` command.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift and Ansible Container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen throughout this chapter, OpenShift is a rich platform that provides
    valuable abstractions on top of Kubernetes. As such, Ansible Container provides
    ample support for deploying and running containerized application life cycles
    through OpenShift. Since OpenShift and Ansible Container are both products of
    the same parent company, Red Hat, it is apparent that OpenShift and Ansible Container
    will have excellent compatibility. So far, we have primarily discussed building
    containers using Ansible Container and running them locally on a Docker host.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a firm foundation from which to understand Kubernetes and OpenShift,
    we can combine the knowledge we have gained so far with Ansible Container to learn
    how to use Ansible Container as a true end-to-end production-ready deployment
    and life cycle management solution. Things are about to get interesting!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**OpenShift project**: [https://www.openshift.com/](https://www.openshift.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MiniShift project**: [https://www.openshift.org/minishift/](https://www.openshift.org/minishift/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Installing MiniShift**: [https://docs.openshift.org/latest/minishift/getting-started/installing.html](https://docs.openshift.org/latest/minishift/getting-started/installing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Container orchestration platforms such as Kubernetes and OpenShift are rapidly
    being adopted by organizations to ease the complex process of scaling out applications,
    deploying updates, and ensuring maximum reliability. With the increasing popularity
    of these platforms, it is even more important that we understand the implications
    of adopting these technologies in order to support the organizational and cultural
    shift of mentality these technologies bring to the table.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift is a platform built on top of the Red Hat distribution of Kubernetes
    that aims to provide the best experience for working with Kubernetes. At the beginning
    of the chapter we learned what OpenShift is, and the various capabilities that
    Red Hat is working to deliver with the OpenShift platform. Next, we learned how
    to install the Minishift project, which is a developer-oriented solution for deploying
    OpenShift locally.
  prefs: []
  type: TYPE_NORMAL
- en: Once we had Minishift installed and working locally, we learned how to run pods,
    deployments, services, and routes from the Minishift web user interface. Finally,
    we learned about the OpenShift command-line interface, OC, and how it functions
    in a similar capacity to kubectl to provide CLI access to OpenShift and the innovative
    functionality that OpenShift builds on top of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, my aim is to tie our knowledge of OpenShift and Kubernetes
    back into Ansible Container to learn about the final step in the Ansible Container
    workflow, deployment. The deployment functionality sets Ansible Container apart
    as a truly robust tool for not only building and testing container images, but
    also for deploying them all the way through to containerized production environments
    running on Kubernetes and OpenShift.
  prefs: []
  type: TYPE_NORMAL
