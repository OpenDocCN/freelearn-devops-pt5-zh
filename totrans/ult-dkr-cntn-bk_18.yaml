- en: '18'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running a Containerized Application in the Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned how to deploy, update, and scale applications
    into a Kubernetes cluster. We discovered how zero-downtime deployments are achieved
    to enable disruption-free updates and rollbacks of mission-critical applications.
    Finally, we were introduced to Kubernetes secrets as a means to configure services
    and protect sensitive data.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will give an overview of the three most popular ways of
    running containerized applications in the cloud. We will explore each of the hosted
    solutions and discuss their pros and cons.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the topics we will be discussing in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Why choose a hosted Kubernetes service?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a simple containerized application on **Amazon Elastic Kubernetes Service**
    (**Amazon EKS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring Microsoft’s **Azure Kubernetes** **Service** (**AKS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding **Google Kubernetes** **Engine** (**GKE**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After reading this chapter, you will be able to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Reason about the pros and potential cons of a hosted Kubernetes service compared
    to a self-managed Kubernetes cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy and run a simple distributed application in Amazon EKS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy and run a simple distributed application on Microsoft’s AKS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy and run a simple distributed application on GKE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are going to use **Amazon Web Services** (**AWS**), Microsoft Azure, and
    Google Cloud in this chapter; therefore, it is necessary to have an account for
    each platform. If you do not have an existing account, you can ask for a trial
    account for all of these cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll also use the files in the `~/The-Ultimate-Docker-Container-Book/sample-solutions/ch18`
    folder of our lab’s repository from GitHub at [https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch18](https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch18).
  prefs: []
  type: TYPE_NORMAL
- en: 'Prepare the folder where you will put your own code. For this, first, navigate
    to the source folder, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, create a `ch18` subfolder and navigate to it, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Why choose a hosted Kubernetes service?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Currently, the three most popular cloud providers, AWS, Microsoft Azure, and
    Google Cloud each have a managed Kubernetes offering, as outlined here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon EKS**: Amazon EKS is a managed service that makes it easy for you
    to run Kubernetes on AWS without needing to install, operate, and maintain your
    own Kubernetes control plane or nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AKS**: AKS is Microsoft’s managed Kubernetes offering. It offers developer
    productivity with **continuous integration and continuous deployment** (**CI/CD**)
    capabilities and Kubernetes tools integration. It also has an Azure DevOps project
    for a complete container CI/CD platform.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GKE**: Google was the original creator of Kubernetes, and GKE was the first
    managed Kubernetes service available on the market. It offers advanced cluster
    management features, as well as integration with Google Cloud services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other providers also offer **Kubernetes as a service** (**KaaS**), such as IBM
    Cloud Kubernetes Service, Oracle Container Engine for Kubernetes, and **DigitalOcean
    Kubernetes** (**DOKS**). It’s always a good idea to check the latest offerings
    and their features since the cloud market evolves rapidly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Managing a Kubernetes cluster, either on-premises or in the cloud, involves
    considerable operational complexity and requires expertise. Here are a few reasons
    why using a hosted Kubernetes service is often the preferred solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ease of setup and management**: Hosted Kubernetes services handle the underlying
    infrastructure, reducing the operational burden of managing a Kubernetes cluster.
    They automatically take care of the provisioning, upgrades, patching, and scaling
    of the Kubernetes control plane.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High availability (HA) and high scalability**: Hosted services often offer
    out-of-the-box HA and high scalability for your applications. They handle the
    orchestration necessary to distribute applications across different nodes and
    data centers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security and compliance**: Hosted services often include built-in security
    features such as network policies, **role-based access control** (**RBAC**), and
    integration with cloud provider **Identity & Access Management** (**IAM**) services.
    They also handle security updates to the Kubernetes software itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring and diagnostics**: Hosted Kubernetes services typically include
    integration with monitoring and logging services, making it easier to observe
    and troubleshoot your applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost**: While there is a cost associated with using a managed service, it
    can often be less than the cost of the dedicated personnel and infrastructure
    required to operate a Kubernetes cluster efficiently and securely.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Support**: When using a hosted Kubernetes service, you’ll have access to
    support from the cloud provider. This can be particularly valuable if you’re running
    production workloads and need fast resolution of any issues that arise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In contrast, running your own Kubernetes clusters involves significant setup
    and maintenance work. You’re responsible for everything, from the installation
    and configuration of Kubernetes to the ongoing tasks of cluster upgrades, security
    patching, node provisioning, and scaling, as well as setting up monitoring and
    alerting.
  prefs: []
  type: TYPE_NORMAL
- en: While managing your own clusters provides more control and flexibility, it requires
    a substantial investment in time, resources, and expertise. For many organizations,
    the benefits of a managed service far outweigh the increased control of self-managing
    their clusters.
  prefs: []
  type: TYPE_NORMAL
- en: "Running a simple containerized application on \LAmazon EKS"
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we want to create a fully managed Kubernetes cluster on Amazon
    EKS using Fargate. The process of creating a new cluster is well described in
    the AWS documentation, and we will refer to the respective pages to not duplicate
    too much information. That said, let us start with the following steps.
  prefs: []
  type: TYPE_NORMAL
- en: What is Fargate?
  prefs: []
  type: TYPE_NORMAL
- en: AWS Fargate is a serverless compute engine for containers provided by AWS. It
    removes the need to manage the underlying servers and allows you to focus on designing
    and building your applications. Fargate handles the deployment, scaling, and management
    of containers, enabling you to launch applications without worrying about the
    infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us first get a few prerequisites out of the way, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make sure you have access to an AWS account. If not, you can get a free 1-year
    trial account here: [https://aws.amazon.com/free](https://aws.amazon.com/free).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in to your AWS account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new *access key* and *access key secret* pair for your account, which
    you will use to configure your AWS CLI so that you can access your account from
    the command line.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Locate your profile at the top right of the screen, and from the dropdown, select
    **Security credentials**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select **Access keys** (access key ID and secret access key) and then click
    **Create** **access key**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.1 – Note down the access key ID and secret pair in a safe place](img/Figure_18.01_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.1 – Note down the access key ID and secret pair in a safe place
  prefs: []
  type: TYPE_NORMAL
- en: Open a new terminal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make sure you have the AWS CLI installed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On a Mac, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'On Windows, use this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In both cases, test the installation with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Configure your AWS CLI. For this, you need your *AWS access key ID* and *AWS
    secret access key* that you created in preceding *step 3*, as well as your default
    *region*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Enter the appropriate values when asked. For the default output format, select
    `JSON`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.2 – Configuring the AWS CLI](img/Figure_18.02_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.2 – Configuring the AWS CLI
  prefs: []
  type: TYPE_NORMAL
- en: 'Try accessing your account with a command such as the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This should list all the **Simple Storage Service** (**S3**) buckets defined
    for your account. Your list may be empty. The important thing here is that the
    command succeeds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, double-check that you have `kubectl` installed by running the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we are ready to create the Amazon EKS cluster. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a few environment variables for later use, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Make sure to replace `eu-central-1` with the AWS region closest to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now create the necessary AWS stack consisting of VPC, private and public
    subnets, and a security group, using the following command, which—to simplify
    things—uses a sample YAML file from AWS:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Please take a moment to download and inspect the preceding YAML file to understand
    what exactly the command is provisioning.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next few steps, you need to define the right settings to grant the necessary
    access rights to the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Start by creating an IAM role with this command:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Proceed by attaching the necessary Amazon EKS-managed IAM policy to the role
    just created with this command:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, we continue with some interactive steps using the Amazon EKS console at
    [https://console.aws.amazon.com/eks/home#/clusters](https://console.aws.amazon.com/eks/home#/clusters).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that the AWS Region shown in the upper right of your console is the
    AWS Region in which you want to create your cluster in (for example, `eu-central-1)`
    in the author’s case). If it’s not, select the dropdown next to the AWS Region
    name and choose the AWS Region that you want to use.
  prefs: []
  type: TYPE_NORMAL
- en: To create your cluster, choose the **Add cluster** command and then choose **Create**.
    If you don’t see this option, choose **Clusters** in the left navigation pane
    first.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the `animals-cluster`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`animals-cluster-role`. Please select it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All the other settings can be left as their default values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the `vpc-00x0000x000x0x000 | animals-stack-VPC`. Note the postfix of the
    name, indicating it is the one we defined just a moment ago.*   Once again, you
    can leave the remaining settings at their default values.*   Choose **Next** to
    continue.*   We do not need to change anything on the **Configure logging** page,
    so choose **Next**.*   The same applies for the **Select add-ons** page; thus,
    choose **Next**.*   And once again, on the **Configure selected add-ons** settings
    page, there is nothing to do, so choose **Next**.*   Finally, on the **Review
    and create** page, choose **Create**.*   To the right of the cluster’s name, the
    cluster status is **Creating** for several minutes until the cluster provisioning
    process completes, as shown in the following screenshot. Don’t continue to the
    next step until the status is **Active**:![Figure 18.3 – Creating an EKS cluster](img/Figure_18.03_B19199.jpg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 18.3 – Creating an EKS cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'Sadly, we are not done yet. We need to create a trust policy and attach it
    to our cluster. To do this, proceed as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Start by creating a `pod-execution-role-trust-policy.json` file and add the
    following content to it:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code, replace `<region-code>` with the code for your AWS region
    (`eu-central-1` in my case) and `<account-no>` with the number of your account.
    You can find the latter under your profile in the upper left of the AWS console.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the trust policy just provisioned, create a **Pod execution IAM role**
    with this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, connect the required role and policy with each other using this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: On the `animals-cluster` cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the `animals-cluster` page, do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `animals-profile`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For `AmazonEKSFargatePodExecutionRole` role that you created in a previous step.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose the **Subnets** dropdown and deselect any subnet with **Public** in its
    name. Only private subnets are supported for Pods that are running on Fargate.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose **Next**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: On the `default`.*   Then choose **Next**.*   On the **Review and create page**,
    review the information for your Fargate profile and choose **Create**.*   After
    a few minutes, the status in the **Fargate Profile configuration** section will
    change from **Creating** to **Active**. Don’t continue to the next step until
    the status is **Active**.*   If you plan to deploy all Pods to Fargate (none to
    Amazon EC2 nodes), do the following to create another Fargate profile and run
    the default name resolver (CoreDNS) on Fargate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If you don’t do this, you won’t have any nodes at this time.
  prefs: []
  type: TYPE_NORMAL
- en: On the `animals-profile`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Fargate profiles**, choose **Add** **Fargate Profile**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Name** field, enter **CoreDNS**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For `AmazonEKSFargatePodExecutionRole` role that you created in *step 13*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the `Public` in its name. Fargate only supports Pods on private subnets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `kube-system`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose **Match labels**, and then choose **Add label**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter `k8s-app` for `kube-dns` for **Value**. This is necessary for the default
    name resolver (CoreDNS) to deploy to Fargate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the **Review and create** page, review the information for your Fargate profile
    and choose **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the following command to remove the default `eks.amazonaws.com/compute-type
    : ec2` annotation from the CoreDNS Pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The system creates and deploys two nodes based on the Fargate profile label
    you added. You won’t see anything listed in **Node groups** because they aren’t
    applicable to Fargate nodes, but you will see the new nodes listed in the **Compute**
    tab.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a more detailed explanation, you can follow the step-by-step instructions
    at the following link to create your cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.xhtml](https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.xhtml)
    (*Getting started with Amazon EKS – AWS Management Console and* *AWS CLI*)'
  prefs: []
  type: TYPE_NORMAL
- en: 'When your cluster is ready, you can then continue with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Configure `kubectl` to access your new cluster on AWS, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The response should be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Here, `<user-name>` corresponds to your username on the machine you’re working
    on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Double-check that `kubectl` is using the correct context—the one that was just
    created for the cluster on AWS and added to your `~/.``kube/config` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The answer should look similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In case another context is the active one, use the `kubectl config use-context`
    command in combination with the correct AWS context.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `kubectl` to list all the resources on your cluster, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The answer at this time should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.4 – Amazon EKS – kubectl get all](img/Figure_18.04_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.4 – Amazon EKS – kubectl get all
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the nodes of your cluster, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should then see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.5 – List of nodes in the EKS cluster](img/Figure_18.05_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.5 – List of nodes in the EKS cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the `ch18` folder of this chapter, create an `aws-eks` subfolder,
    and then navigate to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In this subfolder, create a `deploy-nginx.yaml` file with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.6 – Deployment specification for nginx on Amazon EKS](img/Figure_18.06_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.6 – Deployment specification for nginx on Amazon EKS
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `kubectl` to deploy our deployment to the cluster, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Observe the creation of the Pods with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And wait until they are ready:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.7 – Listing the Pods of the deployment to AWS](img/Figure_18.07_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.7 – Listing the Pods of the deployment to AWS
  prefs: []
  type: TYPE_NORMAL
- en: Wait until their value in the `1/1`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the AWS console, navigate to your cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `web` Pods and two `coredns` Pods were created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Compute** tab, observe that multiple Fargate nodes have been created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drill down to a node to see the Pod that has been deployed to it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drill further down to the Pod and observe the list of events shown in its **Details**
    view.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Congratulations—you have created a fully hosted Kubernetes cluster on AWS and
    created a first Deployment on it using `kubectl`! As you will know, this is quite
    an achievement. It turns out that of all the discussed cloud providers, AWS requires
    by far the most steps to get a Kubernetes cluster up and running.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you leave, and to avoid unexpected costs, make sure you clean up all
    the resources that you have created during this exercise. For this, follow the
    next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `kubectl` to delete the previous deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Locate your `animals-cluster` cluster and select it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `animals-profile` and `CoreDNS` profiles and delete them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When both profiles are deleted—which may take a few minutes—then click the **Delete
    cluster** button to get rid of the cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete the VPC AWS CloudFormation stack that you created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the **AWS CloudFormation** console at [https://console.aws.amazon.com/cloudformation](https://console.aws.amazon.com/cloudformation).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose the `animals-stack` stack, and then choose **Delete**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Delete animals-stack** confirmation dialog box, choose **Delete stack**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete the IAM roles that you created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the IAM console at [https://console.aws.amazon.com/iam/](https://console.aws.amazon.com/iam/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the left navigation pane, choose **Roles**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select each role you created from the list (`myAmazonEKSClusterRole`, as well
    as `AmazonEKSFargatePodExecutionRole` or `myAmazonEKSNodeRole`). Choose **Delete**,
    enter the requested confirmation text, then choose **Delete**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, follow the steps in the *Step 5: Delete resources* section in
    the AWS documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.xhtml](https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: This was quite an achievement! Creating and managing an EKS cluster requires
    more intimate knowledge of details than we would want. We will see that other
    providers are more user-friendly in that regard.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a rough understanding of what Amazon EKS offers, let us have
    a look at what the second-biggest cloud provider has in its portfolio.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Microsoft’s AKS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To experiment with Microsoft’s container-related offerings in Azure, we need
    an account on Azure. You can create a trial account or use an existing account.
    You can get a free trial account here: [https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/).'
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft offers different container-related services on Azure. The easiest
    one to use is probably Azure Container Instances, which promises the fastest and
    simplest way to run a container in Azure, without having to provision any **virtual
    machines** (**VMs**) and without having to adopt a higher-level service. This
    service is only really useful if you want to run a single container in a hosted
    environment. The setup is quite easy. In the Azure portal ([https://portal.azure.com](https://portal.azure.com)),
    you first create a new resource group and then create an Azure container instance.
    You only need to fill out a short form with properties such as the name of the
    container, the image to use, and the port to open. The container can be made available
    on a public or private IP address and will be automatically restarted if it crashes.
    There is a decent management console available, for example, to monitor resource
    consumption such as CPU and memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second choice is **Azure Container Service** (**ACS**), which provides
    a way to simplify the creation, configuration, and management of a cluster of
    VMs that is preconfigured to run containerized applications. ACS uses Docker images
    and provides a choice between three orchestrators: Kubernetes, Docker Swarm, and
    the **Distributed Cloud Operating System** (**DC/OS**) (powered by Apache Mesos).
    Microsoft claims that its service can be scaled to tens of thousands of containers.
    ACS is free, and you are only charged for computing resources.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will concentrate on the most popular offering, based on
    Kubernetes. It is called AKS and can be found here: [https://azure.microsoft.com/en-us/services/kubernetes-service/](https://azure.microsoft.com/en-us/services/kubernetes-service/).
    AKS makes it easy for you to deploy applications in the cloud and run them on
    Kubernetes. All the difficult and tedious management tasks are handled by Microsoft,
    and you can concentrate fully on your applications. What that means is that you
    will never have to deal with tasks such as installing and managing Kubernetes,
    upgrading Kubernetes, or upgrading the operating system of the underlying Kubernetes
    nodes. All this is handled by the experts at Microsoft Azure. Furthermore, you
    will never have to deal with `etc` or Kubernetes master nodes. This is all hidden
    from you, and the only things you will interact with are the Kubernetes worker
    nodes that run your applications.'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the Azure CLI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: That said, let’s start. We assume that you have created a free trial account
    or that you are using an existing account on Azure. There are various ways to
    interact with your Azure account. We will use the Azure CLI running on our local
    computer. We can either download and install the Azure CLI natively on our computer
    or run it from within a container running on our local version of Docker Desktop.
    Since this book is all about containers, let’s select the latter approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'The latest version of the Azure CLI can be found on Docker Hub. Let’s pull
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We will run a container from this CLI and executing all subsequent commands
    from within the shell running inside this container. Now, there is a little problem
    we need to overcome—this container will not have a Docker client installed. But
    we will also run some Docker commands, so we must create a custom image derived
    from the preceding image, which contains a Docker client. The Dockerfile that’s
    needed to do so can be found in the `sample-solutions/ch18` subfolder and has
    this content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'On *line 2*, we are just using the Alpine package manager, `apk`, to install
    Docker. We can then use Docker Compose to build and run this custom image. The
    corresponding `docker-compose.yml` file looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The `tail -F anything` command is used to keep the container running, as well
    as for the mounting of the Docker socket and the current folder in the `volumes`
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are running Docker Desktop on Windows, then you need to define the `COMPOSE_CONVERT_WINDOWS_PATHS`
    environment variable to be able to mount the Docker socket. Use `export COMPOSE_CONVERT_WINDOWS_PATHS=1`
    from a Bash shell or `$Env:COMPOSE_CONVERT_WINDOWS_PATHS=1` when running PowerShell.
    Please refer to the following link for more details: [https://github.com/docker/compose/issues/4240](https://github.com/docker/compose/issues/4240).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s build and run this container, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, let’s execute into the `az` container and run a Bash shell in it with
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Note that your hash code (`376f1e...`) representing the hostname inside the
    container will be different. To simplify the reading, we will omit this hash code
    in subsequent commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may have noted, we find ourselves running in a Bash shell inside the
    container. Let’s first check the version of the CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This should result in an output like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'OK—we’re running on version 2.49.0\. Next, we need to log in to our account.
    Execute this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'You will be presented with the following message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Follow the instructions and log in through the browser. Once you have successfully
    authenticated your Azure account, you can go back to your terminal and you should
    be logged in, as indicated by the output you’ll get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Now, we are ready to first move our container images to Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a container registry on Azure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we create a new resource group named `animal-rg`. In Azure, resource
    groups are used to logically group a collection of associated resources. To have
    an optimal cloud experience and keep latency low, it is important that you select
    a data center located in a region near you. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the following command to list all regions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: This will give you a rather long list of all possible regions you can select
    from. Use the name—for example, `eastasia`—to identify the region of your choice.
    In my case, I will select `westeurope`. Please note that not all locations listed
    are valid for resource groups.
  prefs: []
  type: TYPE_NORMAL
- en: 'The command to create a resource group is simple; we just need a name for the
    group and the location, as demonstrated here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Make sure that your output shows `"``provisioningState": "Succeeded"`.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: When running a containerized application in production, we want to make sure
    that we can freely download the corresponding container images from a container
    registry. So far, we have always downloaded our images from Docker Hub, but this
    is often not possible. For security reasons, the servers of a production system
    often have no direct access to the internet and thus are not able to reach out
    to Docker Hub. Let’s follow this best practice and assume the same for our Kubernetes
    cluster that we are going to create in an instant.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, what can we do? Well, the solution is to use a container image registry
    that is close to our cluster and that is in the same security context. In Azure,
    we can create an **Azure Container Registry** (**ACR**) instance and host our
    images there, so here’s what we’ll do:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first create such a registry, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Note that `<acr-name>` needs to be unique. In my case, I have chosen the name
    `gnsanimalsacr`. The (shortened) output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'After successfully creating the container registry, we need to log in to that
    registry using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The response to the preceding command should be this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Once we are successfully logged in to the container registry on Azure, we need
    to tag our containers correctly so that we can then push them to ACR. Tagging
    and pushing images to ACR will be described next.
  prefs: []
  type: TYPE_NORMAL
- en: Pushing our images to ACR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once we have successfully logged in to ACR, we can tag our images such that
    they can be pushed to the registry. For this, we need to know the URL of our ACR
    instance. It is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We now use the preceding URL to tag our images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can push them to our ACR instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'To double-check that our images are indeed in our ACR instance, we can use
    this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'This should give you the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Indeed, the two images we just pushed are listed.
  prefs: []
  type: TYPE_NORMAL
- en: With that, we are ready to create our Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Kubernetes cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once again, we will be using our custom Azure CLI inside the Docker container
    to create a Kubernetes cluster. We will have to make sure that the cluster can
    access the ACR instance that we just created; this is where our container images
    reside. So, the command to create a cluster named `animals-cluster` with two worker
    nodes looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: This command takes a while, but after a few minutes, we should receive some
    JSON-formatted output with all the details about the newly created cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'To access the cluster, we need `kubectl`. We can easily get it installed in
    our Azure CLI container using this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Having installed `kubectl`, we need the necessary credentials to use the tool
    to operate on our new Kubernetes cluster in Azure. We can get the necessary credentials
    with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The command should respond with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'After the success of the preceding command, we can list all the nodes in our
    cluster, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'This provides us with the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: As expected, we have two worker nodes up and running. The version of Kubernetes
    that is running on those nodes is `v1.25.68`.
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to deploy our application to this cluster. In the next section,
    we are going to learn how we can deploy our application to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying our application to the Kubernetes cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To deploy the application, we can use the `kubectl` `apply` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding command should look similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Now, we want to test the application. Remember that we created a service of
    type `LoadBalancer` for the web component. This service exposes the application
    to the internet.
  prefs: []
  type: TYPE_NORMAL
- en: 'This process can take a moment as AKS, among other tasks, needs to assign a
    public IP address to this service. We can observe this with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Please note the `--watch` parameter in the preceding command. It allows us
    to monitor the progress of the command over time. Initially, we should see output
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The public IP address is marked as `pending`. After a few minutes, that should
    change to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.8 – The LoadBalancer service for the animals application on Microsoft’s
    AKS](img/Figure_18.08_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.8 – The LoadBalancer service for the animals application on Microsoft’s
    AKS
  prefs: []
  type: TYPE_NORMAL
- en: Our application is now ready at the IP address `20.76.160.79` and port number
    `3000`.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the load balancer maps the internal port `32127` to the external port
    `3000`; this was not evident to me the first time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check it out. In a new browser tab, navigate to `http://20.76.160.79:3000/pet`
    and you should see our familiar application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.9 – Our sample application running on AKS](img/Figure_18.09_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.9 – Our sample application running on AKS
  prefs: []
  type: TYPE_NORMAL
- en: With that, we have successfully deployed our distributed application to Kubernetes
    hosted in Azure. We did not have to worry about installing or managing Kubernetes;
    we could concentrate on the application itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that you can also manage your Azure resource group, your container registry,
    and your cluster via the Azure portal at [https://portal.azure.com/](https://portal.azure.com/).
    It will look similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.10 – Microsoft Azure portal showing the animals resource group](img/Figure_18.10_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.10 – Microsoft Azure portal showing the animals resource group
  prefs: []
  type: TYPE_NORMAL
- en: Please make yourself familiar with the portal and try to drill down into the
    cluster, its nodes, and deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we are done experimenting with the application, we should not forget
    to delete all resources on Azure to avoid incurring unnecessary costs. We can
    delete all resources created by deleting the resource group as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Azure has a few compelling offerings regarding the container workload, and the
    lock-in is not as evident as it is on AWS since Azure does mainly offer open source
    orchestration engines, such as Kubernetes, Docker Swarm, DC/OS, and Rancher.
  prefs: []
  type: TYPE_NORMAL
- en: Technically, we remain mobile if we initially run our containerized applications
    in Azure and later decide to move to another cloud provider. The cost should be
    limited.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that when you delete your resource group, the **Azure Active
    Directory** (**AAD**) service principal used by the AKS cluster is not removed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Refer to the online help page for details on how to delete the service principal.
    You can find this information here: [https://learn.microsoft.com/en-us/powershell/module/azuread/remove-azureadserviceprincipal?view=azureadps-2.0](https://learn.microsoft.com/en-us/powershell/module/azuread/remove-azureadserviceprincipal?view=azureadps-2.0).'
  prefs: []
  type: TYPE_NORMAL
- en: Next on the list is Google with its GKE service.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding GKE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google is the inventor of Kubernetes and, to this date, the driving force behind
    it. You would therefore expect that Google has a compelling offering around hosted
    Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s have a peek into it now. To continue, you need to either have an existing
    account with Google Cloud or create a test account here: [https://console.cloud.google.com/freetrial](https://console.cloud.google.com/freetrial).
    Proceed with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the main menu, select **Kubernetes Engine**. The first time you do that,
    it will take a few moments until the Kubernetes engine is initialized.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, create a new project and name it `massai-mara`; this may take a moment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once this is ready, we can create a cluster by clicking on **Create Cluster**
    in the popup.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the `animals-cluster` and select the region closest to you. In the author’s
    case, this is `europe-west1`. Then click **NEXT: NETWORKING**.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leave all settings at their default values and click **NEXT:** **ADVANCED SETTINGS**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once again, leave all settings at their default values and click **NEXT: REVIEW**
    **AND CREATE**.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review your cluster settings and if everything looks OK, then click on **CREATE
    CLUSTER**, as illustrated in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.11 – The Review and create view of the GKE cluster creation wizard](img/Figure_18.11_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.11 – The Review and create view of the GKE cluster creation wizard
  prefs: []
  type: TYPE_NORMAL
- en: It will again take a few moments to provision the cluster for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the cluster has been created, we can open Cloud Shell by clicking on the
    shell icon in the upper-right corner of the view. This is how it should look:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.12 – The first Kubernetes cluster ready and Cloud Shell open in
    GKE](img/Figure_18.12_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.12 – The first Kubernetes cluster ready and Cloud Shell open in GKE
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now clone our lab’s GitHub repository to this environment with the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Switch to the correct folder where you’ll find the sample solution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You should now find an `animals.yaml` file in the current folder, which you
    can use to deploy the `animals` application into our Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Have a look at the file by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It has pretty much the same content as the same file we used in the previous
    chapter. The two differences are these:'
  prefs: []
  type: TYPE_NORMAL
- en: We use a service of type `LoadBalancer` (instead of `NodePort`) to publicly
    expose the `web` component. Note we did the same on Azure AKS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We do not use volumes for the PostgreSQL database since configuring `StatefulSet`
    correctly on GKE is a bit more involved than in a product such as Minikube or
    Docker Desktop. The consequence of this is that our `animals` application will
    not persist the state if the `db` Pod crashes. How to use persistent volumes on
    GKE lies outside the scope of this book.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, note that we are not using **Google Container Registry** (**GCR**) to
    host the container images but are instead directly pulling them from Docker Hub.
    It is very easy—and similar to what we learned in the section about AKS—to create
    such a container registry in Google Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can continue, we need to set up `gcloud` and `kubectl` credentials.
    Here’s the code we need to execute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Please replace `<zone>` with the same zone you selected in *step 5* when you
    created the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The response of the preceding command should be this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s have a look at which nodes for the cluster were created by running the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.13 – Cluster nodes on GCE](img/Figure_18.13_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.13 – Cluster nodes on GCE
  prefs: []
  type: TYPE_NORMAL
- en: We can see that two nodes were created in our cluster, and the version of Kubernetes
    deployed is apparently `v1.25.8`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having done that, it’s time to deploy the application, so run the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.14 – Deploying the application on GKE](img/Figure_18.14_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.14 – Deploying the application on GKE
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the objects have been created, we can observe the `LoadBalancer web` service
    until it is assigned a public IP address, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding command yields this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: The second line in the output is showing the situation while the creation of
    the load balancer is still pending, and the third one gives the final state. Press
    *Ctrl* + *C* to quit the `–watch` command. Apparently, we got the public IP address
    `35.195.160.243` assigned and the port is `3000`.
  prefs: []
  type: TYPE_NORMAL
- en: We can then use this IP address and navigate to `http://<IP address>:3000/pet`,
    and we should be greeted by the familiar animal image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take a moment and use the various `kubectl` commands you know to analyze what’s
    going on in the GKE cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Also, take a moment to use the web portal of GCE and drill down into the details
    of your cluster. Specifically, have a look into the **OBSERVABILITY** tab of the
    cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you are done playing with the application, delete the cluster and the project
    in the Google Cloud console to avoid any unnecessary costs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can use the `gcloud` CLI in the Cloud Shell to delete the cluster, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will take a moment. Alternatively, you can do the same from the web portal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next list all your projects, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, you can use this command to delete the project you created earlier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, you should get the correct `<project-id>` value from the previous `list`
    command.
  prefs: []
  type: TYPE_NORMAL
- en: We have created a hosted Kubernetes cluster in GKE. We then used Cloud Shell,
    provided through the GKE portal, to first clone our lab’s GitHub repository and
    then the `kubectl` tool to deploy the `animals` application into the Kubernetes
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: When looking into a hosted Kubernetes solution, GKE is a compelling offering.
    It makes it very easy to start your projects, and since Google is the main driving
    force behind Kubernetes, we can rest assured that we will always be able to leverage
    the full functionality of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter of the book, you first got an introduction to how to create
    a fully managed Kubernetes cluster on Amazon EKS using Fargate and how to deploy
    a simple application on this cluster. Then, you learned how to create a hosted
    Kubernetes cluster in Azure AKS and run the `animals` application on it, followed
    by doing the same for Google’s own hosted Kubernetes offering, GKE.
  prefs: []
  type: TYPE_NORMAL
- en: Are you ready to unlock the secrets of keeping your production environment in
    peak health? In the next chapter, we will dive into the exciting realm of monitoring
    and troubleshooting an application running in production. We’ll explore diverse
    techniques for instrumenting and overseeing both individual services and entire
    distributed applications operating on a Kubernetes cluster. But it doesn’t stop
    there—you’ll also learn about creating alerts based on crucial metrics. And when
    things go awry, we’ll guide you on how to troubleshoot live applications without
    disrupting the cluster or its nodes. Stay tuned, because this final chapter promises
    to arm you with the tools you need to confidently maintain your applications at
    scale.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To assess your knowledge, please answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: List a few reasons why you would select a hosted Kubernetes offering, such as
    Amazon EKS, Microsoft’s AKS, or Google’s GKE, to run your applications on Kubernetes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name two reasons when using a hosted Kubernetes solution, such as Amazon EKS,
    Azure AKS, or Google GKE, to consider hosting your container images in the container
    registry of the respective cloud provider.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the chapter questions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few reasons to consider a hosted Kubernetes offering:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You do not want to or do not have the resources to install and manage a Kubernetes
    cluster
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You want to concentrate on what brings value to your business, which in most
    cases is the applications that are supposed to run on Kubernetes and not Kubernetes
    itself
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You prefer a cost model where you pay only for what you need
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The nodes of your Kubernetes cluster are automatically patched and updated
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Upgrading the version of Kubernetes with zero downtime is easy and straightforward
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The two main reasons to host container images on the cloud provider’s container
    registry (such as ACR on Microsoft Azure) are these:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The images are geographically close to your Kubernetes cluster, and thus the
    latency and transfer network costs are minimal
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Production or production-like clusters are ideally sealed from the internet,
    and thus the Kubernetes cluster nodes cannot access Docker Hub directly
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
