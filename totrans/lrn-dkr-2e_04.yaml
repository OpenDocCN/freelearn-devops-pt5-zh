- en: Orchestrating Containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the earlier chapters, we laid down a strong foundation on the need for container
    networking, how to run a service inside a Docker container, and how to expose
    this service to the outside world by opening up network ports and other prerequisites.
    However, recently, there are advanced mechanisms being made available and a few
    third-party orchestration platforms hitting the market for sagaciously establishing
    dynamic and decisive linkages between distributed and differently-enabled containers
    in order to compose powerful containers for comprehensively, yet compactly containing
    process-centric, multi-tiered, and enterprise-class distributed applications.
    In the extremely diversified yet connected world, the concept of orchestration
    cannot be kept away from the deserved prominence for long. This chapter is precisely
    allocated for explaining the nitty-gritty of container orchestration, and its
    direct role is in picking up discrete containers to systematically compose sophisticated
    containers that are more directly aligned with the varying business expectations
    and expediencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the following topics in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: Linking containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestrating containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestrating containers using the `docker-compose` tool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As mission-critical applications are overwhelmingly being built through loosely
    coupled, yet highly cohesive components/services destined to run on geographically-distributed
    IT infrastructures and platforms, the concept of composition is getting a lot
    of attention and attraction. For sustaining the well-begun containerization journey,
    the orchestration of containers is being prescribed as one of the most critical
    and crucial requirements in the ensuing, instant-on, adaptive, and smart IT era.
    There are a few proven and promising methods and standards-compliant tools for
    enabling the enigmatic orchestration goals.
  prefs: []
  type: TYPE_NORMAL
- en: Docker inbuilt service discovery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Docker platform inherently supports the service discovery for the containers
    that are attached to any user-defined network using an embedded **Domain Name
    Service** (**DNS**). This functionality has been added to Docker since the version
    `1.10`. The embedded DNS feature enables the Docker containers to discover each
    other using their names or aliases within the user-defined network. In other words,
    the name resolution request from the container is first sent to the embedded DNS.
    The user-defined network then uses a special `127.0.0.11` IP address for the embedded
    DNS, which is also listed in `/etc/resolv.conf`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example will help to gain a better understanding of Docker''s
    built-in service discovery capability:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin by creating a user-defined bridge network, `mybridge`, using the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Inspect the newly created network to understand the subnet range and gateway
    IP:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, the subnet assigned to the `mybridge` network is `172.18.0.0/16` and the
    gateway is `172.18.0.1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create a container by attaching it to the `mybridge` network, as
    shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Continue to list the IP address assigned to the container, as illustrated here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Evidently, the `testdns` container is assigned a `172.18.0.2` IP address. The `172.18.0.2` IP
    address is from the subnet of the `mybridge` network (that is, `172.18.0.0/16`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Having got the IP address of the container, let''s look into the content of
    the `/etc/resolv.conf`  file of the container using the `docker container exec`
    subcommand, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here the `nameserver` is configured as `127.0.0.11`, which is the IP address
    of the embedded DNS.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final step, let''s ping the `testdns` container using the `busybox` image.
    We picked the `busybox` image here because the `ubuntu` image is shipped without
    the `ping` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Awesome, isn't it! The folks behind Docker have made it so simple that with
    no effort we are able to discover the containers in the same network.
  prefs: []
  type: TYPE_NORMAL
- en: Linking containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before the introduction of the concept of the user-defined network, container
    linking was predominantly used for inter-container discovery and communication.
    That is, cooperating containers can be linked together to offer complex and business-aware
    services. The linked containers have a kind of source-recipient relationship,
    wherein the source container gets linked to the recipient container, and the recipient
    securely receives a variety of information from the source container. However,
    the source container will know nothing about the recipients to which it is linked.
    Another noteworthy feature of linking containers in a secured setup is that the
    linked containers can communicate using secure tunnels without exposing the ports
    used for the setup to the external world. Though you will find lots of deployments
    that use container-linking techniques, they are cumbersome and time-consuming
    to configure. Also, they are error-prone. So the new method of embedded DNS is
    highly preferred over the traditional container-linking techniques.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker Engine provides the `--link` option in the `docker run` subcommand
    to link a source container to a recipient container.
  prefs: []
  type: TYPE_NORMAL
- en: 'The format of the `--link` option is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, `<container>` is the name of the source container and `<alias>` is the
    name seen by the recipient container. The name of the container must be unique
    in a Docker host, whereas alias is very specific and local to the recipient container,
    and hence, the alias need not be unique in the Docker host. This gives a lot of
    flexibility to implement and incorporate functionalities with a fixed source alias
    name inside the recipient container.
  prefs: []
  type: TYPE_NORMAL
- en: 'When two containers are linked together, the Docker Engine automatically exports
    a few environment variables to the recipient container. These environment variables
    have a well-defined naming convention, where the variables are always prefixed
    with the capitalized form of the alias name. For instance, if `src` is the alias
    name given to the source container, then the exported environment variables will
    begin with `SRC_`. Docker exports three categories of environment variables, as
    enumerated here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`NAME`: This is the first category of environment variables. These variables
    take the form of `<ALIAS>_NAME`, and they carry the recipient container''s hierarchical
    name as their value. For instance, if the source container''s alias is `src` and
    the recipient container''s name is `rec`, then the environment variable and its
    value will be `SRC_NAME=/rec/src`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ENV`: This is the second category of environment variables used to export
    the environment variables configured in the source container by the `-e` option
    of the `docker run` subcommand or the `ENV` instruction of the `Dockerfile`. This
    type of an environment variable takes the form of `<ALIAS>_ENV_<VAR_NAME>`. For
    instance, if the source container''s alias is `src` and the variable name is `SAMPLE`,
    then the environment variable will be `SRC_ENV_SAMPLE`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PORT`: This is the final and third category of environment variables that
    is used to export the connectivity details of the source container to the recipient.
    Docker creates a bunch of variables for each port exposed by the source container
    through the `-p` option of the `docker run` subcommand or the `EXPOSE` instruction
    of the `Dockerfile`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These variables take the `<ALIAS>_PORT_<port>_<protocol>` form. This form is
    used to share the source''s IP address, port, and protocol as a URL. For example,
    if the source container''s alias is `src`, the exposed port is `8080`, the protocol
    is `tcp`, and the IP address is `172.17.0.2`, then the environment variable and
    its value will be `SRC_PORT_8080_TCP=tcp://172.17.0.2:8080`. This URL further
    splits into the following three environment variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`<ALIAS>_PORT_<port>_<protocol>_ADDR`: This form carries the IP address part
    of the URL (for example, `SRC_PORT_8080_TCP_ADDR= 172.17.0.2`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<ALIAS>_PORT_<port>_<protocol>_PORT`: This form carries the port part of the
    URL (for example, `SRC_PORT_8080_TCP_PORT=8080`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<ALIAS>_PORT_<port>_<protocol>_PROTO`: This form carries the protocol part
    of the URL (for example, `SRC_PORT_8080_TCP_PROTO=tcp`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to the preceding environment variables, the Docker Engine exports
    one more variable in this category, that is, of the `<ALIAS>_PORT` form, and its
    value will be the URL of the lowest number of all the exposed ports of the source
    container. For instance, if the source container's alias is `src`, the exposed
    port numbers are `7070`, `8080`, and `80`, the protocol is `tcp`, and the IP address
    is `172.17.0.2`, then the environment variable and its value will be `SRC_PORT=tcp://172.17.0.2:80`.
  prefs: []
  type: TYPE_NORMAL
- en: Docker exports these autogenerated environment variables in a well-structured
    format so that they can be easily discovered programmatically. Thus, it becomes
    very easy for the recipient container to discover the information about the source
    container. In addition, Docker automatically updates the source IP address and
    its alias as an entry in the `/etc/hosts` file of the recipient.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will dive deep into the mentioned features provided by the
    Docker Engine for container linkage through a bevy of pragmatic examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start with, let''s choose a simple container linking example. Here, we will
    show you how to establish a linkage between two containers, and transfer some
    basic information from the source container to the recipient container, as illustrated
    in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin with launching an interactive container that can be used as a source
    container for linking, using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The container is named `example` using the `--name` option. In addition, the
    `--rm` option is used to clean up the container as soon as you exit from the container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Display the `/etc/hosts` entry of the source container using the `cat` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Here, the first entry in the `/etc/hosts` file is the source container's IP
    address (`172.17.0.3`) and its hostname (`a02895551686`).
  prefs: []
  type: TYPE_NORMAL
- en: 'We will continue to display the environment variables of the source container
    using the `env` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We have now launched the source container. From another Terminal of the same
    Docker host, let''s launch the interactive recipient container by linking it to
    our source container using the `--link` option of the `docker run` subcommand,
    as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Here, the source container named `example` is linked to the recipient container
    with `ex` as its alias.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s display the content of the `/etc/hosts` file of the recipient container
    using the `cat` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Of course, as always, the first entry in the `/etc/hosts` file is the IP address
    of the container and its hostname. However, the noteworthy entry in the `/etc/hosts`
    file is the last entry, where the IP address (`172.17.0.3`) of the source container
    and its alias (`ex`) are added automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will continue to display the recipient container''s environment variable
    using the `env` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Apparently, a new `EX_NAME` environment variable is added automatically to `/berserk_mcclintock/ex`,
    as its value. Here `EX` is the capitalized form of the alias `ex` and `berserk_mcclintock`
    is the autogenerated name of the recipient container.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final step, ping the source container using the widely used `ping` command
    for two counts and use the alias name as the ping address:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Evidently, the alias `ex` of the source container is resolved to the `172.17.0.3`
    IP address, and the recipient container is able to successfully reach the source.
    In the case of secured container communication, pinging between containers is
    not allowed. We will see more details on the aspect of securing containers in
    [Chapter 11](../Text/Ch11.xhtml), *Securing Docker Containers*.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, we can link two containers together, and also, observe
    how elegantly networking is enabled between the containers by updating the IP
    address of the source container in the `/etc/hosts` file of the recipient container.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next example is to demonstrate how container linking exports the environment
    variables of the source container, which are configured using the `-e` option
    of the `docker run` subcommand or the `ENV` instruction of `Dockerfile`, to the
    recipient container. For this purpose, we are going to craft a file named `Dockerfile`
    with the `ENV` instruction, build an image, launch a source container using this
    image, and then launch a recipient container by linking it to the source container:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin with composing a `Dockerfile` with the `ENV` instruction, as shown
    here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are setting up two environment variables, `BOOK` and `CHAPTER`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Proceed to build a Docker image `envex` using the `docker build` subcommand
    from the preceding `Dockerfile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s launch an interactive source container with the `example` name
    using the `envex` image we just built:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'From the source container prompt, display all the environment variables by
    invoking the `env` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In all the preceding environment variables, both the `BOOK` and the `CHAPTER`
    variables are configured with the `ENV` instruction of the `Dockerfile`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final step, to illustrate the `ENV` category of environment variables,
    launch the recipient container with the `env` command, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This example is also available on GitHub at [https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Env](https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Env).
  prefs: []
  type: TYPE_NORMAL
- en: Strikingly, in the preceding output, the variables that are prefixed with `EX_` are
    the outcome of container linking. The environment variables of our interest are
    `EX_ENV_BOOK` and `EX_ENV_CHAPTER`, which were originally set through the `Dockerfile`
    as `BOOK` and `CHAPTER` but modified to `EX_ENV_BOOK` and `EX_ENV_CHAPTER`, as
    an effect of container linking. Though the environment variable names get translated,
    the values stored in these environment variables are preserved as is. We already
    discussed the `EX_NAME` variable name in the previous example.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, we experienced how elegantly and effortlessly Docker
    exports the `ENV` category variables from the source container to the recipient
    container. These environment variables are completely decoupled from the source
    and the recipient, thus a change in the value of these environment variables in
    one container does not impact the other. To be even more precise, the values the
    recipient container receives are the values set during the launch of the source
    container. Any changes made to the value of these environment variables in the
    source container after its launch have no effect on the recipient container. It
    does not matter when the recipient container is launched because the values are
    being read from the JSON file.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our final illustration of linking containers, we are going to show you how
    to take advantage of the Docker feature to share the connectivity details between
    two containers. In order to share the connectivity details between containers,
    Docker uses the `PORT` category of environment variables. The following are the
    steps used to craft two containers and share the connectivity details between
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Craft a `Dockerfile` to expose port `80` and `8080` using the `EXPOSE` instruction,
    as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Proceed to build a `portex` Docker image using the `docker build` subcommand
    from the `Dockerfile`, we created just now, by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s launch an interactive source container with the `example` name
    using the earlier built `portex` image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have launched the source container, let''s continue to create a
    recipient container on another Terminal by linking it to the source container,
    and invoke the `env` command to display all the environment variables, as shown
    here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This example is also available on GitHub at [https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Expose](https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Expose).
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding output of the `env` command, it is quite evident that the
    Docker Engine exported a bunch of four `PORT` category environment variables for
    each port that was exposed using the `EXPOSE` instruction in the `Dockerfile`.
    In addition, Docker also exported another `PORT` category variable `EX_PORT`.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestration of containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The pioneering concept of orchestration in the IT domain has been there for
    a long time now. For instance, in the **Service Computing** (**SC**) arena, the
    idea of service orchestration has been thriving in an unprecedented manner in
    order to produce and sustain highly robust and resilient services. Discrete or
    atomic services do not serve any substantial purpose unless they are composed
    together in a particular sequence to derive process-aware composite services.
    As orchestrated services are more strategically advantageous for businesses in
    expressing and exposing their unique capabilities in the form of identifiable/discoverable,
    interoperable, usable, and composable services to the outside world, corporates
    are showing exemplary interest in having an easily searchable repository of services
    (atomic as well as composite). This repository, in turn, enables businesses in
    realizing large-scale data as well as process-intensive applications. It is clear
    that the multiplicity of services is very pivotal for organizations to grow and
    glow. This increasingly mandated requirement gets solved using the proven and
    promising orchestration capabilities cognitively.
  prefs: []
  type: TYPE_NORMAL
- en: Now, as we are fast tending toward containerized IT environments, application
    and data containers ought to be smartly composed to realize a host of new generation
    software services.
  prefs: []
  type: TYPE_NORMAL
- en: However, for producing highly competent orchestrated containers, both purpose-specific
    as well as agnostic containers need to be meticulously selected and launched in
    the right sequence in order to create orchestrated containers. The sequence can
    come from the process (control as well as data) flow diagrams. Doing this complicated
    and daunting activity manually evokes a series of cynicisms and criticisms. Fortunately,
    there are orchestration tools in the Docker space that come in handy to build,
    run, and manage multiple containers to build enterprise-class services. The Docker
    firm, which has been in charge of producing and promoting the generation and assembly
    of Docker-inspired containers, has come out with a standardized and simplified
    orchestration tool (named as `docker-compose`) in order to reduce the workloads
    of developers as well as system administrators.
  prefs: []
  type: TYPE_NORMAL
- en: The proven composition technique of the SC paradigm is being replicated here
    in the raging containerization paradigm in order to reap the originally envisaged
    benefits of containerization, especially in building powerful application-aware
    containers.
  prefs: []
  type: TYPE_NORMAL
- en: The **Microservice Architecture** (**MSA**) is an architectural concept that
    aims to decouple a software solution by decomposing its functionality in a pool
    of discrete services. This is done by applying an architectural level to many
    of the principles. The MSA is slowly emerging as a championed way to design and
    build large-scale IT and business systems. It not only facilitates loose and light
    coupling and software modularity but it is also a boon to continuous integration
    and deployment for the agile world. Any changes being made to one part of the
    application mandates massive changes that are made to the application as a whole.
    This has been a bane and barrier to the aspect of continuous deployment. Microservices
    aim to resolve this situation, and hence, the MSA needs light-weight mechanisms,
    small, independently deployable services, and to ensure scalability and portability.
    These requirements can be met using Docker-sponsored containers.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices are being built around business capabilities and can be independently
    deployed by fully automated deployment machinery. Each microservice can be deployed
    without interrupting the other microservices, and containers provide an ideal
    deployment and execution environment for services along with other noteworthy
    facilities, such as the reduced time to deployment, isolation management, and
    a simple life cycle. It is easy to quickly deploy new versions of services inside
    containers. All of these factors led to the explosion of microservices using the
    features that Docker had to offer.
  prefs: []
  type: TYPE_NORMAL
- en: As explained, Docker is being positioned as the next-generation containerization
    technology, which provides a proven and potentially sound mechanism to distribute
    applications in a highly efficient and distributed fashion. The beauty is that
    developers can tweak the application pieces within the container while maintaining
    the overall integrity of the container. This has a bigger impact as the brewing
    trend is that instead of large monolithic applications distributed on a single
    physical or virtual server, companies are building smaller, self-defined and contained,
    easily manageable, and discrete services to be contained inside standardized and
    automated containers. In short, the raging containerization technology from Docker
    has come as a boon for the ensuing era of microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Docker was built and sustained to fulfill the elusive goal of *run it once and
    run it everywhere*. Docker containers are generally isolated at the process level,
    portable across IT environments, and easily repeatable. A single physical host
    can host multiple containers, and hence, every IT environment is generally stuffed
    with a variety of Docker containers. The unprecedented growth of containers is
    to spell out troubles for effective container management. The multiplicity and
    the associated heterogeneity of containers are used to sharply increase the management
    complexities of containers. Hence, the technique of orchestration and the flourishing
    orchestration tools have come as a strategic solace for accelerating the containerization
    journey in safe waters.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestrating applications that span multiple containers containing microservices
    has become a major part of the Docker world, via projects, such as Google's Kubernetes
    or Flocker. Decking is another option used to facilitate the orchestration of
    Docker containers. Docker's new offering in this area is a set of three orchestration
    services designed to cover all aspects of the dynamic life cycle of distributed
    applications from application development to deployment and maintenance. Helios
    is another Docker orchestration platform used to deploy and manage containers
    across an entire fleet. In the beginning, `fig` was the most preferred tool for
    container orchestration. However, in the recent past, the company at the forefront
    of elevating the Docker technology has come out with an advanced container orchestration
    tool (`docker-compose`) to make life easier for developers working with Docker
    containers as they move through the container life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Having realized the significance of having the capability of container orchestration
    for the next generation, business-critical, and containerized workloads, the Docker
    company purchased the company that originally conceived and concretized the `fig`
    tool. Then, the Docker company appropriately renamed the tool as `docker-compose`
    and brought in a good number of enhancements to make the tool more tuned to the
    varying expectations of the containers' developers and operation teams.
  prefs: []
  type: TYPE_NORMAL
- en: Here is a gist of `docker-compose`, which is being positioned as a futuristic
    and flexible tool used for defining and running complex applications with Docker.
    With `docker-compose`, you define your application's components (their containers,
    configuration, links, volumes, and so on) in a single file, and then, you can
    spin everything up with a single command, which does everything to get it up and
    running.
  prefs: []
  type: TYPE_NORMAL
- en: This tool simplifies container management by providing a set of built-in tools
    to do a number of jobs that are being performed manually at this point in time.
    In this section, we supplied all the details of using `docker-compose` to perform
    orchestration of containers in order to have a stream of next-generation distributed
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestrating containers using docker-compose
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will discuss the widely used container orchestration tool
    `docker-compose`. The `docker-compose` tool is a very simple, yet power tool and
    has been conceived and concretized to facilitate the running of a group of Docker
    containers. In other words, `docker-compose` is an orchestration framework that
    lets you define and control a multi-container service. It enables you to create
    a fast and isolated development environment as well as orchestrating multiple
    Docker containers in production. The `docker-compose` tool internally leverages
    the Docker Engine for pulling images, building the images, starting the containers
    in the correct sequence, and making the right connectivity/linking among the containers/services
    based on the definition given in the `docker-compose.yml` file.
  prefs: []
  type: TYPE_NORMAL
- en: Installing docker-compose
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At the time of writing this book, the latest release of `docker-compose` is
    1.11.2, and it is recommended that you use it with the Docker release 1.9.1 or
    above. You can find the latest official release of `docker-compose` at the GitHub
    location ([https://github.com/docker/compose/releases/latest](https://github.com/docker/compose/releases/latest)).
  prefs: []
  type: TYPE_NORMAL
- en: 'We have automated the installation process of `docker-compose` and also made
    it available for public consumption at [http://sjeeva.github.io/getcompose](http://sjeeva.github.io/getcompose).
    These automated scripts precisely identify the latest version of `docker-compose`,
    download it, and install it at `/usr/local/bin/docker-compose`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `wget` tool like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `curl` tool like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you may choose to install a particular version of `docker-compose`
    directly from the GitHub software repository. Here, you can find the ways and
    means of downloading and installing the `docker-compose` version `1.11.2`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `wget` tool like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `curl` tool like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The `docker-compose` tool is also available as a Python package, which you
    can install using the `pip` installer, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If `pip` is not installed on the system, install the `pip` package before the
    `docker-compose` installation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having successfully installed `docker-compose`, you can now check the `docker-compose`
    version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The docker-compose file
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `docker-compose` tool orchestrates containers using **YAML**, which is
    a **Yet Another Markup Language** called the `docker-compose` file. YAML is a
    human-friendly data serialization format. Docker began its journey as a container
    enablement tool, and it is growing by leaps and bounds as an ecosystem to automate
    and accelerate most of the tasks such as container provisioning, networking, storage,
    management, orchestration, security, governance, and persistence. Consequently,
    the `docker-compose` file format and its version are revised multiple times to
    keep up with the Docker platform. At the time of writing this edition, the latest
    version of the `docker-compose` file is version 3\. The following table lists
    the `docker-compose` file and the Docker Engine version compatibility matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Docker Compose file format** | **Docker Engine** | **Remarks** |'
  prefs: []
  type: TYPE_TB
- en: '| 3, 3.1 | 1.13.0+ | Provides support for `docker stack deploy` and `docker
    secrets` |'
  prefs: []
  type: TYPE_TB
- en: '| 2.1 | 1.12.0+ | Introduced a few new parameters |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 1.10.0+ | Introduced support for named volumes and networks |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1.9.0+ | Will be deprecated in the future compose releases |'
  prefs: []
  type: TYPE_TB
- en: 'The `docker-compose` tool by default uses a file named as `docker-compose.yml`
    or `docker-compose.yaml` to orchestrate containers. This default file can be modified
    using the `-f` option of the `docker-compose` tool. The following is the format
    of the `docker-compose` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the options used are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`<version>`: This is the version of the `docker-compose` file. Refer to the
    preceding version table.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<service>`: This is the name of the service. You can have more than one service
    definition in a single `docker-compose` file. The service name should be followed
    by one or more keys. However, all the services must either have an `image` or
    a `build` key, followed by any number of optional keys. Except for the `image`
    and `build` keys, the rest of the keys can be directly mapped to the options in
    the `docker run` subcommand. The value can be either a single value or multiple
    values. All the `<service>` definitions must be grouped under the top-level `services`
    key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<network>`: This is the name of the networks that are used by the services.
    All the `<network>` definitions must be grouped under the top-level `networks`
    key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<volume>`: This is the name of the volume that is used by the services. All
    the `<volume>` definitions must be grouped under the top-level `volume` key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, we are listing a few keys supported in the `docker-compose` file version
    3\. Refer to [https://docs.docker.com/compose/compose-file](https://docs.docker.com/compose/compose-file)
    for all the keys supported by `docker-compose`.
  prefs: []
  type: TYPE_NORMAL
- en: '`image`: This is the tag or image ID.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`build`: This is the path to a directory containing a `Dockerfile`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`command`: This key overrides the default command.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deploy`: This key has many subkeys and is used to specify deployment configuration.
    This is used only in the `docker swarm` mode.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`depends_on`: This is used to specify the dependencies between services. It
    can be further extended to chain services based on their conditions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cap_add`: This adds a capability to the container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cap_drop`: This drops a capability of the container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dns`: This sets custom DNS servers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dns_search`: This sets custom DNS search servers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`entrypoint`: This key overrides the default entrypoint.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`env_file`: This key lets you add environment variables through files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`environment`: This adds environment variables and uses either an array or
    a dictionary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`expose`: This key exposes ports without publishing them to the host machine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`extends`: This extends another service defined in the same or a different
    configuration file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`extra_hosts`: This enables you to add additional hosts to `/etc/hosts` inside
    the container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`healthcheck`: This allows us to configure the service health check.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels`: This key lets you add metadata to your container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`links`: This key links to containers in another service. Usage of links is
    strongly discouraged.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logging`: This is used to configure the logging for the service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`network`: This is used to join the service to the network defined in the top-level
    `networks` key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pid`: This enables the PID space sharing between the host and the containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ports`: This key exposes ports and specifies both the `HOST_port:CONTAINER_port`
    ports.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`volumes`: This key mounts path or named volumes. The named volumes need to
    be defined in the top-level `volumes` key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The docker-compose command
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `docker-compose` tool provides sophisticated orchestration functionality
    with a handful of commands. In this section, we will list out the `docker-compose`
    options and commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The `docker-compose` tool supports the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-f`, `--file <file>`: This specifies an alternate file for `docker-compose`
    (default is the `docker-compose.yml` file)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-p`, `--project-name <name>`: This specifies an alternate project name (default
    is the directory name)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--verbose`: This shows more output'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-v`, `--version`: This prints the version and exits'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-H`, `--host <host>`: This is to specify the daemon socket to connect to'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-tls`, `--tlscacert`, `--tlskey`, and `--skip-hostname-check`: The `docker-compose`
    tool also supports these flags for **Transport Layer Security** (**TLS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `docker-compose` tool supports the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`build`: This command builds or rebuilds services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bundle`: This is used to create a Docker bundle from the compose file, this
    is still an experimental feature on Docker 1.13.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`config`: This is a command to validate and display the compose file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`create`: This creates the services defined in the compose file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`down`: This command is used to stop and remove containers and networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`events`: This can be used to view the real-time container life cycle events.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`exec`: This enables you to run a command in a running container. It is used
    predominantly for debugging purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kill`: This command kills running containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logs`: This displays the output from the containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pause`: This command is used to pause services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`port`: This prints the public port for a port binding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ps`: This lists the containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pull`: This command pulls the images from the repository.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`push`: This command pushes the images to the repository.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`restart`: This is used to restart the services defined in the compose file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rm`: This removes the stopped containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`run`: This runs a one-off command.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scale`: This sets a number of containers for a service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start`: This command starts services defined in the compose file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stop`: This stops services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unpause`: This command is used to unpause services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`up`: This creates and starts containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`version`: This prints the version of Docker Compose.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common usage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we are going to experience the power of the orchestration
    feature provided by the Docker Compose framework with the help of an example.
    For this purpose, we are going to build a two-tiered web application that will
    receive your inputs through a URL and respond with the associated response text.
    This application is built using the following two services, as enumerated here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Redis**: This is a key-value database used to store a key and its associated
    value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Node.js**: This is a JavaScript runtime environment used to implement the
    web server functionality as well the application logic'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each of these services is packed inside two different containers that are stitched
    together using the `docker-compose` tool. The following is the architectural representation
    of the services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_08_001.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, in this example, we begin with implementing the `example.js` module, a
    Node.js file to realize the web server, and the key lookup functionality. Further,
    we will craft the `Dockerfile` on the same directory as `example.js` to package
    the Node.js runtime environment, and then, define the service orchestration using
    a `docker-compose.yml` file in the same directory as `example.js`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the `example.js` file, which is a Node.js implementation of
    the simple request/response web application. For demonstration, in this sample
    code, we restrict the request and response for just two `docker-compose` commands
    (`build` and `kill`). For the code to be self-explanatory, we added comments in
    the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: This example is also available at [https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose](https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following text is the content of `Dockerfile` that packs the Node.js image,
    the `redis` driver for Node.js, and the `example.js` file, as defined earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This code is also available at [https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose](https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following text is from the `docker-compose.yml` file that defines the services
    that the Docker Compose tool orchestrates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This example is also available at [https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose](https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose).
  prefs: []
  type: TYPE_NORMAL
- en: 'We defined two services in this `docker-compose.yml` file, wherein these services
    serve the following purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: The service named `web` is built using the `Dockerfile` in the current directory.
    Also, it is instructed that you launch the container by running the `node` (the
    Node.js runtime) with `/myapp/example.js` (web application implementation), as
    its argument. Since this Node.js application uses the `redis` database, the `web`
    service is forced to start after the `redis` service using the `depends_on` instruction.
    Besides, the `80` container port is mapped to the `8080` Docker host's port.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The service named `redis` is instructed to launch a container with the `redis:latest`
    image. If the image is not present in the Docker host, the Docker Engine will
    pull it from the central repository or the private repository.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s continue with our example by building the Docker images using the
    `docker-compose build` command, launch the containers using the `docker-compose
    up` command, and connect with a browser to verify the request/response functionality,
    as explained step by step here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `docker-compose` commands must be executed from the directory in which
    the `docker-compose.yml` file is stored. Besides, `docker-compose` considers each
    `docker-compose.yml` file as a project, and it assumes the project name from the
    `docker-compose.yml` file''s directory. Of course, this can be overridden using
    the `-p` option. So, as a first step, let''s change the directory, wherein the
    `docker-compose.yml` file is stored:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Build the services using the `docker-compose build` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Pull the images from the repository using the `docker-compose pull` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Proceed to bring up the services as indicated in the `docker-compose.yml` file
    using the `docker-compose up` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Since the directory name is `example`, the `docker-compose` tool has assumed
    that the project name is `example`. If you pay attention to the first line of
    the output, you will notice the `example_default` network being created. The Docker
    Compose tool creates this bridge network by default and this network is used by
    the service for IP address resolution. Thus the services can reach the other services
    by just using the service names defined in the compose file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having successfully orchestrated the services using the `docker-compose` tool,
    let''s invoke the `docker-compose ps` command from a different Terminal to list
    the containers associated with the example `docker-compose` project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Evidently, the two `example_redis_1` and `example_web_1` containers are up and
    running. The container name is prefixed with `example_`, which is the `docker-compose`
    project name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Explore the functionality of our own request/response web application on a
    different Terminal of the Docker host, as illustrated here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are directly connecting to the `web` service using `http://localhost:8080`
    because the `web` service is bound to the Docker host on port `8080`. You can
    also access the service externally using the Docker host IP address and port `8080`
    (`https://<docker host ip>:8080`), provided the IP address and the port is reachable
    from the external system.
  prefs: []
  type: TYPE_NORMAL
- en: Cool, isn't it? With very minimal effort and with the help of the `docker-compose.yml`
    file, we are able to compose two different services together and offer a composite
    service.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter was incorporated into this book in order to provide you with all
    the probing and prescribing details on seamlessly orchestrating multiple containers.
    We extensively discussed the need for container orchestration and the enabling
    tools to simplify and streamline the increasingly complicated process of container
    orchestration. In order to substantiate how orchestration is handy and helpful
    in crafting enterprise-class containers and to illustrate the orchestration process,
    we took the widely followed way of explaining the whole gamut through a simple
    example. We developed a web application and contained it within a standard container.
    Similarly, we took a database container, which is a backend for the frontend web
    application. The database gets executed inside another container. We saw how to
    make the web application container aware of the database, using different technologies
    through the container-linkage feature of the Docker Engine. We used an open-source
    tool (`docker-compose`) for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss how Docker facilitates software testing,
    especially integration testing with a few pragmatic examples.
  prefs: []
  type: TYPE_NORMAL
