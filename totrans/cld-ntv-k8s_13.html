<html><head></head><body>
		<div><p><a id="_idTextAnchor229"/></p>
			<h1 id="_idParaDest-218"><em class="italic"><a id="_idTextAnchor230"/>Chapter 10</em>: Troubleshooting Kubernetes</h1>
			<p>This chapter reviews the best-practice methods for effectively troubleshooting Kubernetes clusters and the applications that run on them. This includes a discussion of common Kubernetes issues, as well as how to debug the masters and workers separately. The common Kubernetes issues will be discussed and taught in a case study format, split into cluster issues and application issues.</p>
			<p>We will start with a discussion of some common Kubernetes failure modes, before moving on to how to best troubleshoot clusters and applications.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Understanding failure modes for distributed applications</li>
				<li>Troubleshooting Kubernetes clusters</li>
				<li>Troubleshooting applications on Kubernetes</li>
			</ul>
			<h1 id="_idParaDest-219"><a id="_idTextAnchor231"/>Technical requirements</h1>
			<p>In order to run the commands detailed in this chapter, you will need a computer that supports the <code>kubectl</code> command-line tool along with a working Kubernetes cluster. See <a href="B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016"><em class="italic">Chapter 1</em></a>, <em class="italic">Communicating with Kubernetes</em>, for several methods for getting up and running with Kubernetes quickly, and for instructions on how to install the <code>kubectl</code> tool.</p>
			<p>The code used in this chapter can be found in the book's GitHub repository at <a href="https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter10">https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter10</a>.</p>
			<h1 id="_idParaDest-220"><a id="_idTextAnchor232"/>Understanding failure modes for distributed applications</h1>
			<p>Kubernetes components (and applications running on Kubernetes) are distributed by default if they run more than one replica. This can result in some interesting failure modes, which can be hard to debug.</p>
			<p>For this reason, applications <a id="_idIndexMarker507"/>on Kubernetes are less prone to failure if they are stateless – in which case, the state is offloaded to a cache or database running outside of Kubernetes. Kubernetes primitives such as StatefulSets and PersistentVolumes can make it much easier to run stateful applications on Kubernetes – and with every release, the experience of running stateful applications on Kubernetes improves. Still, deciding to run fully stateful applications on Kubernetes introduces complexity and therefore the potential for failure.</p>
			<p>Failure in distributed applications can be introduced by many different factors. Things as simple as network reliability and bandwidth constraints can cause major issues. These are so varied that <em class="italic">Peter Deutsch</em> at <em class="italic">Sun Microsystems</em> helped pen the <em class="italic">Fallacies of distributed computing</em> (along with <em class="italic">James Gosling</em>, who added the 8th point), which are commonly agreed-upon factors for failures in distributed applications. In the paper <em class="italic">Fallacies of distributed computing explained</em>, <em class="italic">Arnon Rotem-Gal-Oz</em> discusses the source of these fallacies (<a href="https://www.rgoarchitects.com/Files/fallacies.pdf">https://www.rgoarchitects.com/Files/fallacies.pdf</a>).</p>
			<p>The fallacies are as follows, in numerical order: </p>
			<ol>
				<li>The network is reliable.</li>
				<li>Latency is zero.</li>
				<li>Bandwidth is infinite.</li>
				<li>The network is secure.</li>
				<li>The topology doesn't change.</li>
				<li>There is one administrator.</li>
				<li>Transport cost is zero.</li>
				<li>The network is homogeneous.</li>
			</ol>
			<p>Kubernetes has been engineered and developed with these fallacies in mind and is therefore more tolerant. It also helps address these issues for applications running on Kubernetes – but not perfectly. It is therefore very possible that your applications, when containerized and running on Kubernetes, will exhibit problems when faced with any of these issues. Each fallacy, when assumed to be untrue and taken to its logical conclusion, can introduce failure modes in distributed applications. Let's go through each of the fallacies as applied to Kubernetes and applications running on Kubernetes.</p>
			<h2 id="_idParaDest-221"><a id="_idTextAnchor233"/>The network is reliable</h2>
			<p>Applications running on<a id="_idIndexMarker508"/> multiple logical machines must communicate over the internet – so any reliability problems in the network can introduce issues. On Kubernetes specifically, the control plane itself can be distributed in a highly available setup (which means a setup with multiple master Nodes – see <a href="B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016"><em class="italic">Chapter 1</em></a>, <em class="italic">Communicating with Kubernetes</em>), which means that failure modes can be introduced at the controller level. If the network is unreliable, then kubelets may not be able to communicate with the control plane, leading to Pod placement issues.</p>
			<p>Similarly, the Nodes of the control plane may not be able to communicate with each other – though <code>etcd</code> is of course built with a consensus protocol that can tolerate communication failures.</p>
			<p>Finally, the worker Nodes may not be able to communicate with each other – which, in a microservices scenario, could cause problems depending on Pod placement. In some cases, the workers may all be able to communicate with the control plane while still not being able to communicate with each other, which can cause issues with the Kubernetes overlay network.</p>
			<p>As with general unreliability, latency can also cause many of the same problems.</p>
			<h2 id="_idParaDest-222"><a id="_idTextAnchor234"/>Latency is zero</h2>
			<p>If network latency is significant, many of the same failures as with network unreliability will also apply. For instance, calls between kubelets and the control plane may fail, leading to periods of inaccuracy in <code>etcd</code> because the control plane may not be able to contact the kubelets – or properly update <code>etcd</code>. Similarly, requests could be lost between applications running on worker Nodes that would otherwise work perfectly if the applications were collocated on the same Node.</p>
			<h2 id="_idParaDest-223"><a id="_idTextAnchor235"/>Bandwidth is infinite</h2>
			<p>Bandwidth limitations can expose similar issues as with the previous two fallacies. Kubernetes does not currently have a fully supported method to place Pods based on bandwidth subscription. This means that Nodes that are hitting their network bandwidth limits can still have new Pods scheduled to them, causing increased failure rates and latency issues for requests. There have been requests to add this as a core Kubernetes scheduling<a id="_idIndexMarker509"/> feature (basically, a way to schedule on Node bandwidth consumption as with CPU and memory), but for now, the solutions are <a id="_idIndexMarker510"/>mostly restricted to <strong class="bold">Container Network Interface</strong> (<strong class="bold">CNI</strong>) plugins. </p>
			<p class="callout-heading">Important note</p>
			<p class="callout">For instance, the CNI bandwidth plugin supports traffic shaping at the Pod level – see <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping">https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping</a>.</p>
			<p>Third-party Kubernetes networking implementations may also provide additional features around bandwidth – and many are compatible with the CNI bandwidth plugin.</p>
			<h2 id="_idParaDest-224"><a id="_idTextAnchor236"/>The network is secure</h2>
			<p>Network security has effects that reach far beyond Kubernetes – as any insecure network is privy to a whole class of attacks. Attackers may be able to gain SSH access to the master or worker Nodes in a Kubernetes cluster, which can cause significant breaches. Since so much of Kubernetes' magic happens over the network rather than in a single machine, access to the network is doubly problematic in an attack situation.</p>
			<h2 id="_idParaDest-225"><a id="_idTextAnchor237"/>The topology doesn't change</h2>
			<p>This fallacy is extra relevant in the context of Kubernetes, since not only can the meta network topology change with new Nodes being added and removed – the overlay network topology is also altered directly by the Kubernetes control plane and CNI. </p>
			<p>For this reason, an application that is running in one logical location at one moment may be running in a completely different spot in the network. For this reason, the use of Pod IPs to identify logical applications is a bad idea – this is one of the purposes of the Service abstraction (see <a href="B14790_05_Final_PG_ePub.xhtml#_idTextAnchor127"><em class="italic">Chapter 5</em></a>, <em class="italic">Service and Ingress</em> – <em class="italic">Communicating with the outside world</em>). Any application concerns that do not assume an indefinite topology (at least concerning IPs) within the cluster may have issues. As an example, routing applications to a specific Pod IP only works until something happens to that Pod. If that Pod shuts down, the Deployment (for instance) controlling it will start a new Pod to replace it, but the IP will be completely different. A cluster DNS (and by extension, Services) offers a much better way to make requests between applications in a cluster, unless your application has the capability to adjust on the fly to cluster changes such as Pod placements.</p>
			<h2 id="_idParaDest-226"><a id="_idTextAnchor238"/>There is only one administrator</h2>
			<p>Multiple administrators <a id="_idIndexMarker511"/>and conflicting rules can cause issues in the base network, and multiple Kubernetes administrators can cause further issues by changing resource configurations such as Pod resource limits, leading to unintended behavior. Use of Kubernetes <strong class="bold">Role-Based Access Control</strong> (<strong class="bold">RBAC</strong>) capabilities can<a id="_idIndexMarker512"/> help address this by giving Kubernetes users only the permissions they need (read-only, for instance).</p>
			<h2 id="_idParaDest-227"><a id="_idTextAnchor239"/>Transport cost is zero</h2>
			<p>There are two common ways this fallacy is interpreted. Firstly, that the latency cost of transport is zero – which is obviously untrue, as the speed of data transfer over wires is not infinite, and lower-level networking concerns add latency. This is essentially identical to the effects stemming from the <em class="italic">latency is zero</em> fallacy. </p>
			<p>Secondly, this statement can be interpreted to mean that the cost of creating and operating a network for the purposes of transport is zero – as in zero dollars and zero cents. While also being patently untrue (just look at your cloud provider's data transfer fees for proof of this), this does not specifically correspond to application troubleshooting on Kubernetes, so we will focus on the first interpretation.</p>
			<h2 id="_idParaDest-228"><a id="_idTextAnchor240"/>The network is homogeneous</h2>
			<p>This final fallacy has less to do with Kubernetes' components, and more to do with applications running on Kubernetes. However, the fact is that developers operating in today's environment are well aware that application networking may have different implementations across applications – from HTTP 1 and 2 to protocols such as <em class="italic">gRPC</em>.</p>
			<p>Now that we've reviewed some major reasons for application failure on Kubernetes, we can dive into the actual process of troubleshooting both Kubernetes and applications that run on Kubernetes.</p>
			<h1 id="_idParaDest-229"><a id="_idTextAnchor241"/>Troubleshooting Kubernetes clusters</h1>
			<p>Since Kubernetes is a<a id="_idIndexMarker513"/> distributed system that has been designed to tolerate failure where applications are run, most (but not all) issues tend to be centered on the control plane and API. A worker Node failing, in most scenarios, will just result in the Pods being rescheduled to another Node – though compounding factors can introduce issues. </p>
			<p>In order to walk through common Kubernetes cluster issue scenarios, we will use a case study methodology. This should give you all the tools you need to investigate real-world cluster issues. Our first case study is centered on the failure of the API server itself.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">For the purposes of this tutorial, we will assume a self-managed cluster. Managed Kubernetes services such as EKS, AKS, and GKE generally remove some of the failure domains (by autoscaling and managing master Nodes, for instance). A good rule is to check your managed service documentation first, as any issues may be specific to the implementation.</p>
			<h2 id="_idParaDest-230"><a id="_idTextAnchor242"/>Case study – Kubernetes Pod placement failure</h2>
			<p>Let's set the scene. Your <a id="_idIndexMarker514"/>cluster is up and running, but you are experiencing a problem with Pod scheduling. Pods stay stuck in the <code>Pending</code> state indefinitely. Let's confirm this with the command:</p>
			<pre>kubectl get pods</pre>
			<p>The output of the command is the following:</p>
			<pre>NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-tj8ks        0/1       Pending   0          2d
app-1-pod-2821252345-9fj2k        0/1       Pending   0          2d
app-1-pod-2821252345-06hdj        0/1       Pending   0          2d</pre>
			<p>As we can see, none of our Pods are running. Furthermore, we're running three replicas of the application and none of them are getting scheduled. A great next step would be to check the Node state and see if there are any issues there. Run the following command to get the output:</p>
			<pre>kubectl get nodes</pre>
			<p>We get the following output:</p>
			<pre>  NAME           STATUS     ROLES    AGE    VERSION
  node-01        NotReady   &lt;none&gt;   5m     v1.15.6</pre>
			<p>This output gives us some good information – we only have one worker Node, and it isn't available for scheduling. When a <code>get</code> command doesn't give us enough information to go by, <code>describe</code> is usually a good next step. </p>
			<p>Let's run <code>kubectl describe node node-01</code> and check the <code>conditions</code> key. We've dropped a<a id="_idIndexMarker515"/> column in order to fit everything neatly on the page, but the most important columns are there:</p>
			<div><div><img src="img/B14790_10_001.jpg" alt="Figure 10.1 – Describe Node Conditions output"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.1 – Describe Node Conditions output</p>
			<p>What we have here is an interesting split: both <code>MemoryPressure</code> and <code>DiskPressure</code> are fine, while the <code>OutOfDisk</code> and <code>Ready</code> conditions are unknown with the message <code>kubelet stopped posting node status</code>. At a first glance this seems nonsensical – how can <code>MemoryPressure</code> and <code>DiskPressure</code> be fine while the kubelet stopped working?  </p>
			<p>The important part is in the <code>LastTransitionTime</code> column. The kubelet's most recent memory- and disk-specific communication sent positive statuses. Then, at a later time, the kubelet stopped posting its Node status, leading to <code>Unknown</code> statuses for the <code>OutOfDisk</code> and <code>Ready</code> conditions.</p>
			<p>At this point, we're certain that our Node is the problem – the kubelet is no longer sending the Node status to the control plane. However, we don't know why this occurred. It could be a network error, a problem with the machine itself, or something more specific. We'll need to dig further to figure it out.</p>
			<p>A good next step here is to get closer to our malfunctioning Node, as we can reasonably assume that it is encountering some sort of issue. If you have access to the <code>node-01</code> VM or machine, now is a great time to SSH into it. Once we are in the machine, let's start troubleshooting further.</p>
			<p>First, let's check whether<a id="_idIndexMarker516"/> the Node can access the control plane over the network. If not, this is an obvious reason why the kubelet wouldn't be able to post statuses. Let's assume a scenario where our cluster control plane (for instance an on-premise load balancer) is available at <code>10.231.0.1</code>. In order to check whether our Node can access the Kubernetes API server, we can ping the control plane as follows:</p>
			<pre>ping 10.231.0.1   </pre>
			<p class="callout-heading">Important note</p>
			<p class="callout">In order to find the control plane IP or DNS, please check your cluster configuration. In a managed Kubernetes service such as AWS Elastic Kubernetes Service or Azure AKS, this will likely be available to view in the console. If you bootstrapped your own cluster using kubeadm, for instance, this is a value that you provided during the setup as part of the installation.</p>
			<p>Let's check the results:</p>
			<pre>Reply from 10.231.0.1: bytes=1500 time=28ms TTL=54
Reply from 10.231.0.1: bytes=1500 time=26ms TTL=54
Reply from 10.231.0.1: bytes=1500 time=27ms TTL=54</pre>
			<p>That confirms it – our Node can indeed talk to the Kubernetes control plane. So, the network isn't the issue. Next, let's check the actual kubelet service. The Node itself seems to be operational, and the network is fine, so logically, the kubelet is the next thing to check.</p>
			<p>Kubernetes components run as system services on Linux Nodes. </p>
			<p class="callout-heading">Important note</p>
			<p class="callout">On Windows Nodes, the troubleshooting instructions will be slightly different – see the Kubernetes documentation for more information (<a href="https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/">https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/</a>). </p>
			<p>In order to find out the <a id="_idIndexMarker517"/>status of our <code>kubelet</code> service, we can run the following command:</p>
			<pre>systemctl status kubelet -l </pre>
			<p>This gives us the following output:</p>
			<pre> • kubelet.service - kubelet: The Kubernetes Node Agent
   Loaded: loaded (/lib/systemd/system/kubelet.service; enabled)
  Drop-In: /etc/systemd/system/kubelet.service.d
           └─10-kubeadm.conf
   Active: activating (auto-restart) (Result: exit-code) since Fri 2020-05-22 05:44:25 UTC; 3s ago
     Docs: http://kubernetes.io/docs/
  Process: 32315 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_CERTIFICATE_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE)
 Main PID: 32315 (code=exited, status=1/FAILURE)</pre>
			<p>Looks like our kubelet is currently not running – it exited with a failure. This explains everything we've seen as far as cluster status and Pod issues.</p>
			<p>To actually fix the issue, we can first try to restart the <code>kubelet</code> using the command:</p>
			<pre>systemctl start kubelet</pre>
			<p>Now, let's re-check the status of our <code>kubelet</code> with our status command:</p>
			<pre> • kubelet.service - kubelet: The Kubernetes Node Agent
   Loaded: loaded (/lib/systemd/system/kubelet.service; enabled)
  Drop-In: /etc/systemd/system/kubelet.service.d
           └─10-kubeadm.conf
   Active: activating (auto-restart) (Result: exit-code) since Fri 2020-05-22 06:13:48 UTC; 10s ago
     Docs: http://kubernetes.io/docs/
  Process: 32007 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_CERTIFICATE_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE)
 Main PID: 32007 (code=exited, status=1/FAILURE)</pre>
			<p>It looks like the <code>kubelet</code> <a id="_idIndexMarker518"/>failed again. We're going to need to source some additional information about the failure mode in order to find out what happened. </p>
			<p>Let's use the <code>journalctl</code> command to find out if there are any relevant logs:</p>
			<pre>sudo journalctl -u kubelet.service | grep "failed"</pre>
			<p>The output should show us logs of the <code>kubelet</code> service where a failure occurred:</p>
			<pre>May 22 04:19:16 nixos kubelet[1391]: F0522 04:19:16.83719    1287 server.go:262] failed to run Kubelet: Running with swap on is not supported, please disable swap! or set --fail-swap-on flag to false. /proc/swaps contained: [Filename                                Type                Size        Used        Priority /dev/sda1                               partition        6198732        0        -1]</pre>
			<p>Looks like we've found the cause – Kubernetes does not support running on Linux machines with <code>swap</code> set to <code>on</code> by default. Our only choices here are either disabling <code>swap</code> or restarting the <code>kubelet</code> with the <code>--fail-swap-on</code> flag set to <code>false</code>.</p>
			<p>In our case, we'll just change the <code>swap</code> setting by using the following command:</p>
			<pre>sudo swapoff -a</pre>
			<p>Now, restart the <code>kubelet</code> service:</p>
			<pre>sudo systemctl restart kubelet</pre>
			<p>Finally, let's check to<a id="_idIndexMarker519"/> see if our fix worked. Check the Nodes using the following command:</p>
			<pre>kubectl get nodes </pre>
			<p>This should show output similar to the following:</p>
			<pre>  NAME           STATUS     ROLES    AGE    VERSION
  node-01        Ready      &lt;none&gt;   54m    v1.15.6</pre>
			<p>Our Node is finally posting a <code>Ready</code> status!  </p>
			<p>Let's check on our Pod with the following command:</p>
			<pre>kubectl get pods</pre>
			<p>This should show output like this:</p>
			<pre>NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-tj8ks        1/1       Running   0          1m
app-1-pod-2821252345-9fj2k        1/1       Running   0          1m
app-1-pod-2821252345-06hdj        1/1       Running   0          1m</pre>
			<p>Success! Our cluster is healthy, and our Pods are running. </p>
			<p>Next, let's look at how to troubleshoot applications on Kubernetes once any cluster issues are sorted out.</p>
			<h1 id="_idParaDest-231"><a id="_idTextAnchor243"/>Troubleshooting applications on Kubernetes</h1>
			<p>A perfectly running <a id="_idIndexMarker520"/>Kubernetes cluster may still have application issues to debug. These could be due to bugs in the application itself, or due to misconfigurations in the Kubernetes resources that make up the application. As with troubleshooting the cluster, we will dive into these concepts by using a case study.</p>
			<h2 id="_idParaDest-232"><a id="_idTextAnchor244"/>Case study 1 – Service not responding</h2>
			<p>We're going to break this section down into troubleshooting at various levels of the Kubernetes stack, starting with higher-level components, then ending with a deep dive into Pod and container debugging.  </p>
			<p>Let's assume that we have configured our application <code>app-1</code> to respond to requests via a <code>NodePort</code> Service, on port <code>32688</code>. The application listens on port <code>80</code>.  </p>
			<p>We can try to access our application via a <code>curl</code> request on one of our Nodes. The command will look as follows:</p>
			<pre>curl http://10.213.2.1:32688</pre>
			<p>The output of the <code>curl</code> command if it fails will look like the following:</p>
			<pre>curl: (7) Failed to connect to 10.231.2.1 port 32688: Connection refused</pre>
			<p>At this point, our <code>NodePort</code> Service isn't routing requests to any Pod. Following our typical debug path, let's first see which resources are running in the cluster with the following command:</p>
			<pre>kubectl get services</pre>
			<p>Add the <code>-o</code> wide flag to see additional information. Next, run the following command:</p>
			<pre>kubectl get services -o wide </pre>
			<p>This gives us the following output:</p>
			<pre>NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR 
app-1-svc NodePort 10.101.212.57 &lt;none&gt; 80:32688/TCP 3m01s app=app-1</pre>
			<p>It is clear that our Service exists with a proper Node port – but our requests are not being routed to the Pods, as is obvious from the failed <code>curl</code> command.</p>
			<p>To see which routes our Service has set up, let's use the <code>get endpoints</code> command. This will list the Pod IPs, if any, for the Service as configured:</p>
			<pre>kubectl get endpoints app-1-svc</pre>
			<p>Let's check the resulting output of the command:</p>
			<pre>NAME        ENDPOINTS
app-1-svc   &lt;none&gt;</pre>
			<p>Well, something is definitely wrong here. </p>
			<p>Our Service isn't pointing to any Pods. This likely means that there aren't any Pods matching our Service selector available. This could be because there are no Pods available at all – or because those Pods don't properly match the Service selector.</p>
			<p>To check on our Service selector, let's take the next step in the debug path and use the <code>describe</code> command as follows:</p>
			<pre>kubectl describe service app-1-svc  </pre>
			<p>This gives us an <a id="_idIndexMarker521"/>output like the following:</p>
			<pre>Name:                   app-1-svc
Namespace:              default
Labels:                 app=app-11
Annotations:            &lt;none&gt;
Selector:               app=app-11
Type:                   NodePort
IP:                     10.57.0.15
Port:                   &lt;unset&gt; 80/TCP
TargetPort:             80/TCP
NodePort:               &lt;unset&gt; 32688/TCP
Endpoints:              &lt;none&gt;
Session Affinity:       None
Events:                 &lt;none&gt;</pre>
			<p>As you can see, our Service is configured to talk to the correct port on our application. However, the selector is looking for Pods that match the label <code>app = app-11</code>. Since we know our application is named <code>app-1</code>, this could be the cause of our issue.</p>
			<p>Let's edit our Service to look for the correct Pod label, <code>app-1</code>, running another <code>describe</code> command to be sure:</p>
			<pre>kubectl describe service app-1-svc</pre>
			<p>This gives the <a id="_idIndexMarker522"/>following output:</p>
			<pre>Name:                   app-1-svc
Namespace:              default
Labels:                 app=app-1
Annotations:            &lt;none&gt;
Selector:               app=app-1
Type:                   NodePort
IP:                     10.57.0.15
Port:                   &lt;unset&gt; 80/TCP
TargetPort:             80/TCP
NodePort:               &lt;unset&gt; 32688/TCP
Endpoints:              &lt;none&gt;
Session Affinity:       None
Events:                 &lt;none&gt;</pre>
			<p>Now, you can see in the output that our Service is looking for the proper Pod selector, but we still do not have any endpoints. Let's check to see what is going on with our Pods by using the following command:</p>
			<pre>kubectl get pods</pre>
			<p>This shows the following output:</p>
			<pre>NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-tj8ks        0/1       Pending   0          -
app-1-pod-2821252345-9fj2k        0/1       Pending   0          -
app-1-pod-2821252345-06hdj        0/1       Pending   0          -</pre>
			<p>Our Pods are still waiting to be scheduled. This explains why, even with the proper selector, our Service isn't functioning. To get some granularity on why our Pods aren't being scheduled, let's use the <code>describe</code> command:</p>
			<pre>kubectl describe pod app-1-pod-2821252345-tj8ks</pre>
			<p>The following is the <a id="_idIndexMarker523"/>output. Let's focus on the <code>Events</code> section:</p>
			<div><div><img src="img/B14790_10_002.jpg" alt="Figure 10.2 – Describe Pod Events output"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.2 – Describe Pod Events output</p>
			<p>From the <code>Events</code> section, it looks like our Pod is failing to be scheduled due to container image pull failure. There are many possible reasons for this – our cluster may not have the necessary authentication mechanisms to pull from a private repository, for instance – but that would present a different error message.</p>
			<p>From the context and the <code>Events</code> output, we can probably assume that the issue is that our Pod definition is looking for a container named <code>myappimage:lates</code> instead of <code>myappimage:latest</code>.</p>
			<p>Let's update our Deployment spec with the proper image name and roll out the update. </p>
			<p>Use the following command to get confirmation:</p>
			<pre>kubectl get pods</pre>
			<p>The output looks like this:</p>
			<pre>NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-152sf        1/1       Running   0          1m
app-1-pod-2821252345-9gg9s        1/1       Running   0          1m
app-1-pod-2821252345-pfo92        1/1       Running   0          1m</pre>
			<p>Our Pods are now running – let's check to see that our Service has registered the proper endpoints. Use the following command to do this:</p>
			<pre>kubectl describe services app-1-svc</pre>
			<p>The output<a id="_idIndexMarker524"/> should look like this:</p>
			<pre>Name:                   app-1-svc
Namespace:              default
Labels:                 app=app-1
Annotations:            &lt;none&gt;
Selector:               app=app-1
Type:                   NodePort
IP:                     10.57.0.15
Port:                   &lt;unset&gt; 80/TCP
TargetPort:             80/TCP
NodePort:               &lt;unset&gt; 32688/TCP
Endpoints:              10.214.1.3:80,10.214.2.3:80,10.214.4.2:80
Session Affinity:       None
Events:                 &lt;none&gt;</pre>
			<p>Success! Our Service is properly pointing to our application Pods. </p>
			<p>In the next case study, we'll dig a bit deeper by troubleshooting a Pod with incorrect startup parameters.</p>
			<h2 id="_idParaDest-233"><a id="_idTextAnchor245"/>Case study 2 – Incorrect Pod startup command</h2>
			<p>Let's assume we have our <a id="_idIndexMarker525"/>Service properly configured and our Pods running and passing health checks. However, our Pod is not responding to requests as we would expect. We are sure that this is less of a Kubernetes problem and more of an application or configuration problem.</p>
			<p>Our application container works as follows: it takes a startup command with a flag for <code>color</code> and combines it with a variable for <code>version number</code> based on the container's <code>image</code> tag, and echoes that back to the requester. We are expecting our application to return <code>green 3</code>.  </p>
			<p>Thankfully, Kubernetes gives us some good tools to debug applications, which we can use to delve into our specific containers. </p>
			<p>First, let's <code>curl</code> the application to see what response we get:</p>
			<pre>curl http://10.231.2.1:32688  
red 2</pre>
			<p>We expected <code>green 3</code> but got <code>red 2</code>, so it looks like something is wrong with the input, and the version number variable. Let's start with the former.</p>
			<p>As usual, we begin with checking our Pods with the following command:</p>
			<pre>kubectl get pods</pre>
			<p>The output should look like the following:</p>
			<pre>NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-152sf        1/1       Running   0          5m
app-1-pod-2821252345-9gg9s        1/1       Running   0          5m
app-1-pod-2821252345-pfo92        1/1       Running   0          5m</pre>
			<p>Everything looks good in this output. It seems that our app is running as part of a Deployment (and therefore, a ReplicaSet) – we can make sure by running the following command:</p>
			<pre>kubectl get deployments</pre>
			<p>The output should look like the following:</p>
			<pre>NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
app-1-pod     3         3         3            3           5m</pre>
			<p>Let's look a bit closer at<a id="_idIndexMarker526"/> our Deployment to see how our Pods are configured using the following command:</p>
			<pre>kubectl describe deployment app-1-pod -o yaml</pre>
			<p>The output looks like the following:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Broken-deployment-output.yaml</p>
			<pre>apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-1-pod
spec:
  selector:
    matchLabels:
      app: app-1
  replicas: 3
  template:
    metadata:
      labels:
        app: app-1
    spec:
      containers:
      - name: app-1
        image: mycustomrepository/app-1:2
        command: [ "start", "-color", "red" ]
        ports:
        - containerPort: 80</pre>
			<p>Let's see if we can fix our issue, which is really quite simple. We're using the wrong version of our application, and our startup command is wrong. In this case, let's assume we don't have a file <a id="_idIndexMarker527"/>with our Deployment spec – so let's just edit it in place.</p>
			<p>Let's use <code>kubectl edit deployment app-1-pod</code>, and edit the Pod spec to the following:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">fixed-deployment-output.yaml</p>
			<pre>apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-1-pod
spec:
  selector:
    matchLabels:
      app: app-1
  replicas: 3
  template:
    metadata:
      labels:
        app: app-1
    spec:
      containers:
      - name: app-1
        image: mycustomrepository/app-1:3
        command: [ "start", "-color", "green" ]
        ports:
        - containerPort: 80</pre>
			<p>Once the Deployment is saved, you should start seeing your new Pods come up. Let's double-check by using the following command:</p>
			<pre> kubectl get pods</pre>
			<p>The output should<a id="_idIndexMarker528"/> look like the following:</p>
			<pre>NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-f928a        1/1       Running   0          1m
app-1-pod-2821252345-jjsa8        1/1       Running   0          1m
app-1-pod-2821252345-92jhd        1/1       Running   0          1m</pre>
			<p>And finally – let's make a <code>curl</code> request to check that everything is working:</p>
			<pre>curl http://10.231.2.1:32688  </pre>
			<p>The output of the command is as follows:</p>
			<pre>green 3</pre>
			<p>Success!</p>
			<h2 id="_idParaDest-234"><a id="_idTextAnchor246"/>Case study 3 – Pod application malfunction with logs</h2>
			<p>After spending the previous chapter, <a href="B14790_9_Final_PG_ePub.xhtml#_idTextAnchor212"><em class="italic">Chapter 9</em></a>, <em class="italic">Observability on Kubernetes</em>, implementing observability to our applications, let's take a look at a case where those tools can really come in handy. We will use manual <code>kubectl</code> commands for the purposes of this case study – but know that by aggregating logs (for instance, in our EFK stack implementation), we could make the process of debugging this application significantly easier.</p>
			<p>In this case study, we <a id="_idIndexMarker529"/>once again have a deployment of Pods – to check it, let's run the following command:</p>
			<pre>kubectl get pods</pre>
			<p>The output of the command is as follows:</p>
			<pre>NAME              READY     STATUS    RESTARTS   AGE
app-2-ss-0        1/1       Running   0          10m
app-2-ss-1       1/1       Running   0          10m
app-2-ss-2       1/1       Running   0          10m</pre>
			<p>It looks like, in this case, we are working with a StatefulSet instead of a Deployment – a key characteristic here is the incrementing Pod IDs starting from 0.</p>
			<p>We can confirm this by checking for StatefulSets using the following command:</p>
			<pre>kubectl get statefulset</pre>
			<p>The output of the command is as follows:</p>
			<pre>NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
app-2-ss      3         3         3            3           10m</pre>
			<p>Let's take a closer look at our StatefulSet with <code>kubectl get statefulset -o yaml app-2-ss</code>. By using the <code>get</code> command along with <code>-o yaml</code> we can get our <code>describe</code> output in the same format as the typical Kubernetes resource YAML.  </p>
			<p>The output of the preceding command is as follows. We've removed the Pod spec section to keep it shorter: </p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">statefulset-output.yaml</p>
			<pre>apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: app-2-ss
spec:
  selector:
    matchLabels:
      app: app-2
  replicas: 3
  template:
    metadata:
      labels:
        app: app-2</pre>
			<p>We know that our app is<a id="_idIndexMarker530"/> using a service. Let's see which one it is!</p>
			<p>Run <code>kubectl get services -o wide</code>. The output should be something like the following:</p>
			<pre>NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR 
app-2-svc NodePort 10.100.213.13 &lt;none&gt; 80:32714/TCP 3m01s app=app-2</pre>
			<p>It's clear that our service is called <code>app-2-svc</code>. Let's see our exact service definition using the following command:</p>
			<pre>kubectl describe services app-2-svc </pre>
			<p>The output is as follows:</p>
			<pre>Name:                   app-2-svc
Namespace:              default
Labels:                 app=app-2
Annotations:            &lt;none&gt;
Selector:               app=app-2
Type:                   NodePort
IP:                     10.57.0.12
Port:                   &lt;unset&gt; 80/TCP
TargetPort:             80/TCP
NodePort:               &lt;unset&gt; 32714/TCP
Endpoints:              10.214.1.1:80,10.214.2.3:80,10.214.4.4:80
Session Affinity:       None
Events:                 &lt;none&gt;</pre>
			<p>To see exactly what our <a id="_idIndexMarker531"/>application is returning for a given input, we can use <code>curl</code> on our <code>NodePort</code> Service: </p>
			<pre>&gt; curl http://10.231.2.1:32714?equation=1plus1
3</pre>
			<p>Based on our existing knowledge of the application, we would assume that this call should return <code>2</code>, not <code>3</code>. The application developer on our team has asked us to investigate any logging output that would help them figure out what the issue is.</p>
			<p>We know from previous chapters that you can investigate the logging output with <code>kubectl logs &lt;pod name&gt;</code>. In our case, we have three replicas of our application, so we may not be able to find our logs in a single iteration of this command. Let's pick a Pod at random and see if it was the one that served our request:</p>
			<pre>&gt; kubectl logs app-2-ss-1
&gt;</pre>
			<p>It looks like this was not the Pod that served our request, as our application developer has told us that the application definitely logs to <code>stdout</code> when a <code>GET</code> request is made to the server.</p>
			<p>Instead of checking through the other two Pods individually, we can use a joint command to get logs from all three Pods. The command will be as follows:</p>
			<pre>&gt; kubectl logs statefulset/app-2-ss</pre>
			<p>And the output is as follows:</p>
			<pre>&gt; Input = 1plus1
&gt; Operator = plus
&gt; First Number = 1
&gt; Second Number = 2</pre>
			<p>That did the trick – and what's more, we can see some good insight into our issue. </p>
			<p>Everything seems as we would expect, other than the log line reading <code>Second Number</code>. Our <a id="_idIndexMarker532"/>request clearly used <code>1plus1</code> as the query string, which would make both the first number and the second number (split by the operator value) equal to one.</p>
			<p>This will take some additional digging. We could triage this issue by sending additional requests and checking the output in order to guess what is happening, but in this case it may be better to just get bash access to the Pod and figure out what is going on.</p>
			<p>First, let's check our Pod spec, which was removed from the preceding StatefulSet YAML. To see the full StatefulSet spec, check the GitHub repository:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Statefulset-output.yaml</p>
			<pre>spec:
  containers:
  - name: app-2
    image: mycustomrepository/app-2:latest
    volumeMounts:
    - name: scratch
      mountPath: /scratch
  - name: sidecar
    image: mycustomrepository/tracing-sidecar
  volumes:
  - name: scratch-volume
    emptyDir: {}</pre>
			<p>It looks like our<a id="_idIndexMarker533"/> Pod is mounting an empty volume as a scratch disk. It also has two containers in each Pod – a sidecar used for application tracing, and our app itself. We'll need this information to <code>ssh</code> into one of the Pods (it doesn't matter which one for this exercise) using the <code>kubectl exec</code> command. </p>
			<p>We can do it using the following command:</p>
			<pre>kubectl exec -it app-2-ss-1 app2 -- sh.  </pre>
			<p>This command should give you a bash terminal as the output:</p>
			<pre>&gt; kubectl exec -it app-2-ss-1 app2 -- sh
# </pre>
			<p>Now, using the terminal we just created, we should be able to investigate our application code. For the purposes of this tutorial, we are using a highly simplified Node.js application.</p>
			<p>Let's check our Pod filesystem to see what we're working with using the following command:</p>
			<pre># ls
# app.js calculate.js scratch</pre>
			<p>Looks like we have two JavaScript files, and our previously mentioned <code>scratch</code> folder. It's probably a good bet to assume that <code>app.js</code> contains the logic for bootstrapping and serving the application, and <code>calculate.js</code> contains our controller code for doing the calculations.</p>
			<p>We can confirm by printing the contents of the <code>calculate.js</code> file:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Broken-calculate.js</p>
			<pre># cat calculate.js
export const calculate(first, second, operator)
{
  second++;
  if(operator === "plus")
  {
   return first + second;
  }
}</pre>
			<p>Even with little to no knowledge of JavaScript, it's pretty obvious what the issue is here. The code is incrementing the <code>second</code> variable before performing the calculation.</p>
			<p>Since we're inside <a id="_idIndexMarker534"/>of the Pod, and we're using a non-compiled language, we can actually edit this file inline! Let's use <code>vi</code> (or any text editor) to correct this file:</p>
			<pre># vi calculate.js</pre>
			<p>And edit the file to read as follows:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">fixed-calculate.js</p>
			<pre>export const calculate(first, second, operator)
{
  if(operator === "plus")
  {
   return first + second;
  }
}</pre>
			<p>Now, our code should run properly. It's important to state that this fix is only temporary. As soon as our Pod shuts down or gets replaced by another Pod, it will revert to the code that was originally included in the container image. However, this pattern does <a id="_idIndexMarker535"/>allow us to try out quick fixes.</p>
			<p>After exiting the <code>exec</code> session using the <code>exit</code> bash command, let's try our URL again:</p>
			<pre>&gt; curl http://10.231.2.1:32714?equation=1plus1
2</pre>
			<p>As you can see, our hotfixed container shows the right result! Now, we can update our code and Docker image in a more permanent way with our fix. Using <code>exec</code> is a great way to troubleshoot and debug running containers.</p>
			<h1 id="_idParaDest-235"><a id="_idTextAnchor247"/>Summary</h1>
			<p>In this chapter, we learned about troubleshooting applications on Kubernetes. First, we covered some common failure modes of distributed applications. Then, we learned how to triage issues with Kubernetes components. Finally, we reviewed several scenarios where Kubernetes configuration and application debugging were performed. The Kubernetes debugging and troubleshooting techniques you learned in this chapter will help you when triaging issues with any Kubernetes clusters and applications you may work on.</p>
			<p>In the next chapter, <a href="B14790_11_Final_PG_ePub.xhtml#_idTextAnchor251"><em class="italic">Chapter 11</em></a>, <em class="italic">Template Code Generation and CI/CD on Kubernetes</em>, we will look into some ecosystem extensions for templating Kubernetes resource manifests and continuous integration/continuous deployment with Kubernetes.</p>
			<h1 id="_idParaDest-236"><a id="_idTextAnchor248"/>Questions</h1>
			<ol>
				<li value="1">How does the distributed systems fallacy, "<em class="italic">the topology doesn't change</em>," apply to applications on Kubernetes?</li>
				<li>How are the Kubernetes control plane components (and kubelet) implemented at the OS level?</li>
				<li>How would you go about debugging an issue where Pods are stuck in the <code>Pending</code> status? What would be your first step? And your second?</li>
			</ol>
			<h1 id="_idParaDest-237"><a id="_idTextAnchor249"/>Further reading</h1>
			<ul>
				<li>The CNI plugin for traffic shaping: <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping">https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping</a></li>
			</ul>
		</div>
	</body></html>