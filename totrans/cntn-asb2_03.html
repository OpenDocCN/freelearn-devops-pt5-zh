<html><head></head><body>
        

                            
                    <h1 class="header-title">Your First Ansible Container Project</h1>
                
            
            
                
<p>As we learned in <a href="089af66a-24d7-4d4d-bcfd-56bfe873ea91.xhtml" target="_blank">Chapter 2</a>, <em>Working with Ansible Container</em>, Ansible Container is a powerful tool for orchestrating, deploying, and managing containers in a production environment. Using a unique set of versatile tools to initiate, build, run, and deploy Ansible Container enables developers to build containerized applications and deploy them to local environments or cloud hosting providers. Using Ansible Container, we can be sure that containers can be built accurately, will run reliably, and will provide users with a consistent experience, no matter which application or platform the containers are deployed to.</p>
<p>In this chapter, we will focus on building our first Ansible Container project by building an application container, testing it in our local environment, and pushing our container artifact to a container image repository. This will provide the user with a real-world use case for Ansible Container and provide experience with leveraging container-enabled roles. In this chapter, you will learn:</p>
<ul>
<li class="mce-root">What are Ansible roles and container-enabled roles?</li>
<li class="mce-root">Roles in Ansible Galaxy</li>
<li>Ansible Container NGINX role</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">What are Ansible roles and container-enabled roles?</h1>
                
            
            
                
<p>Roles in Ansible are a way to organize playbooks into reusable, shareable, and discrete units that are normally broken up by an application. Inside of a role are typically a series of playbooks, configuration file templates, static files, and other metadata that are required to bring the target host (or container) into a desired state. In a typical three-tier application stack, consisting of a web server, database server, and a load balancer, each of these components might be contained in three separate Ansible roles. This provides the benefits of reuse across your infrastructure and a simple way to share playbooks over the internet or with coworkers. For example, if you wrote a load balancer role for one project, and needed to provision another load balancer for an entirely different project, you could simply download the role and assign it to another set of inventory hosts. In Ansible Core, roles are assigned to servers or virtual machines through a parent playbook that describes what the infrastructure looks like and how Ansible should bring that infrastructure into the desired state. The main benefit of roles is that they provide the user with a simple interface to access commonly used playbook tasks and resources so that the user can be certain their infrastructure is configured and running precisely as expected.</p>
<p>In Ansible Container, roles work in a way that is remarkably similar to Ansible Core. In Ansible Container, instead of assigning roles based on infrastructure components, roles are assigned to individual containers, which are then built using the configurations described in Ansible playbooks by the conductor container. One of the major benefits of Ansible Container is that it greatly simplifies the curve to enable containerized resources in your infrastructure. Many Ansible Core roles can be reused to build containers that function very similarly to how your infrastructure runs if you are currently using Ansible Core for configuration management. Unfortunately, since containers and full infrastructure servers are fundamentally different, not all tasks can be directly ported to Ansible Container roles without a little rework. For example, since containers are much more lightweight than a full-blown operating system, containers usually lack tools and components that come in most operating system releases, such as init systems and resource managers.</p>
<p>To address this disparity, the Ansible Container project has created a different subset of roles, known as <em>container-enabled roles</em>. These are roles that are designed with a focus on containers and are usually more minimalistic then regular Ansible roles. These are leveraged to create a final container image with the smallest footprint possible while maximizing functionality and flexibility. Container-enabled roles consist of many of the same constructs that regular Ansible roles do, such as templates, tasks, handlers, and metadata. This makes it easy to get started writing roles for Ansible Container if you are familiar with Ansible syntax and language constructs.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Roles in Ansible Galaxy</h1>
                
            
            
                
<p>Ansible Galaxy, located at <a href="https://galaxy.ansible.com/">https://galaxy.ansible.com</a>, is a site created by the Ansible Community to share, download, and encourage the reuse of Ansible roles. From Ansible Galaxy, you can search and download roles for almost any application or platform you wish to automate. If you have experience with Ansible Core, you have undoubtedly used Ansible Galaxy to download, share, and explore roles written and maintained by other Ansible users. If you are new to Ansible, Galaxy makes it easy to find and leverage new roles from your web browser or the Ansible command line. With the release of Ansible Container, you can browse Ansible Galaxy for core roles as well as container-enabled roles. From the main website (<a href="https://galaxy.ansible.com/">https://galaxy.ansible.com</a>) you can select BROWSE ROLES | Role Type | Container Enabled to search for roles that fit your particular requirements:</p>
<div><strong><img height="355" width="797" src="img/2adc2d03-4129-44bd-af89-ceefa55cb323.png"/><br/></strong></div>
<p>Figure 1: Ansible Galaxy website browsing for container-enabled roles</p>
<p>More recently, the Ansible Container community created the concept of <em>container apps</em>, which are (sometimes) used to deploy multiple containers that constitute an application stack. We will look into <em>container apps</em> later in the book.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Ansible Container NGINX role</h1>
                
            
            
                
<p>Throughout this chapter, we are going to look at how to leverage pre-written Ansible Container roles featured on Ansible Galaxy to quickly get up-and-running using roles to deploy container-based services. One of the major benefits of Ansible Galaxy is that it gives users the ability to leverage the collective knowledge pool of other users who have opted to share their projects in the form of roles. Like many DevOps engineers, you are probably not familiar with how every possible application, framework, or service should be configured for optimal performance. Online repositories such as Ansible Galaxy help to simplify the learning curve of deploying many new applications, since the applications essentially work out-of-the-box with little to no input required from the user. Users who consume roles from Ansible Galaxy also have the option of customizing already-written roles to suit their particular requirements. Throughout this chapter, we will be using the official Ansible Container NGINX role to build and deploy a functional NGINX web server container. The link to the role we are using can be found here: <a href="https://galaxy.ansible.com/ansible/nginx-container/">https://galaxy.ansible.com/ansible/nginx-container/</a>.</p>
<p>Before we start installing and using the NGINX role, let's review the Ansible Container workflow and how it applies to prewritten roles:</p>
<ul>
<li class="mce-root"><kbd>ansible-container init</kbd>: Used to initialize a new project to use our role with.</li>
<li class="mce-root"><kbd>ansible-container build</kbd>: Generates the conductor container that we will use to install the NGINX role. <kbd>build</kbd> is also used after installing the role to build the container image.</li>
<li class="mce-root"><kbd>ansible-container install</kbd>: Leverages the conductor container to download and install our role within the project.</li>
<li class="mce-root"><kbd>ansible-container run</kbd>: Runs the project locally to test and verify that the NGINX server is running as intended.</li>
<li class="mce-root"><kbd>ansible-container push</kbd>: Pushes the built container image to your Docker Hub repository.</li>
</ul>
<p>At any time during this chapter, you can review the completed lab exercise from the GitHub repository at:  <a href="https://github.com/aric49/ansible_container_lab/tree/master/AnsibleContainer/nginx_demo">https://github.com/aric49/ansible_container_lab/tree/master/AnsibleContainer/nginx_demo</a>.</p>
<p>Prior to starting work on this lab exercise, it is a good idea to create a free Docker Hub account, which will allow you to upload and share the container you create. Go to <a href="https://hub.docker.com/">https://hub.docker.com</a> to create a free account.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Starting a new project</h1>
                
            
            
                
<p>By now, you are probably quite familiar with initializing a new Ansible Container project and generating the file and directory structure automatically using the <kbd>ansible-container init</kbd> command. From a new directory on the Vagrant host, run <kbd>ansible-container init</kbd> to begin your new project and ensure the required files are automatically generated:</p>
<pre class="western"><strong>ubuntu@node01:$ ansible-container init 
Ansible Container initialized.</strong></pre>
<p>Once you have validated that your new project files and directory scaffolding have been created, we need to run an initial, blank build of our project to create a conductor container. Before Ansible Container can install roles or build more complex projects, a conductor container needs to be present on your workstation so that Ansible Container can modify files locally and download the required dependencies that allow container roles to function properly. Now that we have initialized our project, let's do a blank build of the project in order to create a conductor container:</p>
<pre class="western"><strong>ubuntu@node01:/vagrant/AnsibleContainer/nginx_webserver$ ansible-container build
Building Docker Engine context...
Starting Docker build of Ansible Container Conductor image (please be patient)...
Parsing conductor CLI args.
Docker™ daemon integration engine loaded. Build starting.       project=nginx_webserver
All images successfully built.
Conductor terminated. Cleaning up.      command_rc=0 conductor_id=1e8a3e0164cf617ad121c27b41dfcc782c0a2990eab54b70b687555726874e27 save_container=False</strong></pre>
<p>It is best practice to always use the same base image for your conductor container that you are using to build your project containers with to ensure compatibility. If you opt to use a different base image than the default <kbd>centos:7</kbd> you may need to modify the <kbd>container.yml</kbd> file prior to building the project. More on this in later chapters.</p>
<p>Once the project has been built, you should see <kbd>All Images Successfully Built</kbd> and <kbd>command_rc=0</kbd> returned, indicating that the Ansible Container conductor container has been successfully built. You may check to ensure the conductor image has been built and resides locally on your host using the <kbd>docker images</kbd> command.</p>
<p>Newer versions of Ansible Container (1.0+) come with prebuilt conductor images that do not require you to build projects prior to installing roles. However, it is a good idea to build conductor images unique to your projects in order to fully leverage the Ansible Container workflow more effectively.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Installing the NGINX role</h1>
                
            
            
                
<p>Now that we have a new project initialized and a conductor image built, we can use the <kbd>ansible-container install</kbd> command to install the NGINX role from Ansible Galaxy. The syntax for this command is pretty straightforward: execute <kbd>ansible-container install</kbd> followed by the username of the user who owns the project, in this case, <kbd>ansible</kbd>, then a period <kbd>.</kbd> and the name of the project, <kbd>nginx-container</kbd>. You should see output similar to the following:</p>
<pre class="western"><strong>ubuntu@node01:$ ansible-container install ansible.nginx-container
Parsing conductor CLI args.
- downloading role 'nginx-container', owned by ansible
- downloading role from https://github.com/ansible/nginx-container/archive/master.tar.gz
- extracting ansible.nginx-container to /tmp/tmpip0YiN/ansible.nginx-container
- ansible.nginx-container (master) was installed successfully
Conductor terminated. Cleaning up.      command_rc=0 conductor_id=a9e6723de6f3a236dd7823dbd999b97a5e1917bcb6794f3b0e9cd4b6bb54433b save_container=False</strong></pre>
<p>Upon successful completion, you should see the message:</p>
<pre class="western"><strong>- ansible.nginx-container (master) was installed successfully</strong></pre>
<p>This indicates that the role has been successfully downloaded and installed from Ansible Galaxy and the parent GitHub repository. The <kbd>install</kbd> command also made some modifications to the <kbd>container.yml</kbd> and <kbd>requirements.yml</kbd> files that already exist in your project directory. If you open these files in a text editor, you will find that the role has already been added to these files:</p>
<p><kbd>requirements.yml</kbd>:</p>
<pre>- src: ansible.nginx-container</pre>
<p><kbd>container.yml</kbd>:</p>
<pre>services:
  ansible.nginx-container:
    roles:
    - ansible.nginx-container</pre>
<p>It is important to note that the container role has already added itself to <kbd>container.yml</kbd> with any pre-populated information the roles author wants us to use the role with. By default, Ansible Container will look inside the role, use the default information provided in the <kbd>meta/main.yml</kbd> and <kbd>meta/container.yml</kbd> files of the role, and pass this information into the build process, if it is not overridden in the <kbd>container.yml</kbd> file. Later in this chapter, we will look at how this works when we slightly customize how the NGINX role works in our project.</p>
<p>The install process also added a reference to the name of the role, <kbd>ansible.nginx-container</kbd>, to the <kbd>requirements.yml</kbd> file. This file is used to keep track of the Ansible Galaxy roles and other dependencies that are being used in the project. If you are sharing your project with another developer who wants to build the project locally, the <kbd>requirements.yml</kbd> file is leveraged by Ansible Container to install all of the dependency roles in one shot. This speeds up the development process quite a bit if you are using multiple container-enabled roles in your project.</p>
<p>Now that we have installed the container-enabled role, let's rerun our build process and build our new container image:</p>
<pre class="western"><strong>ubuntu@node01:$ ansible-container build
Building Docker Engine context...                                              
Starting Docker build of Ansible Container Conductor image (please be patient)...    
Parsing conductor CLI args.                                      
Docker™ daemon integration engine loaded. Build starting.       project=nginx_webserver   
Building service… project=nginx_webserver service=ansible.nginx-container                                                

PLAY [ansible.nginx-container] *************************************************                                  
TASK [Gathering Facts] *********************************************************                       ok:[ansible.nginx-container]                                                                                                                                     
TASK [ansible.nginx-container : Install epel-release] **************************                    
changed:[ansible.nginx-container]                                               

TASK [ansible.nginx-container : Install nginx] *********************************
changed: [ansible.nginx-container] =&gt; (item=[u'nginx', u'rsync'])                                                                      

TASK [ansible.nginx-container : Install dumb init]
*****************************
changed:[ansible.nginx-container]                                                       
TASK [ansible.nginx-container : Update nginx user]
*****************************                            
changed:[ansible.nginx-container]

TASK [ansible.nginx-container : Put nginx config]
******************************
changed: [ansible.nginx-container]

TASK [ansible.nginx-container : Create directories, if they don't exist]
******************************
changed: [ansible.nginx-container] =&gt; (item=/static)   
changed: [ansible.nginx-container] =&gt; (item=/run/nginx)
changed: [ansible.nginx-container] =&gt; (item=/var/log/nginx)  
changed: [ansible.nginx-container] =&gt; (item=/var/lib/nginx)  

TASK [ansible.nginx-container : Clear log files]
*******************************
ok: [ansible.nginx-container] =&gt; (item=access.log)
ok: [ansible.nginx-container] =&gt; (item=error.log)
................


PLAY RECAP *********************************************************************
ansible.nginx-container    : ok=18   changed=14   unreachable=0    failed=0

Applied role to service role=ansible.nginx-container service=ansible.nginx-container
Committed layer as image        image=sha256:e4416fbb0ba74f4d39a5b6522466f8c0087582de64298ac63bc43a73f577d85a service=ansible.nginx-container
Build complete. service=ansible.nginx-container
All images successfully built.
Conductor terminated. Cleaning up.      command_rc=0 conductor_id=86b437e5e4ebca2d29ef89193be1bd7184b5bc9e8566305dbf470a8cd188ac7e save_container=False</strong></pre>
<p>It looks like, our build output is a bit more interesting than previous examples. You can see that Ansible Container has recognized that our project now has a service called <kbd>ansible.nginx-container</kbd> and proceeded to run the <kbd>ansible.nginx-container</kbd> role associated with it in the <kbd>container.yml</kbd> file. During the build process, the conductor image runs Ansible Core, passing in the playbook tasks located within the role in order to bring the container image into the desired state. Each task that gets executed from the role is displayed in the build output, which allows the developer to see exactly what actions are being executed inside the container. Here are a few key takeaways to keep in mind when examining the Ansible Container build output:</p>
<ul>
<li class="mce-root"><strong>Executed tasks</strong>: In Ansible, each task has a unique name associated with it, which helps to make the build output easy for just about anyone to read and understand. Sometimes, logical conditions are not triggered correctly, which can cause some tasks to be skipped. Read through the tasks to make sure those tasks you are expecting to be run are actually run.</li>
<li class="mce-root"><strong>Changed tasks versus OK tasks</strong>: Since Ansible, at its core, is a configuration management tool, it closely follows the principle of idempotency. In other words, if Ansible sees that a task is not required to be run since the container already has the desired state, Ansible will mark that task as <kbd>OK</kbd>. When Ansible makes a change, it will mark tasks as <kbd>CHANGED</kbd>, indicating that Ansible modified something in the base container image. It is important to note that all tasks, regardless of whether they are <kbd>SKIPPED</kbd>, <kbd>CHANGED</kbd>, or <kbd>OK</kbd>, will be counted as <kbd>OK</kbd> at the end of the build process, indicating that a failure has not occurred during the task execution.</li>
<li class="mce-root"><strong>PLAY RECAP</strong>: At the end of every Ansible Container build, you will be presented with a <kbd>PLAY RECAP</kbd> section highlighting the state of the Ansible Container build. This provides a handy reference to show every task that Ansible Container executed at a quick glance and the status of the tasks: <kbd>OK</kbd>, <kbd>Changed</kbd>, <kbd>Unreachable</kbd>, or <kbd>Failed</kbd>. Tasks that have failed will cause the build process to stop immediately at the failed task unless otherwise overridden in the role.</li>
</ul>
<p>Once the build process has completed, Ansible Container commits the changes as a single layer to the base image, creating a brand new container image for your project. Remember, in <a href="61a61ca8-60d4-48a0-8987-6f719d6a2c36.xhtml" target="_blank">Chapter 1</a>, <em>Building Containers with Docker</em>, when we used Dockerfiles to build container images? If you remember, each line in a Dockerfile represents a layer in the container image. Using Dockerfiles to build complex container images can quickly create large and unruly containers that have large file sizes.</p>
<p>Using Ansible Container, we can make as many changes as we want by adding tasks in the role and our final container image is still streamlined by only having one container layer created:</p>
<div><img height="159" width="292" src="img/68bfbb96-6ded-478c-b5a7-efa1fc47661a.png"/></div>
<p>Figure 2: Container image layers in a container image built by Ansible Container</p>
<p>However, do keep in mind that you should still strive to keep container images built by Ansible Container as small as possible by only adding the most necessary files, packages, and services. Having the benefits of Ansible Container creating only one layer in the container can quickly be outweighed if having that single layer is 2 GB in size!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Running the NGINX role</h1>
                
            
            
                
<p>Now that our project has been built and the role has been applied without any errors, we can run our container using the <kbd>ansible-container run</kbd> command. <kbd>run</kbd> will leverage the local Ansible deployment playbooks, created during the build process, to bring up our container so that we can test it and ensure it is running as expected:</p>
<pre class="western"><strong>ubuntu@node01:$ ansible-container run
Parsing conductor CLI args.
Engine integration loaded. Preparing run.       engine=Docker™ daemon
Verifying service image service=ansible.nginx-container

PLAY [localhost] ***************************************************************

TASK [docker_service] **********************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=1    changed=1    unreachable=0    failed=0

All services running.   playbook_rc=0
Conductor terminated. Cleaning up.      command_rc=0 conductor_id=e62dc0e401d3d76bf771c6e8db74fb0970e9d5e57be9ad6642cff92592248215 save_container=False</strong></pre>
<p>Based on the provided <kbd>PLAY RECAP</kbd>, we can easily identify that the task that was executed on our local VM to run the container has made one change in order to bring our container into a running state. The <kbd>docker ps -a</kbd> output also shows that our container is running:</p>
<pre class="western"><strong>ubuntu@node01:~$ docker ps -a
CONTAINER ID  IMAGE  COMMAND  CREATED  STATUS  PORTS  NAMES
f213412bd485  nginx_webserver.. "/usr/bin/dumb-ini..." 2 minutes ago Up 2 minutes  0.0.0.0:8000-&gt;8000/tcp  nginxwebserver_ansible..</strong></pre>
<p>By default, this container uses the host and container TCP port: <kbd>8000</kbd> that comes out of the box with the role. Let's use the <kbd>curl</kbd> utility to see if we can access the NGINX default website on port <kbd>8000</kbd>:</p>
<pre class="western"><strong>ubuntu@node01:$ curl localhost:8000
.....(output truncated)
&lt;title&gt;Test Page for the Nginx HTTP Server on Fedora&lt;/title&gt;</strong></pre>
<p>Based on the output from <kbd>curl</kbd>, it looks like we have successfully deployed the NGINX role on our workstation and have a functional NGINX server container running. This is great if you want a web server to run on port <kbd>8000</kbd> and want it to use only the absolute defaults. Unfortunately, this is probably not ideal for anyone to use. Let's modify our role by overriding a few defaults to see if we can get a container that runs a bit closer to what we might expect to see running in an actual functional environment.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Modifying the NGINX role</h1>
                
            
            
                
<p>Ansible, functions and behaves quite differently from a lot of configuration management platforms such as Chef, Puppet, or Salt. Roles are seen as service abstractions that can be tweaked and modified to function in almost any way the user desires. Ansible provides the concept of variables and variable precedence, which can take input from a number of sources and, in order of precedence, can modify the role so that it will run differently depending on how the role itself is designed. It is important to note that role variable precedence is more common for Ansible Core, in which a user may have playbooks that need to run in development, staging, QA, and production environments, and require different configurations based on the environment they are deployed to.</p>
<p>It is still important to understand how overriding role variables and parameters can be leveraged in Ansible Container in order to build resilient and customized infrastructure artifacts. Ansible roles are designed in such a way that role variables can be overridden without modifying the role itself. Using the concept of variable precedence, Ansible Container will automatically identify role variable values in the <kbd>container.yml</kbd> file and pass these values into the role, which can be accessed by the playbooks. This allows the user to write code that is portable and repeatable simply by downloading the correct role from Ansible Galaxy and building projects using the correct <kbd>container.yml</kbd> file that contains all the customizations. Of course, not every part of a role can be overridden in the <kbd>container.yml</kbd> file, but we will learn in this section how we can make basic modifications and push our customized container images to Docker Hub.</p>
<p>When leveraging a role written by another user on Ansible Galaxy, the first thing a good Ansible Container engineer should do is read through the README file, usually located in the root directory of the role. The README will usually provide a guide on how to run the role in the most basic sense, as well as by providing a list of common variables that can be overridden. Having a firm grasp of the README is key to understanding how the role will function in the overall scheme of more complex projects. You can view the README for the NGINX role here: <a href="https://github.com/ansible/nginx-container/blob/master/README.md">https://github.com/ansible/nginx-container/blob/master/README.md</a>.</p>
<p>As you progress to writing your own Ansible Container roles and container-enabled applications, having an updated and accurate README file will be helpful for other users trying to use your project. Always update your README!</p>
<p>For this exercise, we are going to customize the <kbd>container.yml</kbd> file so that it will be exposed on the host port <kbd>80</kbd> instead of the default <kbd>8000</kbd>, and also pass in a new path for the document root, from which websites will be served. It should also be noted that we have changed the service name from the name of the role to a more commonly understood name: <kbd>webserver</kbd>. The final <kbd>container.yml</kbd> file can be found in the GitHub repository for the book in the <kbd>AnsibleContainer/nginx_demo</kbd> directory.</p>
<p>First, modify the <kbd>container.yml</kbd> file so that it resembles the following, keeping in mind that we are passing in the overridden variable <kbd>STATIC_ROOT</kbd> as a child parameter of the role we specified for our service. We determined that <kbd>STATIC_ROOT</kbd> was a valid variable that can be overridden in the role based on the information the developer provided to us in the role's README file. Essentially, this is telling Ansible Container to use the value the user has provided over the default value, which is hardcoded inside the role:</p>
<pre class="western">version: '2'
settings:
  conductor_base: centos:7

services:
  webserver:
    roles:
      - role: ansible.nginx-container
        STATIC_ROOT: /MySite
    ports:
      - "80:8000"

registries: {}</pre>
<p>Upon rebuilding our project, Ansible Container will identify changes in the <kbd>container.yml</kbd> file. This will prompt Ansible Container to rerun the role, using the updated value for <kbd>STATIC_ROOT</kbd>. You will notice that, this time, the resulting build process will take less time, and have fewer changed tasks from the first time we executed the build. You should see an output similar to the following, keeping in mind that this example is truncated:</p>
<pre class="western"><strong>ubuntu@node01:$ ansible-container build
Building Docker Engine context...
Starting Docker build of Ansible Container Conductor image (please be patient)...
Parsing conductor CLI args.
Docker™ daemon integration engine loaded. Build starting.       project=nginx_webserver
Building service...     project=nginx_webserver service=WebServer                                                               

PLAY [WebServer] ***************************************************************</strong></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Running the modified role</h1>
                
            
            
                
<p>Once the build has completed, you can execute the <kbd>ansible-container run</kbd> command to ensure that our NGINX container is still running as expected:</p>
<pre class="western"><strong>buntu@node01:$ ansible-container run
Parsing conductor CLI args.
Engine integration loaded. Preparing run.       engine=Docker™ daemon
Verifying service image service=WebServer

PLAY [localhost] ***************************************************************

TASK [docker_service] **********************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=1    changed=1    unreachable=0    failed=0

All services running.   playbook_rc=0
Conductor terminated. Cleaning up.      command_rc=0 conductor_id=b97bbb161e1a735891cacbbf1eae263c8947cf16d55480568aee8debe7763e17 save_container=False</strong></pre>
<p>As you can see from the preceding example, the run process completed as expected, displaying the message <kbd>All services running. Conductor Terminated. Cleaning Up</kbd> with the relevant zero return codes. This indicates that our container is running as expected. We can validate this in the local Docker environment, using the <kbd>docker ps -a</kbd> command again. In this example, we can see that port <kbd>8000</kbd> on the container is mapped to port <kbd>80</kbd> on the host, indicating that the changes in our <kbd>container.yml</kbd> file have been accurately built into the new iteration of our project:</p>
<pre class="western"><strong>ubuntu@node01:$ docker ps -a
CONTAINER ID  IMAGE  COMMAND  CREATED  STATUS  PORTS  NAMES</strong><br/><strong>5d979fc13cad  nginx_webserver-webserver:20170802144124 "/usr/bin/dumb-ini…"  3 minutes ago  Up 3 minutes 0.0.0.0:80 -&gt; 8000/tcp  nginxwebserver_WebServer_1</strong></pre>
<p>To ensure our NGINX server is functioning as intended, we can use our trusty <kbd>curl</kbd> command to make sure we are getting the expected response on the VM localhost port <kbd>80</kbd>:</p>
<pre class="western"><strong>ubuntu@node01:/vagrant/AnsibleContainer/nginx_webserver$ curl localhost:80
.....
&lt;title&gt;Test Page for the Nginx HTTP Server on Fedora&lt;/title&gt;</strong></pre>
<p>Congratulations! You have successfully built a functioning NGINX server container by leveraging a community role from Ansible Galaxy! We have even customized the role slightly by passing our own parameters into the role to slightly tweak the way the role functions and the resulting container. Unfortunately, the work we put into the container isn't of much use to us running on our local workstation. One of the major benefits of building containers is the ability to upload containers we build to image registries for other users to deploy and use. For this purpose, we will learn about the <kbd>ansible-container push</kbd> command to push our NGINX image to the free Docker Hub repository we created at the beginning of the chapter for others to use and download.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Pushing the project to Docker Hub</h1>
                
            
            
                
<p>To enable this functionality, we will activate the final portion of the <kbd>container.yml</kbd> file by removing the curly braces after the <kbd>registries</kbd> section. Under the registries section, we will create a subsection called docker, that takes two major parameters: URL and namespace. For this example, since we are using the Docker Hub registry, we will provide the public API URL for Docker Hub (at the time of writing) and the username we created at the beginning of the chapter as the namespace parameter. The registries section of your container.yml should resemble the following:</p>
<pre class="western">registries:
  docker:
    url: https://index.docker.io/v1/
    namespace: username</pre>
<p>It should also be noted that you can name your registry anything you want in the <kbd>container.yml</kbd> file. In this example, since we are using Docker Hub, I am using the name: <kbd>docker</kbd>. If you were using an internal or private registry, you could provide any name that makes sense. For example, <kbd>My_Corporate_Registry</kbd> might be a good name for an internal image registry hosted by your company. You can even list multiple registries, provided they are each named differently.</p>
<p>It should also be noted here that the <kbd>registries</kbd> section is a completely optional portion of the <kbd>container.yml</kbd> file. By default, the <kbd>ansible-container push</kbd> command will push to Docker Hub if no entries are written in the <kbd>registries</kbd> section of the <kbd>container.yml</kbd>. All that is required is for the user to provide a <kbd>--username</kbd> flag in the <kbd>ansible-container push</kbd> command.</p>
<p>The following example demonstrates me uploading my project to my personal image registry, supplying my username: <kbd>aric49</kbd>. Ansible Container will then prompt for your Docker Hub password and push the container image to your free registry, as shown. Ansible Container will automatically name your container based on the service name in your <kbd>container.yml</kbd> file.</p>
<pre class="western"><strong>ubuntu@node01:$ ansible-container push --username aric49 --tag 1.0
Enter password for aric49 at Docker Hub:
Parsing conductor CLI args.
Engine integration loaded. Preparing push.      engine=Docker™ daemon
Tagging aric49/nginx_webserver-webserver
Pushing aric49/nginx_webserver-webserver:1.0...
The push refers to a repository [docker.io/aric49/nginx_webserver-webserver]
Preparing
Layer already exists
1.0: digest: sha256:e0d93e16fd1ec9432ab0024653e3781ded3b1ac32ed6386677447637fcd2d3ea size: 741
Conductor terminated. Cleaning up.      command_rc=0 conductor_id=6685c1596e1da31b90b2553a84c23e112c84eeb27573e33a6c5ef7389df58f56 save_container=False</strong></pre>
<p>It is important to always provide the <kbd>--tag</kbd> flag in the <kbd>push</kbd> command. This ensures that you can maintain version control over the various iterations of your container images in the future. In this example, we are uploading version 1.0 of our container image. If you make changes to your project in the future, you can upload a version 2.0 tag and the image registry will automatically maintain the older version, 1.0, in case you ever need to roll back or upgrade to another version of your project.</p>
<p>For the purposes of this demonstration, we are not going to use the default push behavior to upload to Docker Hub, instead of uploading our container image to the image registry we specified in the <kbd>container.yml</kbd> file, which just so happens to also be Docker Hub. We can use the <kbd>--push-to</kbd> flag to specify the name of the image registry we configured in our project, providing the username and image tagging details as in the preceding example:</p>
<pre class="western"><strong>ansible-container push --username username --push-to docker --tag 1.0</strong></pre>
<p>Once the container has been uploaded to our image registry of choice, we can execute a manual <kbd>docker pull</kbd> to download the container from our image registry. By default, <kbd>docker pull</kbd> requires the user to provide the name of the container image repository, the name of the image, as well as the tagged version you would like to pull. When using Docker Hub, we will use your username as the image repository since we are using our personal Docker Hub account. For example, you can pull my NGINX web server image using the <kbd>docker pull</kbd> command:</p>
<pre class="western"><strong>ubuntu@node01:~$ docker -D pull aric49/nginx_demo-webserver:1.0
1.0: Pulling from aric49/nginx_demo-webserver
e6e5bfbc38e5: Pull complete
51c9be88e17b: Pull complete
Digest: sha256:e0d93e16fd1ec9432ab0024653e3781ded3b1ac32ed6386677447637fcd2d3ea
Status: Downloaded newer image for aric49/nginx_demo-webserver:1.0</strong></pre>
<p>Use the <kbd>-D</kbd> flag to enable debug mode. This allows you to see more details about how the Docker image is being pulled.</p>
<p>You can see from the preceding output that the image we are pulling is only two layers deep. This is due to the fact that Ansible Container commits all of the playbook runs as a single layer in the container image. This allows the developer to build a rather complex container while minimizing the size of the resulting image. Just remember to keep your playbooks small and efficient, or you will start to lose the benefits of containerized microservice architecture.</p>
<p>Now that our image has been cached locally, we can run the container manually using Docker. Of course, we could always run our project using Ansible Container directly, but the purpose of this example is to demonstrate running our container directly in Docker, which may simulate environments in which you do not, or cannot, install Ansible Container. The only caveat with this approach is that you have to specify the port-forwarding manually since that configuration is a part of our <kbd>container.yml</kbd> file and is not built intrinsically into the image itself. In this example, we are going to run the container in Docker, giving it the name <kbd>Ansible_Nginx</kbd> and specifying the container image in the following format: <kbd>username/containername:tag</kbd></p>
<pre class="western"><strong>docker run -d -p 80:8000 --name Ansible_Nginx aric49/nginx_demo-webserver:1.0</strong></pre>
<p>The <kbd>docker ps -a</kbd> output should show the container running and functional:</p>
<pre class="western"><strong>ubuntu@node01:$ sudo docker ps -a
CONTAINER ID  IMAGE  COMMAND  CREATED  STATUS  PORTS  NAMES
6061f0249930 aric49/nginx_demo-webserver:1.0 "/usr/bin/dumb-init n" 8 seconds ago Up 7 seconds 0.0.0.0:80-&gt;8000/tcp Ansible_Nginx</strong></pre>
<p>You may need to run the Ansible Container <kbd>destroy</kbd> command prior to manually running the container through Docker, as port <kbd>80</kbd> may already be used by your running project container.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, you have learned one of the core concepts at the heart of Ansible Container: building container images using roles. By leveraging Ansible roles to create container images, you can be sure the resulting container images are built with the exact configurations that are required for production-grade, reliable, container services. Furthermore, this also ensures that container images are built using close to the exact playbook roles that your infrastructure is already using, allowing container services to be built with the assurance that services currently running in production can be replicated with, generally, little rework effort. Ansible Container provides an excellent shim between bare metal or virtualized application deployments and containerized services. Leveraging Ansible Galaxy, you can even download and share custom container-enabled roles built by yourself or other members of the Ansible Container Community.</p>
<p>However, as already mentioned earlier in the chapter, existing Ansible roles cannot be ported 1:1 directly to container-enabled roles, as containers function quite differently to traditional infrastructures. In the next chapter, we will learn about how to write custom Ansible container-enabled roles, as well as some best practices for porting existing roles over to Ansible Container. Get your text editors ready, we are about to get our hands dirty writing some code!</p>
<p class="mce-root"/>


            

            
        
    </body></html>