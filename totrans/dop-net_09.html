<html><head></head><body><div class="chapter" title="Chapter&#xA0;9.&#xA0;Using Continuous Delivery Pipelines to Deploy Network Changes"><div class="titlepage"><div><div><h1 class="title"><a id="ch09"/>Chapter 9. Using Continuous Delivery Pipelines to Deploy Network Changes</h1></div></div></div><p>This chapter will focus on some of the different methods that can be used to deploy network changes using deployment pipelines.</p><p>It will first look at Continuous Delivery  and continuous deployment processes and what these methodologies entail in terms of workflow.</p><p>We will also look at the different deployment tools, artifacts repositories, and packaging methods that can be used to set up deployment pipelines and ways in which network changes can be integrated into those pipelines.</p><p>In this chapter, the following topics will be covered:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Continuous integration package management</li><li class="listitem" style="list-style-type: disc">Continuous Delivery  and deployment overview</li><li class="listitem" style="list-style-type: disc">Deployment methodologies</li><li class="listitem" style="list-style-type: disc">Packaging deployment artifacts</li><li class="listitem" style="list-style-type: disc">Deployment pipeline tooling</li><li class="listitem" style="list-style-type: disc">Deploying network changes with deployment pipelines</li></ul></div><div class="section" title="Continuous integration package management"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec45"/>Continuous integration package management</h1></div></div></div><p>In <a class="link" href="ch07.html" title="Chapter 7. Using Continuous Integration Builds for Network Configuration">Chapter 7</a>, <span class="emphasis"><em>Using Continuous Integration Builds For Network Configuration</em></span>, we looked at the process of continuous integration and in <a class="link" href="ch08.html" title="Chapter 8. Testing Network Changes">Chapter 8</a>, <span class="emphasis"><em>Testing Network Changes</em></span>, we looked at adding <a id="id757" class="indexterm"/>testing to the continuous integration process to provide increased validation and feedback loops in case of failure.</p><p>When carrying out continuous integration, using a fail fast / fix fast philosophy is desirable. This involves putting in necessary validation checks to decipher whether a build is valid and provide feedback loops to users.</p><p>This promotes the correct behavior within the teams that do frequent, small, incremental changes, which de-risks the changes. While each change is validated using the <span class="strong"><strong>Continuous Integration</strong></span> (<span class="strong"><strong>CI</strong></span>) engine <a id="id758" class="indexterm"/>with instant feedback on changes, a process of continuous improvement is adhered to as teams strive to make more robust solutions that will pass all quality checks.</p><p>As important as providing feedback loops is, producing successful builds is equally important to the process as this is how products are shipped to market. When a continuous integration build completes, it often needs to package build artifacts that are in a fit state so they can be deployed to target servers. This is often referred to as creating a shippable product or artifact.</p><p>Any continuous integration process should carry out the following steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Commit</li><li class="listitem" style="list-style-type: disc">Build (Compile/Version/Tag)</li><li class="listitem" style="list-style-type: disc">Validate</li><li class="listitem" style="list-style-type: disc">Package</li><li class="listitem" style="list-style-type: disc">Push</li></ul></div><p>Every time a new commit takes place, a new continuous integration build will be triggered. This will result in a code being pulled down from the SCM system, which will trigger a build step, which can <a id="id759" class="indexterm"/>either be a compilation process, or if the build process is not using a compiled language, then versioning or tagging of the binaries. Finally, a set of validation steps will be carried out inclusive of any required testing.</p><p>If all validations prove successful, then a set of post-continuous integration process steps need to be carried out. Post-build steps will include the package and push process, this means packaging build binaries and pushing the newly versioned package to an Artifact Repository of choice.</p><p>An example process <a id="id760" class="indexterm"/>that includes <span class="strong"><strong>Commit Change</strong></span>, Build (<span class="strong"><strong>Compile Code</strong></span>), <a id="id761" class="indexterm"/>Validate (<span class="strong"><strong>Unit Tests</strong></span>), <span class="strong"><strong>Package</strong></span> (Artifact), and <a id="id762" class="indexterm"/>Push to an <span class="strong"><strong>Artifact Repository</strong></span> is shown <a id="id763" class="indexterm"/>in the <a id="id764" class="indexterm"/>following diagram:</p><div class="mediaobject"><img src="graphics/B05559_09_01.jpg" alt="Continuous integration package management"/></div><p>An important principle to remember when setting up continuous integration builds and packaging continuous integration artifacts, is that artifacts should be packaged once only, not every single time they need to be deployed.</p><p>This is important from a repeatability perspective and also reduces the time taken to deploy as a build process can be lengthy and take many minutes. When a build has been packaged, all tests and <a id="id765" class="indexterm"/>necessary validation have been carried out on the artifact as part of the continuous integration process, so there is no need to repeat this process again if no changes have occurred.</p><p>It is imperative that we ensure the exact same artifact is deployed to test environments before being promoted onto production; this means there will be no drift between environments. The same source code being packaged on a different build server may result in the version of Java being slightly different, or even something as simple as a different environment variable could mean the build binaries are compiled differently.</p><p>Maintain consistent deployment artifacts, always swearing by the principle of package once  and deploy multiple times.</p><p>The standard of package once, deploy multiple times is illustrated following, where a single artifact is used to seed test and production environments:</p><div class="mediaobject"><img src="graphics/B05559_09_02.jpg" alt="Continuous integration package management"/></div><p>Creating different build artifacts for each environment is a non-starter; release management best practices dictate that a build package and artifacts should include tokens so different snapshots of the same package are not required.</p><p>Build package tokens can <a id="id766" class="indexterm"/>then be transformed at deployment time. All environment specific information is held in a configuration file of some sort, normally called an <span class="strong"><strong>environment</strong></span> file, <a id="id767" class="indexterm"/>which is used to populate the tokens at deployment time.</p><p>The following best <a id="id768" class="indexterm"/>practices should be adhered to when packaging continuous integration build artifacts:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Artifacts should be packaged once and distributed many times</li><li class="listitem" style="list-style-type: disc">Artifact packages should be packaged with tokenized configuration files</li><li class="listitem" style="list-style-type: disc">Artifact package configuration files should be transformed at deployment time using an environment file</li><li class="listitem" style="list-style-type: disc">Common files can be used to supplement environment files if deployment configuration is common to all environments to avoid repetition</li></ul></div><p>The following popular configuration management tools have the ability to transform tokenized templates by utilizing configuration files. Each of these configuration files take on the role of the environment file:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Puppet <a class="ulink" href="https://puppet.com/">https://puppet.com/</a></li><li class="listitem" style="list-style-type: disc">Chef <a class="ulink" href="https://www.chef.io/chef/">https://www.chef.io/chef/</a></li><li class="listitem" style="list-style-type: disc">Ansible <a class="ulink" href="https://www.ansible.com/">https://www.ansible.com/</a></li><li class="listitem" style="list-style-type: disc">Salt <a class="ulink" href="https://saltstack.com/">https://saltstack.com/</a></li></ul></div><p>Taking Ansible <a id="id769" class="indexterm"/>as an <a id="id770" class="indexterm"/>example, in <a class="link" href="ch04.html" title="Chapter 4. Configuring Network Devices Using Ansible">Chapter 4</a>, <span class="emphasis"><em>Configuring Network Devices Using Ansible</em></span>, we <a id="id771" class="indexterm"/>covered the concept of <a id="id772" class="indexterm"/>jinja2 templates. Jinja2 templates allow template files to be populated with tokens and these tokens are substituted with particular key value pairs at deployment time.</p><p>Ansible allows users to populate jinja2 templates to be populated with variables (tokens). Each <code class="literal">var</code> file can be <a id="id773" class="indexterm"/>configured so that it is unique to each environment. Environment files can be imported into playbooks and roles by inputting it as a command line argument. This will in turn transform the jinja2 templates at deployment time with the environment-specific information.</p><p>In the following example, we see an Ansible playbook <code class="literal">configure_env.yml</code> being executed, and a unique environment variable called environment needing to be set:</p><div class="mediaobject"><img src="graphics/B05559_09_03.jpg" alt="Continuous integration package management"/></div><p>This will be imported into the playbook <code class="literal">configure_env.yml</code> so that a unique set of environment information is loaded for each environment.</p><p>Therefore, taking the component, integration, system test, and production environments as an example the following files would be loaded:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">../roles/networking/vars/comp.yml</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">../roles/networking/vars/int.yml</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">../roles/networking/vars/sys.yml</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">../roles/networking/vars/prod.yml</code></li></ul></div><p>For each unique environment, the deployment command differs only in the environment file that is loaded which will make the deployment environment specific:</p><div class="mediaobject"><img src="graphics/B05559_09_04.jpg" alt="Continuous integration package management"/></div></div></div>
<div class="section" title="Continuous Delivery and deployment overview"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec46"/>Continuous Delivery and deployment overview</h1></div></div></div><p>Continuous Delivery  <a id="id774" class="indexterm"/>and deployment are a natural extension of the <a id="id775" class="indexterm"/>continuous integration process. Continuous Delivery and deployment create a consistent mechanism to deploy changes to production and create a conveyer belt delivering new features to customers or end users. So conceptually a conveyer belt is what continuous Delivery  is all about, but in terms of actual process how is this achieved?</p><p>A continuous integration process will carry out the following high level steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Commit</li><li class="listitem" style="list-style-type: disc">Build (Compile/Version/Tag)</li><li class="listitem" style="list-style-type: disc">Validate</li><li class="listitem" style="list-style-type: disc">Package</li><li class="listitem" style="list-style-type: disc">Push</li></ul></div><p>Continuous Delivery and deployment take over once the artifact has been pushed to the artifact repository. Each and every build artifact created by a continuous integration process should be considered a release candidate, meaning that it can potentially be deployed to production if it passes all validations in the Continuous Delivery pipeline.</p><p>Like continuous integration, Continuous Delivery and deployment create a series of feedback loops to indicate if validation tests have failed on an environment.</p><p>A Continuous Delivery pipeline process will encapsulate the following high level steps at each stage of a deployment pipeline:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Deploy (pull/tokenize/setup)</li><li class="listitem" style="list-style-type: disc">Validate (test)</li><li class="listitem" style="list-style-type: disc">Promote</li></ul></div><p>A stage in a deployment pipeline will contain a series of tests which will be used to help validate whether the <a id="id776" class="indexterm"/>application is functioning as required prior to it being released to production.</p><p>Each stage in the <a id="id777" class="indexterm"/>deployment pipeline will have a deployment step which will pull down the artifact from the <span class="strong"><strong>Artifact Repository</strong></span> to <a id="id778" class="indexterm"/>the target server and execute the deployment steps. The deployment process will normally involve installing software or configuring a change to the state of the server. Configuration changes are typically governed by a configuration management tool such as Puppet, Chef, Ansible, or Salt.</p><p>Once deployment is completed, a series of tests will be carried out in the environment to validate the deployment and also test the functionality of the application or change.</p><p>Continuous Delivery  means that if validation tests pass on a test environment then the build artifact is automatically promoted to the next environment. The deployment, validation, and promotion steps are carried out again on the next environment in the same way as the previous environment. In the event of a failure, the release candidate will break and it will not be promoted to the next stage of the process.</p><p>When using Continuous Delivery this automatic promotion happens all the way to the environment prior to production as shown in the following diagram:</p><div class="mediaobject"><img src="graphics/B05559_09_05.jpg" alt="Continuous Delivery and deployment overview"/></div><p>Continuous deployment on the <a id="id779" class="indexterm"/>other hand has no paused state before production <a id="id780" class="indexterm"/>and differs from Continuous Delivery in that it will automatically deploy to production:</p><div class="mediaobject"><img src="graphics/B05559_09_06.jpg" alt="Continuous Delivery and deployment overview"/></div><p>So the only difference between Continuous Delivery and continuous deployment is the manual pause from promoting the build artifact to production.</p><p>The reason for implementing Continuous Delivery over continuous deployment is normally down to either governance or the maturity of testing.</p><p>When starting out, <a id="id781" class="indexterm"/>continuously deploying to production throughout the day can seem very daunting as it mandates that the deployment process is completely <a id="id782" class="indexterm"/>automated and that the validation and testing on each environment is mature enough to catch all known errors.</p><p>With continuous deployment, the trigger of a production deployment is a SCM commit, so it puts a lot of trust in the deployment system. This means it is desirable that the branching strategy is set up to <a id="id783" class="indexterm"/>pull all changes from the <span class="strong"><strong>trunk/mainline/master</strong></span> branch and trigger the deployment pipeline. Having multiple different branches will complicate the deployment process so it is important to implement a branching strategy that minimizes repetition, and an explosion of the number of deployment pipelines that are required.</p><p>If implemented badly, continuous deployment can result in continuous downtime, so normally after setting up continuous integration businesses, teams should start with Continuous Delivery  and aim to eventually move to a continuous deployment once processes have matured sufficiently.</p><p>As covered in <a class="link" href="ch03.html" title="Chapter 3. Bringing DevOps to Network Operations">Chapter 3</a>, <span class="emphasis"><em>Bringing DevOps to Network Operations</em></span>, cultural change is needed within the business to implement a Continuous Delivery  model and it really is an all or nothing approach for it to work successfully.</p><p>As stated in <a class="link" href="ch08.html" title="Chapter 8. Testing Network Changes">Chapter 8</a>, <span class="emphasis"><em>Testing Network Changes</em></span>, manually updating environments can compromise the validity of tests so they should be avoided at all costs, every change should flow through SCM to downstream environments.</p><p>Continuous Delivery promotes automation and creation of test packs at every stage in the deployment pipeline, but it also allows a business to cherry-pick the release candidate that is finally deployed to production.</p><p>This means additional validation could be carried out manually during the imposed stop before production, in the absence of the desired level or test coverage for a build artifact. It also plays well with companies that are subject to regulatory requirements that may mean they only have a specified deployment window and they cannot deploy to production continuously.</p><p>Continuous Delivery means that regulated companies can still benefit from automated environments and tests, but the production deployment is just a button click to select the artifact, which has passed all aforementioned promotions and is deployed to production.</p></div>
<div class="section" title="Deployment methodologies"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec47"/>Deployment methodologies</h1></div></div></div><p>When carrying out Continuous Delivery  and deployment, there is no one size fits all deployment strategy. Configuration management tools such as Puppet, Chef, Ansible, and Salt have different approaches to deployment and use different approaches when keeping servers up to date.</p><p>The tool that is selected is not important, only the ideal workflow and processes to support delivering changes that are consistent, quick, and accurate.</p><div class="section" title="Pull model"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec109"/>Pull model</h2></div></div></div><p>Tools such as Puppet and <a id="id784" class="indexterm"/>Chef adopt a centralized approach to <a id="id785" class="indexterm"/>configuration management, where they have a centralized server that acts as the brain for the deployment process.</p><p>In Puppet's case the centralized server are the Puppet Master and in Chef's case the centralized server is the Chef Server. This centralized server is a set of infrastructure provisioned to store server configuration according to the configuration management tool's reference architecture.</p><p>All updates to server configuration is pushed to the centralized server first and then subsequently pushed out to the corresponding servers using agents. These agents can either poll the centralized server for updates and apply them straight away or alternately wait for the Puppet Agent, or in Chef's case, the Chef Client to be invoked to start the convergence of configuration from the centralized server to the server containing the agent.</p><p>The overriding principle in a pull model is that the centralized server governs the state of the system and every change goes via the Puppet Master or Chef Server.</p><p>If any user logs onto a server and changes the state, then the next time that the state converges from the centralized server it could overwrite those manual changes when the agent runs (Puppet Agent or Chef Client) if that particular configuration is managed by the centralized server.</p><p>In this model, the centralized server will control all application versioning information and environment configuration.</p><p>An example of a pull <a id="id786" class="indexterm"/>model is shown in the following diagram. This shows Chef being used in a Continuous Delivery  process:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The continuous integration process creates a new build artifact which is pushed <a id="id787" class="indexterm"/>to the <span class="strong"><strong>Artifact Repository</strong></span></li><li class="listitem" style="list-style-type: disc">Chef's command line client <span class="strong"><strong>knife</strong></span> is invoked as a post-build action which updates the <span class="strong"><strong>Chef Server</strong></span> with the <a id="id788" class="indexterm"/>new version of the application which is being deployed</li><li class="listitem" style="list-style-type: disc">The deployment process <a id="id789" class="indexterm"/>is then triggered on <span class="strong"><strong>Component Test Environment</strong></span> by running <span class="strong"><strong>Chef Client</strong></span> which will <a id="id790" class="indexterm"/>trigger the <span class="strong"><strong>Chef Client</strong></span> to check the state against the <span class="strong"><strong>Chef Server</strong></span></li><li class="listitem" style="list-style-type: disc">The <span class="strong"><strong>Chef Client</strong></span> in this <a id="id791" class="indexterm"/>case, sees a new application <a id="id792" class="indexterm"/>version is available based on the last <span class="strong"><strong>knife</strong></span> update <a id="id793" class="indexterm"/>and as a result updates the environment to the new version of the application</li><li class="listitem" style="list-style-type: disc">Finally, all validation and test steps are run prior to promoting it to the next stage of the deployment pipeline</li><li class="listitem" style="list-style-type: disc">Convergence <a id="id794" class="indexterm"/>on the subsequent <span class="strong"><strong>Integration Test Environment</strong></span> is only triggered if the <span class="strong"><strong>Component Test Environment</strong></span> promotion is successful<div class="mediaobject"><img src="graphics/B05559_09_07.jpg" alt="Pull model"/></div></li></ul></div></div><div class="section" title="Push model"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec110"/>Push model</h2></div></div></div><p>Tools such as Ansible <a id="id795" class="indexterm"/>and Salt adopt a push model to configuration <a id="id796" class="indexterm"/>management, where they have a control host that is used to connect to servers using SSH and configure them.</p><p>Instead of using a centralized server, Ansible and Salt use a control host, which has a command-line client installed on the server. The control host is then used to push changes to servers via logging on to them using SSH either via password or alternatively, SSH keys.</p><p>As Ansible and Salt are Python-based, they are agentless and can run on any Linux distribution, as Python is a <a id="id797" class="indexterm"/>pre-requisite for these servers. Windows machines are <a id="id798" class="indexterm"/>connected to and configured using WinRM.</p><p>All configuration management information is stored in SCM systems and pulled down to the control host, this configuration is then used to push updates out to servers.</p><p>The overriding principle in a push model is that changes are committed into SCM. The SCM server, rather than a centralized server, is the source of truth for state, configuration, and versioning.</p><p>An example of a <a id="id799" class="indexterm"/>push model follows. This shows Ansible being used in a Continuous Delivery  process:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The continuous <a id="id800" class="indexterm"/>integration process creates a new build artifact which is pushed to the <span class="strong"><strong>Artifact Repository</strong></span></li><li class="listitem" style="list-style-type: disc">A new artifact being present in the <span class="strong"><strong>Artifact Repository</strong></span> triggers the deployment <a id="id801" class="indexterm"/>process and the Ansible playbook/role is <a id="id802" class="indexterm"/>downloaded from the <span class="strong"><strong>SCM System</strong></span> to the <span class="strong"><strong>Ansible Control Host</strong></span></li><li class="listitem" style="list-style-type: disc">The deployment process is <a id="id803" class="indexterm"/>then triggered on <span class="strong"><strong>Component Test Environment</strong></span> and Ansible is executed against all servers that are present in the targeted inventory</li><li class="listitem" style="list-style-type: disc">Finally, all validation and test steps are run prior to promoting it to the next stage of the deployment pipeline</li><li class="listitem" style="list-style-type: disc">Ansible is only executed on the subsequent Integration Test Environment if the Component Test Environment promotion is successful<div class="mediaobject"><img src="graphics/B05559_09_08.jpg" alt="Push model"/></div></li></ul></div></div><div class="section" title="When to choose pull or push"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec111"/>When to choose pull or push</h2></div></div></div><p>When selecting a pull or push method of configuration management, it is down to preference and <a id="id804" class="indexterm"/>should be selected based on the approach to <a id="id805" class="indexterm"/>infrastructure.</p><p>Pull models are popular when dealing with server estates that have long-lived infrastructure. It lends itself well to patching a whole estate of servers to keep on top of compliance. Pull models, as they have a centralized server with the current state, means that if configuration is removed from a server, then the centralized server will register that a delete is required. Push models only understand the new desired state and don't take into account the previous state due to the lack of convergence. So if some configuration is removed from a playbook for example, it won't be automatically cleaned up when the next deployment occurs.</p><p>The drawbacks of a pull approach are the requirement to maintain the infrastructure for the centralized server which can be somewhat large, and as it is agent-based, agent versions also need to be maintained.</p><p>Push models align themselves well to orchestration and updating large amounts of servers. They are popular when using immutable infrastructure as the old state of the server is not important. This means that only the current desired state is relevant, so it is not necessary to clean-up deleted configuration as servers will be deployed at every deployment.</p><p>A pull model with <a id="id806" class="indexterm"/>immutable <a id="id807" class="indexterm"/>infrastructure wouldn't really make sense as the boxes would only converge once and then be destroyed, so the overhead of running large centralized servers to take care of convergence is wasteful.</p></div></div>
<div class="section" title="Packaging deployment artifacts"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec48"/>Packaging deployment artifacts</h1></div></div></div><p>Using configuration management tooling just to deploy applications is not enough; Continuous Delivery <a id="id808" class="indexterm"/>and deployment are only as quick as its slowest component. So having to wait for manual network or infrastructure changes is not an option; all components need to be built, versioned, and have their deployment automated.</p><p>When looking at building new environments from scratch, multiple deployment artifacts need to be used to build an environment; application code is just one piece of the jigsaw.</p><p>The following dependencies are required to build a redundant environment:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Application</li><li class="listitem" style="list-style-type: disc">Infrastructure (base operating systems and virtual or physical servers)</li><li class="listitem" style="list-style-type: disc">Networking</li><li class="listitem" style="list-style-type: disc">Load balancing</li><li class="listitem" style="list-style-type: disc">Deployment scripts (configuration management)</li></ul></div><p>Not versioning all these components together means that true rollback is not available as components may break if an application is rolled back and the network has moved forward in terms of state.</p><p>Ideally application code, infrastructure, networking, load balancing, and deployment scripts should all be versioned and tested together as one entity. So if rollback is required then operators can simply roll-back to the last known package which has tried and tested versions of the application code, infrastructure, networking, load balancing, and deployment scripts that were known to work together.</p><p>One option is to have a single repository that versions all dependencies in that one repository. This can be inflexible when dealing with large numbers of applications and can result in repetition of configuration.</p><p>Another way to version all components is via continuous integration builds, each of the components can have their own continuous integration build to version the individual components and a unique repository.</p><p>Applications will be a packaged entity which may be an RPM file on Red Hat Linux, APT file on Ubuntu, or a NuGet package on Windows.</p><p>Infrastructure will be provisioned using cloud provider APIs such as OpenStack, Microsoft Azure, Google Cloud, or AWS, so the desired number of servers will need to be specified using a version controlled inventory file.</p><p>The base operating system <a id="id809" class="indexterm"/>images can be created using tooling such as Packer or OpenStack Disk Image Builder and uploaded to a cloud provider's image registry.</p><p>As covered in <a class="link" href="ch04.html" title="Chapter 4. Configuring Network Devices Using Ansible">Chapter 4</a>, <span class="emphasis"><em>Configuring Network Devices Using Ansible</em></span>, <a class="link" href="ch05.html" title="Chapter 5. Orchestrating Load Balancers Using Ansible">Chapter 5</a>, <span class="emphasis"><em>Configuring Load Balancers Using Ansible</em></span>, and <a class="link" href="ch06.html" title="Chapter 6. Orchestrating SDN Controllers Using Ansible">Chapter 6</a>, <span class="emphasis"><em>Configuring SDN Controllers Using Ansible</em></span>, network configuration, when utilizing Ansible, normally takes the form of <code class="literal">var</code> files which describe the desired state of the system.</p><p>When using an SDN controller, the subnet ranges and ACL firewall rules can be described in these <code class="literal">var</code> files and utilize modules scheduled in specific orders to apply them at deployment time. In a similar vein, the load balancing configuration object model can be stored in Ansible <code class="literal">var</code> files to set up load balancing.</p><p>Each of these repositories should be tagged as part of the continuous integration build and a supplementary package build can then be created for each application. This package build is used to roll-up all the dependencies and version them together using a manifest file.</p><p>The continuous integration builds that contribute to the manifest file are shown in the following diagram:</p><div class="mediaobject"><img src="graphics/B05559_09_09.jpg" alt="Packaging deployment artifacts"/></div><p>A manifest file can take the form of a simple key value pair file or a JSON file. The format of the file is not important, recording the latest tagged version of each continuous integration build is integral to the process.</p><p>At deployment time, a <a id="id810" class="indexterm"/>new packaged manifest should be used as the trigger for the deployment pipeline. The first step of the deployment pipeline will pull down the manifest file from the artifact repository and it can then be read for version information.</p><p>All versions of the repositories present in the manifest file can then be pulled down to the Ansible control server and used to deploy the desired application version along with the desired state to the infrastructure, network, and load balancer required for each environment.</p><p>Roll-back would involve passing the previous version of the manifest file to the deployment process which would then revert to the last tried and tested versions of the application code, infrastructure, networking, load balancing, and deployment scripts that were known to work together.</p></div>
<div class="section" title="Deployment pipeline tooling"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec49"/>Deployment pipeline tooling</h1></div></div></div><p>Deployment pipelines involve <a id="id811" class="indexterm"/>chaining different tools together to create Continuous Delivery processes.</p><p>Being able to track the process flow through the Continuous Delivery tooling is integral, as it is important to be able to visualize the pipeline process, so it is easy for operators to follow.</p><p>Having visibility of a process makes debugging the process easy if errors occur, which may happen as errors will occur in any process and are inevitable. The whole point of the Continuous Delivery pipeline, aside from automating delivery of changes to environments, is to provide feedback loops. So if a pipeline is not easy to follow and debug, it has failed one of its main objectives.</p><p>Building automatic clean-up into pipelines should be implemented if possible, so if a failure occurs mid-deployment then changes can be reverted back to the last known good state without the need for manual intervention.</p><p>At a high level, the <a id="id812" class="indexterm"/>following <a id="id813" class="indexterm"/>tooling is <a id="id814" class="indexterm"/>required <a id="id815" class="indexterm"/>when creating a deployment pipeline for Continuous Delivery which includes a <span class="strong"><strong>SCM System</strong></span>, <span class="strong"><strong>CI Build Server</strong></span>, <span class="strong"><strong>Artifact Repository</strong></span>, and <span class="strong"><strong>CD Pipeline Scheduler</strong></span>:</p><div class="mediaobject"><img src="graphics/B05559_09_10.jpg" alt="Deployment pipeline tooling"/></div><p>In <a class="link" href="ch07.html" title="Chapter 7. Using Continuous Integration Builds for Network Configuration">Chapter 7</a>, <span class="emphasis"><em>Using Continuous Integration Builds for Network Configuration</em></span>, and <a class="link" href="ch08.html" title="Chapter 8. Testing Network Changes">Chapter 8</a>, <span class="emphasis"><em>Unit Testing Network Changes</em></span>, we covered the importance of the SCM System and CI Build Server in <a id="id816" class="indexterm"/>continuous integration and testing. In this chapter we will focus on the tooling required for the deployment process which includes the Artifact Repository and CD Pipeline Scheduler that is used to schedule configuration management tooling.</p><div class="section" title="Artifact repositories"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec112"/>Artifact repositories</h2></div></div></div><p>Artifact repositories are a <a id="id817" class="indexterm"/>key component in any deployment pipeline; they <a id="id818" class="indexterm"/>can be used to host a multitude of different repositories or even just hold generic artifacts.</p><p>Platform golden images in ISO, AMI, VMDK, and QCOW format can be stored and versioned in artifact repositories and used as the source for image registries for cloud providers such as AWS, Google Cloud, Microsoft Azure, and OpenStack.</p><p>Manifest files can also be held in a release repository to govern the roll-forward and roll-back of application, infrastructure, networking, and load balancing requirements.</p><div class="section" title="Artifactory"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec14"/>Artifactory</h3></div></div></div><p>Artifactory from JFrog is one of the most popular artifact repositories on the market today and provides access <a id="id819" class="indexterm"/>to repositories via an NFS-based shared storage solution. Artifactory is bundled with the Apache Tomcat web server as part of the installer bundle and can be hosted on Linux or Windows.</p><p>In terms of load balancing, Artifactory can be set up in a highly available, three tier cluster for redundancy. Artifactory can use a wide variety of load balancers such as Nginx or HAProxy as well as proprietary load balancers such as Citrix NetScaler, F5 Big-IP, or Avi Networks.</p><p>Artifactory is backed by a MySQL or Postgres database and requires an NFS file-system or Amazon S3 storage to store artifacts that are made available to each of Artifactories three HA nodes.</p><p>The architectural <a id="id820" class="indexterm"/>overview of <span class="strong"><strong>Artifactory</strong></span> is shown in the following diagram:</p><div class="mediaobject"><img src="graphics/B05559_09_11.jpg" alt="Artifactory"/></div><p>Artifactory <a id="id821" class="indexterm"/>supports <a id="id822" class="indexterm"/>numerous different repository <a id="id823" class="indexterm"/>types, <a id="id824" class="indexterm"/>some of <a id="id825" class="indexterm"/>which are <a id="id826" class="indexterm"/>shown here, so it can host multiple different repositories for delivery teams depending on the <a id="id827" class="indexterm"/>applications that they are developing:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Maven <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/Maven+Repository">https://www.jfrog.com/confluence/display/RTF/Maven+Repository</a></li><li class="listitem" style="list-style-type: disc">Ivy <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/Working+with+Ivy">https://www.jfrog.com/confluence/display/RTF/Working+with+Ivy</a></li><li class="listitem" style="list-style-type: disc">Gradle <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/Gradle+Artifactory+Plugin">https://www.jfrog.com/confluence/display/RTF/Gradle+Artifactory+Plugin</a></li><li class="listitem" style="list-style-type: disc">Git LFS <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/Git+LFS+Repositories">https://www.jfrog.com/confluence/display/RTF/Git+LFS+Repositories</a></li><li class="listitem" style="list-style-type: disc">NPM <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/Npm+Registry">https://www.jfrog.com/confluence/display/RTF/Npm+Registry</a></li><li class="listitem" style="list-style-type: disc">NuGet <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/NuGet+Repositories">https://www.jfrog.com/confluence/display/RTF/NuGet+Repositories</a></li><li class="listitem" style="list-style-type: disc">PyPi <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/PyPI+Repositories">https://www.jfrog.com/confluence/display/RTF/PyPI+Repositories</a></li><li class="listitem" style="list-style-type: disc">Bower <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/Bower+Repositories">https://www.jfrog.com/confluence/display/RTF/Bower+Repositories</a></li><li class="listitem" style="list-style-type: disc">YUM <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/YUM+Repositories">https://www.jfrog.com/confluence/display/RTF/YUM+Repositories</a></li><li class="listitem" style="list-style-type: disc">Vagrant <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/Vagrant+Repositories">https://www.jfrog.com/confluence/display/RTF/Vagrant+Repositories</a></li><li class="listitem" style="list-style-type: disc">Docker <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/Docker+Registry">https://www.jfrog.com/confluence/display/RTF/Docker+Registry</a></li><li class="listitem" style="list-style-type: disc">Debian <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/Debian+Repositories">https://www.jfrog.com/confluence/display/RTF/Debian+Repositories</a></li><li class="listitem" style="list-style-type: disc">SBT <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/SBT+Repositories">https://www.jfrog.com/confluence/display/RTF/SBT+Repositories</a></li><li class="listitem" style="list-style-type: disc">Generic <a class="ulink" href="https://www.jfrog.com/confluence/display/RTF/Configuring+Repositories">https://www.jfrog.com/confluence/display/RTF/Configuring+Repositories</a></li></ul></div><p>This <a id="id828" class="indexterm"/>means Artifactory <a id="id829" class="indexterm"/>can be <a id="id830" class="indexterm"/>used <a id="id831" class="indexterm"/>as the single <a id="id832" class="indexterm"/>repository end-point <a id="id833" class="indexterm"/>for Continuous Delivery pipelines. Artifactory has <a id="id834" class="indexterm"/>recently introduced support for Vagrant boxes and Docker registry so it <a id="id835" class="indexterm"/>can be used to store Vagrant test environments, which could be used to store network operating systems or containers. This illustrates some of the features available from market-leading artifact repositories.</p></div></div><div class="section" title="CD pipeline scheduler"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec113"/>CD pipeline scheduler</h2></div></div></div><p>While the job of the <a id="id836" class="indexterm"/>artifact repository is <a id="id837" class="indexterm"/>relatively straightforward, but no less important, choosing the correct Continuous Delivery pipeline tool is much more difficult.</p><p>There is a wide array of options available such as:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">IBM <a id="id838" class="indexterm"/>Urban Code Deploy <a class="ulink" href="https://developer.ibm.com/urbancode/products/urbancode-deploy/">https://developer.ibm.com/urbancode/products/urbancode-deploy/</a></li><li class="listitem" style="list-style-type: disc">Electric <a id="id839" class="indexterm"/>Flow Deploy <a class="ulink" href="http://electric-cloud.com/products/electricflow/deploy-automation/">http://electric-cloud.com/products/electricflow/deploy-automation/</a></li><li class="listitem" style="list-style-type: disc">Jenkins <a class="ulink" href="https://jenkins.io/">https://jenkins.io/</a></li><li class="listitem" style="list-style-type: disc">Thoughtworks Go <a class="ulink" href="https://www.go.cd/">https://www.go.cd/</a></li><li class="listitem" style="list-style-type: disc">XL<a id="id840" class="indexterm"/> Deploy <a class="ulink" href="https://xebialabs.com/products/xl-deploy">https://xebialabs.com/products/xl-deploy</a></li></ul></div><p>But before picking <a id="id841" class="indexterm"/>a tool, the process being implemented needs to be considered. So what are the main aims <a id="id842" class="indexterm"/>of a Continuous Delivery pipeline?</p><p>A good Continuous Delivery pipeline should meet the following goals:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Trigger deployments based on new artifacts being available in artifact repository</li><li class="listitem" style="list-style-type: disc">Schedule command lines</li><li class="listitem" style="list-style-type: disc">Render a pipeline view</li><li class="listitem" style="list-style-type: disc">Break tasks into stages</li><li class="listitem" style="list-style-type: disc">Provide good log output</li><li class="listitem" style="list-style-type: disc">Feedback pass or failures</li><li class="listitem" style="list-style-type: disc">Integration with testing</li></ul></div><p>All of these points need to be considered when selecting tooling so we will cherry-pick one of the most popular Continuous Delivery pipeline scheduling tools Jenkins, and look at ways in which it schedules pipelines.</p><div class="section" title="Jenkins"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec15"/>Jenkins</h3></div></div></div><p>Jenkins was <a id="id843" class="indexterm"/>primarily a continuous integration build server when it was conceived. Jenkins has a pluggable framework that means that it is often customized to carry out deployments, with plugins <a id="id844" class="indexterm"/>such as the multi-job plugin built to allow it to schedule pipelines.</p><p>However, as of the Jenkins 2.x release, Jenkins now makes pipelines a core feature component of its distribution rather than depending on plugins to cater for its deployment capabilities.</p><p>In the following example, the Jenkins Pipeline job type can be seen:</p><div class="mediaobject"><img src="graphics/B05559_09_12.jpg" alt="Jenkins"/></div><p>Using the Jenkins Pipeline job type, users can specify pipelines using a <code class="literal">Pipeline Script</code>, declaring each stage <a id="id845" class="indexterm"/>of the pipeline. In this instance, the echo command has been used to spoof each pipeline stage to show how a <code class="literal">Pipeline script</code> may look:</p><div class="mediaobject"><img src="graphics/B05559_09_13.jpg" alt="Jenkins"/></div><p>The visual display of the pipeline from the pipeline script is shown in the <span class="strong"><strong>Stage View</strong></span>. The <span class="strong"><strong>Stage View</strong></span> shows the eight stages the pipeline went through in order to deploy the networking, virtual machines, application, and load balancer configuration:</p><div class="mediaobject"><img src="graphics/B05559_09_14.jpg" alt="Jenkins"/></div><p>Logging for each stage is shown clearly in the Jenkins console logs which allow users of the tool to see feedback on <a id="id846" class="indexterm"/>successful and unsuccessful console logs:</p><div class="mediaobject"><img src="graphics/B05559_09_15.jpg" alt="Jenkins"/></div><p>When putting valid commands into <code class="literal">Pipeline script</code>, as opposed to simulating echoes as we have in the above example, Jenkins allows users to use a groovy snippet generator to translate any steps to <a id="id847" class="indexterm"/>Pipeline Script format.</p><p>In this instance, a shell command is required to execute the Ansible playbook to <code class="literal">create_vip.yml</code> on the component test environment, so the snipped generator is used to create it:</p><div class="mediaobject"><img src="graphics/B05559_09_16.jpg" alt="Jenkins"/></div><p>This snippet command can then be pasted into the <code class="literal">create_vip.yml</code> stage that was created on the Pipeline script:</p><div class="mediaobject"><img src="graphics/B05559_09_17.jpg" alt="Jenkins"/></div><p>The output of the job <a id="id848" class="indexterm"/>configuration is a Jenkins file that can be stored in SCM to version control the deployment pipeline changes.</p></div></div></div>
<div class="section" title="Deploying network changes with deployment pipelines"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec50"/>Deploying network changes with deployment pipelines</h1></div></div></div><p>When carrying out <a id="id849" class="indexterm"/>Continuous Delivery <a id="id850" class="indexterm"/>or deployment, it is essential to incorporate network changes. Network teams need to contribute major pieces of the deployment pipeline.</p><p>As the CD Pipeline scheduler allows different stages to be specified in the deployment pipeline, it gives great flexibility and allows all teams to contribute pieces, forming a true collaborative DevOps model.</p><p>Sometimes a concern from network teams is that developers should not have the necessary access to all network devices as they are not experts. Truth be told, developers don't want access to network devices, they instead want a quick way of pushing out their changes where they are not impeded by having to wait on network changes being applied.</p><div class="section" title="Network self-service"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec114"/>Network self-service</h2></div></div></div><p>Allowing developers <a id="id851" class="indexterm"/>the ability to self-service their own network changes is very important, otherwise the network team becomes the bottleneck for the Continuous Delivery process.</p><p>So providing development teams with, say, a hardened Ansible playbook to create everyday network functions will undoubtedly help alleviate developer pain and make deployment of new network changes a self-service function.</p><p>Developers can use a playbook that incorporates all the best practices of the network team to apply any network changes. This is following the model where developers can utilize a playbook provided by the infrastructure team to spin up new virtual machines and register their DNS entries with the IPAM solution.</p></div><div class="section" title="Steps in a deployment pipeline"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec115"/>Steps in a deployment pipeline</h2></div></div></div><p>When creating deployment pipelines, it is important to break up each function into a granular set of steps. This <a id="id852" class="indexterm"/>means if any step fails it can be easily rolled back. Understanding the deployment pipeline visually is also important as breaking down complex operations into small steps makes debugging failures less daunting too.</p><p>A modern application deployment pipeline will provision new environments by carrying out the following <a id="id853" class="indexterm"/>high level steps every single deployment:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Download manifest</li><li class="listitem">Create network</li><li class="listitem">Create VMs in network</li><li class="listitem">Install application</li><li class="listitem">Create VIP</li><li class="listitem">Rolling update</li><li class="listitem">Run test pack</li><li class="listitem">Promote to next phase</li></ol></div><p>The first stage of the pipeline is the trigger for a new deployment to the first test environment. In this case, the detection of a new manifest file artifact.</p><p>The manifest artifact will be downloaded to the CD Pipeline scheduler and parsed. The Ansible <code class="literal">var</code> file structure will be assembled from SCM using the manifest versions.</p><p>Once assembled, the network needs to be provisioned. An A or B network will be created depending on the release and the necessary Ingress and Egress ACL rules will be applied to the network.</p><p>Virtual machines will then be booted into the newly-provisioned network and tagged with their metadata profile stating the software that needs to be installed on them.</p><p>Ansible dynamic inventory is run to pull back the new virtual machines that were just created, Ansible reads the profile metadata from the virtual machines. metadata tags and Ansible installs the required role on the new cluster of virtual machines depending on what profile is specified.</p><p>A VIP is created on the load balancer if it doesn't already exist and its load balancing policies are applied. Boxes are then rolled into service on the new VIP and old boxes are rolled out of service. The new boxes are smoke tested to make sure they are operating as expected before the previous release is destroyed.</p><p>A full quality assurance test pack is then executed and the manifest artifact is then promoted to the next stage if successful.</p><p>Each of these steps will be repeated all the way up to production. In a Continuous Delivery model, the production deployment will be a manual button press to trigger the pipeline, where in Continuous Delivery pipeline will automatically trigger if all quality gates pass.</p></div><div class="section" title="Incorporating configuration management tooling"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec116"/>Incorporating configuration management tooling</h2></div></div></div><p>When utilizing a CD <a id="id854" class="indexterm"/>scheduler such as Jenkins, its agents, known as slaves, can be used to install Ansible on them and they become the Ansible Control Host for the deployment.</p><p>Each stage in the deployment pipeline can be a small modular Ansible playbook that allows developers to self-serve their network needs. These playbooks can be created by the network team and continuously improved over time.</p><p>So the Jenkins <code class="literal">Pipeline script</code> would resemble the following, with a unique playbook for each stage:</p><div class="mediaobject"><img src="graphics/B05559_09_18.jpg" alt="Incorporating configuration management tooling"/></div><p>The steps applied on each test environment should be consistent with production and all steps should be carried out by a service account for the pipeline.</p><p>Each and every environment should be built from source control by implementing immutable infrastructure and networking. This is so that the desired state is always what is specified in the manifest file's associated repositories.</p><p>The Ansible <code class="literal">var</code> files that feed each playbook can be filled in by the development teams in order to set firewall policies or load balancing policies.</p><p>These <code class="literal">var</code> files are versioned by the associated continuous integration builds for the SDN or load balancing configuration. Each network-related CI build then rolls up into a new manifest file when an application continuous integration build is triggered. The generation of a new manifest file triggers the first step in the deployment pipeline.</p></div><div class="section" title="Network teams' role in Continuous Delivery pipelines"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec117"/>Network teams' role in Continuous Delivery pipelines</h2></div></div></div><p>When analyzing the steps <a id="id855" class="indexterm"/>that are executed by a deployment pipeline, if we look at which teams would have the necessary permissions to carry out each pipeline stage manually, it becomes very apparent the importance of integrating networking into the Continuous Delivery  processes.</p><p>Out of the eight high level stages to deploy an application, three of them are integrating with the network when executing <span class="strong"><strong>create network</strong></span>, <span class="strong"><strong>create vip</strong></span>, and <span class="strong"><strong>rolling update</strong></span> as shown here:</p><div class="mediaobject"><img src="graphics/B05559_09_19.jpg" alt="Network teams' role in Continuous Delivery pipelines"/></div><p>This shows that if network operations were not part of the deployment pipeline then true Continuous Delivery would not be achievable.</p></div><div class="section" title="Failing fast and feedback loops"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec118"/>Failing fast and feedback loops</h2></div></div></div><p>One of the key objectives of creating Continuous Delivery pipelines is creating feedback loops which <a id="id856" class="indexterm"/>fail fast and create a radiator view for developers. However, with <a id="id857" class="indexterm"/>Continuous Delivery moving into continuous operations space, as it now incorporates infrastructure, networking, and quality assurance, all teams need to be mindful of failures and react accordingly.</p><p>When pipeline stages fail, it is important to incorporate automated clean-up every time there is a failure, this leaves the pipeline in a good state so the next pipeline is not impeded. Any break in the process means that changes cannot reach production.</p><p>So although it may be a test environment that is breaking, it is now blocking potential fixes being deployed to production. If a failure occurs, the pipeline should also halt the whole process and not proceed to the next stage as shown below:</p><div class="mediaobject"><img src="graphics/B05559_09_20.jpg" alt="Failing fast and feedback loops"/></div><p>Ansible block rescue functionality is very useful when dealing with failed pipeline stages and clean-up, providing a try and catch-like feature for playbooks and roles.</p><p>Testing should also be <a id="id858" class="indexterm"/>incorporated into the deployment pipeline so if the run <a id="id859" class="indexterm"/>test stage of the pipeline fails, then there is a history of why the tests failed that can be audited. Pipelines also help provide a full history of changes that have been applied to the environment. Although triggered by a service account, the user that committed the change in source control should take ownership for each change.</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec51"/>Summary</h1></div></div></div><p>In this chapter, we looked at integrating network changes into deployment pipelines so that network teams can contribute to the Continuous Delivery process. We then discussed the difference between Continuous Delivery and deployment.</p><p>We then looked at how package management is crucial for wrapping development, infrastructure, quality assurance, and network changes together as part of deployment pipelines. We also illustrated some of the market-leading artifact repositories and CD pipeline schedulers using Artifactory and Jenkins as examples.</p><p>Finally, we looked at best practices that should be adopted when setting up deployment pipelines within the remits of Continuous Delivery and deployment. We then focused on ways network teams could contribute to deployment pipelines by providing self-service deployment scripts to developers, so they keep the overall process quick, lean, and automated.</p><p>After reading this chapter, you should now understand why that applications should be compiled only once and stored in an artifact repository, and the same binaries should be deployed to multiple environments so the deployment process is consistent.</p><p>The chapter also focused on the differences between pull-based tools, such as Chef and Puppet, and tools such as Ansible and Salt that utilize a push model for configuration management.</p><p>Key takeaways should also include how to utilize Artifactory as an artifact repository to store numerous types of build artifacts, and ways in which manifest files can be generated using continuous integration to version code, infrastructure, networking, and load balancing.</p><p>Readers should learn all the necessary steps in a Continuous Delivery pipeline, how to set up a deployment pipeline using Jenkins 2.x, and the importance of integrating networking in the Continuous Delivery model.</p><p>In the next chapter, we will focus on containers and look at the impact they have had on networking and network operations. We will look at some of the different orchestration options that can be used such as Docker and Kubernetes.</p></div></body></html>