<html><head></head><body>
<div><div><h1 class="chapter-number" id="_idParaDest-396"><a id="_idTextAnchor396"/>18</h1>
<h1 id="_idParaDest-397"><a id="_idTextAnchor397"/>Running a Containerized Application in the Cloud</h1>
<p>In the previous chapter, we learned how to deploy, update, and scale applications into a Kubernetes cluster. We discovered how zero-downtime deployments are achieved to enable disruption-free updates and rollbacks of mission-critical applications. Finally, we were introduced to Kubernetes secrets as a means to configure services and protect sensitive data.</p>
<p>In this chapter, we will give an overview of the three most popular ways of running containerized applications in the cloud. We will explore each of the hosted solutions and discuss their pros and cons.</p>
<p>Here are the topics we will be discussing in this chapter:</p>
<ul>
<li>Why choose a hosted Kubernetes service?</li>
<li>Running a <a id="_idIndexMarker1529"/>simple containerized application on <strong class="bold">Amazon Elastic Kubernetes Service</strong> (<strong class="bold">Amazon EKS</strong>)</li>
<li>Exploring <a id="_idIndexMarker1530"/>Microsoft’s <strong class="bold">Azure Kubernetes </strong><strong class="bold">Service</strong> (<strong class="bold">AKS</strong>)</li>
<li>Understanding <strong class="bold">Google Kubernetes </strong><strong class="bold">Engine</strong> (<strong class="bold">GKE</strong>)</li>
</ul>
<p>After reading <a id="_idIndexMarker1531"/>this chapter, you will be able to do the following:</p>
<ul>
<li>Reason about the pros and potential cons of a hosted Kubernetes service compared to a self-managed Kubernetes cluster</li>
<li>Deploy and run a simple distributed application in Amazon EKS</li>
<li>Deploy and run a simple distributed application on Microsoft’s AKS</li>
<li>Deploy and run a simple distributed application on GKE</li>
</ul>
<h1 id="_idParaDest-398"><a id="_idTextAnchor398"/>Technical requirements</h1>
<p>We are <a id="_idIndexMarker1532"/>going to use <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>), Microsoft Azure, and Google Cloud in this chapter; therefore, it is necessary to have an account for each platform. If you do not have an existing account, you can ask for a trial account for all of these cloud providers.</p>
<p>We’ll also use the files in the <code>~/The-Ultimate-Docker-Container-Book/sample-solutions/ch18</code> folder of our lab’s repository from GitHub at <a href="https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch18">https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch18</a>.</p>
<p>Prepare the folder where you will put your own code. For this, first, navigate to the source folder, as follows:</p>
<pre class="source-code">
$ cd ~/The-Ultimate-Docker-Container-Book</pre> <p>Then, create a <code>ch18</code> subfolder and navigate to it, like so:</p>
<pre class="source-code">
$ mkdir ch18 &amp; cd ch18</pre> <h1 id="_idParaDest-399"><a id="_idTextAnchor399"/>Why choose a hosted Kubernetes service?</h1>
<p>Currently, the three most popular cloud providers, AWS, Microsoft Azure, and Google Cloud each have a managed <a id="_idIndexMarker1533"/>Kubernetes offering, as outlined here:</p>
<ul>
<li><strong class="bold">Amazon EKS</strong>: Amazon EKS is <a id="_idIndexMarker1534"/>a managed <a id="_idIndexMarker1535"/>service that makes it easy for you to run Kubernetes on AWS without needing to install, operate, and maintain your own Kubernetes control plane or nodes.</li>
<li><strong class="bold">AKS</strong>: AKS is <a id="_idIndexMarker1536"/>Microsoft’s managed Kubernetes <a id="_idIndexMarker1537"/>offering. It offers developer productivity with <strong class="bold">continuous integration and continuous deployment</strong> (<strong class="bold">CI/CD</strong>) capabilities and Kubernetes tools integration. It <a id="_idIndexMarker1538"/>also has an Azure DevOps project for a complete container CI/CD platform.</li>
<li><strong class="bold">GKE</strong>: Google <a id="_idIndexMarker1539"/>was the original creator of <a id="_idIndexMarker1540"/>Kubernetes, and GKE was the first managed Kubernetes service available on the market. It offers advanced cluster management features, as well as integration with Google Cloud services.</li>
</ul>
<p>Other providers <a id="_idIndexMarker1541"/>also offer <strong class="bold">Kubernetes as a service</strong> (<strong class="bold">KaaS</strong>), such as IBM Cloud Kubernetes Service, Oracle Container Engine for Kubernetes, and <strong class="bold">DigitalOcean Kubernetes</strong> (<strong class="bold">DOKS</strong>). It’s always a good idea to check the latest <a id="_idIndexMarker1542"/>offerings and their features since the cloud market evolves rapidly.</p>
<p>Managing a Kubernetes cluster, either on-premises or in the cloud, involves considerable operational complexity and requires expertise. Here are a few reasons why using a hosted Kubernetes service is often the preferred solution:</p>
<ul>
<li><strong class="bold">Ease of setup and management</strong>: Hosted Kubernetes services handle the underlying <a id="_idIndexMarker1543"/>infrastructure, reducing the operational burden of managing a Kubernetes cluster. They automatically take care of the provisioning, upgrades, patching, and scaling of the Kubernetes control plane.</li>
<li><strong class="bold">High availability (HA) and high scalability</strong>: Hosted services often offer out-of-the-box <a id="_idIndexMarker1544"/>HA and high scalability <a id="_idIndexMarker1545"/>for your applications. They handle the orchestration necessary to distribute applications across different nodes and data centers.</li>
<li><strong class="bold">Security and compliance</strong>: Hosted services often include built-in security features <a id="_idIndexMarker1546"/>such as network <a id="_idIndexMarker1547"/>policies, <strong class="bold">role-based access control</strong> (<strong class="bold">RBAC</strong>), and <a id="_idIndexMarker1548"/>integration with cloud provider <strong class="bold">Identity &amp; Access Management</strong> (<strong class="bold">IAM</strong>) services. They also handle security updates to the Kubernetes software itself.</li>
<li><strong class="bold">Monitoring and diagnostics</strong>: Hosted Kubernetes services typically include integration <a id="_idIndexMarker1549"/>with monitoring and logging services, making it easier to observe and troubleshoot your applications.</li>
<li><strong class="bold">Cost</strong>: While <a id="_idIndexMarker1550"/>there is a cost associated with using a managed service, it can often be less than the cost of the dedicated personnel and infrastructure required to operate a Kubernetes cluster efficiently and securely.</li>
<li><strong class="bold">Support</strong>: When using <a id="_idIndexMarker1551"/>a hosted Kubernetes service, you’ll have access to support from the cloud provider. This can be particularly valuable if you’re running production workloads and need fast resolution of any issues that arise.</li>
</ul>
<p>In contrast, running your own Kubernetes clusters involves significant setup and maintenance work. You’re responsible for everything, from the installation and configuration of Kubernetes to the ongoing tasks of cluster upgrades, security patching, node provisioning, and scaling, as well as setting up monitoring and alerting.</p>
<p>While managing your own clusters provides more control and flexibility, it requires a substantial investment in time, resources, and expertise. For many organizations, the benefits of a managed service far outweigh the increased control of self-managing their clusters.</p>
<h1 id="_idParaDest-400"><a id="_idTextAnchor400"/>Running a simple containerized application on  Amazon EKS</h1>
<p>In this section, we want <a id="_idIndexMarker1552"/>to create a fully <a id="_idIndexMarker1553"/>managed Kubernetes cluster on Amazon EKS using Fargate. The process of creating a new cluster is well described in the AWS documentation, and we will refer to the respective pages to not duplicate too much information. That said, let us start with the following steps.</p>
<p class="callout-heading">What is Fargate?</p>
<p class="callout">AWS Fargate is a <a id="_idIndexMarker1554"/>serverless compute engine for containers provided by AWS. It removes the need to manage the underlying servers and allows you to focus on designing and building your applications. Fargate handles the deployment, scaling, and management of containers, enabling you to launch applications without worrying about the infrastructure.</p>
<p>Let us first <a id="_idIndexMarker1555"/>get a few prerequisites <a id="_idIndexMarker1556"/>out of the way, as follows:</p>
<ol>
<li>Make sure you have access to an AWS account. If not, you can get a free 1-year trial account here: <a href="https://aws.amazon.com/free">https://aws.amazon.com/free</a>.</li>
<li>Log in to your AWS account.</li>
<li>Create a new <em class="italic">access key</em> and <em class="italic">access key secret</em> pair for your account, which you will use to configure your AWS CLI so that you can access your account from the command line.</li>
<li>Locate your profile at the top right of the screen, and from the dropdown, select <strong class="bold">Security credentials</strong>.</li>
</ol>
<p>Select <strong class="bold">Access keys</strong> (access key ID and secret access key) and then click <strong class="bold">Create </strong><strong class="bold">access key</strong>:</p>
<div><div><img alt="Figure 18.1 – Note down the access key ID and secret pair in a safe place" height="434" src="img/Figure_18.01_B19199.jpg" width="1099"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.1 – Note down the access key ID and secret pair in a safe place</p>
<ol>
<li value="5">Open a new terminal.</li>
<li>Make sure you have the AWS CLI installed.</li>
</ol>
<p>On a Mac, use the following command:</p>
<pre class="source-code">
$ brew install awscli</pre> <p>On Windows, use this command:</p>
<pre class="source-code">
$ choco install awscli</pre> <ol>
<li value="7">In both cases, test the installation with the following command:<pre class="source-code">
$ aws --version</pre></li> <li>Configure <a id="_idIndexMarker1557"/>your AWS CLI. For this, you <a id="_idIndexMarker1558"/>need your <em class="italic">AWS access key ID</em> and <em class="italic">AWS secret access key</em> that you created in preceding <em class="italic">step 3</em>, as well as your default <em class="italic">region</em>.</li>
</ol>
<p>Then, use the following command:</p>
<pre class="source-code">
$ aws configure</pre> <p>Enter the appropriate values when asked. For the default output format, select <code>JSON</code>, as shown here:</p>
<div><div><img alt="Figure 18.2 – Configuring the AWS CLI" height="129" src="img/Figure_18.02_B19199.jpg" width="814"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.2 – Configuring the AWS CLI</p>
<ol>
<li value="9">Try accessing your account with a command such as the following:<pre class="source-code">
$ aws s3 ls</pre></li> </ol>
<p>This should <a id="_idIndexMarker1559"/>list all the <strong class="bold">Simple Storage Service</strong> (<strong class="bold">S3</strong>) buckets defined for your account. Your list may be empty. The important thing here is that the command succeeds.</p>
<ol>
<li value="10">Finally, double-check that you have <code>kubectl</code> installed by running the following command:<pre class="source-code">
$ kubectl version</pre></li> </ol>
<p>Now, we are <a id="_idIndexMarker1560"/>ready to create the Amazon <a id="_idIndexMarker1561"/>EKS cluster. Follow these steps:</p>
<ol>
<li>Define a few environment variables for later use, as follows:<pre class="source-code">
$ export AWS_REGION=eu-central-1$ export AWS_STACK_NAME=animals-stack$ export AWS_CLUSTER_ROLE=animals-cluster-role</pre></li> </ol>
<p>Make sure to replace <code>eu-central-1</code> with the AWS region closest to you.</p>
<ol>
<li value="2">You can now create the necessary AWS stack consisting of VPC, private and public subnets, and a security group, using the following command, which—to simplify things—uses a sample YAML file from AWS:<pre class="source-code">
$ aws cloudformation create-stack --region $AWS_REGION \    --stack-name $AWS_STACK_NAME \    --template-url https://s3.us-west-2.amazonaws.com/amazon-eks/cloudformation/2020-10-29/amazon-eks-vpc-private-subnets.yaml</pre></li> </ol>
<p>Please take a moment to download and inspect the preceding YAML file to understand what exactly the command is provisioning.</p>
<ol>
<li value="3">In the next few steps, you need to define the right settings to grant the necessary access rights to the cluster:<ol><li>Start by creating an IAM role with this command:</li></ol><pre class="source-code">
<code>$ aws iam create-role \</code><code>    --role-name $AWS_CLUSTER_ROLE \</code><code>    --assume-role-policy-document file://"eks-cluster-role-trust-policy.json"</code></pre><ol><li value="2">Proceed <a id="_idIndexMarker1562"/>by attaching <a id="_idIndexMarker1563"/>the necessary Amazon EKS-managed IAM policy to the role just created with this command:</li></ol><pre class="source-code"><code>$ aws iam attach-role-policy \</code><code>    --policy-arn arn:aws:iam::aws:policy/AmazonEKSClusterPolicy \</code><code>    --role-name $AWS_CLUSTER_ROLE</code></pre></li> <li>Now, we continue with some interactive steps using the Amazon EKS console at <a href="https://console.aws.amazon.com/eks/home#/clusters">https://console.aws.amazon.com/eks/home#/clusters</a>.</li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">Make sure that the AWS Region shown in the upper right of your console is the AWS Region in which you want to create your cluster in (for example, <code>eu-central-1)</code> in the author’s case). If it’s not, select the dropdown next to the AWS Region name and choose the AWS Region that you want to use.</p>
<ol>
<li value="5">To create your cluster, choose the <strong class="bold">Add cluster</strong> command and then choose <strong class="bold">Create</strong>. If you don’t see this option, choose <strong class="bold">Clusters</strong> in the left navigation pane first.</li>
<li>On the <code>animals-cluster</code>.</li><li><code>animals-cluster-role</code>. Please select it.</li><li>All the other settings can be left as their default values.</li><li>Choose <strong class="bold">Next</strong>.</li></ol></li>
<li>On the <code>vpc-00x0000x000x0x000 | animals-stack-VPC</code>. Note the postfix of the name, indicating it is the one we defined just a moment ago.</li><li>Once again, you can leave the remaining settings at their default values.</li><li>Choose <strong class="bold">Next</strong> to continue.</li></ol></li>
<li>We do <a id="_idIndexMarker1564"/>not need to change anything on the <strong class="bold">Configure logging</strong> page, so choose <strong class="bold">Next</strong>.</li>
<li>The same <a id="_idIndexMarker1565"/>applies for the <strong class="bold">Select add-ons</strong> page; thus, choose <strong class="bold">Next</strong>.</li>
<li>And once again, on the <strong class="bold">Configure selected add-ons</strong> settings page, there is nothing to do, so choose <strong class="bold">Next</strong>.</li>
<li>Finally, on the <strong class="bold">Review and create </strong>page, choose <strong class="bold">Create</strong>.</li>
<li>To the right of the cluster’s name, the cluster status is <strong class="bold">Creating</strong> for several minutes until the cluster provisioning process completes, as shown in the following screenshot. Don’t continue to the next step until the status is <strong class="bold">Active</strong>:</li>
</ol>
<div><div><img alt="Figure 18.3 – Creating an EKS cluster" height="238" src="img/Figure_18.03_B19199.jpg" width="795"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.3 – Creating an EKS cluster</p>
<ol>
<li value="13">Sadly, we are <a id="_idIndexMarker1566"/>not done yet. We need <a id="_idIndexMarker1567"/>to create a trust policy and attach it to our cluster. To do this, proceed as follows:<ol><li>Start by creating a <code>pod-execution-role-trust-policy.json</code> file and add the following content to it:</li></ol><pre class="source-code">
<code>{</code><code>  "Version": "2012-10-17",</code><code>  "Statement": [</code><code>    {</code><code>      "Effect": "Allow",</code><code>      "Condition": {</code><code>        "ArnLike": {</code><code>          "aws:SourceArn": "arn:aws:eks:&lt;region-code&gt;:&lt;account-no&gt;:fargateprofile/animals-cluster/*"</code><code>        }</code><code>      },</code><code>      "Principal": {</code><code>        "Service": "eks-fargate-pods.amazonaws.com"</code><code>      },</code><code>      "Action": "sts:AssumeRole"</code><code>    }</code><code>  ]</code><code>}</code></pre></li> </ol>
<p>In the preceding code, replace <code>&lt;region-code&gt;</code> with the code for your AWS region (<code>eu-central-1</code> in my case) and <code>&lt;account-no&gt;</code> with the number of your account. You can find the latter under your profile in the upper left of the AWS console.</p>
<ol>
<li value="2">Using the <a id="_idIndexMarker1568"/>trust policy <a id="_idIndexMarker1569"/>just provisioned, create <a id="_idIndexMarker1570"/>a <strong class="bold">Pod execution IAM role</strong> with this command:</li>
</ol>
<pre class="source-code">
<code>$ aws iam create-role \</code><code>    --role-name AmazonEKSFargatePodExecutionRole \</code>
<code>    --assume-role-policy-document file://"pod-execution-role-trust-policy.json"</code></pre>
<ol>
<li value="3">Finally, connect the required role and policy with each other using this command:</li>
</ol>
<pre class="source-code">
<code>$ aws iam attach-role-policy \</code><code>    --policy-arn arn:aws:iam::aws:policy/AmazonEKSFargatePodExecutionRolePolicy \</code>
<code>    --role-name AmazonEKSFargatePodExecutionRole</code></pre>
<ol>
<li value="14">On the <code>animals-cluster</code> cluster.</li>
<li>On the <code>animals-cluster</code> page, do the following:<ol><li>Select the <code>animals-profile</code>.</li><li>For <code>AmazonEKSFargatePodExecutionRole</code> role that you created in a previous step.</li><li>Choose the <strong class="bold">Subnets</strong> dropdown and deselect any subnet with <strong class="bold">Public</strong> in its name. Only private subnets are supported for Pods that are running on Fargate.</li><li>Choose <strong class="bold">Next</strong>.</li></ol></li></ol></li>
<li>On the <code>default</code>.</li><li>Then choose <strong class="bold">Next</strong>.</li></ol></li>
<li>On the <strong class="bold">Review and create page</strong>, review the information for your Fargate profile and choose <strong class="bold">Create</strong>.</li>
<li>After a <a id="_idIndexMarker1571"/>few minutes, the status <a id="_idIndexMarker1572"/>in the <strong class="bold">Fargate Profile configuration</strong> section will change from <strong class="bold">Creating</strong> to <strong class="bold">Active</strong>. Don’t continue to the next step until the status is <strong class="bold">Active</strong>.</li>
<li>If you plan to deploy all Pods to Fargate (none to Amazon EC2 nodes), do the following to create another Fargate profile and run the default name resolver (CoreDNS) on Fargate.</li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">If you don’t do this, you won’t have any nodes at this time.</p>
<ol>
<li value="20">On the <code>animals-profile</code>.</li>
<li>Under <strong class="bold">Fargate profiles</strong>, choose <strong class="bold">Add </strong><strong class="bold">Fargate Profile</strong>.</li>
<li>In the <strong class="bold">Name</strong> field, enter <strong class="bold">CoreDNS</strong>.</li>
<li>For <code>AmazonEKSFargatePodExecutionRole</code> role that you created in <em class="italic">step 13</em>.</li>
<li>Click the <code>Public</code> in its name. Fargate only supports Pods on private subnets.</li>
<li>Choose <strong class="bold">Next</strong>.</li>
<li>In the <code>kube-system</code>.</li>
<li>Choose <strong class="bold">Match labels</strong>, and then choose <strong class="bold">Add label</strong>.</li>
<li>Enter <code>k8s-app</code> for <code>kube-dns</code> for <strong class="bold">Value</strong>. This is necessary for the default name resolver (CoreDNS) to deploy to Fargate.</li>
<li>Choose <strong class="bold">Next</strong>.</li>
<li>On the <strong class="bold">Review and create </strong>page, review the information for your Fargate profile and choose <strong class="bold">Create</strong>.</li>
<li>Run the <a id="_idIndexMarker1573"/>following command <a id="_idIndexMarker1574"/>to remove the default <code>eks.amazonaws.com/compute-type : ec2</code> annotation from the CoreDNS Pods:<pre class="source-code">
kubectl patch deployment coredns \    -n kube-system \    --type json \    -p='[{"op": "remove", "path": "/spec/template/metadata/annotations/eks.amazonaws.com~1compute-type"}]'</pre></li> </ol>
<p class="callout-heading">Note</p>
<p class="callout">The system creates and deploys two nodes based on the Fargate profile label you added. You won’t see anything listed in <strong class="bold">Node groups</strong> because they aren’t applicable to Fargate nodes, but you will see the new nodes listed in the <strong class="bold">Compute</strong> tab.</p>
<p>For a more <a id="_idIndexMarker1575"/>detailed explanation, you can <a id="_idIndexMarker1576"/>follow the step-by-step instructions at the following link to create your cluster:</p>
<p><a href="https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.xhtml">https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.xhtml</a> (<em class="italic">Getting started with Amazon EKS – AWS Management Console and </em><em class="italic">AWS CLI</em>)</p>
<p>When your cluster is ready, you can then continue with the following steps:</p>
<ol>
<li>Configure <code>kubectl</code> to access your new cluster on AWS, as follows:<pre class="source-code">
$ aws eks update-kubeconfig --name animals-cluster</pre></li> </ol>
<p>The response should be similar to the following:</p>
<pre class="source-code">
Added new context arn:aws:eks:eu-central-...:cluster/animals-cluster to /Users/&lt;user-name&gt;/.kube/config</pre> <p>Here, <code>&lt;user-name&gt;</code> corresponds to your username on the machine you’re working on.</p>
<ol>
<li value="2">Double-check that <code>kubectl</code> is using the correct context—the one that was just created for the cluster on AWS and added to your <code>~/.</code><code>kube/config</code> file:<pre class="source-code">
$ kubectl config current-context</pre></li> </ol>
<p>The answer should look similar to the following:</p>
<pre class="source-code">
arn:aws:eks:eu-central-...:cluster/animals-cluster</pre> <p>In case another context is the active one, use the <code>kubectl config use-context</code> command in combination with the correct AWS context.</p>
<ol>
<li value="3">Use <code>kubectl</code> to list all the resources on your cluster, like so:<pre class="source-code">
$ kubectl get all</pre></li> </ol>
<p>The answer at this time should look like this:</p>
<div><div><img alt="Figure 18.4 – Amazon EKS – kubectl get all" height="87" src="img/Figure_18.04_B19199.jpg" width="832"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.4 – Amazon EKS – kubectl get all</p>
<ol>
<li value="4">To see <a id="_idIndexMarker1577"/>the nodes of your cluster, use the following command:<pre class="source-code">
$ kubectl get nodes</pre></li> </ol>
<p>You <a id="_idIndexMarker1578"/>should then see something like this:</p>
<div><div><img alt="Figure 18.5 – List of nodes in the EKS cluster" height="108" src="img/Figure_18.05_B19199.jpg" width="1132"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.5 – List of nodes in the EKS cluster</p>
<ol>
<li value="5">Navigate to the <code>ch18</code> folder of this chapter, create an <code>aws-eks</code> subfolder, and then navigate to it:<pre class="source-code">
$ cd ~/The-Ultimate-Docker-Container-Book/ch18$ mkdir aws-eks &amp;&amp; cd aws-eks</pre></li> <li>In this subfolder, create a <code>deploy-nginx.yaml</code> file with the following content:</li>
</ol>
<div><div><img alt="Figure 18.6 – Deployment specification for nginx on Amazon EKS" height="976" src="img/Figure_18.06_B19199.jpg" width="599"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.6 – Deployment specification for nginx on Amazon EKS</p>
<ol>
<li value="7">Use <code>kubectl</code> to deploy <a id="_idIndexMarker1579"/>our deployment <a id="_idIndexMarker1580"/>to the cluster, as follows:<pre class="source-code">
$ kubectl apply -f deploy-nginx.yaml</pre></li> <li>Observe the creation of the Pods with the following command:<pre class="source-code">
$ kubectl get pods -w</pre></li> </ol>
<p>And wait until they are ready:</p>
<div><div><img alt="Figure 18.7 – Listing the Pods of the deployment to AWS" height="125" src="img/Figure_18.07_B19199.jpg" width="761"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.7 – Listing the Pods of the deployment to AWS</p>
<ol>
<li value="9">Wait until <a id="_idIndexMarker1581"/>their value in the <code>1/1</code>.</li>
<li>In the <a id="_idIndexMarker1582"/>AWS console, navigate to your cluster.</li>
<li>In the <code>web</code> Pods and two <code>coredns</code> Pods were created.</li>
<li>In the <strong class="bold">Compute</strong> tab, observe that multiple Fargate nodes have been created.</li>
<li>Drill down to a node to see the Pod that has been deployed to it.</li>
<li>Drill further down to the Pod and observe the list of events shown in its <strong class="bold">Details</strong> view.</li>
</ol>
<p>Congratulations—you have created a fully hosted Kubernetes cluster on AWS and created a first Deployment on it using <code>kubectl</code>! As you will know, this is quite an achievement. It turns out that of all the discussed cloud providers, AWS requires by far the most steps to get a Kubernetes cluster up and running.</p>
<p>Before you leave, and to avoid unexpected costs, make sure you clean up all the resources that you have created during this exercise. For this, follow the next steps:</p>
<ol>
<li>Use <code>kubectl</code> to delete the previous deployment:<pre class="source-code">
$ kubectl delete -f deploy-nginx.yaml</pre></li> <li>Locate your <code>animals-cluster</code> cluster and select it.</li>
<li>In the <code>animals-profile</code> and <code>CoreDNS</code> profiles and delete them.</li>
<li>When both profiles are deleted—which may take a few minutes—then click the <strong class="bold">Delete cluster</strong> button to get rid of the cluster.</li>
<li>Delete the VPC AWS CloudFormation stack that you created.</li>
<li>Open the <strong class="bold">AWS CloudFormation</strong> console at <a href="https://console.aws.amazon.com/cloudformation">https://console.aws.amazon.com/cloudformation</a>.</li>
<li>Choose the <code>animals-stack</code> stack, and then choose <strong class="bold">Delete</strong>.</li>
<li>In the <strong class="bold">Delete animals-stack</strong> confirmation dialog box, choose <strong class="bold">Delete stack</strong>.</li>
<li>Delete the IAM roles that you created.</li>
<li>Open the IAM console at <a href="https://console.aws.amazon.com/iam/">https://console.aws.amazon.com/iam/</a>.</li>
<li>In the <a id="_idIndexMarker1583"/>left navigation pane, choose <strong class="bold">Roles</strong>.</li>
<li>Select each <a id="_idIndexMarker1584"/>role you created from the list (<code>myAmazonEKSClusterRole</code>, as well as <code>AmazonEKSFargatePodExecutionRole</code> or <code>myAmazonEKSNodeRole</code>). Choose <strong class="bold">Delete</strong>, enter the requested confirmation text, then choose <strong class="bold">Delete</strong>.</li>
</ol>
<p>Alternatively, follow the steps in the <em class="italic">Step 5: Delete resources</em> section in the AWS documentation:</p>
<p><a href="https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.xhtml">https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.xhtml</a></p>
<p>This was quite an achievement! Creating and managing an EKS cluster requires more intimate knowledge of details than we would want. We will see that other providers are more user-friendly in that regard.</p>
<p>Now that we have a rough understanding of what Amazon EKS offers, let us have a look at what the second-biggest cloud provider has in its portfolio.</p>
<h1 id="_idParaDest-401"><a id="_idTextAnchor401"/>Exploring Microsoft’s AKS</h1>
<p>To experiment with Microsoft’s container-related offerings in Azure, we need an account on Azure. You can create a trial account or use an existing account. You can get a free trial account here: <a href="https://azure.microsoft.com/en-us/free/">https://azure.microsoft.com/en-us/free/</a>.</p>
<p>Microsoft offers <a id="_idIndexMarker1585"/>different container-related services on Azure. The easiest one to use is probably Azure Container Instances, which promises the fastest and simplest way to run a container in Azure, without having to provision any <strong class="bold">virtual machines</strong> (<strong class="bold">VMs</strong>) and without <a id="_idIndexMarker1586"/>having to adopt a higher-level service. This service is only really useful if you want to run a single container in a hosted environment. The setup is quite easy. In the Azure portal (<a href="https://portal.azure.com">https://portal.azure.com</a>), you first create a new resource group and then create an Azure container instance. You only need to fill out a short form with properties such as the name of the container, the image to use, and the port to open. The container can be made available on a public or private IP address and will be automatically restarted if it crashes. There is a decent management console available, for example, to monitor resource consumption such as CPU and memory.</p>
<p>The second <a id="_idIndexMarker1587"/>choice is <strong class="bold">Azure Container Service</strong> (<strong class="bold">ACS</strong>), which provides a way to simplify the creation, configuration, and management of a cluster of VMs that is preconfigured to run containerized applications. ACS uses Docker images <a id="_idIndexMarker1588"/>and provides a choice between three orchestrators: Kubernetes, Docker Swarm, and the <strong class="bold">Distributed Cloud Operating System</strong> (<strong class="bold">DC/OS</strong>) (powered by Apache Mesos). Microsoft claims that its service can be scaled to tens of thousands of containers. ACS is free, and you are only charged for computing resources.</p>
<p>In this section, we will concentrate on the most popular offering, based on Kubernetes. It is called <a id="_idIndexMarker1589"/>AKS and can be found here: <a href="https://azure.microsoft.com/en-us/services/kubernetes-service/">https://azure.microsoft.com/en-us/services/kubernetes-service/</a>. AKS makes it easy for you to deploy applications in the cloud and run them on Kubernetes. All the difficult and tedious management tasks are handled by Microsoft, and you can concentrate fully on your applications. What that means is that you will never have to deal with tasks such as installing and managing Kubernetes, upgrading Kubernetes, or upgrading the operating system of the underlying Kubernetes nodes. All this is handled by the experts at Microsoft Azure. Furthermore, you will never have to deal with <code>etc</code> or Kubernetes master nodes. This is all hidden from you, and the only things you will interact with are the Kubernetes worker nodes that run your applications.</p>
<h2 id="_idParaDest-402"><a id="_idTextAnchor402"/>Preparing the Azure CLI</h2>
<p>That said, let’s start. We assume that you have created a free trial account or that you are using an <a id="_idIndexMarker1590"/>existing account on Azure. There are various ways to interact with your Azure account. We will use the Azure CLI running on our local computer. We can either download and install the Azure CLI natively on our computer or run it from within a container running on our local version of Docker Desktop. Since this book is all about containers, let’s select the latter approach.</p>
<p>The latest version of the Azure CLI can be found on Docker Hub. Let’s pull it:</p>
<pre class="source-code">
$ docker image pull mcr.microsoft.com/azure-cli:latest</pre> <p>We will run a container from this CLI and executing all subsequent commands from within the shell running inside this container. Now, there is a little problem we need to overcome—this container will not have a Docker client installed. But we will also run some Docker commands, so we must create a custom image derived from the preceding image, which contains a Docker client. The Dockerfile that’s needed to do so can be found in the <code>sample-solutions/ch18</code> subfolder and has this content:</p>
<pre class="source-code">
FROM mcr.microsoft.com/azure-cli:latestRUN apk update &amp;&amp; apk add docker</pre>
<p>On <em class="italic">line 2</em>, we are just using the Alpine package manager, <code>apk</code>, to install Docker. We can then use Docker Compose to build and run this custom image. The corresponding <code>docker-compose.yml</code> file looks like this:</p>
<pre class="source-code">
version: "2.4"services:
  az:
    image: fundamentalsofdocker/azure-cli
    build: .
    command: tail -F anything
    working_dir: /app
    volumes:
    - /var/run/docker.sock:/var/run/docker.sock
    - .:/app</pre>
<p class="callout-heading">Note</p>
<p class="callout">The <code>tail -F anything</code> command is used to keep the container running, as well as for the mounting of the Docker socket and the current folder in the <code>volumes</code> section.</p>
<p class="callout-heading">Tip</p>
<p class="callout">If you are running Docker Desktop on Windows, then you need to define the <code>COMPOSE_CONVERT_WINDOWS_PATHS</code> environment variable to be able to mount the Docker socket. Use <code>export COMPOSE_CONVERT_WINDOWS_PATHS=1</code> from a Bash shell or <code>$Env:COMPOSE_CONVERT_WINDOWS_PATHS=1</code> when running PowerShell. Please refer to the following link for more details: <a href="https://github.com/docker/compose/issues/4240">https://github.com/docker/compose/issues/4240</a>.</p>
<p>Now, let’s <a id="_idIndexMarker1591"/>build and run this container, as follows:</p>
<pre class="source-code">
$ docker compose up --build -d</pre> <p>Then, let’s execute into the <code>az</code> container and run a Bash shell in it with the following command:</p>
<pre class="source-code">
$ docker compose exec az /bin/bash</pre> <p>You should get an output like this:</p>
<pre class="source-code">
376f1e715919:/app #</pre> <p>Note that your hash code (<code>376f1e...</code>) representing the hostname inside the container will be different. To simplify the reading, we will omit this hash code in subsequent commands.</p>
<p>As you may have noted, we find ourselves running in a Bash shell inside the container. Let’s first check the version of the CLI:</p>
<pre class="source-code">
# az --version</pre> <p>This should <a id="_idIndexMarker1592"/>result in an output like this:</p>
<pre class="source-code">
azure-cli                         2.49.0core                              2.49.0
telemetry                          1.0.8
Dependencies:
msal                              1.20.0
azure-mgmt-resource               22.0.0
Python location '/usr/local/bin/python'
Extensions directory '/root/.azure/cliextensions'
Python (Linux) 3.10.11 (main, May 11 2023, 23:59:31) [GCC 12.2.1 20220924]
Legal docs and information: aka.ms/AzureCliLegal
Your CLI is up-to-date.</pre>
<p>OK—we’re running on version 2.49.0. Next, we need to log in to our account. Execute this command:</p>
<pre class="source-code">
# az login</pre> <p>You will be presented with the following message:</p>
<pre class="source-code">
To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code &lt;code&gt; to authenticate.</pre> <p>Follow the instructions and log in through the browser. Once you have successfully authenticated <a id="_idIndexMarker1593"/>your Azure account, you can go back to your terminal and you should be logged in, as indicated by the output you’ll get:</p>
<pre class="source-code">
[  {
    "cloudName": "AzureCloud",
    "id": "&lt;id&gt;",
    "isDefault": true,
    "name": "&lt;account name&gt;",
    "state": "Enabled",
    "tenantId": "&lt;tenant-it&gt;",
    "user": {
      "name": &lt;your-email&gt;,
      "type": "user"
    }
  }
]</pre>
<p>Now, we are ready to first move our container images to Azure.</p>
<h2 id="_idParaDest-403"><a id="_idTextAnchor403"/>Creating a container registry on Azure</h2>
<p>First, we create <a id="_idIndexMarker1594"/>a new resource group named <code>animal-rg</code>. In Azure, resource groups are used to logically group a collection of associated resources. To have an optimal cloud experience and keep latency low, it is important that you select a data center located in a region near you. Follow these steps:</p>
<ol>
<li>You can <a id="_idIndexMarker1595"/>use the following command to list all regions:<pre class="source-code">
# az account list-locations</pre></li> </ol>
<p>The output should look like this:</p>
<pre class="source-code">
[  {
    "displayName": "East Asia",
    "id": "/subscriptions/186760.../locations/eastasia",
    "latitude": "22.267",
    "longitude": "114.188",
    "name": "eastasia",
    "subscriptionId": null
  },
...
]</pre>
<p>This will give you a rather long list of all possible regions you can select from. Use the name—for example, <code>eastasia</code>—to identify the region of your choice. In my case, I will select <code>westeurope</code>. Please note that not all locations listed are valid for resource groups.</p>
<ol>
<li value="2">The command to create a resource group is simple; we just need a name for the group and the location, as demonstrated here:<pre class="source-code">
# az group create --name animals-rg --location westeurope{  "id": "/subscriptions/186.../resourceGroups/animals-rg",  "location": "westeurope",  "managedBy": null,  "name": "animals-rg",  "properties": {    "provisioningState": "Succeeded"  },  "tags": null,  "type": "Microsoft.Resources/resourceGroups"}</pre></li> </ol>
<p>Make sure that your output shows <code>"</code><code>provisioningState": "Succeeded"</code>.</p>
<p class="callout-heading">Note</p>
<p class="callout">When running a containerized application in production, we want to make sure that we <a id="_idIndexMarker1596"/>can freely download the corresponding container images from a container registry. So far, we have always downloaded our images from Docker Hub, but this is often not possible. For security reasons, the servers of a production system often have no direct access to the internet and thus are not able to reach out to Docker Hub. Let’s follow this best practice and assume the same for our Kubernetes cluster that we are going to create in an instant.</p>
<p>So, what can we do? Well, the solution is to use a container image registry that is close to our cluster <a id="_idIndexMarker1597"/>and that is in the same security context. In Azure, we can create an <strong class="bold">Azure Container Registry</strong> (<strong class="bold">ACR</strong>) instance and host our images there, so here’s what we’ll do:</p>
<ol>
<li>Let’s first create such a registry, as follows:<pre class="source-code">
# az acr create --resource-group animals-rg \    --name &lt;acr-name&gt; --sku Basic</pre></li> </ol>
<p>Note that <code>&lt;acr-name&gt;</code> needs to be unique. In my case, I have chosen the name <code>gnsanimalsacr</code>. The (shortened) output looks like this:</p>
<pre class="source-code">
Registration succeeded.{
  "adminUserEnabled": false,
  "creationDate": "2023-06-04T10:31:14.848776+00:00",
...
  "id": "/subscriptions/186760ad...",
  "location": "westeurope",
  "loginServer": "gnsanimalsacr.azurecr.io",
  "name": " gnsanimalsacr ",
...
  "provisioningState": "Succeeded",</pre>
<ol>
<li value="2">After <a id="_idIndexMarker1598"/>successfully creating the container registry, we need to log in to that registry using the following command:<pre class="source-code">
# az acr login --name &lt;acr-name&gt;</pre></li> </ol>
<p>The response to the preceding command should be this:</p>
<pre class="source-code">
Login Succeeded</pre> <p>Once we are successfully logged in to the container registry on Azure, we need to tag our containers correctly so that we can then push them to ACR. Tagging and pushing images to ACR will be described next.</p>
<h2 id="_idParaDest-404"><a id="_idTextAnchor404"/>Pushing our images to ACR</h2>
<p>Once we <a id="_idIndexMarker1599"/>have successfully logged in to ACR, we can tag our images such that they can be pushed to the registry. For this, we need to know the URL of our ACR instance. It is as follows:</p>
<pre class="source-code">
&lt;acr-name&gt;.azurecr.io</pre> <p>We now use the preceding URL to tag our images:</p>
<pre class="source-code">
# docker image tag fundamentalsofdocker/ch11-db:2.0 \    &lt;acr-name&gt;.azurecr.io/db:2.0
# docker image tag fundamentalsofdocker/ch11-web:2.0 \
    &lt;acr-name&gt;.azurecr.io/web:2.0</pre>
<p>Then, we can <a id="_idIndexMarker1600"/>push them to our ACR instance:</p>
<pre class="source-code">
# docker image push &lt;acr-name&gt;.azurecr.io/db:2.0# docker image push &lt;acr-name&gt;.azurecr.io/web:2.0</pre>
<p>To double-check that our images are indeed in our ACR instance, we can use this command:</p>
<pre class="source-code">
# az acr repository list --name &lt;acr-name&gt; --output table</pre> <p>This should give you the following output:</p>
<pre class="source-code">
Result--------
Db
web</pre>
<p>Indeed, the two images we just pushed are listed.</p>
<p>With that, we are ready to create our Kubernetes cluster.</p>
<h2 id="_idParaDest-405"><a id="_idTextAnchor405"/>Creating a Kubernetes cluster</h2>
<p>Once again, we will be using our custom Azure CLI inside the Docker container to create a Kubernetes <a id="_idIndexMarker1601"/>cluster. We will have to make sure that the cluster can access the ACR instance that we just created; this is where our container images reside. So, the command to create a cluster named <code>animals-cluster</code> with two worker nodes looks like this:</p>
<pre class="source-code">
# az aks create \    --resource-group animals-rg \
    --name animals-cluster \
    --node-count 2 \
    --generate-ssh-keys \
    --attach-acr &lt;acr-name&gt;</pre>
<p>This command takes a while, but after a few minutes, we should receive some JSON-formatted output with all the details about the newly created cluster.</p>
<p>To access the cluster, we need <code>kubectl</code>. We can easily get it installed in our Azure CLI container using this command:</p>
<pre class="source-code">
# az aks install-cli</pre> <p>Having installed <code>kubectl</code>, we need the necessary credentials to use the tool to operate <a id="_idIndexMarker1602"/>on our new Kubernetes cluster in Azure. We can get the necessary credentials with this:</p>
<pre class="source-code">
# az aks get-credentials --resource-group animals-rg \    --name animals-cluster</pre>
<p>The command should respond with the following:</p>
<pre class="source-code">
Merged "animals-cluster" as current context in /root/.kube/config</pre> <p>After the success of the preceding command, we can list all the nodes in our cluster, like so:</p>
<pre class="source-code">
# kubectl get nodes</pre> <p>This provides us with the following list:</p>
<pre class="source-code">
NAME STATUS ROLES AGE VERSIONaks-nodepool1-12528297-vmss000000 Ready agent 4m38s v1.25.68
aks-nodepool1-12528297-vmss000001 Ready agent 4m32s v1.25.68</pre>
<p>As expected, we have two worker nodes up and running. The version of Kubernetes that is running on those nodes is <code>v1.25.68</code>.</p>
<p>We are <a id="_idIndexMarker1603"/>now ready to deploy our application to this cluster. In the next section, we are going to learn how we can deploy our application to Kubernetes.</p>
<h2 id="_idParaDest-406"><a id="_idTextAnchor406"/>Deploying our application to the Kubernetes cluster</h2>
<p>To deploy the application, we can use the <code>kubectl </code><code>apply</code> command:</p>
<pre class="source-code">
# kubectl apply -f animals.yaml</pre> <p>The <a id="_idIndexMarker1604"/>output of the preceding command should look similar to this:</p>
<pre class="source-code">
deployment.apps/web createdservice/web created
deployment.apps/db created
service/db created</pre>
<p>Now, we want to test the application. Remember that we created a service of type <code>LoadBalancer</code> for the web component. This service exposes the application to the internet.</p>
<p>This process can take a moment as AKS, among other tasks, needs to assign a public IP address to this service. We can observe this with the following command:</p>
<pre class="source-code">
# kubectl get service web --watch</pre> <p>Please note the <code>--watch</code> parameter in the preceding command. It allows us to monitor the progress of the command over time. Initially, we should see output like this:</p>
<pre class="source-code">
NAME   TYPE           CLUSTER-IP    EXTERNAL-IP  PORT(S)          AGEweb    LoadBalancer   10.0.38.189   &lt;pending&gt;    3000:32127/TCP   5s</pre>
<p>The public IP address is marked as <code>pending</code>. After a few minutes, that should change to this:</p>
<div><div><img alt="Figure 18.8 – The LoadBalancer service for the animals application on Microsoft’s AKS" height="66" src="img/Figure_18.08_B19199.jpg" width="726"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.8 – The LoadBalancer service for the animals application on Microsoft’s AKS</p>
<p>Our application is now ready at the IP address <code>20.76.160.79</code> and port number <code>3000</code>.</p>
<p>Note that the load balancer maps the internal port <code>32127</code> to the external port <code>3000</code>; this <a id="_idIndexMarker1605"/>was not evident to me the first time.</p>
<p>Let’s check it out. In a new browser tab, navigate to <code>http://20.76.160.79:3000/pet</code> and you should see our familiar application:</p>
<div><div><img alt="Figure 18.9 – Our sample application running on AKS" height="638" src="img/Figure_18.09_B19199.jpg" width="1000"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.9 – Our sample application running on AKS</p>
<p>With that, we have successfully deployed our distributed application to Kubernetes hosted in Azure. We did not have to worry about installing or managing Kubernetes; we could concentrate on the application itself.</p>
<p>Note that you can also manage your Azure resource group, your container registry, and your cluster via the Azure portal at <a href="https://portal.azure.com/">https://portal.azure.com/</a>. It will look similar to this:</p>
<div><div><img alt="Figure 18.10 – Microsoft Azure portal showing the animals resource group" height="442" src="img/Figure_18.10_B19199.jpg" width="1099"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.10 – Microsoft Azure portal showing the animals resource group</p>
<p>Please make yourself familiar with the portal and try to drill down into the cluster, its nodes, and deployments.</p>
<p>Now <a id="_idIndexMarker1606"/>that we are done experimenting with the application, we should not forget to delete all resources on Azure to avoid incurring unnecessary costs. We can delete all resources created by deleting the resource group as follows:</p>
<pre class="source-code">
# az group delete --name animal-rg --yes --no-wait</pre> <p>Azure has a few compelling offerings regarding the container workload, and the lock-in is not as evident as it is on AWS since Azure does mainly offer open source orchestration engines, such as Kubernetes, Docker Swarm, DC/OS, and Rancher.</p>
<p>Technically, we remain mobile if we initially run our containerized applications in Azure and later decide to move to another cloud provider. The cost should be limited.</p>
<p class="callout-heading">Note</p>
<p class="callout">It is worth <a id="_idIndexMarker1607"/>noting that when you <a id="_idTextAnchor407"/>delete your resource group, the <strong class="bold">Azure Active Directory</strong> (<strong class="bold">AAD</strong>) service principal used by the AKS cluster is not removed.</p>
<p>Refer to the online help page for details on how to delete the service principal. You can find this information here: <a href="https://learn.microsoft.com/en-us/powershell/module/azuread/remove-azureadserviceprincipal?view=azureadps-2.0">https://learn.microsoft.com/en-us/powershell/module/azuread/remove-azureadserviceprincipal?view=azureadps-2.0</a>.</p>
<p>Next on the list is Google with its GKE service.</p>
<h1 id="_idParaDest-407"><a id="_idTextAnchor408"/>Understanding GKE</h1>
<p>Google is the inventor of Kubernetes and, to this date, the driving force behind it. You would <a id="_idIndexMarker1608"/>therefore expect that Google has a compelling offering around hosted Kubernetes.</p>
<p>Let’s have a peek into it now. To continue, you need to either have an existing account with Google Cloud or create a test account here: <a href="https://console.cloud.google.com/freetrial">https://console.cloud.google.com/freetrial</a>. Proceed with the following steps:</p>
<ol>
<li>In the main menu, select <strong class="bold">Kubernetes Engine</strong>. The first time you do that, it will take a few moments until the Kubernetes engine is initialized.</li>
<li>Next, create a new project and name it <code>massai-mara</code>; this may take a moment.</li>
<li>Once this is ready, we can create a cluster by clicking on <strong class="bold">Create Cluster</strong> in the popup.</li>
<li>On the <code>animals-cluster</code> and select the region closest to you. In the author’s case, this is <code>europe-west1</code>. Then click <strong class="bold">NEXT: NETWORKING</strong>.</li>
<li>Leave all settings at their default values and click <strong class="bold">NEXT: </strong><strong class="bold">ADVANCED SETTINGS</strong>.</li>
<li>Once again, leave all settings at their default values and click <strong class="bold">NEXT: REVIEW </strong><strong class="bold">AND CREATE</strong>.</li>
<li>Review your cluster settings and if everything looks OK, then click on <strong class="bold">CREATE CLUSTER</strong>, as illustrated in the following screenshot:</li>
</ol>
<div><div><img alt="Figure 18.11 – The Review and create view of the GKE cluster creation wizard" height="1028" src="img/Figure_18.11_B19199.jpg" width="876"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.11 – The Review and create view of the GKE cluster creation wizard</p>
<p>It will again <a id="_idIndexMarker1609"/>take a few moments to provision the cluster for us.</p>
<ol>
<li value="8">Once the cluster has been created, we can open Cloud Shell by clicking on the shell icon in the upper-right corner of the view. This is how it should look:</li>
</ol>
<div><div><img alt="Figure 18.12 – The first Kubernetes cluster ready and Cloud Shell open in GKE" height="606" src="img/Figure_18.12_B19199.jpg" width="1120"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.12 – The first Kubernetes cluster ready and Cloud Shell open in GKE</p>
<ol>
<li value="9">We can now <a id="_idIndexMarker1610"/>clone our lab’s GitHub repository to this environment with the following command:<pre class="source-code">
$ git clone https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book.git ~/src</pre></li> <li>Switch to the correct folder where you’ll find the sample solution:<pre class="source-code">
$ cd ~/src/sample-solutions/ch18/gce</pre></li> </ol>
<p>You should now find an <code>animals.yaml</code> file in the current folder, which you can use to deploy the <code>animals</code> application into our Kubernetes cluster.</p>
<ol>
<li value="11">Have a look at the file by running the following command:<pre class="source-code">
$ less animals.yaml</pre></li> </ol>
<p>It has pretty much the same content as the same file we used in the previous chapter. The two differences are these:</p>
<ul>
<li>We use a service of type <code>LoadBalancer</code> (instead of <code>NodePort</code>) to publicly expose the <code>web</code> component. Note we did the same on Azure AKS.</li>
<li>We do not use volumes for the PostgreSQL database since configuring <code>StatefulSet</code> correctly on GKE is a bit more involved than in a product such as Minikube or Docker Desktop. The consequence of this is that our <code>animals</code> application will not persist the state if the <code>db</code> Pod crashes. How to use persistent volumes on GKE lies outside the scope of this book.</li>
</ul>
<p>Also, note <a id="_idIndexMarker1611"/>that we are not using <strong class="bold">Google Container Registry</strong> (<strong class="bold">GCR</strong>) to host the container images but are instead directly pulling them from Docker Hub. It is very easy—and similar to what we learned in the section about AKS—to create such a container registry in Google Cloud.</p>
<ol>
<li value="12">Before we <a id="_idIndexMarker1612"/>can continue, we need to set up <code>gcloud</code> and <code>kubectl</code> credentials. Here’s the code we need to execute:<pre class="source-code">
$ gcloud container clusters \   get-credentials animals-cluster --zone &lt;zone&gt;</pre></li> </ol>
<p>Please replace <code>&lt;zone&gt;</code> with the same zone you selected in <em class="italic">step 5</em> when you created the cluster.</p>
<p>The response of the preceding command should be this:</p>
<pre class="source-code">
Fetching cluster endpoint and auth data.kubeconfig entry generated for animals-cluster.</pre>
<ol>
<li value="13">Let’s have a look at which nodes for the cluster were created by running the following command:<pre class="source-code">
$ kubectl get nodes</pre></li> </ol>
<p>You should see something like this:</p>
<div><div><img alt="Figure 18.13 – Cluster nodes on GCE" height="127" src="img/Figure_18.13_B19199.jpg" width="1134"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.13 – Cluster nodes on GCE</p>
<p>We can see that two nodes were created in our cluster, and the version of Kubernetes deployed is apparently <code>v1.25.8</code>.</p>
<ol>
<li value="14">Having done that, it’s time to deploy the application, so run the following command:<pre class="source-code">
$ kubectl apply -f animals.yaml</pre></li> </ol>
<p>The output should look like this:</p>
<div><div><img alt="Figure 18.14 – Deploying the application on GKE" height="177" src="img/Figure_18.14_B19199.jpg" width="1101"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 18.14 – Deploying the application on GKE</p>
<ol>
<li value="15">Once the <a id="_idIndexMarker1613"/>objects have been created, we can observe the <code>LoadBalancer web</code> service until it is assigned a public IP address, as follows:<pre class="source-code">
$ kubectl get svc/web –watch</pre></li> </ol>
<p>The preceding command yields this output:</p>
<pre class="source-code">
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEweb LoadBalancer 10.57.129.72 &lt;pending&gt; 3000: 32384/TCP 32s
web LoadBalancer 10. 57.129.72 35.195.160.243 3000: 32384/TCP 39s</pre>
<p>The second line in the output is showing the situation while the creation of the load balancer is still pending, and the third one gives the final state. Press <em class="italic">Ctrl</em> + <em class="italic">C</em> to quit the <code>–watch</code> command. Apparently, we got the public IP address <code>35.195.160.243</code> assigned and the port is <code>3000</code>.</p>
<ol>
<li value="16">We can then use this IP address and navigate to <code>http://&lt;IP address&gt;:3000/pet</code>, and we should be greeted by the familiar animal image.</li>
<li>Take a moment and use the various <code>kubectl</code> commands you know to analyze what’s going on in the GKE cluster.</li>
<li>Also, take a moment to use the web portal of GCE and drill down into the details of your cluster. Specifically, have a look into the <strong class="bold">OBSERVABILITY</strong> tab of the cluster.</li>
<li>Once you are <a id="_idIndexMarker1614"/>done playing with the application, delete the cluster and the project in the Google Cloud console to avoid any unnecessary costs.</li>
<li>You can use the <code>gcloud</code> CLI in the Cloud Shell to delete the cluster, as follows:<pre class="source-code">
$ gcloud container clusters delete animals-cluster</pre></li> </ol>
<p>This will take a moment. Alternatively, you can do the same from the web portal.</p>
<ol>
<li value="21">Next list all your projects, like so:<pre class="source-code">
$ gcloud projects list</pre></li> <li>Next, you can use this command to delete the project you created earlier:<pre class="source-code">
$ gcloud projects delete &lt;project-id&gt;</pre></li> </ol>
<p>Here, you should get the correct <code>&lt;project-id&gt;</code> value from the previous <code>list</code> command.</p>
<p>We have created a hosted Kubernetes cluster in GKE. We then used Cloud Shell, provided through the GKE portal, to first clone our lab’s GitHub repository and then the <code>kubectl</code> tool to deploy the <code>animals</code> application into the Kubernetes cluster.</p>
<p>When looking into a hosted Kubernetes solution, GKE is a compelling offering. It makes it very easy to start your projects, and since Google is the main driving force behind Kubernetes, we can <a id="_idIndexMarker1615"/>rest assured that we will always be able to leverage the full functionality of Kubernetes.</p>
<h1 id="_idParaDest-408"><a id="_idTextAnchor409"/>Summary</h1>
<p>In this chapter of the book, you first got an introduction to how to create a fully managed Kubernetes cluster on Amazon EKS using Fargate and how to deploy a simple application on this cluster. Then, you learned how to create a hosted Kubernetes cluster in Azure AKS and run the <code>animals</code> application on it, followed by doing the same for Google’s own hosted Kubernetes offering, GKE.</p>
<p>Are you ready to unlock the secrets of keeping your production environment in peak health? In the next chapter, we will dive into the exciting realm of monitoring and troubleshooting an application running in production. We’ll explore diverse techniques for instrumenting and overseeing both individual services and entire distributed applications operating on a Kubernetes cluster. But it doesn’t stop there—you’ll also learn about creating alerts based on crucial metrics. And when things go awry, we’ll guide you on how to troubleshoot live applications without disrupting the cluster or its nodes. Stay tuned, because this final chapter promises to arm you with the tools you need to confidently maintain your applications at scale.</p>
<h1 id="_idParaDest-409"><a id="_idTextAnchor410"/>Questions</h1>
<p>To assess your knowledge, please answer the following questions:</p>
<ol>
<li>List a few reasons why you would select a hosted Kubernetes offering, such as Amazon EKS, Microsoft’s AKS, or Google’s GKE, to run your applications on Kubernetes.</li>
<li>Name two reasons when using a hosted Kubernetes solution, such as Amazon EKS, Azure AKS, or Google GKE, to consider hosting your container images in the container registry of the respective cloud provider.</li>
</ol>
<h1 id="_idParaDest-410"><a id="_idTextAnchor411"/>Answers</h1>
<p>Here are some sample answers to the chapter questions:</p>
<ol>
<li>Here are a few reasons to consider a hosted Kubernetes offering:<ul><li>You do not want to or do not have the resources to install and manage a Kubernetes cluster</li><li>You want to concentrate on what brings value to your business, which in most cases is the applications that are supposed to run on Kubernetes and not Kubernetes itself</li><li>You prefer a cost model where you pay only for what you need</li><li>The nodes of your Kubernetes cluster are automatically patched and updated</li><li>Upgrading the version of Kubernetes with zero downtime is easy and straightforward</li></ul></li>
<li>The two main reasons to host container images on the cloud provider’s container registry (such as ACR on Microsoft Azure) are these:<ul><li>The images are geographically close to your Kubernetes cluster, and thus the latency and transfer network costs are minimal</li><li>Production or production-like clusters are ideally sealed from the internet, and thus the Kubernetes cluster nodes cannot access Docker Hub directly</li></ul></li>
</ol>
</div>
</div></body></html>