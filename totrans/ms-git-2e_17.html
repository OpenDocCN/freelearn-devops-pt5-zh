<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-320"><a id="_idTextAnchor349" class="pcalibre1 pcalibre calibre6"/>14</h1>
<h1 id="_idParaDest-321" class="calibre5"><a id="_idTextAnchor350" class="pcalibre1 pcalibre calibre6"/>Git Administration</h1>
<p class="calibre3">The previous chapter, <em class="italic">Customizing and Extending Git</em>, among other things, explained how to use Git hooks for automation. The client-side hooks were described in detail, while the server-side hooks were only covered briefly. In this chapter, we will cover server-side hooks comprehensively and discuss client-side hooks’ usage as helpers.</p>
<p class="calibre3">The earlier chapters helped master your work with Git as a developer, as a team member collaborating with others, and as a maintainer. When the book discussed setting up repositories and branch structure, it was from the point of view of a Git user.</p>
<p class="calibre3">This chapter is intended to help those of you who are in a situation of dealing with the administrative side of Git. This includes setting up remote Git repositories and configuring their access. This chapter covers the work required to make Git go smoothly (that is, Git maintenance) and finding and recovering from repository errors. It also describes how to use server-side hooks to implement and enforce a development policy. Additionally, you will find here a short description of the various types of tools that can be used to manage remote repositories, helping you to choose from them.</p>
<p class="calibre3">In this chapter, we will cover the following topics:</p>
<ul class="calibre16">
<li class="calibre15">Server-side hooks – implementing a policy and notifications</li>
<li class="calibre15">How to set up Git on a server</li>
<li class="calibre15">Third-party tools to manage remote repositories</li>
<li class="calibre15">Signed pushes to assert updating refs and enable audits</li>
<li class="calibre15">Reducing the size of hosted repositories with alternates and namespaces</li>
<li class="calibre15">Improving server performance and helping the initial clone</li>
<li class="calibre15">Checking for repository corruption and fixing a repository</li>
<li class="calibre15">Recovering from errors with the help of reflogs and <strong class="source-inline1">git fsck</strong></li>
<li class="calibre15">Git repository maintenance and repacking</li>
<li class="calibre15">Augmenting development workflows with Git</li>
</ul>
<h1 id="_idParaDest-322" class="calibre5"><a id="_idTextAnchor351" class="pcalibre1 pcalibre calibre6"/>Repository maintenance</h1>
<p class="calibre3">Occasionally, you may need<a id="_idIndexMarker1275" class="pcalibre1 pcalibre calibre6"/> to do some cleanup of a repository, usually to make it more compact. Such cleanups are also a very important step after migrating a repository from another version control system.</p>
<h2 id="_idParaDest-323" class="calibre7"><a id="_idTextAnchor352" class="pcalibre1 pcalibre calibre6"/>Automatic housekeeping with git-gc</h2>
<p class="calibre3">Modern Git (or, rather, all but ancient Git) from time<a id="_idIndexMarker1276" class="pcalibre1 pcalibre calibre6"/> to time runs the <code>git gc --auto</code> command<a id="_idIndexMarker1277" class="pcalibre1 pcalibre calibre6"/> in each repository. This command checks whether there are too many loose objects (objects stored as separate files, with one file per object, rather than those stored together in a packfile; objects are almost always created loosely), and if so, then it launches the garbage collection operation. Garbage collection means gathering up all the loose objects and placing them in packfiles, as well as consolidating many small packfiles into one large packfile. Additionally, it packs references into the <code>packed-refs</code> file. Objects that are unreachable even via reflog and are safely old are, by default, packed separately into a cruft pack. Git then deletes loose objects, cruft packs, and packfiles that got repacked (with some safety margin relating to the age of the loose objects files), thus pruning old unreachable objects. There are various configuration knobs in the <code>gc.*</code> namespace to control garbage collection operations.</p>
<p class="calibre3">You can run <code>auto gc</code> manually with <code>git gc --auto</code> or force garbage collection with <code>git gc</code>. The <code>git count-objects</code> command (sometimes with the help of the <code>-v</code> parameter) can be used to check whether there are signs that a repack is needed. You can even run individual steps of the garbage collection individually with <code>git repack</code>, <code>git pack-refs</code>, <code>git prune</code>, and <code>git prune-packed</code>.</p>
<p class="calibre3">By default, Git will try to reuse the results of an earlier packing to reduce CPU time spent on repacking, while still providing good disk space utilization. In some cases, you will want to more aggressively optimize the size of the repository at the cost of it taking more time; this is possible with <code>git gc --aggressive</code> (or by repacking the repository by hand with <code>git repack</code>, run with appropriate parameters). It is recommended to do this after importing from other version control systems, as the mechanism that Git uses for importing (namely, the <code>fast-import</code> stream) is optimized for the speed of the operation, not for the final repository size.</p>
<p class="calibre3">There are issues of maintenance not covered by <code>git gc</code> because of their nature. One of them is pruning (deleting) remote-tracking branches that were deleted in the remote repository. This can be done with <code>git fetch --prune</code> or <code>git remote prune</code>, or on a per-branch basis with <code>git branch --delete --remotes &lt;remote-tracking branch&gt;</code>. This action is left to the user and not run by <code>git gc</code>, as Git simply cannot know whether<a id="_idIndexMarker1278" class="pcalibre1 pcalibre calibre6"/> you have based your own work<a id="_idIndexMarker1279" class="pcalibre1 pcalibre calibre6"/> on the remote-tracking branch that will be pruned.</p>
<h2 id="_idParaDest-324" class="calibre7"><a id="_idTextAnchor353" class="pcalibre1 pcalibre calibre6"/>Periodic maintenance with git-maintenance</h2>
<p class="calibre3">Git commands that add data<a id="_idIndexMarker1280" class="pcalibre1 pcalibre calibre6"/> to the repository, such as <code>git add</code> or <code>git fetch</code>, can trigger automatic garbage collection<a id="_idIndexMarker1281" class="pcalibre1 pcalibre calibre6"/> and perform some repository optimization. However, because they need to provide a responsive user interface, this does not trigger more costly repository optimizations. Those tasks include updating the commit graph data, prefetching from remote repositories (so that <code>git fetch</code> will have fewer objects to download), cleaning up loose objects, and doing an incremental repack. Such optimization tasks often scale with the full size of the repository.</p>
<p class="calibre3">A better solution is to run the maintenance tasks that are expensive in the background, periodically – hourly, daily, or weekly. With modern Git, you can schedule those tasks with the help of the <code>git maintenance</code> command. It will schedule those jobs differently depending on the operating system.</p>
<p class="calibre3">You can configure how often a given task is run. Note that <code>git maintenance run</code>, a process that performs scheduled tasks, puts a lock on the repository’s object database, preventing competing processes from leaving the repository in an unpredicted state. This is not the case for <code>git gc</code>; therefore, if you do periodic maintenance, use <code>git maintenance run --task=gc</code> instead <a id="_idIndexMarker1282" class="pcalibre1 pcalibre calibre6"/>of <a id="_idIndexMarker1283" class="pcalibre1 pcalibre calibre6"/>the <code>git </code><code>gc</code> command.</p>
<h1 id="_idParaDest-325" class="calibre5"><a id="_idTextAnchor354" class="pcalibre1 pcalibre calibre6"/>Data recovery and troubleshooting</h1>
<p class="calibre3">It is almost impossible to never make any mistakes. This applies also to using Git. The knowledge presented in this book, and your experience with using Git, should help to reduce the number of mistakes. Note that Git tries quite hard not to help you avoid losing your work; many mistakes are recoverable. The next subsection will explain how you can try to recover from an error.</p>
<h2 id="_idParaDest-326" class="calibre7"><a id="_idTextAnchor355" class="pcalibre1 pcalibre calibre6"/>Recovering a lost commit</h2>
<p class="calibre3">It may happen that you accidentally<a id="_idIndexMarker1284" class="pcalibre1 pcalibre calibre6"/> lost a commit. Perhaps you force-deleted an incorrect branch that you were going to work on, you rewound the branch to an incorrect place, or you were on an incorrect branch while starting an operation. Assuming something like this happened, is there any way to get your commits back and undo the mistake?</p>
<p class="calibre3">Because Git does not delete objects immediately and keeps them for a while, only deleting them if they are unreachable during the garbage collection phase, the commit you lost will be there; you just need to find it. The garbage collection operation has, as mentioned, its own safety margins; however, if you find that you need to troubleshoot, it is better to turn off automatic garbage collection temporarily with <code>git config gc.auto never</code> (and turning off the <code>gc</code> task if it is scheduled to run periodically with <code>git maintenance</code>, by setting <code>maintenance.gc.enabled</code> to false or by turning maintenance off with <code>git </code><code>maintenance unregister</code>).</p>
<p class="calibre3">Often, the simplest way to find and recover lost commits is to use the <code>git reflog</code> tool. For each branch, and separately for the <code>HEAD</code>, Git silently records (logs) where the tip of the branch was in your local repository, what time it was there, and how it got there. This<a id="_idIndexMarker1285" class="pcalibre1 pcalibre calibre6"/> record is called the <strong class="bold">reflog</strong>. Each time you commit or rewind a branch, the reflog for the branch and the HEAD is updated. Each time you change the branches, the HEAD reflog is updated, and so on.</p>
<p class="calibre3">You can see where the tip of a branch has been at any time by running <code>git reflog</code> or <code>git reflog &lt;branch&gt;</code>. You can also run <code>git log -g</code>, where <code>-g</code> is a short way of saying <code>--walk-reflog</code>; this gives you a normal configurable log output. There is also <code>--grep-reflog=&lt;pattern&gt;</code> to search the reflog:</p>
<pre class="console">
$ git reflog
6c89dee HEAD@{0}: commit: Ping asynchronously
d996b71 HEAD@{1}: rebase -i (finish): returning to refs/heads/ajax
d996b71 HEAD@{2}: rebase -i (continue): Ping asynchronously WIP
89579c9 HEAD@{3}: rebase -i (pick): Use Ajax mode
7c6d322 HEAD@{4}: commit (amend): Simplify index()
e1e6f65 HEAD@{5}: cherry-pick: fast-forward
eea7a7c HEAD@{6}: checkout: moving from ssh-check to ajax
c3e77bf HEAD@{7}: reset: moving to ajax@{1}</pre>
<p class="calibre3">You should remember the <code>&lt;ref&gt;@{&lt;n&gt;}</code> syntax from <a href="B21194_04.xhtml#_idTextAnchor083" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 4</em></a>, <em class="italic">Exploring Project History</em>. With the information from reflogs, you can rewind the branch in question to the version from before the set of operations, or you can start a new branch, starting with any commit in the list.</p>
<p class="calibre3">Let’s assume that your loss<a id="_idIndexMarker1286" class="pcalibre1 pcalibre calibre6"/> was caused by deleting the wrong branch. Because of the way reflogs are implemented (e.g., logs for a branch named <code>foo</code> – that is, for the <code>refs/heads/foo</code> ref – are kept in the <code>.git/logs/refs/heads/foo</code> file), a reflog for a given branch is deleted, together with the branch. You might still have the necessary information in the <code>HEAD</code> reflog, unless you have manipulated the branch tip without involving the working area, but it might not be easy to find it.</p>
<p class="calibre3">In a case where the information is not present in reflogs, one way to find the necessary information to recover lost objects is to use the <code>git fsck</code> utility, which checks your repository for integrity. With the <code>--full</code> option, you can use this command to show all unreferenced objects:</p>
<pre class="console">
$ git fsck --full
Checking object directories: 100% (256/256), done.
Checking objects: 100% (58/58), done.
dangling commit 50b836cb93af955ca99f2ccd4a1cc4014dc01a58
dangling blob 59fc7435baf79180a3835dddc52752f6044bab99
dangling blob fd64375c1f2b17b735f3145446d267822ae3ddd5
[...]</pre>
<p class="calibre3">You can see the SHA1 identifiers of the unreferenced (lost) commits in the lines with the <code>git fsck</code> output for the commits with <code>grep "commit"</code>, extract their SHA1 identifiers with <code>cut -d' ' -f3</code>, and then feed these revisions into <code>git log --stdin --no-walk</code>, as shown here:</p>
<pre class="console">
$ git fsck --full | grep "commit" | cut -d' ' -f3 | git log --stdin --no- walk</pre>
<p class="callout-heading">Tip</p>
<p class="callout">The same technique, but with using <strong class="source-inline1">blob</strong> command, can be used to recover accidentally deleted files – assuming that you have used <strong class="source-inline1">git add</strong> with the version of the file you want to recover.</p>
<h2 id="_idParaDest-327" class="calibre7"><a id="_idTextAnchor356" class="pcalibre1 pcalibre calibre6"/>Troubleshooting Git</h2>
<p class="calibre3">The main purpose of <code>git fsck</code> is to check<a id="_idIndexMarker1288" class="pcalibre1 pcalibre calibre6"/> for repository corruption. Besides having the option to find dangling objects, this command runs sanity checks for each object and tracks the reachability fully. It can find corrupted and missing objects; then, if the corruption was limited to your clone and the correct version can be found in other repositories (in backups and other archives), you can try to recover those objects from an uncorrupted source.</p>
<p class="calibre3">Sometimes, however, the error might be more difficult to recover from. You can try to find a Git expert outside your team, but often, the data in the repository is proprietary. Creating a minimal reproduction of the problem is not always possible. With modern Git, if the problem is structural, you can try to use <code>git fast-export --anonymize</code> to strip the repository from the data, while ensuring that the anonymized repository reproduces the issue. Reproducing some bugs may require referencing particular commits or paths; with modern Git, you can ask for a particular token to be left as-is, or mapped to a new value with a set of <code>--</code><code>anonymize-map</code> options.</p>
<p class="calibre3">If the repository is fine but the problem is with the Git operations, you can try to use various tracking and debugging mechanisms built into Git, or you can try to increase the verbosity of the commands. You can turn on tracing with the appropriate environment variables (which we will show later). The trace output can be written to a standard error stream by setting the value of the appropriate environment variable to <strong class="bold">1</strong>, <strong class="bold">2</strong>, or <strong class="bold">true</strong>. The <strong class="bold">0</strong> or <strong class="bold">false</strong> value disables it. Other integer values between 2 and 10 will be interpreted as open file descriptors to be used for trace output. You can also set such environment variables to the absolute path of the file to write trace messages to.</p>
<p class="calibre3">These tracking-related variables<a id="_idIndexMarker1289" class="pcalibre1 pcalibre calibre6"/> include the following (see the manpage of the <code>git</code> wrapper for the complete list):</p>
<ul class="calibre16">
<li class="calibre15"><strong class="source-inline1">GIT_TRACE</strong>: This enables general trace messages that do not fit into any specific category. This includes the expansion of Git aliases (see <a href="B21194_13_split_000.xhtml#_idTextAnchor320" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 13</em></a>,<em class="italic"> Customizing and Extending Git</em>), built-in command execution, and external command execution (such as pager, editor, or helper).</li>
<li class="calibre15"><strong class="source-inline1">GIT_TRACE_PACKET</strong>: This enables packet-level tracking of the network operations for the “smart” transport protocols. This can help to debug protocol issues or any troubles with the remote server that you set up. To debug and fetch from shallow repositories, there is <strong class="source-inline1">GIT_TRACE_SHALLOW</strong>.</li>
<li class="calibre15"><strong class="source-inline1">GIT_TRACE_CURL</strong> (possibly with <strong class="source-inline1">GIT_TRACE_CURL_NO_DATA</strong>): This enables a <strong class="source-inline1">curl</strong> full trace dump of the HTTP(S) transport protocol, similar to running the <strong class="source-inline1">curl --</strong><strong class="source-inline1">trace-ascii</strong> option.</li>
<li class="calibre15"><strong class="source-inline1">GIT_TRACE_SETUP</strong>: This enables trace messages, printing information about the location of the administrative area of the repository, the working area, the current working directory, and the prefix (the last one is the subdirectory inside the repository directory structure).</li>
<li class="calibre15"><strong class="source-inline1">GIT_TRACE_PERFORMANCE</strong>: This shows the total execution time of each Git command.</li>
</ul>
<p class="calibre3">With modern Git, you can enable more detailed trace messages from the <code>trace2</code> library, either in a simple text-based format meant for human consumption with <code>GIT_TRACE2</code>, or in the JSON-based format meant for machine interpretation with <code>GIT_TRACE2_EVENT</code>. In addition to redirecting the output from a standard error, to a given file descriptor, or to a given file, you can also ask to write output files to a given directory (one file per process) and even ask to open the path as a Unix domain socket. The Trace2 API replacement for <code>GIT_TRACE_PERFORMANCE</code> is <code>GIT_TRACE2_PERF</code>. Instead of environment variables, you can use the <code>trace2.normalTarget</code>, <code>trace2.eventTarget</code>, and <code>trace2.perfTarget</code> configuration variables, respectively.</p>
<p class="calibre3">There is also <code>GIT_CURL_VERBOSE</code> to emit all the messages<a id="_idIndexMarker1290" class="pcalibre1 pcalibre calibre6"/> generated by the curl library for the network operations over HTTP, and <code>GIT_MERGE_VERBOSITY</code> to control the amount of output shown by the recursive merge strategy.</p>
<h1 id="_idParaDest-328" class="calibre5"><a id="_idTextAnchor357" class="pcalibre1 pcalibre calibre6"/>Git on the server</h1>
<p class="calibre3">The previous chapters<a id="_idIndexMarker1291" class="pcalibre1 pcalibre calibre6"/> should have given you enough knowledge to master most of the day-to-day version control tasks in Git. <a href="B21194_06.xhtml#_idTextAnchor140" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 6</em></a>, <em class="italic">Collaborative Development with Git</em>, explained how you can lay out repositories for collaboration. Here, we will explain how to set up Git repositories to enable remote access on a server, allowing you to fetch from and push to them.</p>
<p class="calibre3">The topic of administration of the Git repositories is a large one. There are books written about specific repository management solutions, such as Gitolite, Gerrit, GitHub, or GitLab. Here, you will hopefully find enough information to help you choose a solution or your own.</p>
<p class="calibre3">Let’s start with the tools and mechanisms to manage remote repositories themselves, and then move on to the ways of serving Git repositories (i.e., putting Git on the server).</p>
<h2 id="_idParaDest-329" class="calibre7"><a id="_idTextAnchor358" class="pcalibre1 pcalibre calibre6"/>Server-side hooks</h2>
<p class="calibre3">Hooks that are invoked<a id="_idIndexMarker1292" class="pcalibre1 pcalibre calibre6"/> on the server can be used for server administration; among others, these hooks can control access to the remote repository by performing the authorization step, and they can ensure that the commits entering the repository meet certain minimal criteria. The latter is best done with the additional help of client-side hooks, which were discussed in <a href="B21194_13_split_000.xhtml#_idTextAnchor320" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 13</em></a>, <em class="italic">Customizing and Extending Git</em>. That way, users are not notified that their commits do not pass muster only when they want to publish them. Conversely, client-side hooks implementing validation are easy to skip with the <code>--no-verify</code> option (so server-side validation is necessary), and you need to remember to install them.</p>
<p class="callout-heading">Important note</p>
<p class="callout">Note, however, that server-side hooks are invoked only during the push operation; you need other solutions for access control to the fetch (and clone) operation.</p>
<p class="callout">Hooks are also obviously not run while using “dumb” protocols – there is no Git on the server invoked then.</p>
<p class="calibre3">While writing hooks to implement some Git-enforced policy, you need to remember at what stage the hook in question is run and what information is available then. It is also important to know how the relevant information is passed to the hook; however, you can find the last quite easily in the Git documentation on the <code>githooks</code> man page. The previous chapter included a simple summary of server-side hooks. Here, we will expand a bit on this topic.</p>
<p class="calibre3">All the server-side hooks are invoked by <code>git receive-pack</code>, which is responsible for receiving published commits (which are received in the form of a packfile, hence the name of the command). If a hook, except for a <code>post-*</code> one, exits with the non-zero status, then the operation is interrupted and no further stages are run. The post hooks are run after the operation finishes, so there is nothing to interrupt.</p>
<p class="calibre3">Both the standard output and the standard error output are forwarded to <code>git send-pack</code> at the client end, so the hooks can simply pass messages for the user by printing them (for example, with <code>echo</code>, if the hook was written as a shell script). Note that the client doesn’t disconnect until all the hooks complete their operation, so be careful if you try to do anything that may take a long time, such as automated tests. It is better to have a hook simply start such long operations asynchronously and exit, allowing the client to finish.</p>
<p class="calibre3">You need to remember that, with pre-hooks, you don’t have refs updated yet, and that post-hooks cannot affect the result of an operation. You can use pre-hooks for access control (permission checking),and post-hooks for notification, updating the side data, and logging. Hooks<a id="_idIndexMarker1293" class="pcalibre1 pcalibre calibre6"/> are listed in the order of operation.</p>
<h3 class="calibre9">The pre-receive hook</h3>
<p class="calibre3">The first hook to run is the <code>git push</code> operation will fail before Git invokes this hook.</p>
<p class="calibre3">This hook receives no arguments; all the information is received on the standard input of the script. For each ref to be updated, it receives a line in the following format:</p>
<pre class="console">
&lt;old-SHA1-value&gt; &lt;new-SHA1-value&gt; &lt;full-ref-name&gt;</pre>
<p class="calibre3">Refs that need to be created will have the old SHA1 value of 40 zeros, while refs that need to be deleted will have a new SHA1 value equal to the same. The same convention is used in all the other places, where the hooks receive the old and new state of the updated ref.</p>
<p class="callout-heading">Push options</p>
<p class="callout">You can pass additional data to the server with <strong class="source-inline1">git push --push-option=&lt;option&gt;</strong> or the <strong class="source-inline1">push.pushOption</strong> configuration variable. Both can be given multiple times. This data is then passed to pre-receive and post-receive hooks via environment variables – <strong class="source-inline1">GIT_PUSH_OPTION_COUNT</strong> and <strong class="source-inline1">GIT_PUSH_OPTION_0</strong>, <strong class="source-inline1">GIT_PUSH_OPTION_1</strong>, and so on.</p>
<p class="calibre3">This hook can be used to quickly abort the operation if the update cannot to be accepted – for example, if the received commits do not follow the specified policy or if the signed push (more on this later) is invalid. Note that to use it for access control (i.e., authorization) you need to get the authentication token somehow, be it with the <code>getpwuid</code> command or with an environment variable such as <code>USER</code>. However, this depends on the server setup <a id="_idIndexMarker1296" class="pcalibre1 pcalibre calibre6"/>and the server<a id="_idIndexMarker1297" class="pcalibre1 pcalibre calibre6"/> configuration.</p>
<h3 class="calibre9">The push-to-checkout hook to push to non-bare repositories</h3>
<p class="calibre3">When pushing <a id="_idIndexMarker1298" class="pcalibre1 pcalibre calibre6"/>to the non-bare repositories, if a push operation tries<a id="_idIndexMarker1299" class="pcalibre1 pcalibre calibre6"/> to update the currently checked-out branch, then the <code>receive.denyCurrentBranch</code> configuration variable is set to the <code>updateInstead</code> value (instead of one of the <code>true</code> or <code>refuse</code>, <code>warn</code> or <code>false</code>, or <code>ignore</code> values). This hook receives the SHA1 identifier of the commit that will be the tip of the current branch that is going to be updated.</p>
<p class="calibre3">This mechanism is intended to synchronize working directories when one side is not easily accessible interactively (for example, accessible via interactive <code>ssh</code>), or as a simple deployment scheme. It can be used to deploy to a live website or to run code tests on different operating systems.</p>
<p class="calibre3">If this hook is not present, Git will refuse the update of the ref if either the working tree or the index (the staging area) differs from <code>HEAD</code> – that is, if the status is “not clean.” This hook should be used to override this default behavior.</p>
<p class="calibre3">You can craft this hook to have it make changes to the working tree and the index that are necessary to bring them to the desired state. For example, the hook can simply run <code>git read-tree -u -m HEAD "$1"</code> to switch to the new branch tip (the <code>-u</code> option updates the files in the working tree), while keeping the local changes (the <code>-m</code> option makes it perform a fast-forward merge with two commits/trees). If this hook exits with a nonzero status, then Git will refuse to push to the currently checked-out branch.</p>
<h3 class="calibre9">The update hook</h3>
<p class="calibre3">The next to run is the <code>receive. denyDeletes</code>, <code>receive.denyDeleteCurrent</code>, <code>receive.denyCurrentBranch</code>, and <code>receive.denyNonFastForwards</code>.</p>
<p class="calibre3">Note that exiting with nonzero refuses the ref to be updated; if the push is <em class="italic">atomic</em> (<code>git push --atomic</code>), then refusing any ref to be updated will abandon the whole push operation. With an ordinary push, only the update of a single ref will be refused; the push of other refs will proceed normally.</p>
<p class="calibre3">This hook receives the information about the ref to be updated as its parameters, in order:</p>
<ul class="calibre16">
<li class="calibre15">The full name of the ref that is updated,</li>
<li class="calibre15">The old SHA1 object name stored in the ref before the push operation</li>
<li class="calibre15">The new SHA1 object name to be stored in the ref after the push operation</li>
</ul>
<p class="calibre3">The <code>update.sample</code> hook example can be used to block unannotated tags from entering the repository, and also to allow or deny deleting and modifying tags and deleting and creating branches. All the configurable of this sample hook is done with the appropriate <code>hooks.*</code> configuration variables, rather than being hardcoded. There is also the <code>update-paranoid</code> Perl script in <code>contrib/hooks/</code>, which can be used as an example of how to use this hook for access control. This hook is configured with an external configuration file, where, among other options, you can set up access so that only commits and tags from specified authors are allowed, and authors are required to have correct access permissions.</p>
<p class="calibre3">Many repository management tools, such as Gitolite, set up and use this hook for their work. You need to read the tool documentation if you want, for some reason, to run your own <code>update</code> hook together with the one provided by such a tool, perhaps with the help of some hook management tool (see, for example, a list of such tools on <a href="https://githooks.com/" class="pcalibre1 pcalibre calibre6">https://githooks.com/</a>).</p>
<h3 class="calibre9">The post-receive hook</h3>
<p class="calibre3">Then, after all the refs<a id="_idIndexMarker1302" class="pcalibre1 pcalibre calibre6"/> are updated, the <code>pre-receive</code> one. Only now do all the refs point to the new SHA1s. It can happen that another user has modified the ref after it was updated but before the hook was able to evaluate it. This hook can be used to update other services (for example, notify the continuous integration server), notify users (via an email or a mailing list, a chat channel, or a ticket-tracking system), or log the information about the push for audit (for example, about signed pushes). It supersedes the <code>post-update</code> hook, and should be used instead.</p>
<p class="calibre3">There is no default <code>post-receive</code> hook, but you can find the simple <code>post-receive-email</code> script, and its replacement, <code>git-multimail</code>, in the <code>contrib/hooks/</code> area.</p>
<p class="calibre3">These two example hooks are actually developed separately from Git itself, but for convenience, they are provided with the Git source. <code>git-multimail</code> sends one email summarizing each changed ref, one email for each new commit with the changes –  threaded (as a reply) to the corresponding ref change email, and one announcement email for each new annotated tag. Each of these is separately configurable with respect to the email address used and, to some extent, also with respect to the information included in the emails.</p>
<p class="calibre3">To provide an example of third-party<a id="_idIndexMarker1304" class="pcalibre1 pcalibre calibre6"/> tools, <code>irker</code> includes the script to be used as Git’s <code>post-receive</code> hook to send notifications about the new changes to the appropriate IRC channel, using the irker daemon (set up separately).</p>
<h3 class="calibre9">The post-update hook (a legacy mechanism)</h3>
<p class="calibre3">Then, the <code>post-receive</code> hook is a better solution.</p>
<p class="calibre3">The sample hook runs <code>git update-server-info</code> to prepare a repository for use over the dumb transports(described in the <em class="italic">Legacy (dumb) transports</em> section of <a href="B21194_07.xhtml#_idTextAnchor172" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 7</em></a><em class="italic">, Publishing Your Changes</em>, and in the <em class="italic">Dumb protocols</em> section later in this chapter), by creating and saving some extra information. If the directory with the repository is to be accessible via plain HTTP or other walker-based transport like FTP, you may consider enabling it. However, in modern Git, it is enough<a id="_idIndexMarker1307" class="pcalibre1 pcalibre calibre6"/> to simply set <code>receive.updateServerInfo</code> to <code>true</code> so that a hook<a id="_idIndexMarker1308" class="pcalibre1 pcalibre calibre6"/> is no longer necessary.</p>
<h2 id="_idParaDest-330" class="calibre7"><a id="_idTextAnchor359" class="pcalibre1 pcalibre calibre6"/>Using hooks to implement Git-enforced policy</h2>
<p class="calibre3">The only way to truly enforce a policy<a id="_idIndexMarker1309" class="pcalibre1 pcalibre calibre6"/> is to implement it using<a id="_idIndexMarker1310" class="pcalibre1 pcalibre calibre6"/> server-side hooks, either <code>pre-receive</code> or <code>update</code>; if you want a per-ref decision, you need to use the latter. Client-side hooks can be used to help developers pay attention to the policy, but these can be disabled, skipped, or not enabled.</p>
<h3 class="calibre9">Enforcing the policy with server-side hooks</h3>
<p class="calibre3">One part of the development policy<a id="_idIndexMarker1311" class="pcalibre1 pcalibre calibre6"/> could be requiring<a id="_idIndexMarker1312" class="pcalibre1 pcalibre calibre6"/> that each commit message adheres to a specified template. For example, you could require each non-merge commit message to include the <em class="italic">digital certificate of origin</em> in the form of the <strong class="bold">Signed-off-by:</strong> line, or that each commit refers to the issue tracker ticket by<a id="_idIndexMarker1313" class="pcalibre1 pcalibre calibre6"/> including a string that looks like <strong class="bold">ref: 2387</strong>. The possibilities are endless.</p>
<p class="calibre3">To implement such a hook, you first need to turn the old and new values for a ref (that you got by either reading them line by line from the standard input in <code>pre-receive</code>, or as the <code>update</code> hook parameters) into a list of all the commits that are being pushed. You need to take care of the corner cases – deleting a ref (no commits pushed), creating a new ref, and a possibility of non-fast-forward pushes (where you need to use the merge base as the lower limit of the revision range – for example, with the <code>git merge-base</code> command), pushes to tags, pushes to notes, and other non-branch pushes. The operation of turning a revision range into a list of commits can be done with the <code>git rev-list</code> command, which is a low-level equivalent (plumbing) of the user-facing <code>git log</code> command (<code>porcelain</code>); by default, this command prints out only the SHA1 values of the commits in the specified revision range, one per line, and no other information.</p>
<p class="calibre3">Then, for each revision, you need to grab the commit message and check whether it matches the template specified in the policy. You can use another plumbing command, called <code>git cat-file</code>, and then extract the commit message from this command output by skipping everything before the first blank line. This blank line separates commit metadata in the raw form from the commit body:</p>
<pre class="console">
$ git cat-file commit a7b1a955
tree 171626fc3b628182703c3b3c5da6a8c65b187b52
parent 5d2584867fe4e94ab7d211a206bc0bc3804d37a9
author Alice Developer  1440011825 +0200
committer Alice Developer  1440011825 +0200
Added COPYRIGHT file</pre>
<p class="calibre3">Alternatively, you can use <code>git show -s</code> or <code>git log -1</code>, which are both porcelain commands, instead of <code>git cat-file</code>. However, you would then need to specify the exact output format – for example, <code>git show -s --</code><code>format=%B &lt;SHA1&gt;</code>.</p>
<p class="calibre3">When you have these commit messages, you can then use the regular expression match or another tool on each of the commit messages caught to check whether they matche the policy.</p>
<p class="calibre3">Another part of the policy<a id="_idIndexMarker1314" class="pcalibre1 pcalibre calibre6"/> may be the restrictions on how branches<a id="_idIndexMarker1315" class="pcalibre1 pcalibre calibre6"/> are managed. For example, you may want to prevent the deletion of long-lived development stage branches (see <a href="B21194_08_split_000.xhtml#_idTextAnchor196" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 8</em></a>, <em class="italic">Advanced Branching Techniques</em>), while allowing the deletion of topic branches. To distinguish between them – that is, to find out whether the branch being deleted is a topic branch or not – you can either include a configurable list of branches to manage strictly, or you can assume that topic branches always use the <code>&lt;user&gt;/&lt;topic&gt;</code> naming convention. The latter solution can be enforced by requiring the newly created branches, which should be topic branches only, to match this naming convention.</p>
<p class="calibre3">Conceivably, you could make a policy that topic branches can be fast-forwarded only if they are not merged in, although implementing checks for this policy would be nontrivial.</p>
<p class="calibre3">Usually, only specific people have permission to push to the official repository of a project (holding a so-called commit bit). With server-side<a id="_idIndexMarker1316" class="pcalibre1 pcalibre calibre6"/> hooks, you can configure the repository so that it allows anyone to push, but only to the special mob branch; all the other push access is restricted.</p>
<p class="calibre3">You can also use server-side hooks to require that only annotated tags are allowed in the repository, that tags are signed with a public key that is present in the specified key server (and, thus, can be verified by other developers), and that tags cannot be deleted or updated. If needed, you can restrict signed tags to those coming from the selected (and configured) set of users – for example, enforcing<a id="_idIndexMarker1317" class="pcalibre1 pcalibre calibre6"/> a policy that only one of the maintainers can mark a project<a id="_idIndexMarker1318" class="pcalibre1 pcalibre calibre6"/> for a release (by creating an appropriately named tag – e.g., <code>v0.9</code>).</p>
<h3 class="calibre9">Early notices about policy violations with client-side hooks</h3>
<p class="calibre3">It would be not a good solution<a id="_idIndexMarker1319" class="pcalibre1 pcalibre calibre6"/> to have strict enforcement of development policies and not provide users with a way to help watch and fulfill those policies. Having your work rejected during a push can be frustrating; to fix the issue preventing one from publishing the commit, you would have to edit your local history of the project (that is, rewrite your changes). See <a href="B21194_10_split_000.xhtml#_idTextAnchor247" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 10</em></a>, <em class="italic">Keeping History Clean</em>, for details on how to do it.</p>
<p class="calibre3">The answer to that problem is to provide some client-side hooks that users can install and have Git notify them immediately when they violate the policy, which would make their changes get rejected by the server. The intent is to help correct any problem as fast as possible, usually before committing the changes. These client-side hooks must be distributed somehow, as hooks are not copied when cloning a repository. Various ways to distribute these hooks are described in <a href="B21194_13_split_000.xhtml#_idTextAnchor320" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 13</em></a>, <em class="italic">Customizing and </em><em class="italic">Extending Git</em>.</p>
<p class="calibre3">If there are any limitations on the contents of the changes (for example, some files might be changed only by specified developers), a warning message can be created with <code>pre-commit</code> hook. The <code>prepare-commit-msg</code> hook (and the <code>commit.template</code> configuration variable) can provide the developer with a customized template to be filled in while working on a commit message. You can also make Git check the commit message, just before the commit is recorded, with the <code>commit-msg</code> hook. This hook would find out and inform you whether you have correctly formatted the commit message and whether it includes all the information required by the policy. This hook can also be used instead of or in addition to <code>pre-commit</code>, checking whether you are modifying the files you are not allowed to.</p>
<p class="calibre3">The <code>pre-rebase</code> hook can be used to verify that you don’t try to rewrite history in a manner that would lead to a non-fast-forward push (with <code>receive.</code><code>denyNonFastForwards</code> on the server, forcing a push won’t work anyway).</p>
<p class="calibre3">As a last resort, there is a <code>pre-push</code> hook, which can<a id="_idIndexMarker1320" class="pcalibre1 pcalibre calibre6"/> check for correctness before trying to connect to the remote repository.</p>
<h2 id="_idParaDest-331" class="calibre7"><a id="_idTextAnchor360" class="pcalibre1 pcalibre calibre6"/>Signed pushes</h2>
<p class="calibre3"><a href="B21194_06.xhtml#_idTextAnchor140" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 6</em></a>, <em class="italic">Collaborative Development with Git</em>, includes a description<a id="_idIndexMarker1321" class="pcalibre1 pcalibre calibre6"/> of various mechanisms that a developer can use to ensure the integrity and authenticity of their work – signed tags, signed commits, and signed merges (merging signed tags). All these mechanisms assert that the objects (and the changes they contain) came from the signer.</p>
<p class="calibre3">However, signed tags and commits do not assert that the developer wanted to have a particular revision at the tip of a particular branch. Authentication done by the hosting site cannot be easily audited later, and it requires you to trust the hosting site and its authentication mechanism. Modern Git (version 2.2 or newer) allows you to <strong class="bold">sign pushes</strong> for this purpose.</p>
<p class="calibre3">Signed pushes require the server to set up <code>receive.certNonceSeed</code> and the client to use <code>git push --signed</code>. Handling of signed pushes is done with the server-side hooks. Currently, none of the Git forges such as GitHub, GitLab, Bitbucket, or Gitea support signed<a id="_idIndexMarker1322" class="pcalibre1 pcalibre calibre6"/> pushes; there are tools such as <strong class="bold">gittuf</strong> or <strong class="bold">Kernel.org Transparency Log Monitor</strong> that provide transparency logs<a id="_idIndexMarker1323" class="pcalibre1 pcalibre calibre6"/> for push operations.</p>
<p class="calibre3">The signed push certificate sent by the client is stored in the repository as a blob object and is verified using the <code>pre-receive</code> hook can then examine various <code>GIT_PUSH_CERT_*</code> environment variables (see the <code>git-receive-pack</code> man page for the details) to decide whether to accept or deny a given signed push.</p>
<p class="calibre3">Logging signed pushes for audit can be done with the <code>post-receive</code> hook. You can have this hook send an email notification about the signed push or have it append information about the push to a log file. The <code>pre-receive</code> and <code>post-receive</code> input.</p>
<h2 id="_idParaDest-332" class="calibre7"><a id="_idTextAnchor361" class="pcalibre1 pcalibre calibre6"/>Serving Git repositories</h2>
<p class="calibre3">In <a href="B21194_06.xhtml#_idTextAnchor140" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 6</em></a>, <em class="italic">Collaborative Development with Git</em>, we examined<a id="_idIndexMarker1326" class="pcalibre1 pcalibre calibre6"/> four major protocols used by Git<a id="_idIndexMarker1327" class="pcalibre1 pcalibre calibre6"/> to connect with remote repositories – local, HTTP, <strong class="bold">SSH</strong> (<strong class="bold">Secure</strong> <strong class="bold">Shell</strong>), and Git (the native protocol). This was done from the point of view of a client connecting to the repository, discussing what these protocols are and which one to use if the remote repository offers more than one.</p>
<p class="calibre3">This chapter will offer the administrator’s side of view, explaining how to set up and later move rephrased Git repositories to be served with different transport protocols. Here, we will also examine, for each protocol, what authentication and authorization look like.</p>
<h3 class="calibre9">Local protocol</h3>
<p class="calibre3">This is the most basic protocol, where a client <a id="_idIndexMarker1328" class="pcalibre1 pcalibre calibre6"/>uses a path to the repository or the <code>file://</code> URL to access remotes. You just need to have a shared filesystem, such as an NFS or SMB/CIFS mount, which contains Git repositories to serve. This is a nice option if you already have access to a networked filesystem, as you don’t need to set up any server.</p>
<p class="calibre3">Access to repositories using a file-based transport protocol is controlled by the existing file permissions and network access permissions. You need read permissions to fetch and clone and write permissions to push.</p>
<p class="calibre3">In the latter case, if you want to enable a push, you’d better set up a repository in such a way that pushing does not screw up the permissions. This can be helped by creating a repository with the <code>--shared</code> option to use <code>git init</code> (or <code>git clone</code>). This option allows users belonging to the same group to push into the repository by using the sticky group ID, ensuring that the repositories stay available to all the group members.</p>
<p class="calibre3">The disadvantage of this method is that shared access to a networked filesystem is, generally, more difficult to set up and reach safely from multiple remote locations than basic network access and setting up an appropriate server. Mounting the remote disk over the internet can be difficult and slow.</p>
<p class="calibre3">This protocol does not protect the repository against accidental damage. Every user has full access to the repository’s internal files, and there is nothing preventing them from accidentally corrupting<a id="_idIndexMarker1329" class="pcalibre1 pcalibre calibre6"/> the repository.</p>
<h3 class="calibre9">The SSH protocol</h3>
<p class="calibre3">SSH is a common transport<a id="_idIndexMarker1330" class="pcalibre1 pcalibre calibre6"/> protocol (commonly used by Linux users) to self-host Git repositories. SSH access to servers is often already set up in many cases as a way to safely log in to the remote machine; if not, it is generally quite easy to set up and use. SSH is an authenticated and encrypted network protocol.</p>
<p class="calibre3">Conversely, you can’t serve anonymous access to Git repositories over SSH. People must have at least limited access to your machine over SSH; this protocol does not allow anonymous read-only access to published repositories.</p>
<p class="calibre3">Generally, there are two ways to give access to Git repositories over SSH. The first is to have a separate account on the server for each client trying to access the repository (although such an account can be limited and does not need full shell access, you can, in this case, use <code>git-shell</code> as a login shell for Git-specific accounts). This can be used both with ordinary SSH access, where you provide the password, and with a public-key login. In a one-account-per-user case, the access control situation is similar to the local protocol – namely, access is controlled with filesystem permissions.</p>
<p class="calibre3">A second method is to create a single shell account, which is often the <code>git</code> user, specifically to access Git repositories and use public-key login to authenticate users. Each user who will have access to the repositories would then need to send their SSH public key to the administrator, who would then add this key to the list of authorized keys. The actual user is identified by the key they use to connect to the server.</p>
<p class="calibre3">Another alternative is to have the SSH server authenticated from an LDAP server or some other centralized authentication scheme (often to implement single sign-on). As long as the client<a id="_idIndexMarker1331" class="pcalibre1 pcalibre calibre6"/> can get (limited) shell access, any SSH authentication mechanism can be used.</p>
<h3 class="calibre9">Anonymous Git protocol</h3>
<p class="calibre3">Next is the Git protocol. This is served<a id="_idIndexMarker1332" class="pcalibre1 pcalibre calibre6"/> by a special and really simple TCP daemon, which listens on a dedicated port (by default, port <code>9418</code>). This is (or was) a common choice for fast, anonymous, and unauthenticated read-only access to Git repositories.</p>
<p class="calibre3">The Git protocol server, <code>git daemon</code>, is relatively easy to set up. Basically, you need to run this command, usually in a daemonized manner. How to run the daemon (the server) depends on the operating system you use. It can be a <code>systemd</code> unit file, an Upstart script, or a <code>sysvinit</code> script. A common solution is to use <code>inetd</code> or <code>xinetd</code>.</p>
<p class="calibre3">You can remap all the repository requests relative to the given path (a project root for the Git repositories) with <code>--base-path=&lt;directory&gt;</code>. There is also support for virtual hosting; see the <code>git-daemon</code> documentation for more details. By default, <code>git daemon</code> will export only the repositories that have the <code>git-daemon-export-ok</code> file inside <code>gitdir</code>, unless the <code>--export-all</code> option is used. Usually, you would also want to turn on <code>--reuseaddr</code>, allowing the server to restart without waiting for the connection to time out.</p>
<p class="calibre3">The downside of the Git protocol is the lack of authentication and the obscure port that it runs on (which may require you to punch a hole in the firewall). The lack of authentication is because, by default, it is used only for read access – that is, for fetching and cloning repositories. Generally, it is paired with either SSH (always authenticated and never anonymous) or HTTPS for pushing.</p>
<p class="calibre3">You can configure it to allow for a push (by starting the <code>receive-pack</code> service with the <code>--enable=&lt;service&gt;</code> command-line option or, on a per-repository basis, by setting the <code>daemon.receivePack</code> configuration to <code>true</code>), but it is generally not recommended. The only information available to hooks to implement access control is the client address, unless you require all the pushes to be signed. You can run external commands in an access hook, but this would not provide much more information about the client.</p>
<p class="callout-heading">Tip</p>
<p class="callout">One service you might consider enabling is <strong class="source-inline1">upload-archive</strong>, which serves <strong class="source-inline1">git </strong><strong class="source-inline1">archive --remote</strong>.</p>
<p class="calibre3">This lack of authentication<a id="_idIndexMarker1333" class="pcalibre1 pcalibre calibre6"/> means that not only does the Git server not know who accesses the repositories, but also that the client must trust the network to not spoof the address while accessing the server. This transportation is not encrypted.</p>
<h3 class="calibre9">The smart HTTP(S) protocol</h3>
<p class="calibre3">Setting up the so-called “smart” HTTP(S) protocol<a id="_idIndexMarker1334" class="pcalibre1 pcalibre calibre6"/> consists basically of enabling<a id="_idIndexMarker1335" class="pcalibre1 pcalibre calibre6"/> a server script that would invoke <code>git receive-pack</code> and <code>git upload-pack</code> on the server. Git provides a CGI script named <code>git-http-backend</code> for this task. This CGI script can detect whether the client understands the smart HTTP protocol; if not, it will fall back on the “dumb” behavior (a backward compatibility feature).</p>
<p class="calibre3">To use this protocol, you need a CGI server – for example, Apache (with this server ,       you would also need the <code>mod_cgi</code> module or its equivalent, and the <code>mod_env</code> and <code>mod_alias</code> modules). The parameters are passed using environment variables (hence the need for <code>mod_env</code> when using Apache) – <code>GIT_PROJECT_ROOT</code> to specify where repositories are and an optional <code>GIT_HTTP_EXPORT_ALL</code> if you want to have all the repositories exported, not only those with the <code>git-daemon-export-ok</code> file in them.</p>
<p class="calibre3">The authentication is done by the web server. In particular, you can set it up to allow unauthenticated anonymous read-only access, while requiring authentication for a push. Utilizing HTTPS gives encryption and server authentication, like with the SSH protocol. The URL for fetching and pushing is the same when using HTTP(S); you can also configure it so that the web interface to browse Git repositories uses the same URL for fetching.</p>
<p class="callout-heading">Note</p>
<p class="callout">The documentation of <strong class="source-inline1">git-http-backend</strong> includes a setup for Apache for different situations, including unauthenticated read and authenticated write. The setup presented there is a bit involved because initial ref advertisements use the query string, while the <strong class="source-inline1">receive-pack</strong> service invocation uses path info.</p>
<p class="callout">Conversely, requiring authentication with any valid account for reads and writes, and leaving the restriction of writes to the server-side hook, is a simpler and often acceptable solution.</p>
<p class="calibre3">If you try to push to the repository that requires authentication, the server can prompt for credentials. Because the HTTP protocol is stateless and involves more than one connection sometimes, it is useful to utilize credential helpers (see <a href="B21194_13_split_000.xhtml#_idTextAnchor320" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 13</em></a>,<em class="italic"> Customizing and Extending Git</em>) to avoid either having to give the password more than once for a single operation, or having<a id="_idIndexMarker1336" class="pcalibre1 pcalibre calibre6"/> to save the password somewhere on the disk (for example, in the remote URL).</p>
<p class="callout-heading">Gitolite for smart HTTPS access control</p>
<p class="callout">While Gitolite (<a href="https://gitolite.com/" class="pcalibre1 pcalibre calibre6">https://gitolite.com/</a>) provides an access<a id="_idIndexMarker1337" class="pcalibre1 pcalibre calibre6"/> control layer on top of Git<a id="_idIndexMarker1338" class="pcalibre1 pcalibre calibre6"/> for access over SSH, it can be configured to perform authorization for smart HTTP mode.</p>
<h3 class="calibre9">Dumb protocols</h3>
<p class="calibre3">If you cannot run Git<a id="_idIndexMarker1339" class="pcalibre1 pcalibre calibre6"/> on the server, you can still use the dumb protocol, which does not require it. The dumb HTTP(S) protocol expects the Git repository to be served like normal static files from the web server. However, to be able to use this kind of protocol, Git requires the extra <code>objects/info/packs</code> and <code>info/refs</code> files to be present on the server and kept up to date with <code>git update-server-info</code>. This command is usually run on a push via one of the earlier mentioned smart protocols (the default <code>post-update</code> hook does that, and so does <code>git-receive-pack</code> if <code>receive.updateServerInfo</code> is set to <code>true</code>).</p>
<p class="calibre3">It is possible to push with the dumb protocol, but this requires a setup that allows you to update files using a specified transport; for the dumb HTTP(S) transport protocol, this means configuring WebDAV.</p>
<p class="calibre3">Authentication, in this case, is done by the web server for static files. Obviously, for this kind of transport, Git’s server-side hooks are not invoked, and thus they cannot be used to further restrict access.</p>
<p class="callout-heading">Historical note</p>
<p class="callout">Note that, for modern Git, the dumb transport is implemented using the curl family of remote helpers, which may be not installed by default.</p>
<p class="calibre3">This transport works (for fetching) by downloading requested refs (as plain files), examining where to find files containing the referenced commit objects (hence the need for server information files, at least for objects in packfiles), getting them, and then walking through the chain of revisions, examining each object needed, and downloading new files if the object is not present yet in the local repository. This walker method can be horrendously inefficient if the repository is not packed well with respect to the requested revision range. It requires a large number of connections and always downloads the whole pack, even if only one object from it is needed.</p>
<p class="calibre3">With smart protocols, Git on the client side and Git on the server side negotiate between themselves which objects need to be sent (a want/have negotiation). Git then creates a customized packfile, utilizing the knowledge of what objects are already present on the other side, and usually includes only deltas – that is, the difference from what the other side has (a thin packfile). The other<a id="_idIndexMarker1340" class="pcalibre1 pcalibre calibre6"/> side rewrites the received packfile to be self-contained.</p>
<h3 class="calibre9">Remote helpers</h3>
<p class="calibre3">Git allows us to create support<a id="_idIndexMarker1341" class="pcalibre1 pcalibre calibre6"/> for new transport protocols by writing remote helper programs. This mechanism can be also used to support foreign repositories. Git interacts with a repository requiring a remote helper by spawning the helper as an independent child process, communicating with this process through its standard input and output with a set of commands. The use of remote transport helpers is described in <a href="B21194_06.xhtml#_idTextAnchor140" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 6</em></a>,<em class="italic"> Collaborative Development </em><em class="italic">with Git</em>.</p>
<p class="calibre3">You can find third-party remote helpers to add support to the new ways of accessing repositories – for example, there is <code>git-remote-dropbox</code> to use Dropbox to store the remote Git repository. Note, however, that remote helpers are (possibly yet) limited in features compared<a id="_idIndexMarker1342" class="pcalibre1 pcalibre calibre6"/> to built-in transport support.</p>
<h2 id="_idParaDest-333" class="calibre7"><a id="_idTextAnchor362" class="pcalibre1 pcalibre calibre6"/>Tools to manage Git repositories</h2>
<p class="calibre3">Nowadays, there is no need to write a Git repository <a id="_idIndexMarker1343" class="pcalibre1 pcalibre calibre6"/>management solution yourself. There is a wide range of various third-party solutions that you can use. It is impossible to list them all, and even giving recommendations is risky. The Git ecosystem is actively developed; which tool is the best could have changed since the time of writing.</p>
<p class="calibre3">I’d like to focus here just on the types of tools for administrators, just as I did for GUIs in <a href="B21194_13_split_000.xhtml#_idTextAnchor320" class="pcalibre1 pcalibre calibre6"><em class="italic">Chapter 13</em></a>, <em class="italic">Customizing and </em><em class="italic">Extending Git</em>.</p>
<p class="calibre3">First, there are <code>update-paranoid</code> script in the <code>contrib/</code> area). These tools focus on access control, usually the authorization part, making it easy to add repositories and manage their permissions. An example of such a tool is <em class="italic">Gitolite</em>.</p>
<p class="calibre3">They often support some mechanism to add your own additional access constraints.</p>
<p class="calibre3">Then, there are <code>git log</code> and <code>git show</code> commands, and a view with a list of files in the repository. An example of such tools is the <code>gitweb</code> script in Perl that is distributed with Git; another is <code>cgit</code>, used by <a href="http://git.kernel.org" class="pcalibre1 pcalibre calibre6">git.kernel.org</a>.</p>
<p class="calibre3">Also useful are the <strong class="bold">code review</strong> (<strong class="bold">code collaboration</strong>) tools. These make it possible for developers in a team<a id="_idIndexMarker1345" class="pcalibre1 pcalibre calibre6"/> to review each other’s proposed changes using a web interface. These tools often allow the creation of new projects and the handling of access management. An example of such a tool is Gerrit Code Review.</p>
<p class="calibre3">Finally, there are <strong class="bold">Git hosting</strong> solutions, also called <strong class="bold">software forges</strong>, usually with a<a id="_idIndexMarker1346" class="pcalibre1 pcalibre calibre6"/> web interface<a id="_idIndexMarker1347" class="pcalibre1 pcalibre calibre6"/> for the administrative side of managing repositories, allowing us to add users, create repositories, manage their access, and often work from the web browser on Git repositories. Examples of such tools are GitLab and Gitea. There are also similar <strong class="bold">source code management</strong> systems, which<a id="_idIndexMarker1348" class="pcalibre1 pcalibre calibre6"/> provide (among other web-based interfaces) repository hosting services, together with the features to collaborate and manage development. One example of such a system is Kallithea; however, nowadays, many software forges include some source<a id="_idIndexMarker1349" class="pcalibre1 pcalibre calibre6"/> code management features, such as issue tracking, and <strong class="bold">CI/CD</strong> (<strong class="bold">Continuous Integration/Continuous </strong><strong class="bold">Delivery</strong>) pipelines.</p>
<p class="calibre3">Of course, you don’t need to self-host your code. There is a plethora of third-party hosted options – GitHub, Bitbucket, and so on. There are even hosted solutions using open source hosting management<a id="_idIndexMarker1350" class="pcalibre1 pcalibre calibre6"/> tools, such as GitLab and Codeberg.</p>
<h2 id="_idParaDest-334" class="calibre7"><a id="_idTextAnchor363" class="pcalibre1 pcalibre calibre6"/>Tips and tricks to host repositories</h2>
<p class="calibre3">If you want to self-host Git <a id="_idIndexMarker1351" class="pcalibre1 pcalibre calibre6"/>repositories, there are a few things that may help you with server performance and user satisfaction.</p>
<h3 class="calibre9">Reducing the size taken by repositories</h3>
<p class="calibre3">If you are hosting many forks (clones) of the same repository, you might want to reduce disk usage by somehow sharing common objects. One solution is to use <code>git clone --reference</code>) while creating a fork. In this case, the derived repository would look to its parent object storage if the object is not found on its own.</p>
<p class="calibre3">There are, however, two problems with this approach. First, you need to ensure that the object the borrowing repository relies on does not vanish from the repository set as the alternate object storage (the repository you borrow from). This can be done, for example, by linking the borrowing repository refs in the repository lending the objects, (e.g., in the <code>refs/borrowed/</code> namespace). Second is that the objects entering the borrowing repository are not automatically de-duplicated; you need to run <code>git repack -a -d -l</code>, which internally passes the <code>--local</code> option to <code>git pack-objects</code>.</p>
<p class="calibre3">An alternate solution would be to keep every fork together in a single repository and use <code>git-http-backend</code> manpage includes an example configuration to serve multiple repositories from different namespaces in a single repository. Gitolite also has some support for namespaces in the form of logical and backing repositories and <code>option namespace.pattern</code>, although not every feature works for logical repositories.</p>
<p class="calibre3">Storing multiple repositories as the namespace of a single repository avoids storing duplicated copies of the same objects. It automatically prevents duplication between new objects without the need for ongoing maintenance, as opposed to the alternate solution. Conversely, security is weaker; you need to treat anyone with access to the single namespace, which is within the repository, as if they had access to all the other namespaces (although this might not be a problem for your case).</p>
<h3 class="calibre9">Speeding up smart protocols with pack bitmaps</h3>
<p class="calibre3">Another issue that you can<a id="_idIndexMarker1353" class="pcalibre1 pcalibre calibre6"/> stumble upon while self-hosting repositories<a id="_idIndexMarker1354" class="pcalibre1 pcalibre calibre6"/> is the performance of smart protocols. For the clients of your server, it is important that operations finish quickly; as an administrator, you would not want to generate a high CPU load on the server due to serving Git repositories.</p>
<p class="calibre3">One feature, ported from JGit, should significantly improve the performance of the counting objects phase, while serving objects from a repository that uses it. This<a id="_idIndexMarker1355" class="pcalibre1 pcalibre calibre6"/> feature is a <strong class="bold">bitmap-index file</strong>, available since Git 2.0.</p>
<p class="callout-heading">The bitmap-index file</p>
<p class="callout">The major function<a id="_idIndexMarker1356" class="pcalibre1 pcalibre calibre6"/> of the <strong class="source-inline1">bitmap-index</strong> file is providing for a selected subset of commits, including the most recent ones, bit vectors (bitmaps) that store reachability information for a set of objects in a packfile, or in a multi-pack index. In each bit vector, the value of 1 at index <strong class="source-inline1">i</strong> means that the <strong class="source-inline1">i-th</strong> object (in the order defined by a packfile or a multi-pack index file) is reachable from the commit that the given bit vector belongs to.</p>
<p class="calibre3">This file is stored alongside packfiles and their indexes. It can be generated manually by running <code>git repack -A -d --write-bitmap-index</code>, or it can be generated automatically together with the packfile by setting the <code>repack.writeBitmaps</code> configuration variable to <code>true</code>. The disadvantage of this solution is that bitmaps take additional disk space, and the initial repack requires extra time to create bitmap-index. With modern Git, thanks to the multi-pack index, you no longer need to repack everything into a single packfile to be able to use the bitmap file. This feature also makes it faster to update<a id="_idIndexMarker1357" class="pcalibre1 pcalibre calibre6"/> the bitmap.</p>
<p class="calibre3">Nowadays, this feature is turned on by default for bare repositories.</p>
<h3 class="calibre9">Solving the large non-resumable initial clone problem</h3>
<p class="calibre3">Repositories with a large code base<a id="_idIndexMarker1358" class="pcalibre1 pcalibre calibre6"/> and a long history can get quite<a id="_idIndexMarker1359" class="pcalibre1 pcalibre calibre6"/> large. The problem is that the initial clone, where you need to get everything in a possibly large repository, is an all-or-nothing operation, at least for modern (safe and effective) smart transfer protocols – SSH, <code>git://</code>, and smart HTTP(S). This might be a problem if a network connection is not very reliable. There is no support for a resumable clone, and it unfortunately looks like it is a fundamentally hard problem to solve for Git developers. This does not mean, however, that you, as a hosting administrator, can do nothing to help users get this initial clone.</p>
<p class="calibre3">One solution is to create, with the <code>git bundle</code> command, a static file that can be used for the initial clone, or as a reference repository for the initial clone (the latter can be done with the <code>git clone --reference=&lt;bundle&gt; --dissociate</code> command after downloading the bundle). This bundle file can be distributed using any transport – in particular, one that can be resumed if interrupted, be it HTTP(S), FTP, rsync, or BitTorrent. The convention that people use, besides explaining how to get such a bundle in the developer documentation, is to use the same URL as that used for the repository but with the <code>.bundle</code> extension (instead of an empty extension or a <code>.git</code> suffix). If the bundle is available via the HTTP(S) or SSH protocols, it can be used without explicitly downloading it first with <code>git clone --</code><code>bundle-uri=&lt;bundle uri&gt;</code>.</p>
<p class="calibre3">There is also the <strong class="bold">bundle-uri</strong> capability of Git, where the server<a id="_idIndexMarker1360" class="pcalibre1 pcalibre calibre6"/> suggests where you can download such a bundle from the client, which in turn can use the bundle to speed up the initial clone. At the time of <a href="https://github.com/git-ecosystem/git-bundle-server" class="pcalibre1 pcalibre calibre6">writing, no software forge supports this feature, </a>but there is the <strong class="bold">git bundle-server</strong> (<a href="https://github.com/git-ecosystem/git-bundle-server" class="pcalibre1 pcalibre calibre6">https://github.com/git-ecosystem/git-bundle-server</a>) web server<a id="_idIndexMarker1361" class="pcalibre1 pcalibre calibre6"/> and management interface<a id="_idIndexMarker1362" class="pcalibre1 pcalibre calibre6"/> for use with this feature.</p>
<p class="calibre3">There are also more esoteric approaches to solving the problem of the initial clone cost, such as a step-by-step deepening of a shallow clone (or perhaps just using a shallow clone with <code>git clone --depth</code> is all that’s needed), starting with a partial clone, or using approaches<a id="_idIndexMarker1363" class="pcalibre1 pcalibre calibre6"/> such as GitTorrent.</p>
<h1 id="_idParaDest-335" class="calibre5"><a id="_idTextAnchor364" class="pcalibre1 pcalibre calibre6"/>Augmenting development workflows</h1>
<p class="calibre3">Handling version control<a id="_idIndexMarker1364" class="pcalibre1 pcalibre calibre6"/> is only a part of the development workflow. There is also work management, code review and audit, running automated tests, and generating builds.</p>
<p class="calibre3">Many of these steps can be aided by specialized tools. Many of them offer Git integration. For example, code review can be managed using Gerrit, requiring that each change passes a review before being made public. Another example is setting up development environments so that pushing changes to the public repository can automatically close tickets in the issue tracker, based on the patterns in the commit messages. This can be done with server-side hooks or with the hosting service’s Webhooks.</p>
<p class="calibre3">A repository can serve as a gateway, running automated tests (for example, with the help of Jenkins’ or Hudson’s continuous integration service) and deploying changes to ensure quality environments only after passing all of these tests. Another repository can be configured to trigger builds for various supported systems. Many tools and services support push-to-deploy mechanisms (for example, Heroku or Google’s App Engine).</p>
<p class="calibre3">Git can automatically notify users and developers about published changes. This can be done via email, a mailing list, an IRC/Discord/Slack channel, or a web-based dashboard application. The possibilities<a id="_idIndexMarker1365" class="pcalibre1 pcalibre calibre6"/> are plentiful; you only need to find them.</p>
<h2 id="_idParaDest-336" class="calibre7"><a id="_idTextAnchor365" class="pcalibre1 pcalibre calibre6"/>Defining development workflows in the repository</h2>
<p class="calibre3">Many software forges<a id="_idIndexMarker1366" class="pcalibre1 pcalibre calibre6"/> allow you to automate, customize, and execute software development workflows right from the repository. Those solutions, such as <em class="italic">GitHub Actions</em> and <em class="italic">GitLab CI/CD</em>, let you run various workflows (for example, to run tests or to deploy an application) when other events happen in your repository at the software forge. Those workflows are run using runners, either virtual machines or containers. They are usually defined by a YAML file checked into your repository.</p>
<p class="calibre3">While the specific dialect of the YAML<a id="_idIndexMarker1367" class="pcalibre1 pcalibre calibre6"/> markup language, the pathname of the file, and the available pre-defined actions differ from service to service, they are similar enough that you should be able to migrate from one solution to the other.</p>
<h2 id="_idParaDest-337" class="calibre7"><a id="_idTextAnchor366" class="pcalibre1 pcalibre calibre6"/>GitOps – using Git for operational procedures</h2>
<p class="calibre3">The natural extension of defining<a id="_idIndexMarker1368" class="pcalibre1 pcalibre calibre6"/> software development workflows in the Git repository is to use Git to automatically manage deployment infrastructure, especially for cloud-native applications. This is called <strong class="bold">GitOps</strong> – an operational framework that uses<a id="_idIndexMarker1369" class="pcalibre1 pcalibre calibre6"/> the Git repository to store <strong class="bold">infrastructure as code</strong> (<strong class="bold">IoC</strong>) files and application configuration files. This data can be stored in the same repository as the application code, or in a separate repository.</p>
<p class="calibre3">GitOps ensures that the infrastructure (including the development, testing, and deployment environments) is immediately reproducible, based on the state of the Git repository. This provides version control for operations should a rollback be needed.</p>
<p class="calibre3">Often, the infrastructure configuration is defined declaratively, and a specialized software agent (such as Argo CD, Flux, or Gitkube) running in the cloud pulls from the Git repository at regular intervals and checks the configuration against the live state, adjusting the state as necessary.</p>
<h1 id="_idParaDest-338" class="calibre5"><a id="_idTextAnchor367" class="pcalibre1 pcalibre calibre6"/>Summary</h1>
<p class="calibre3">This chapter covered various issues related to the administrative side of working with Git. You learned the basics of maintenance, data recovery, and repository troubleshooting. You also learned how to set up Git on a server, how to use server-side hooks, and how to manage remote repositories. The chapter covered tips and tricks for a better remote performance. It described how you can use Git (with the help of third-party tools) to augment development workflows. The information in this chapter should help you to choose a Git repository management solution, or even write your own.</p>
<p class="calibre3">The next chapter will include a set of recommendations and best practices, both specific to Git and those that are version control-agnostic. A policy based on these suggestions can be enforced and encouraged with the help of the tools explored in this chapter.</p>
<h1 id="_idParaDest-339" class="calibre5"><a id="_idTextAnchor368" class="pcalibre1 pcalibre calibre6"/>Questions</h1>
<p class="calibre3">Answer the following questions to test your knowledge of this chapter:</p>
<ol class="calibre14">
<li class="calibre15">How do you set up automatic repository maintenance to ensure that Git operations will not slow down?</li>
<li class="calibre15">How you can try to recover a lost commit?</li>
<li class="calibre15">How do you find out why some Git commands started to perform badly and took too much time to execute?</li>
<li class="calibre15">How you can ensure that development follows a given defined policy?</li>
<li class="calibre15">What is the simplest solution to sharing the repository privately, where all developers work on a single computer (on a single machine)?</li>
</ol>
<h1 id="_idParaDest-340" class="calibre5"><a id="_idTextAnchor369" class="pcalibre1 pcalibre calibre6"/>Answers</h1>
<p class="calibre3">Here are the answers to the questions given above:</p>
<ol class="calibre14">
<li class="calibre15">Use the <strong class="source-inline1">git </strong><strong class="source-inline1">maintenance</strong> command.</li>
<li class="calibre15">First, check the branch and HEAD reflogs if the lost committing question is not readily available from there. If this fails, you can try to browse through unreachable commits with <strong class="source-inline1">git fsck</strong>.</li>
<li class="calibre15">You can use the “<strong class="source-inline1">Git trace</strong>” mechanism – for example, with the <strong class="source-inline1">GIT_TRACE2_PERF</strong> or <strong class="source-inline1">GIT_TRACE_PERFORMANCE</strong> environment variables.</li>
<li class="calibre15">Use your software forge features, if possible (for example, to protect a branch against changes or deletion), or use server-side hooks. Enforcing the policy can be helped, but not ensured, with client-side hooks.</li>
<li class="calibre15">Simply create the bare repository with <strong class="source-inline1">git init --bare --shared</strong>, while ensuring that all developers that need access to it have appropriate filesystem permissions. If necessary, push to that repository.</li>
</ol>
<h1 id="_idParaDest-341" class="calibre5"><a id="_idTextAnchor370" class="pcalibre1 pcalibre calibre6"/>Further reading</h1>
<p class="calibre3">To learn more about the topics that were covered in this chapter, take a look at the following resources:</p>
<ul class="calibre16">
<li class="calibre15">Scott Chacon, Ben Straub: <em class="italic">Pro Git, 2nd Edition</em>, Apress (2014) <em class="italic">Chapter 4</em>, <em class="italic">Git on the </em><em class="italic">Server</em> <a href="https://git-scm.com/book/en/v2/Git-on-the-Server-The-Protocols" class="pcalibre1 pcalibre calibre6">https://git-scm.com/book/en/v2/Git-on-the-Server-The-Protocols</a></li>
<li class="calibre15">Scott Chacon: <em class="italic">Git Tips 2: New Stuff in Git</em> (2024) <a href="https://blog.gitbutler.com/git-tips-2-new-stuff-in-git/#git-maintenance" class="pcalibre1 pcalibre calibre6">https://blog.gitbutler.com/git-tips-2-new-stuff-in-git/#git-maintenance</a></li>
<li class="calibre15">Konstantin Ryabitsev: <em class="italic">Signed git pushes</em> (2020) <a href="https://people.kernel.org/monsieuricon/signed-git-pushes" class="pcalibre1 pcalibre calibre6">https://people.kernel.org/monsieuricon/signed-git-pushes</a></li>
<li class="calibre15">Vicent Martí: <em class="italic">Counting Objects</em> (2015) <a href="https://github.blog/2015-09-22-counting-objects/" class="pcalibre1 pcalibre calibre6">https://github.blog/2015-09-22-counting-objects/</a></li>
<li class="calibre15">Sitaram Chamarty: <em class="italic">Gitolite Essentials</em>, Packt (2014) <a href="https://subscription.packtpub.com/book/programming/9781783282371" class="pcalibre1 pcalibre calibre6">https://subscription.packtpub.com/book/programming/9781783282371</a></li>
<li class="calibre15">Derrick Stolee: <em class="italic">Exploring new frontiers for Git push performance</em> (2019) <a href="https://devblogs.microsoft.com/devops/exploring-new-frontiers-for-git-push-performance/" class="pcalibre1 pcalibre calibre6">https://devblogs.microsoft.com/devops/exploring-new-frontiers-for-git-push-performance/</a></li>
<li class="calibre15">Taylor Blau: <em class="italic">Scaling monorepo maintenance</em> (2021) <a href="https://github.blog/2021-04-29-scaling-monorepo-maintenance/" class="pcalibre1 pcalibre calibre6">https://github.blog/2021-04-29-scaling-monorepo-maintenance/</a></li>
</ul>
</div>
</body></html>