<html><head></head><body><div class="chapter" title="Chapter&#xA0;5.&#xA0;Ever-Ready to Deploy Using Continuous Delivery"><div class="titlepage"><div><div><h1 class="title"><a id="ch05"/>Chapter 5. Ever-Ready to Deploy Using Continuous Delivery</h1></div></div></div><p>Thanks to the Continuous Integration setup we examined in the previous chapter, we now have a way of continuously producing deployable artifacts from our source code.</p><p>Our next goal will be to upgrade the pipeline from a Continuous Integration to an <span class="strong"><strong>Integration</strong></span> plus <span class="strong"><strong>Delivery</strong></span> one. To illustrate, we are in the middle of a three stage workflow:</p><p>
</p><div class="mediaobject"><img src="graphics/image_05_001.jpg" alt="Ever-Ready to Deploy Using Continuous Delivery"/></div><p>
</p><p>That is to say, following a successful Integration run, we trigger the Delivery stage that will do the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Launch a vanilla EC2 instance</li><li class="listitem" style="list-style-type: disc">Apply configuration management to it:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Install the <code class="literal">demo-app</code> RPM we produced</li><li class="listitem" style="list-style-type: disc">Install other required packages to turn it into a web server</li></ul></div><p>
</p></li><li class="listitem" style="list-style-type: disc">Test the applied configuration (using <span class="strong"><strong>Serverspec</strong></span>)</li><li class="listitem" style="list-style-type: disc">Produce an AMI out of the configured instance (using <span class="strong"><strong>Packer</strong></span>)</li><li class="listitem" style="list-style-type: disc">Launch an EC2 instance from the produced AMI</li><li class="listitem" style="list-style-type: disc">Run additional tests against the new EC2 instance</li></ul></div><p>This pipeline will ensure that the application RPM installs correctly, our configuration management gets applied as expected, and our new AMI artifact is fit for purpose. At the end we should be left with a sparkling, prebaked, production-ready AMI of a web server with our <code class="literal">demo-app</code> on it.</p><p>To accomplish these tasks, we are going to introduce two new tools to the mix - Packer and Serverspec (more details as we go).</p><p>We will be able to reuse a significant part of our work so far, given that we are building on top of it. As before, we will start by preparing our code, deploying it to AWS, and configuring our Jenkins Pipeline.</p><p>Feel free to skip some of the following steps if you have kept the AWS environment from the previous chapter running. Although I think that it might be better to start from scratch to avoid any confusion.</p><div class="section" title="Preparing Terraform templates"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec14"/>Preparing Terraform templates</h1></div></div></div><p>In addition to the usual VPC, IGW, and subnet that we need for Jenkins, we are going to deploy NAT and ELB for our <code class="literal">demo-app</code> web server scenario.</p><div class="section" title="Resources"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec30"/>Resources</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note45"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/Terraform/resources.tf">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/Terraform/resources.tf</a>.</p></div></div><p>We start with VPC, IGW, and NAT:</p><pre class="programlisting">resource "aws_vpc" "terraform-vpc" { &#13;
  cidr_block = "${var.vpc-cidr}" &#13;
... &#13;
 &#13;
resource "aws_internet_gateway" "terraform-igw" { &#13;
  vpc_id = "${aws_vpc.terraform-vpc.id}" &#13;
} &#13;
 &#13;
resource "aws_eip" "nat-eip" { &#13;
  vpc = true &#13;
} &#13;
 &#13;
resource "aws_nat_gateway" "terraform-nat" { &#13;
  allocation_id = "${aws_eip.nat-eip.id}" &#13;
  subnet_id = "${aws_subnet.public-1.id}" &#13;
  depends_on = ["aws_internet_gateway.terraform-igw"] &#13;
... &#13;
</pre><p>We add a <code class="literal">public</code> subnet for Jenkins and ELB, plus a <code class="literal">private</code> one to be used by the EC2 web server:</p><pre class="programlisting">resource "aws_route_table" "public" { &#13;
  vpc_id = "${aws_vpc.terraform-vpc.id}" &#13;
... &#13;
resource "aws_route_table" "private" { &#13;
  vpc_id = "${aws_vpc.terraform-vpc.id}" &#13;
... &#13;
</pre><p>Next is IAM. We need a role for Jenkins:</p><pre class="programlisting">resource "aws_iam_role" "jenkins" { &#13;
    name = "jenkins" &#13;
    path = "/" &#13;
    assume_role_policy = &lt;&lt;EOF &#13;
{ &#13;
</pre><p>And another one for the <code class="literal">demo-app</code> web server:</p><pre class="programlisting">resource "aws_iam_role" "demo-app" { &#13;
    name = "demo-app" &#13;
    path = "/" &#13;
    assume_role_policy = &lt;&lt;EOF &#13;
{ &#13;
</pre><p>They will be sharing a common policy, allowing them to access CodeCommit, where we keep our infrastructure and application code and S3, where we store our RPM artifacts:</p><pre class="programlisting">resource "aws_iam_policy" "common" { &#13;
    name = "common" &#13;
    path = "/" &#13;
    policy = &lt;&lt;EOF &#13;
{ &#13;
    "Version": "2012-10-17", &#13;
    "Statement": [ &#13;
       { &#13;
            "Effect": "Allow", &#13;
            "Action": [ &#13;
                "codecommit:Get*", &#13;
                "codecommit:GitPull", &#13;
                "codecommit:List*" &#13;
            ], &#13;
            "Resource": "*" &#13;
       }, &#13;
       { &#13;
            "Effect": "Allow", &#13;
            "NotAction": [ &#13;
                "s3:DeleteBucket" &#13;
            ], &#13;
            "Resource": "*" &#13;
... &#13;
</pre><p>The newcomer, Packer, is going to require a separate policy to allow for the manipulation of EC2 resources. We are going to use it to start/stop/terminate instances and create AMIs:</p><pre class="programlisting">resource "aws_iam_policy" "jenkins" { &#13;
    name = "jenkins" &#13;
    path = "/" &#13;
    policy = &lt;&lt;EOF &#13;
{ &#13;
    "Version": "2012-10-17", &#13;
    "Statement": [ &#13;
       { &#13;
         "Effect": "Allow", &#13;
         "Action": [ &#13;
           "ec2:AttachVolume", &#13;
           "ec2:CreateVolume", &#13;
           "ec2:DeleteVolume", &#13;
           "ec2:CreateKeypair", &#13;
           "ec2:DeleteKeypair", &#13;
           "ec2:DescribeSubnets" &#13;
... &#13;
         "Resource": "*", &#13;
       }, &#13;
       { &#13;
         "Effect": "Allow", &#13;
         "Action": "iam:PassRole", &#13;
         "Resource": ["${aws_iam_role.demo-app.arn}"] &#13;
... &#13;
</pre><p>The need to allow <code class="literal">PassRole</code> represents an IAM security feature which helps prevent users/services granting themselves more privileges than they are supposed to have (refer to: <a class="ulink" href="https://blogs.aws.amazon.com/security/post/Tx3M0IFB5XBOCQX/Granting-Permission-to-Launch-EC2-Instances-with-IAM-Roles-PassRole-Permission">https://blogs.aws.amazon.com/security/post/Tx3M0IFB5XBOCQX/Granting-Permission-to-Launch-EC2-Instances-with-IAM-Roles-PassRole-Permission</a>).</p><p>We are going to need a security group for ELB, accepting HTTP traffic from the World:</p><pre class="programlisting">resource "aws_security_group" "demo-app-elb" { &#13;
  name = "demo-app-elb" &#13;
  description = "ELB security group" &#13;
  vpc_id = "${aws_vpc.terraform-vpc.id}" &#13;
 &#13;
  ingress { &#13;
    from_port = "80" &#13;
    to_port = "80" &#13;
    protocol = "tcp" &#13;
    cidr_blocks = ["0.0.0.0/0"] &#13;
... &#13;
</pre><p>Then, ELB itself:</p><pre class="programlisting">resource "aws_elb" "demo-app-elb" { &#13;
  name = "demo-app-elb" &#13;
  security_groups = ["${aws_security_group.demo-app-elb.id}"] &#13;
  subnets = ["${aws_subnet.public-1.id}"] &#13;
 &#13;
  listener { &#13;
    instance_port = 80 &#13;
    instance_protocol = "http" &#13;
    lb_port = 80 &#13;
    lb_protocol = "http" &#13;
... &#13;
</pre><p>We create a security group for Jenkins permitting SSH and HTTP/S traffic from anywhere:</p><pre class="programlisting">resource "aws_security_group" "jenkins" { &#13;
  name = "jenkins" &#13;
  description = "ec2 instance security group" &#13;
  vpc_id = "${aws_vpc.terraform-vpc.id}" &#13;
 &#13;
ingress { &#13;
    from_port = "80" &#13;
    to_port = "80" &#13;
    protocol = "tcp" &#13;
    cidr_blocks = ["0.0.0.0/0"] &#13;
  } &#13;
 &#13;
  ingress { &#13;
    from_port = "443" &#13;
    to_port = "443" &#13;
    protocol = "tcp" &#13;
    cidr_blocks = ["0.0.0.0/0"] &#13;
... &#13;
</pre><p>The next one is for the web server, accepting HTTP from ELB and SSH from Jenkins:</p><pre class="programlisting">resource "aws_security_group" "demo-app" { &#13;
  name = "demo-app" &#13;
  description = "ec2 instance security group" &#13;
  vpc_id = "${aws_vpc.terraform-vpc.id}" &#13;
 &#13;
  ingress { &#13;
    from_port = "80" &#13;
    to_port = "80" &#13;
    protocol = "tcp" &#13;
    security_groups = ["${aws_security_group.demo-app-elb.id}"] &#13;
  } &#13;
 &#13;
  ingress { &#13;
    from_port = "22" &#13;
    to_port = "22" &#13;
    protocol = "tcp" &#13;
    security_groups = ["${aws_security_group.jenkins.id}"] &#13;
... &#13;
</pre><p>To bootstrap the Jenkins node, we need the user-data we used in the past, with one important addition:</p><pre class="programlisting">resource "aws_instance" "jenkins" { &#13;
... &#13;
    user_data = &lt;&lt;EOF &#13;
... &#13;
# Install SaltStack &#13;
yum -y install https://repo.saltstack.com/yum/amazon/salt-amzn-repo-latest-1.ami.noarch.rpm &#13;
yum clean expire-cache; yum -y install salt-minion; chkconfig salt-minion off &#13;
# Put custom minion config in place (for enabling masterless mode) &#13;
cp -r /srv/salt/minion.d /etc/salt/ &#13;
echo -e 'grains:\n roles:\n  - jenkins' &gt; /etc/salt/minion.d/grains.conf &#13;
... &#13;
</pre><p>You will note that after we have installed SaltStack and put the masterless minion configuration in place, we also add a custom Grains file. The roles list that it holds will help us assign the Salt States later on (since we are now going to have two different types of hosts under configuration management: <code class="literal">jenkins</code> and our <code class="literal">demo-app</code> web server).</p></div><div class="section" title="Variables"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec31"/>Variables</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note46"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/Terraform/variables.tf">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/Terraform/variables.tf</a>.</p></div></div><p>No change from <a class="link" href="ch04.html" title="Chapter 4. Build, Test, and Release Faster with Continuous Integration">Chapter 4</a>, <span class="emphasis"><em>Build, Test, and Release Faster with Continuous Integration</em></span>, we set just a few VPC- and EC2 (Jenkins)-related variables.</p></div><div class="section" title="Variables (values)"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec32"/>Variables (values)</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note47"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/Terraform/terraform.tfvars">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/Terraform/terraform.tfvars</a>.</p></div></div><p>Same as our previous deployment, we specify the values for the VPC and Jenkins variables.</p></div><div class="section" title="Outputs"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec33"/>Outputs</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note48"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/Terraform/outputs.tf">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/Terraform/outputs.tf</a>.</p></div></div><p>Some new <code class="literal">outputs</code> reflect the additional <code class="literal">resources</code>. The ELB endpoint and the ID of our Private subnet and the <code class="literal">demo-app</code> security group:</p><pre class="programlisting">output "ELB URI" { &#13;
  value = "${aws_elb.demo-app-elb.dns_name}" &#13;
} &#13;
output "Private subnet ID" { &#13;
  value = "${aws_subnet.private-1.id}" &#13;
} &#13;
output "Demo-app secgroup" { &#13;
  value = "${aws_security_group.demo-app.id}"  &#13;
} &#13;
</pre><p>This is certainly not an exhaustive list, and if we need more information later, we can always retrieve a detailed description of our deployed infrastructure via the <code class="literal">terraform show</code> command.</p></div></div></div>
<div class="section" title="Prepareing Salt code"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec15"/>Prepareing Salt code</h1></div></div></div><p>We will be using SaltStack to apply configuration management on both our Jenkins and <code class="literal">demo-app</code> web server nodes. We will be using Grains to define which States/Pillars apply to which host. Let us have a look at the code:</p><div class="section" title="States"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec34"/>States</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note49"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit/salt/states">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit/salt/states</a>.</p></div></div><div class="section" title="top.sls"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec22"/>top.sls</h3></div></div></div><p>The <code class="literal">top</code> file shows us that some states are shared between all hosts/roles while others are assigned based on the role:</p><pre class="programlisting">base: &#13;
  '*': &#13;
    - users &#13;
    - yum-s3 &#13;
 &#13;
  'roles:jenkins': &#13;
    - match: grain &#13;
    - jenkins &#13;
    - nginx.jenkins &#13;
    - docker &#13;
    - packer &#13;
 &#13;
  'roles:demo-app': &#13;
    - match: grain &#13;
    - php-fpm &#13;
    - nginx.demo-app &#13;
    - demo-app &#13;
</pre><p>You are already familiar with the users and the <code class="literal">yum-s3</code> States. Now this is a good time to add an account and an SSH key for yourself.</p></div><div class="section" title="jenkins"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec23"/>jenkins</h3></div></div></div><p>We install the service as before plus a couple of extra tools:</p><pre class="programlisting">jenkins_prereq: &#13;
  pkg.installed: &#13;
    - pkgs: &#13;
... &#13;
      - jq &#13;
      - httpd-tools &#13;
... &#13;
</pre><p>We will be using <code class="literal">jq</code> to parse JSON output and <code class="literal">ab</code> from the <code class="literal">httpd-tools</code> package for basic HTTP load testing.</p></div><div class="section" title="nginx"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec24"/>nginx</h3></div></div></div><p>This time we split the NGINX State into three parts:</p><p>
<span class="strong"><strong>init.sls</strong></span>
</p><p>This installs the main package and sets up the service daemon:</p><pre class="programlisting">nginx: &#13;
  pkg.installed: [] &#13;
 &#13;
  service.running: &#13;
    - enable: True &#13;
    - reload: True &#13;
    - require: &#13;
      - pkg: nginx &#13;
</pre><p>
<span class="strong"><strong>jenkins.sls</strong></span>
</p><p>This deploys the NGINX configuration and related file needed for the Jenkins service:</p><pre class="programlisting">include: &#13;
  - nginx &#13;
 &#13;
/etc/nginx/conf.d/jenkins.conf: &#13;
  file.managed: &#13;
    - source: salt://nginx/files/jenkins.conf &#13;
... &#13;
</pre><p>
<span class="strong"><strong>demo-app.sls</strong></span>
</p><p>This deploys the NGINX configuration and related file needed for the <code class="literal">demo-app</code> web server:</p><pre class="programlisting">include: &#13;
  - nginx &#13;
 &#13;
/etc/nginx/conf.d/demo-app.conf: &#13;
  file.managed: &#13;
    - source: salt://nginx/files/demo-app.conf &#13;
</pre><p>In both cases, we include <code class="literal">init.sls</code> also known as NGINX, which provides shared functionality, Docker remains the same, whereas Packer is a new addition which we will get to play with shortly:</p><pre class="programlisting">packer: &#13;
  archive.extracted: &#13;
    - name: /opt/ &#13;
    - source: 'https://releases.hashicorp.com/packer/0.10.1/packer_0.10.1_linux_amd64.zip' &#13;
    - source_hash: md5=3a54499fdf753e7e7c682f5d704f684f &#13;
    - archive_format: zip &#13;
    - if_missing: /opt/packer &#13;
 &#13;
  cmd.wait: &#13;
    - name: 'chmod +x /opt/packer' &#13;
    - watch: &#13;
      - archive: packer &#13;
</pre><p>The archive module conveniently downloads and extracts the Packer zip file for us. After that we ensure that the binary is executable with <code class="literal">cmd.wait</code>, which gets triggered on package change (that is watch archive).</p><p>
<span class="strong"><strong>php-fpm</strong></span>
</p><p>We need PHP in order to be able to serve our PHP <code class="literal">application </code>(<code class="literal">demo-app)</code>:</p><pre class="programlisting">include: &#13;
  - nginx &#13;
 &#13;
php-fpm: &#13;
  pkg.installed: &#13;
    - name: php-fpm &#13;
    - require: &#13;
      - pkg: nginx &#13;
 &#13;
  service.running: &#13;
    - name: php-fpm &#13;
    - enable: True &#13;
    - reload: True &#13;
    - require_in: &#13;
      - service: nginx &#13;
... &#13;
</pre><p>And finally, the <code class="literal">demo-app</code> State, which installs a selected version the application <code class="literal">rpm</code>. We will discuss how we populate <code class="literal">/tmp/APP_VERSION</code> a bit later:</p><pre class="programlisting">{% set APP_VERSION = salt['cmd.run']('cat /tmp/APP_VERSION') %} &#13;
 &#13;
include: &#13;
  - nginx &#13;
 &#13;
demo-app: &#13;
  pkg.installed: &#13;
    - name: demo-app &#13;
    - version: {{ APP_VERSION }} &#13;
    - require_in: &#13;
      - service: nginx &#13;
</pre></div></div><div class="section" title="Pillars"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec35"/>Pillars</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note50"/>Note</h3><p>Please refer to<a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit/salt/pillars"> https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit/salt/pillars</a>.</p></div></div><p>We will reuse the <code class="literal">nginx</code> and <code class="literal">users</code> Pillars from the previous chapter.</p></div><div class="section" title="Minion configuration"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec36"/>Minion configuration</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note51"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit/salt/minion.d">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit/salt/minion.d</a>.</p></div></div><p>While <code class="literal">masterless.conf</code> remains the same as before, we are extending the <code class="literal">minion</code> configuration with a custom role Grain, which we set via UserData for Jenkins and a config file for the <code class="literal">demo-app</code> web server (discussed later in the chapter).</p></div></div>
<div class="section" title="Preparing Jenkins code"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec16"/>Preparing Jenkins code</h1></div></div></div><p>Before we proceed with Jenkins, allow me to introduce the two new helpers – Packer and Serverspec.</p><div class="section" title="Packer"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec37"/>Packer</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note52"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit/demo-app-cdelivery/packer">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit/demo-app-cdelivery/packer</a>.</p></div></div><p>As described:</p><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p>
<span class="emphasis"><em>"Packer is a tool for creating machine and container images for multiple platforms from a single source configuration."</em></span>
</p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top" style="text-align: center">--<span class="attribution"><span class="emphasis"><em>https://www.packer.io</em></span></span></td></tr></table></div><p>Essentially, Packer is going to, well, pack things for us. We will feed it a template, based on which it will launch an EC2 instance, perform requested tasks (over SSH), then create an AMI from it. Packer can talk to various platforms (AWS, GCE, OpenStack, and so on) to provision resources via local shell, remote (SSH), Salt, Ansible, Chef, and others. As a HashiCorp product, it does not come as a surprise that Packer uses a templating system very similar to Terraform's.</p><div class="section" title="demo-app.json"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec25"/>demo-app.json</h3></div></div></div><p>Here, we define what and how it should be provisioned. At the top, we set our <code class="literal">variables</code>:</p><pre class="programlisting">  "variables": { &#13;
    "srcAmiId": null, &#13;
    "amiName": null, &#13;
    "sshUser": null, &#13;
    "instanceProfile": null, &#13;
    "subnetId": null, &#13;
    "vpcId": null, &#13;
    "userDataFile": null, &#13;
    "appVersion": null &#13;
  } &#13;
... &#13;
</pre><p>We have exported the actual values to a <code class="literal">variables</code> file (see later). Setting a value to null here, makes it required. We could also fix values here or make use of environment variables (refer to <a class="ulink" href="https://www.packer.io/docs/templates/user-variables.html">https://www.packer.io/docs/templates/user-variables.html</a>). Once defined, you can refer to variables with this syntax: <code class="literal">{{user `srcAmiId`}}</code>.</p><p>The next section lists the <code class="literal">builders</code>, in our case, AWS EC2:</p><pre class="programlisting">  "builders": [{ &#13;
    "type": "amazon-ebs", &#13;
    "region": "us-east-1", &#13;
    "source_ami": "{{user `srcAmiId`}}", &#13;
    "instance_type": "t2.nano", &#13;
    "ssh_username": "{{user `sshUser`}}", &#13;
    "ami_name": "{{user `amiName`}}-{{timestamp}}", &#13;
    "iam_instance_profile": "{{user `instanceProfile`}}", &#13;
    "subnet_id": "{{user `subnetId`}}", &#13;
    "vpc_id": "{{user `vpcId`}}", &#13;
    "user_data_file": "{{user `userDataFile`}}", &#13;
    "run_tags": { &#13;
      "Name": "Packer ({{user `amiName`}}-{{timestamp}})", &#13;
      "CreatedBy": "Jenkins" &#13;
      }, &#13;
    "tags": { &#13;
      "Name": "{{user `amiName`}}-{{timestamp}}", &#13;
      "CreatedBy": "Jenkins" &#13;
      } &#13;
  }] &#13;
</pre><p>We are asking for an EBS-backed nano instance in the US-East-1 region. It is to be bootstrapped via UserData (see later in the text) and tagged as <code class="literal">"CreatedBy": "Jenkins"</code>.</p><p>Naturally, after launching the instance, we would like to provision it:</p><pre class="programlisting">"provisioners": [ &#13;
    { &#13;
      "type": "shell", &#13;
      "inline": [  &#13;
        "echo 'Waiting for the instance to fully boot up...'", &#13;
        "sleep 30" , &#13;
        "echo "Setting APP_VERSION to {{user `appVersion`}}"", &#13;
        "echo "{{user `appVersion`}}" &gt; /tmp/APP_VERSION" &#13;
        ] &#13;
    } &#13;
</pre><p>Here, our first <code class="literal">provisioners</code> is a shell command to be executed over SSH by Packer (refer to <a class="ulink" href="https://www.packer.io/docs/provisioners/shell.html">https://www.packer.io/docs/provisioners/shell.html</a>). It pauses for 30 seconds to allow the node to complete its boot process, then creates the <code class="literal">APP_VERSION</code> file needed by the Salt <code class="literal">php-fpm</code> State.</p><p>Next, we run SaltStack:</p><pre class="programlisting">{ &#13;
      "type": "salt-masterless", &#13;
      "skip_bootstrap": true, &#13;
      "local_state_tree": "salt/states", &#13;
      "local_pillar_roots": "salt/pillars" &#13;
} &#13;
</pre><p>Packer already knows how to run Salt via the salt-masterless <code class="literal">provisioner</code>. It only needs a source of States and Pillars (refer to: <a class="ulink" href="https://www.packer.io/docs/provisioners/salt-masterless.html">https://www.packer.io/docs/provisioners/salt-masterless.html</a>). We define a relative path of <code class="literal">salt/</code>, which is part of a checked out Git repository (see <code class="literal">demo-app-cdelivery</code> here). We are opting to install Salt via UserData, hence <code class="literal">skip_bootstrap: true</code>.</p><p>We will get to Serverspec in a moment, but here is how we run it:</p><pre class="programlisting">{ &#13;
      "type": "file", &#13;
      "source": "serverspec", &#13;
      "destination": "/tmp/" &#13;
}, &#13;
{ &#13;
      "type": "shell", &#13;
      "inline": [  &#13;
        "echo 'Installing Serverspec tests...'", &#13;
        "sudo gem install --no-document rake serverspec", &#13;
        "echo 'Running Serverspec tests...'", &#13;
        "cd /tmp/serverspec &amp;&amp; sudo /usr/local/bin/rake spec" &#13;
  ] &#13;
} &#13;
</pre><p>The file <code class="literal">provisioners</code> is used to transfer data between the remote instance and Packer (refer to <a class="ulink" href="https://www.packer.io/docs/provisioners/file.html">https://www.packer.io/docs/provisioners/file.html</a>). We push the local <code class="literal">"serverspec/"</code> folder containing our Serverspec tests to <code class="literal">"/tmp"</code> on the remote side. Then, run a few shell commands to install the Serverspec ruby gem and run the tests.</p></div><div class="section" title="demo-app_vars.json"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec26"/>demo-app_vars.json</h3></div></div></div><p>The values for the variables we defined earlier (alternatively, you could set these as a list of <code class="literal">-var 'key=value'</code> cmd line arguments):</p><pre class="programlisting">{  &#13;
  "srcAmiId": "ami-6869aa05", &#13;
  "amiName": "demo-app", &#13;
  "sshUser": "ec2-user", &#13;
  "instanceProfile": "demo-app", &#13;
  "subnetId": "subnet-4d1c2467", &#13;
  "vpcId": "vpc-bd6f0bda", &#13;
  "userDataFile": "packer/demo-app_userdata.sh" &#13;
} &#13;
</pre></div><div class="section" title="demo-app_userdata.sh"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec27"/>demo-app_userdata.sh</h3></div></div></div><p>The EC2 UserData to bootstrap our test instance:</p><pre class="programlisting">#!/bin/bash &#13;
 &#13;
set -euf -o pipefail &#13;
exec 1&gt; &gt;(logger -s -t $(basename $0)) 2&gt;&amp;1 &#13;
 &#13;
# Install SaltStack &#13;
yum -y install https://repo.saltstack.com/yum/amazon/salt-amzn-repo-latest-1.ami.noarch.rpm &#13;
yum clean expire-cache; yum -y install salt-minion; chkconfig salt-minion off &#13;
 &#13;
# Put custom grains in place &#13;
echo -e 'grains:\n roles:\n  - demo-app' &gt; /etc/salt/minion.d/grains.conf &#13;
</pre><p>Much like the one we use for Jenkins. It gets SaltStack installed and puts the roles Grain in place.</p></div></div><div class="section" title="Serverspec"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec38"/>Serverspec</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note53"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit/demo-app-cdelivery/serverspec">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit/demo-app-cdelivery/serverspec</a>.</p></div></div><p>Straight out of the front page:</p><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p>
<span class="emphasis"><em>"RSpec tests for your servers configured by CFEngine, Puppet, Ansible, Itamae or anything else.
With Serverspec, you can write RSpec tests for checking your servers are configured correctly.
Serverspec tests your servers' actual state by executing command locally, via SSH, via WinRM, via Docker API and so on. So you don't need to install any agent softwares on your servers and can use any configuration management tools, Puppet, Ansible, CFEngine, Itamae and so on.
But the true aim of Serverspec is to help refactoring infrastructure code."</em></span>
</p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top" style="text-align: center">--<span class="attribution"><span class="emphasis"><em>http://serverspec.org</em></span></span></td></tr></table></div><p>We are going to use Serverspec to assert the final state of the EC2 instance after all other configuration tasks have been completed. It should help verify that any nonconfiguration management changes have taken effect (for example, shell commands) and that configuration management has been applied correctly (for example, no race conditions/overlaps/conflicts in States). This does introduce some overhead and some will rightly question whether it is needed in addition to a SaltStack run, so it remains a personal preference. I see it as a second layer of verification or a safety net.</p><p>The content under the <code class="literal">serverspec/</code> folder has been created by running <code class="literal">serverspec-init</code> (refer to <a class="ulink" href="http://serverspec.org">http://serverspec.org</a>), selecting UNIX and then SSH. We replace the sample <code class="literal">spec.rb</code> file with our own:</p><div class="section" title="spec/localhost/demo-app_spec.rb"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec28"/>spec/localhost/demo-app_spec.rb</h3></div></div></div><pre class="programlisting">require 'spec_helper' &#13;
 &#13;
versionFile = open('/tmp/APP_VERSION') &#13;
appVersion = versionFile.read.chomp &#13;
 &#13;
describe package("demo-app-#{appVersion}") do &#13;
  it { should be_installed } &#13;
end &#13;
 &#13;
describe service('php-fpm') do &#13;
  it { should be_enabled } &#13;
  it { should be_running } &#13;
end &#13;
 &#13;
describe service('nginx') do &#13;
  it { should be_enabled } &#13;
  it { should be_running } &#13;
end &#13;
 &#13;
describe user('veselin') do &#13;
  it { should exist } &#13;
  it { should have_authorized_key 'ssh-rsa ...' } &#13;
end &#13;
</pre><p>Serverspec performs tests on supported resource types (refer to <a class="ulink" href="http://serverspec.org/resource_types.html">http://serverspec.org/resource_types.html</a>).</p><p>In the preceding brief example we assert that:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A specific version of our <code class="literal">demo-app</code> package has been installed</li><li class="listitem" style="list-style-type: disc">PHP-FPM and NGINX are running and enabled on boot</li><li class="listitem" style="list-style-type: disc">The SSH <code class="literal">authorized_keys</code> file for a given user has the expected contents</li></ul></div><p>Our Serverspec tests can be run from the containing folder like so:</p><pre class="programlisting">
<span class="strong"><strong>cd /tmp/serverspec &amp;&amp; sudo /usr/local/bin/rake spec</strong></span>
</pre><p>It will parse any files it finds ending in <code class="literal">_spec.rb</code>. We use <code class="literal">sudo</code> only because, in this case, we are trying to read a private file (<code class="literal">authorized_keys</code>).</p><p>And back to Jenkins. We are already familiar with the concept of a <code class="literal">Jenkinsfile</code> (as used by our Integration job). In this example, we will be adding a second (Delivery) pipeline using the same approach.</p><p>Let us examine both pipeline jobs.</p></div></div><div class="section" title="demo-app"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec39"/>demo-app</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note54"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/CodeCommit/demo-app/Jenkinsfile">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/CodeCommit/demo-app/Jenkinsfile</a>.</p></div></div><p>This is our old Integration job that downloads the application code, runs tests against it, produces an RPM package and uploads the package to a YUM repository. We are going to add one more stage to this process:</p><pre class="programlisting">stage "Trigger downstream" &#13;
    build job: "demo-app-cdelivery", &#13;
    parameters: [[$class: "StringParameterValue", name: "APP_VERSION", value: &#13;
    "${gitHash}-1"]], wait: false &#13;
</pre><p>This final stage triggers our next job that is the Delivery pipeline and passes an <code class="literal">APP_VERSION</code> parameter to it.</p><p>The value of this parameter is the <code class="literal">gitHash</code> which we have been using so far as a version string for our <code class="literal">demo-app RPM package</code>.</p><p>The <code class="literal">-1</code> you see appended to the <code class="literal">gitHash</code> represents the rpm's minor version number which you can safely ignore at this time.</p><p>Setting <code class="literal">wait</code> to <code class="literal">false</code> means that we don't want to keep the current job running, waiting for the subsequently triggered one to complete.</p></div><div class="section" title="demo-app-cdelivery"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec40"/>demo-app-cdelivery</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note55"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/CodeCommit/demo-app-cdelivery/Jenkinsfile">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/CodeCommit/demo-app-cdelivery/Jenkinsfile</a>.</p></div></div><p>Now the fun part. The Delivery job has been passed an <code class="literal">APP_VERSION</code> and is ready to start, let us follow the process described in the <code class="literal">Jenkinsfile</code>.</p><p>We start by cleaning up our workspace, checking out the <code class="literal">demo-app-cdelivery</code> repository, then adding the SaltStack code on top of it. We need both codebases in order to launch an instance and configure it to be a web server:</p><pre class="programlisting">#!groovy &#13;
 &#13;
node { &#13;
 &#13;
  step([$class: 'WsCleanup']) &#13;
 &#13;
  stage "Checkout Git repo" &#13;
    checkout scm &#13;
 &#13;
  stage "Checkout additional repos" &#13;
    dir("salt") { &#13;
      git "https://git-codecommit.us-east-1.amazonaws.com/v1/repos/salt" &#13;
    } &#13;
</pre><p>After this, we are ready to run Packer:</p><pre class="programlisting">stage "Run Packer" &#13;
    sh "/opt/packer validate -var="appVersion=$APP_VERSION" -var-file=packer/demo-app_vars.json packer/demo-app.json" &#13;
    sh "/opt/packer build -machine-readable -var="appVersion=$APP_VERSION" -var-file=packer/demo-app_vars.json packer/demo-app.json | tee packer/packer.log" &#13;
</pre><p>First, we validate our template and then execute, requesting a machine-readable output. Packer is going to spin up an instance, connect over SSH to it, apply all relevant Salt States, run Serverspec tests, and produce an AMI of what is essentially a web server that has the <code class="literal">demo-app</code> and all its prerequisites installed.</p><p>Then, we go ahead and launch a second EC2 instance; this time, form the AMI we just created:</p><pre class="programlisting">stage "Deploy AMI" &#13;
    def amiId = sh returnStdout: true, script:"tail -n1 packer/packer.log | awk '{printf \$NF}'" &#13;
    def ec2Keypair = "terraform" &#13;
    def secGroup = "sg-2708ef5d" &#13;
    def instanceType = "t2.nano" &#13;
    def subnetId = "subnet-4d1c2467" &#13;
    def instanceProfile = "demo-app" &#13;
    echo "Launching an instance from ${amiId}" &#13;
    sh "aws ec2 run-instances \ &#13;
        --region us-east-1 \ &#13;
        --image-id ${amiId} \ &#13;
        --key-name ${ec2Keypair} \ &#13;
        --security-group-ids ${secGroup} \ &#13;
        --instance-type ${instanceType} \ &#13;
        --subnet-id ${subnetId} \ &#13;
        --iam-instance-profile Name=${instanceProfile} \ &#13;
        | tee .ec2_run-instances.log \ &#13;
       " &#13;
    def instanceId = sh returnStdout: true, script: "printf \$(jq .Instances[0].InstanceId &lt; .ec2_run-instances.log)" &#13;
</pre><p>The variables seen at the top we get from Terraform (<code class="literal">terraform show</code>).</p><p>We use the <code class="literal">aws cli</code> to launch the instance inside the Private VPC subnet, attach the <code class="literal">demo-app</code> security group, the Terraform key, and <code class="literal">demo-app</code> instance profile to it. You will notice that we need not pass any EC2 credentials here as Jenkins is already authorized via the IAM role we assigned to it earlier.</p><p>Next, we retrieve the <code class="literal">instanceId</code> by parsing the <code class="literal">aws cli</code> JSON output with <code class="literal">jq</code> (refer to <a class="ulink" href="https://stedolan.github.io/jq">https://stedolan.github.io/jq</a>).</p><p>After we have launched the instance, we set its tags, register it with ELB, and loop until its ELB status becomes <code class="literal">InService</code>:</p><pre class="programlisting">sh "aws ec2 create-tags --resources ${instanceId} \ &#13;
        --region us-east-1 \ &#13;
        --tags Key=Name,Value="Jenkins (demo-app-$APP_VERSION)" &#13;
        Key=CreatedBy,Value=Jenkins \ \ &#13;
       " &#13;
 &#13;
    echo "Registering with ELB" &#13;
    def elbId = "demo-app-elb" &#13;
    sh "aws elb register-instances-with-load-balancer \ &#13;
        --region us-east-1 \ &#13;
        --load-balancer-name ${elbId} \ &#13;
        --instances ${instanceId} \ &#13;
       " &#13;
 &#13;
    echo "Waiting for the instance to come into service" &#13;
    sh "while [ "x\$(aws elb describe-instance-health --region us-east-1 --load-&#13;
    balancer-name ${elbId} --instances ${instanceId} | &#13;
    jq .InstanceStates[].State | tr -d '"')" != "xInService" ]; do : ; sleep 60; &#13;
    done" &#13;
</pre><p>Now that the node is ready to serve, we can launch our improvised Load Test using AB:</p><pre class="programlisting">  stage "Run AB test" &#13;
    def elbUri = "http://demo-app-elb-1931064195.us-east-1.elb.amazonaws.com/"   &#13;
    sh "ab -c5 -n1000 -d -S ${elbUri} | tee .ab.log" &#13;
    def non2xx = sh returnStdout: true, script:"set -o pipefail;(grep 'Non-2xx' .ab.log | awk '{printf \$NF}') || (printf 0)" &#13;
    def writeErr = sh returnStdout: true, script:"grep 'Write errors' .ab.log | awk '{printf \$NF}'" &#13;
    def failedReqs = sh returnStdout: true, script:"grep 'Failed requests' .ab.log | awk '{printf \$NF}'" &#13;
    def rps = sh returnStdout: true, script:"grep 'Requests per second' .ab.log | awk '{printf \$4}' | awk -F. '{printf \$1}'" &#13;
    def docLen = sh returnStdout: true, script:"grep 'Document Length' .ab.log | awk '{printf \$3}'" &#13;
 &#13;
    echo "Non2xx=${non2xx}, WriteErrors=${writeErr}, FailedReqs=${failedReqs}, ReqsPerSec=${rps}, DocLength=${docLen}" &#13;
    sh "if [ ${non2xx} -gt 10 ] || [ ${writeErr} -gt 10 ] || [ ${failedReqs} -gt 10 ] || [ ${rps} -lt 1000 ] || [ ${docLen} -lt 10 ]; then \ &#13;
          echo "ERR: AB test failed" | tee -a .error.log; \ &#13;
        fi \ &#13;
       " &#13;
</pre><p>At the end of the AB test, the various reported metrics are compared with preset thresholds and logged.</p><p>The EC2 instance is no longer needed, so it can be terminated:</p><pre class="programlisting"> stage "Terminate test instance" &#13;
    sh "aws ec2 terminate-instances --region us-east-1 --instance-ids ${instanceId}" &#13;
</pre><p>In the final stage, the job's exit code is determined by the AB test results:</p><pre class="programlisting">  stage "Verify test results" &#13;
    sh "if [ -s '.error.log' ]; then \ &#13;
          cat '.error.log'; \ &#13;
          :&gt; '.error.log'; \ &#13;
          exit 100; \ &#13;
        else \ &#13;
          echo 'Tests OK'; \ &#13;
        fi \ &#13;
       " &#13;
</pre></div></div>
<div class="section" title="Preparing CodeCommit repositories"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec17"/>Preparing CodeCommit repositories</h1></div></div></div><p>Ideally, we would put all the preceding code under revision control, so let us create some repositories. We need an IAM user with enough privileges to do that:</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note56"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/CodeCommit/demo-app-cdelivery/Jenkinsfile">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_05_CodeFiles/CodeCommit/demo-app-cdelivery/Jenkinsfile</a>.</p></div></div><pre class="programlisting">{ &#13;
    "Version": "2012-10-17", &#13;
    "Statement": [ &#13;
      { &#13;
          "Effect": "Allow", &#13;
          "NotAction": [ &#13;
              "codecommit:DeleteRepository" &#13;
          ], &#13;
          "Resource": "*" &#13;
      }, &#13;
      { &#13;
          "Effect": "Allow", &#13;
          "NotAction": [ &#13;
              "s3:DeleteBucket" &#13;
          ], &#13;
          "Resource": "*" &#13;
      }, &#13;
      { &#13;
          "Sid": "Stmt1461764665000", &#13;
          "Effect": "Allow", &#13;
          "Action": [ &#13;
              "ec2:AllocateAddress", &#13;
              "ec2:AssociateAddress", &#13;
... &#13;
</pre><p>We create a <code class="literal">terraform</code> IAM user with the preceding policy that grants us privileges to carry out the CodeCommit tasks and also do the Terraform deployment later (remember to write down the API keys).</p><p>Please refer to the previous chapter on how to export the API keys and create three CodeCommit repositories: <code class="literal">salt</code>, <code class="literal">demo-app</code>, and <code class="literal">demo-app-cdelivery</code>.</p><p>You will need to clone the repositories locally and populate each with the code we prepared earlier respectively (refer to: <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_05_CodeFiles/CodeCommit</a>).</p></div>
<div class="section" title="Deploy Terraform templates"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec18"/>Deploy Terraform templates</h1></div></div></div><p>Create a <code class="literal">terraform</code> EC2 key pair, then run terraform plan, terraform validate, and finally terraform apply inside the Terraform templates folder (if needed, please refer to the previous chapter for details on how to do all of this).</p></div>
<div class="section" title="Initializing Jenkins"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec19"/>Initializing Jenkins</h1></div></div></div><p>Once Terraform has finished the deployment, you will get the Jenkins EIP value in the outputs. Do a hostname lookup on it and load the resulting address in your browser. You should see the <span class="strong"><strong>Getting Started</strong></span> page (screenshots and instructions in previous chapter):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Unlock jenkins</li><li class="listitem" style="list-style-type: disc">Install suggested plugins</li><li class="listitem" style="list-style-type: disc">Create an Admin user</li></ul></div></div>
<div class="section" title="Configuring Jenkins jobs"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec20"/>Configuring Jenkins jobs</h1></div></div></div><p>Prior to recreating the Continuous Integration pipeline job, we need a S3 bucket for our YUM repository. Create a bucket (unless you've kept the old one around), update the <code class="literal">demo-app/Jenkinsfile</code> script accordingly then commit and push Git changes upstream.</p><div class="section" title="demo-app pipeline"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec41"/>demo-app pipeline</h2></div></div></div><p>Refer to the <span class="emphasis"><em>Setting up the pipeline</em></span> steps from the previous chapter to create the Continuous Integration job. Let us call it <code class="literal">demo-app</code> this time around. The script path remains the same (<a class="ulink" href="https://git-codecommit.us-east-1.amazonaws.com/v1/repos/demo-app">https://git-codecommit.us-east-1.amazonaws.com/v1/repos/demo-app</a>).</p><p>You should now have this:</p><p>
</p><div class="mediaobject"><img src="graphics/image_05_002.jpg" alt="demo-app pipeline"/></div><p>
</p><p>The pipeline is going to fail as we do not have our YUM repository configured yet:</p><p>
</p><div class="mediaobject"><img src="graphics/image_05_003.jpg" alt="demo-app pipeline"/></div><p>
</p><p>The repository contents have already been uploaded to S3 by this first job run. Now we need to update the <code class="literal">salt/states/yum-s3/files/s3.repo</code> file with the S3 URL and set the repository to <code class="literal">enabled</code>. Commit and push the Salt changes to the Git repository, then pull and apply on the Jenkins node.</p><p>A subsequent pipeline run takes us a step further:</p><p>
</p><div class="mediaobject"><img src="graphics/image_05_004.jpg" alt="demo-app pipeline"/></div><p>
</p><p>This time the failure is because our downstream job is not quite ready yet. Let us fix that next.</p></div><div class="section" title="demo-app-cdelivery pipeline"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec42"/>demo-app-cdelivery pipeline</h2></div></div></div><p>From the Jenkin's dashboard, we select  <span class="strong"><strong>New Item</strong></span>:</p><p>
</p><div class="mediaobject"><img src="graphics/image_05_005.jpg" alt="demo-app-cdelivery pipeline"/></div><p>
</p><p>We shall call it <code class="literal">demo-app-cdelivery</code>:</p><p>
</p><div class="mediaobject"><img src="graphics/image_05_006.jpg" alt="demo-app-cdelivery pipeline"/></div><p>
</p><p>This job will be triggered by another one, so no need to poll SCM. Also, we have a parameter being passed to this pipeline:</p><p>
</p><div class="mediaobject"><img src="graphics/image_05_007.jpg" alt="demo-app-cdelivery pipeline"/></div><p>
</p><p>Finally, we set the location of the <code class="literal">Jenkinsfile</code> (<a class="ulink" href="https://git-codecommit.us-east-1.amazonaws.com/v1/repos/demo-app-cdelivery">https://git-codecommit.us-east-1.amazonaws.com/v1/repos/demo-app-cdelivery</a>):</p><p>
</p><div class="mediaobject"><img src="graphics/image_05_008.jpg" alt="demo-app-cdelivery pipeline"/></div><p>
</p><p>Do you remember the VPC details we specified in the Packer <code class="literal">variables</code> file and also the <code class="literal">Jenkinsfile</code> for this pipeline? We need to set those to match our current VPC:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Update the variables in <code class="literal">packer/demo-app_vars.json</code><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">srcAmiId</code> could be the latest AmazonLinux AMI</li><li class="listitem" style="list-style-type: disc"><code class="literal">subnetId</code> is the ID of the Private subnet</li><li class="listitem" style="list-style-type: disc"><code class="literal">vpcId</code></li></ul></div></li><li class="listitem" style="list-style-type: disc">Update <code class="literal">demo-app-cdelivery/Jenkinsfile</code>:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">In the <span class="strong"><strong>Deploy AMI</strong></span> stage:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">secGroup</code>is the ID of the <code class="literal">demo-app</code> security group</li><li class="listitem" style="list-style-type: disc"><code class="literal">subnetId</code>is the ID of the Private VPC subnet as mentioned earlier</li></ul></div><p>
</p></li><li class="listitem" style="list-style-type: disc">In <span class="strong"><strong>Run AB test</strong></span><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">elbUri</code>is the endpoint address of the <code class="literal">demo-app-elb</code> ELB</li></ul></div><p>
</p></li></ul></div><p>
</p></li><li class="listitem" style="list-style-type: disc">Commit and push your changes.</li></ul></div><p>Here, we are with our two pipelines ready for action:</p><p>
</p><div class="mediaobject"><img src="graphics/image_05_009.jpg" alt="demo-app-cdelivery pipeline"/></div><p>
</p><p>Let us trigger a <code class="literal">demo-app</code> run by changing the <code class="literal">$full_name</code> in <code class="literal">demo-app/src/index.php</code>. You should see it running after detecting the Git change. At the end of the run, it should trigger the downstream <code class="literal">demo-app-cdelivery</code> pipeline, and after another approximately10 minutes, there should be a brand new <code class="literal">demo-app AMI</code> waiting for you (check the AWS console).</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note57"/>Note</h3><p>Please remember to delete any AWS resources used in the mentioned examples (VPC, EC2, S3, IAM, CodeCommit, and so on) to avoid unnecessary charges.</p></div></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec21"/>Summary</h1></div></div></div><p>In this chapter, we extended our Jenkins pipeline to deploy and test our application artifact on an EC2 instance in a VPC environment. You learned how to use Packer to template the provisioning of instances as well as how to use Serverspec to apply extra verification of our infrastructure.</p><p>In the next chapter, we are going to finalize our Jenkins pipeline setup by adding the Continuous Deployment element to it. We will examine ways to deploy AMIs created during the Delivery stage into a production environment.</p></div></body></html>