- en: Instrumenting Services
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务的监控
- en: In the previous chapters, we used data from *cAdvisor* to scale services automatically.
    Specifically, Prometheus was firing alerts if memory limits were reached. When
    memory utilization was over the limit, we were scaling the service associated
    with the data. While that approach is a good start, it is far from enough for
    the type of the system we’re building. As a minimum, we need to measure response
    times of our services. Should we look for an exporter that would provide that
    information?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们使用了来自 *cAdvisor* 的数据来自动扩展服务。具体来说，当内存限制达到时，Prometheus 会触发警报。当内存使用超过限制时，我们会扩展与数据相关联的服务。虽然这种方法是一个好的开始，但对于我们正在构建的系统类型来说，远远不够。最低限度，我们需要测量服务的响应时间。我们是否应该寻找一个可以提供这些信息的导出器？
- en: The chances are that your first thought would be to use [haproxy_exporter](https://github.com/prometheus/haproxy_exporter).
    If all public requests are going through it, it makes sense to scrape response
    times and set some alerts based on collected data. That model would be in line
    with the most of the other monitoring systems. The only problem with that approach
    is that it would be almost useless.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你的第一个想法可能是使用 [haproxy_exporter](https://github.com/prometheus/haproxy_exporter)。如果所有公共请求都经过它，抓取响应时间并基于收集到的数据设置一些警报是有意义的。这个模型与大多数其他监控系统的运作方式一致。唯一的问题是，这种方法几乎没什么用处。
- en: Not all requests are going through the proxy. Services that do not need to be
    accessed publicly are not hooked into the proxy. For example, *Docker Flow Swarm
    Listener* cannot be accessed. It does not publish any port, nor it has an API.
    It listens to Docker Socket and sends information to other services (e.g. *Docker
    Flow Proxy*, *Docker Flow Monitor*, and so on). It is entirely invisible to the
    proxy. We could overlook this lack of information if that were the only problem
    behind the idea of monitoring the proxy.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有请求都通过代理。那些不需要公开访问的服务并未与代理连接。例如，*Docker Flow Swarm Listener* 无法被访问。它没有公开任何端口，也没有
    API。它监听 Docker Socket 并将信息发送给其他服务（例如 *Docker Flow Proxy*、*Docker Flow Monitor*
    等）。它对代理完全不可见。如果这就是监控代理的唯一问题，我们可能会忽视这种信息的缺乏。
- en: When a request enters the proxy, it is forwarded to a service based on request
    paths, domains, and a few other criteria. By scraping metrics from the proxy,
    we would know only response times of those requests. In many cases, a service
    that receives a request forwarded from the proxy is making other requests. For
    example, *go-demo* communicates with *MongoDB*. A service that receives a request
    from the proxy might make many requests to other services. The proxy does not
    know about any of those. It receives a request, forwards it, waits for a response,
    and re-sends it to the client that initiated the communication. It is oblivious
    of any other processes or requests happening in the middle. As a result, we would
    know the duration of a request that enters the proxy but would be oblivious what
    are response times of each service involved in serving those requests.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 当请求进入代理时，它会根据请求路径、域名和其他一些标准转发到一个服务。通过从代理中抓取指标，我们只会知道这些请求的响应时间。在许多情况下，接收来自代理的请求的服务还会向其他服务发起请求。例如，*go-demo*与*MongoDB*进行通信。接收来自代理的请求的服务可能会向其他服务发起许多请求。代理对此一无所知。它接收请求，转发请求，等待响应，并将其重新发送到发起通信的客户端。它对中间发生的任何其他进程或请求毫不知情。因此，我们只能知道进入代理的请求的持续时间，但无法得知每个参与处理这些请求的服务的响应时间。
- en: Without the knowledge about response times of each service, we cannot deduce
    which one needs to be scaled. If a response time of a backend is high, should
    we scale that same backend or the database it uses?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有关于每个服务响应时间的知识，我们无法推断出哪个服务需要扩展。如果一个后端的响应时间很高，应该扩展这个后端还是它使用的数据库？
- en: To make things more complicated, response times are not the only metrics we
    need. We might be interested in failure rates, paths, methods, and a few other
    pieces of additional data. And all that needs to be related to a particular service,
    or even a concrete replica of a service
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 事情变得更加复杂的是，响应时间并不是我们需要的唯一指标。我们可能还会关注失败率、路径、方法以及其他一些附加数据。而所有这些数据需要与特定的服务或甚至某个具体的服务副本相关联。
- en: If your memory serves you well, you might remember that I said that **my advice
    is to always start with exporters, and instrument your services only if you require
    metrics that are not provided by one of the existing exporters**. Well… We reached
    that point when exporters are not enough. We need to instrument our services and
    gather more detailed metrics.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的记忆不错，你可能记得我说过**我的建议是始终从导出器开始，只有在现有导出器没有提供所需指标时，才为你的服务添加监控**。嗯……我们已经到了导出器不足的阶段。我们需要为我们的服务添加监控，并收集更详细的指标。
- en: We’ll limit the focus to only a few metrics. Specifically, we’ll explore ways
    to collect error counts, response times, status codes, and a few other metrics.
    Do not take that as a sign that other types are not needed. They are. However,
    we need to keep the scope limited and produce tangible results within a decent
    number of pages. Otherwise, we could just as well start competing with [Encyclopedia
    Britannica](https://en.wikipedia.org/wiki/Encyclop%C3%A6dia_Britannica). I will
    assume that you will take those examples for what they are and use them as a base
    for your own system. Error rates, response times, and status codes might be the
    most common types of metrics, but they are almost certainly not the only ones
    you need.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把焦点限制在少数几个指标上。具体来说，我们将探索如何收集错误计数、响应时间、状态码以及其他几个指标。不要把这个当作其他类型指标不重要的标志。它们是必要的。然而，我们需要将范围保持在一个合理的限度内，并在一定页数内产生可行的结果。否则，我们完全可以开始与[大英百科全书](https://en.wikipedia.org/wiki/Encyclop%C3%A6dia_Britannica)竞争。我假设你会把这些示例当作它们的本意，并以此为基础构建你自己的系统。错误率、响应时间和状态码可能是最常见的指标类型，但它们几乎肯定不是你需要的唯一类型。
- en: With the scope limited to only a few metrics, we should spend a bit of time
    discussing the data we would need.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在范围仅限于少数几个指标的情况下，我们应该花一点时间讨论我们需要的数据。
- en: Defining Requirements Behind Service Specific Metrics
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义服务特定指标背后的需求
- en: We might need different types of metrics. Some of them could be simple counters.
    A good example is errors. We might want to count them and react when their numbers
    reach certain thresholds. That in itself might not be enough, and we should be
    able to differentiate errors depending on a function or part of the service that
    produced them.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能需要不同类型的指标。其中一些可能是简单的计数器。一个很好的例子是错误。我们可能希望计数错误，并在错误数量达到某个阈值时做出反应。仅此可能还不够，我们应该能够根据产生错误的函数或服务的某个部分来区分错误。
- en: How about more complex metrics? Response times are another good example.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 那么更复杂的指标呢？响应时间就是另一个很好的例子。
- en: We might need a metric that will provide request response times. That might
    lead us towards having something like `resp_time 0.043` as the metric. It has
    a name (`resp_time`) and value in seconds (`0.043`). If we’d implement a metric
    like that, we’d soon discover that we need more. Having the information that the
    system responses are slow does not give us a clue which part of it is misbehaving.
    We need to know the name of the service.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能需要一个提供请求响应时间的指标。这可能会引导我们产生类似`resp_time 0.043`这样的指标。它有一个名称（`resp_time`）和以秒为单位的值（`0.043`）。如果我们实现了这样的指标，我们很快会发现我们还需要更多。仅仅知道系统响应慢并不能告诉我们是哪一部分出现了问题。我们需要知道服务的名称。
- en: We might not be able to instrument all the services in our clusters. If we take
    `go-demo` stack as an example, it consists of two services. It has a backend and
    a MongoDB. The backend is in our control, and we can easily extend it by adding
    instrumentation. The database is a different story. While we can (and should)
    use [MongoDB Exporter](https://github.com/dcu/mongodb_exporter), it provides data
    related to the server status. What we need are metrics that we can relate to the
    backend service. We need to know whether a request sent to the `go-demo` stack
    is slow because of an issue in the backend or the database. Assuming that we are
    not going to “adapt” MongoDB to our own needs, we should try to answer that and
    few other questions by extending metrics inside services we’re controlling.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能无法为集群中的所有服务添加监控。如果以`go-demo`栈为例，它由两个服务组成。它有一个后端和一个MongoDB。后端在我们的控制下，我们可以通过添加监控来轻松扩展它。数据库则是另一回事。虽然我们可以（并且应该）使用[MongoDB
    Exporter](https://github.com/dcu/mongodb_exporter)，它提供的是与服务器状态相关的数据。我们需要的是能够与后端服务相关联的指标。我们需要知道，发送到`go-demo`栈的请求是否因为后端或数据库的问题而变慢。假设我们不会“调整”MongoDB来满足我们的需求，我们应该尝试通过扩展我们控制的服务内的指标来回答这个问题以及其他一些问题。
- en: We can use request path and method. If we add it to our metric, it should give
    us fairly good granularity of information. Depending on the path and the method,
    we can know whether the metric is related to the database or is limited to the
    internal processes of the service. We could also add query, but that would go
    too far. It would record almost each request separately and might result in too
    much memory and CPU usage when stored in Prometheus. Our updated metric could
    be as follows.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用请求路径和方法。如果将其添加到我们的度量标准中，它应该能提供相当好的信息粒度。根据路径和方法，我们可以知道该度量标准是否与数据库相关，或者仅限于服务的内部流程。我们也可以添加查询，但那样做就有些过头了。它几乎会单独记录每个请求，可能会导致存储在
    Prometheus 中时过多的内存和 CPU 使用。我们更新后的度量标准可能如下所示。
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
