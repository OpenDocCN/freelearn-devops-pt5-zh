<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch04"/>Chapter 4. Building Multicontainer Applications</h1></div></div></div><p>In the last few chapters, we built some cool stuff with Puppet and Docker. It has all been straight forward. Now, we are getting into the more complex topics such as how to keep a state and why to keep a state in a container. Docker is known to couple hand in hand with the micro service architecture, where the container would for the most part just be receiving data and transforming it into an output for a downstream application or data source to ingest. Thus, the container never keeps any state. Docker does not limit itself to such applications. In this chapter, we are going to prove this by building a fully functional Bitbucket server with a separate Postgres backend. We will mount the data that is stateful to the underlying host and decouple the applications from that state.</p><p>The other good feature of building Bitbucket is that you can use it for your Git server at home to make sure that all your future modules are in source control. Atlasssian offers a $10 dollar license for start-ups or developers that allow up to 10 users, which is a bargain.</p><p>In this chapter, we will build applications using standard manifest resources and then Docker Compose. Before we jump into coding, let's talk a little more about decoupling the state of an application from the actual application itself. The following are the topics that we will cover in this chapter:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Decoupling a state</li><li class="listitem" style="list-style-type: disc">Docker_bitbucket (manifest resources)</li><li class="listitem" style="list-style-type: disc">Docker_bitbucket (Docker Compose)</li></ul></div><div><div><div><div><h1 class="title"><a id="ch04lvl1sec20"/>Decoupling a state</h1></div></div></div><p>In this topic, we are<a id="id110" class="indexterm"/> going to talk about state in containers. This topic will be all theory, but don't worry, we are going to put that theory to test when we write our module. We need to understand the theory behind state versus stateless so that in future, when writing your own Puppet modules to ship Docker, you can make the right design choice<a id="id111" class="indexterm"/> about states.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec26"/>State versus stateless</h2></div></div></div><p>So, we briefly touched on<a id="id112" class="indexterm"/> the topic of state versus stateless in the preceding section, but now, let's get into the nuts and bolts of it. So, let's look at two example applications: one with state and one without. First, we will start with a redis container. Its job is to be the backend store for activemq. The application that uses the queue has logic to check whether the message has been received and expects a response. If that fails, it will retry to send the message. Thus, the queue itself is stateless. We are using redis as a cache. There is no need to give the redis container state, as the information it holds is ephemeral. If the container fails, we just respawn a new one and it will cache the queue again.</p><p>Now, let's look at a container that needs state and the options we have to keep state. In the application, we are going to build two containers. One is Bitbucket itself, and then Postgres will be used as the backend database. So, both of these need state. Let's look at Bitbucket first. If we don't give states to the Bitbucket server, every time we restart the container, we would lose all the projects that we checked in via Git. That doesn't sound like it would be a viable solution. Now, let's look at the options that we have to give to the container's state. First, we could add volume to our Dockerfile:</p><div><img src="img/B05201_04_01.jpg" alt="State versus stateless"/></div><p>This will give the container state; we can reboot the application and all the data will be there, which is good. That is what we want. There is a downside to this method. Volume resides inside the container and is not decoupled from the application. So when we run into issues with this method, the main operational issue is when we need to update the version of the application in the container. As all our data lives in the container, we can't just pull the latest. So we are stuck with the available options. Now, let's look at how to map a folder from localhost to the container. We do this using <code class="literal">/data:/var/atlassian/application-data/bitbucket</code>. The left side of the colon is the localhost running the Docker daemon and the right side is the container.</p><p>Docker uses fully qualified paths, so it will create the <code class="literal">/data</code> directory. Now, we have decoupled our application from our data. If we want to update the version of Bitbucket, all we would need to do is change the <code class="literal">image</code> tag in our Puppet code to the new version. Then, we would run Puppet. Once that is complete, the new version of Bitbucket will boot with our existing data. Now, there is a cost to using this method as well. We have now tied this container to the one host. If you are using schedulers such as Kubernetes or Docker Swarm, this probably<a id="id113" class="indexterm"/> isn't the best idea. This problem has been solved by the new volume driver added to the Docker engine 1.8 and above. This allows us to create storage objects that are external of the host on which the engine is running.</p><div><div><h3 class="title"><a id="note08"/>Note</h3><p>This is out of the scope of this book, but if you would like to do some more reading about the technology, I <a id="id114" class="indexterm"/>would recommend that you visit <a class="ulink" href="https://clusterhq.com/flocker/introduction/">https://clusterhq.com/flocker/introduction/</a>. Now, we have a good understanding of state versus stateless containers. Let's start the fun bit and get coding!</p></div></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec21"/>Docker_bitbucket (manifest resources)</h1></div></div></div><p>In this topic, we are going to write our module that will install Atlassian's Bitbucket. The application will be comprised<a id="id115" class="indexterm"/> of two containers, among which one will be Postgres as we mentioned earlier. We are actually going to tweak the container to secure the backend and make it only accessible to Bitbucket. Then, we will<a id="id116" class="indexterm"/> run the Bitbucket container, configure the user it will run as, and then map the filesystem from the host machine to the container.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec27"/>Creating our module skeleton</h2></div></div></div><p>This is just going to be a<a id="id117" class="indexterm"/> quick refresher, as we covered this in the last chapter. If you are still not feeling comfortable with this step, I would recommend you to go over the last chapter again until you have a good grasp of the process.</p><p>So, we are going to open up our terminal and change directory or cd into the root of our Vagrant repo. Then, we will type <code class="literal">vagrant up</code>, and once the box is up, we will use SSH into it with <code class="literal">vagrant ssh</code>. The next step is to change to root (<code class="literal">sudo -i</code>). Now that we are root, let's change the directory to <code class="literal">/vagrant</code>, which maps back to our local machine. We are then going to issue the <code class="literal">puppet module generate &lt;AUTHOR&gt;-docker_bitbucket</code> command. Again, there are a few more tweaks that we need, but they are in the last chapter, so let's not repeat ourselves here. Once you have completed the outstanding task, you can move on to the next chapter.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec28"/>Let's code</h2></div></div></div><p>Now, we have our<a id="id118" class="indexterm"/> module skeleton and we have moved it into the <code class="literal">modules</code> directory in the root of our Vagrant environment. We need to add two new files: <code class="literal">install.pp</code> and <code class="literal">params.pp</code>. Our module should look like as shown in the following screenshot:</p><div><img src="img/B05201_04_02.jpg" alt="Let's code"/></div><p>In this example, we have a few new things going on, so I have not used <code class="literal">params.pp</code> in this example. This gives you a perfect opportunity to use the knowledge that you gained in the last chapter and apply it. So, for now, we will leave <code class="literal">params.pp</code> empty. Seeing as we are not putting parameters in <code class="literal">init.pp</code>, let's look at that first:</p><div><img src="img/B05201_04_03.jpg" alt="Let's code"/></div><p>As you can see in the preceding screenshot, we are only calling the <code class="literal">docker_bitbucket::install</code> class. We can now move on to the chunky <code class="literal">install.pp</code> class. Again, we<a id="id119" class="indexterm"/> are going to brake this down into three parts. This will make it easier to explain the logic of the class. Let's look at part one, which is as follows:</p><div><img src="img/B05201_04_04.jpg" alt="Let's code"/></div><p>In this top section of the class, we are installing the <code class="literal">device-mapper-libs</code> package. This is a prerequisite for the RHEL family and Docker. The next thing that we are declaring is the Docker class. In this resource, we are defining the version of Docker that we want to be installed, the TCP bind that Docker will use, and lastly, the Unix socket that Docker will bind to. This is the same configuration that we used to define our Docker daemon in the last chapter. This will stay fairly static until we move into Docker schedulers. Let's now move to Postgres:</p><div><img src="img/B05201_04_05.jpg" alt="Let's code"/></div><p>First, we will define the image of Postgres that we would like to use. For this example, we are using Postgres 9.2. So, the correct tag from Docker Hub is <code class="literal">postgres:9.2</code>. Now, let's look at the <code class="literal">docker::run</code> class; this is where all the configurations for Postgres will be defined. So, you can see that we are calling the image that we set in the preceding resource <code class="literal">postgres:9.2</code>. We will then set the hostname as <code class="literal">bitbucket-db</code>. This setting is important, so let's store it into our memory for later use.</p><p>Let's look at the <code class="literal">env</code><a id="id120" class="indexterm"/> resource declaration as we have a bit going on there. In this one line, we are declaring the Postgres user, the database password, the name of the database that we will connect with Bitbucket, and lastly the path where Postgres with store the database. Lastly, we are declaring our volumes as <code class="literal">/root/db:/var/lib/postgresql/data/pgdata</code>.</p><p>As mentioned earlier, the left-hand side of the colon is mapping the the local machine and the right is mapping the container. There are two major call outs with our configuration. First, the <code class="literal">/root/db</code> folder is arbitrary and not what you would use in production. The second is that you will note that the left side of the colon, <code class="literal">/var/lib/postgresql/data/pgdata</code>, and the value in env, <code class="literal">PGDATA</code>, are the same. This is no coincidence; that folder holds the only state that we care about: the actual database. That is the only state that we will keep. Nothing more and nothing less. You will note that we have not exposed any ports from this container. This is by design. We are going to link our Bitbucket container to Postgres. What does link mean? It means that by default, the Postgres image exposes port 5432. This is the port that we will use to connect to our database. By linking the containers, only the Bitbucket container has access to 5432; if we exposed the port (5432:5432), any other application that has access to the host instance could hit the port. Thus, linking is much more secure. So, we need to remember a few things from this section of code for later use: the hostname and the entire env line. For now, let's move on to the Bitbucket container:</p><div><img src="img/B05201_04_06.jpg" alt="Let's code"/></div><p>As you can see in the preceding screenshot, the image resources are the same, but instead of calling Postgres, we are going to call <code class="literal">atlassian/bitbucket-server</code>. The next resource we will declare<a id="id121" class="indexterm"/> is the ports resource. You will note that we are declaring two ports <code class="literal">7990:7990</code>, which will be the port that we hit the web UI on, and <code class="literal">7999:7999</code>, which is the port that Bitbucket uses for SSH. We will set the username to <code class="literal">root</code>. This is recommended in Atlassian's <a id="id122" class="indexterm"/>documentation (<a class="ulink" href="https://hub.docker.com/r/atlassian/bitbucket-server/">https://hub.docker.com/r/atlassian/bitbucket-server/</a>).</p><p>Next, we are going to map our volume drive. In this case, we are only going to map Bitbucket's data directory. This is where all our Git repo, user information, and so on is kept. Again, <code class="literal">/data</code> is an arbitrary location; you could use any location you like. The important location to note is on the left-hand side of the colon, <code class="literal">/var/atlassian/application-data/bitbucket</code>.</p><p>Lastly, we link our two containers. Another benefit of linking containers is that the Docker daemon will write to both the containers' <code class="literal">/etc/hosts</code> files with their hostname and IP address. So, the containers have no issue talking to each other. There is no need to worry about the IP address, as it is arbitrary and is looked after by the Docker daemon. Now that we have written our module, we can build our application.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec29"/>Running our module</h2></div></div></div><p>The first thing that <a id="id123" class="indexterm"/>we need to do is forward the correct ports on our <code class="literal">servers.yml</code> file that allow us to hit the ports we forwarded to Bitbucket. To do this, we need to modify the file so that it looks as shown in the following screenshot:</p><div><img src="img/B05201_04_07.jpg" alt="Running our module"/></div><p>So, let's open our<a id="id124" class="indexterm"/> terminal and change the directory to the root of our Vagrant repo and run <code class="literal">vagrant up</code>. You should get the following output after this:</p><div><img src="img/B05201_04_08.jpg" alt="Running our module"/></div><p>Now that our application is built, we can go to <code class="literal">http://127.0.0.1:7990</code>. We should get the following page:</p><div><img src="img/B05201_04_09.jpg" alt="Running our module"/></div><p>Earlier in the topic, we had remembered some details about our Postgres install. Now is the time to use them, so let's begin. The first thing that we need to do is use an external database. The next <a id="id125" class="indexterm"/>piece of configuration we need to choose is the database type. Of course, we are going to choose Postgres.</p><p>The hostname will be set to the hostname of the <code class="literal">bitbucket-db</code> container, the port is <code class="literal">5432</code>, and the database name is <code class="literal">bitbucket</code>, as we set in our code. We will use PostgreSQL as the username and the password will be <code class="literal">Gr33nTe@</code>. Refer to the following screenshot to know more:</p><div><img src="img/B05201_04_10.jpg" alt="Running our module"/></div><p>Next, click on the <strong>Test</strong><a id="id126" class="indexterm"/> button, and we should get the <strong>Successfully established database connection.</strong> message, as shown in the following screenshot:</p><div><img src="img/B05201_04_11.jpg" alt="Running our module"/></div><p>I will let you finish the rest of the setup. But what we just set up was not simple, and now, we have a very solid base to move on to more complex applications.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec22"/>Docker_bitbucket (Docker Compose)</h1></div></div></div><p>In this topic, we are <a id="id127" class="indexterm"/>going to build the same Bitbucket application. The difference this time is that we are going to use <code class="literal">docker-compose</code> as a <code class="literal">.erb</code> file instead of the resource declarations in a manifest.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec30"/>Let's code – take 2</h2></div></div></div><p>We covered a lot of <a id="id128" class="indexterm"/>what happens under the hood in the last topic. We will not be repeating ourselves, so this topic will be just about the code. We are going to keep both <code class="literal">init.pp</code> and <code class="literal">params.pp</code> the same as we did in the last topic. So, let's jump straight to <code class="literal">install.pp</code>. It will look very similar to <code class="literal">install.pp</code> from the last chapter:</p><div><img src="img/B05201_04_12.jpg" alt="Let's code – take 2"/></div><p>All the magic happens in our template file. So, let's jump to our <code class="literal">.erb</code> file that lives in the <code class="literal">templates</code> folder in the root of our module:</p><div><img src="img/B05201_04_13.jpg" alt="Let's code – take 2"/></div><p>As you can see in our <code class="literal">.erb</code> file in the preceding screenshot, all the configurations are familiar. There are<a id="id129" class="indexterm"/> absolutely no changes to what we covered in our last topic.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec31"/>Running our module – take 2</h2></div></div></div><p>Let's open our terminal<a id="id130" class="indexterm"/> and change the directory to the root of our Vagrant repo and run <code class="literal">vagrant up</code>. You should get the following output:</p><div><img src="img/B05201_04_14.jpg" alt="Running our module – take 2"/></div><p>Now, let's just go to <code class="literal">http://127.0.0.1:7990</code>, and we should get the following page:</p><div><img src="img/B05201_04_15.jpg" alt="Running our module – take 2"/></div><p>Just follow the same <a id="id131" class="indexterm"/>setup as in the preceding topic to configure Bitbucket. You can use a trail license to try the <a id="id132" class="indexterm"/>application, or as I mentioned earlier, there is a development/startup license at <a class="ulink" href="https://bitbucket.org/product/pricing?tab=server-pricing">https://bitbucket.org/product/pricing?tab=server-pricing</a> with the proceeds of the $10 license going to charity.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec23"/>Summary</h1></div></div></div><p>By building a multicontainer application, we learned and covered a lot. We first looked at state versus stateless containers, the pros and cons of having state, and what design choices we have to keep a state. We then looked at linked containers and how they communicate with each other through their hostfiles. All the topics in this chapter will set us up with the knowledge that we need to move forward with topics such as service discovery and container schedulers.</p></div></body></html>