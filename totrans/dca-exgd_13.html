<html><head></head><body>
        

                            
                    Introduction to the Docker Enterprise Platform
                
            
            
                
<p class="mce-root">In the previous chapters, we talked about Docker's features and Docker environments. We introduced the concepts of containers and looked at how we can deploy applications to orchestrated environments. All the features we saw were based on Docker Community Edition. In this chapter, we will learn about all the various Docker editions and their differences before introducing the Docker Enterprise platform.</p>
<p class="mce-root">In this chapter, we will introduce the different Docker editions and tools. We will also review the concept of <strong>Container as a Service</strong> (<strong>CaaS</strong>) and learn about what we need in these kinds of environments. Docker provides an enterprise-ready CaaS platform and we will review all of its components.</p>
<p>We will cover the following topics in this chapter:</p>
<ul>
<li>Reviewing the Docker editions</li>
<li>Understanding CaaS</li>
<li>The Docker Enterprise platform</li>
<li>Planning your Docker Enterprise deployment</li>
</ul>
<p class="mce-root">Let's start this chapter by learning about all the different Docker editions and their specific features.</p>
<h1 id="uuid-b987f443-48d1-4688-add5-ad3da134bbf1" class="mce-root">Reviewing the Docker editions</h1>
<p>In this section, we will have a quick review of the different Docker editions. We have been using Docker Community in previous chapters, but now, it is time to learn about Docker Enterprise. This is because it is very important for the Docker Certified Associate exam. In fact, it could relate to more than 50% of the knowledge required for the exam because all of the concepts you'll be learning about will relate to this platform.</p>
<p>Docker Community is the Docker platform we use while developing container-based applications. It is free to use and is supported on GitHub (<a href="https://github.com/docker/docker-ce">https://github.com/docker/docker-ce</a>) and Docker Forums (<a href="https://forums.docker.com/">https://forums.docker.com/</a>).</p>
<p>Docker Enterprise is an enterprise-ready solution. Docker/Mirantis provides <em>24/7</em> support and is licensed by subscription.</p>
<h2 id="uuid-08781791-6fdb-4d1b-8476-4bee5eb087c1">Docker Community</h2>
<p>When we talk about Docker Community Edition, also known as <strong>docker-ce</strong>, we are just referring to Docker Engine (daemon), although there are other community software products made by Docker's team:</p>
<ul>
<li><strong>Docker Toolbox</strong>: This was the first approach available for Microsoft Windows and Apple Mac users. Before Windows containers, this was the only way of using Docker on Windows nodes. It provides a desktop environment with many tools and shortcuts for most components and actions.</li>
<li><strong>Docker Machine</strong>: Docker Machine allows us to provision Docker hosts. It comes with some predefined provisioners and we can extend this list with external binaries to deploy nodes with the most popular cloud providers and on-premises infrastructures.</li>
<li><strong>Docker Desktop</strong>: This was an evolution of the Docker Toolbox environment on Windows Professional environments. Developers were very happy with the experience they had with Docker Toolbox. In response, Docker created a desktop environment capable of launching a small Kubernetes environment, while also including application templates to help developers create simple applications with just a few mouse clicks.</li>
</ul>
<p>Docker Community Edition provides a complete Docker Engine platform. Hence, we can create a cluster with either Docker Swarm or Kubernetes. All Community Edition features have been covered in previous chapters â€“ we have never talked about any Enterprise-specific integrations. Docker Swarm does not provide <strong>role-based access control</strong> (<strong>RBAC</strong>) for user management. We also have to provide a solution for publishing applications securely. Remember that Docker just provides a router mesh and host publishing features and that they are not secure. For many users, Docker Swarm, with a couple of tweaks, is more than enough. It is easy to learn and manage and also provides resilience and high availability for core components.</p>
<p>Kubernetes can be deployed on top of Docker Community Edition. We will just use Docker Engine as the runtime for the Kubernetes cluster. This is quite common as it's the most-used solution nowadays. Kubernetes provides a rich ecosystem and comes with some out-of-the-box features required for production. But, on the other hand, some details, such as networking, require third-party solutions. Kubernetes has a different approach to the world of containers. Docker follows the "<em>batteries included but interchangeable"</em> approach, providing everything required to work out of the box, although we can change most of its components. On the other hand, Kubernetes was made with the "<em>everything should be pluggable" </em>mindset. Kubernetes has a richer ecosystem because there are many solutions around its core pieces. These help it grow faster and bigger than Docker.</p>
<h2 id="uuid-8be40a30-1948-4a0e-8c39-2d7345bc77b7">Docker Enterprise</h2>
<p>Docker Enterprise has everything that's missing from Docker Swarm. It provides a full CaaS platform that's based on two components: Docker <strong>Universal Control Plane</strong> (<strong>UCP</strong>) and <strong>Docker Trusted Registry</strong> (<strong>DTR</strong>). During the last European DockerCon, in December 2018, Docker Desktop Enterprise was announced and it was stated that it would include desktop functionality for developers. Docker Desktop Enterprise allows developers to create applications easily using Docker. They can also test their developed containers on Kubernetes locally or even choose which production environment they want to test in to ensure that their applications will run smoothly in production. Docker Desktop was created with developers in mind and Enterprise helps them avoid friction between development and production.</p>
<p>At the time of writing this book, Docker can be found under two different product brands. Mirantis bought the Docker Enterprise product, while Docker maintains Docker Community software and their desktop product. The complete Enterprise platform will be part of the Mirantis catalog.</p>
<p>Therefore, Docker Enterprise Edition covers the following products:</p>
<ul>
<li><strong>Docker Enterprise Engine</strong>: Docker Engine is required for the Docker Enterprise platform; it provides all the required runtime features. There are slight differences between the Community and Enterprise editions. In fact, the most important one is to do with support. Docker Enterprise provides an enterprise <em>24/7</em> support subscription option and a working hours support subscription option. The Docker Community edition does not provide such support. This slight difference will probably persuade enterprise users to use Docker Enterprise Edition.</li>
<li><strong>Docker UCP</strong>: The control plane for the cluster is also included in Docker Enterprise Edition. This product is called Docker UCP. It also provides a Kubernetes production-ready platform out of the box, on top of a production-ready Docker Swarm cluster. It is probably the best option for getting a Kubernetes cluster with minimal effort. This cluster distribution is also supported by Docker, which means that all Kubernetes integrations have been fully tested on the Docker Enterprise platform. The bad thing about this is that Kubernetes releases have to be frozen during a product's lifetime. At the time of writing this book, the currently supported and distributed Kubernetes release is 1.14, while it is generally available as 1.17 in the Community edition. This is normal for enterprise products. Everything must be tested and verified before moving to a newer release, and this takes time.</li>
<li><strong>Docker Trusted Registry</strong>: A registry is always required to work with containers. Although Docker developed <strong>Docker Registry</strong><em><strong> </strong></em>and it is open source, it is not enough for production. It provides neither authentication nor authorization, which are fundamental to ensure secure access to images. We can integrate <strong>Docker Trusted Content</strong><em>,<strong> </strong></em>but this is not easy. We will need to include Notary<em> </em>services and integrate them into the rest of the deployed platform. Believe me, this is not easy. I have done it in the past and it was hard to implement and even harder to maintain. DTR includes authentication and authorization based on the RBAC model. We can have organizations, teams, and different access for different users, and we can make some of our images publicly available. We get fully featured access and image publishing control. It also includes a Docker Trusted Content implementation, with all the required components and integrations. It includes CI/CD workflow integrations for different stages and security image scanning. These features will allow us to ensure that only approved images that are free from vulnerabilities run in our production CaaS platform.</li>
<li><strong>Docker Desktop Enterprise</strong>: This is the most recently added feature at the time of writing this book. The Docker Certified Associate exam does not include any questions about it right now. Due to this, we will just provide a basic Docker Desktop introduction. This is a desktop application that provides developers with full Docker Swarm and Kubernetes environments so that they can develop and test their applications on their laptops before moving their artifacts to other stages.</li>
</ul>
<p>As we can see, there's a number of different components that are packaged in a Docker Enterprise release. If we go to <a href="https://success.docker.com/article/compatibility-matrix">https://success.docker.com/article/compatibility-matrix</a>, we can review which component releases are verified and are supported to work together. At the time of writing this book, these are the latest supported releases of each component for Docker Enterprise Edition 3.0:</p>
<ul>
<li>Docker Engine 19.03.x</li>
<li>Universal Control Plane 3.2.x</li>
<li>Docker Trusted Registry 2.7.x</li>
</ul>
<p>Docker Engine is supported on many Linux distributions (such as Red Hat/CentOS, SUSE SLES, Oracle Linux, and Ubuntu) and Windows (2016 and 2019 releases).</p>
<p>Windows nodes are only supported as worker nodes and they will only be part of a Docker Swarm orchestration. Kubernetes is not available on the Windows platform on Docker Enterprise 3.0.</p>
<p class="mce-root">In the next section, we will discuss what a CaaS platform is and how Docker provides all the expected features.</p>
<h1 id="uuid-c249c17a-7437-4a4f-945e-2c6b6493e5d4" class="mce-root">Understanding CaaS</h1>
<p class="mce-root">A CaaS platform is a platform that can be used to provide container services to users. The term <em>as a Service</em> is usually associated with cloud providers and their solutions. We will extend this terminology to on-premises environments here. We will talk about CaaS as a framework or compound of applications designed to provide a complete container-based solution to users. A CaaS solution must provide the full container workflow (build, ship, and run). There is also another new term these days: <strong>KaaS</strong> solutions. This terminology refers to <strong>Kubernetes as a Service</strong> platforms, where Kubernetes is the core of the environment. These solutions add some facilities that are not included with Kubernetes out of the box, such as monitoring, logging, and CI/CD.</p>
<p class="mce-root">CaaS and KaaS environments are aimed at users that require a complete solution. There will be administrators of the solution and clients that will consume the services provided in the environment.<br/></p>
<p>These platforms must provide the following:</p>
<ul>
<li><strong>Authentication</strong>: Users accessing the platform should be authenticated so as to only allow approved users.</li>
<li><strong>Authorization</strong>: Roles will provide different access to different users. There should be administrators and users. Each should have different levels of access and views within the platform. Actions that can be performed on containers should be inaccessible to non-authorized users.</li>
<li><strong>Runtime</strong>: All containers will run on container engines. This is a requirement. There are different engines, but Docker Engine is still the most common nowadays.</li>
<li><strong>Publishing</strong>: We use these platforms to create and run applications based on containers, but people have to be able to consume our deployed services. CaaS/KaaS platforms must provide a component that allows us to publish applications that are deployed inside our environment.</li>
<li><strong>Registry</strong>: All images must be stored somewhere. Remember, images are always required. There are no containers without images, and versioning them alongside code changes will help you track issues and new functionalities. Having a registry included in your CaaS/KaaS platform is vital.</li>
<li><strong>Status</strong>: We need to have a complete view of the statuses of all our platform components. If there's a failure, we need to know which components will be affected, whether we'll be able to push new images, and whether our services work, for instance.</li>
<li><strong>Integrations</strong>: Although, in my opinion, logging and monitoring are not strictly required, it is good to at least provide integrations to external platforms for these features. Some CaaS platforms include these services in their deployment (such as Red Hat's OpenShift, among others), but it should be easy to integrate our logging and monitoring environments. Sometimes, operations teams will have their own monitoring platforms; a CaaS platform should just forward all required events to them. CI/CD workflows are another interesting integration. If a CaaS platform can integrate development and test stages within the platform, users will be able to just code. Everything else can be automated with CI/CD tools.</li>
</ul>
<p>As we mentioned previously, these platforms will require some administrators to do all the maintenance tasks and configurations, while users will just consume the provided services to create and run their applications. There are some cloud providers that have taken a different approach. <strong>Azure Kubernetes Service</strong> (<strong>AKS</strong>), Amazon's <strong>Elastic Kubernetes Service</strong> (<strong>EKS</strong>), and <strong>Google Kubernetes Service</strong> (<strong>GKS</strong>) are the most well-known examples of these environments.</p>
<p>On these platforms, we just select the number of workers to deploy in our cluster. All maintenance tasks are managed by the cloud provider; we just configure user access and prepare some of the cloud provider's load balancers to route the traffic. Everything else is configured and deployed in Kubernetes. This is great because we get to just focus on deploying applications. We don't have to care about high availability in the environment, backups, or platform upgrades. The cloud provider will manage all these tasks for us. Such platforms also include monitoring and logging facilities that are integrated into their <strong>Platform as a Service</strong> (<strong>PaaS</strong>) environments.</p>
<p>In this section, we reviewed what we need to provide in a CaaS or KaaS platform. In the next section, we will learn about how Docker Enterprise implements these concepts.</p>
<h1 id="uuid-f154bb63-c580-48d5-8c3f-472ec32fba23" class="mce-root">The Docker Enterprise platform</h1>
<p class="mce-root">Docker Enterprise provides a CaaS platform. In this section, we will try to apply everything we know about CaaS platforms to what we understand about Docker Enterprise. We will cover many concepts in order to help you to understand how we implement end-to-end container-based solutions with Docker Enterprise. We will not cover Docker Desktop Enterprise because it is not part of the Docker Certified Associate exam.</p>
<h2 id="uuid-a39eadb6-9659-4910-ba26-4b18fa035a1f">Docker Engine</h2>
<p class="mce-root">Docker Engine is a core piece of the platform. It provides the runtime for executing the platform. Unlike Kubernetes, Docker Swarm requires Docker Engine to work. Kubernetes provides the option to use <kbd>containerd</kbd> directly or a <strong>Container Runtime Interface Optimized</strong> (<strong>CRI-O</strong> for OCI-compatible containers). Docker Engine includes Swarm mode, and we do not need any other software to implement a fully functional distributed orchestration environment. Docker Engine provides the underlying layer of execution of all platform components.</p>
<p class="mce-root">On top of Docker Engine, we will create a Docker Swarm cluster, and other Docker Enterprise components will run either as Docker Swarm services or multi-container applications. This is key because there are a few components that will run as agents in the platform, and we will automatically deploy them as <strong>global services</strong><em><strong> </strong></em>(remember these concepts). But there are also some components that must be unique within the cluster. They will run as <strong>multi-container</strong><em><strong> </strong></em>applications on top of some defined hosts. These components will use different schemas for their execution.</p>
<p>For Docker Enterprise, we will deploy Docker Enterprise Engine, along with support for specific releases. Enterprise releases have to be supported for a long time, so this affects release times. As we saw in the <em>Docker Enterprise Engine</em> section, the currently supported release is 19.03.x (at the time of writing this book), while for the Community Edition, the supported release can be different (it's currently also 19.03.6, but it was only until recently that there could be big differences between releases). This is normal because Docker engineers and support teams must verify all components' integrations and solve any issues for current Docker Enterprise releases, while at the same time evolving the product by adding new features. These features always appear on Docker Community Edition before they are fully tested and implemented for Docker Enterprise Edition.</p>
<p class="mce-root">Because we will be working in a cluster environment, we will be able to execute maintenance tasks and move workloads between nodes without service interruption. Docker Engine updates will be smooth and easy.</p>
<h2 id="uuid-d0e8f700-c66d-47d8-b484-446d99c7006f">Universal Control Plane</h2>
<p class="mce-root">UCP provides the control plane for the Docker Enterprise platform. It provides all the processes and tools you need in order to manage all your cluster components and their statuses. UCP will deploy components on master and worker nodes, as we will learn in <a href="1879ea92-ae47-4230-ac84-784d4bc73185.xhtml">Chapter 11</a>, <em>Universal Control Plane</em>. It is based on Docker Swarm orchestration, but, as we mentioned previously, the core components will run as multi-container applications. The master nodes will run the control plane processes. These processes will not run on any other node if they fail. It is important to understand that these core processes can only run on defined nodes. No other nodes can take these workloads. If we have a problem occurring on a master node and we cannot recover the master node, we need to create a new master. We will promote a worker node or install a new master after removing the old one.</p>
<p>UCP will deploy some distributed databases, and it is important to maintain their quorum. We will review a couple of common issues in <a href="1879ea92-ae47-4230-ac84-784d4bc73185.xhtml">Chapter 11</a>, <em>Universal Control Plane</em>. Remember, UCP manager nodes are very important and processes need to run on defined nodes.</p>
<p>All internal cluster communications will be encrypted using TLS. UCP manages all nodes, all components, and all their certificates. It will also provide certificates for authenticated and authorized users. We can ensure secure client-to-server communications by default.</p>
<p>The Kubernetes cluster will also be deployed with the required <strong>Container Network Interface</strong> (<strong>CNI</strong>), Calico, by default, and secured configurations. UCP provides a production-ready Docker Swarm and Kubernetes platform.</p>
<p>Cluster authentication and authorization will be managed by UCP. We will be able to integrate third-party authentication systems, such as <strong>Lightweight Directory Access Protocol</strong> (<strong>LDAP</strong>), and Active Directory. All authorization mechanisms and implementations are also included in UCP. We can provide a unified login, delegating all DTR authentication requests to UCP. This is the usual and preferred configuration. UCP provides a complete RBAC system based on resources, roles, and grants. We will have high levels of granularity to specify customized access to any resource within the cluster.</p>
<p>UCP provides a management web UI and also an API interface to access a cluster's resources. We will be able to configure all Docker Swarm and Kubernetes resources. For Kubernetes, a simple interface is provided to deploy resources' YAML files. We will use the cluster remotely. We will never allow a user access to either manager or worker nodes.</p>
<p>It is very important to disallow any non-authorized access to cluster nodes. Access via SSH to Docker hosts or directly to Docker Engine's daemon will bypass all security implementations applied by UCP.</p>
<p>The web UI will also provide some simple monitoring capabilities to verify the entire cluster's state. We can review the status of all containers, pods, services, and, in general, all resources managed by the cluster. We can also export the cluster's metrics using Prometheus' standard integrations. The web UI also provides access to container logs, and we can even use them to review the application's behavior. All this access will be managed by UCP's RBAC system.</p>
<p>Docker Swarm and Kubernetes will be available through their APIs. Kubernetes provides its own RBAC, as we learned in <a href="abcbf266-c469-4d84-ad4f-abd321a64b53.xhtml">Chapter 9</a>, <em>Orchestration Using Kubernetes</em>. Docker Swarm requires external tools. UCP provides these external tools, proxying all API requests to UCP's internal RBAC integration and providing appropriate authentication and authorization mechanisms. </p>
<p>UCP also provides an integrated component for publishing applications deployed within the cluster. This component is Interlock and, at the time of writing this book, is based on NGINX. Interlock only works with Docker Swarm deployments, monitoring the cluster's API for changes on defined services. We will define which services will be published and which headers, names, and routes should be available. All changes that are applied to the services will be automatically populated to Interlock's reverse proxy component, which will forward requests to the associated backends. We will learn about this in more depth in <a href="ab131f1f-ca6e-4815-9a3a-8c92c93c9dbc.xhtml">Chapter 12</a>, <em>Publishing Applications in Docker Enterprise</em>.</p>
<h2 id="uuid-2a0b5fcc-dbf5-426c-b963-64e43aaec739">Docker Trusted Registry</h2>
<p>As we mentioned when we were talking about CaaS requirements, we need a registry to store images. This registry must provide secure access and roles because we need some granularity when publishing images. Some users will be owners of their images, while others will only use them. We need to ensure image immutability. DTR provides this. It is built on top of the open source Docker Registry, but many improvements were added to provide an enterprise-ready solution.</p>
<p>DTR provides a secured store for all CaaS/KaaS images. We will be able to ensure provenance and immutability. We will also provide different access levels to images. Some users will be maintainers of base images, while others will be able to use them for their own projects. We also have teams and organizations. We can publish images within organizations in a multi-tenant environment, ensuring that all users within an organization are able to use their public images. Teams will share image maintenance responsibilities, but only some members will be able to modify image content.</p>
<p>Because security is key in CaaS environments, DTR will provide image scanning and signing. Image scanning will review all images, searching for binary vulnerabilities. It will use a <strong>Common Vulnerabilities and Exposures</strong><em><strong> </strong></em>(<strong>CVE</strong>) database to find any vulnerable files. All vulnerable content will be reported and administrators will manage these issues within the platform. We can decide to only execute clean images; that is, images that are without any reported vulnerabilities. Image signing will allow us to forbid any unsigned images into our infrastructure. This ensures that we will only execute images that have been created and signed within our organization. If an image has been externally modified, it will not be allowed to run a container.</p>
<p>DTR can also be integrated into a CI/CD pipeline, along with its image promotion features. Image tags can be modified with triggers. This process can also tell external applications to track and help us implement special stages in our deployment workflow. Images are the new code artifacts for applications and we can integrate DTR in our CI/CD pipelines.</p>
<p>In the next section, we will describe a minimal environment for production using Docker Enterprise Edition.</p>
<h1 id="uuid-5a3cde0d-b954-4ebc-ba56-d5565eea9257" class="mce-root">Planning your Docker Enterprise deployment</h1>
<p class="mce-root">Docker Enterprise provides a production-ready CaaS platform, as we have been discussing throughout this chapter. In this section, we will review the minimum logical requirements for deploying Docker Enterprise in production.</p>
<p class="mce-root">We learned that Docker Swarm and Kubernetes require an odd number of master nodes to work properly. Docker Swarm does not require an external key-value store, while Kubernetes does. Docker Enterprise will deploy this key-value store with UCP, so a minimum of three manager nodes will be required to provide high availability. All managers will run the same services. In Docker Swarm and Kubernetes, we have a leader node that writes cluster changes in the database. Other managers will sync their data, but we can also run administration commands on any of them. We need to integrate an external load balancer to distribute API requests on all manager nodes.</p>
<p>Remember, three nodes only protect the cluster if one of them fails. The cluster will work fine with two manager nodes, but if another one fails, the cluster will become inconsistent.</p>
<p class="mce-root">UCP requires at least three manager nodes. But what about DTR? This component has its own distributed database: it uses <strong>R</strong><strong>ethinkDB</strong>. This database also requires an odd number of replicas; therefore, three nodes will be required. DTR will be deployed on worker nodes using a multi-container architecture. We can then say that we will need at least three worker nodes for DTR. Image scanning can consume a lot of CPU resources, and it is recommended to isolate DTR nodes from other worker nodes to avoid application impact. A DTR cluster requires shared storage between nodes because only the node receiving the application's requests will write changes to the database. But all nodes must write to the same storage location, so shared storage is required. We will use an external load balancer in front of DTR's API to distribute requests between service nodes.</p>
<p>We will add workers to this platform as needed. In fact, we will start with a minimum of two worker nodes for high availability. All application workloads must have resilience; hence, a minimum of two nodes for Windows and Linux workloads will be required if we deploy on both architectures. The following diagram represents the described scenario:</p>
<div><img src="img/8cc0a9be-946f-468e-b835-0f84e645bb24.jpg" style=""/></div>
<p>We will use fixed IP addresses for the manager and worker nodes. This is preferred, although worker nodes can be deployed using DHCP. We will isolate the control plane from the data plane, as we discussed in <a href="78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml">Chapter 8</a>, <em>Orchestration Using Docker Swarm</em>. The data plane will be used for applications, while the control plane will be used for internal cluster communications.</p>
<p>Calico will be used by default as the Kubernetes CNI, and it is important to check for any possible IP range conflicts. The following table shows the default IP addresses used for Docker Engine, Docker Swarm, and Kubernetes:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Component</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Subnet</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Range</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Default IP address</strong></p>
</td>
</tr>
<tr>
<td>
<p>Engine</p>
</td>
<td>
<p><kbd>fixed-cidr</kbd></p>
</td>
<td>
<p>CIDR range for the <kbd>docker0</kbd> interface and local containers</p>
</td>
<td>
<p><kbd>172.17.0.0/16</kbd></p>
</td>
</tr>
<tr>
<td>
<p>Engine</p>
</td>
<td>
<p><kbd>default-address-pools</kbd></p>
</td>
<td>
<p>CIDR range for the <kbd>docker_gwbridge</kbd> interface and bridge networks</p>
</td>
<td>
<p><kbd>172.18.0.0/16</kbd></p>
</td>
</tr>
<tr>
<td>
<p>Swarm</p>
</td>
<td>
<p><kbd>default-addr-pool</kbd></p>
</td>
<td>
<p>CIDR range for Docker Swarm overlay networks</p>
</td>
<td>
<p><kbd>10.0.0.0/8</kbd></p>
</td>
</tr>
<tr>
<td>
<p>Kubernetes</p>
</td>
<td>
<p><kbd>pod-cidr</kbd></p>
</td>
<td>
<p>CIDR range for Kubernetes pods</p>
</td>
<td>
<p><kbd>192.168.0.0/16</kbd></p>
</td>
</tr>
<tr>
<td>
<p>Kubernetes</p>
</td>
<td>
<p><kbd>service-cluster-ip-range</kbd></p>
</td>
<td>
<p>CIDR range for Kubernetes services</p>
</td>
<td>
<p><kbd>10.96.0.0/16</kbd></p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>To avoid any firewall issues, take a look at the following link, which describes some of the configurations required on some Linux platforms: <a href="https://docs.docker.com/ee/ucp/admin/install/plan-installation">https://docs.docker.com/ee/ucp/admin/install/plan-installation</a>.</p>
<p>We will use <strong>Fully Qualified Domain Names</strong> (<strong>FQDNs</strong>) for the virtual IP addresses associated with UCP/Kubernetes and DTR APIs.</p>
<p>We will review all required ports in <a href="1879ea92-ae47-4230-ac84-784d4bc73185.xhtml">Chapter 11</a>, <em>Universal Control Plane</em>, and <a href="108b5948-15a9-40fb-b8dd-5a44c54efd7d.xhtml">Chapter 13</a>, <em>Implementing an Enterprise-Grade Registry with DTR</em>. But clients consume cluster services using specific exposed ports. By default, UCP and DTR will expose their APIs and web UI on port <kbd>443</kbd>, while Kubernetes will be exposed on port <kbd>6443</kbd>.</p>
<p>We will usually require internet access during product installation, although we can execute an offline installation. Internet access is needed for DTR if we need to provide automatic image-scanning database synchronization. We can download a compressed database file from Docker's site once a week, for example, to avoid this required connectivity.</p>
<p>Licensing processes can also be automated, and subscription renewal can synchronize product licenses before they expire.</p>
<p>This was a brief description of the deployment of Docker Enterprise components to production. We will cover these components in more depth in the following chapters.</p>
<h1 id="uuid-05702148-bb89-4c93-b7fd-ec00c03c98b2" class="mce-root">Summary</h1>
<p class="mce-root">In this chapter, we provided an introduction to the Docker Enterprise platform. We reviewed the main differences between Docker Community tools and Docker Enterprise products.</p>
<p class="mce-root">We also covered the concepts of the CaaS and KaaS platforms. We looked at what we should expect from these platforms and how different manufacturers and cloud providers deploy their implementations.</p>
<p class="mce-root">We also described the most important features of Docker Enterprise, namely Docker Enterprise Engine, UCP, and DTR. These components provide Docker's CaaS solution. With that, we've covered the most important things to consider when planning a Docker Enterprise production environment.</p>
<p>In the next chapter, we will explore UCP in more depth.</p>
<h1 id="uuid-0b7e2a26-ad4f-42c6-b04e-fd4c43aa81b5" class="mce-root">Questions</h1>
<ol>
<li class="mce-root">Which of these components is not part of the Docker Enterprise platform?</li>
</ol>
<p style="padding-left: 90px" class="mce-root">a) DTR.<br/>
b) Docker Enterprise Engine.<br/>
c) Docker Machine.<br/>
d) All of these are part of the Docker Enterprise platform.</p>
<ol start="2">
<li class="mce-root">Which of these statements are true about Docker Community and Docker Enterprise?</li>
</ol>
<p style="padding-left: 90px" class="mce-root">a) Docker Enterprise provides an enterprise-ready platform.<br/>
b) We cannot deploy Docker Swarm to production.<br/>
c) Kubernetes is not supported in Docker Enterprise; only Docker Swarm is supported.<br/>
d) Docker Registry is an enterprise-ready registry.</p>
<ol start="3">
<li class="mce-root">Which Docker components are required to deploy a KaaS solution?</li>
</ol>
<p style="padding-left: 90px" class="mce-root">a) Docker Enterprise Engine.<br/>
b) UCP.<br/>
c) Kubernetes.<br/>
d) DTR.</p>
<ol start="4">
<li class="mce-root">Which of the following statements are true for deploying a Docker Enterprise environment?</li>
</ol>
<p style="padding-left: 90px" class="mce-root">a) We use fixed IP addresses for manager nodes only.<br/>
b) We just route traffic to one of the manager nodes.<br/>
c) We need to deploy a CNI after UCP completes the Kubernetes installation.<br/>
d) None of the above.</p>
<ol start="5">
<li class="mce-root">What is the minimum number of nodes required to execute Linux workloads on a Docker Enterprise platform with high availability?</li>
</ol>
<p style="padding-left: 90px">a) We need to deploy three managers, three workers with DTR, and one Linux worker with enough resources to run all workloads.<br/>
b) We need to deploy three managers with DTR running on them and two Linux workers.<br/>
c) We need to deploy three managers, three workers with DTR, and two Linux workers.<br/>
d) All these options are valid.</p>
<h1 id="uuid-f995f78d-aaee-45f0-afc1-949629cdb984">Further reading</h1>
<p>You can refer to the following references for more information about the topics that were covered in this chapter:</p>
<ul>
<li>Introduction to Docker Enterprise: <a href="https://docs.docker.com/ee/">https://docs.docker.com/ee/</a></li>
<li>Docker Enterprise components: <a href="https://docs.docker.com/ee/docker-ee-architecture/">https://docs.docker.com/ee/docker-ee-architecture/</a></li>
<li>Mirantis Docker Enterprise website: <a href="https://www.mirantis.com/software/docker/docker-enterprise/">https://www.mirantis.com/software/docker/docker-enterprise/</a></li>
<li>Mirantis Docker acquisition: <a href="https://www.mirantis.com/company/press-center/company-news/mirantis-acquires-docker-enterprise/">https://www.mirantis.com/company/press-center/company-news/mirantis-acquires-docker-enterprise/</a></li>
</ul>


            

            
        
    </body></html>