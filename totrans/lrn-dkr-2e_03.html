<html><head></head><body>
  
    
      <h1>Sharing Data with Containers</h1>
    

    
      <p>"Do one thing at a time and do it well," has been one of the successful mantras in the <strong>Information Technology</strong> (<strong>IT</strong>) sector for quite a long time now. This widely used tenet fits nicely to build and expose Docker containers too, and it is being prescribed as one of the best practices to avail the originally envisaged benefits of the Docker-inspired containerization paradigm. This means that, we must inscribe a single application along with its direct dependencies and libraries inside a Docker container in order to ensure the container's independence, self-sufficiency, horizontal scalability, and maneuverability. Let's see why containers are that important:</p>

      <ul>
        <li><strong>The temporal nature of containers</strong>: The container typically lives as long as the application lives and vice versa. However, this has some negative implications for the application data. Applications naturally go through a variety of changes in order to accommodate both business as well as technical changes, even in their production environments. There are other causes, such as application malfunctions, version changes, and application maintenance, for software applications to be consistently and constantly updated and upgraded. In the case of a general-purpose computing model, even when an application dies for any reason, the persistent data associated with this application can be preserved in the filesystem. However, in the case of the container paradigm, the application upgrades are usually performed by systematically crafting a new container with the newer version of the application by simply discarding the old one. Similarly, when an application malfunctions, a new container needs to be launched and the old one has to be discarded. To sum it up, containers are typically temporal in nature.</li>

        <li><strong>The need for a business continuity</strong>: In the container landscape, the complete execution environment, including its data files, is usually bundled and encapsulated inside the container. For any reason, when a container gets discarded, the application data files also perish along with the container. However, in order to provide software applications without any interruption and disruption of service, these application data files must be preserved outside the container and passed on to the container on a need basis in order to ensure business continuity. This means that the resiliency and reliability of containers need to be guaranteed. Besides, some application data files, such as the log files, needs to be collected and accessed outside the container for various posterior analyses. The Docker technology addresses this file persistence issue very innovatively through a new building block called data volume.</li>
      </ul>

      <p>The Docker technology has three different ways of providing persistent storage:</p>

      <ul>
        <li>The first and recommended approach is to use volumes that are created using Docker's volume management.</li>

        <li>The second method is to mount a directory from the Docker host to a specified location inside the container.</li>

        <li>The other alternative is to use a data-only container. The data-only container is a specially crafted container that is used to share data with one or more containers.</li>
      </ul>

      <p>In this chapter, we will cover the following topics:</p>

      <ul>
        <li>Data volume</li>

        <li>Sharing host data</li>

        <li>Sharing data between containers</li>

        <li>The avoidable common pitfalls</li>
      </ul>
    
  

  
    
      <h2 id="sigil_toc_id_103">Data volume</h2>
    

    
      <p>Data volume is the fundamental building block of data sharing in the Docker environment. Before getting into the details of data sharing, it is imperative to get a good understanding of the data volume concept. Until now, all the files that we create in an image or a container is part and parcel of the union filesystem. The container's union filesystem perishes along with the container. In other words, when the container is removed, its filesystem is also automatically removed. However, the enterprise-grade applications must persist data and the container's filesystem will not render itself for such a requirement.</p>

      <p>The Docker ecosystem, however, elegantly addresses this issue with the data volume concept. Data volume is essentially a part of the Docker host filesystem and it simply gets mounted inside the container. Optionally, you can use other advanced filesystems such as Flocker and GlusterFS as data volumes through pluggable volume drivers. Since data volume is not a part of the container's filesystem, it has a life cycle independent of the container.</p>

      <p>A data volume can be inscribed in a Docker image using the <code>VOLUME</code> instruction of the <code>Dockerfile</code>. Also, it can be prescribed during the launch of a container using the <code>-v</code> option of the <code>docker run</code> subcommand. Here, in the following example, the implication of the <code>VOLUME</code> instruction in the <code>Dockerfile</code> is illustrated in detail in the following steps:</p>

      <ol>
        <li>Create a very simple <code>Dockerfile</code> with the instruction of the base image (<code>ubuntu:16.04</code>) and the data volume (<code>/MountPointDemo</code>):</li>
      </ol>

      <pre>      FROM ubuntu:16.04 <br/>      VOLUME /MountPointDemo 
</pre>

      <ol start="2">
        <li>Build the image with the <code>mount-point-demo</code> name using the <code>docker build</code> subcommand:</li>
      </ol>

      <pre>      <strong>$ sudo docker build -t mount-point-demo .</strong>
</pre>

      <ol start="3">
        <li>Having built the image, let's quickly inspect the image for our data volume using the <code>docker inspect</code> subcommand:</li>
      </ol>

      <pre><strong> $ sudo docker inspect mount-point-demo</strong><br/><strong> [</strong><br/><strong> {</strong><br/><strong> "Id": "sha256:&lt;64 bit hex id&gt;",</strong><br/><strong> "RepoTags": [</strong><br/><strong> "mount-point-demo:latest"</strong><br/><strong> ],</strong><br/><strong> ... TRUNCATED OUTPUT ... </strong><br/><strong> "Volumes": {</strong><br/><strong> "/MountPointDemo": {}</strong><br/><strong> },</strong><br/><strong> ... TRUNCATED OUTPUT ...</strong>
</pre>

      <p style="padding-left: 60px">Evidently, in the preceding output, data volume is inscribed in the image itself.</p>

      <ol start="4">
        <li>Now, let's launch an interactive container using the <code>docker run</code> subcommand from the earlier crafted image, as shown in the following command:</li>
      </ol>

      <pre>      <strong>$ sudo docker run --rm -it mount-point-demo</strong>
</pre>

      <p style="padding-left: 60px">From the container's prompt, let's check the presence of data volume using the <code>ls -ld</code> command:</p>

      <pre><strong> root@8d22f73b5b46:/# ls -ld /MountPointDemo</strong><br/><strong> drwxr-xr-x 2 root root 4096 Nov 18 19:22 </strong><br/><strong> /MountPointDemo</strong>
</pre>

      <p style="padding-left: 60px">As mentioned earlier, data volume is part of the Docker host filesystem and it gets mounted, as shown in the following command:</p>

      <pre><strong> root@8d22f73b5b46:/# mount | grep MountPointDemo</strong><br/><strong> /dev/xvda2 on /MountPointDemo type ext3 </strong><br/><strong> (rw,noatime,nobarrier,errors=remount-ro,data=ordered) </strong> 
</pre>

      <ol start="5">
        <li>In this section, we inspected the image to find out about the data volume declaration in the image. Now that we have launched the container, let's inspect the container's data volume using the <code>docker inspect</code> subcommand with the container ID as its argument in a different Terminal. We created a few containers previously and for this purpose, let's take the <code>8d22f73b5b46</code> container ID directly from the container's prompt:</li>
      </ol>

      <pre><strong> $ sudo docker inspect -f </strong><br/><strong> '{{json .Mounts}}' 8d22f73b5b46 </strong><br/><strong> [</strong><br/><strong> {</strong><br/><strong> "Propagation": "",</strong><br/><strong> "RW": true,</strong><br/><strong> "Mode": "",</strong><br/><strong> "Driver": "local",</strong><br/><strong> "Destination": "/MountPointDemo",</strong><br/><strong> "Source":<br/>"/var/lib/docker/volumes</strong><strong>/720e2a2478e70a7cb49ab7385b8be627d4b</strong><strong>6ec52e6bb33063e4144355d59592a/</strong><strong>_data",</strong><br/><strong>"Name": "720e2a2478e70a7cb49ab7385b8be627d4b6</strong><strong>ec52e6bb33063e4144355d59592a"</strong><br/><strong> }</strong><br/><strong> ]</strong>
</pre>

      <p>Apparently, here, data volume is mapped to a directory in the Docker host, and the directory is mounted in the read-write mode. This directory, also called as volume, is created by the Docker Engine automatically during the launch of the container. Since version 1.9 of Docker, the volumes are managed through a top-level volume management command, which we will dive and dig further down into tell all in the next section.</p>

      <p>So far, we have seen the implication of the <code>VOLUME</code> instruction in the <code>Dockerfile</code>, and how Docker manages data volume. Like the <code>VOLUME</code> instruction of the <code>Dockerfile</code>, we can use the <code>-v &lt;container mount point path&gt;</code> option of the <code>docker run</code> subcommand, as shown in the following command:</p>

      <pre><strong>$ sudo docker run -v /MountPointDemo -it ubuntu:16.04</strong>  
</pre>

      <p>Having launched the container, we encourage you to try the <code>ls -ld /MountPointDemo</code> and <code>mount</code> commands in the newly launched container, and then also, inspect the container, as shown in the preceding step 5.</p>

      <p>In both the scenarios described here, the Docker Engine automatically creates the volume under the <code>/var/lib/docker/volumes/</code> directory and mounts it to the container. When a container is removed using the <code>docker rm</code> subcommand, the Docker Engine does not remove the volume that was automatically created during the launch of the container. This behavior is innately designed to preserve the state of the container's application that was stored in the volume filesystem. If you want to remove the volume that was automatically created by the Docker Engine, you can do so while removing the container by providing a <code>-v</code> option to the <code>docker rm</code> subcommand, on an already stopped container:</p>

      <pre><strong>$ sudo docker rm -v 8d22f73b5b46</strong>  
</pre>

      <p>If the container is still running, then you can remove the container as well as the autogenerated directory by adding a <code>-f</code> option to the previous command:</p>

      <pre><strong>$ sudo docker rm -fv 8d22f73b5b46</strong>  
</pre>

      <p>We have taken you through the techniques and tips to autogenerate a directory in the Docker host and mount it to the data volume in the container. However, with the <code>-v</code> option of the <code>docker run</code> subcommand, a user-defined directory can be mounted to the data volume. In such cases, the Docker Engine will not autogenerate any directory.</p>

      <p>The system generation of a directory has a caveat of directory leak. In other words, if you forget to delete the system-generated directories, you may face some unwanted issues. For further information, read the <em>Avoiding common pitfalls</em> section in this chapter.
      </p>
    
  

  
    
      <h2 id="sigil_toc_id_104">The volume management command</h2>
    

    
      <p>Docker has introduced a top-level volume management command from version 1.9 in order to manage the persistent filesystem effectively. The volume management command is capable of managing data volumes that are part of the Docker host. In addition to that, it also helps us to extend the Docker persistent capability using pluggable volume drivers (Flocker, GlusterFS, and so on). You can find the list of supported plugins at <a href="https://docs.docker.com/engine/extend/legacy_plugins/">https://docs.docker.com/engine/extend/legacy_plugins/</a>.</p>

      <p>The <code>docker volume</code> command supports four subcommands as listed here:</p>

      <ul>
        <li><code>create</code>: This creates a new volume</li>

        <li><code>inspect</code>: This displays detailed information about one or more volumes</li>

        <li><code>ls</code>: This lists the volumes in the Docker host</li>

        <li><code>rm</code>: This removes a volume</li>
      </ul>

      <p>Let's quickly explore the volume management command through a few examples. You can create a volume using the <code>docker volume create</code> subcommand, as shown here:</p>

      <pre><strong>$ sudo docker volume create</strong><br/><strong>50957995c7304e7d398429585d36213bb87781c53550b72a6a27c755c7a99639</strong>
</pre>

      <p>The preceding command will create a volume by autogenerating a 64-hex digit string as the volume name. However, it is more effective to name the volume with a meaningful name for easy identification. You can name a volume using the <code>--name</code> option of the <code>docker volume create</code> subcommand:</p>

      <pre><strong>$ sudo docker volume create --name example</strong><br/><strong>example</strong>  
</pre>

      <p>Now, that we have created two volumes with and without a volume name, let's use the <code>docker volume ls</code> subcommand to display them:</p>

      <pre><strong>$ sudo docker volume ls</strong><br/><strong>DRIVER VOLUME NAME</strong><br/><strong>local 50957995c7304e7d398429585d36213bb87781c53550b72a6a27c755c7a99639</strong><br/><strong>local example</strong>  
</pre>

      <p>Having listed out the volumes, let's run the <code>docker volume inspect</code> subcommand into the details of the volumes we have created earlier:</p>

      <pre><strong>$ sudo docker volume inspect example</strong><br/><strong>[</strong><br/><strong> {</strong><br/><strong> "Name": "example",</strong><br/><strong> "Driver": "local",</strong><br/><strong> "Mountpoint": <br/> "/var/lib/docker/volumes/example/_data",</strong><br/><strong> "Labels": {},</strong><br/><strong> "Scope": "local"</strong><br/><strong> }</strong><br/><strong>]</strong>
</pre>

      <p>The <code>docker volume rm</code> subcommand enables you to remove the volumes you don't need anymore:</p>

      <pre><strong>$ sudo docker volume rm example</strong><br/><strong>example</strong>
</pre>

      <p>Now that we are familiar with Docker volume management, let's dive deep into data sharing in the ensuing sections.</p>
    
  

  
    
      <h2 id="sigil_toc_id_105">Sharing host data</h2>
    

    
      <p>Earlier, we described the steps to create a data volume in a Docker image using the <code>VOLUME</code> instruction in the <code>Dockerfile</code>. However, Docker does not provide any mechanism to mount the host directory or file during the build time in order to ensure the Docker images to be portable. The only provision Docker provides is to mount the host directory or file to a container's data volume during the container's launch. Docker exposes the host directory or file mounting facility through the <code>-v</code> option of the <code>docker run</code> subcommand. The <code>-v</code> option has five different formats, enumerated as follows:</p>

      <ul>
        <li><code>-v &lt;container mount path&gt;</code></li>

        <li><code>-v &lt;host path&gt;:&lt;container mount path&gt;</code></li>

        <li><code>-v &lt;host path&gt;:&lt;container mount path&gt;:&lt;read write mode&gt;</code></li>

        <li><code>-v &lt;volume name&gt;:&lt;container mount path&gt;</code></li>

        <li><code>-v &lt;volume name&gt;:&lt;container mount path&gt;:&lt;read write mode&gt;</code></li>
      </ul>

      <p>The <code>&lt;host path&gt;</code> format is an absolute path in the Docker host, <code>&lt;container mount path&gt;</code> is an absolute path in the container filesystem, <code>&lt;volume name&gt;</code> is the name of the volume created using the <code>docker volume create</code> subcommand, and <code>&lt;read write mode&gt;</code> can be either the read-only (<code>ro</code>) or read-write (<code>rw</code>) mode. The first <code>-v &lt;container mount path&gt;</code> format has already been explained in the <em>Data volume</em> section in this chapter, as a method to create a mount point during the launch of the container launch. The second and third formats enable us to mount a file or directory from the Docker host to the container mount point. The fourth and fifth formats allow us to mount volumes created using the <code>docker volume create</code> subcommand.</p>

      <p>We would like to dig deeper to gain a better understanding of the host's data sharing through a couple of examples. In the first example, we will demonstrate how to share a directory between the Docker host and the container, and in the second example, we will demonstrate file sharing.</p>

      <p>Here, in the first example, we mount a directory from the Docker host to a container, perform a few basic file operations on the container, and verify these operations from the Docker host, as detailed in the following steps:</p>

      <ol>
        <li>First, let's launch an interactive container with the <code>-v</code> option of the <code>docker run</code> subcommand to mount <code>/tmp/hostdir</code> of the Docker host directory to <code>/MountPoint</code> of the container:</li>
      </ol>

      <pre>     <strong> $ sudo docker run -v /tmp/hostdir:/MountPoint \</strong><br/><strong> -it ubuntu:16.04</strong>
</pre>

      <p>If <code>/tmp/hostdir</code> is not found on the Docker host, the Docker Engine will create the directory per se. However, the problem is that the system-generated directory cannot be deleted using the <code>-v</code> option of the <code>docker rm</code> subcommand.
      </p>

      <ol start="2">
        <li>Having successfully launched the container, we can check the presence of <code>/MountPoint</code> using the <code>ls</code> command:</li>
      </ol>

      <pre><strong> root@4a018d99c133:/# ls -ld /MountPoint</strong><br/><strong> drwxr-xr-x 2 root root 4096 Nov 23 18:28 </strong><br/><strong> /MountPoint</strong>
</pre>

      <ol start="3">
        <li>Now, we can proceed to check the mount details using the <code>mount</code> command:</li>
      </ol>

      <pre><strong> root@4a018d99c133:/# mount | grep MountPoint</strong><br/><strong> /dev/xvda2 on /MountPoint type ext3 </strong><br/><strong> (rw,noatime,nobarrier,errors=</strong><br/><strong> remount-ro,data=ordered)</strong>
</pre>

      <ol start="4">
        <li>Here, we are going to validate <code>/MountPoint</code>, change to the <code>/MountPoint</code> directory using the <code>cd</code> command, create a few files using the <code>touch</code> command, and list the files using the <code>ls</code> command, as shown in the following script:</li>
      </ol>

      <pre><strong> root@4a018d99c133:/# cd /MountPoint/</strong><br/><strong> root@4a018d99c133:/MountPoint# touch {a,b,c}</strong><br/><strong> root@4a018d99c133:/MountPoint# ls -l</strong><br/><strong> total 0</strong><br/><strong> -rw-r--r-- 1 root root 0 Nov 23 18:39 a</strong><br/><strong> -rw-r--r-- 1 root root 0 Nov 23 18:39 b</strong><br/><strong> -rw-r--r-- 1 root root 0 Nov 23 18:39 c</strong>
</pre>

      <ol start="5">
        <li>It might be worth the effort to verify the files in the <code>/tmp/hostdir</code> Docker host directory using the <code>ls</code> command on a new Terminal, as our container is running in an interactive mode on the existing Terminal:</li>
      </ol>

      <pre><strong> $ sudo ls -l /tmp/hostdir/</strong><br/><strong> total 0</strong><br/><strong> -rw-r--r-- 1 root root 0 Nov 23 12:39 a</strong><br/><strong> -rw-r--r-- 1 root root 0 Nov 23 12:39 b</strong><br/><strong> -rw-r--r-- 1 root root 0 Nov 23 12:39 c</strong>
</pre>

      <p style="padding-left: 60px">Here, we can see the same set of files, as we saw in step 4. However, you might have noticed the difference in the timestamp of the files. This time difference is due to the time zone difference between the Docker host and the container.</p>

      <ol start="6">
        <li>Finally, let's run the <code>docker inspect</code> subcommand with the <code>4a018d99c133</code> container ID as an argument to see whether the directory mapping is set up between the Docker host and the container mount point, as shown in the following command:</li>
      </ol>

      <pre><strong> $ sudo docker inspect \</strong><br/><strong> --format='{{json .Mounts}}' 4a018d99c133</strong><br/><strong> [{"Source":"/tmp/hostdir",</strong><br/><strong> "Destination":"/MountPoint","Mode":"",</strong><br/><strong> "RW":true,"Propagation":"rprivate"}]</strong>
</pre>

      <p style="padding-left: 60px">Apparently, in the preceding output of the <code>docker inspect</code> subcommand, the <code>/tmp/hostdir</code> directory of the Docker host is mounted on the <code>/MountPoint</code> mount point of the container.</p>

      <p>For the second example, we will mount a file from the Docker host to a container, update the file from the container, and verify those operations from the Docker host, as detailed in the following steps:</p>

      <ol>
        <li>In order to mount a file from the Docker host to the container, the file must preexist in the Docker host. Otherwise, the Docker Engine will create a new directory with the specified name and mount it as a directory. We can start by creating a file on the Docker host using the <code>touch</code> command:</li>
      </ol>

      <pre>      <strong>$ touch /tmp/hostfile.txt</strong>
</pre>

      <ol start="2">
        <li>Launch an interactive container with the <code>-v</code> option of the <code>docker run</code> subcommand to mount the <code>/tmp/hostfile.txt</code> Docker host file to the container as <code>/tmp/mntfile.txt</code>:</li>
      </ol>

      <pre>      <strong>$ sudo docker run -v /tmp/hostfile.txt:/mntfile.txt \</strong><br/><strong> -it ubuntu:16.04</strong>
</pre>

      <ol start="3">
        <li>Having successfully launched the container, now let's check the presence of <code>/mntfile.txt</code> using the <code>ls</code> command:</li>
      </ol>

      <pre><strong> root@d23a15527eeb:/# ls -l /mntfile.txt</strong><br/><strong> -rw-rw-r-- 1 1000 1000 0 Nov 23 19:33 /mntfile.txt</strong>
</pre>

      <ol start="4">
        <li>Then, proceed to check the mount details using the <code>mount</code> command:</li>
      </ol>

      <pre><strong> root@d23a15527eeb:/# mount | grep mntfile</strong><br/><strong> /dev/xvda2 on /mntfile.txt type ext3 </strong><br/><strong> (rw,noatime,nobarrier,errors=remount-ro,data=ordered)</strong>
</pre>

      <ol start="5">
        <li>Then, update some text to <code>/mntfile.txt</code> using the <code>echo</code> command:</li>
      </ol>

      <pre>      <strong>root@d23a15527eeb:/# echo "Writing from Container" </strong><br/><strong> &gt; mntfile.txt</strong>
</pre>

      <ol start="6">
        <li>Meanwhile, switch to a different Terminal in the Docker host, and print the <code>/tmp/hostfile.txt</code> Docker host file using the <code>cat</code> command:</li>
      </ol>

      <pre><strong> $ cat /tmp/hostfile.txt</strong><br/><strong> Writing from Container </strong> 
</pre>

      <ol start="7">
        <li>Finally, run the <code>docker inspect</code> subcommand with the <code>d23a15527eeb</code> container ID as it's argument to see the file mapping between the Docker host and the container mount point:</li>
      </ol>

      <pre><strong> $ sudo docker inspect \</strong><br/><strong> --format='{{json .Mounts}}' d23a15527eeb</strong><br/><strong> [{"Source":"/tmp/hostfile.txt", </strong><br/><strong> "Destination":"/mntfile.txt",</strong><br/><strong> "Mode":"","RW":true,"Propagation":"rprivate"}]</strong>
</pre>

      <p style="padding-left: 60px">From the preceding output, it is evident that the <code>/tmp/hostfile.txt</code> file from the Docker host is mounted as <code>/mntfile.txt</code> inside the container.</p>

      <p>For the last example, we will create a Docker volume and mount a named data volume to a container. In this example, we are not going to run the verification steps as we did in the previous two examples. However, you are encouraged to run the verification steps we laid out in the first example.</p>

      <ol>
        <li>Create a named data volume using the <code>docker volume create</code> subcommand, as shown here:</li>
      </ol>

      <pre>      <strong>$ docker volume create --name namedvol</strong>
</pre>

      <ol start="2">
        <li>Now, launch an interactive container with the <code>-v</code> option of the <code>docker run</code> subcommand to mount <code>namedvol</code> a named data value to <code>/MountPoint</code> of the container:</li>
      </ol>

      <pre>      <strong>$ sudo docker run -v namedvol:/MountPoint \</strong><br/><strong> -it ubuntu:16.04</strong>
</pre>

      <p>During the launch of the container, Docker Engine creates <code>namedvol</code> if it is not created already.
      </p>

      <ol start="3">
        <li>Having successfully launched the container, you can repeat the verification steps 2 to 6 of the first example and you will find the same output pattern in this example as well.</li>
      </ol>
    
  

  
    
      <h3 id="sigil_toc_id_106">The practicality of host data sharing</h3>
    

    
      <p>In the previous chapter, we launched an HTTP service in a Docker container. However, if you remember correctly, the log file for the HTTP service is still inside the container, and it cannot be accessed directly from the Docker host. Here, in this section, we elucidate the procedure of accessing the log files from the Docker host in a step-by-step manner:</p>

      <ol>
        <li>Let's begin with launching an Apache2 HTTP service container by mounting the <code>/var/log/myhttpd</code> directory of the Docker host to the <code>/var/log/apache2</code> directory of the container, using the <code>-v</code> option of the <code>docker run</code> subcommand. In this example, we are leveraging the <code>apache2</code> image, which we had built in the previous chapter, by invoking the following command:</li>
      </ol>

      <pre>      <strong>$ sudo docker run -d -p 80:80 \</strong><br/><strong> -v /var/log/myhttpd:/var/log/apache2 apache2</strong><br/><strong>9c2f0c0b126f21887efaa35a1432ba7092b69e0c6d523ffd50684e27eeab37ac</strong>
</pre>

      <p style="padding-left: 60px">If you recall the <code>Dockerfile</code> in <a href="../Text/Ch06.xhtml">Chapter 6</a>, <em>Running Services in a Container</em>, the <code>APACHE_LOG_DIR</code> environment variable is set to the <code>/var/log/apache2</code> directory, using the <code>ENV</code> instruction. This will make the Apache2 HTTP service to route all log messages to the <code>/var/log/apache2</code> data volume.</p>

      <ol start="2">
        <li>Once the container is launched, we can change the directory to <code>/var/log/myhttpd</code> on the Docker host:</li>
      </ol>

      <pre>      <strong>$ cd /var/log/myhttpd</strong>
</pre>

      <ol start="3">
        <li>Perhaps, a quick check of the files present in the <code>/var/log/myhttpd</code> directory is appropriate here:</li>
      </ol>

      <pre><strong> $ ls -1</strong><br/><strong> access.log</strong><br/><strong> error.log</strong><br/><strong> other_vhosts_access.log</strong>
</pre>

      <p style="padding-left: 60px">Here, the <code>access.log</code> file contains all the access requests handled by the Apache2 HTTP server. The <code>error.log</code> file is a very important log file, where our HTTP server records the errors it encounters while processing any HTTP requests. The <code>other_vhosts_access.log</code> file is the virtual host log, which will always be empty in our case.</p>

      <ol start="4">
        <li>We can display the content of all the log files in the <code>/var/log/myhttpd</code> directory using the <code>tail</code> command with the <code>-f</code> option:</li>
      </ol>

      <pre><strong> $ tail -f *.log</strong><br/><strong> ==&gt; access.log &lt;==</strong><br/><br/><strong> ==&gt; error.log &lt;==</strong><br/><strong> AH00558: apache2: Could not reliably determine the </strong><br/><strong> server's fully qualified domain name, using 172.17.0.17. </strong><br/><strong> Set the 'ServerName' directive globally to suppress this </strong><br/><strong> message</strong><br/><strong> [Thu Nov 20 17:45:35.619648 2014] [mpm_event:notice] </strong><br/><strong> [pid 16:tid 140572055459712] AH00489: Apache/2.4.7 </strong><br/><strong> (Ubuntu) configured -- resuming normal operations</strong><br/><strong> [Thu Nov 20 17:45:35.619877 2014] [core:notice] </strong><br/><strong> [pid 16:tid 140572055459712] AH00094: Command line: </strong><br/><strong> '/usr/sbin/apache2 -D FOREGROUND'</strong><br/><strong> ==&gt; other_vhosts_access.log &lt;==</strong>
</pre>

      <p style="padding-left: 60px">The <code>tail -f</code> command will run continuously and display the content of the files, as soon as they get updated. Here, both <code>access.log</code> and <code>other_vhosts_access.log</code> are empty, and there are a few error messages on the <code>error.log</code> file. Apparently, these error logs are generated by the HTTP service running inside the container. The logs are then stocked in the Docker host directory, which is mounted during the launch of the container.</p>

      <ol start="5">
        <li>As we continue to run <code>tail -f *</code>, let's connect to the HTTP service from a web browser running inside the container, and observe the log files:</li>
      </ol>

      <pre><strong> ==&gt; access.log &lt;==</strong><br/><strong> 111.111.172.18 - - [20/Nov/2014:17:53:38 +0000] "GET / </strong><br/><strong> HTTP/1.1" 200 3594 "-" "Mozilla/5.0 (Windows NT 6.1; </strong><br/><strong> WOW64) </strong><br/><strong> AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.65 </strong><br/><strong> Safari/537.36"</strong><br/><strong> 111.111.172.18 - - [20/Nov/2014:17:53:39 +0000] "GET </strong><br/><strong> /icons/ubuntu-logo.png HTTP/1.1" 200 3688 </strong><br/><strong> "http://111.71.123.110/" "Mozilla/5.0 (Windows NT 6.1; </strong><br/><strong> WOW64) </strong><br/><strong> AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.65 </strong><br/><strong> Safari/537.36"</strong><br/><strong> 111.111.172.18 - - [20/Nov/2014:17:54:21 +0000] "GET </strong><br/><strong> /favicon.ico HTTP/1.1" 404 504 "-" "Mozilla/5.0 (Windows </strong><br/><strong> NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) </strong><br/><strong> Chrome/39.0.2171.65 Safari/537.36"</strong>
</pre>

      <p style="padding-left: 60px">The HTTP service updates the <code>access.log</code> file, which we can manipulate from the host directory mounted through the <code>-v</code> option of the <code>docker run</code> subcommand.</p>
    
  

  
    
      <h2 id="sigil_toc_id_107">Sharing data between containers</h2>
    

    
      <p>In the previous section, you learned how seamlessly the Docker Engine enables data sharing between the Docker host and the container. Although it is a very effective solution for most of the use cases, there are use cases wherein you will have to share data between one or more containers. The Docker's prescription to address this use case is to mount the data volume of one container to other containers using the <code>--volume-from</code> option of the <code>docker run</code> subcommand.</p>
    
  

  
    
      <h3 id="sigil_toc_id_108">Data-only containers</h3>
    

    
      <p>Before Docker introduced the top-level volume management feature, the data-only container was the recommended approach to achieve data persistency. It is worth understanding data-only containers because you will find many implementations that are based on data-only containers. The prime responsibility of a data-only container is to preserve the data. Creating a data-only container is very similar to the method illustrated in the <em>Data volume</em> section. In addition, the containers are named explicitly for other containers to mount the data volume using the container's name. Besides, the container's data volumes are accessible from other containers even when the data-only containers are in the stopped state. The data-only containers can be created in two ways, as follows:</p>

      <ul>
        <li>During the launch of the container by configuring the data volume and the container's name</li>

        <li>Data volume can also be inscribed with <code>Dockerfile</code> during image-building, and later, the container can be named during the container's launch</li>
      </ul>

      <p>In the following example, we are launching a data-only container by configuring the container launch with the <code>-v</code> and <code>--name</code> options of the <code>docker run</code> subcommand, as shown here:</p>

      <pre><strong>$ sudo docker run --name datavol \</strong><br/><strong> -v /DataMount \</strong><br/><strong> busybox:latest /bin/true</strong>
</pre>

      <p>Here, the container is launched from the <code>busybox</code> image, which is widely used for its smaller footprint. Here, we choose to execute the <code>/bin/true</code> command because we don't intend to do any operations on the container. Therefore, we named the container <code>datavol</code> using the <code>--name</code> option and created a new <code>/DataMount</code> data volume using the <code>-v</code> option of the <code>docker run</code> subcommand. The <code>/bin/true</code> command exits immediately with the <code>0</code> exit status, which in turn will stop the container and continue to be in the stopped state.</p>
    
  

  
    
      <h3 id="sigil_toc_id_109">Mounting data volume from other containers</h3>
    

    
      <p>The Docker Engine provides a nifty interface to mount (share) the data volume from one container to another. Docker makes this interface available through the <code>--volumes-from</code> option of the <code>docker run</code> subcommand. The <code>--volumes-from</code> option takes a container name or container ID as its input and automatically mounts all the data volumes available on the specified container. Docker allows you to mount multiple containers with data volume using the <code>--volumes-from</code> option multiple times.</p>

      <p>Here is a practical example that demonstrates how to mount data volume from another container and showcases the data volume mount step by step:</p>

      <ol>
        <li>We begin with launching an interactive Ubuntu container by mounting the data volume from the data-only container (<code>datavol</code>), which we launched in the previous section:</li>
      </ol>

      <pre>      <strong>$ sudo docker run -it \</strong><br/><strong> --volumes-from datavol \</strong><br/><strong> ubuntu:latest /bin/bash</strong>
</pre>

      <ol start="2">
        <li>Now from the container's prompt, let's verify the data volume mounts using the <code>mount</code> command:</li>
      </ol>

      <pre><strong> root@e09979cacec8:/# mount | grep DataMount</strong><br/><strong> /dev/xvda2 on /DataMount type ext3 </strong><br/><strong> (rw,noatime,nobarrier,errors=remount-ro,data=ordered)</strong>
</pre>

      <p style="padding-left: 60px">Here, we successfully mounted the data volume from the <code>datavol</code> data-only container.</p>

      <ol start="3">
        <li>Next, we need to inspect the data volume of this container from another Terminal using the <code>docker inspect</code> subcommand:</li>
      </ol>

      <pre>      <strong>$ sudo docker inspect --format='{{json .Mounts}}' <br/> e09979cacec8</strong><br/><strong> [{"Name":<br/> "7907245e5962ac07b31c6661a4dd9b283722d3e7d0b0fb40a90<br/> 43b2f28365021","Source":<br/> "/var/lib/docker/volumes <br/> /7907245e5962ac07b31c6661a4dd9b283722d3e7d0b0fb40a9043b<br/> 2f28365021/_data","Destination":"<br/> /DataMount","Driver":"local","Mode":"",<br/> "RW":true,"Propagation":""}]</strong>
</pre>

      <p style="padding-left: 60px">Evidently, the data volume from the <code>datavol</code> data-only container is mounted as if they were mounted directly on to this container.</p>

      <p>We can mount a data volume from another container and also showcase the mount points. We can make the mounted data volume to work by sharing data between containers using the data volume, as demonstrated here:</p>

      <ol>
        <li>Let's reuse the container that we launched in the previous example and create a <code>/DataMount/testfile</code> file in the <code>/DataMount</code> data volume by writing some text to the file, as shown here:</li>
      </ol>

      <pre>      <strong>root@e09979cacec8:/# echo \</strong><br/><strong> "Data Sharing between Container" &gt; \</strong><br/><strong> /DataMount/testfile </strong>
</pre>

      <ol start="2">
        <li>Just spin off a container to display the text that we wrote in the previous step, using the <code>cat</code> command:</li>
      </ol>

      <pre>      <strong>$ sudo docker run --rm \</strong><br/><strong> --volumes-from datavol \</strong><br/><strong> busybox:latest cat /DataMount/testfile</strong>
</pre>

      <p style="padding-left: 60px">The following is the typical output of the preceding command:</p>

      <pre>      <strong>Data Sharing between Container</strong>
</pre>

      <p>Evidently, the preceding <code>Data Sharing between Container</code> output of our newly containerized <code>cat</code> command is the text that we have written in <code>/DataMount/testfile</code> of the <code>datavol</code> container in step 1.</p>

      <p>Cool, isn't it? You can share data seamlessly between containers by sharing the data volumes. Here, in this example, we used data-only containers as the base container for data sharing. However, Docker allows us to share any type of data volumes and to mount data volumes one after another, as depicted here:</p>

      <pre><strong>$ sudo docker run --name vol1 --volumes-from datavol \</strong><br/><strong> busybox:latest /bin/true</strong><br/><strong>$ sudo docker run --name vol2 --volumes-from vol1 \</strong><br/><strong> busybox:latest /bin/true</strong>
</pre>

      <p>Here, in the <code>vol1</code> container, we mounted the data volume from the <code>datavol</code> container. Then, in the <code>vol2</code> container, we mounted the data volume from the <code>vol1</code> container, which is eventually from the <code>datavol</code> container.</p>
    
  

  
    
      <h3 id="sigil_toc_id_110">The practicality of data sharing between containers</h3>
    

    
      <p>Earlier in this chapter, you learned the mechanism of accessing the log files of the Apache2 HTTP service from the Docker host. Although it was fairly convenient to share data by mounting the Docker host directory to a container, later we came to know that data can be shared between containers by just using data volumes. So here, we are bringing in a twist to the method of the Apache2 HTTP service log handling by sharing data between containers. To share log files between containers, we will spin off the following containers as enlisted in the following steps:</p>

      <ol>
        <li>First, a data-only container that will expose the data volume to other containers.</li>

        <li>Then, an Apache2 HTTP service container leveraging the data volume of the data-only container.</li>

        <li>A container to view the log files generated by our Apache2 HTTP service.</li>
      </ol>

      <p>If you are running any HTTP service on the <code>80</code> port number of your Docker host machine, pick any other unused port number for the following example. If not, first stop the HTTP service, then proceed with the example in order to avoid any port conflict.
      </p>

      <p>Now, we'll meticulously walk you through the steps to craft the respective images and launch the containers to view the log files:</p>

      <ol>
        <li>Here, we begin with crafting a <code>Dockerfile</code> with the <code>/var/log/apache2</code> data volume using the <code>VOLUME</code> instruction. The <code>/var/log/apache2</code> data volume is a direct mapping to <code>APACHE_LOG_DIR</code>, the environment variable set in the <code>Dockerfile</code> in <a href="../Text/Ch06.xhtml">Chapter 6</a>, <em>Running Services in a Container</em>, using the <code>ENV</code> instruction:</li>
      </ol>

      <pre>      ####################################################### <br/>      # Dockerfile to build a LOG Volume for Apache2 Service <br/>      ####################################################### <br/>      # Base image is BusyBox <br/>      FROM busybox:latest <br/>      # Author: Dr. Peter <br/>      MAINTAINER Dr. Peter &lt;peterindia@gmail.com&gt; <br/>      # Create a data volume at /var/log/apache2, which is <br/>      # same as the log directory PATH set for the apache image <br/>      VOLUME /var/log/apache2 <br/>      # Execute command true <br/>      CMD ["/bin/true"] 
</pre>

      <p style="padding-left: 60px">Since this <code>Dockerfile</code> is crafted to launch data-only containers, the default execution command is set to <code>/bin/true</code>.</p>

      <ol start="2">
        <li>We will continue to build a Docker image with the <code>apache2log</code> name from the preceding <code>Dockerfile</code> using <code>docker build</code>, as presented here:</li>
      </ol>

      <pre><strong> $ sudo docker build -t apache2log .</strong><br/><strong> Sending build context to Docker daemon 2.56 kB</strong><br/><strong> Sending build context to Docker daemon</strong><br/><strong> Step 0 : FROM busybox:latest</strong><br/><strong> ... TRUNCATED OUTPUT ...</strong>
</pre>

      <ol start="3">
        <li>Launch a data-only container from the <code>apache2log</code> image using the <code>docker run</code> subcommand and name the resulting container <code>log_vol</code>, using the <code>--name</code> option:</li>
      </ol>

      <pre>      <strong>$ sudo docker run --name log_vol apache2log</strong>
</pre>

      <p style="padding-left: 60px">Acting on the preceding command, the container will create a data volume in <code>/var/log/apache2</code> and move it to a stop state.</p>

      <ol start="4">
        <li>Meanwhile, you can run the <code>docker ps</code> subcommand with the <code>-a</code> option to verify the container's state:</li>
      </ol>

      <pre><strong> $ sudo docker ps -a</strong><br/><strong> CONTAINER ID IMAGE COMMAND </strong><br/><strong> CREATED STATUS PORTS </strong><br/><strong> NAMES</strong><br/><strong> 40332e5fa0ae apache2log:latest "/bin/true" </strong><br/><strong> 2 minutes ago Exited (0) 2 minutes ago </strong><br/><strong> log_vol</strong>
</pre>

      <p style="padding-left: 60px">As per the output, the container exits with the <code>0</code> exit value.</p>

      <ol start="5">
        <li>Launch the Apache2 HTTP service using the <code>docker run</code> subcommand. Here, we are reusing the <code>apache2</code> image we crafted in <a href="../Text/Ch06.xhtml">Chapter 6</a>, <em>Running Services in a Container</em>. Besides, in this container, we will mount the <code>/var/log/apache2</code> data volume from <code>log_vol</code>, the data-only container that we launched in step 3, using the <code>--volumes-from</code> option:</li>
      </ol>

      <pre>      <strong>$ sudo docker run -d -p 80:80 \</strong><br/><strong> --volumes-from log_vol \</strong><br/><strong> apache2</strong><br/><strong> 7dfbf87e341c320a12c1baae14bff2840e64afcd082dda3094e7cb0a0023cf42</strong>  
</pre>

      <p style="padding-left: 60px">With the successful launch of the Apache2 HTTP service with the <code>/var/log/apache2</code> data volume mounted from <code>log_vol</code>, we can access the log files using transient containers.</p>

      <ol start="6">
        <li>Here, we are listing the files stored by the Apache2 HTTP service, using a transient container. This transient container is spun off by mounting the <code>/var/log/apache2</code> data volume from <code>log_vol</code>, and the files in <code>/var/log/apache2</code> are listed using the <code>ls</code> command. Further, the <code>--rm</code> option of the <code>docker run</code> subcommand is used to remove the container once it is done executing the <code>ls</code> command:</li>
      </ol>

      <pre><strong> $ sudo docker run --rm \</strong><br/><strong> --volumes-from log_vol \</strong><br/><strong> busybox:latest ls -l /var/log/apache2</strong><br/><strong> total 4</strong><br/><strong> -rw-r--r-- 1 root root 0 Dec 5 15:27 </strong><br/><strong> access.log</strong><br/><strong> -rw-r--r-- 1 root root 461 Dec 5 15:27 </strong><br/><strong> error.log</strong><br/><strong> -rw-r--r-- 1 root root 0 Dec 5 15:27 </strong><br/><strong> other_vhosts_access.log</strong>
</pre>

      <ol start="7">
        <li>Finally, the error log produced by the Apache2 HTTP service is accessed using the <code>tail</code> command, as highlighted in the following command:</li>
      </ol>

      <pre><strong> $ sudo docker run --rm \</strong><br/><strong> --volumes-from log_vol \</strong><br/><strong> ubuntu:16.04 \</strong><br/><strong> tail /var/log/apache2/error.log</strong><br/><strong> AH00558: apache2: Could not reliably determine the </strong><br/><strong> server's fully qualified domain name, using 172.17.0.24. </strong><br/><strong> Set the 'ServerName' directive globally to suppress this </strong><br/><strong> message</strong><br/><strong> [Fri Dec 05 17:28:12.358034 2014] [mpm_event:notice] </strong><br/><strong> [pid 18:tid 140689145714560] AH00489: Apache/2.4.7 </strong><br/><strong> (Ubuntu) configured -- resuming normal operations</strong><br/><strong> [Fri Dec 05 17:28:12.358306 2014] [core:notice] </strong><br/><strong> [pid 18:tid 140689145714560] AH00094: Command line: </strong><br/><strong> '/usr/sbin/apache2 -D FOREGROUND'</strong>
</pre>
    
  

  
    
      <h2 id="sigil_toc_id_111">Avoiding common pitfalls</h2>
    

    
      <p>Until now, we have discussed how effectively data volumes can be used to share data between the Docker host and the containers as well as between containers. Data sharing using data volumes is turning out to be a very powerful and essential tool in the Docker paradigm. However, it does carry a few pitfalls that are to be carefully identified and eliminated. In this section, we make an attempt to list out a few common issues associated with data sharing and the ways and means to overcome them.</p>
    
  

  
    
      <h3 id="sigil_toc_id_112">Directory leaks</h3>
    

    
      <p>Earlier in the <em>Data volume</em> section, you learned that the Docker Engine automatically creates directories based on the <code>VOLUME</code> instruction in the <code>Dockerfile</code> as well as the <code>-v</code> option of the <code>docker run</code> subcommand. We also understood that the Docker Engine does not automatically delete these autogenerated directories in order to preserve the state of the application(s) run inside the container. We can force Docker to remove these directories using the <code>-v</code> option of the <code>docker rm</code> subcommand. This process of manual deletion poses two major challenges enumerated as follows:</p>

      <ul>
        <li><strong>Undeleted directories:</strong> There can be scenarios where you may intentionally or unintentionally choose not to remove the generated directory while removing the container.</li>

        <li><strong>Third-party images:</strong> Quite often, we leverage third-party Docker images that could have been built with the <code>VOLUME</code> instruction. Likewise, we might also have our own Docker images with <code>VOLUME</code> inscribed in it. When we launch containers using such Docker images, the Docker Engine will autogenerate the prescribed directories. Since we are not aware of the data volume creation, we may not call the <code>docker rm</code> subcommand with the <code>-v</code> option to delete the autogenerated directory.</li>
      </ul>

      <p>In the previously mentioned scenarios, once the associated container is removed, there is no direct way to identify the directories whose containers were removed. Here are a few recommendations on how to avoid this pitfall:</p>

      <ul>
        <li>Always inspect the Docker images using the <code>docker inspect</code> subcommand and check whether any data volume is inscribed in the image or not.</li>

        <li>Always run the <code>docker rm</code> subcommand with the <code>-v</code> option to remove any data volume (directory) created for the container. Even if the data volume is shared by multiple containers, it is still safe to run the <code>docker rm</code> subcommand with the <code>-v</code> option because the directory associated with the data volume will be deleted only when the last container sharing that data volume is removed.</li>

        <li>For any reason, if you choose to preserve the autogenerated directory, you must keep a clear record so that you can remove them at a later point.</li>

        <li>Implement an audit framework that will audit and find out the directories that do not have any container association.</li>
      </ul>
    
  

  
    
      <h3 id="sigil_toc_id_113">The undesirable effect of data volume</h3>
    

    
      <p>As mentioned earlier, Docker enables access for us to each data volume in a Docker image using the <code>VOLUME</code> instruction during the build time. Nevertheless, data volumes should never be used to store any data during the build time, otherwise it will result in an unwanted effect.</p>

      <p>In this section, we will demonstrate the undesirable effect of using data volume during the build by crafting a <code>Dockerfile</code>, and then showcase the implication by building this <code>Dockerfile</code>.</p>

      <p>The following are the details of <code>Dockerfile</code>:</p>

      <ol>
        <li>Build the image using Ubuntu 16.04 as the base image:</li>
      </ol>

      <pre>      # Use Ubuntu as the base image <br/>      FROM ubuntu:16.04 
</pre>

      <ol start="2">
        <li>Create a <code>/MountPointDemo</code> data volume using the <code>VOLUME</code> instruction:</li>
      </ol>

      <pre>      VOLUME /MountPointDemo 
</pre>

      <ol start="3">
        <li>Create a file in the <code>/MountPointDemo</code> data volume using the <code>RUN</code> instruction:</li>
      </ol>

      <pre>      RUN date &gt; /MountPointDemo/date.txt 
</pre>

      <ol start="4">
        <li>Display the file in the <code>/MountPointDemo</code> data volume using the <code>RUN</code> instruction:</li>
      </ol>

      <pre>      RUN cat /MountPointDemo/date.txt 
</pre>

      <ol start="5">
        <li>Proceed to build an image from this <code>Dockerfile</code> using the <code>docker build</code> subcommand, as shown here:</li>
      </ol>

      <pre><strong> $ sudo docker build -t testvol .</strong><br/><strong> Sending build context to Docker daemon 2.56 kB</strong><br/><strong> Sending build context to Docker daemon</strong><br/><strong> Step 0 : FROM ubuntu:16.04</strong><br/><strong> ---&gt; 9bd07e480c5b</strong><br/><strong> Step 1 : VOLUME /MountPointDemo</strong><br/><strong> ---&gt; Using cache</strong><br/><strong> ---&gt; e8b1799d4969</strong><br/><strong> Step 2 : RUN date &gt; /MountPointDemo/date.txt</strong><br/><strong> ---&gt; Using cache</strong><br/><strong> ---&gt; 8267e251a984</strong><br/><strong> Step 3 : RUN cat /MountPointDemo/date.txt</strong><br/><strong> ---&gt; Running in a3e40444de2e</strong><br/><strong> cat: /MountPointDemo/date.txt: No such file or directory</strong><br/><strong> 2014/12/07 11:32:36 The command [/bin/sh -c cat </strong><br/><strong> /MountPointDemo/date.txt] returned a non-zero code: 1</strong>
</pre>

      <p>In the preceding output of the <code>docker build</code> subcommand, you would have noticed that the build fails in step 3 because it could not find the file created in step 2. Apparently, the file that was created in step 2 vanishes when it reaches step 3. This undesirable effect is due to the approach Docker uses to build its images. An understanding of the Docker image-building process will unravel the mystery.</p>

      <p>In the build process, for every instruction in a <code>Dockerfile</code>, the following steps are followed:</p>

      <ol>
        <li>Create a new container by translating the <code>Dockerfile</code> instruction to an equivalent <code>docker run</code> subcommand.</li>

        <li>Commit the newly-created container to an image.</li>

        <li>Repeat steps 1 and 2 by treating the newly-created image as the base image for step 1.</li>
      </ol>

      <p>When a container is committed, it saves the filesystem of the container and deliberately does not save the filesystem of the data volumes. Therefore, any data stored in the data volume will be lost in this process. So, never use a data volume as a storage during the build process.</p>
    
  

  
    
      <h2 id="sigil_toc_id_114">Summary</h2>
    

    
      <p>For enterprise-scale distributed applications to be distinct in their operations and outputs, data is the most important instrument and ingredient. With IT containerization, the journey takes off in a brisk and bright fashion. IT as well as business software solutions are intelligently containerized through the smart leverage of the Docker Engine. However, the original instigation is the need for a faster and flawless realization of application-aware Docker containers, and hence, the data is tightly coupled with the application within the container. However, this closeness brings in some real risks. If the application collapses, then the data is also gone. Also, multiple applications might depend on the same data and hence, data has to be shared across.</p>

      <p>In this chapter, we discussed the capabilities of the Docker Engine in facilitating the seamless data sharing between the Docker host and container as well as between containers. The data volume is being prescribed as the foundational building block for enabling data sharing among the constituents of the growing Docker ecosystem. In the next chapter, we will explain the concept behind the container orchestration, and see how this complicated aspect gets simplified through a few automated tools. Orchestration is indispensable for realizing composite containers.</p>
    
  
</body></html>