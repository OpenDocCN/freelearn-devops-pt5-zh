<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Running Containers in AWS</h1>
                </header>
            
            <article>
                
<p><span>In</span> <span class="ChapterrefPACKT"><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml">Chapter 6</a>, <a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml"/><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml"/><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml"/><em>Scaling Your Infrastructure</em></span><span>, our architecture changed quite a bit. W</span><span>e explored different ways to scale our applications in AWS, but one of the major technologies that we left out was containers. Containers are at the heart of the <strong>software development life cycle</strong> (<strong>SDLC</strong>) of many major technology companies.</span></p>
<p>So far, we have used our personal computers to develop our applications. This works well for simple projects, such as our Hello World <span>application. However, when it comes to more complex projects with many dependencies, it's a different story. Have you ever heard of situations in which</span> a certain feature works on a developer's laptop but does not work for the rest of the organization-or-even worse, <em>does not work in production?</em> <span>A lot of these issues stem from the differences between environments. When we build our staging and production environments, we rely on CloudFormation, Terraform, and Ansible, to keep those environments consistent. Unfortunately, we can't easily replicate that to our local development environment.</span></p>
<p>Containers address this issue. With them, we can package an application and include the operating system, the application code, and everything in between. Containers can also help at a later stage, when it's time to break out the monolithic approach.</p>
<p>In this chapter, we will look at <strong>Docker</strong>, the most popular container technology. After a brief explanation of what Docker is and how to use its basic functionalities, we will Dockerize our application. This will help us to understand the value of using Docker as a developer. In this chapter, we will cover the following topics:</p>
<ul>
<li>Dockerizing our Hello World application</li>
<li>Using the EC2 container service</li>
<li>Updating our CI/CD pipeline to utilize ECS</li>
</ul>
<div class="packt_infobox">This book covers ECS, but also offers further options for using Docker in AWS. You can also take a look at CoreOS Tectonic <span>(<a href="https://tectonic.com/" target="_blank">https://tectonic.com/</a>), Mesosphere DC/OS (<a href="https://mesosphere.com/">https://mesosphere.com</a>), or Docker Datacenter (<a href="https://www.docker.com/products/docker-datacenter" target="_blank">https://www.docker.com/products/docker-datacenter</a>).</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p class="mce-root">The technical requirements for this chapter are as follows:</p>
<ul>
<li>Docker</li>
<li>Dockerfile</li>
<li><strong>EC2 Container Registry</strong> (<strong>ECR</strong>)</li>
<li><strong>Elastic Container Service</strong> (<strong>ECS</strong>)</li>
<li><strong>Application Load Balancer</strong> (<strong>ALB</strong>)</li>
<li>CodeBuild</li>
<li>CodePipeline</li>
</ul>
<p>The GitHub links for the code used in this chapter are as follows:</p>
<ul>
<li><a href="https://github.com/yogeshraheja/helloworld/blob/master/helloworld.js" target="_blank"><span class="MsoHyperlink">https://github.com/yogeshraheja/helloworld/blob/master/helloworld.js</span></a></li>
<li><a href="https://github.com/yogeshraheja/helloworld/blob/master/package.json" target="_blank"><span class="MsoHyperlink">https://github.com/yogeshraheja/helloworld/blob/master/package.json</span></a></li>
<li><a href="https://github.com/yogeshraheja/helloworld/blob/master/Dockerfile" target="_blank"><span class="MsoHyperlink">https://github.com/yogeshraheja/helloworld/blob/master/Dockerfile</span></a></li>
<li><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ecr-repository-cf-template.py" target="_blank"><span class="MsoHyperlink">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ecr-repository-cf-template.py</span></a></li>
<li><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ecs-cluster-cf-template.py" target="_blank"><span class="MsoHyperlink">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ecs-cluster-cf-template.py</span></a></li>
<li><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-ecs-alb-cf-template.py" target="_blank"><span class="MsoHyperlink">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-ecs-alb-cf-template.py</span></a></li>
</ul>
<ul>
<li><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-ecs-service-cf-template.py" target="_blank"><span class="MsoHyperlink">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-ecs-service-cf-template.py</span></a></li>
<li><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-codebuild-cf-template.py" target="_blank"><span class="MsoHyperlink">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-codebuild-cf-template.py</span></a></li>
<li><a href="https://raw.githubusercontent.com/yogeshraheja/EffectiveDevOpsTemplates/master/helloworld-ecs-service-cf-template.py" target="_blank"><span class="MsoHyperlink">https://raw.githubusercontent.com/yogeshraheja/EffectiveDevOpsTemplates/master/helloworld-ecs-service-cf-template.py</span></a></li>
<li><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-codepipeline-cf-template.py" target="_blank"><span class="MsoHyperlink">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-codepipeline-cf-template.py</span></a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dockerizing our Hello World application</h1>
                </header>
            
            <article>
                
<p><span>Docker, and containers in general, are very powerful tools, worth exploring. By combining resource isolation features, including <strong>union capable filesystem</strong> (<strong>UCF</strong>), Docker allows for the creation of packages called <strong>containers</strong></span>, which <span>include everything that is needed to run an application. Containers, like virtual machines, are self-contained, but they virtualize the OS itself,</span> <span>instead of virtualizing the hardware</span><span>. In practice, this makes a huge difference. As you have probably noticed by now, starting a virtual machine, such as an EC2 instance, takes time. This comes from the fact that in order to start a virtual machine, the hypervisor (that's the name of the technology that creates and runs virtual machines) has to simulate all of the motions involved in starting a physical server, loading an operating system, and going through the different run-levels. In addition, virtual machines have a much larger footprint on the disk and in the memory. With Docker, the added layer is hardly noticeable, and the size of the containers can stay very small. In order to better illustrate this, we will first install Docker and explore its basic usage a bit.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting started with Docker</h1>
                </header>
            
            <article>
                
<p><span>Before we start to use Docker, it might be useful to</span> <span>better</span> <span>understand Docker's concept and architecture. First, we will discuss Docker's fundamental changes with regards to the SDLC. Following that introduction, we will install Docker on our computers and look at some of the most common commands needed to use Docker.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Docker fundamentals</h1>
                </header>
            
            <article>
                
<p>The best way to understand how Docker works is to compare how using Docker differs from what we've done so far:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c68877c6-26c3-4a77-a641-937b0f365231.png"/></p>
<p class="mce-root">The preceding diagram can be explained as follows:</p>
<ul>
<li>The first stack on the left represents what we did so far. Using the EC2 service, we picked an AMI providing AWS Linux, and, with the help of the user data field, we installed Ansible to configure our system. When Ansible kicks in, it installs and configures the system, so that later, CodeDeploy can deploy and run our application.</li>
<li>The middle stack represents what it means to use Docker on top of EC2. The process starts the same way with an AMI running AWS Linux. However, this time, instead of relying on Ansible and CodeDeploy, we will simply install the Docker server application. After that, we will deploy Docker containers, which will have everything that was previously provided by Ansible and CodeDeploy.</li>
<li>Finally, the big win of that architecture is what we see on the last stack on the right. No matter what the underlying technology is, as long as we can run a Docker server, we can run the exact same container. This means that we can easily test what we will deploy on EC2. Similarly, if an issue happens in a container running on an EC2 instance, we can pull the exact same container and run it locally to possibly troubleshoot the issue.</li>
</ul>
<p class="mce-root"/>
<p>In order to make that happen, Docker relies on a couple of key concepts, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/87dc7058-dd1d-4f80-a35d-4ac2568dce89.png"/></p>
<p><span>At its core, Docker runs a daemon that loads images (templates describing the stack of the application, including the operating system, application code, and everything in between) and runs them in self-contained directories called containers. When working in Docker, as a developer, your work mostly consists of building new images by layering new commands on top of pre-existing images. Images are stored in external registries. Those registries can be public or private. Finally, all the interaction is done through a RESTful API, usually using the command-line interface.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Docker in action</h1>
                </header>
            
            <article>
                
<p>To see Docker in action, we will start by installing it on our computer. The installation of Docker is very straightforward; you can follow the instructions found at <span><a href="http://dockr.ly/2iVx6yG" target="_blank">http://dockr.ly/2iVx6yG</a> to install and start Docker on Mac, Linux, and Windows. Docker provides two offerings: Docker <strong>Community Edition</strong> (<strong>CE</strong>) and Docker <strong>Enterprise Edition</strong> (<strong>EE</strong>). Throughout this book, we are going to focus on open source tools, as well as using Docker CE, which is free of cost. Again, we will be demonstrating the following examples on a Linux based Centos 7.x distribution. If you are also following the same operating system then follow the instructions available at <a href="https://docs.docker.com/install/linux/docker-ce/centos/" target="_blank">https://docs.docker.com/install/linux/docker-ce/centos/</a> to set up Docker locally on your system. When you are done with the installation of Docker CE, verify the installed Docker version using the <kbd>docker</kbd> utility. At the time of writing this book, <kbd>18.06</kbd> is the latest version of Docker, although you might see a newer version on your system now:</span></p>
<pre><strong>$ docker –version</strong><br/><strong>Docker version 18.06.1-ce, build e68fc7a
</strong></pre>
<p>Once Docker is up and running, we can start using it as follows:</p>
<ol>
<li><span>The first thing that we will do is pull an image from a registry. By default, Docker points to Docker Hub (</span><span><a href="https://hub.docker.com/" target="_blank">https://hub.docker.com</a>), which is the official Docker registry from the company Docker Inc. In order to pull an image, we will run the following command:</span></li>
</ol>
<pre style="padding-left: 90px"><strong>$ docker pull alpine</strong> </pre>
<p style="padding-left: 60px">We will use the <kbd>latest</kbd> default tag, as follows:</p>
<pre style="padding-left: 90px"><strong>Using default tag: latest</strong><br/><strong>latest: Pulling from library/alpine</strong><br/><strong>8e3ba11ec2a2: Pull complete</strong><br/><strong>Digest: sha256:7043076348bf5040220df6ad703798fd8593a0918d06d3ce30c6c93be117e430</strong><br/><strong>Status: Downloaded newer image for alpine:latest
</strong></pre>
<ol start="2">
<li>In a matter of seconds, Docker will download the image called <kbd>alpine</kbd> from the registry, which is a minimal Docker image based on Alpine Linux with a complete package index. This is only <kbd>4.41 MB</kbd> in size:</li>
</ol>
<pre style="padding-left: 90px"><strong>$ docker images</strong><br/><strong>REPOSITORY  TAG     IMAGE ID      CREATED       SIZE</strong><br/><strong>alpine      latest  11cd0b38bc3c  2 months ago  4.41 MB
</strong></pre>
<p class="mce-root"/>
<p style="padding-left: 60px">When working with Docker, the size of a container matters. Consequently, working with smaller base images, such as Alpine Linux, is highly recommended.</p>
<ol start="3">
<li>We can now run our container. In order to do this, we will start with the following simple command:</li>
</ol>
<pre style="padding-left: 90px"><strong>$ docker run alpine echo "Hello World" Hello World</strong> </pre>
<ol start="4">
<li>On the surface, not a lot seems to have happened here, and we were left with the same output as we had when running echo <kbd>Hello World</kbd> without Docker. What really happened behind the scenes is a lot more interesting; Docker loaded the <kbd>alpine</kbd> Linux image that we previously pulled, and used the Alpine operating system <kbd>echo</kbd> command to print <kbd>Hello World</kbd>. Finally, because the <kbd>echo</kbd> <span>command</span> completed, the container was terminated.</li>
</ol>
<p>Containers can also be used in a more interactive way, as follows:</p>
<ul>
<li><span>We can, for example, start a shell and interact with it by using the following command:</span></li>
</ul>
<pre style="padding-left: 90px"><strong>$ docker run -it alpine /bin/sh</strong></pre>
<p style="padding-left: 60px">The <kbd>-i</kbd> <span>option</span> <span>means</span> interactive<span>; this allows us to type commands in our container while the</span> <kbd>-t</kbd> <span>option</span> <span>allocates a pseudo TTY to see what we are typing as well as the output of our commands.</span></p>
<ul>
<li>Containers can also be run in the background by using the <kbd><span>-d</span></kbd> <span>option, which will detach our container from the Terminal:</span></li>
</ul>
<pre style="padding-left: 90px"><strong>$ docker run -d alpine sleep 1000 c274537aec04d08c3033f45ab723ba90bcb40240d265851b28f39122199b0600</strong> </pre>
<p style="padding-left: 60px">This command returns a 64-bit long ID of the container running the <kbd>alpine</kbd> image and the <span>sleep <kbd>1000</kbd></span> c<span>ommand</span><span>.</span></p>
<ul>
<li>We can keep track of the different running containers running by using the following command:</li>
</ul>
<pre style="padding-left: 90px"><strong>$ docker ps</strong> </pre>
<p class="MsoBodyText CDPAlignLeft CDPAlign" style="padding-left: 60px">The output of running the preceding command is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/1bd7bd33-00e4-4266-aae0-fe91c4a52faf.png"/></p>
<ul>
<li>Running containers can be stopped using the <kbd>stop</kbd> option followed by the container name or ID (adapt the ID and name based on the output of your <kbd><span>docker ps</span></kbd> command):</li>
</ul>
<pre style="padding-left: 90px"><strong>$ docker stop c274537aec04 c274537aec04</strong> </pre>
<p style="padding-left: 60px">You can also use the following command:</p>
<pre style="padding-left: 90px"><strong>$ docker stop friendly_dijkstra friendly_dijkstra</strong> </pre>
<ul>
<li>Stopped containers can be started again with the <kbd><span>start</span></kbd> option, as follows:</li>
</ul>
<pre style="padding-left: 90px"><strong>$ docker start friendly_dijkstra friendly_dijkstra</strong> </pre>
<ul>
<li><span>Finally, containers can be removed by using the the</span> <kbd><span>rm</span></kbd> command, but always stop the container before removing them:</li>
</ul>
<pre style="padding-left: 90px"><strong>$ docker stop &lt;ID/NAME&gt;</strong><br/><strong>$ docker rm &lt;ID/NAME&gt; 
</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/110220a2-1d44-4f16-b631-f7ad7c814dfa.png"/></p>
<p><span>This brief overview should provide us with the knowledge we need when reading this chapter. We will discover a few more commands along the way, but for a complete list of options, you can use the</span> <kbd>d<span>ocker help</span></kbd> <span>command or consult the Docker CLI documentation at</span> <span><a href="http://dockr.ly/2jEF8hj">http://dockr.ly/2jEF8hj</a>. Running simple commands through containers is sometimes useful but, as we know, the real strength of Docker is its ability to handle any code, including our web application. In order to make that happen, we will use another key concept of Docker: a Dockerfile.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating our Dockerfile</h1>
                </header>
            
            <article>
                
<p>Dockerfiles are text files that are usually collocated with applications that instruct Docker on how to build a new Docker image. Through the creation of those files, you have the ability to tell Docker which Docker image to start from, what to copy on the container filesystem, what network port to expose, and so on. You can find the full documentation of the Dockerfile at <span><a href="http://dockr.ly/2jmoZMw" target="_blank">http://dockr.ly/2jmoZMw</a><span class="MsoHyperlink">.</span> We are going to create a Dockerfile for our</span> Hello World application, at the root of the <kbd>helloworld</kbd> project that we created in our GitHub repository, using the following commands:</p>
<pre><strong>$ cd helloworld</strong><br/><strong>$ touch Dockerfile
</strong></pre>
<p>The first instruction of a Dockerfile is always a <kbd>FROM</kbd> instruction. This tells Docker which Docker image to start from. We could use the Alpine image, as we did, but we can also save some time by using an image that has more than just an operating system. <span>Through Docker Hub, the official Docker registry, Docker provides a number of curated sets of Docker repositories called</span> <strong>official</strong><span>. We know that in order to run our application, we need</span> N<span>ode.js</span> and <kbd>npm</kbd><span>. We can use the Docker CLI to look for an official <kbd>node</kbd> image. To do that, we will use the</span> <kbd><span>docker search</span></kbd> <span>command and filter only on official images:</span></p>
<pre><strong>$ docker search --filter=is-official=true node<br/>NAME    DESCRIPTION                                   STARS  OFFICIAL     <br/>           AUTOMATED<br/>node    Node.js is a JavaScript-based platform for s… 6123    [OK]
</strong></pre>
<p class="mce-root"/>
<p>Alternatively, we can also search for this using our browser. As a result, we would end up with that same image, <span><a href="https://hub.docker.com/_/node/" target="_blank">https://hub.docker.com/_/node/</a>. As we can see, the following screenshot comes in a variety of versions:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ea4202d1-ce5c-474e-a493-1bc16c06733a.png"/></p>
<p>Docker images are always made up of a name and a tag, using the syntax <kbd>name:tag</kbd><span>. If the tag is omitted, Docker will default to</span> <kbd>latest</kbd><span>. From the</span> <span>preceding</span> <kbd><span>docker pull</span></kbd> <span>command, we can see how the output says <kbd>Using default tag: latest</kbd>. When creating a Dockerfile, it is best practice to use an explicit tag that doesn't change over time (unlike the</span> <kbd>latest</kbd> tag).</p>
<div class="packt_tip">If you are trying to migrate an application currently running on AWS Linux and make a certain number of assumptions based on that OS, you may want to look into using the official AWS Docker image. You can read more about this at <span><a href="http://amzn.to/2jnmklF" target="_blank">http://amzn.to/2jnmklF</a><span class="MsoHyperlink">.</span></span></div>
<p>On the first line of our file, we will add the following:</p>
<pre>FROM node:carbon</pre>
<p>This will tell Docker that we want to use that specific version of the <kbd>node</kbd> image. This means that we won't have to install <span><kbd>node</kbd></span> or <kbd>npm</kbd>. Since we have the OS and runtime binaries needed by our application, we can start looking into adding our application to this image. First, we will want to create a directory on top of the <kbd><span>node:carbon</span></kbd> image's filesystem, to hold our code. We can do that using the <kbd>RUN</kbd> <span>instruction, as follows</span>:</p>
<pre>RUN mkdir -p /usr/local/helloworld/</pre>
<p>We now want to copy our application files onto the image. We will use the <kbd><span>COPY</span></kbd> directive to do that:</p>
<pre>COPY helloworld.js package.json /usr/local/helloworld/</pre>
<div class="packt_infobox"><span>Make sure that you copy the <kbd>helloworld.js</kbd> and <kbd>package.json</kbd> files inside the <kbd>/helloworld</kbd> project directory where you are</span> locally <span>developing Dockerfile. The files are placed at</span> <a href="https://github.com/yogeshraheja/helloworld/blob/master/helloworld.js" target="_blank">https://github.com/yogeshraheja/helloworld/blob/master/helloworld.js</a> <span>and</span> <a href="https://github.com/yogeshraheja/helloworld/blob/master/package.json" target="_blank">https://github.com/yogeshraheja/helloworld/blob/master/package.json</a>.</div>
<p>We will now use the <span><kbd>WORKDIR</kbd></span> instruction to set our new working directory to be that <kbd>helloworld</kbd> directory:</p>
<pre> WORKDIR /usr/local/helloworld/</pre>
<p>We can now run the <kbd><span>npm install</span></kbd> command to download and install our dependencies. Because we won't use that container to test our code, we can just install the <kbd>npm</kbd> packages needed for production, as follows:</p>
<pre>RUN npm install --production</pre>
<p>Our application uses port <kbd>3000</kbd>. We need to make this port accessible to our host. In order to do that, we will use the <kbd><span>EXPOSE</span></kbd> instruction:</p>
<pre>EXPOSE 3000</pre>
<p>Finally, we can start our application. For that, we will use the <kbd><span>ENTRYPOINT</span></kbd> instruction:</p>
<pre>ENTRYPOINT [ "node", "helloworld.js" ]</pre>
<p>We can now save the file. It should look like the template at <span><a href="https://github.com/yogeshraheja/helloworld/blob/master/Dockerfile" target="_blank">https://github.com/yogeshraheja/helloworld/blob/master/Dockerfile</a>. <a href="https://github.com/yogeshraheja/helloworld/blob/master/Dockerfile"/></span>We can now build our new image.</p>
<p>Back in the Terminal, we will again use the <kbd>docker</kbd> <span>command, but this time with the</span> <kbd>build</kbd> <span>argument</span><span>. We will also use the</span> <kbd><span>-t</span></kbd> <span>option</span> <span>to provide the name</span> <kbd>helloworld</kbd> <span>to our image, followed by a (<kbd>.</kbd>) dot that indicates the location of our Dockerfile:</span></p>
<pre><strong>$ docker build -t helloworld .<br/>Sending build context to Docker daemon 4.608kB<br/>Step 1/7 : FROM node:carbon<br/>carbon: Pulling from library/node<br/>f189db1b88b3: Pull complete<br/>3d06cf2f1b5e: Pull complete<br/>687ebdda822c: Pull complete<br/>99119ca3f34e: Pull complete<br/>e771d6006054: Pull complete<br/>b0cc28d0be2c: Pull complete<br/>9bbe77ca0944: Pull complete<br/>75f7d70e2d07: Pull complete<br/>Digest: sha256:3422df4f7532b26b55275ad7b6dc17ec35f77192b04ce22e62e43541f3d28eb3<br/>Status: Downloaded newer image for node:carbon<br/> ---&gt; 8198006b2b57<br/>Step 2/7 : RUN mkdir -p /usr/local/helloworld/<br/> ---&gt; Running in 2c727397cb3e<br/>Removing intermediate container 2c727397cb3e<br/> ---&gt; dfce290bb326<br/>Step 3/7 : COPY helloworld.js package.json /usr/local/helloworld/<br/> ---&gt; ad79109b5462<br/>Step 4/7 : WORKDIR /usr/local/helloworld/<br/> ---&gt; Running in e712a394acd7<br/>Removing intermediate container e712a394acd7<br/> ---&gt; b80e558dff23<br/>Step 5/7 : RUN npm install --production<br/> ---&gt; Running in 53c81e3c707a<br/>npm notice created a lockfile as package-lock.json. You should commit this file.<br/>npm WARN helloworld@1.0.0 No description<br/><br/>up to date in 0.089s<br/>Removing intermediate container 53c81e3c707a<br/> ---&gt; 66c0acc080f2<br/>Step 6/7 : EXPOSE 3000<br/> ---&gt; Running in 8ceba9409a63<br/>Removing intermediate container 8ceba9409a63<br/> ---&gt; 1902103f865c<br/>Step 7/7 : ENTRYPOINT [ "node", "helloworld.js" ]<br/> ---&gt; Running in f73783248c5f <br/>Removing intermediate container f73783248c5f<br/> ---&gt; 4a6cb81d088d<br/>Successfully built 4a6cb81d088d<br/>Successfully tagged helloworld:latest
</strong></pre>
<p>As you can see, each command produces a new intermediary container with the changes triggered by that step.</p>
<p>We can now run our newly created image to create a container with the following command:</p>
<pre><strong>$ docker run -p 3000:3000 -d helloworld e47e4130e545e1b2d5eb2b8abb3a228dada2b194230f96f462a5612af521ddc5</strong> </pre>
<p>Here, we are adding the<kbd>-p</kbd> option to our command to map the exposed port of our container to a port on our host. There are a few ways to validate that our container is working correctly. We can start by looking at the logs produced by our container (replace the container ID with the output of the previous command):</p>
<pre><strong>$ docker logs e47e4130e545e1b2d5eb2b8abb3a228dada2b194230f96f462a5612af521ddc5 </strong><br/><strong>Server running</strong> </pre>
<p>We can also use the <kbd><span>docker ps</span></kbd> command to see the status of our container:</p>
<pre><strong>$ docker ps</strong> </pre>
<p class="MsoBodyText CDPAlignLeft CDPAlign">The output of the preceding command is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e2440413-c06d-48aa-a81d-6b7da5fd9448.png"/></p>
<p>And, of course, we can simply test the application with the <kbd>curl</kbd> command:</p>
<pre><strong>$ curl localhost:3000<br/>Hello World</strong> </pre>
<p>Also, if your host has a public IP then you can even verify the outputs on the browser with <kbd>&lt;ip:exposedport&gt;</kbd>, which in my case is <kbd>54.205.200.149:3000</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b3adc093-30ac-418d-ba0a-0e7e057a5f76.png" style="width:24.50em;height:4.83em;"/></p>
<p>Finally, kill the container using the <kbd>docker kill</kbd> command and container ID:</p>
<pre><strong>$ docker kill e47e4130e545</strong><br/><strong>e47e4130e545</strong></pre>
<p>Since our image is <span>working</span> <span>correctly, we can commit the code to GitHub:</span></p>
<pre><strong>$ git add Dockerfile</strong><br/><strong>$ git commit -m "Adding Dockerfile"</strong><br/><strong>$ git push
</strong></pre>
<p>In addition, you can now create an account (for free) on Docker Hub and upload that new image. If you want to give it a try, you can follow the instructions at <span><a href="http://dockr.ly/2ki6DQV" target="_blank">http://dockr.ly/2ki6DQV</a>.</span></p>
<p>Having the ability to easily share containers makes a big difference when collaborating on projects. Instead of sharing code and asking people to compile or build packages, you can actually share a Docker image. For instance, this can be done by running the following:</p>
<pre><strong>docker pull yogeshraheja/helloworld</strong> </pre>
<p class="mce-root">The output of running the preceding command is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/8bdb0d8a-8b89-48e9-8e3c-e0ae88bb3309.png"/></p>
<p><span>You can experience the</span> Hello World <span>application, the exact way I see it</span><span>,</span> <span>no matter what your underlying architecture is. This new way of running applications makes Docker a very strong solution for sharing work or collaborating on projects. Docker's strengths do not end with work collaboration, however. As we are about to see, using containers in production is also a very interesting option. In order to easily implement such solutions, AWS created the EC2 container service. We are going to use it to deploy our newly created</span> <kbd>helloworld</kbd> image.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using the EC2 container service</h1>
                </header>
            
            <article>
                
<p>We just went over creating a Docker image for our application. Here, we saw how easy and fast it is to start a container using Docker. This is a very transformative experience compared to using only virtual machine technologies such as EC2. <span>One possibility that we haven't explicitly mentioned so far is that you can start multiple containers with the same image. We can, for example, start our</span> <kbd>helloworld</kbd> <span>container five times, binding five different ports using the following command (adapt the ID based on the image ID you built. If needed, run</span> D<span>ocker images</span> <span>to find its ID):</span></p>
<pre><strong>$ for p in {3001..3005}; do docker run -d -p ${p}:3000 4a6cb81d088d; done </strong> </pre>
<p>We can validate that everything is working using the <kbd><span>ps</span></kbd> and <kbd>curl</kbd> commands:</p>
<pre><strong>$ docker ps</strong><strong><br/>$ curl localhost:3005</strong> </pre>
<p class="mce-root">The output of running the preceding command is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/6bc2a770-1f61-41fa-b8aa-be32f8b55a01.png"/></p>
<div class="packt_tip"><span class="packt_screen">Cleaning up containers:</span><br/>
We can clean up everything by stopping and removing all containers with these two handy one-line commands:<br/>
<ul>
<li><strong><kbd>$ docker stop $(docker ps -a -q)</kbd></strong></li>
<li><strong><kbd>$ docker system prune</kbd></strong></li>
</ul>
</div>
<p>The output of running the preceding commands is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f26a7e76-daad-43cd-bac0-4b92cec1cb45.png" style="width:37.67em;height:34.67em;"/></p>
<p><span>This ability to start multiple containers on a single host with almost no overhead or latency makes Docker an ideal candidate for production. In addition, more and more companies are deciding to take the service-oriented architecture approach to an all-new level by breaking out each business function into a separate service. This is often called a <strong>microservices</strong> approach. Docker is a natural fit for microservices and for managing microservice architecture. This is because it provides a platform that is language agnostic (you can start any type of application written in any language inside your container), able to scale horizontally and vertically with ease, and a common story around deployment as we deploy containers instead of a variety of services.</span> <span>We will implement our container architecture using the <strong>Infrastructure as Code</strong> (<strong>IaC</strong>) best practices and use CloudFormation through the intermediary of Troposphere. The first service we are going to look at is AWS's ECR.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating an ECR repository to manage our Docker image</h1>
                </header>
            
            <article>
                
<p><span>In the first part of this chapter, we used the Docker Hub public registry. AWS provides a similar service to this called ECR. This allows you to keep your images in a private registry called a <strong>repository</strong>. ECR is fully compatible with the Docker CLI but also integrates deeply with the remaining ECS services. We are going to use this to store our</span> <kbd>helloworld</kbd> images.</p>
<p><span>As mentioned, we will</span> <span>rely</span> <span>heavily on CloudFormation to make our changes. Unlike what we saw</span> previously<span>, because of its nature, the ECS infrastructure we are going to build needs to be very modular. This is because, in practice, we will want to share some of those components with other services. Consequently, we will create a number of templates and link them to one another. One good way to do that is to rely on CloudFormation's export ability, which allows us to do cross-stack referencing.</span></p>
<div class="packt_tip">One of the added bonuses that export provides is a fail-safe mechanism. You can't delete or edit a stack if another stack references an exported output.</div>
<p><span>To generate our template, we will create a new Troposphere script. To do this, go to the <kbd>EffectiveDevOpsTemplates</kbd> repository and create a new script named</span> <kbd>ecr-repository-cf- template.py</kbd>.</p>
<p>We will start by importing a number of modules, including the <span><kbd>Export</kbd></span> mentioned earlier and the <kbd>ecr</kbd> module, in order to create our repository. We will also create our template variable, <kbd><span>t</span></kbd>, as we did in previous chapters:</p>
<pre>"""Generating CloudFormation template."""<br/><br/>from troposphere import ( <br/>Export,<br/>Join, <br/>Output,<br/>Parameter, <br/>Ref, <br/>Template<br/>)<br/>from troposphere.ecr import Repository <br/>t = Template()</pre>
<p class="mce-root"/>
<p>Since we are going to create a number of CloudFormation templates in this chapter, we will add a description so that it's easier to understand which template does what when looking at them in the AWS console:</p>
<pre>t.add_description("Effective DevOps in AWS: ECR Repository") </pre>
<p>We will create a parameter for the name of the repository so that we will be able to reuse that CloudFormation template for every repository we create:</p>
<pre>t.add_parameter(Parameter( <br/>       "RepoName", <br/>        Type="String",<br/>        Description="Name of the ECR repository to create"<br/>))</pre>
<p>We can now create our repository as follows:</p>
<pre>t.add_resource(Repository( <br/>        "Repository", <br/>         RepositoryName=Ref("RepoName")<br/>))</pre>
<p>We are keeping the code very simple here and not enforcing any particular permissions. If you need to restrict who can access your repository and see more complex configurations, you can refer to the AWS documentation and, in particular, <span><a href="http://amzn.to/2j7hA2P" target="_blank">http://amzn.to/2j7hA2P</a>. </span>Lastly, we will output the name of the repository we created and export its value through a template variable <kbd>t</kbd>:</p>
<pre>t.add_output(Output(<br/>    "Repository",<br/>    Description="ECR repository",<br/>    Value=Ref("RepoName"),<br/>    Export=Export(Join("-", [Ref("RepoName"), "repo"])),<br/>))<br/>print(t.to_json())</pre>
<p>We can save our script now. It should look like this: <span><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ecr-repository-cf-template.py" target="_blank">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ecr-repository-cf-template.py</a><span class="MsoHyperlink">.</span> We will now generate the CloudFormation template and create our stack as follows:</span></p>
<pre><strong>$ python ecr-repository-cf-template.py &gt; ecr-repository-cf.template</strong><br/><strong>$ aws cloudformation create-stack \</strong><br/><strong>    --stack-name helloworld-ecr \</strong><br/><strong>    --capabilities CAPABILITY_IAM \</strong><br/><strong>    --template-body file://ecr-repository-cf.template \</strong><br/><strong>    --parameters \ ParameterKey=RepoName,ParameterValue=helloworld
</strong></pre>
<p>After a few minutes, our stack will be created. We can validate that the repository was correctly created as follows:</p>
<pre><strong>$ aws ecr describe-repositories</strong><br/><strong>{</strong><br/><strong>    "repositories": [</strong><br/><strong>        {</strong><br/><strong>            "registryId": "094507990803",</strong><br/><strong>            "repositoryName": "helloworld",</strong><br/><strong>            "repositoryArn": "arn:aws:ecr:us-east- <br/>             1:094507990803:repository/helloworld",</strong><br/><strong>            "createdAt": 1536345671.0,</strong><br/><strong>            "repositoryUri": "094507990803.dkr.ecr.us-east-<br/>             1.amazonaws.com/helloworld"</strong><br/><strong>        }</strong><br/><strong>    ]</strong><br/><strong>}
</strong></pre>
<p>We can see our exported output with the following command:</p>
<pre><strong>$ aws cloudformation list-exports</strong><br/><strong>{</strong><br/><strong>    "Exports": [</strong><br/><strong>        {</strong><br/><strong>            "ExportingStackId": "arn:aws:cloudformation:us-east-<br/>             1:094507990803:stack/helloworld-ecr/94d9ed70-b2cd-11e8-<br/>             b767-50d501eed2b3",</strong><br/><strong>            "Value": "helloworld",</strong><br/><strong>            "Name": "helloworld-repo"</strong><br/><strong>        }</strong><br/><strong>    ]</strong><br/><strong>}
</strong></pre>
<p>Our repository can now be used to store our <kbd>helloworld</kbd> <span>image. We will use the Docker CLI to do that. The first step of that process is to log in to the</span> <kbd>ecr</kbd> <span>service. You can do this with the following handy one-line command:</span></p>
<pre><strong>$ eval "$(aws ecr get-login --region us-east-1 --no-include-email )"</strong> </pre>
<p class="mce-root">The output of running the preceding command can be shown as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/805706d0-cfab-4e33-a0ae-de6edbd3a93c.png" style="width:49.75em;height:6.92em;"/></p>
<p>Back in our <kbd>helloworld</kbd> directory where the Dockerfile is, we will tag our image as follows:</p>
<pre><strong>$ cd helloworld</strong> </pre>
<p>It is a common practice to use the <kbd>latest</kbd> <span>tag</span> <span>to designate the most recent version of an image. In addition, you need to adapt the following command based on the output of the</span> <kbd>aws ecr describe-repositories</kbd> <span>output (we assume here that you have already built your image):</span></p>
<pre><strong>$ docker tag helloworld:latest 094507990803.dkr.ecr.us-east-1.amazonaws.com/helloworld:latest</strong> </pre>
<p>We can now push that image to our registry as follows:</p>
<pre><strong>$ docker push 094507990803.dkr.ecr.us-east-1.amazonaws.com/helloworld:latest</strong><br/><strong>The push refers to repository [094507990803.dkr.ecr.us-east-1.amazonaws.com/helloworld]</strong><br/><strong>c7f21f8d59de: Pushed</strong><br/><strong>3c36cf19a914: Pushed</strong><br/><strong>8faa1d9821d6: Pushed</strong><br/><strong>be0fb77bfb1f: Pushed</strong><br/><strong>63c810287aa2: Pushed</strong><br/><strong>2793dc0607dd: Pushed</strong><br/><strong>74800c25aa8c: Pushed</strong><br/><strong>ba504a540674: Pushed</strong><br/><strong>81101ce649d5: Pushed</strong><br/><strong>daf45b2cad9a: Pushed</strong><br/><strong>8c466bf4ca6f: Pushed</strong><br/><strong>latest: digest: sha256:95906ec13adf9894e4611cd37c8a06569964af0adbb035fcafa6020994675161 size: 2628
</strong></pre>
<p>We can see how each layer of our image is pushed in parallel to our registry. Once the operation completes, we can validate that the new image is present in our registry as follows:</p>
<pre><strong>$ aws ecr describe-images --repository-name helloworld</strong><br/><strong>{</strong><br/><strong>    "imageDetails": [</strong><br/><strong>        {</strong><br/><strong>            "imageSizeInBytes": 265821145,</strong><br/><strong>            "imageDigest": <br/>"sha256:95906ec13adf9894e4611cd37c8a06569964af0adbb035fcafa6020994675161",</strong><br/><strong>            "imageTags": [</strong><br/><strong>                "latest"</strong><br/><strong>            ],</strong><br/><strong>            "registryId": "094507990803",</strong><br/><strong>            "repositoryName": "helloworld",</strong><br/><strong>            "imagePushedAt": 1536346218.0</strong><br/><strong>        }</strong><br/><strong>    ]</strong><br/><strong>}
</strong></pre>
<p><span>At this point, our image is now available to the rest of our infrastructure. We are going to move on to the next step of our process, which is the creation of the ECS cluster.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating an ECS cluster</h1>
                </header>
            
            <article>
                
<p>Creating an ECS cluster is a very similar process to the one in <span class="ChapterrefPACKT"><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml">Chapter 6</a>, <a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml"/><em>Scaling Your Infrastructure</em></span><span>, when we created an Auto Scaling Group to run our</span> Hello World <span>application. The main difference is that there is one more level of abstraction. ECS will run a number of services called <strong>task</strong>s.</span></p>
<p>Each of those tasks may exist multiple times in order to handle the traffic:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/328a29f3-4714-484d-b04b-b22d0d86e9a3.png" style="width:47.08em;height:23.58em;"/></p>
<p>In order to do that, the ECS service provides an orchestration layer. <span>That orchestration layer is in charge of managing the life cycle of containers, including upgrading or downgrading and scaling your containers</span> <span>up or down</span><span>. The orchestration layer also distributes all containers for every service across all instances of the cluster optimally. Finally, it also exposes a discovery mechanism that interacts with other services such as ALB and ELB to register and deregister containers.</span></p>
<div class="mce-root packt_infobox"><span class="packt_screen">Task placement strategies:</span><br/>
By default, the entire orchestration system is managed by AWS. However, you also have the ability to customize it through the creation of a task placement strategy. This will let you configure the orchestration to optimize for instance count, for load distribution, to add constraints, and make sure that certain tasks are launched on the same instances.</div>
<p>We will create a new script to generate our ECS cluster. The filename will be <kbd>ecs-cluster-cf-template.py</kbd>. <span>This template starts almost exactly like the template we created in</span> <span class="ChapterrefPACKT"><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml">Chapter 6</a>, <a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml"/><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml"/><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml"/><em>Scaling Your Infrastructure</em></span><span>, for the Auto Scaling Group:</span></p>
<pre>"""Generating CloudFormation template."""<br/><br/>from ipaddress import ip_network from ipify import get_ip<br/>from troposphere import (<br/>    Base64,<br/>    Export, <br/>    Join, <br/>    Output, <br/>    Parameter, <br/>    Ref,<br/>    Sub, <br/>    Template, <br/>    ec2<br/>)<br/><br/>from troposphere.autoscaling import ( <br/>    AutoScalingGroup, <br/>    LaunchConfiguration, <br/>    ScalingPolicy<br/>)<br/><br/>from troposphere.cloudwatch import ( <br/>    Alarm,<br/>    MetricDimension<br/>)<br/>from troposphere.ecs import Cluster<br/>from troposphere.iam import (<br/>    InstanceProfile, <br/>    Role<br/>)</pre>
<p><span>The only new import is the</span> c<span>luster</span> <span>one from the ECS module. Just like we did in</span> <span class="ChapterrefPACKT"><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml">Chapter 6</a>, <em>Scaling Your Infrastructure</em></span><span>, we will extract our IP address in order to use it later for the SSH security group, create our template variable, and add a description to the stack:</span></p>
<pre>PublicCidrIp = str(ip_network(get_ip()))<br/>t = Template()<br/>t.add_description("Effective DevOps in AWS: ECS Cluster")</pre>
<p><span>We will now proceed with adding our parameters, which are the the same parameters as used in</span> <span class="ChapterrefPACKT"><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml">Chapter 6</a>, <em>Scaling Your Infrastructure</em></span><span>. This includes the</span> SSH <span>key-pair</span><span>, the</span> VPC <span>ID</span><span>, and its subnets:</span></p>
<pre>t.add_parameter(Parameter(<br/>    "KeyPair",<br/>    Description="Name of an existing EC2 KeyPair to SSH",<br/>    Type="AWS::EC2::KeyPair::KeyName",<br/>    ConstraintDescription="must be the name of an existing EC2   <br/>    KeyPair.",<br/>))<br/><br/>t.add_parameter(Parameter(<br/>    "VpcId",<br/>    Type="AWS::EC2::VPC::Id",<br/>    Description="VPC"<br/>))<br/><br/>t.add_parameter(Parameter(<br/>    "PublicSubnet",<br/>    Description="PublicSubnet",<br/>    Type="List&lt;AWS::EC2::Subnet::Id&gt;",<br/>    ConstraintDescription="PublicSubnet"<br/>))</pre>
<p>Next, we will look at creating our security group resources:</p>
<pre>t.add_resource(ec2.SecurityGroup(<br/>    "SecurityGroup",<br/>    GroupDescription="Allow SSH and private network access",<br/>    SecurityGroupIngress=[<br/>        ec2.SecurityGroupRule(<br/>            IpProtocol="tcp",<br/>            FromPort=0,<br/>            ToPort=65535,<br/>            CidrIp="172.16.0.0/12",<br/>        ),<br/>        ec2.SecurityGroupRule(<br/>            IpProtocol="tcp",<br/>            FromPort="22",<br/>            ToPort="22",<br/>            CidrIp=PublicCidrIp,<br/>        ),<br/>    ],<br/>    VpcId=Ref("VpcId")<br/>))</pre>
<div class="packt_infobox">There is one important difference here. In <span class="ChapterrefPACKT"><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml">Chapter 6</a>, <em>Scaling Your Infrastructure</em></span><span>, we opened up port</span> <kbd>3000</kbd> <span>since that's what our application is using. Here, we are opening every port to the CIDR</span> 1 <kbd>72.16.0.0/12</kbd><span>, which is the private IP space of our internal network. This will give our ECS cluster the ability to run multiple</span> <kbd>helloworld</kbd> <span>containers on the same hosts, binding different ports.</span></div>
<p>We will now create our cluster resource. This can simply be done with the following command:</p>
<pre>t.add_resource(Cluster(<br/>    'ECSCluster',<br/>))</pre>
<p><span>Next, we will focus on configuring instances of the cluster, starting with their IAM role. Overall, this is one of the more complex resources to create in ECS as the cluster will need to perform a number of interactions with other AWS services. We can create a complete custom policy for it or import the policies AWS created as follows:</span></p>
<pre>t.add_resource(Role(<br/>    'EcsClusterRole',<br/>    ManagedPolicyArns=[<br/>        'arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM',<br/>        'arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly',<br/>        'arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role',<br/>        'arn:aws:iam::aws:policy/CloudWatchFullAccess'<br/>    ],<br/>    AssumeRolePolicyDocument={<br/>        'Version': '2012-10-17',<br/>        'Statement': [{<br/>            'Action': 'sts:AssumeRole',<br/>            'Principal': {'Service': 'ec2.amazonaws.com'},<br/>            'Effect': 'Allow',<br/>        }]<br/>    }<br/>))</pre>
<p>We can now tie our role with the instance profile as follows:</p>
<pre>t.add_resource(InstanceProfile(<br/>    'EC2InstanceProfile',<br/>    Roles=[Ref('EcsClusterRole')],<br/>))</pre>
<p>The next step is to create our launch configuration. The following code snippet shows what it looks like:</p>
<pre>t.add_resource(LaunchConfiguration(<br/>    'ContainerInstances',<br/>     UserData=Base64(Join('', [<br/>        "#!/bin/bash -xe\n",<br/>        "echo ECS_CLUSTER=",<br/>        Ref('ECSCluster'),<br/>        " &gt;&gt; /etc/ecs/ecs.config\n",<br/>        "yum install -y aws-cfn-bootstrap\n",<br/>        "/opt/aws/bin/cfn-signal -e $? ",<br/>        " --stack ",<br/>        Ref('AWS::StackName'),<br/>        " --resource ECSAutoScalingGroup ",<br/>        " --region ",<br/>        Ref('AWS::Region'),<br/>        "\n"])),<br/>    ImageId='ami-04351e12',<br/>    KeyName=Ref("KeyPair"),<br/>    SecurityGroups=[Ref("SecurityGroup")],<br/>    IamInstanceProfile=Ref('EC2InstanceProfile'),<br/>    InstanceType='t2.micro',<br/>    AssociatePublicIpAddress='true',<br/>))</pre>
<p>In this example, we don't install Ansible like we did before. Instead, we are using an ECS- optimized AMI (you can read more about this at <span><a href="http://amzn.to/2jX0xVu" target="_blank">http://amzn.to/2jX0xVu</a>) that lets us use the</span> <kbd><span>UserData</span></kbd> field to configure the ECS service, and then starting it. Now that we have our launch configuration, we can create our Auto Scaling Group resources.</p>
<p>When working with ECS, scaling is needed at two levels:</p>
<ul>
<li>The containers level, as we will need to run more containers of a given service if the traffic spikes</li>
<li>The underlying infrastructure level</li>
</ul>
<p>Containers, through the intermediary of their task definitions, set a requirement for CPU and memory. They will require, for example, 1024 CPU units, which represents one core, and 256 memory units, which means 256 MB of RAM. If the ECS instances are close to being filled up on one of those two constraints, the ECS Auto Scaling Group needs to add more instances:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7a4a4d06-7d7b-46d5-88f7-dfe4d3e19d6e.png" style="width:40.33em;height:33.08em;"/></p>
<p><span>In terms of implementation, the process is very similar to what we did in</span> <span class="ChapterrefPACKT"><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml">Chapter 6</a>, <em>Scaling Your Infrastructure</em></span>. Here, we first create the A<span>uto Scaling Group</span> resource, as follows:</p>
<pre>t.add_resource(AutoScalingGroup(<br/>    'ECSAutoScalingGroup',<br/>    DesiredCapacity='1',<br/>    MinSize='1',<br/>    MaxSize='5',<br/>    VPCZoneIdentifier=Ref("PublicSubnet"),<br/>    LaunchConfigurationName=Ref('ContainerInstances'),<br/>))</pre>
<p class="mce-root"/>
<p><span>Next, we will create</span> s<span>caling policies</span> and a<span>larms</span> <span>to monitor the CPU and memory reservation metrics. In order to accomplish that, we will take advantage of Python to generate our stack and create for loops as follows:</span></p>
<pre>states = {<br/>    "High": {<br/>        "threshold": "75",<br/>        "alarmPrefix": "ScaleUpPolicyFor",<br/>        "operator": "GreaterThanThreshold",<br/>        "adjustment": "1"<br/>    },<br/>    "Low": {<br/>        "threshold": "30",<br/>        "alarmPrefix": "ScaleDownPolicyFor",<br/>        "operator": "LessThanThreshold",<br/>        "adjustment": "-1"<br/>    }<br/>}<br/><br/>for reservation in {"CPU", "Memory"}:<br/>    for state, value in states.iteritems():<br/>        t.add_resource(Alarm(<br/>            "{}ReservationToo{}".format(reservation, state),<br/>            AlarmDescription="Alarm if {} reservation too {}".format(<br/>                reservation,<br/>                state),<br/>            Namespace="AWS/ECS",<br/>            MetricName="{}Reservation".format(reservation),<br/>            Dimensions=[<br/>                MetricDimension(<br/>                    Name="ClusterName",<br/>                    Value=Ref("ECSCluster")<br/>                ),<br/>            ],<br/>            Statistic="Average",<br/>            Period="60",<br/>            EvaluationPeriods="1",<br/>            Threshold=value['threshold'],<br/>            ComparisonOperator=value['operator'],<br/>            AlarmActions=[<br/>                Ref("{}{}".format(value['alarmPrefix'], reservation))]<br/>        ))<br/>        t.add_resource(ScalingPolicy(<br/>            "{}{}".format(value['alarmPrefix'], reservation),<br/>            ScalingAdjustment=value['adjustment'],<br/>            AutoScalingGroupName=Ref("ECSAutoScalingGroup"),<br/>            AdjustmentType="ChangeInCapacity",<br/>        ))</pre>
<p class="mce-root"/>
<p>Finally, we will provide a small amount of resource information, namely the stack ID, the VPC ID, and the public subnets:</p>
<pre>t.add_output(Output(<br/>    "Cluster",<br/>    Description="ECS Cluster Name",<br/>    Value=Ref("ECSCluster"),<br/>    Export=Export(Sub("${AWS::StackName}-id")),<br/>))<br/><br/>t.add_output(Output(<br/>    "VpcId",<br/>    Description="VpcId",<br/>    Value=Ref("VpcId"),<br/>    Export=Export(Sub("${AWS::StackName}-vpc-id")),<br/>))<br/><br/>t.add_output(Output(<br/>    "PublicSubnet",<br/>    Description="PublicSubnet",<br/>    Value=Join(',', Ref("PublicSubnet")),<br/>    Export=Export(Sub("${AWS::StackName}-public-subnets")),<br/>))<br/><br/>print(t.to_json())</pre>
<div class="packt_infobox">CloudFormation provides a number of pseudo-parameters, such as <kbd>AWS::StackName</kbd><span>. Throughout the chapter, we will rely on it to make our template generic enough to be used across different environments and services. In the preceding code, we created an ECR repository for our</span> <kbd>helloworld</kbd> <span>container. The name was generated by the stack creation command. If required, we can reuse that exact same template to create another repository for another container.</span></div>
<p>The script is now complete, and should look like the script at: <span class="MsoHyperlink"><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ecs-cluster-cf-template.py" target="_blank">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ecs-cluster-cf-template.py</a>.</span></p>
<p>As before, we can now commit our script and create our stack by first generating our template, as follows:</p>
<pre><strong>$ git add ecs-cluster-cf-template.py</strong><br/><strong>$ git commit -m "Adding Troposphere script to generate an ECS cluster"</strong><br/><strong>$ git push</strong><br/><strong>$ python ecs-cluster-cf-template.py &gt; ecs-cluster-cf.template
</strong></pre>
<p><span>To create our stack, we need three parameters; the</span> key-pair<span>, the</span> <span>VPC ID</span><span>, and the</span> subnets<span>. In the previous chapters, we used the web interface to create those stacks. Here, we will look at how to get that information using the CLI.</span></p>
<p>To get the VPC ID and the subnet IDs, we can use the following commands:</p>
<pre><strong>$ aws ec2 describe-vpcs --query 'Vpcs[].VpcId' <br/>[</strong><br/><strong>    "vpc-4cddce2a"</strong><br/><strong>]</strong><br/><strong>$ aws ec2 describe-subnets --query 'Subnets[].SubnetId' <br/>[</strong><br/><strong>    "subnet-e67190bc",</strong><br/><strong>    "subnet-658b6149",</strong><br/><strong>    "subnet-d890d3e4",</strong><br/><strong>    "subnet-6fdd7927",</strong><br/><strong>    "subnet-4c99c229",</strong><br/><strong>    "subnet-b03baebc"</strong><br/><strong>]
</strong></pre>
<p>We can now create our stack by combining the preceding outputs. Since ECS clusters can run a variety of containers and a number of applications and services, we will aim for one ECS cluster per environment, starting with staging. In order to differentiate each environment, we will rely on the stack names. Consequently, it is important to call your <kbd><span>staging-cluster</span></kbd> stack, as shown here:</p>
<pre><strong>$ aws cloudformation create-stack \<br/>    --stack-name staging-cluster \<br/>    --capabilities CAPABILITY_IAM \<br/>    --template-body file://ecs-cluster-cf.template \<br/>    --parameters \             <br/>    ParameterKey=KeyPair,ParameterValue=EffectiveDevOpsAWS \     <br/>    ParameterKey=VpcId,ParameterValue=vpc-4cddce2a \<br/>    ParameterKey=PublicSubnet,ParameterValue=subnet-e67190bc\\,subnet-<br/>    658b6149\\,subnet-d890d3e4\\,subnet-6fdd7927\\,subnet-<br/>    4c99c229\\,subnet-b03baebc<br/>{<br/>    "StackId": "arn:aws:cloudformation:us-east-   <br/>    1:094507990803:stack/staging-cluster/581e30d0-b2d2-11e8-b48f-<br/>    503acac41e99"<br/>}
</strong></pre>
<p><span>We will now add a load balancer. In the previous chapter, we used an ELB for our Auto Scaling Group. Later, we also mentioned the existence of the ALB service. This time, we will create an ALB instance to proxy our application traffic.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating an ALB</h1>
                </header>
            
            <article>
                
<p>As mentioned previously, ECS provides an orchestrator that takes care of allocating the containers across our Auto Scaling Group. It also keeps track of which port each container uses and integrates with ALB so that our load balancer can correctly route the incoming traffic to all containers running a given service. ECS supports both the ELB and ALB services but the ALB gives more flexibility when working with containers. We will demonstrate how to create an ALB using CloudFormation through Troposphere.</p>
<p><span>We will start by creating a new file and calling it</span> <kbd>helloworld-ecs-alb-cf-template.py</kbd>. We will then put our usual import<span>, and will create our template variable and add a description, as follows:</span></p>
<pre>"""Generating CloudFormation template."""<br/><br/>from troposphere import elasticloadbalancingv2 as elb<br/><br/>from troposphere import (<br/>    Export,<br/>    GetAtt,<br/>    ImportValue,<br/>    Join,<br/>    Output,<br/>    Ref,<br/>    Select,<br/>    Split,<br/>    Sub,<br/>    Template,<br/>    ec2<br/>)<br/><br/>t = Template()<br/><br/>t.add_description("Effective DevOps in AWS: ALB for the ECS Cluster")</pre>
<p>We are now going to create our security group. No surprises here; we are opening <kbd>TCP/3000</kbd> to the world, as we did in <span class="ChapterrefPACKT"><a href="c54f64c9-e8a3-4eed-b68d-087ff40f8b1d.xhtml" target="_blank">Chapter 6</a>, <em>Scaling Your Infrastructure</em></span>, with the ELB:</p>
<pre>t.add_resource(ec2.SecurityGroup(<br/>    "LoadBalancerSecurityGroup",<br/>    GroupDescription="Web load balancer security group.",<br/>    VpcId=ImportValue(<br/>        Join(<br/>            "-",<br/>            [Select(0, Split("-", Ref("AWS::StackName"))),<br/>                "cluster-vpc-id"]<br/>        )<br/>    ),<br/>    SecurityGroupIngress=[<br/>        ec2.SecurityGroupRule(<br/>            IpProtocol="tcp",<br/>            FromPort="3000",<br/>            ToPort="3000",<br/>            CidrIp="0.0.0.0/0",<br/>        ),<br/>    ],<br/>))</pre>
<p><span>The main difference from what we did previously is that instead of starting with a parameter section and requesting, yet again, to provide the VPC ID and public subnets, we are taking advantage of the value that we exported before. When we launch this stack, we will call it</span> <kbd>staging-alb</kbd><span>. The block of code inside the</span> <kbd><span>ImportValue</span></kbd> parameter <span>does the following:</span></p>
<ol>
<li><span>First, we get the name of our stack. We will launch that stack under the name</span> <kbd>staging-alb</kbd>.</li>
<li><span>The</span> <kbd>S<span>plit</span></kbd> <span>function breaks the stack name on the character</span> <kbd>-</kbd><span>, meaning that we end up with</span> [<kbd>staging</kbd>, <kbd>alb</kbd>].</li>
<li><span>The</span> <kbd>S<span>elect</span></kbd> <span>function takes the first element of the list:</span> staging.</li>
<li><span>The</span> <kbd>J<span>oin</span></kbd> <span>function concatenates that element with the string</span> <kbd>cluster-vpc-id</kbd><span>. In the end, we get</span> <kbd>Import("staging-cluster-vpc-id")</kbd><span>, which is the name of the key we defined to export the VPC ID when we created our ECS cluster:</span></li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c1f4d0bf-28f4-4c35-8f74-9a0faf3f1924.png"/></p>
<p>We will now create our ALB. ALB, being more flexible and feature-rich than ELB, requires a bit more effort when it comes to configuration. ALB works through the intermediary of three different resources. The first one is the ALB resource, which handles incoming connections. On the opposite side, we can find the target groups, which are the resources used by the ECS clusters registered to those ALBs. Finally, in order to tie the two, we find the listener's resources. We will first define our load balancer resource, as follows:</p>
<pre>t.add_resource(elb.LoadBalancer(<br/>    "LoadBalancer",<br/>    Scheme="internet-facing",<br/>    Subnets=Split(<br/>        ',',<br/>        ImportValue(<br/>            Join("-",<br/>                 [Select(0, Split("-", Ref("AWS::StackName"))),<br/>                  "cluster-public-subnets"]<br/>                 )<br/>        )<br/>    ),<br/>    SecurityGroups=[Ref("LoadBalancerSecurityGroup")],<br/>))</pre>
<div class="packt_infobox">We use a very similar series of calls to the function to import our subnet as we did just before for the VPC ID.</div>
<p>We will now create our target group and configure our health check, as follows:</p>
<pre>t.add_resource(elb.TargetGroup(<br/>    "TargetGroup",<br/>    DependsOn='LoadBalancer',<br/>    HealthCheckIntervalSeconds="20",<br/>    HealthCheckProtocol="HTTP",<br/>    HealthCheckTimeoutSeconds="15",<br/>    HealthyThresholdCount="5",<br/>    Matcher=elb.Matcher(<br/>        HttpCode="200"),<br/>    Port=3000,<br/>    Protocol="HTTP",<br/>    UnhealthyThresholdCount="3",<br/>    VpcId=ImportValue(<br/>        Join(<br/>            "-",<br/>            [Select(0, Split("-", Ref("AWS::StackName"))),<br/>                "cluster-vpc-id"]<br/>        )<br/>    ),<br/>))</pre>
<p>Finally, we will add the listener to connect our target group to our load balancer:</p>
<pre>t.add_resource(elb.Listener(<br/>    "Listener",<br/>    Port="3000",<br/>    Protocol="HTTP",<br/>    LoadBalancerArn=Ref("LoadBalancer"),<br/>    DefaultActions=[elb.Action(<br/>        Type="forward",<br/>        TargetGroupArn=Ref("TargetGroup")<br/>    )]<br/>))</pre>
<p>Lastly, we will want to create two outputs. The first output is the target group. We will export its value so that our application can register to the group. The second output is the DNS record of the ALB. This will be the entry point to our application:</p>
<pre>t.add_output(Output(<br/>    "TargetGroup",<br/>    Description="TargetGroup",<br/>    Value=Ref("TargetGroup"),<br/>    Export=Export(Sub("${AWS::StackName}-target-group")),<br/>))<br/><br/>t.add_output(Output(<br/>    "URL",<br/>    Description="Helloworld URL",<br/>    Value=Join("", ["http://", GetAtt("LoadBalancer", "DNSName"), ":3000"])<br/>))<br/><br/>print(t.to_json())</pre>
<p>The file is now ready, and should look like the file at: <span class="MsoHyperlink"><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-ecs-alb-cf-template.py" target="_blank">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-ecs-alb-cf-template.py</a>.</span> We can now generate our template and create our stack, as follows:</p>
<pre><strong>$ git add helloworld-ecs-alb-cf-template.py</strong><br/><strong>$ git commit -m "Adding a Load balancer template for our helloworld application on ECS"</strong><br/><strong>$ git push</strong><br/><strong>$ python helloworld-ecs-alb-cf-template.py &gt; helloworld-ecs-alb-cf.template</strong><br/><strong>$ aws cloudformation create-stack \</strong><br/><strong>    --stack-name staging-alb \</strong><br/><strong>    --capabilities CAPABILITY_IAM \</strong><br/><strong>    --template-body file://helloworld-ecs-alb-cf.template</strong><br/><strong>  {</strong><br/><strong>    "StackId": "arn:aws:cloudformation:us-east-        <br/>     1:094507990803:stack/staging-alb/4929fee0-b2d4-11e8-825f-<br/>     50fa5f2588d2"</strong><br/><strong>}
</strong></pre>
<p>As mentioned, it is important to call the stack <kbd><span>staging-alb</span></kbd>, and that first word is used to import the VPC ID and subnets. The last stack we need is the creation of our container service.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating our ECS hello world service</h1>
                </header>
            
            <article>
                
<p><span>We have an ECS cluster and a load balancer ready to take on traffic on one side and an ECR repository containing the image of our application on the other side. We now need to tie the two together. This is done by creating an ECS service resource.</span> We will create a new file called <kbd><span>helloworld-ecs-service-cf-template.py</span></kbd> and start as usual with its imports, template variable creation, and template description:</p>
<pre>"""Generating CloudFormation template."""<br/><br/>from troposphere.ecs import (<br/>    TaskDefinition,<br/>    ContainerDefinition<br/>)<br/>from troposphere import ecs<br/>from awacs.aws import (<br/>    Allow,<br/>    Statement,<br/>    Principal,<br/>    Policy<br/>)<br/>from troposphere.iam import Role<br/><br/>from troposphere import (<br/>    Parameter,<br/>    Ref,<br/>    Template,<br/>    Join,<br/>    ImportValue,<br/>    Select,<br/>    Split,<br/>)<br/><br/>from awacs.sts import AssumeRole<br/><br/>t = Template()<br/><br/>t.add_description("Effective DevOps in AWS: ECS service - Helloworld")</pre>
<p><span>Our template will take one argument, which is the tag of the image we want to deploy. Our repository currently only has one image tagged as the</span> latest, <span>but in the next section we will update our deployment pipeline and automatize the deployment of our service to ECS:</span></p>
<pre>t.add_parameter(Parameter(<br/>    "Tag",<br/>    Type="String",<br/>    Default="latest",<br/>    Description="Tag to deploy"<br/>))</pre>
<p><span>In ECS, applications are defined by their task definitions. This is where we declare which repository to use to get our image, how much CPU and memory the application needs, and all other system properties such as port mapping, environment variables, mount points, and so on. We will keep our task definition minimal; in order to select the proper image, we will utilize the</span> <kbd><span>ImportValue</span></kbd> <span>function (we previously exported the repository name) combined with a</span> <kbd><span>Join</span></kbd> function <span>to craft the repository URL. We will require</span> <span>32</span> <span>MB of RAM and one-quarter of a core to run our application. Finally, we will specify that port</span> <kbd>3000</kbd> <span>needs to be mapped onto the system:</span></p>
<pre>t.add_resource(TaskDefinition(<br/>    "task",<br/>    ContainerDefinitions=[<br/>        ContainerDefinition(<br/>            Image=Join("", [<br/>                Ref("AWS::AccountId"),<br/>                ".dkr.ecr.",<br/>                Ref("AWS::Region"),<br/>                ".amazonaws.com",<br/>                "/",<br/>                ImportValue("helloworld-repo"),<br/>                ":",<br/>                Ref("Tag")]),<br/>            Memory=32,<br/>            Cpu=256,<br/>            Name="helloworld",<br/>            PortMappings=[ecs.PortMapping(<br/>                ContainerPort=3000)]<br/>        )<br/>    ],<br/>))</pre>
<p class="mce-root"/>
<p>As for most of the AWS managed services, the ECS service needs a certain set of permissions provided by the intermediary of a role. We will create that role and use the vanilla policy for the ECS service role, as follows:</p>
<pre>t.add_resource(Role(<br/>    "ServiceRole",<br/>    AssumeRolePolicyDocument=Policy(<br/>        Statement=[<br/>            Statement(<br/>                Effect=Allow,<br/>                Action=[AssumeRole],<br/>                Principal=Principal("Service", ["ecs.amazonaws.com"])<br/>            )<br/>        ]<br/>    ),<br/>    Path="/",<br/>    ManagedPolicyArns=[<br/>        'arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceRole']<br/>))</pre>
<p>We will complete the creation of our template with the addition of the ECS service resource, which ties the task definition, the ECS cluster, and the ALB together:</p>
<pre>t.add_resource(ecs.Service(<br/>    "service",<br/>    Cluster=ImportValue(<br/>        Join(<br/>            "-",<br/>            [Select(0, Split("-", Ref("AWS::StackName"))),<br/>                "cluster-id"]<br/>        )<br/>    ),<br/>    DesiredCount=1,<br/>    TaskDefinition=Ref("task"),<br/>    LoadBalancers=[ecs.LoadBalancer(<br/>        ContainerName="helloworld",<br/>        ContainerPort=3000,<br/>        TargetGroupArn=ImportValue(<br/>            Join(<br/>                "-",<br/>                [Select(0, Split("-", Ref("AWS::StackName"))),<br/>                    "alb-target-group"]<br/>            ),<br/>        ),<br/>    )],<br/>    Role=Ref("ServiceRole")<br/>))</pre>
<p>Finally, as always, we will output the template generated by our code using the following command:</p>
<pre>print(t.to_json())</pre>
<p>The script is now ready and should look like the script at: <span><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-ecs-service-cf-template.py">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-ecs-service-cf-template.py</a>.<a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-ecs-service-cf-template.py"/></span></p>
<p>We will now generate the template and create our stack, as follows:</p>
<pre><strong>$ git add helloworld-ecs-service-cf-template.py</strong><br/><strong>$ git commit -m "Adding helloworld ECS service script"</strong><br/><strong>$ git push</strong><br/><strong>$ python helloworld-ecs-service-cf-template.py &gt; helloworld-ecs-service- cf.template</strong><br/><strong>$ aws cloudformation create-stack \</strong><br/><strong>    --stack-name staging-helloworld-service \</strong><br/><strong>    --capabilities CAPABILITY_IAM \</strong><br/><strong>    --template-body file://helloworld-ecs-service-cf.template \</strong><br/><strong>    --parameters \ ParameterKey=Tag,ParameterValue=latest
</strong></pre>
<p>After a few minutes, the stack should be created. We can circle back to the output of the ALB stack to get the URL of our newly deployed application and test its output, as follows:</p>
<pre><strong>$ aws cloudformation describe-stacks \</strong><br/><strong>    --stack-name staging-alb \</strong><br/><strong>    --query 'Stacks[0].Outputs'</strong><br/><br/><strong>[</strong><br/><strong>    {</strong><br/><strong>        "Description": "TargetGroup",</strong><br/><strong>        "ExportName": "staging-alb-target-group",</strong><br/><strong>        "OutputKey": "TargetGroup",</strong><br/><strong>        "OutputValue": "arn:aws:elasticloadbalancing:us-east-<br/>         1:094507990803:targetgroup/stagi-Targe-<br/>         ZBW30U7GT7DX/329afe507c4abd4d"</strong><br/><strong>    },</strong><br/><strong>    {</strong><br/><strong>        "Description": "Helloworld URL",</strong><br/><strong>        "OutputKey": "URL",</strong><br/><strong>        "OutputValue": "http://stagi-LoadB-122Z9ZDMCD68X-1452710042.us-<br/>         east-1.elb.amazonaws.com:3000"</strong><br/><strong>    }</strong><br/><strong>]</strong><br/><br/><strong>$ curl http://stagi-LoadB-122Z9ZDMCD68X-1452710042.us-east-1.elb.amazonaws.com:3000</strong><br/><strong>Hello World</strong><br/><strong>Also the same can be confirmed from the browser.
</strong></pre>
<p>This can also be confirmed from the browser, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3386d1b4-0477-4392-a767-430badf63775.png"/></p>
<p><span>We have completed the creation of our staging ECS environment.</span> At this point, we can easily manually deploy new code to our staging, as follows:</p>
<ol>
<li><span>Make the changes in the</span> <kbd>helloworld</kbd> <span>code, locally. For example, change <kbd>Hello World</kbd> to <kbd>Hello From Yogesh Raheja</kbd>, as shown in the following screenshot:</span></li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/32772faa-db7f-42ee-ad93-f0b38472839f.png" style="width:35.92em;height:20.17em;"/></p>
<ol start="2">
<li>Log in to the <kbd>ecr</kbd> registry, as follows:</li>
</ol>
<pre style="padding-left: 90px"><strong>$ eval "$(aws ecr get-login --region us-east-1 --no-include- email)"</strong> </pre>
<ol start="3">
<li>Build your Docker container, as follows:</li>
</ol>
<pre style="padding-left: 90px"><strong>$ docker build -t helloworld</strong> </pre>
<p class="mce-root"/>
<ol start="4">
<li>Pick a new unique tag, and use it to tag your image. For example, let's suppose that your new tag is <kbd>foobar</kbd>, as shown in the following code:</li>
</ol>
<pre style="padding-left: 90px"><strong>$ docker tag helloworld 094507990803.dkr.ecr.us-east-1.amazonaws.com/helloworld:foobar
</strong></pre>
<ol start="5">
<li>Push the image to the <kbd>ecr</kbd> repository, as follows:</li>
</ol>
<pre style="padding-left: 90px"><strong>$ docker push 094507990803.dkr.ecr.us-east-1.amazonaws.com/helloworld:foobar</strong></pre>
<ol start="6">
<li>Update the ECS service CloudFormation stack, as follows:</li>
</ol>
<pre style="padding-left: 90px"><strong>$ aws cloudformation update-stack \</strong><br/><strong>    --stack-name staging-helloworld-service \</strong><br/><strong>    --capabilities CAPABILITY_IAM \</strong><br/><strong>    --template-body file://helloworld-ecs-service-cf.template \</strong><br/><strong>    --parameters \ <br/>      ParameterKey=Tag,ParameterValue=foobar
</strong></pre>
<ol start="7">
<li>Check the outputs after it updates, as follows:</li>
</ol>
<pre style="padding-left: 90px"><strong>$ curl http://stagi-LoadB-122Z9ZDMCD68X-1452710042.us-east-1.elb.amazonaws.com:3000</strong> 

<strong>Hello From Yogesh Raheja</strong> </pre>
<p><span>The browser output also reflects the updated image response:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5f8c34e6-dd67-438f-a599-6502944443a1.png"/></p>
<p>Using this sequence of events, we are going to automate the deployment process and create a new continuous integration/continuous deployment pipeline.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a CI/CD pipeline to deploy to ECS</h1>
                </header>
            
            <article>
                
<p>As we know, having the ability to continuously deploy code across our environments is a very powerful tool as it helps to break out those traditional Dev versus Ops silos and improve the velocity at which new code is being released. We created a pipeline that allows us to automatically deploy new changes from our Hello World application to our Auto Scaling Groups for staging and production. We will create a similar pipeline but, this time, it will deploy changes to ECS. Our ECS infrastructure will be as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/bf0104de-f636-4398-a66e-f602ed354865.png"/></p>
<p>Reusing the CloudFormation templates produced in the previous section will create a production environment identical to the staging one. Note that the <kbd>ecr</kbd> repository is meant to be unique for a given application, and therefore will share it across our environments. <span>In addition, we will follow the best practices learned in</span> <span class="ChapterrefPACKT"><a href="8a74da7b-0748-4b90-a3bc-58e853e820ec.xhtml">Chapter 3</a>, <em>Treating Your Infrastructure As Code</em></span><span>, and create our pipeline through a CloudFormation stack.</span> Our first step will be to create an ECS cluster for production.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating our production ECS cluster</h1>
                </header>
            
            <article>
                
<p>Thanks to the upfront work we did with our CloudFormation templates, adding a new environment will be trivial. We will start by launching a production ECS cluster:</p>
<pre><strong>$ aws cloudformation create-stack \</strong><br/><strong>    --stack-name production-cluster \</strong><br/><strong>    --capabilities CAPABILITY_IAM \</strong><br/><strong>    --template-body file://ecs-cluster-cf.template \</strong><br/><strong>    --parameters \     <br/>      ParameterKey=KeyPair,ParameterValue=EffectiveDevOpsAWS \ <br/>      ParameterKey=VpcId,ParameterValue=vpc-4cddce2a \ <br/>      ParameterKey=PublicSubnet,ParameterValue=subnet-<br/>      e67190bc\\,subnet-658b6149\\,subnet-d890d3e4\\,subnet-<br/>      6fdd7927\\,subnet-4c99c229\\,subnet-b03baebc</strong><br/><strong>{</strong><br/><strong>    "StackId": "arn:aws:cloudformation:us-east-<br/>     1:094507990803:stack/production-cluster/1e1a87f0-b2da-11e8-8fd2-<br/>     503aca4a58d1"</strong><br/><strong>}
</strong></pre>
<p>We need to wait for the creation of the stack to complete as we need to get some of the exported values from the cluster creation. We can run the following command to get our Terminal to hang until we can create our next stack:</p>
<pre><strong>$ aws cloudformation wait stack-create-complete \</strong><br/><strong>    --stack-name production-cluster
</strong></pre>
<p>In the meantime, we create our ALB and wait for the creation process to complete:</p>
<pre><strong>$ aws cloudformation create-stack \</strong><br/><strong>    --stack-name production-alb \</strong><br/><strong>    --capabilities CAPABILITY_IAM \</strong><br/><strong>    --template-body file://helloworld-ecs-alb-cf.template</strong><br/><strong>{</strong><br/><strong>    "StackId": "arn:aws:cloudformation:us-east-<br/>    1:094507990803:stack/production-alb/bea35530-b2da-11e8-a55e-<br/>    500c28903236"</strong><br/><strong>}</strong><br/><br/><strong>$ aws cloudformation wait stack-create-complete --stack-name production-alb
</strong></pre>
<p>Finally, we can create our service with the following code:</p>
<pre><strong>$ aws cloudformation create-stack \</strong><br/><strong>    --stack-name production-helloworld-service \</strong><br/><strong>    --capabilities CAPABILITY_IAM \</strong><br/><strong>    --template-body file://helloworld-ecs-service-cf.template \</strong><br/><strong>    --parameters \ ParameterKey=Tag,ParameterValue=latest</strong><br/><strong>{</strong><br/><strong>    "StackId": "arn:aws:cloudformation:us-east-<br/>     1:094507990803:stack/production-helloworld-service/370a3d40-b2db-<br/>     11e8-80a8-503f23fb5536"</strong><br/><strong>}</strong><br/><br/><strong>$ aws cloudformation wait stack-create-complete \</strong><br/><strong>    --stack-name production-helloworld-service
</strong></pre>
<p><span>At this point, our production environment should be working. We can get its URL by looking at the output of the ALB stack creation, and</span> we can CURL <span>the endpoint to ensure that the application is up and running:</span></p>
<pre><strong>$ aws cloudformation describe-stacks \</strong><br/><strong>    --stack-name production-alb \</strong><br/><strong>    --query 'Stacks[0].Outputs'</strong><br/><strong>[</strong><br/><strong>    {</strong><br/><strong>        "Description": "TargetGroup",</strong><br/><strong>        "ExportName": "production-alb-target-group",</strong><br/><strong>        "OutputKey": "TargetGroup",</strong><br/><strong>        "OutputValue": "arn:aws:elasticloadbalancing:us-east-<br/>         1:094507990803:targetgroup/produ-Targe-<br/>         LVSNKY9T8S6E/83540dcf2b5a5b54"</strong><br/><strong>    },</strong><br/><strong>    {</strong><br/><strong>        "Description": "Helloworld URL",</strong><br/><strong>        "OutputKey": "URL",</strong><br/><strong>        "OutputValue": "http://produ-LoadB-40X7DRUNEBE3-676991098.us-<br/>         east-1.elb.amazonaws.com:3000"</strong><br/><strong>    }</strong><br/><strong>]</strong><br/><br/><strong>$ curl http://produ-LoadB-40X7DRUNEBE3-676991098.us-east-1.elb.amazonaws.com:3000</strong><br/><strong>Hello World
</strong></pre>
<p class="mce-root"/>
<p>The output will be as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/2b95d0e1-3bb8-4ee5-a297-99d55463d50e.png"/></p>
<p>Now that our production environment is ready, we will look into automating the creation of containers. In order to accomplish that, we will rely on the CodeBuild service.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Automating the creation of containers with CodeBuild</h1>
                </header>
            
            <article>
                
<p class="MsoBodyText CDPAlignLeft CDPAlign">AWS CodeBuild is a managed service geared toward compiling source code. It is comparable to Jenkins but since it's a managed service that conforms to AWS standards, it presents a different set of features and benefits. In our case, using CodeBuild over Jenkins will allow us to create containers without needing to spin up and manage an extra EC2 instance. The service also integrates well with CodePipeline, which, as before, will drive our process.</p>
<p>We will use CloudFormation through the intermediary of Troposphere to create our CodeBuild project.</p>
<p>We will also create a new script and call it <kbd>helloworld-codebuild-cf-template.py</kbd>. We will start with our usual import, template variable creation, and description, shown as follows:</p>
<pre>"""Generating CloudFormation template."""<br/><br/>from awacs.aws import (<br/>    Allow,<br/>    Policy,<br/>    Principal,<br/>    Statement<br/>)<br/><br/>from awacs.sts import AssumeRole<br/><br/>from troposphere import (<br/>    Join,<br/>    Ref,<br/>    Template<br/>)<br/><br/>from troposphere.codebuild import (<br/>    Artifacts,<br/>    Environment,<br/>    Project,<br/>    Source<br/>)<br/>from troposphere.iam import Role<br/><br/>t = Template()<br/><br/>t.add_description("Effective DevOps in AWS: CodeBuild - Helloworld container")</pre>
<p>We will now define a new role to grant the proper permissions to our CodeBuild project. The CodeBuild project will interact with a number of AWS services such as ECR, CodePipeline, S3, and CloudWatch logs. To speed up the process, we will rely on the AWS vanilla policies to configure the permissions. This gives us the following code:</p>
<pre>t.add_resource(Role(<br/>    "ServiceRole",<br/>    AssumeRolePolicyDocument=Policy(<br/>        Statement=[<br/>            Statement(<br/>                Effect=Allow,<br/>                Action=[AssumeRole],<br/>                Principal=Principal("Service", ["codebuild.amazonaws.com"])<br/>            )<br/>        ]<br/>    ),<br/>    Path="/",<br/>    ManagedPolicyArns=[<br/>        'arn:aws:iam::aws:policy/AWSCodePipelineReadOnlyAccess',<br/>        'arn:aws:iam::aws:policy/AWSCodeBuildDeveloperAccess',<br/>        'arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryPowerUser',<br/>        'arn:aws:iam::aws:policy/AmazonS3FullAccess',<br/>        'arn:aws:iam::aws:policy/CloudWatchLogsFullAccess'<br/>    ]<br/>))</pre>
<p class="mce-root"/>
<p>CodeBuild projects require defining a number of elements. The first one we will define is the environment. This tells CodeBuild what type of hardware and OS we need to build our project, and what needs to be preinstalled. It will also let us define extra environment variables. We will use a Docker image provided by AWS, which will give us everything we need to get our work done. The Docker image comes with the AWS and Docker CLI preinstalled and configured. We will also define an environment variable to find our <kbd>ecr</kbd> repository endpoint:</p>
<pre>environment = Environment(<br/>    ComputeType='BUILD_GENERAL1_SMALL',<br/>    Image='aws/codebuild/docker:1.12.1',<br/>    Type='LINUX_CONTAINER',<br/>    EnvironmentVariables=[<br/>        {'Name': 'REPOSITORY_NAME', 'Value': 'helloworld'},<br/>        {'Name': 'REPOSITORY_URI',<br/>            'Value': Join("", [<br/>                Ref("AWS::AccountId"),<br/>                ".dkr.ecr.",<br/>                Ref("AWS::Region"),<br/>                ".amazonaws.com",<br/>                "/",<br/>                "helloworld"])},<br/>    ],<br/>)</pre>
<p>In CodeBuild, most of the logic is defined in a resource called a <kbd>buildspec</kbd>. The <kbd>buildspec</kbd> section <span>defines the different phases of the build and what to run during those phases. It is very similar to the Jenkins file we created in</span> <span class="ChapterrefPACKT"><a href="">Chapter 5</a>, <em>Adding Continuous Integration and Continuous Deployment</em></span>. The <kbd>buildspec</kbd> section <span>can be created as part of the CodeBuild project or added as a YAML file to the root directory of the projects that are being built. We will opt for the first option and define</span> <kbd>buildspec</kbd> <span>inside our CloudFormation template. We will create a variable and store a YAML string into it. Since it's going to be a multiline variable, we will use the Python triple quote syntax.</span></p>
<p>The first key-pair we need to specify is the version of the template. The current version of CodeBuild templates is <kbd>0.1</kbd>:</p>
<pre class="CDPAlignLeft CDPAlign">buildspec = """version: 0.1</pre>
<p>The goal of our build process is to generate a new container image, tag it, and push it to the <kbd>ecr</kbd> repository. This will be done in three phases:</p>
<ul>
<li><strong>Pre-build</strong>: This will generate the container image tag and log in to ECR</li>
<li><strong>Build</strong>: This will build the new container image</li>
<li><strong>Post-build</strong>: This will push the new container image to ECR and update the <kbd>latest</kbd> tag to point to the new container</li>
</ul>
<p><span>In order to easily understand what is in each container, we will tag them with the SHA of the most recent Git commit in the</span> <kbd>helloworld</kbd> <span>project. This will help in understanding what is in each container, as we will be able to run commands such as</span> <kbd><span>git checkout &lt;container tag&gt;</span></kbd> or <kbd><span>git log &lt;container tag&gt;</span></kbd>. Due to how CodeBuild and CodePipeline are architected, getting this tag in CodeBuild requires a bit of work. We will need to run two complex commands as follows:</p>
<ul>
<li>The first one will extract the execution ID of the current code pipeline execution. This is achieved by combining the AWS CLI and the environment variables <kbd><span>CODEBUILD_BUILD_ID</span></kbd> and <kbd>CODEBUILD_INITIATOR</kbd>, which are defined by the CodeBuild service when a build starts.</li>
<li>Next, we will use that execution ID to extract the artifact revision ID, which happens to be the commit SHA we are looking for.</li>
</ul>
<p>These commands use some of the most advanced features of the <kbd>--query</kbd> filter option. You can read more about this at the following link: <span><a href="http://amzn.to/2k7SoLE" target="_blank">http://amzn.to/2k7SoLE</a>.</span></p>
<div class="packt_infobox CDPAlignLeft CDPAlign">In CodeBuild, each command runs in its own environment, and therefore the easiest way to share data across steps is to use temporary files.</div>
<p>Right after the <kbd>buildspec</kbd> version definition, add the following to generate the first part of our pre-build phase and extract the tag:</p>
<pre>phases:<br/>  pre_build:<br/>    commands:<br/>      - aws codepipeline get-pipeline-state --name "${CODEBUILD_INITIATOR##*/}" --query stageStates[?actionStates[0].latestExecution.externalExecutionId==\`$CODEBUILD_BUILD_ID\`].latestExecution.pipelineExecutionId --output=text &gt; /tmp/execution_id.txt<br/>      - aws codepipeline get-pipeline-execution --pipeline-name "${CODEBUILD_INITIATOR##*/}" --pipeline-execution-id $(cat /tmp/execution_id.txt) --query 'pipelineExecution.artifactRevisions[0].revisionId' --output=text &gt; /tmp/tag.txt</pre>
<p><span>Our tag is now present in the</span> <kbd><span>/tmp/tag.txt</span></kbd> <span>file. We now need to generate two files as follows:</span></p>
<ul>
<li class="CDPAlignLeft CDPAlign"><span>The first one will contain the argument for the <kbd>docker tag</kbd> command (this will be something like</span> <kbd>&lt;AWS::AccountId&gt;.dkr.ecr.us-east-1.amazonaws.com/helloworld:&lt;tag&gt;</kbd>). To do that, we will take advantage of the environment variable defined earlier in our template.</li>
<li class="CDPAlignLeft CDPAlign"><span>The second file will be a JSON file that will define a key-value pair with the tag. We will use that file a bit later when we work on deploying our new containers to ECS.</span></li>
</ul>
<p>After the previous commands, add the following commands to generate those files:</p>
<pre>printf "%s:%s" "$REPOSITORY_URI" "$(cat /tmp/tag.txt)" &gt; /tmp/build_tag.txt<br/>      - printf '{"tag":"%s"}' "$(cat /tmp/tag.txt)" &gt; /tmp/build.json</pre>
<p>To conclude the <kbd><span>pre_build</span></kbd> section, we will log in to our <kbd>ecr</kbd> repository:</p>
<pre>- $(aws ecr get-login --no-include-email)</pre>
<p><span>We will now define our build phase. Thanks to the</span> <kbd><span>build_tag</span></kbd> <span>file created earlier, the build phase will be straightforward. We will call the</span> <kbd><span>docker build</span></kbd> <span>command in a similar way to how we did in the first section of this chapter:</span></p>
<pre> build:<br/>    commands:<br/>      - docker build -t "$(cat /tmp/build_tag.txt)" .</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>We will now add the <kbd><span>post_build</span></kbd> phase to complete the build. In this section, we will push the newly built container to our <kbd>ecr</kbd> repository as follows:</p>
<pre>post_build:<br/>    commands:<br/>      - docker push "$(cat /tmp/build_tag.txt)"<br/>      - aws ecr batch-get-image --repository-name $REPOSITORY_NAME --image-ids imageTag="$(cat /tmp/tag.txt)" --query 'images[].imageManifest' --output text | tee /tmp/latest_manifest.json<br/>      - aws ecr put-image --repository-name $REPOSITORY_NAME --image-tag latest --image-manifest "$(cat /tmp/latest_manifest.json)"</pre>
<p class="mce-root"/>
<p>In addition to the phases, one of the sections that is also defined in a <kbd>buildspec</kbd> is the <kbd><span>artifacts</span></kbd> <span>section. This section is used to define what needs to be uploaded to S3 after the build succeeds, as well as how to prepare it. We will export the</span> <kbd>build.json</kbd> file and set the <kbd><span>discard-paths</span></kbd> <span>variable to</span> <span>true</span> <span>so we don't preserve the</span> <kbd><span>/tmp/</span></kbd> <span>directory information. Finally, we will close our triple quote string as follows:</span></p>
<pre>artifacts:<br/>  files: /tmp/build.json<br/>  discard-paths: yes<br/>"""</pre>
<p><span>Now that our</span> <kbd>buildspec</kbd> <span>variable is defined, we can add our CodeBuild project resource. Through the instantiation of the project, we will set a name for our project, set its environment by calling the variable previously defined, set the service role, and configure the source and artifact resources, which define how to handle the build process and its output:</span></p>
<pre>t.add_resource(Project(<br/>    "CodeBuild",<br/>    Name='HelloWorldContainer',<br/>    Environment=environment,<br/>    ServiceRole=Ref("ServiceRole"),<br/>    Source=Source(<br/>        Type="CODEPIPELINE",<br/>        BuildSpec=buildspec<br/>    ),<br/>    Artifacts=Artifacts(<br/>        Type="CODEPIPELINE",<br/>        Name="output"<br/>    ),<br/>))</pre>
<p class="mce-root"/>
<p>As always, we will conclude the creation of the script with the following <kbd><span>print</span></kbd> command:</p>
<pre>print(t.to_json()) </pre>
<p>Our script is now complete and should look like this: <span><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-codebuild-cf-template.py" target="_blank">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-codebuild-cf-template.py</a>.<a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-codebuild-cf-template.py"/></span></p>
<p>We can save the file, add it to git, generate the CloudFormation template, and create our stack as follows:</p>
<pre><strong>$ git add helloworld-codebuild-cf-template.py</strong><br/><strong>$ git commit -m "Adding CodeBuild Template for our helloworld application"</strong><br/><strong>$ git push</strong><br/><strong>$ python helloworld-codebuild-cf-template.py &gt; helloworld-codebuild- cf.template</strong><br/><strong>$ aws cloudformation create-stack \</strong><br/><strong>    --stack-name helloworld-codebuild \</strong><br/><strong>    --capabilities CAPABILITY_IAM \</strong><br/><strong>    --template-body file://helloworld-codebuild-cf.template
</strong></pre>
<p><span>In a matter of minutes, our stack will be created. We will now want to take advantage of it. To do so, we will turn to CodePipeline once again and create a brand new, container-aware pipeline.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating our deployment pipeline with CodePipeline</h1>
                </header>
            
            <article>
                
<p>We will use AWS CodePipeline to build a pipeline very similar to the one we created in <span class="ChapterrefPACKT"><a href="">Chapter 5</a>, <em>Adding Continuous Integration and Continuous Deployment</em>:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/22a0888a-7630-48da-9601-20035de62882.png"/></p>
<p class="mce-root"/>
<p><span>We will start with a Source step where we will connect to GitHub and trigger new pipelines that run automatically when the code changes. After this, we will build a new container and push it to our</span> <kbd>ecr</kbd> repository rely upon the CodeBuild project we just created. We will then deploy the new container to staging. To do that, we will use the CloudFormation integration provided by CodePipeline, combined with the <kbd>build.json</kbd> file produced in the <kbd>buildspec</kbd> section of our CodeBuild project. You may recall that our <kbd>helloworld</kbd> service templates take the tag to deploy as an argument. We will trigger a stack update action and override the default value for that parameter with what's defined in the <kbd>build.json</kbd> file. After that, we will add a manual approval step before triggering the same deployment again, but this time for production.</p>
<p><span>Deploying and updating CloudFormation templates through CodePipeline will require specifying the location of the template within the inputs. In order to easily provide it, we will first start by adding the CloudFormation template to our source.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding the CloudFormation template to our code base</h1>
                </header>
            
            <article>
                
<p><span>ECS changes are driven by the task definition present in our</span> <kbd><span>helloworld-ecs-service- cf.template</span></kbd> <span>file. So far we have only stored our Python script</span> <span>in GitHub</span><span>. We will have to make a special case for that template and store the JSON output of it so that CodePipeline can interact with our stack. We will add this file to our Git repository in a new directory as follows:</span></p>
<pre><strong>$ cd helloworld</strong><br/><strong>$ mkdir templates</strong><br/><strong>$ curl -L https://raw.githubusercontent.com/yogeshraheja/EffectiveDevOpsTemplates/master/helloworld-ecs-service-cf-template.py | python &gt; templates/helloworld-ecs-service-cf.template</strong><br/><strong>$ git add templates</strong><br/><strong>$ git commit -m "Adding CloudFormation template for the helloworld task"</strong><br/><strong>$ git push
</strong></pre>
<p><span>Now that our template is present in our source, we can create our CloudFormation template for our pipeline.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a CloudFormation template for CodePipeline</h1>
                </header>
            
            <article>
                
<p><span>We will start by creating a file called</span> <kbd>helloworld-codepipeline-cf- template.py</kbd> inside EffectiveDevOpsTemplates locally.</p>
<p>We will start the script with our boilerplates:</p>
<pre>"""Generating CloudFormation template."""<br/><br/>from awacs.aws import (<br/>    Allow,<br/>    Policy,<br/>    Principal,<br/>    Statement,<br/>)<br/>from awacs.sts import AssumeRole<br/>from troposphere import (<br/>    Ref,<br/>    GetAtt,<br/>    Template,<br/>)<br/>from troposphere.codepipeline import (<br/>    Actions,<br/>    ActionTypeId,<br/>    ArtifactStore,<br/>    InputArtifacts,<br/>    OutputArtifacts,<br/>    Pipeline,<br/>    Stages<br/>)<br/>from troposphere.iam import Role<br/>from troposphere.iam import Policy as IAMPolicy<br/><br/>from troposphere.s3 import Bucket, VersioningConfiguration<br/><br/>t = Template()<br/><br/>t.add_description("Effective DevOps in AWS: Helloworld Pipeline")</pre>
<p>The first resource we will create is the S3 bucket that the pipeline will use to store all the artifacts produced by each stage. We will also turn on versioning on that bucket:</p>
<pre>t.add_resource(Bucket(<br/>    "S3Bucket",<br/>    VersioningConfiguration=VersioningConfiguration(<br/>        Status="Enabled",<br/>    )<br/>))</pre>
<p>We will now create the IAM roles needed as follows:</p>
<ol>
<li><span>The first role we are going to define will be for the CodePipeline service:</span></li>
</ol>
<pre style="padding-left: 90px">t.add_resource(Role(<br/>    "PipelineRole",<br/>    AssumeRolePolicyDocument=Policy(<br/>        Statement=[<br/>            Statement(<br/>                Effect=Allow,<br/>                Action=[AssumeRole],<br/>                Principal=Principal("Service", ["codepipeline.amazonaws.com"])<br/>            )<br/>        ]<br/>    ),<br/>    Path="/",<br/>    Policies=[<br/>        IAMPolicy(<br/>            PolicyName="HelloworldCodePipeline",<br/>            PolicyDocument={<br/>                "Statement": [<br/>                    {"Effect": "Allow", "Action": "cloudformation:*", "Resource": "*"},<br/>                    {"Effect": "Allow", "Action": "codebuild:*", "Resource": "*"},<br/>                    {"Effect": "Allow", "Action": "codepipeline:*", "Resource": "*"},<br/>                    {"Effect": "Allow", "Action": "ecr:*", "Resource": "*"},<br/>                    {"Effect": "Allow", "Action": "ecs:*", "Resource": "*"},<br/>                    {"Effect": "Allow", "Action": "iam:*", "Resource": "*"},<br/>                    {"Effect": "Allow", "Action": "s3:*", "Resource": "*"},<br/>                ],<br/>            }<br/>        ),<br/>    ]<br/>))</pre>
<ol start="2">
<li>The second role will be used by the deploy stages to perform CloudFormation changes:</li>
</ol>
<pre style="padding-left: 90px">t.add_resource(Role(<br/>    "CloudFormationHelloworldRole",<br/>    RoleName="CloudFormationHelloworldRole",<br/>    Path="/",<br/>    AssumeRolePolicyDocument=Policy(<br/>        Statement=[<br/>            Statement(<br/>                Effect=Allow,<br/>                Action=[AssumeRole],<br/>                Principal=Principal(<br/>                    "Service", ["cloudformation.amazonaws.com"])<br/>            ),<br/>        ]<br/>    ),<br/>    Policies=[<br/>        IAMPolicy(<br/>            PolicyName="HelloworldCloudFormation",<br/>            PolicyDocument={<br/>                "Statement": [<br/>                    {"Effect": "Allow", "Action": "cloudformation:*", "Resource": "*"},<br/>                    {"Effect": "Allow", "Action": "ecr:*", "Resource": "*"},<br/>                    {"Effect": "Allow", "Action": "ecs:*", "Resource": "*"},<br/>                    {"Effect": "Allow", "Action": "iam:*", "Resource": "*"},<br/>                ],<br/>            }<br/>        ),<br/>    ]<br/>))</pre>
<p class="mce-root"/>
<ol start="3">
<li>We can now create our pipeline resource. We will first configure its name and specify the role <strong>Amazon Resource Name</strong> (<strong>ARN</strong>) of the role we just created:</li>
</ol>
<pre style="padding-left: 90px">t.add_resource(Pipeline(<br/>    "HelloWorldPipeline",<br/>    RoleArn=GetAtt("PipelineRole", "Arn"),</pre>
<ol start="4">
<li>After this, we will reference the S3 bucket created earlier so that we have a place to store the different artifacts produced through the pipeline execution:</li>
</ol>
<pre style="padding-left: 90px"> ArtifactStore=ArtifactStore(<br/>        Type="S3",<br/>        Location=Ref("S3Bucket")</pre>
<ol start="5">
<li>We will now define each stage of the pipeline. The CloudFormation structure reflects what we did previously using the web interface. Each stage has a unique name and is composed of actions. Each action is defined by a name, a category, a configuration, and, optionally, input and output artifacts:</li>
</ol>
<p style="padding-left: 60px">Our first stage will be the GitHub stage, as follows:</p>
<pre style="padding-left: 90px">Stages=[<br/>        Stages(<br/>            Name="Source",<br/>            Actions=[<br/>                Actions(<br/>                    Name="Source",<br/>                    ActionTypeId=ActionTypeId(<br/>                        Category="Source",<br/>                        Owner="ThirdParty",<br/>                        Version="1",<br/>                        Provider="GitHub"<br/>                    ),<br/>                    Configuration={<br/>                        "Owner": "ToBeConfiguredLater",<br/>                        "Repo": "ToBeConfiguredLater",<br/>                        "Branch": "ToBeConfiguredLater",<br/>                        "OAuthToken": "ToBeConfiguredLater"<br/>                    },<br/>                    OutputArtifacts=[<br/>                        OutputArtifacts(<br/>                            Name="App"<br/>                        )<br/>                    ],<br/>                )<br/>            ]<br/>        ),</pre>
<ol start="6">
<li>We will create a first artifact called <kbd>App</kbd> with the content of the repository. In order to avoid hardcoding any <kbd>OAuthToken</kbd>, we will configure the GitHub integration after creating the CloudFormation stack.</li>
</ol>
<p style="padding-left: 60px">Our next step will be to configure our build. As mentioned, we will simply call out to the CodeBuild stack we spawned up in the last section. We will store the output artifact under the name <kbd>BuildOutput</kbd>, meaning that we now have two artifacts: the <kbd>App</kbd> artifact and <kbd>BuildOutput</kbd>, which contains the <kbd>tag.json</kbd> file produced by CodeBuild<span>:</span></p>
<pre style="padding-left: 60px">Stages(<br/>            Name="Build",<br/>            Actions=[<br/>                Actions(<br/>                    Name="Container",<br/>                    ActionTypeId=ActionTypeId(<br/>                        Category="Build",<br/>                        Owner="AWS",<br/>                        Version="1",<br/>                        Provider="CodeBuild"<br/>                    ),<br/>                    Configuration={<br/>                        "ProjectName": "HelloWorldContainer",<br/>                    },<br/>                    InputArtifacts=[<br/>                        InputArtifacts(<br/>                            Name="App"<br/>                        )<br/>                    ],<br/>                    OutputArtifacts=[<br/>                        OutputArtifacts(<br/>                            Name="BuildOutput"<br/>                        )<br/>                    ],<br/>                )<br/>            ]<br/>        ),</pre>
<ol start="7">
<li>We will now create our staging deployment. Unlike before, we won't use CodeDeploy but will directly update our CloudFormation template. In order to accomplish that, we will need to provide the location of the template to the configuration of our action. Since we added it to our <kbd>helloworld</kbd> <span>GitHub repository, we can reference it with the help of the</span> <kbd>App</kbd> <span>artifact. Our template is</span> present under <kbd>&lt;directory root&gt;/templates/helloworld-ecs-service- cf.template</kbd>, which in turn means for CodePipeline <kbd>App::templates/helloworld-ecs-service-cf.template</kbd>.</li>
</ol>
<p class="mce-root"/>
<p style="padding-left: 60px">The next trick in configuring our CloudFormation action relies on the fact that we can override the parameters provided for the stack. CloudFormation provides a couple of functions to help with dynamic parameters. You can read more about those at <span><a href="http://amzn.to/2kTgIUJ" target="_blank">http://amzn.to/2kTgIUJ</a>. We will focus on a particular one here:</span> <kbd>Fn::GetParam</kbd><span>. This function returns a value from a key-value pair file present in an artifact. This is where we take advantage of the file we created in CodeBuild, as it will contain a JSON string in the format</span> <kbd><span>{ "tag": "&lt;latest git commit sha&gt;" }</span></kbd>:</p>
<pre style="padding-left: 90px">Stages(<br/>            Name="Staging",<br/>            Actions=[<br/>                Actions(<br/>                    Name="Deploy",<br/>                    ActionTypeId=ActionTypeId(<br/>                        Category="Deploy",<br/>                        Owner="AWS",<br/>                        Version="1",<br/>                        Provider="CloudFormation"<br/>                    ),<br/>                    Configuration={<br/>                        "ChangeSetName": "Deploy",<br/>                        "ActionMode": "CREATE_UPDATE",<br/>                        "StackName": "staging-helloworld-ecs-service",<br/>                        "Capabilities": "CAPABILITY_NAMED_IAM",<br/>                        "TemplatePath": "App::templates/helloworld-ecs-service-cf.template",<br/>                        "RoleArn": GetAtt("CloudFormationHelloworldRole", "Arn"),<br/>                        "ParameterOverrides": """{"Tag" : { "Fn::GetParam" : [ "BuildOutput", "build.json", "tag" ] } }"""<br/>                    },<br/>                    InputArtifacts=[<br/>                        InputArtifacts(<br/>                            Name="App",<br/>                        ),<br/>                        InputArtifacts(<br/>                            Name="BuildOutput"<br/>                        )<br/>                    ],<br/>                )<br/>            ]<br/>        ),</pre>
<ol start="8">
<li>After the staging deployment completes, we will request a manual approval, as follows:</li>
</ol>
<pre style="padding-left: 90px"> Stages(<br/>            Name="Approval",<br/>            Actions=[<br/>                Actions(<br/>                    Name="Approval",<br/>                    ActionTypeId=ActionTypeId(<br/>                        Category="Approval",<br/>                        Owner="AWS",<br/>                        Version="1",<br/>                        Provider="Manual"<br/>                    ),<br/>                    Configuration={},<br/>                    InputArtifacts=[],<br/>                )<br/>            ]<br/>        ),</pre>
<ol start="9">
<li>Finally, we will create a last stage to run the production deployment. The code is exactly the same here as it is for staging, except for the name of the stage and the stack targeted by our configuration:</li>
</ol>
<pre style="padding-left: 90px">Stages(<br/>            Name="Production",<br/>            Actions=[<br/>                Actions(<br/>                    Name="Deploy",<br/>                    ActionTypeId=ActionTypeId(<br/>                        Category="Deploy",<br/>                        Owner="AWS",<br/>                        Version="1",<br/>                        Provider="CloudFormation"<br/>                    ),<br/>                    Configuration={<br/>                        "ChangeSetName": "Deploy",<br/>                        "ActionMode": "CREATE_UPDATE",<br/>                        "StackName": "production-helloworld-ecs-service",<br/>                        "Capabilities": "CAPABILITY_NAMED_IAM",<br/>                        "TemplatePath": "App::templates/helloworld-ecs-service-cf.template",<br/>                        "RoleArn": GetAtt("CloudFormationHelloworldRole", "Arn"),<br/>                        "ParameterOverrides": """{"Tag" : { "Fn::GetParam" : [ "BuildOutput", "build.json", "tag" ] } }"""<br/>                    },<br/>                    InputArtifacts=[<br/>                        InputArtifacts(<br/>                            Name="App",<br/>                        ),<br/>                        InputArtifacts(<br/>                            Name="BuildOutput"<br/>                        )<br/>                    ],<br/>                )<br/>            ]<br/>        )<br/>    ],<br/>))</pre>
<ol start="10">
<li>Our pipeline resource has now been created. We can conclude the creation of our script by printing out our template:</li>
</ol>
<pre style="padding-left: 90px">print(t.to_json()) </pre>
<p>The script is now ready to be used. It should look like the script at: <span><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-codepipeline-cf-template.py" target="_blank">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-codepipeline-cf-template.py</a>.<a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/helloworld-codepipeline-cf-template.py"/></span></p>
<p>We can now create our pipeline.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Starting and configuring our CloudFormation stack</h1>
                </header>
            
            <article>
                
<p>We will proceed as usual for the first part of our pipeline's creation, as follows:</p>
<pre><strong>$ git add helloworld-codepipeline-cf-template.py</strong><br/><strong>$ git commit -m "Adding Pipeline to deploy our helloworld application using ECS"</strong><br/><strong>$ git push</strong><br/><strong>$ python helloworld-codepipeline-cf-template.py &gt; helloworld-codepipeline- cf.template</strong><br/><strong>$ aws cloudformation create-stack \</strong><br/><strong>    --stack-name helloworld-codepipeline \</strong><br/><strong>    --capabilities CAPABILITY_NAMED_IAM \</strong><br/><strong>    --template-body file://helloworld-codepipeline-cf.template
</strong></pre>
<div class="packt_infobox CDPAlignLeft CDPAlign"><span>We are using the</span> <kbd><span>CAPABILITY_NAMED_IAM</span></kbd> <span>capability in this case, as we are defining custom names at the IAM level.</span></div>
<p>This will create our pipeline. However, a small catch is that we didn't specify the GitHub credentials in the pipeline. This is because we don't want to store it in clear text in GitHub. AWS offers a service within IAM to do encryption, but we won't cover <span>that in this book. Consequently, we will simply edit the pipeline the first time around, as follows:</span></p>
<ol>
<li><span>Open</span> <span><a href="https://console.aws.amazon.com/codepipeline" target="_blank">https://console.aws.amazon.com/codepipeline</a></span> <span>in your browser</span></li>
<li><span>Select your newly created pipeline</span></li>
<li><span>Click on <span class="packt_screen">Edit</span> at the top</span></li>
<li><span>Click on the pen icon on the <span class="packt_screen">GitHub</span> action:</span></li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/506252fb-0441-4a3c-9b01-ee48aac15212.png" style="width:10.50em;height:3.67em;"/></p>
<ol start="5">
<li>Click on <span class="packt_screen">Connect to GitHub</span> on the right-hand-side menu and follow the steps to authorize AWS CodePipeline</li>
<li>Select your <kbd>helloworld</kbd> project in the repository step and the master branch</li>
<li>Click on <span class="packt_screen">Update</span>, save the pipeline changes, and finally, <span class="packt_screen">Save and Continue</span></li>
</ol>
<p>After a few seconds, your pipeline will trigger, and you should see your first deployment going through. This concludes the creation of our CI/CD pipeline:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5852e5b1-5dc4-4346-814f-96a5c982093c.png"/></p>
<p>You will also be able to see all of the CloudFormation stack details on the AWS console with the <kbd>CREATE_COMPLETE</kbd> status, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/fcd718ba-f6e2-4acc-90ec-f5d648d0aa71.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we explored the concept of containers, using Docker and ECS. After exploring the basics of how Docker works, we created a container for our application. After running it locally, we created a new set of resources to run Docker containers on AWS. We did that using the DevOps best practices and used CloudFormation to generate our resources, treating our infrastructure as code. This allows us to keep those changes under source control. Resource-wise, we created an ECR repository to manage the different revisions of our containers. We also created two ECS clusters with auto scaling capabilities for staging and production, two ALBs to proxy the traffic to our containers, a set of tasks, and an ECS service, to configure and deploy our application.</p>
<p>Finally, we re-implemented a CI/CD pipeline. We did that by using CodeBuild, CodePipeline, and their integrations with CloudFormation.</p>
<p>We will continue improving our systems and we will implement one of the last key characteristics of DevOps; measuring everything. By taking advantage of a number of features that are present in the different services that we use, and by coupling them with other AWS services (such as CloudWatch), we will be able to implement a monitoring strategy for our infrastructure and services.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li class="CDPAlignLeft CDPAlign">What is Docker? List the important components of Docker Engine.</li>
<li class="CDPAlignLeft CDPAlign">Can you install and configure the latest Docker CE on any supported platform/OS of your choice?</li>
<li class="CDPAlignLeft CDPAlign">Can you create a Docker image and use the same image to create a web server container?</li>
<li>Can you create ECR and ECS using AWS webconsole to get familiar with ECS terminologies?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<p>Refer to the following links for further information:</p>
<ul>
<li class="CDPAlignLeft CDPAlign"><strong>Docker Documentation</strong>: <span><a href="https://docs.docker.com" target="_blank">https://docs.docker.com</a></span></li>
<li class="CDPAlignLeft CDPAlign"><strong>Docker Hub</strong>: <span><a href="https://hub.docker.com">https://hub.docker.com</a></span></li>
<li class="CDPAlignLeft CDPAlign"><strong>AWS CodeBuild</strong>: <span><a href="https://aws.amazon.com/codebuild/" target="_blank">https://aws.amazon.com/codebuild/</a></span></li>
<li class="CDPAlignLeft CDPAlign"><strong>AWS CodePipeline</strong>: <span><a href="https://aws.amazon.com/codepipeline/" target="_blank">https://aws.amazon.com/codepipeline/</a></span></li>
<li class="CDPAlignLeft CDPAlign"><strong>AWS Elastic Container Service</strong>: <span><a href="https://aws.amazon.com/ecs/" target="_blank">https://aws.amazon.com/ecs/</a></span></li>
</ul>


            </article>

            
        </section>
    </body></html>