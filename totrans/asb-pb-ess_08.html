<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch07"/>Chapter 7. Node Discovery and Clustering</h1></div></div></div><p>For most real-world scenarios, we would need to create a cluster of compute nodes with the applications running on top, which are linked together. For example, the WordPress site that we have been building requires web servers and databases connected together.</p><p>Clustered infrastructure has a topology where one class of nodes should be able to discover information about the different, or the same, class of servers. For example, the WordPress application servers need to discover information about database servers, and load balancers need to know about the IP address/hostname of each web server that it's serving traffic to. This chapter focuses on what primitives Ansible offers to group together nodes and discover the attributes of interconnected nodes.</p><p>In this chapter, we will learn about:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Discovering information about other nodes in the cluster</li><li class="listitem" style="list-style-type: disc">Generating configurations dynamically using the magic variables discovered</li><li class="listitem" style="list-style-type: disc">Why and how to enable fact caching</li></ul></div><div><div><div><div><h1 class="title"><a id="ch07lvl1sec54"/>Node discovery with magic variables</h1></div></div></div><p>We have looked at <a id="id211" class="indexterm"/>user-defined variables as well as system data, that is, facts. In addition to these, there are a few variables that define the meta information about the nodes, inventory, and plays, for example, which groups a node belongs to, what groups are part of the inventory, which nodes belong to which group, and so on. These variables, which are implicitly set, are called <strong>magic</strong> variables, and are very useful for discovering nodes and topology information. The following table lists the most useful magic variables, and their description:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Magic Variable</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">hostvars</code>
</p>
</td><td style="text-align: left" valign="top">
<p>These are <a id="id212" class="indexterm"/>lookup variables or facts set on another host.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">groups</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the <a id="id213" class="indexterm"/>list of groups in the inventory. This can be used to walk over a group of nodes to discover its topology information. </p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">group_names</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the <a id="id214" class="indexterm"/>list of groups that the node belongs to.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">inventory_hostname</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the <a id="id215" class="indexterm"/>hostname set in the inventory file. It can be different to the <code class="literal">ansible_hostname</code> fact.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">play_hosts</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the <a id="id216" class="indexterm"/>list of all the hosts that belong to the current play.</p>
</td></tr></tbody></table></div><p>In addition to the preceding table, there are a few additional magic variables, for example, the <code class="literal">delegate_to</code>, <code class="literal">inventory_dir</code> and <code class="literal">inventory_file</code> parameters, however, these are not relevant to node discovery and are less frequently used.</p><p>We are now going to create a new role to serve as a load balancer, which relies on this node discovery feature provided by the magic variables.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec55"/>Creating the load balancer role</h1></div></div></div><p>We created the <a id="id217" class="indexterm"/>Nginx and MySQL roles to serve the WordPress site. However, if we have to build a scalable site, we also need to add a load balancer to the mix. This load balancer will then act as an entry point for the incoming requests, and then spread the traffic across the available web servers. Let's consider the following scenario, where our fifanews site has become an instant hit. The traffic is growing exponentially, and the single web server approach that we have been using is showing cracks. We need to scale out horizontally and add more web servers. Once we start creating more web servers, we also need to have some mechanism to balance traffic across those. We have been tasked to create a <code class="literal">haproxy</code> role, which would discover all web servers in our cluster automatically and add to its configurations.</p><p>The following diagram explains this scenario with haproxy as a frontend, balancing the load across web servers in the backend. Haproxy is a widely used open source TCP/HTTP load balancer. Let's take a <a id="id218" class="indexterm"/>look at the following diagram:</p><div><img src="img/B03800_07_01.jpg" alt="Creating the load balancer role"/></div><p>In the next steps, we will not only create a <code class="literal">haproxy</code> module, but also have it configured automatically with the IP addresses of all the web server nodes using magic variables:</p><div><ol class="orderedlist arabic"><li class="listitem">Let's start by creating the scaffolding required to write this role, using the following command:<div><pre class="programlisting">
<strong>$ ansible-galaxy init --init-path roles/ mysql</strong>
</pre></div><p>The output will look as follows:</p><div><pre class="programlisting">
<strong>   haproxy was created successfully</strong>
</pre></div></li><li class="listitem">We will now add some variables related to the <code class="literal">haproxy</code> role to the variable defaults:<div><pre class="programlisting">---
# filename: roles/haproxy/defaults/main.yml
haproxy:
  config:
    cnfpath: /etc/haproxy/haproxy.cfg
    enabled: 1
    listen_address: 0.0.0.0
    listen_port: 8080
  service: haproxy
  pkg: haproxy</pre></div><div><div><h3 class="title"><a id="tip14"/>Tip</h3><p>Even though it's a good practice to add a parameter for each configuration that haproxy supports, we will stick to a subset of parameters while writing this role; this is specially useful for node discovery.</p></div></div></li><li class="listitem">Let's now create <a id="id219" class="indexterm"/>some tasks and handlers, which install, configure, and manage the haproxy service on an Ubuntu host:<div><pre class="programlisting">---
# filename: roles/haproxy/tasks/main.yml
- include: install.yml
- include: configure.yml
- include: service.yml

---
# filename: roles/haproxy/tasks/install.yml
  - name: install haproxy
    apt:
      name: "{{ haproxy['pkg'] }}"

---
# filename: roles/haproxy/tasks/configure.yml
 - name: create haproxy config
   template: src="img/haproxy.cfg.j2" dest="{{ haproxy['config']['cnfpath'] }}" mode=0644
   notify:
    - restart haproxy service

 - name: enable haproxy
   template: src="img/haproxy.default.j2" dest=/etc/default/haproxy mode=0644
   notify:
    - restart haproxy service

---
# filename: roles/haproxy/tasks/service.yml
 - name: start haproxy server
   service:
     name: "{{ haproxy['service'] }}" 
     state: started

---
# filename: roles/haproxy/handlers/main.yml
- name: restart haproxy service
  service: name="{{ haproxy['service'] }}" state=restarted</pre></div></li></ol></div><p>Here is the analysis of <a id="id220" class="indexterm"/>the preceding code:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">As per the best practices, we created separate task files for each phase: install, configure, and service. We then called these from the main tasks file, that is, the <code class="literal">tasks/main.yml</code> file.</li><li class="listitem" style="list-style-type: disc">The configuration file for haproxy will be created in <code class="literal">/etc/haproxy/haproxy.cfg</code> using a Jinja2 template. In addition to creating the configuration, we also need to enable the <code class="literal">haproxy</code> service in the <code class="literal">/etc/defaults/haproxy</code> file.</li><li class="listitem" style="list-style-type: disc">Install, service, and handlers are similar to the roles that we created earlier, hence we will skip the description.</li></ul></div><p>We have defined the usage of templates in the <code class="literal">configure.yml</code> file. Let's now create the templates:</p><div><pre class="programlisting">#filename: roles/haproxy/templates/haproxy.default
ENABLED="{{ haproxy['config']['enabled'] }}"

#filename: roles/haproxy/templates/haproxy.cfg.j2
global
        log 127.0.0.1 local0
        log 127.0.0.1 local1 notice
        maxconn 4096
        user haproxy
        group haproxy
        daemon

defaults
        log global
        mode http
        option httplog
        option dontlognull
        retries 3
        option redispatch
        maxconn 2000
        contimeout 5000
        clitimeout 50000
        srvtimeout 50000

listen fifanews {{ haproxy['config']['listen_address'] }}:{{ haproxy['config']['listen_port'] }}
        cookie  SERVERID rewrite
        balance roundrobin
    {% for host in groups['www'] %}
        server {{ hostvars[host]['ansible_hostname'] }} {{ hostvars[host]['ansible_eth1']['ipv4']['address'] }}:{{ hostvars[host]['nginx']['phpsites']['fifanews']['port'] }} cookie {{ hostvars[host]['inventory_hostname'] }} check
    {% endfor %}</pre></div><p>The second template that we created at <code class="literal">roles/haproxy/templates/haproxy.cfg.j2</code> is of particular interest to <a id="id221" class="indexterm"/>us pertaining to node discovery. The following diagram shows the relevant section with the usage of magic variables marked:</p><div><img src="img/B03800_07_02.jpg" alt="Creating the load balancer role"/></div><p>Let's analyze this template snippet:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">We are using the magic variable <code class="literal">groups</code> to discover all hosts that belong to the group <code class="literal">www</code> in the inventory, as follows:<p>{% for host in groups['www'] -%}</p></li><li class="listitem" style="list-style-type: disc">For each discovered host, we fetch facts as well as user-defined variables using the <code class="literal">hostvars</code> <a id="id222" class="indexterm"/>parameter, which is another magic variable. We are looking up facts and user-defined variables, as well as another magic variable, which is <code class="literal">inventory_hostname</code>, as follows:<p>{{ hostvars[host]['ansible_eth1']['ipv4']['address'] }}</p><div><pre class="programlisting">{{ hostvars[host]['inventory_hostname'] }}
{{ hostvars[host]['nginx']['phpsites']['fifanews']['port'] }}</pre></div></li></ul></div><p>To apply this role to the load balancer host defined in the inventory, we need to create a play, which should be part of the <code class="literal">site.yml</code> file, which is our main playbook:</p><div><pre class="programlisting">---
#filename: lb.yml
- hosts: lb
  remote_user: vagrant
  sudo: yes
  roles:
     - { role: haproxy, when: ansible_os_family == 'Debian' }

---
# This is a site wide playbook 
# filename: site.yml
- include: db.yml
- include: www.yml
- include: lb.yml</pre></div><p>Now, run the playbook using the following command:</p><div><pre class="programlisting">
<strong>$ ansible-playbook -i customhosts site.yml</strong>
</pre></div><p>The preceding run will <a id="id223" class="indexterm"/>install <code class="literal">haproxy</code> and create a configuration with all web servers added to the <code class="literal">haproxy.cfg</code> file in the backends section. An example of the <code class="literal">haprxy.cfg</code> file is as follows:</p><div><pre class="programlisting">listen fifanews 0.0.0.0:8080
     cookie  SERVERID rewrite
     balance roundrobin
     server  vagrant 192.168.61.12:8080 cookie 192.168.61.12 check</pre></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec56"/>Accessing facts for non-playbook hosts</h1></div></div></div><p>In the earlier <a id="id224" class="indexterm"/>exercise, we launched the main playbook, which <a id="id225" class="indexterm"/>invokes all the other playbooks to configure the entire infrastructure. At times, we may just want to configure a portion of our infrastructure, in which case, we can just invoke the individual playbooks, such as <code class="literal">lb.yml</code>, <code class="literal">www.yml</code>, or <code class="literal">db.yml</code>. Let's try running the Ansible playbook just for the load balancers:</p><div><pre class="programlisting">
<strong>$ ansible-playbook -i customhosts lb.yml</strong>
</pre></div><p>Oops! It failed! Here is the snapshot of the snippet from the output:</p><div><img src="img/B03800_07_03.jpg" alt="Accessing facts for non-playbook hosts"/></div><p>Ansible exits with an error as it was not able to find a variable from the host, which is not part of the playbook anymore. Here is how Ansible behaves when it comes to magic variables:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Ansible starts to gather facts while it runs the code on a host. These facts are then stored in the memory for the duration of the playbook run. This is the default behavior, and can be turned off.</li><li class="listitem" style="list-style-type: disc">For host B to discover variables from host A, Ansible should have communicated with <a id="id226" class="indexterm"/>host A earlier in the playbook.</li></ul></div><p>This behavior from Ansible can cause undesired results and can limit a host to discover information about nodes that are only part of its own play.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec45"/>Facts caching with Redis</h2></div></div></div><p>Failure to discover facts from non-playbook hosts can be avoided by caching facts. This feature was added in version 1.8 of Ansible and supports caching facts between playbook runs in <strong>Redis</strong>, a key-value in the memory data store. This requires two changes:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Installing and starting the Redis service on the Ansible control node</li><li class="listitem" style="list-style-type: disc">Configuring Ansible to send facts to the instance of Redis</li></ul></div><p>Let's now install and <a id="id227" class="indexterm"/>start the Redis server using the following commands:</p><div><pre class="programlisting">
<strong>$ sudo apt-get install redis-server</strong>
<strong>$ sudo service redis-server start</strong>
<strong>$ apt-get install python-pip</strong>
<strong>$ pip install redis</strong>
</pre></div><p>This will install Redis on the Ubuntu host and start the service. If you have an <code class="literal">rpm</code> package-based system, you can install it as follows:</p><div><pre class="programlisting">
<strong>$ sudo yum install redis</strong>
<strong>$ sudo yum install python-pip</strong>
<strong>$ sudo service start redis</strong>
<strong>$ sudo pip install redis</strong>
</pre></div><div><div><h3 class="title"><a id="tip15"/>Tip</h3><p>Before enabling facts caching, it's a good idea to first check if you are running a version of Ansible equal to, or greater, than 1.8. You can do so by running the command <code class="literal">$ ansible –version</code>.</p></div></div><p>Now that we have <a id="id228" class="indexterm"/>started Redis, it's time to configure Ansible. Let's edit the <code class="literal">ansible.cfg</code> file as follows:</p><div><pre class="programlisting"># filename: /etc/ansible/ansible.cfg
# Comment  following lines 
# gathering = smart
# fact_caching = memory
# Add  following lines 
gathering = smart
fact_caching = redis
fact_caching_timeout = 86400
fact_caching_connection = localhost:6379:0</pre></div><p>Let's now validate this setup by running the playbook, which configures web servers:</p><div><pre class="programlisting">
<strong>$ ansible-playbook -i customhosts www.yml</strong>
<strong>$ redis-cli </strong>
<strong>$ keys *</strong>
</pre></div><p>Let's take a look <a id="id229" class="indexterm"/>at the following screenshot:</p><div><img src="img/B03800_07_04.jpg" alt="Facts caching with Redis"/></div><p>Now we will try running the load balancer playbook again using the following command:</p><div><pre class="programlisting">
<strong>$ ansible-playbook -i customhosts lb.yml</strong>
</pre></div><p>This time it goes through <a id="id230" class="indexterm"/>successfully. It's able to discover facts for the web server, which is not part of the play.</p></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec46"/>Caching facts in files</h2></div></div></div><p>Even though <a id="id231" class="indexterm"/>using Redis is the recommended approach, it's possible to cache facts in flat files as well. Ansible can write facts to files using the JSON format. To enable a JSON file as a format, we just need to edit the <code class="literal">ansible.cfg</code> file as follows:</p><div><pre class="programlisting">   # filename: /etc/ansible/ansible.cfg 
   fact_caching = jsonfile
fact_caching_connection = /tmp/cache</pre></div><p>Ensure that the directory specified exists with the correct permissions:</p><div><pre class="programlisting">
<strong>$ mkdir /tmp/cache</strong>
<strong>$ chmod 777 /tmp/cache</strong>
</pre></div><p>After making these <a id="id232" class="indexterm"/>changes, all we have to do is run the playbook, and Ansible will start writing facts to JSON files named after the hosts created under this directory.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec57"/>Review questions</h1></div></div></div><p>Do you think you've understood the chapter well enough? Try answering the following questions to test your understanding:</p><div><ol class="orderedlist arabic"><li class="listitem">Are magic variables different to facts? What are they used for?</li><li class="listitem">Which magic variable would allow us to walk over a list of web servers and enumerate an IP address for each?</li><li class="listitem">Why is facts caching required? What are the different modes for caching facts?</li><li class="listitem">Will the <code class="literal">inventory_hostname</code> fact always be the same as the <code class="literal">ansible_hostname</code> fact?</li></ol></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec58"/>Summary</h1></div></div></div><p>In this chapter, you learned how to discover information about other nodes in the cluster to connect them together. We started with the introduction to magic variables and looked at the most commonly used ones. We then started creating a role for haproxy, which auto-discovers web servers and creates configurations dynamically. Finally, we looked at the issue of accessing information about hosts not in the playbook, and you learned how to solve it by enabling the caching of facts. Magic variables are very powerful, especially while orchestrating your infrastructure with Ansible, where discovering topology information automatically is very useful.</p><p>In the next chapter, you will learn how to securely pass data using vault, an encrypted data store.</p></div></body></html>