<html><head></head><body>
		<div><h1 id="_idParaDest-107"><em class="italic"><a id="_idTextAnchor106"/>Chapter 4</em>: Continuous Integration Pipeline</h1>
			<p>We already know how to configure Jenkins. In this chapter, we will see how to use it effectively, focusing on the feature that lies at the heart of Jenkins – pipelines. By building a complete continuous integration process from scratch, we will describe all aspects of modern team-oriented code development.</p>
			<p>This chapter covers the following topics:</p>
			<ul>
				<li>Introducing pipelines</li>
				<li>The commit pipeline</li>
				<li>Code quality stages</li>
				<li>Triggers and notifications</li>
				<li>Team development strategies</li>
			</ul>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor107"/>Technical requirements</h1>
			<p>To complete this chapter, you'll need the following software:</p>
			<ul>
				<li>Jenkins</li>
				<li>Java JDK 8+</li>
			</ul>
			<p>All the examples and solutions to the exercises can be found at <a href="https://github.com/PacktPublishing/Continuous-Delivery-With-Docker-and-Jenkins-3rd-Edition/tree/main/Chapter04">https://github.com/PacktPublishing/Continuous-Delivery-With-Docker-and-Jenkins-3rd-Edition/tree/main/Chapter04</a>.</p>
			<p>Code in Action videos for this chapter can be viewed at <a href="https://bit.ly/3r9lbmG">https://bit.ly/3r9lbmG</a>.</p>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor108"/>Introducing pipelines</h1>
			<p>A <strong class="bold">pipeline</strong> is a sequence of automated operations that<a id="_idIndexMarker334"/> usually represents a part of the software delivery and quality assurance process. It can be seen as a chain of scripts that provide the following additional benefits:</p>
			<ul>
				<li><strong class="bold">Operation grouping</strong>: Operations are grouped<a id="_idIndexMarker335"/> together into stages (also known as <strong class="bold">gates</strong> or <strong class="bold">quality gates</strong>) that introduce<a id="_idIndexMarker336"/> a structure<a id="_idIndexMarker337"/> into a process and clearly define a rule – if one stage fails, no further stages are executed.</li>
				<li><strong class="bold">Visibility</strong>: All aspects of a process are visualized, which helps in quick failure analysis and promotes team collaboration.</li>
				<li><strong class="bold">Feedback</strong>: Team members learn about problems as soon as they occur so that they can react quickly.<p class="callout-heading">Information</p><p class="callout">The concept of pipelining is similar to most continuous integration tools. However, the naming can differ. In this book, we will stick to the Jenkins terminology.</p></li>
			</ul>
			<p>Let's first describe the Jenkins pipeline structure and then how it works in action.</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor109"/>The pipeline structure</h2>
			<p>A Jenkins pipeline<a id="_idIndexMarker338"/> consists of two kinds of elements – a <strong class="bold">stage</strong> and a <strong class="bold">step</strong>. The following diagram shows how they are used:</p>
			<div><div><img src="img/B18223_04_01.jpg" alt="Figure 4.1 – The Jenkins pipeline structure&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.1 – The Jenkins pipeline structure</p>
			<p>The following are the basic pipeline elements:</p>
			<ul>
				<li><strong class="bold">Step</strong>: A single operation<a id="_idIndexMarker339"/> that tells Jenkins what to do – for example, check out code from the repository and execute a script</li>
				<li><strong class="bold">Stage</strong>: A logical separation<a id="_idIndexMarker340"/> of steps that groups conceptually distinct sequences of steps – for example, <strong class="bold">build</strong>, <strong class="bold">test</strong>, and <strong class="bold">deploy</strong>, used to visualize the Jenkins pipeline progress<p class="callout-heading">Information</p><p class="callout">Technically, it's possible to create parallel steps; however, it's better to treat them as an exception that is only used for optimization purposes.</p></li>
			</ul>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor110"/>A multi-stage Hello World</h2>
			<p>As an example, let's extend<a id="_idIndexMarker341"/> the <code>Hello World</code> pipeline<a id="_idIndexMarker342"/> to contain two stages:</p>
			<pre>pipeline {
     agent any
     stages {
          stage('First Stage') {
               steps {
                    echo 'Step 1. Hello World'
               }
          }
          stage('Second Stage') {
               steps {
                    echo 'Step 2. Second time Hello'
                    echo 'Step 3. Third time Hello'
               }
          }
     }
}</pre>
			<p>The pipeline has no special requirements in terms of environment, and it executes three steps inside two stages. When we click on <strong class="bold">Build Now</strong>, we should see a visual representation:</p>
			<div><div><img src="img/B18223_04_02.jpg" alt="Figure 4.2 – The multi-stage pipeline build&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.2 – The multi-stage pipeline build</p>
			<p>The pipeline succeeded, and we can see the step<a id="_idIndexMarker343"/> execution details by clicking on<a id="_idIndexMarker344"/> the console. If any of the steps failed, processing would stop, and no further steps would run. Actually, the sole reason for a pipeline is to prevent all further steps from execution and visualize the point of failure.</p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor111"/>The pipeline syntax</h2>
			<p>We've discussed the pipeline elements and already<a id="_idIndexMarker345"/> used a few of the pipeline steps – for example, <code>echo</code>. <em class="italic">What other operations can we use inside the pipeline definition?</em></p>
			<p class="callout-heading">Information </p>
			<p class="callout">In this book, we use the declarative syntax<a id="_idIndexMarker346"/> that is recommended for all new projects. The other options are a Groovy-based DSL and (prior to Jenkins 2) XML (created through the web interface).</p>
			<p>The declarative syntax was designed to make it as simple as possible to understand the pipeline, even by people who do not write code on a daily basis. This is why the syntax is limited only to the most important keywords.</p>
			<p>Let's try an experiment, but before<a id="_idIndexMarker347"/> we describe all the details, please read the following pipeline definition and try to guess what it does:</p>
			<pre>pipeline {
     agent any
     triggers { cron('* * * * *') }
     options { timeout(time: 5) }
     parameters { 
          booleanParam(name: 'DEBUG_BUILD', defaultValue: true, 
          description: 'Is it the debug build?') 
     }
     stages {
          stage('Example') {
               environment { NAME = 'Rafal' }
               when { expression { return params.DEBUG_BUILD } } 
               steps {
                    echo "Hello from $NAME"
                    script {
                         def browsers = ['chrome', 'firefox']
                         for (int i = 0; i &lt; browsers.size(); ++i) {
                              echo "Testing the ${browsers[i]} browser."
                         }
                    }
               }
          }
     }
     post { always { echo 'I will always say Hello again!' } }
}</pre>
			<p>Hopefully, the pipeline<a id="_idIndexMarker348"/> didn't scare you. It is quite complex. Actually, it is so complex that it contains most available Jenkins instructions. To answer the experiment puzzle, let's see what the pipeline does instruction by instruction:</p>
			<ol>
				<li>Uses any available agent</li>
				<li>Executes automatically every minute</li>
				<li>Stops if the execution takes more than 5 minutes</li>
				<li>Asks for the Boolean input parameter before starting</li>
				<li>Sets <code>Rafal</code> as the <code>NAME</code> environment variable</li>
				<li>Does the following, only in the case of the <code>true</code> input parameter:<ul><li>Prints <code>Hello from Rafal</code></li><li>Prints <code>Testing the chrome browser</code></li><li>Prints <code>Testing the firefox browser</code></li></ul></li>
				<li>Prints <code>I will always say Hello again!</code>, regardless of whether there are any errors during the execution</li>
			</ol>
			<p>Now, let's describe the most important Jenkins keywords. A declarative pipeline is always specified inside the <code>pipeline</code> block and contains sections, directives, and steps. We will walk through each of them.</p>
			<p class="callout-heading">Information</p>
			<p class="callout">The complete pipeline syntax description<a id="_idIndexMarker349"/> can be found on the official Jenkins page at <a href="https://jenkins.io/doc/book/pipeline/syntax/">https://jenkins.io/doc/book/pipeline/syntax/</a>.</p>
			<h3>Sections</h3>
			<p>Sections define the pipeline structure and usually<a id="_idIndexMarker350"/> contain one or more directives or steps. They are defined with the following keywords:</p>
			<ul>
				<li><strong class="bold">Stages</strong>: This defines a series of one<a id="_idIndexMarker351"/> or more stage directives.</li>
				<li><strong class="bold">Steps</strong>: This defines a series of one or more step<a id="_idIndexMarker352"/> instructions.</li>
				<li><strong class="bold">Post</strong>: This defines a series of one or more step<a id="_idIndexMarker353"/> instructions that are run at the end of the pipeline build; they are marked with a condition (for example, always, success, or failure) and are usually used to send notifications after the pipeline build (we will cover this in detail in the <em class="italic">Triggers and notifications</em> section).</li>
				<li><code>label</code> to match the equally labeled agents, or <code>docker</code> to specify a container that is dynamically provisioned to provide an environment for the pipeline execution.</li>
			</ul>
			<h3>Directives</h3>
			<p>Directives express the configuration<a id="_idIndexMarker355"/> of a pipeline or its parts:</p>
			<ul>
				<li><code>cron</code> to set the time-based scheduling, or <code>pollSCM</code> to check the repository for changes (we will cover this in detail in the <em class="italic">Triggers and notifications</em> section).</li>
				<li><code>timeout</code> (the maximum time of a pipeline run) or <code>retry</code> (the number of times the pipeline should be rerun after failure).</li>
				<li><strong class="bold">Environment</strong>: This defines a set of key values used as environment variables during the build.</li>
				<li><strong class="bold">Parameters</strong>: This defines a list of user-input parameters.</li>
				<li><strong class="bold">Stage</strong>: This allows for the logical grouping of steps.</li>
				<li><strong class="bold">When</strong>: This determines whether the stage should be executed, depending on the given condition.</li>
				<li><code>PATH</code>.</li>
				<li><strong class="bold">Input</strong>: This allows us to prompt the input parameters.</li>
				<li><strong class="bold">Parallel</strong>: This allows us to specify stages that are run in parallel.</li>
				<li><strong class="bold">Matrix</strong>: This allows us to specify combinations<a id="_idIndexMarker358"/> of parameters for which the given stages run in parallel.</li>
			</ul>
			<h3>Steps</h3>
			<p>Steps are the most<a id="_idIndexMarker359"/> fundamental part of the pipeline. They define the operations that are executed, so they actually tell Jenkins <em class="italic">what to do</em>:</p>
			<ul>
				<li><code>sh</code>: This executes the shell command; actually, it's possible to define almost any operation using <code>sh</code>.</li>
				<li><code>custom</code>: Jenkins offers a lot of operations that can be used as steps (for example, <code>echo</code>); many of them are simply wrappers over the <code>sh</code> command used for convenience. Plugins can also define their own operations.</li>
				<li><code>script</code>: This executes a block of Groovy-based code that can be used for some non-trivial scenarios where flow control is needed.<p class="callout-heading">Information</p><p class="callout">The complete specification<a id="_idIndexMarker360"/> of the available steps can be found at <a href="https://jenkins.io/doc/pipeline/steps/">https://jenkins.io/doc/pipeline/steps/</a>.</p></li>
			</ul>
			<p>Note that the pipeline syntax is very generic and, technically, can be used for almost any automation process. This is why the pipeline should be treated as a method of structuing and visualization. However, the most common use case is to implement the continuous integration server, which we will look at in the following section.</p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor112"/>The commit pipeline</h1>
			<p>The most basic continuous integration process is called a <code>commit</code> (or <code>push</code> in Git) to the main repository and results in a report about the build success or failure. Since it runs after each change in the code, the build should take no more than 5 minutes and should consume a reasonable amount of resources. The commit phase is always the starting point of the continuous delivery process and provides the most important feedback cycle in the development process – constant information if the code is in a healthy state.</p>
			<p>The commit phase works as follows: a developer checks in the code to the repository, the continuous integration server detects the change, and the build starts. The most fundamental commit pipeline contains three stages:</p>
			<ul>
				<li><strong class="bold">Checkout</strong>: This stage downloads the source code from the repository.</li>
				<li><strong class="bold">Compile</strong>: This stage compiles the source code.</li>
				<li><strong class="bold">Unit test</strong>: This stage runs a suite of unit tests.</li>
			</ul>
			<p>Let's create a sample project and see how to implement the commit pipeline.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">This is an example of a pipeline for a project that uses technologies such as Git, Java, Gradle, and Spring Boot. Nevertheless, the same principles apply to any other technology.</p>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor113"/>Checkout</h2>
			<p>Checking out code from<a id="_idIndexMarker362"/> the repository is always the first operation<a id="_idIndexMarker363"/> in any pipeline. In order to see this, we need<a id="_idIndexMarker364"/> to have a repository. Then, we are able to create a pipeline.</p>
			<h3>Creating a GitHub repository</h3>
			<p>Creating a repository<a id="_idIndexMarker365"/> on the GitHub<a id="_idIndexMarker366"/> server takes just a few steps:</p>
			<ol>
				<li value="1">Go to <a href="https://github.com/">https://github.com/</a>.</li>
				<li>Create an account if you don't have one yet.</li>
				<li>Click on <strong class="bold">New</strong>, next to <strong class="bold">Repositories</strong>.</li>
				<li>Give it a name – <code>calculator</code>.</li>
				<li>Tick <strong class="bold">Initialize this repository with a README</strong>.</li>
				<li>Click on <strong class="bold">Create repository</strong>.</li>
			</ol>
			<p>Now, you should see the address of the repository – for example, <a href="https://github.com/leszko/calculator.git">https://github.com/leszko/calculator.git</a>.</p>
			<h3>Creating a checkout stage</h3>
			<p>We can create<a id="_idIndexMarker367"/> a new pipeline called <code>calculator</code>, and as it is a <code>Checkout</code>:</p>
			<pre>pipeline {
     agent any
     stages {
          stage("Checkout") {
               steps {
                    git url: 'https://github.com/leszko/calculator.git', branch: 'main'
               }
          }
     }
}</pre>
			<p>The pipeline can be executed on any of the agents, and its only step does nothing more than download code<a id="_idIndexMarker369"/> from the repository. We can click on <strong class="bold">Build Now</strong> to see whether it was executed successfully.</p>
			<p class="callout-heading">Information</p>
			<p class="callout">The Git toolkit needs to be installed on the node where the build is executed.</p>
			<p>When we have the checkout, we're ready for the second stage.</p>
			<h2 id="_idParaDest-115"><a id="_idTextAnchor114"/>Compile</h2>
			<p>In order to compile<a id="_idIndexMarker370"/> a project, we need to do<a id="_idIndexMarker371"/> the following:</p>
			<ol>
				<li value="1">Create a project with the source code.</li>
				<li>Push it to the repository.</li>
				<li>Add the <code>Compile</code> stage to the pipeline.</li>
			</ol>
			<p>Let's look at these steps in detail.</p>
			<h3>Creating a Java Spring Boot project</h3>
			<p>Let's create a very simple<a id="_idIndexMarker372"/> Java project using the Spring Boot<a id="_idIndexMarker373"/> framework built by Gradle.</p>
			<p class="callout-heading">Information</p>
			<p class="callout">Spring Boot is a Java framework that simplifies building enterprise applications. Gradle is a build automation system that is based on the concepts of Apache Maven.</p>
			<p>The simplest way to create a Spring Boot project is to perform the following steps:</p>
			<ol>
				<li value="1">Go to <a href="http://start.spring.io/">http://start.spring.io/</a>.</li>
				<li>Select <strong class="bold">Gradle Project</strong> instead of <strong class="bold">Maven Project</strong> (you can choose Maven<a id="_idIndexMarker374"/> if you prefer<a id="_idIndexMarker375"/> it to Gradle).</li>
				<li>Fill <code>com.leszko</code> and <code>calculator</code>).</li>
				<li>Add <strong class="bold">Web</strong> to <strong class="bold">Dependencies</strong>.</li>
				<li>Click on <strong class="bold">Generate</strong>.</li>
				<li>The generated skeleton project should be downloaded (the <code>calculator.zip</code> file).</li>
			</ol>
			<p>The following screenshot<a id="_idIndexMarker376"/> shows the <a href="http://start.spring.io/">http://start.spring.io/</a> page:</p>
			<div><div><img src="img/B18223_04_03.jpg" alt="Figure 4.3 – spring initializr&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.3 – spring initializr</p>
			<p>After the project<a id="_idIndexMarker377"/> is created, we can push<a id="_idIndexMarker378"/> it into the GitHub repository.</p>
			<h3>Pushing code to GitHub</h3>
			<p>We will use<a id="_idIndexMarker379"/> the Git tool to perform<a id="_idIndexMarker380"/> the <code>commit</code> and <code>push</code> operations.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">In order to run the <code>git</code> command, you need<a id="_idIndexMarker381"/> to have the Git toolkit installed (it can be downloaded from <a href="https://git-scm.com/downloads">https://git-scm.com/downloads</a>).</p>
			<p>Let's first clone the repository to the filesystem:</p>
			<pre>$ git clone https://github.com/leszko/calculator.git</pre>
			<p>Extract the project<a id="_idIndexMarker382"/> downloaded from <a href="http://start.spring.io/">http://start.spring.io/</a> into the directory<a id="_idIndexMarker383"/> created by Git.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">If you prefer, you can import the project into IntelliJ, Visual Studio Code, Eclipse, or your favorite IDE tool.</p>
			<p>As a result, the <code>calculator</code> directory should have the following files:</p>
			<pre>$ ls -a
. .. build.gradle .git .gitignore gradle gradlew gradlew.bat HELP.md README.md settings.gradle src</pre>
			<p class="callout-heading">Information </p>
			<p class="callout">In order to perform the Gradle operations locally, you need to have the Java JDK installed.</p>
			<p>We can compile the project locally using the following code:</p>
			<pre>$ ./gradlew compileJava</pre>
			<p>In the case of Maven, you can run <code>./mvnw compile</code>. Both Gradle and Maven compile the Java classes located in the <code>src</code> directory.</p>
			<p>Now, we can commit and push to the GitHub repository:</p>
			<pre>$ git add .
$ git commit -m "Add Spring Boot skeleton"
$ git push -u origin main</pre>
			<p>The code<a id="_idIndexMarker384"/> is already in the GitHub repository. If you want to check it, you can<a id="_idIndexMarker385"/> go to the GitHub page and see the files.</p>
			<h3>Creating a Compile stage</h3>
			<p>We can add a <code>Compile</code> stage to the pipeline using<a id="_idIndexMarker386"/> the following code:</p>
			<pre>stage("Compile") {
     steps {
          sh "./gradlew compileJava"
     }
}</pre>
			<p>Note that we used exactly the same command locally and in the Jenkins pipeline, which is a very good sign because the local development process is consistent with the continuous integration environment. After running the build, you should see two green boxes. You can also check that the project was compiled correctly in the console log.</p>
			<h2 id="_idParaDest-116"><a id="_idTextAnchor115"/>Unit tests</h2>
			<p>It's time to add the last<a id="_idIndexMarker387"/> stage, which is the unit test; it checks whether<a id="_idIndexMarker388"/> our code does what we expect it to do. We have to do the following:</p>
			<ol>
				<li value="1">Add the source code for the calculator logic.</li>
				<li>Write a unit test for the code.</li>
				<li>Add a Jenkins stage to execute the unit test.</li>
			</ol>
			<p>Let's elaborate more on these steps next.</p>
			<h3>Creating business logic</h3>
			<p>The first version of the calculator<a id="_idIndexMarker389"/> will be able to add two<a id="_idIndexMarker390"/> numbers. Let's add the business logic as a class in the <code>src/main/java/com/leszko/calculator/Calculator.java</code> file:</p>
			<pre>package com.leszko.calculator;
import org.springframework.stereotype.Service;
@Service
public class Calculator {
     public int sum(int a, int b) {
          return a + b;
     }
}</pre>
			<p>To execute the business logic, we also need<a id="_idIndexMarker391"/> to add the web service controller in a separate file: <code>src/main/java/com/leszko/calculator/CalculatorController.java</code>:</p>
			<pre>package com.leszko.calculator;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;
@RestController
class CalculatorController {
     @Autowired
     private Calculator calculator;
     @RequestMapping("/sum")
     String sum(@RequestParam("a") Integer a, 
                @RequestParam("b") Integer b) {
          return String.valueOf(calculator.sum(a, b));
     }
}</pre>
			<p>This class exposes business logic as a web service. We can run the application and see how it works:</p>
			<pre>$ ./gradlew bootRun</pre>
			<p>This should start our web service, and we can check<a id="_idIndexMarker392"/> that it works by navigating<a id="_idIndexMarker393"/> to the browser and opening <code>http://localhost:8080/sum?a=1&amp;b=2</code>. This should sum two numbers (<code>1</code> and <code>2</code>) and show <code>3</code> in the browser.</p>
			<h3>Writing a unit test</h3>
			<p>We already have the working application. <em class="italic">How can we ensure that the logic works as expected?</em> We tried it once, but in order<a id="_idIndexMarker394"/> to know that it will work consistently, we need a unit test. In our case, it will be trivial, maybe even unnecessary; however, in real projects, unit tests can save you from bugs and system failures.</p>
			<p>Let's create a unit test in the <code>src/test/java/com/leszko/calculator/CalculatorTest.java</code> file:</p>
			<pre>package com.leszko.calculator;
import org.junit.Test;
import static org.junit.Assert.assertEquals;
public class CalculatorTest {
     private Calculator calculator = new Calculator();
     @Test
     public void testSum() {
          assertEquals(5, calculator.sum(2, 3));
     }
}</pre>
			<p>Our test uses the JUnit library, so we need<a id="_idIndexMarker395"/> to add it as a dependency in the <code>build.gradle</code> file:</p>
			<pre>dependencies {
     ...
testImplementation 'junit:junit:4.13'
}</pre>
			<p>We can run the test locally using the <code>./gradlew test</code> command. Then, let's commit the code and push it to the repository:</p>
			<pre>$ git add .
$ git commit -m "Add sum logic, controller and unit test"
$ git push</pre>
			<h3>Creating a Unit test stage</h3>
			<p>Now, we can<a id="_idIndexMarker396"/> add a <code>Unit test</code> stage to the pipeline:</p>
			<pre>stage("Unit test") {
     steps {
          sh "./gradlew test"
     }
}</pre>
			<p class="callout-heading">Tip</p>
			<p class="callout">In the case of Maven, use the <code>./mvnw test</code> command instead.</p>
			<p>When we build the pipeline<a id="_idIndexMarker397"/> again, we should see three boxes, which means that we've completed the continuous integration pipeline:</p>
			<div><div><img src="img/B18223_04_04.jpg" alt="Figure 4.4 – A continuous integration pipeline build&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.4 – A continuous integration pipeline build</p>
			<p>Now that we have our pipeline prepared, let's look at how to achieve exactly the same result using Jenkinsfile.</p>
			<h2 id="_idParaDest-117"><a id="_idTextAnchor116"/>Jenkinsfile</h2>
			<p>So far, we've created<a id="_idIndexMarker398"/> all the pipeline code directly in Jenkins. This is, however, not the only option. We can also put the pipeline definition inside a file called <code>Jenkinsfile</code> and commit it to the repository, together with the source code. This method is even more consistent because the way your pipeline looks is strictly related to the project itself.</p>
			<p>For example, if you don't need the code compilation because your programming language is interpreted (and not compiled), you won't have the <code>Compile</code> stage. The tools you use also differ, depending on the environment. We used Gradle/Maven because we've built a Java project; however, in the case of a project written in Python, you can use PyBuilder. This leads to the idea that the pipelines should be created by the same people who write the code – the developers. Also, the pipeline definition should be put together with the code, in the repository.</p>
			<p>This approach brings immediate benefits, as follows:</p>
			<ul>
				<li>In the case of a Jenkins<a id="_idIndexMarker399"/> failure, the pipeline definition is not lost (because it's stored in the code repository, not in Jenkins).</li>
				<li>The history of the pipeline changes is stored.</li>
				<li>Pipeline changes go through the standard code development process (for example, they are subjected to code reviews).</li>
				<li>Access to the pipeline changes is restricted in exactly the same way as access to the source code.</li>
			</ul>
			<p>Let's see how it all looks in practice by creating a <code>Jenkinsfile</code> file.</p>
			<h3>Creating the Jenkins file</h3>
			<p>We can create the <code>Jenkinsfile</code> file and push it into our GitHub repository. Its content is almost the same as the commit<a id="_idIndexMarker400"/> pipeline we wrote. The only difference is that the checkout stage becomes redundant because Jenkins has to first check out the code (together with <code>Jenkinsfile</code>) and then read the pipeline structure (from <code>Jenkinsfile</code>). This is why Jenkins needs to know the repository address before it reads <code>Jenkinsfile</code>.</p>
			<p>Let's create a file called <code>Jenkinsfile</code> in the <code>root</code> directory of our project:</p>
			<pre>pipeline {
     agent any
     stages {
          stage("Compile") {
               steps {
                    sh "./gradlew compileJava"
               }
          }
          stage("Unit test") {
               steps {
                    sh "./gradlew test"
               }
          }
     }
}</pre>
			<p>We can now commit the added files and push them to the GitHub repository:</p>
			<pre>$ git add Jenkinsfile
$ git commit -m "Add Jenkinsfile"
$ git push</pre>
			<h3>Running the pipeline from Jenkinsfile</h3>
			<p>When <code>Jenkinsfile</code> is in the<a id="_idIndexMarker401"/> repository, all we have to do is to open the pipeline<a id="_idIndexMarker402"/> configuration and do the following in the <code>Pipeline</code> section:</p>
			<ol>
				<li value="1">Change <strong class="bold">Definition</strong> from <strong class="bold">Pipeline script</strong> to <strong class="bold">Pipeline script from SCM</strong>.</li>
				<li>Select <strong class="bold">Git</strong> in <strong class="bold">SCM</strong>.</li>
				<li>Put <a href="https://github.com/leszko/calculator.git">https://github.com/leszko/calculator.git</a> in <strong class="bold">Repository URL</strong>.</li>
				<li>Use <code>*/main</code> as <strong class="bold">Branch Specifier</strong>.</li>
			</ol>
			<div><div><img src="img/B18223_04_05.jpg" alt="Figure 4.5 – The Jenkinsfile pipeline configuration&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.5 – The Jenkinsfile pipeline configuration</p>
			<p>After saving, the build<a id="_idIndexMarker403"/> will always run from the current version of <code>Jenkinsfile</code> in the<a id="_idIndexMarker404"/> repository.</p>
			<p>We have successfully created the first complete commit pipeline. It can be treated as a minimum viable product, and actually, in many cases, this suffices as the continuous integration process. In the following sections, we will see what improvements can be done to make the commit pipeline even better.</p>
			<h1 id="_idParaDest-118"><a id="_idTextAnchor117"/>Code-quality stages</h1>
			<p>We can extend the three classic steps of continuous<a id="_idIndexMarker405"/> integration with additional steps. The most popular are code coverage and static analysis. Let's look at each of them.</p>
			<h2 id="_idParaDest-119"><a id="_idTextAnchor118"/>Code coverage</h2>
			<p>Think about the following <a id="_idIndexMarker406"/>scenario: you have a well-configured continuous integration<a id="_idIndexMarker407"/> process; however, nobody in your project writes unit tests. It passes all the builds, but it doesn't mean that the code is working as expected. <em class="italic">What do we do then?</em> <em class="italic">How do we ensure that the code is tested?</em></p>
			<p>The solution is to add a code coverage tool that runs all tests and verifies which parts of the code have been executed. Then, it can create a report that shows the untested sections. Moreover, we can make the build fail when there is too much untested code.</p>
			<p>There are a lot of tools available to perform the test coverage analysis; for Java, the most popular are JaCoCo, OpenClover, and Cobertura.</p>
			<p>Let's use JaCoCo and show how the coverage check works. In order to do this, we need to perform the following steps:</p>
			<ol>
				<li value="1">Add JaCoCo to the Gradle configuration.</li>
				<li>Add the code coverage stage to the pipeline.</li>
				<li>Optionally, publish JaCoCo reports in Jenkins.</li>
			</ol>
			<p>Let's look at these steps in detail.</p>
			<h3>Adding JaCoCo to Gradle</h3>
			<p>In order to<a id="_idIndexMarker408"/> run JaCoCo from Gradle, we<a id="_idIndexMarker409"/> need to add the <code>jacoco</code> plugin to the <code>build.gradle</code> file by inserting<a id="_idIndexMarker410"/> the following line:</p>
			<pre>plugins {
     ...
     id 'jacoco'
}</pre>
			<p>Next, if we want to make Gradle fail in the case of low code<a id="_idIndexMarker411"/> coverage, we can add<a id="_idIndexMarker412"/> the following configuration to the <code>build.gradle</code> file:</p>
			<pre>jacocoTestCoverageVerification {
     violationRules {
          rule {
               limit {
                    minimum = 0.2
               }
          }
     }
}</pre>
			<p>This configuration sets the minimum code coverage to 20%. We can run it with the following command:</p>
			<pre>$ ./gradlew test jacocoTestCoverageVerification</pre>
			<p>This command checks whether the code coverage is at least 20%. You can play with the minimum value to see the level at which the build fails. We can also generate a test coverage report using the following command:</p>
			<pre>$ ./gradlew test jacocoTestReport</pre>
			<p>You can check out the full coverage report in the <code>build/reports/jacoco/test/html/index.html</code> file:</p>
			<div><div><img src="img/B18223_04_06.jpg" alt="Figure 4.6 – JaCoCo code coverage report&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.6 – JaCoCo code coverage report</p>
			<p>Let's now add the coverage stage in our pipeline.</p>
			<h3>Adding a code coverage stage</h3>
			<p>Adding a code coverage stage<a id="_idIndexMarker413"/> to the pipeline is as simple as the previous stages:</p>
			<pre>stage("Code coverage") {
     steps {
          sh "./gradlew jacocoTestReport"
          sh "./gradlew jacocoTestCoverageVerification"
     }
}</pre>
			<p>After adding this stage, if anyone commits code that is not well covered with tests, the build will fail.</p>
			<h3>Publishing the code coverage report</h3>
			<p>When coverage is low and the pipeline fails, it is useful to look at the code coverage report and find what parts<a id="_idIndexMarker414"/> are not yet covered with tests. We can run Gradle locally and generate the coverage report; however, it is more convenient if Jenkins shows the report for us.</p>
			<p>In order to publish the code coverage report in Jenkins, we require the following stage definition:</p>
			<pre>stage("Code coverage") {
     steps {
          sh "./gradlew jacocoTestReport"
          publishHTML (target: [
               reportDir: 'build/reports/jacoco/test/html',
               reportFiles: 'index.html',
               reportName: "JaCoCo Report"
          ])
          sh "./gradlew jacocoTestCoverageVerification"
     }
}</pre>
			<p>This stage copies the generated JaCoCo report to the Jenkins output. When we run the build again, we should see a link to the code<a id="_idIndexMarker415"/> coverage reports (in the menu on the left-hand side, below <strong class="bold">Build Now</strong>).</p>
			<p class="callout-heading">Information </p>
			<p class="callout">To perform the <code>publishHTML</code> step, you need to have the HTML Publisher plugin installed in Jenkins. You can read<a id="_idIndexMarker416"/> more about the plugin at <a href="https://www.jenkins.io/doc/pipeline/steps/htmlpublisher/">https://www.jenkins.io/doc/pipeline/steps/htmlpublisher/</a>. Note also that if the report is generated but not displayed properly in Jenkins, you may need to configure<a id="_idIndexMarker417"/> Jenkins Security, as described here: <a href="https://www.jenkins.io/doc/book/security/configuring-content-security-policy/">https://www.jenkins.io/doc/book/security/configuring-content-security-policy/</a>.</p>
			<p>We have created the code coverage stage, which shows the code that is not tested and therefore vulnerable to bugs. Let's see what else can be done in order to improve the code quality.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">If you need code coverage that is stricter, you can check the concept of mutation testing and add the PIT framework<a id="_idIndexMarker418"/> stage to the pipeline. Read more at <a href="http://pitest.org/">http://pitest.org/</a>.</p>
			<h2 id="_idParaDest-120"><a id="_idTextAnchor119"/>Static code analysis</h2>
			<p>Your code coverage<a id="_idIndexMarker419"/> may work perfectly fine; however, <em class="italic">what about the quality of the code itself?</em> <em class="italic">How do we ensure it is maintainable and written in a good style?</em></p>
			<p>Static code analysis<a id="_idIndexMarker420"/> is an automatic process of checking code without actually executing it. In most cases, it implies checking a number of rules on the source code. These rules may apply to a wide range of aspects; for example, all public classes need to have a Javadoc comment, the maximum length of a line is 120 characters, or if a class defines the <code>equals()</code> method, it has to define the <code>hashCode()</code> method as well.</p>
			<p>The most popular tools to perform<a id="_idIndexMarker421"/> static analysis on Java code are Checkstyle, FindBugs, and PMD. Let's look at an example and add the static code analysis stage using Checkstyle. We will do this in three steps:</p>
			<ol>
				<li value="1">Adding the Checkstyle configuration</li>
				<li>Adding the Checkstyle stage</li>
				<li>Optionally, publishing the Checkstyle report in Jenkins</li>
			</ol>
			<p>We will walk through each of them.</p>
			<h3>Adding the Checkstyle configuration</h3>
			<p>In order to add the Checkstyle<a id="_idIndexMarker422"/> configuration, we need to define the rules<a id="_idIndexMarker423"/> against which the code is checked. We can do this by specifying the <code>config/checkstyle/checkstyle.xml</code> file:</p>
			<pre>&lt;?xml version="1.0"?&gt;
&lt;!DOCTYPE module PUBLIC
     "-//Puppy Crawl//DTD Check Configuration 1.2//EN"
     "http://www.puppycrawl.com/dtds/configuration_1_2.dtd"&gt;
&lt;module name="Checker"&gt;
     &lt;module name="TreeWalker"&gt;
          &lt;module name="ConstantName" /&gt;
     &lt;/module&gt;
&lt;/module&gt;</pre>
			<p>The configuration contains only one rule – checking whether all Java constants follow the naming convention and consist of uppercase characters only.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">The complete<a id="_idIndexMarker424"/> Checkstyle description can be found at <a href="https://checkstyle.sourceforge.io/config.html">https://checkstyle.sourceforge.io/config.html</a>.</p>
			<p>We also need to<a id="_idIndexMarker425"/> add the <code>checkstyle</code> plugin<a id="_idIndexMarker426"/> to the <code>build.gradle</code> file:</p>
			<pre>plugins {
     ...
     id 'checkstyle'
}</pre>
			<p>Then, we can run <code>checkstyle</code> with the following command:</p>
			<pre>$ ./gradlew checkstyleMain</pre>
			<p>In the case of our project, this command should complete successfully because we didn't use any constants so far. However, you can try adding a constant with the wrong name and checking whether the build fails. For example, if you add the following constant to the <code>src/main/java/com/leszko/calculator/CalculatorApplication.java</code> file, <code>checkstyle</code> fails:</p>
			<pre>@SpringBootApplication
public class CalculatorApplication {
     private static final String constant = "constant";
     public static void main(String[] args) {
          SpringApplication.run(CalculatorApplication.class, args);
     }
}</pre>
			<h3>Adding a Static code analysis stage</h3>
			<p>We can add a <code>Static code analysis</code> stage to<a id="_idIndexMarker427"/> the pipeline:</p>
			<pre>stage("Static code analysis") {
     steps {
          sh "./gradlew checkstyleMain"
     }
}</pre>
			<p>Now, if anyone commits any code that does not follow the Java constant naming convention, the build will fail.</p>
			<h3>Publishing static code analysis reports</h3>
			<p>Very similar to JaCoCo, we can add<a id="_idIndexMarker428"/> the Checkstyle report to Jenkins:</p>
			<pre>publishHTML (target: [
     reportDir: 'build/reports/checkstyle/',
     reportFiles: 'main.html',
     reportName: "Checkstyle Report"
])</pre>
			<p>This generates a link to the Checkstyle report.</p>
			<p>We have now added the static code analysis stage, which can help to find bugs and standardize the code style inside a team or organization.</p>
			<p>Let's see one more option we have when it comes to implementing code analysis.</p>
			<h2 id="_idParaDest-121"><a id="_idTextAnchor120"/>SonarQube</h2>
			<p>SonarQube is the most widespread source<a id="_idIndexMarker429"/> code quality management tool. It supports multiple programming languages and can be treated as an alternative to the code coverage and static code analysis steps we looked at. Actually, it is a separate server that aggregates different code analysis frameworks, such as Checkstyle, FindBugs, and JaCoCo. It has its own dashboards and integrates well with Jenkins.</p>
			<p>Instead of adding code quality steps<a id="_idIndexMarker430"/> to the pipeline, we can install SonarQube, add plugins there, and add a <em class="italic">sonar</em> stage to the pipeline. The advantage of this solution is that SonarQube provides a user-friendly web interface to configure rules and show code vulnerabilities.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">You can read more about<a id="_idIndexMarker431"/> SonarQube on its official page at <a href="https://www.sonarqube.org/">https://www.sonarqube.org/</a>.</p>
			<p>Now that we have covered the code quality stages, let's focus on triggers and notifications.</p>
			<h1 id="_idParaDest-122"><a id="_idTextAnchor121"/>Triggers and notifications</h1>
			<p>So far, we have always built the pipeline manually by clicking on the <strong class="bold">Build Now</strong> button. It works completely fine<a id="_idIndexMarker432"/> but may not be very convenient in practice. All team members would have to remember<a id="_idIndexMarker433"/> that after committing to the repository, they need to open Jenkins and start the build. The same applies to pipeline monitoring; so far, we have manually opened Jenkins and checked the build status. In this section, we will see how to improve the process so that the pipeline will start automatically and, when completed, notify team members regarding its status.</p>
			<h2 id="_idParaDest-123"><a id="_idTextAnchor122"/>Triggers</h2>
			<p>An automatic action<a id="_idIndexMarker434"/> to start the build is called the<a id="_idIndexMarker435"/> pipeline trigger. In Jenkins, there are many options to choose<a id="_idIndexMarker436"/> from; however, they all boil down to three types:</p>
			<ul>
				<li>External</li>
				<li>Polling <strong class="bold">Source Control Management</strong> (<strong class="bold">SCM</strong>)</li>
				<li>A scheduled build</li>
			</ul>
			<p>Let's take a look at each of them.</p>
			<h3>External</h3>
			<p>External triggers are easy<a id="_idIndexMarker437"/> to understand. They mean that Jenkins starts the build<a id="_idIndexMarker438"/> after it's called by the <strong class="bold">notifier</strong>, which can be the other pipeline build, the SCM system (for example, GitHub), or any remote script.</p>
			<p>The following diagram presents the communication:</p>
			<div><div><img src="img/B18223_04_07.jpg" alt="Figure 4.7 – An external trigger&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.7 – An external trigger</p>
			<p>GitHub triggers Jenkins after a push to the repository and the build is started.</p>
			<p>To configure the system this way, we need the following setup steps:</p>
			<ol>
				<li value="1">Install the GitHub plugin in Jenkins.</li>
				<li>Generate a secret key for Jenkins.</li>
				<li>Set the GitHub webhook and specify the Jenkins address and key.</li>
			</ol>
			<p>In the case of the most popular SCM providers, dedicated Jenkins plugins are always provided.</p>
			<p>There is also a more generic way to trigger Jenkins via the REST call to the <code>&lt;jenkins_url&gt;/job/&lt;job_name&gt;/build?token=&lt;token&gt;</code> endpoint. For security reasons, it requires setting <code>token</code> in Jenkins and then using it in the remote script.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">Jenkins must be accessible from the SCM server. In other words, if we use the public GitHub repository to trigger Jenkins, our Jenkins server must be public as well. This also applies to the REST call solution, in which case, the <code>&lt;jenkins_url&gt;</code> address must be accessible from the script that triggers it.</p>
			<h3>Polling SCM</h3>
			<p>Polling the SCM trigger<a id="_idIndexMarker439"/> is a little less intuitive. The following diagram presents<a id="_idIndexMarker440"/> the communication:</p>
			<div><div><img src="img/B18223_04_08.jpg" alt="Figure 4.8 – Polling the SCM trigger&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.8 – Polling the SCM trigger</p>
			<p>Jenkins periodically calls GitHub and checks whether there was any push to the repository. Then, it starts the build. It may sound counter-intuitive, but there are at least two good cases for using this method:</p>
			<ul>
				<li>Jenkins is inside the firewalled network (which GitHub does not have access to).</li>
				<li>Commits are frequent and the build takes a long time, so executing a build after every commit would cause an overload.</li>
			</ul>
			<p>The configuration of <code>pollSCM</code> is also somehow simpler because the way to connect from Jenkins to GitHub is already set up (Jenkins checks out the code from GitHub, so it knows how to access it). In the case of our calculator project, we can set up an automatic trigger by adding the <code>triggers</code> declaration (just after <code>agent</code>) to the pipeline:</p>
			<pre>triggers {
     pollSCM('* * * * *')
}</pre>
			<p>After running the pipeline manually for the first time, the automatic trigger is set. Then, it checks GitHub every minute, and for new commits, it starts a build. To test that it works as expected, you can commit and push anything to the GitHub repository and see that the build starts.</p>
			<p>We used the mysterious <code>* * * * *</code> as an argument to <code>pollSCM</code>. It specifies how often Jenkins should check for new source<a id="_idIndexMarker441"/> changes and is expressed in the <code>cron</code>-style<a id="_idIndexMarker442"/> string format.</p>
			<p class="callout-heading">Information</p>
			<p class="callout">The <code>cron</code> string format<a id="_idIndexMarker443"/> is described (together with the cron tool) at <a href="https://en.wikipedia.org/wiki/Cron">https://en.wikipedia.org/wiki/Cron</a>.</p>
			<h3>Scheduled builds</h3>
			<p>The scheduled trigger<a id="_idIndexMarker444"/> means that Jenkins runs the build periodically, regardless of whether there were any commits to the repository.</p>
			<p>As the following screenshot shows, no communication with any system is required:</p>
			<div><div><img src="img/B18223_04_09.jpg" alt="Figure 4.9 – The scheduled build trigger&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.9 – The scheduled build trigger</p>
			<p>The implementation of <code>cron</code> keyword is used instead of <code>pollSCM</code>. This trigger method is rarely used for the commit pipeline but applies well to nightly builds (for example, complex integration testing executed at night).</p>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor123"/>Notifications</h2>
			<p>Jenkins provides a lot of ways to announce its build<a id="_idIndexMarker445"/> status. What's more, as with everything in Jenkins, new notification types can be added using plugins.</p>
			<p>Let's walk through the most popular types so that you can choose the one that fits your needs.</p>
			<h3>Email</h3>
			<p>The most classic way to notify users about the Jenkins build status is to send emails. The advantage of this solution<a id="_idIndexMarker446"/> is that everybody has a mailbox, everybody knows how to use it, and everybody<a id="_idIndexMarker447"/> is used to receiving information in it. The drawback is that, usually, there are simply too many emails, and the ones from Jenkins quickly become filtered out and never read.</p>
			<p>The configuration of the email notification is very simple:</p>
			<ol>
				<li value="1">Have the <strong class="bold">SMTP</strong> (<strong class="bold">Simple Mail Transfer Protocol</strong>) server configured.</li>
				<li>Set its details in Jenkins (in <strong class="bold">Manage Jenkins</strong> | <strong class="bold">Configure System</strong>).</li>
				<li>Use the <code>mail to</code> instruction in the pipeline.</li>
			</ol>
			<p>The pipeline configuration can be as follows:</p>
			<pre>post {
     always {
          mail to: 'team@company.com',
          subject: "Completed Pipeline: ${currentBuild.fullDisplayName}",
          body: "Your build completed, please check: ${env.BUILD_URL}"
     }
}</pre>
			<p>Note that all notifications are usually called in the <code>post</code> section of the pipeline, which is executed after all steps, no matter whether the build succeeded or failed. We used the <code>always</code> keyword; however, there are different options:</p>
			<ul>
				<li><code>always</code>: Execute regardless of the completion status.</li>
				<li><code>changed</code>: Execute only if the pipeline changed its status.</li>
				<li><code>fixed</code>: Execute only if the pipeline changed its status from failed to success.</li>
				<li><code>regression</code>: Execute only if the pipeline changed its status from success to failed, unstable, or aborted.</li>
				<li><code>aborted</code>: Execute only if the pipeline was manually aborted.</li>
				<li><code>failure</code>: Execute only if the pipeline has the <code>failed</code> status.</li>
				<li><code>success</code>: Execute only if the pipeline has the <code>success</code> status.</li>
				<li><code>unstable</code>: Execute only if the pipeline has the <code>unstable</code> status (usually caused by test failures or code violations).</li>
				<li><code>unsuccessful</code>: Execute<a id="_idIndexMarker448"/> only if the pipeline<a id="_idIndexMarker449"/> has any status other than <code>success</code>.</li>
			</ul>
			<h3>Group chats</h3>
			<p>If a group chat (for example, Slack) is the first method<a id="_idIndexMarker450"/> of communication<a id="_idIndexMarker451"/> in your team, it's worth considering adding the automatic build notifications there. No matter which tool you use, the procedure to configure it is always the same:</p>
			<ol>
				<li value="1">Find and install the plugin for your group chat tool (for example, the <strong class="bold">Slack Notification</strong> plugin).</li>
				<li>Configure the plugin (the server URL, channel, authorization token, and so on).</li>
				<li>Add the sending instruction to the pipeline.</li>
			</ol>
			<p>Let's see a sample pipeline configuration for Slack to send notifications after the build fails:</p>
			<pre>post {
     failure {
          slackSend channel: '#dragons-team',
          color: 'danger',
          message: "The pipeline ${currentBuild.fullDisplayName} failed."
     }
}</pre>
			<h3>Team spaces</h3>
			<p>Together with the agile culture<a id="_idIndexMarker452"/> came the idea that it's better to have everything<a id="_idIndexMarker453"/> happening in a team space. Instead of writing emails, meet together; instead of online messaging, come and talk; instead of task tracking tools, have a whiteboard. The same idea came to continuous delivery and Jenkins. Currently, it's very common<a id="_idIndexMarker454"/> to install big screens (also called <strong class="bold">build radiators</strong>) in the team space. Then, when you come to the office, the first thing you see is the current status of the pipeline. Build radiators are considered one of the most effective notification strategies. They ensure that everyone is aware of failing builds and, as a beneficial side effect, they boost team spirit and favor in-person communication.</p>
			<p>Since developers are creative beings, they invented a lot of other ideas that play the same role as the radiators. Some teams hang large speakers that beep when the pipeline fails. Others have toys that blink when the build is done. One of my favorites is Pipeline State UFO, which is provided as an open source project on GitHub. On its page, you can find a description of how to print and configure a UFO that hangs off the ceiling and signals the pipeline state. You can find more information at <a href="https://github.com/Dynatrace/ufo">https://github.com/Dynatrace/ufo</a>.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">Since Jenkins is extensible by plugins, its community wrote a lot of different ways to inform users about the build statuses. Among them, you can find RSS feeds, SMS notifications, mobile applications, and desktop notifiers.</p>
			<p>Now that we have covered triggers and notifications, let's focus on one more important aspect – team development strategies.</p>
			<h1 id="_idParaDest-125"><a id="_idTextAnchor124"/>Team development strategies</h1>
			<p>We have covered everything regarding how the continuous<a id="_idIndexMarker455"/> integration pipeline should look. However, <em class="italic">when exactly should it be run?</em> Of course, it is triggered after the commit to the repository, but <em class="italic">after the commit to which branch?</em> <em class="italic">Only to the trunk or to every branch?</em> Or, <em class="italic">maybe it should run before, not after, committing so that the repository will always be healthy?</em> Or, <em class="italic">how about the crazy idea of having no branches at all?</em></p>
			<p>There is no single best answer to these questions. Actually, the way you use the continuous integration<a id="_idIndexMarker456"/> process depends on your team development workflow. So, before we go any further, let's describe the possible workflows.</p>
			<h2 id="_idParaDest-126"><a id="_idTextAnchor125"/>Development workflows</h2>
			<p>A development workflow<a id="_idIndexMarker457"/> is the way your team puts<a id="_idIndexMarker458"/> code into the repository. It depends, of course, on many factors, such as the SCM tool, the project specifics, and the team size.</p>
			<p>As a result, each team develops the code in a slightly different manner. We can, however, classify them into three types: a <strong class="bold">trunk-based workflow</strong>, a <strong class="bold">branching workflow</strong>, and a <strong class="bold">forking workflow</strong>.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">All workflows<a id="_idIndexMarker459"/> are described in detail, with examples, at <a href="https://www.atlassian.com/git/tutorials/comparing-workflows">https://www.atlassian.com/git/tutorials/comparing-workflows</a>.</p>
			<h3>The trunk-based workflow</h3>
			<p>The trunk-based workflow<a id="_idIndexMarker460"/> is the simplest possible<a id="_idIndexMarker461"/> strategy. It is presented in the following diagram:</p>
			<div><div><img src="img/B18223_04_10.jpg" alt="Figure 4.10 – The trunk-based workflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.10 – The trunk-based workflow</p>
			<p>There is one central repository with a single entry for all changes to the project, which is called the <strong class="bold">trunk</strong> or <strong class="bold">master</strong>. Every member<a id="_idIndexMarker462"/> of the team clones<a id="_idIndexMarker463"/> the central repository to have their own local copies. The changes<a id="_idIndexMarker464"/> are committed directly<a id="_idIndexMarker465"/> to the central repository.</p>
			<h3>The branching workflow</h3>
			<p>The branching workflow, as its name suggests, means<a id="_idIndexMarker466"/> that the code is kept in many<a id="_idIndexMarker467"/> different branches. The idea is presented in the following diagram:</p>
			<div><div><img src="img/B18223_04_11.jpg" alt="Figure 4.11 – The branching workflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.11 – The branching workflow</p>
			<p>When developers start to work on a new feature, they create a dedicated branch from the trunk and commit all feature-related changes there. This makes it easy for multiple developers to work on a feature<a id="_idIndexMarker468"/> without breaking the main code base. This is why, in the case of the branching workflow, there is no problem in keeping the master healthy. When the feature<a id="_idIndexMarker469"/> is completed, a developer rebases the feature branch from the master and creates a pull request that contains all feature-related code changes. It opens the code review discussions and makes space to check whether the changes disturb the master. When the code is accepted by other developers and automatic system checks, it is merged into the main code base. The build is run again on the master but should almost never fail, since it didn't fail on the branch.</p>
			<h3>The forking workflow</h3>
			<p>The forking workflow<a id="_idIndexMarker470"/> is very popular among<a id="_idIndexMarker471"/> open source communities. It is presented in the following diagram:</p>
			<div><div><img src="img/B18223_04_12.jpg" alt="Figure 4.12 – The forking workflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.12 – The forking workflow</p>
			<p>Each developer has their own server-side repository. It may or may not be the official repository, but technically, each repository is exactly the same.</p>
			<p><strong class="bold">Forking</strong> means literally creating a new repository from another repository. Developers push to their own repositories, and when they<a id="_idIndexMarker472"/> want to integrate code, they create a pull request<a id="_idIndexMarker473"/> to the other repository.</p>
			<p>The main advantage of the forking workflow is that the integration is not necessarily via a central repository. It also helps with ownership because it allows the acceptance of pull requests from others without giving them write access.</p>
			<p>In the case of requirement-oriented commercial projects, a team usually works on one product and therefore has a central repository, so this model boils down to having a branching workflow with good ownership assignment; for example, only project leads can merge pull requests into the central repository.</p>
			<h2 id="_idParaDest-127"><a id="_idTextAnchor126"/>Adopting continuous integration</h2>
			<p>We have<a id="_idIndexMarker474"/> described different development<a id="_idIndexMarker475"/> workflows, but <em class="italic">how do they influence the continuous integration configuration?</em></p>
			<h3>Branching strategies</h3>
			<p>Each development workflow implies<a id="_idIndexMarker476"/> a different continuous integration approach:</p>
			<ul>
				<li><strong class="bold">Trunk-based workflow</strong>: This implies constantly struggling against the broken pipeline. If everyone<a id="_idIndexMarker477"/> commits to the main code base, the pipeline often fails. In this case, the old continuous integration rule says, <em class="italic">If the build is broken, the development team stops whatever they are doing and fixes the problem immediately</em>.</li>
				<li><strong class="bold">Branching workflow</strong>: This solves the broken trunk issue but introduces another one: if everyone<a id="_idIndexMarker478"/> develops in their own branches, <em class="italic">where is the integration?</em> A feature usually takes weeks or months to develop, and for all this time, the branch is not integrated into the main code. Therefore, it cannot really be called continuous integration – not to mention that there is a constant need for merging and resolving conflicts.</li>
				<li><strong class="bold">Forking workflow</strong>: This implies managing the continuous integration process by every repository<a id="_idIndexMarker479"/> owner, which isn't usually a problem. It does share, however, the same issues as the branching workflow.</li>
			</ul>
			<p>There is no silver bullet, and different<a id="_idIndexMarker480"/> organizations choose different strategies. The solution that is the closest to perfection uses the technique of the branching workflow and the philosophy of the trunk-based workflow. In other words, we can create very small branches and integrate them frequently into the master. This seems to take the best aspects of both. However, it requires either having tiny features or using feature toggles. Since the concept of feature toggles fits very well into continuous integration and continuous delivery, let's take a moment to explore it.</p>
			<h3>Feature toggles</h3>
			<p>Feature toggles is a technique<a id="_idIndexMarker481"/> that is an alternative to maintaining<a id="_idIndexMarker482"/> multiple source code branches, such that the feature can be tested before it is completed and ready for release. It is used to disable the feature for users but enable it for developers while testing. Feature toggles are essentially variables used in conditional statements.</p>
			<p>The simplest implementation of feature toggles are flags and the <code>if</code> statements. A development using feature toggles, as opposed to a feature branching development, appears as follows:</p>
			<ol>
				<li value="1">A new feature has to be implemented.</li>
				<li>Create a new flag or a configuration property – <code>feature_toggle</code> (instead of the <code>feature</code> branch).</li>
				<li>All feature-related code is added inside the <code>if</code> statement (instead of committing to the <code>feature</code> branch), such as the following:<pre>if (feature_toggle) {
     // do something
}</pre></li>
				<li>During the feature development, the following takes place:<ul><li>Coding is done in the master with <code>feature_toggle = true</code> (instead of coding in the feature branch).</li><li>The release is done from the master with <code>feature_toggle = false</code>.</li></ul></li>
				<li>When the feature development is completed, all <code>if</code> statements are removed and <code>feature_toggle</code> is removed from the configuration (instead of merging <code>feature</code> to the master and removing the <code>feature</code> branch).</li>
			</ol>
			<p>The benefit of feature toggles<a id="_idIndexMarker483"/> is that all development is done in the trunk, which facilitates<a id="_idIndexMarker484"/> real continuous integration and mitigates problems with merging the code.</p>
			<h2 id="_idParaDest-128"><a id="_idTextAnchor127"/>Jenkins multi-branch</h2>
			<p>If you decide to use branches<a id="_idIndexMarker485"/> in any form, either the long-feature branches or the recommended short-lived branches, it is convenient to know<a id="_idIndexMarker486"/> that the code is healthy before merging it into the master. This approach results in always keeping the main code base green, and luckily, there is an easy way to do it with Jenkins.</p>
			<p>In order to use multi-branch in our calculator project, let's proceed with the following steps:</p>
			<ol>
				<li value="1">Open the main Jenkins page.</li>
				<li>Click on <strong class="bold">New Item</strong>.</li>
				<li>Enter <code>calculator-branches</code> as the item name, select <strong class="bold">Multibranch Pipeline</strong>, and click on <strong class="bold">OK</strong>.</li>
				<li>In the <strong class="bold">Branch Sources</strong> section, click on <strong class="bold">Add source</strong>, and select <strong class="bold">Git</strong>.</li>
				<li>Enter the repository address in the <strong class="bold">Project Repository</strong> field:</li>
			</ol>
			<div><div><img src="img/B18223_04_13.jpg" alt="Figure 4.13 – The multi-branch pipeline configuration&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.13 – The multi-branch pipeline configuration</p>
			<ol>
				<li value="6">Tick <strong class="bold">Periodically if not otherwise run</strong> and set <strong class="bold">1 minute</strong> as the interval.</li>
				<li>Click on <strong class="bold">Save</strong>.</li>
			</ol>
			<p>Every minute, this configuration<a id="_idIndexMarker487"/> checks whether there<a id="_idIndexMarker488"/> were any branches added (or removed) and creates (or deletes) the dedicated pipeline defined by <code>Jenkinsfile</code>.</p>
			<p>We can create a new branch and see how it works. Let's create a new branch called <code>feature</code> and push it into the repository:</p>
			<pre>$ git checkout -b feature
$ git push origin feature</pre>
			<p>After a moment, you should see a new branch pipeline automatically created and run:</p>
			<div><div><img src="img/B18223_04_14.jpg" alt="Figure 4.14 – The multi-branch pipeline build&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.14 – The multi-branch pipeline build</p>
			<p>Now, before merging the feature branch to the master, we can check whether it's green. This approach should never break the master build.</p>
			<p>A very similar approach<a id="_idIndexMarker489"/> is to build a pipeline per pull request instead of a pipeline<a id="_idIndexMarker490"/> per branch, which gives the same result – the main code base is always healthy.</p>
			<h2 id="_idParaDest-129"><a id="_idTextAnchor128"/>Non-technical requirements</h2>
			<p>Last but not least, continuous<a id="_idIndexMarker491"/> integration is not all about technology. On the contrary, technology comes second. James Shore, in his <em class="italic">Continuous Integration on a Dollar a Day</em> article, described how to set up the continuous integration process without any additional software. All he used was a rubber chicken and a bell. The idea is to make the team work in one room and set up a separate computer with an empty chair. Put the rubber chicken and the bell in front <a id="_idIndexMarker492"/>of that computer. Now, when you plan to check in the code, take the rubber chicken, check in the code, go to the empty computer, check out the fresh code, run all tests there, and if everything passes, put back the rubber chicken, and ring the bell so that everyone knows that something has been added to the repository.</p>
			<p class="callout-heading"> Information</p>
			<p class="callout"><em class="italic">Continuous Integration on a Dollar a Day</em> by <em class="italic">James Shore</em> can be found at <a href="http://www.jamesshore.com/v2/blog/2006/continuous-integration-on-a-dollar-a-day">http://www.jamesshore.com/v2/blog/2006/continuous-integration-on-a-dollar-a-day</a>.</p>
			<p>The idea is a little oversimplified, and automated tools are useful; however, the main message is that without each team member's engagement, even the best tools won't help. In his book, Jez Humble outlines the prerequisites<a id="_idIndexMarker493"/> for continuous integration:</p>
			<ul>
				<li><strong class="bold">Check in regularly</strong>: To quote Mike Roberts, <em class="italic">continuously is more often than you think</em>; the minimum is once a day.</li>
				<li><strong class="bold">Create comprehensive unit tests</strong>: It's not only about high test coverage; it's possible to have no assertions and still keep 100% coverage.</li>
				<li><strong class="bold">Keep the process quick</strong>: Continuous integration must take a short time, preferably under 5 minutes. 10 minutes is already a lot.</li>
				<li><strong class="bold">Monitor the builds</strong>: This can be a shared responsibility, or you can adapt the <strong class="bold">build master</strong> role that rotates weekly.</li>
			</ul>
			<h1 id="_idParaDest-130"><a id="_idTextAnchor129"/>Summary</h1>
			<p>In this chapter, we covered all aspects of the continuous integration pipeline, which is always the first step for continuous delivery. Here are the key takeaways:</p>
			<ul>
				<li>The pipeline provides a general mechanism for organizing any automation processes; however, the most common use cases are continuous integration and continuous delivery.</li>
				<li>Jenkins accepts different ways of defining pipelines, but the recommended one is the declarative syntax.</li>
				<li>The commit pipeline is the most basic continuous integration process, and as its name suggests, it should be run after every commit to the repository.</li>
				<li>The pipeline definition should be stored in the repository as a <code>Jenkinsfile</code> file.</li>
				<li>The commit pipeline can be extended with the code quality stages.</li>
				<li>No matter what the project build tool, Jenkins commands should always be consistent with local development commands.</li>
				<li>Jenkins offers a wide range of triggers and notifications.</li>
				<li>The development workflow should be carefully chosen inside a team or organization because it affects the continuous integration process and defines the way code is developed.</li>
			</ul>
			<p>In the next chapter, we will focus on the next phase of the continuous delivery process – automated acceptance testing. This can be considered the most important and, in many cases, the most difficult step to implement. We will explore the idea of acceptance testing and a sample implementation using Docker.</p>
			<h1 id="_idParaDest-131"><a id="_idTextAnchor130"/>Exercises</h1>
			<p>You've learned a lot about how to configure the continuous integration process. Since <em class="italic">practice makes perfect</em>, I recommend doing the following exercises:</p>
			<ul>
				<li>Create a Python program that multiplies two numbers passed as command-line parameters. Add unit tests and publish the project on GitHub:<ol><li>Create two files: <code>calculator.py</code> and <code>test_calculator.py</code>.</li><li>You can use the <code>unittest</code> library at <a href="https://docs.python.org/3/library/unittest.html">https://docs.python.org/3/library/unittest.html</a>.</li><li>Run the program and the unit test.</li></ol></li>
				<li>Build the continuous integration pipeline for the Python calculator project:<ol><li value="1">Use <code>Jenkinsfile</code> to specify the pipeline.</li><li>Configure the trigger so that the pipeline runs automatically in case of any commits to the repository.</li><li>The pipeline doesn't need the <code>Compile</code> step since Python is an interpretable language.</li><li>Run the pipeline and observe the results.</li><li>Try to commit the code that breaks the pipeline build and observe how it is visualized in Jenkins.</li></ol></li>
			</ul>
			<h1 id="_idParaDest-132"><a id="_idTextAnchor131"/>Questions</h1>
			<p>To verify the knowledge acquired from this chapter, please answer the following questions:</p>
			<ol>
				<li value="1">What is a pipeline?</li>
				<li>What is the difference between a <em class="italic">stage</em> and a <em class="italic">step</em> in the pipeline?</li>
				<li>What is the <code>post</code> section in the Jenkins pipeline?</li>
				<li>What are the three most fundamental stages of the commit pipeline?</li>
				<li>What is <code>Jenkinsfile</code>?</li>
				<li>What is the purpose of the code coverage stage?</li>
				<li>What is the difference between the following Jenkins triggers – external and polling SCM?</li>
				<li>What are the most common Jenkins notification methods? Name at least three.</li>
				<li>What are the three most common development workflows?</li>
				<li>What is a feature toggle?</li>
			</ol>
			<h1 id="_idParaDest-133"><a id="_idTextAnchor132"/>Further reading</h1>
			<p>To read more about the continuous integration topic, please refer to the following resources:</p>
			<ul>
				<li><em class="italic">Continuous Delivery</em>, <em class="italic">Jez Humble and David Farley</em>: <a href="https://continuousdelivery.com/">https://continuousdelivery.com/</a></li>
				<li><em class="italic">Continuous Integration: Improving Software Quality and Reducing Risk</em>, <em class="italic">Andrew Glover, Steve Matyas, and Paul M. Duvall</em>: <a href="https://www.oreilly.com/library/view/continuous-integration-improving/9780321336385/">https://www.oreilly.com/library/view/continuous-integration-improving/9780321336385/</a></li>
			</ul>
		</div>
	</body></html>