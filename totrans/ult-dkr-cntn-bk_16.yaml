- en: '16'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '16'
- en: Introducing Kubernetes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Kubernetes
- en: This chapter introduces the current most popular container orchestrator. It
    introduces the core Kubernetes objects that are used to define and run a distributed,
    resilient, robust, and highly available application in a cluster. Finally, it
    introduces minikube as a way to locally deploy a Kubernetes application and also
    the integration of Kubernetes with Docker Desktop.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍当前最流行的容器编排工具。它介绍了用于定义和运行分布式、弹性、稳健和高度可用应用程序的Kubernetes核心对象。最后，它介绍了minikube作为本地部署Kubernetes应用程序的一种方式，以及Kubernetes与Docker
    Desktop的集成。
- en: 'We will discuss the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论以下主题：
- en: Understanding Kubernetes architecture
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Kubernetes架构
- en: Kubernetes master nodes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes主节点
- en: Cluster nodes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群节点
- en: Introduction to Play with Kubernetes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Play with Kubernetes简介
- en: Kubernetes support in Docker Desktop
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes在Docker Desktop中的支持
- en: Introduction to pods
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod简介
- en: Kubernetes ReplicaSets
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes ReplicaSets
- en: Kubernetes Deployment
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes部署
- en: Kubernetes Service
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes服务
- en: Context-based routing
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于上下文的路由
- en: Comparing SwarmKit with Kubernetes
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较SwarmKit和Kubernetes
- en: 'After reading this chapter, you should have acquired the following skills:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完本章后，你应该掌握以下技能：
- en: Drafting the high-level architecture of a Kubernetes cluster on a napkin
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在餐巾纸上草拟Kubernetes集群的高级架构
- en: Explaining three to four main characteristics of a Kubernetes pod
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释Kubernetes Pod的三到四个主要特性
- en: Describing the role of Kubernetes ReplicaSets in two to three short sentences
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用两到三句话描述Kubernetes ReplicaSets的作用
- en: Explaining the two to three main responsibilities of a Kubernetes service
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释Kubernetes服务的两到三个主要职责
- en: Creating a pod in minikube
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在minikube中创建一个Pod
- en: Configuring Docker Desktop to use Kubernetes as an orchestrator
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置Docker Desktop以使用Kubernetes作为编排工具
- en: Creating a Deployment in Docker Desktop
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Docker Desktop中创建一个Deployment
- en: Creating a Kubernetes Service to expose an application service internally (or
    externally) to the cluster
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个Kubernetes服务来暴露应用程序服务（内部或外部）到集群中
- en: Technical requirements
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, if you want to follow along with the code, you need Docker
    Desktop and a code editor—preferably Visual Studio Code:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，如果你想跟随代码示例，你需要安装Docker Desktop和一个代码编辑器——最好是Visual Studio Code：
- en: 'Please navigate to the folder in which you have cloned the sample repository.
    Normally, this should be `~/The-Ultimate-Docker-Container-Book`:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请导航到你克隆示例代码库的文件夹。通常，这应该是`~/The-Ultimate-Docker-Container-Book`：
- en: '[PRE0]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create a new subfolder called `ch16` and navigate to it:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`ch16`的新子文件夹，并进入该文件夹：
- en: '[PRE1]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'A complete set of sample solutions to all the examples discussed in this chapter
    can be found in the `sample-solutions/ch16` folder or directly on GitHub: [https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch16](https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch16).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论的所有示例的完整解决方案可以在`sample-solutions/ch16`文件夹中找到，或者直接访问GitHub：[https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch16](https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch16)。
- en: Understanding Kubernetes architecture
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Kubernetes架构
- en: A Kubernetes cluster consists of a set of servers. These servers can be VMs
    or physical servers. The latter is also called bare metal. Each member of the
    cluster can have one of two roles. It is either a Kubernetes master or a (worker)
    node. The former is used to manage the cluster, while the latter will run an application
    workload. I have put worker in parentheses since, in Kubernetes parlance, you
    only talk about a node when you’re talking about a server that runs application
    workloads. But in Docker and Swarm parlance, the equivalent is a worker node.
    I think that the notion of a worker node better describes the role of the server
    than a simple node.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一个Kubernetes集群由一组服务器组成。这些服务器可以是虚拟机或物理服务器，后者也叫裸金属服务器。集群的每个成员都可以有两种角色之一。它要么是Kubernetes主节点，要么是（工作）节点。前者用于管理集群，而后者则运行应用程序工作负载。我将工作节点放在括号中，因为在Kubernetes术语中，只有在谈到运行应用程序工作负载的服务器时才会提到节点。但在Docker和Swarm的术语中，相当于工作节点。我认为“工作节点”这一概念更好地描述了服务器的角色，而不仅仅是一个简单的节点。
- en: In a cluster, you have a small and odd number of masters and as many worker
    nodes as needed. Small clusters might only have a few worker nodes, while more
    realistic clusters might have dozens or even hundreds of worker nodes. Technically,
    there is no limit to how many worker nodes a cluster can have. In reality, though,
    you might experience a significant slowdown in some management operations when
    dealing with thousands of nodes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个集群中，你有一个小且奇数数量的主节点，以及根据需要的多个工作节点。小型集群可能只有几个工作节点，而更现实的集群可能有几十个甚至上百个工作节点。从技术上讲，集群可以拥有的工作节点数量没有限制。然而，实际上，当处理成千上万个节点时，某些管理操作可能会出现显著的性能下降。
- en: On the Kubernetes worker nodes, we run pods. This is a new concept not present
    in Docker or Docker Swarm. A pod is an atomic unit of execution on a Kubernetes
    cluster. In many cases, a pod contains a single container, but a pod can consist
    of many containers running co-located. We will describe pods in much more detail
    later in this section.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 工作节点上，我们运行的是 Pods。这是一个在 Docker 或 Docker Swarm 中没有的概念。Pod 是 Kubernetes
    集群中的原子执行单元。在很多情况下，一个 Pod 只包含一个容器，但一个 Pod 也可以由多个容器共同运行。我们将在本节稍后对 Pods 进行更详细的描述。
- en: All members of the cluster need to be connected by a physical network, the so-called
    **underlay network**. Kubernetes defines one flat network for the whole cluster.
    Kubernetes does not provide any networking implementation out of the box. Instead,
    it relies on plugins from third parties.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 集群中的所有成员需要通过物理网络连接，所谓的**底层网络**。Kubernetes 为整个集群定义了一个平面网络。Kubernetes 本身并不提供任何网络实现，而是依赖于第三方的插件。
- en: Kubernetes just defines the **Container Network Interface** (**CNI**) and leaves
    the implementation to others. The CNI is pretty simple. It states that each pod
    running in the cluster must be able to reach any other pod also running in the
    cluster without any **Network Address Translation** (**NAT**) happening in between.
    The same must be true between cluster nodes and pods, that is, applications or
    daemons running directly on a cluster node must be able to reach each pod in the
    cluster and vice versa.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 只是定义了**容器网络接口**（**CNI**），并将实现留给其他人。CNI 非常简单。它规定，集群中运行的每个 Pod 必须能够与集群中任何其他
    Pod 相互连接，而不会发生任何**网络地址转换**（**NAT**）。同样的要求也适用于集群节点和 Pods 之间，即，直接在集群节点上运行的应用程序或守护进程必须能够访问集群中的每个
    Pod，反之亦然。
- en: 'The following diagram illustrates the high-level architecture of a Kubernetes
    cluster:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 Kubernetes 集群的高级架构：
- en: '![Figure 16.1 – High-level architecture diagram of Kubernetes](img/Figure_16.01_B19199.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.1 – Kubernetes 的高级架构图](img/Figure_16.01_B19199.jpg)'
- en: Figure 16.1 – High-level architecture diagram of Kubernetes
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.1 – Kubernetes 的高级架构图
- en: The preceding diagram is explained as follows.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 上图的解释如下：
- en: In the top box, in the middle, we have a cluster of `etcd` nodes. An `etcd`
    node is a distributed key-value store that, in a Kubernetes cluster, is used to
    store all the states of the cluster. The number of `etcd` nodes has to be odd,
    as mandated by the Raft consensus protocol, which states which nodes are used
    to coordinate among themselves. When we talk about the Cluster State, we do not
    include data that is produced or consumed by applications running in the cluster.
    Instead, we’re talking about all the information on the topology of the cluster,
    what services are running, network settings, secrets used, and more. That said,
    this `etcd` cluster is mission-critical to the overall cluster and thus, we should
    never run only a single `etcd` server in a production environment or any environment
    that needs to be highly available.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部框中间，我们有一个 `etcd` 节点集群。`etcd` 节点是一个分布式键值存储，在 Kubernetes 集群中用于存储集群的所有状态。`etcd`
    节点的数量必须是奇数，正如 Raft 一致性协议所要求的那样，该协议指定了哪些节点用于相互协调。我们谈论集群状态时，并不包括由运行在集群中的应用程序产生或消耗的数据。相反，我们指的是关于集群拓扑、运行的服务、网络设置、使用的密钥等所有信息。也就是说，这个
    `etcd` 集群对整个集群至关重要，因此，我们永远不应在生产环境或任何需要高可用性的环境中仅运行单个 `etcd` 服务器。
- en: Then, we have a cluster of Kubernetes master nodes, which also form a Consensus
    Group among themselves, similar to the `etcd` nodes. The number of master nodes
    also has to be odd. We can run clusters with a single master but we should never
    do that in a production or mission-critical system. There, we should always have
    at least three master nodes. Since the master nodes are used to manage the whole
    cluster, we are also talking about the management plane.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们有一个Kubernetes主节点集群，它们也在彼此之间形成一个共识组，类似于`etcd`节点。主节点的数量也必须是奇数。我们可以运行一个单主节点的集群，但在生产环境或关键任务系统中，我们绝不应该这样做。在这种情况下，我们应该始终至少有三个主节点。由于主节点用于管理整个集群，因此我们也在讨论管理平面。
- en: Master nodes use the `etcd` cluster as their backing store. It is good practice
    to put a **load balancer** (**LB**) in front of master nodes with a well-known
    **Fully Qualified Domain Name** (**FQDN**), such as [https://admin.example.com](https://admin.example.com).
    All tools that are used to manage the Kubernetes cluster should access it through
    this LB rather than using the public IP address of one of the master nodes. This
    is shown on the upper left side of the preceding diagram.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点使用`etcd`集群作为其后端存储。将**负载均衡器**（**LB**）放在主节点前面，并使用一个知名的**完全限定域名**（**FQDN**），如[https://admin.example.com](https://admin.example.com)，是一种良好的实践。所有用于管理Kubernetes集群的工具应该通过这个负载均衡器访问，而不是直接使用其中一个主节点的公共IP地址。这在前面图的左上方有展示。
- en: Toward the bottom of the diagram, we have a cluster of worker nodes. The number
    of nodes can be as low as one and does not have an upper limit.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在图的底部，我们有一个工作节点集群。节点的数量可以少到一个，并且没有上限。
- en: Kubernetes master and worker nodes communicate with each other. It is a bidirectional
    form of communication that is different from the one we know from Docker Swarm.
    In Docker Swarm, only manager nodes communicate with worker nodes and never the
    other way around. All ingress traffic accessing applications running in the cluster
    should go through another load balancer.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes主节点和工作节点彼此通信。这是一种双向通信方式，不同于我们在Docker Swarm中看到的那种通信方式。在Docker Swarm中，只有管理节点与工作节点通信，而不会有反向通信。所有访问集群中运行的应用程序的入口流量都应该通过另一个负载均衡器。
- en: This is the application load balancer or reverse proxy. We never want external
    traffic to directly access any of the worker nodes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是应用程序负载均衡器或反向代理。我们永远不希望外部流量直接访问任何工作节点。
- en: Now that we have an idea about the high-level architecture of a Kubernetes cluster,
    let’s delve a bit more deeply and look at the Kubernetes master and worker nodes.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对Kubernetes集群的高层架构有了一个大致的了解，让我们更深入地探讨Kubernetes主节点和工作节点。
- en: Kubernetes master nodes
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes主节点
- en: 'Kubernetes master nodes are used to manage a Kubernetes cluster. The following
    is a high-level diagram of such a master:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes主节点用于管理Kubernetes集群。以下是这样的主节点的高层次图示：
- en: '![Figure 16.2 – Kubernetes master](img/Figure_16.02_B19199.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图16.2 – Kubernetes主节点](img/Figure_16.02_B19199.jpg)'
- en: Figure 16.2 – Kubernetes master
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.2 – Kubernetes主节点
- en: At the bottom of the preceding diagram, we have the infrastructure, which can
    be a VM on-premises or in the cloud or a server (often called bare metal) on-premises
    or in the cloud.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图的底部，我们有基础设施，它可以是本地或云端的虚拟机，或者本地或云端的服务器（通常称为裸金属）。
- en: 'Currently, Kubernetes masters only run on Linux. The most popular Linux distributions,
    such as RHEL, CentOS, and Ubuntu, are supported. On this Linux machine, we have
    at least the following four Kubernetes services running:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Kubernetes主节点仅在Linux上运行。支持最流行的Linux发行版，如RHEL、CentOS和Ubuntu。在这台Linux机器上，我们至少有以下四个Kubernetes服务在运行：
- en: '`kubectl` use to manage the cluster and applications in the cluster.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl`用于管理集群和集群中的应用程序。'
- en: '**Controller**: The controller, or more precisely the controller manager, is
    a control loop that observes the state of the cluster through the API server and
    makes changes, attempting to move the current or effective state toward the desired
    state if they differ.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制器**：控制器，或者更准确地说是控制器管理器，是一个控制循环，它通过API服务器观察集群的状态并进行更改，尝试将当前状态或有效状态调整为所需状态，如果它们不同的话。'
- en: '**Scheduler**: The scheduler is a service that tries its best to schedule pods
    on worker nodes while considering various boundary conditions, such as resource
    requirements, policies, quality-of-service requirements, and more.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调度器**：调度器是一项服务，它尽力在工作节点上调度Pods，同时考虑各种边界条件，如资源需求、策略、服务质量要求等。'
- en: '`etcd` that is used to store all information about the state of the cluster.
    To be more precise, `etcd`, which is used as a cluster store, does not necessarily
    have to be installed on the same node as the other Kubernetes services. Sometimes,
    Kubernetes clusters are configured to use standalone clusters of `etcd` servers,
    as shown in *Figure 16**.1*. But which variant to use is an advanced management
    decision and is outside the scope of this book.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于存储集群状态所有信息的`etcd`。更准确地说，作为集群存储的`etcd`不一定需要与其他Kubernetes服务安装在同一个节点上。有时，Kubernetes集群配置为使用独立的`etcd`服务器集群，如*图16.1*所示。但选择使用哪种变体是一个高级管理决策，超出了本书的范围。
- en: We need at least one master, but to achieve high availability, we need three
    or more master nodes. This is very similar to what we have learned about the manager
    nodes of a Docker Swarm. In this regard, a Kubernetes master is equivalent to
    a Swarm manager node.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们至少需要一个主节点，但为了实现高可用性，我们需要三个或更多主节点。这与我们在学习Docker Swarm的管理节点时学到的非常相似。在这方面，Kubernetes主节点相当于Swarm管理节点。
- en: Kubernetes masters never run application workloads. Their sole purpose is to
    manage the cluster. Kubernetes masters build a Raft consensus group. The Raft
    protocol is a standard protocol used in situations where a group of members needs
    to make decisions. It is used in many well-known software products such as MongoDB,
    Docker SwarmKit, and Kubernetes. For a more thorough discussion of the Raft protocol,
    see the link in the *Further* *reading* section.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes主节点从不运行应用工作负载。它们的唯一目的是管理集群。Kubernetes主节点构建了一个Raft共识组。Raft协议是一种标准协议，通常用于一组成员需要做出决策的场景。它被许多知名的软件产品所使用，如MongoDB、Docker
    SwarmKit和Kubernetes。有关Raft协议的更详细讨论，请参见*进一步阅读*部分中的链接。
- en: Running workload on master
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在主节点上运行工作负载
- en: At times, specifically in development and test scenarios, it can make sense
    to work with a single-node Kubernetes cluster, which then naturally becomes a
    master and a worker node at the same time. But this scenario should be avoided
    in production.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，特别是在开发和测试场景中，使用单节点Kubernetes集群是有意义的，这样它自然就成了主节点和工作节点。但这种场景应该避免在生产环境中使用。
- en: As we mentioned in the previous section, the state of the Kubernetes cluster
    is stored in an `etcd` node. If the Kubernetes cluster is supposed to be highly
    available, then the `etcd` node must also be configured in HA mode, which normally
    means that we have at least three `etcd` instances running on different nodes.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Kubernetes集群的状态存储在`etcd`节点中。如果Kubernetes集群需要高可用性，则`etcd`节点也必须配置为HA模式，通常意味着我们至少在不同的节点上运行三个`etcd`实例。
- en: Let’s state once again that the whole cluster state is stored in an `etcd` node.
    This includes all the information about all the cluster nodes, all the ReplicaSets,
    Deployments, secrets, network policies, routing information, and so on. It is
    therefore crucial that we have a robust backup strategy in place for this key-value
    store.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再一次声明，整个集群状态存储在`etcd`节点中。这包括所有关于集群节点的信息、所有ReplicaSets、Deployments、Secrets、网络策略、路由信息等。因此，拥有一个强大的备份策略来保护这个键值存储至关重要。
- en: Now, let’s look at the nodes that will be running the actual workload of the
    cluster.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看将实际运行集群工作负载的节点。
- en: Cluster nodes
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群节点
- en: 'Cluster nodes are the nodes with which Kubernetes schedules application workloads.
    They are the workhorses of the cluster. A Kubernetes cluster can have a few, dozens,
    hundreds, or even thousands of cluster nodes. Kubernetes has been built from the
    ground up for high scalability. Don’t forget that Kubernetes was modeled on Google
    Borg, which has run tens of thousands of containers for years:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 集群节点是Kubernetes调度应用工作负载的节点。它们是集群的工作马。一个Kubernetes集群可以有几个、几十个、几百个，甚至几千个集群节点。Kubernetes从一开始就为高扩展性而构建。别忘了，Kubernetes是以Google
    Borg为模型构建的，后者已经运行了数万个容器多年：
- en: '![Figure 16.3 – Kubernetes worker node](img/Figure_16.03_B19199.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图16.3 – Kubernetes工作节点](img/Figure_16.03_B19199.jpg)'
- en: Figure 16.3 – Kubernetes worker node
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.3 – Kubernetes工作节点
- en: A worker node – which is a cluster node, as are the master nodes – can run on
    a VM, bare metal, on-premises, or in the cloud. Originally, worker nodes could
    only be configured on Linux. But since version 1.10 of Kubernetes, worker nodes
    can also run on Windows Server 2010 or later. It is perfectly fine to have a mixed
    cluster with Linux and Windows worker nodes.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点——它是集群节点，就像主节点一样——可以在虚拟机、裸金属、内部部署或云中运行。最初，工作节点只能配置在 Linux 上。但自 Kubernetes
    1.10 版本以来，工作节点也可以在 Windows Server 2010 或更高版本上运行。拥有包含 Linux 和 Windows 工作节点的混合集群是完全可以接受的。
- en: 'On each node, we have three services that need to run, as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个节点上，我们需要运行以下三项服务：
- en: '`YAML` or `JSON` format and they declaratively describe a pod. We will get
    to know what pods are in the next section. `PodSpecs` is provided to Kubelet primarily
    through the API server.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`YAML` 或 `JSON` 格式，它们声明性地描述了一个 Pod。我们将在下一部分了解 Pod 是什么。`PodSpecs` 主要通过 API 服务器提供给
    Kubelet。'
- en: '`containerd` since version 1.9 as its container runtime. Prior to that, it
    used the Docker daemon. Other container runtimes, such as `rkt` or `CRI-O`, can
    be used. The container runtime is responsible for managing and running the individual
    containers of a pod.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从版本 1.9 起，`containerd` 被用作容器运行时。在此之前，它使用的是 Docker 守护进程。还可以使用其他容器运行时，如 `rkt`
    或 `CRI-O`。容器运行时负责管理和运行 Pod 中的各个容器。
- en: '**kube-proxy**: Finally, there is kube-proxy. It runs as a daemon and is a
    simple network proxy and load balancer for all application services running on
    that particular node.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kube-proxy**：最后是 kube-proxy。它作为一个守护进程运行，是一个简单的网络代理和负载均衡器，用于所有在该节点上运行的应用服务。'
- en: Now that we have learned about the architecture of Kubernetes and the master
    and worker nodes, it is time to introduce the tooling that we can use to develop
    applications targeted at Kubernetes.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 Kubernetes 的架构以及主节点和工作节点，接下来是介绍我们可以用来开发针对 Kubernetes 应用的工具。
- en: Introduction to Play with Kubernetes
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Play with Kubernetes 介绍
- en: 'Play with Kubernetes is a free playground sponsored by Docker, where users
    can learn how to use Docker containers and deploy them to Kubernetes:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Play with Kubernetes 是一个由 Docker 赞助的免费沙盒，用户可以在其中学习如何使用 Docker 容器并将其部署到 Kubernetes：
- en: Navigate to [https://labs.play-with-k8s.com/](https://labs.play-with-k8s.com/).
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 [https://labs.play-with-k8s.com/](https://labs.play-with-k8s.com/)。
- en: Log in using your GitHub or Docker credentials.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您的 GitHub 或 Docker 凭据登录。
- en: Once successfully logged in, create a first cluster node or instance by clicking
    the **+ ADD NEW INSTANCE** button on the left side of the screen.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 成功登录后，通过点击屏幕左侧的**+ 添加新实例**按钮，创建第一个集群节点或实例。
- en: Follow the instructions on the screen to create a first master node for your
    Kubernetes sandbox cluster.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照屏幕上的指示创建您的 Kubernetes 沙盒集群的第一个主节点。
- en: 'Initialize the cluster master node with the command as indicated in *step 1*
    of the instructions in the terminal window. It’s best if you directly copy the
    command from there. It should look like this:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用终端窗口中*步骤 1*中指示的命令初始化集群主节点。最好直接从那里复制命令。命令应如下所示：
- en: '[PRE2]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The first command argument uses the name of the host to advertise the address
    of the Kubernetes API server and the second one defines the subnet the cluster
    is supposed to use.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令参数使用主机名称来广告 Kubernetes API 服务器的地址，第二个命令定义了集群应使用的子网。
- en: 'Next, as indicated in Point 2 of the instructions in the console, initialize
    networking in our Kubernetes cluster (note, the following command should be on
    a single line):'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，如控制台中的步骤 2 所示，在我们的 Kubernetes 集群中初始化网络（注意，以下命令应为单行）：
- en: '[PRE3]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Create a second cluster node by again clicking the **ADD NEW** **INSTANCE**
    button.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过再次点击**添加新实例**按钮，创建第二个集群节点。
- en: 'Once the node is ready, run the `join` command that was output during *step
    4*, where `<token-1>` and `<token-2>` are specific to your cluster:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦节点准备就绪，运行在*步骤 4*中输出的`join`命令，其中 `<token-1>` 和 `<token-2>` 是特定于您集群的：
- en: '[PRE4]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: It is best if you just copy the correct command from your command line in Play
    with Kubernetes.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 最好直接从 Play with Kubernetes 中的命令行复制正确的命令。
- en: 'Once the second node has joined the cluster, run the following command on the
    first node, where you initialized the cluster, to list the set of nodes in your
    new cluster:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦第二个节点加入集群，请在第一个节点上运行以下命令，该节点是您初始化集群的地方，用于列出新集群中的节点集合：
- en: '[PRE5]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output should look similar to this:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该类似于以下内容：
- en: '[PRE6]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note how Play with Kubernetes, at the time of writing, uses version 1.20.1 of
    Kubernetes, which even now is a rather old version. The latest stable version
    available is currently 1.27.x. But worry not; for our example version, 1.20.x,
    is enough.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，撰写本文时，Play with Kubernetes 使用的是 Kubernetes 1.20.1 版本，这个版本现在已经比较旧了。目前可用的最新稳定版本是
    1.27.x。但不用担心，我们示例使用的 1.20.x 版本已经足够。
- en: Now let’s try to deploy a pod to this cluster. Don’t worry about what a *pod*
    is for now; we will delve into all the details about it later in this chapter.
    For the moment, just take it as is.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试在这个集群上部署一个 pod。暂时不用担心 *pod* 是什么，我们将在本章后面详细讲解。此时，只需要按现状理解即可。
- en: 'In your chapter code folder, create a new file called `sample-pod.yaml` and
    add the following content:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的章节代码文件夹中，创建一个名为 `sample-pod.yaml` 的新文件，并添加以下内容：
- en: '[PRE7]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, to run the aforementioned pod on Play with Kubernetes, we need to copy
    the content of the preceding `yaml` file and create a new file on `node1` of our
    cluster:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，为了在 Play with Kubernetes 上运行前述的 pod，我们需要复制前面的 `yaml` 文件内容，并在我们集群的 `node1`
    上创建一个新文件：
- en: Use `vi` to create a new file called `sample-pod.yaml`.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `vi` 创建一个名为 `sample-pod.yaml` 的新文件。
- en: Hit *I* (the letter “i”) to switch into the insert mode of `vi`.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按下 *I*（字母 “i”）进入 `vi` 编辑器的插入模式。
- en: Paste the copied code snippet with *Ctrl* + *V* (or *Command* + *V* on a Mac)
    into this file.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将复制的代码片段用 *Ctrl* + *V*（或在 Mac 上使用 *Command* + *V*）粘贴到此文件中。
- en: Press *Esc* to go into the command mode of `vi`.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按下 *Esc* 键进入 `vi` 的命令模式。
- en: Input `:wq` and hit *Enter* to save the file and quit `vi`.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入 `:wq` 并按 *Enter* 键保存文件并退出 `vi`。
- en: Tip
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: 'Why are we using the Vi editor in our examples? It’s the editor that is installed
    on any Linux (or Unix) distribution and is thus always available. You can find
    a quick tutorial for the Vi editor here: [https://www.tutorialspoint.com/unix/unix-vi-editor.htm](https://www.tutorialspoint.com/unix/unix-vi-editor.htm).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么在示例中使用 Vi 编辑器？它是任何 Linux（或 Unix）发行版中都已安装的编辑器，因此始终可用。你可以在这里找到 Vi 编辑器的快速教程：[https://www.tutorialspoint.com/unix/unix-vi-editor.htm](https://www.tutorialspoint.com/unix/unix-vi-editor.htm)。
- en: 'Now let’s use the Kubernetes CLI called `kubectl` to deploy this pod. The `kubectl`
    CLI is already installed on each of the cluster nodes of your Play with Kubernetes
    cluster:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们使用名为 `kubectl` 的 Kubernetes CLI 来部署这个 pod。`kubectl` CLI 已经安装在你 Play with
    Kubernetes 集群的每个节点上：
- en: '[PRE8]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Doing so results in this output:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做会产生以下输出：
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now we list all of the pods:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在列出所有的 pods：
- en: '[PRE10]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We should see the following:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该看到以下内容：
- en: '[PRE11]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To be able to access this pod, we need to create a Service. Let’s use the `sample-service.yaml`
    file, which has the following content:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了能够访问这个 pod，我们需要创建一个 Service。让我们使用 `sample-service.yaml` 文件，其中包含以下内容：
- en: '[PRE12]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Again, don’t worry about what exactly a *Service* is at this time. We’ll explain
    this later.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，不必担心此时*Service*究竟是什么，我们稍后会解释。
- en: 'Let’s just create this Service:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建这个 Service：
- en: '[PRE13]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now let’s see what Kubernetes created and list all Services defined on the
    cluster:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们看看 Kubernetes 创建了什么，并列出集群上定义的所有服务：
- en: '[PRE14]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We should see something similar to this:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该看到类似这样的内容：
- en: '![Figure 16.4 – List of services](img/Figure_16.04_B19199.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.4 – 服务列表](img/Figure_16.04_B19199.jpg)'
- en: Figure 16.4 – List of services
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.4 – 服务列表
- en: Please note the `PORT(S)` column. In my case, Kubernetes mapped the `80` container
    port of Nginx to the `31384` node port. We will use this port in the next command.
    Make sure you use the port number assigned on your system instead!
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意 `PORT(S)` 列。在我的情况下，Kubernetes 将 Nginx 的 `80` 容器端口映射到 `31384` 节点端口。我们将在下一条命令中使用这个端口。确保你使用的是系统上分配的端口号！
- en: 'Now, we can use `curl` to access the service:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 `curl` 访问该服务：
- en: '[PRE15]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We should receive the Nginx welcome page as an answer.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到 Nginx 欢迎页面作为回应。
- en: 'Before you continue, please remove the two objects you just created:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在继续之前，请删除你刚才创建的两个对象：
- en: '[PRE16]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note that in the aforementioned commands, the `po` shortcut is equivalent to
    `pod` or `pods`. The `kubectl` tool is very flexible and allows such abbreviations.
    Similarly, `svc` is a shortcut for `service` or `services`.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在前述命令中，`po` 快捷方式相当于 `pod` 或 `pods`。`kubectl` 工具非常灵活，允许使用这样的缩写。同样，`svc` 是
    `service` 或 `services` 的缩写。
- en: In the next section, we are going to use Docker Desktop and its support for
    Kubernetes to run the same pod and service as we did in this section.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将使用 Docker Desktop 及其对 Kubernetes 的支持，运行与本部分相同的 pod 和服务。
- en: Kubernetes support in Docker Desktop
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker Desktop 中的 Kubernetes 支持
- en: 'Starting from version 18.01-ce, Docker Desktop started to support Kubernetes
    out of the box. Developers who want to deploy their containerized applications
    to Kubernetes can use this orchestrator instead of SwarmKit. Kubernetes support
    is turned off by default and has to be enabled in the settings. The first time
    Kubernetes is enabled, Docker Desktop will need a moment to download all the components
    that are needed to create a single-node Kubernetes cluster. Contrary to minikube,
    which is also a single-node cluster, the version provided by the Docker tools
    uses **containerized** versions of all Kubernetes components:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 从 18.01-ce 版本开始，Docker Desktop 开始支持开箱即用的 Kubernetes。开发人员如果希望将容器化应用程序部署到 Kubernetes
    中，可以使用这个编排工具，而不是 SwarmKit。Kubernetes 支持默认是关闭的，需要在设置中启用。第一次启用 Kubernetes 时，Docker
    Desktop 需要一些时间来下载创建单节点 Kubernetes 集群所需的所有组件。与 minikube（它也是单节点集群）不同，Docker 工具提供的版本使用了所有
    Kubernetes 组件的**容器化**版本：
- en: '![Figure 16.5 – Kubernetes support in Docker Desktop](img/Figure_16.05_B19199.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.5 – Docker Desktop 中的 Kubernetes 支持](img/Figure_16.05_B19199.jpg)'
- en: Figure 16.5 – Kubernetes support in Docker Desktop
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.5 – Docker Desktop 中的 Kubernetes 支持
- en: 'The preceding diagram gives us a rough overview of how Kubernetes support has
    been added to Docker Desktop. Docker Desktop for macOS uses hyperkit to run a
    LinuxKit-based VM. Docker Desktop for Windows uses Hyper-V to achieve the result.
    Inside the VM, Docker Engine is installed. Part of the engine is SwarmKit, which
    enables Swarm mode. Docker Desktop uses the `kubeadm` tool to set up and configure
    Kubernetes in that VM. The following three facts are worth mentioning: Kubernetes
    stores its cluster state in `etcd`; thus, we have `etcd` running on this VM. Then,
    we have all the services that make up Kubernetes and, finally, some services that
    support the Deployment of Docker stacks from the Docker CLI into Kubernetes. This
    Service is not part of the official Kubernetes distribution, but it is Docker-specific.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表大致展示了 Kubernetes 支持是如何被添加到 Docker Desktop 中的。macOS 上的 Docker Desktop 使用
    hyperkit 来运行基于 LinuxKit 的虚拟机。Windows 上的 Docker Desktop 使用 Hyper-V 来实现这一结果。在虚拟机内部，安装了
    Docker 引擎。引擎的一部分是 SwarmKit，它启用了 Swarm 模式。Docker Desktop 使用 `kubeadm` 工具在虚拟机中设置和配置
    Kubernetes。以下三个事实值得一提：Kubernetes 将其集群状态存储在 `etcd` 中；因此，我们在这个虚拟机上运行了 `etcd`。接着，我们有构成
    Kubernetes 的所有服务，最后，还有一些支持从 Docker CLI 部署 Docker 堆栈到 Kubernetes 的服务。这个服务不是 Kubernetes
    官方发行版的一部分，但它是特定于 Docker 的。
- en: All Kubernetes components run in containers in the LinuxKit VM. These containers
    can be hidden through a setting in Docker Desktop. Later in this section, we’ll
    provide a complete list of Kubernetes system containers that will be running on
    your laptop, if you have Kubernetes support enabled.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 Kubernetes 组件都在 LinuxKit 虚拟机中的容器中运行。这些容器可以通过 Docker Desktop 中的设置进行隐藏。稍后我们将在本节中提供一份完整的
    Kubernetes 系统容器列表，前提是你已启用 Kubernetes 支持。
- en: One big advantage of Docker Desktop with Kubernetes enabled over minikube is
    that the former allows developers to use a single tool to build, test, and run
    a containerized application targeted at Kubernetes. It is even possible to deploy
    a multi-service application into Kubernetes using a Docker Compose file.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 启用 Kubernetes 的 Docker Desktop 相对于 minikube 的一个大优势是，前者允许开发人员使用单一工具构建、测试和运行面向
    Kubernetes 的容器化应用程序。甚至可以使用 Docker Compose 文件将多服务应用部署到 Kubernetes 中。
- en: 'Now let’s get our hands dirty:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们动手操作：
- en: 'First, we have to enable Kubernetes. On macOS, click on the Docker icon in
    the menu bar. On Windows, go to the command tray and select **Preferences**. In
    the dialog box that opens, select **Kubernetes**, as shown in the following screenshot:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要启用 Kubernetes。在 macOS 上，点击菜单栏中的 Docker 图标。在 Windows 上，前往任务栏并选择**首选项**。在弹出的对话框中，选择**Kubernetes**，如以下截图所示：
- en: '![Figure 16.6 – Enabling Kubernetes in Docker Desktop](img/Figure_16.06_B19199.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.6 – 在 Docker Desktop 中启用 Kubernetes](img/Figure_16.06_B19199.jpg)'
- en: Figure 16.6 – Enabling Kubernetes in Docker Desktop
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.6 – 在 Docker Desktop 中启用 Kubernetes
- en: Then, tick the **Enable Kubernetes** checkbox. Also, tick the **Show system
    containers (****advanced)** checkboxes.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，勾选**启用 Kubernetes**复选框。还需要勾选**显示系统容器（**高级）**复选框。
- en: Then, click the **Apply & restart** button. Installing and configuring Kubernetes
    takes a few minutes. It’s time to take a break and enjoy a nice cup of tea.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，点击**应用并重启**按钮。安装和配置 Kubernetes 需要几分钟时间。是时候休息一下，享受一杯好茶了。
- en: Once the installation is finished (which Docker notifies us of by showing a
    green status icon in the `kubectl` to access the latter.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完成后（Docker 会通过在 `kubectl` 中显示绿色状态图标来通知我们），以便访问后者。
- en: 'First, let’s list all the contexts that we have. We can use the following command
    for this:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们列出我们拥有的所有上下文。我们可以使用以下命令来完成：
- en: '[PRE17]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In the case of the author’s laptop, we get this output:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在作者的笔记本电脑上，我们得到以下输出：
- en: '![Figure 16.7 – List of contexts for kubectl](img/Figure_16.07_B19199.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图16.7 - kubectl的上下文列表](img/Figure_16.07_B19199.jpg)'
- en: Figure 16.7 – List of contexts for kubectl
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.7 - kubectl的上下文列表
- en: Here, we can see that, on the author’s laptop, we have three contexts, two of
    them stemming from his use of `kind`. Currently, the `kind` context with the `kind-demo`
    name is still active, flagged by the asterisk in the `CURRENT` column.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，在作者的笔记本电脑上，我们有三个上下文，其中两个来自于他使用`kind`。目前，名为`kind-demo`的`kind`上下文仍然处于活动状态，通过`CURRENT`列中的星号标记。
- en: 'We can switch to the `docker-desktop` context using the following command:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令切换到`docker-desktop`上下文：
- en: '[PRE18]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Doing so results in this ouput:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此操作后，会得到以下输出：
- en: '[PRE19]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now we can use `kubectl` to access the cluster that Docker Desktop just created:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用`kubectl`访问Docker Desktop刚创建的集群：
- en: '[PRE20]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We should see something simliar to the following:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该看到类似以下的内容：
- en: '[PRE21]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: OK, this looks very familiar. It is pretty much the same as what we saw when
    working with Play with Kubernetes. The version of Kubernetes that the author’s
    Docker Desktop is using is 1.25.9\. We can also see that the node is a `master`
    node, indicated by the role `control-plane`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这看起来很熟悉。它与我们在使用Play with Kubernetes时看到的几乎相同。作者的Docker Desktop使用的Kubernetes版本是1.25.9。我们还可以看到节点是一个`master`节点，由`control-plane`角色指示。
- en: 'If we list all the containers that are currently running on our Docker Desktop,
    we get the list shown in the following screenshot (note that we use the `--format`
    argument to output the container ID and names of the containers):'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们列出当前在Docker Desktop上运行的所有容器，我们会得到以下截图所示的列表（注意，我们使用了`--format`参数来输出容器ID和容器名称）：
- en: '[PRE22]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This will result in the following output:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '![Figure 16.8 – List of Kubernetes system containers](img/Figure_16.08_B19199.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图16.8 - Kubernetes系统容器列表](img/Figure_16.08_B19199.jpg)'
- en: Figure 16.8 – List of Kubernetes system containers
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.8 - Kubernetes系统容器列表
- en: 'In the preceding list, we can identify all the now-familiar components that
    make up Kubernetes, as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的列表中，我们可以识别出所有组成Kubernetes的现在熟悉的组件，如下所示：
- en: API server
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API服务器
- en: '`etcd`'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`etcd`'
- en: '`kube-proxy`'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-proxy`'
- en: DNS service
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DNS服务
- en: '`kube-controller`'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-controller`'
- en: '`kube-scheduler`'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-scheduler`'
- en: Normally, we don’t want to clutter our list of containers with these system
    containers. Therefore, we can uncheck the **Show system containers (advanced)**
    checkbox in the settings for Kubernetes.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们不希望将这些系统容器混入我们的容器列表中。因此，我们可以在Kubernetes的设置中取消选中**显示系统容器（高级）**复选框。
- en: Now let’s try to deploy a Docker Compose application to Kubernetes.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试将Docker Compose应用程序部署到Kubernetes。
- en: Navigate to the `ch16` subfolder of our `~/``The-Ultimate-Docker-Container-Book`
    folder.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入我们`~/``The-Ultimate-Docker-Container-Book`文件夹的`ch16`子文件夹。
- en: 'Copy the `docker-compose.yml` file from the sample solutions to this location:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`docker-compose.yml`文件从示例解决方案复制到此位置：
- en: '[PRE23]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Install the `kompose` tool on your machine by following the instructions on
    https://kompose.io/installation/:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照https://kompose.io/installation/上的说明，在你的机器上安装`kompose`工具：
- en: On a Mac, it can be installed using `$ brew` `install kompose`
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Mac上，可以通过`$ brew` `install kompose`安装
- en: On Windows, use `$ choco` `install kubernetes-kompose`
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Windows上，使用`$ choco` `install kubernetes-kompose`
- en: 'Run the `kompose` tool as follows:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式运行`kompose`工具：
- en: '[PRE24]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The tool should create four files:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具应该创建四个文件：
- en: '`db-deployment.yaml`'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`db-deployment.yaml`'
- en: '`pets-data-persistentvolumeclaim.yaml`'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pets-data-persistentvolumeclaim.yaml`'
- en: '`web-deployment.yaml`'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`web-deployment.yaml`'
- en: '`web-service.yaml`'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`web-service.yaml`'
- en: 'Open the `web-service.yaml` file and after line 11 (the `spec` entry), add
    the `NodePort` entry type so that it looks as follows:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`web-service.yaml`文件，在第11行（`spec`条目）后，添加`NodePort`条目类型，使其如下所示：
- en: '[PRE25]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now we can use `kubectl` to deploy these four resources to our Kubernetes cluster:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用`kubectl`将这四个资源部署到我们的Kubernetes集群：
- en: '[PRE26]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We should see this:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该看到这个：
- en: '[PRE27]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We need to find out to which host port Kubernetes has mapped the `3000` service
    port. Use the following command for this:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要找出Kubernetes将`3000`服务端口映射到哪个主机端口。使用以下命令来实现：
- en: '[PRE28]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You should see something similar to this:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到类似以下内容：
- en: '[PRE29]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In my case, we can see that the service web has the `3000` port mapped to the
    `32134` host (or node) port. In the following command, I have to use that port.
    In your case, the number likely will be different. Use the number you are getting
    from the previous command!
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的例子中，我们可以看到服务 web 将 `3000` 端口映射到 `32134` 主机（或节点）端口。在下面的命令中，我必须使用这个端口。在你的情况下，端口号可能会不同。使用你从上一条命令中得到的数字！
- en: 'We can test the application using `curl`:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用 `curl` 测试应用程序：
- en: '[PRE30]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We will see that it is running as expected:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到它按预期运行：
- en: '![Figure 16.9 – Pets application running in Kubernetes on Docker Desktop](img/Figure_16.09_B19199.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.9 – 宠物应用程序在 Docker Desktop 上的 Kubernetes 环境中运行](img/Figure_16.09_B19199.jpg)'
- en: Figure 16.9 – Pets application running in Kubernetes on Docker Desktop
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.9 – 宠物应用程序在 Docker Desktop 上的 Kubernetes 环境中运行
- en: Now, let’s see exactly what resources we have on Kubernetes after the previous
    Deployment.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看在前面的部署之后，Kubernetes 上到底有哪些资源。
- en: 'We can use `kubectl` to find out:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用 `kubectl` 来查看：
- en: '[PRE31]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This gives us this output:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们带来了以下输出：
- en: '![Figure 16.10 – Listing all Kubernetes objects created by Docker stack deploy](img/Figure_16.10_B19199.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.10 – 列出 Docker stack deploy 创建的所有 Kubernetes 对象](img/Figure_16.10_B19199.jpg)'
- en: Figure 16.10 – Listing all Kubernetes objects created by Docker stack deploy
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.10 – 列出 Docker stack deploy 创建的所有 Kubernetes 对象
- en: Docker created a Deployment for the `web` service and `db` service. It also
    automatically created a Kubernetes service for `web` so that it can be accessed
    inside the cluster.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 为 `web` 服务和 `db` 服务创建了一个 Deployment。它还自动为 `web` 创建了一个 Kubernetes 服务，以便在集群内访问。
- en: This is pretty cool, to say the least, and tremendously decreases friction in
    the development process for teams targeting Kubernetes as their orchestration
    platform.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以说相当酷，极大地减少了面向 Kubernetes 作为编排平台的团队在开发过程中遇到的摩擦。
- en: 'Before you continue, please remove the stack from the cluster:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在继续之前，请从集群中删除该堆栈：
- en: '[PRE32]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Now that we have had an introduction to the tools we can use to develop applications
    that will eventually run in a Kubernetes cluster, it is time to learn about all
    the important Kubernetes objects that are used to define and manage such an application.
    We will start with pods.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经了解了可以用来开发最终将在 Kubernetes 集群中运行的应用程序的工具，接下来是时候了解所有重要的 Kubernetes 对象，这些对象用于定义和管理这样的应用程序。我们将从
    pod 开始。
- en: Introduction to pods
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pod 介绍
- en: 'Contrary to what is possible in Docker Swarm, you cannot run containers directly
    in a Kubernetes cluster. In a Kubernetes cluster, you can only run pods. **Pods**
    are the atomic units of Deployment in Kubernetes. A pod is an abstraction of one
    or many co-located containers that share the same kernel namespaces, such as the
    network namespace. No equivalent exists in Docker SwarmKit. The fact that more
    than one container can be co-located and shared with the same network namespace
    is a very powerful concept. The following diagram illustrates two pods:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Docker Swarm 中的可能性相反，你不能直接在 Kubernetes 集群中运行容器。在 Kubernetes 集群中，你只能运行 pod。**Pod**
    是 Kubernetes 中 Deployment 的基本单元。一个 pod 是一个或多个共址容器的抽象，这些容器共享相同的内核命名空间，例如网络命名空间。Docker
    SwarmKit 中没有类似的概念。多个容器可以共址并共享相同的网络命名空间是一个非常强大的概念。下图展示了两个 pod：
- en: '![Figure 16.11 – Kubernetes pods](img/Figure_16.11_B19199.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.11 – Kubernetes pods](img/Figure_16.11_B19199.jpg)'
- en: Figure 16.11 – Kubernetes pods
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.11 – Kubernetes pods
- en: In the preceding diagram, we have two pods, `10.0.12.3` and `10.0.12.5`. Both
    are part of a private subnet managed by the Kubernetes network driver.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图示中，我们有两个 pod，`10.0.12.3` 和 `10.0.12.5`。这两个 pod 都是由 Kubernetes 网络驱动管理的私有子网的一部分。
- en: A pod can contain one or many containers. All those containers share the same
    Linux kernel namespaces, and in particular, they share the network namespace.
    This is indicated by the dashed rectangle surrounding the containers. Since all
    containers running in the same pod share the network namespace, each container
    needs to make sure to use its own port since duplicate ports are not allowed in
    a single network namespace. In this case, in Pod 1, the main container is using
    the `80` port while the supporting container is using the `3000` port.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 pod 可以包含一个或多个容器。所有这些容器共享相同的 Linux 内核命名空间，特别是它们共享网络命名空间。这一点通过围绕容器的虚线矩形表示。由于在同一个
    pod 中运行的所有容器共享网络命名空间，每个容器需要确保使用自己的端口，因为在一个网络命名空间中不允许重复端口。在这种情况下，在 Pod 1 中，主容器使用的是
    `80` 端口，而辅助容器使用的是 `3000` 端口。
- en: Requests from other pods or nodes can use the pod’s IP address combined with
    the corresponding port number to access the individual containers. For example,
    you could access the application running in the main container of Pod 1 through
    `10.0.12.3:80`.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 来自其他 Pod 或节点的请求可以使用 Pod 的 IP 地址结合相应的端口号来访问单个容器。例如，你可以通过 `10.0.12.3:80` 访问运行在
    Pod 1 主容器中的应用程序。
- en: Comparing Docker container and Kubernetes pod networking
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较 Docker 容器和 Kubernetes Pod 网络
- en: 'Now, let’s compare Docker’s container networking and Kubernetes pod networking.
    In the following diagram, we have Docker on the left-hand side and Kubernetes
    on the right-hand side:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们比较 Docker 的容器网络与 Kubernetes 的 Pod 网络。在下面的图示中，左边是 Docker，右边是 Kubernetes：
- en: '![Figure 16.12 – Containers in a pod sharing the same network namespace](img/Figure_16.12_B19199.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.12 – Pod 中共享同一网络命名空间的容器](img/Figure_16.12_B19199.jpg)'
- en: Figure 16.12 – Containers in a pod sharing the same network namespace
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.12 – Pod 中共享同一网络命名空间的容器
- en: When a Docker container is created and no specific network is specified, then
    Docker Engine creates a virtual ethernet (`veth`) endpoint. The first container
    gets `veth0`, the next one gets `veth1`, and so on. These virtual ethernet endpoints
    are connected to the Linux bridge, `docker0`, that Docker automatically creates
    upon installation. Traffic is routed from the `docker0` bridge to every connected
    `veth` endpoint. Every container has its own network namespace. No two containers
    use the same namespace. This is on purpose, to isolate applications running inside
    the containers from each other.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建 Docker 容器且未指定特定网络时，Docker Engine 会创建一个虚拟以太网（`veth`）端点。第一个容器获得 `veth0`，下一个获得
    `veth1`，以此类推。这些虚拟以太网端点连接到 Docker 在安装时自动创建的 Linux 桥接器 `docker0`。流量从 `docker0` 桥接器路由到每个连接的
    `veth` 端点。每个容器都有自己的网络命名空间。没有两个容器使用相同的命名空间。这是故意的，目的是将容器内运行的应用程序彼此隔离。
- en: 'For a Kubernetes pod, the situation is different. When creating a new pod,
    Kubernetes first creates a so-called `pause` container, the purpose of which is
    to create and manage the namespaces that the pod will share with all containers.
    Other than that, it does nothing useful; it is just sleeping. The `pause` container
    is connected to the `docker0` bridge through `veth0`. Any subsequent container
    that will be part of the pod uses a special feature of Docker Engine that allows
    it to reuse an existing network namespace. The syntax to do so looks like this:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Kubernetes Pod，情况则不同。当创建一个新 Pod 时，Kubernetes 首先创建一个所谓的 `pause` 容器，其目的是创建和管理
    Pod 将与所有容器共享的命名空间。除此之外，它没有做任何实际的工作；它只是处于休眠状态。`pause` 容器通过 `veth0` 连接到 `docker0`
    桥接器。任何后续加入 Pod 的容器都会使用 Docker Engine 的特殊功能，允许它重用现有的网络命名空间。实现的语法如下所示：
- en: '[PRE33]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The important part is the `--net` argument, which uses `container:<container
    name>` as a value. If we create a new container this way, then Docker does not
    create a new `veth` endpoint; the container uses the same one as the pause container.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 重要部分是 `--net` 参数，其值为 `container:<container name>`。如果我们以这种方式创建一个新容器，那么 Docker
    不会创建一个新的 `veth` 端点；该容器将使用与暂停容器相同的 `veth` 端点。
- en: 'Another important consequence of multiple containers sharing the same network
    namespace is the way they communicate with each other. Let’s consider the following
    situation: a pod containing two containers, one listening at the `80` port and
    the other at the `3000` port:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 多个容器共享相同网络命名空间的另一个重要后果是它们相互通信的方式。我们来考虑以下情况：一个 Pod 中包含两个容器，一个监听 `80` 端口，另一个监听
    `3000` 端口：
- en: '![Figure 16.13 – Containers in pods communicating via localhost](img/Figure_16.13_B19199.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.13 – Pod 中的容器通过 localhost 进行通信](img/Figure_16.13_B19199.jpg)'
- en: Figure 16.13 – Containers in pods communicating via localhost
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.13 – Pod 中的容器通过 localhost 进行通信
- en: When two containers use the same Linux kernel network namespace, they can communicate
    with each other through `localhost`, similarly to how, when two processes are
    running on the same host, they can communicate with each other through `localhost`
    too.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个容器使用相同的 Linux 内核网络命名空间时，它们可以通过 `localhost` 相互通信，类似于当两个进程在同一主机上运行时，它们也可以通过
    `localhost` 进行通信。
- en: This is illustrated in the preceding diagram. From the `main` container, the
    containerized application inside it can reach out to the service running inside
    the supporting container through http://localhost:3000.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点在前面的图示中得到了说明。从 `main` 容器中，容器化的应用程序可以通过 http://localhost:3000 访问支持容器内运行的服务。
- en: Sharing the network namespace
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 共享网络命名空间
- en: After all this theory, you might be wondering how a pod is actually created
    by Kubernetes.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了这些理论之后，你可能会想知道 Kubernetes 实际上是如何创建一个 Pod 的。
- en: Kubernetes only uses what Docker provides. So, how does this network namespace
    share work? First, Kubernetes creates the so-called `pause` container, as mentioned
    previously.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 仅使用 Docker 提供的功能。那么，这种网络命名空间共享是如何工作的呢？首先，Kubernetes 创建了前面提到的所谓 `pause`
    容器。
- en: 'This container has no other function than to reserve the kernel namespaces
    for that pod and keep them alive, even if no other container inside the pod is
    running. Let’s simulate the creation of a pod, then. We start by creating the
    pause container and use Nginx for this purpose:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这个容器的唯一作用就是为该 Pod 保留内核命名空间，并保持它们的存活，即使 Pod 内没有其他容器运行。接下来，让我们模拟创建一个 Pod。我们从创建
    pause 容器开始，并使用 Nginx 来实现：
- en: '[PRE34]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now we add a second container called `main` and attach it to the same network
    namespace as the pause container:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们添加第二个容器，命名为 `main`，并将其连接到与 pause 容器相同的网络命名空间：
- en: '[PRE35]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Since the `pause` and sample `containers` are both parts of the same network
    namespace, they can reach each other through `localhost`. To show this, we have
    to exec into the main container:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `pause` 和示例 `containers` 都是同一网络命名空间的一部分，它们可以通过 `localhost` 互相访问。为了证明这一点，我们必须进入主容器执行操作：
- en: '[PRE36]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now we can test the connection to Nginx running in the pause container and
    listening on the `80` port. The following is what we get if we use the `wget`
    utility to do so:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以测试连接到运行在 pause 容器中并监听 `80` 端口的 Nginx。使用 `wget` 工具进行测试时，我们会得到如下结果：
- en: '[PRE37]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Doing so gives us this output:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做会给我们以下输出：
- en: '![Figure 16.14 – Two containers sharing the same network namespace](img/Figure_16.14_B19199.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.14 – 两个容器共享相同的网络命名空间](img/Figure_16.14_B19199.jpg)'
- en: Figure 16.14 – Two containers sharing the same network namespace
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.14 – 两个容器共享相同的网络命名空间
- en: 'The output shows that we can indeed access Nginx on `localhost`. This is proof
    that the two containers share the same namespace. If that is not enough, we can
    use the `ip` tool to show `eth0` inside both containers and we will get the exact
    same result, specifically, the same IP address, which is one of the characteristics
    of a pod; all its containers share the same IP address:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果显示我们确实可以在 `localhost` 上访问 Nginx。这证明了这两个容器共享相同的命名空间。如果这还不够，我们可以使用 `ip` 工具在两个容器中显示
    `eth0`，并且会得到完全相同的结果，具体来说，就是相同的 IP 地址，这是 Pod 的一个特征：所有容器共享相同的 IP 地址：
- en: '[PRE38]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This will show the following output:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示以下输出：
- en: '![Figure 16.15 – Displaying the properties of eth0 with the ip tool](img/Figure_16.15_B19199.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.15 – 使用 ip 工具显示 eth0 的属性](img/Figure_16.15_B19199.jpg)'
- en: Figure 16.15 – Displaying the properties of eth0 with the ip tool
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.15 – 使用 ip 工具显示 eth0 的属性
- en: 'We inspect the `bridge` network with the following:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下命令检查 `bridge` 网络：
- en: '[PRE39]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'After that, we can see that only the pause container is listed:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们可以看到只列出了 pause 容器：
- en: '[PRE40]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The preceding output has been shortened for readability.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的输出已被简化以提高可读性。
- en: The main container didn’t get an entry in the `Containers` list since it is
    reusing the `pause` container’s endpoint.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 main 容器复用了 pause 容器的端点，因此它没有在 `Containers` 列表中出现。
- en: 'Before you continue, please remove the two `pause` and `main` containers:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，请删除两个 `pause` 和 `main` 容器：
- en: '[PRE41]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Next, we will be looking at the pod life cycle.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论 Pod 的生命周期。
- en: Pod life cycle
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pod 生命周期
- en: Earlier in this book, we learned that containers have a life cycle. A container
    is initialized, run, and ultimately exited. When a container exits, it can do
    this gracefully with an exit code zero or it can terminate with an error, which
    is equivalent to a non-zero exit code.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 本书前面提到过，容器有生命周期。容器首先初始化，运行，然后最终退出。当容器退出时，它可以通过退出代码零优雅地退出，或者通过非零退出代码终止，后者相当于发生了错误。
- en: 'Similarly, a pod has a life cycle. Because a pod can contain more than one
    container, this life cycle is slightly more complicated than that of a single
    container. The life cycle of a pod can be seen in the following diagram:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，Pod 也有生命周期。由于一个 Pod 可以包含多个容器，因此其生命周期比单一容器的生命周期稍微复杂一些。Pod 的生命周期可以在下图中看到：
- en: '![Figure 16.16 – The life cycle of Kubernetes pods](img/Figure_16.16_B19199.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.16 – Kubernetes Pod 的生命周期](img/Figure_16.16_B19199.jpg)'
- en: Figure 16.16 – The life cycle of Kubernetes pods
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.16 – Kubernetes Pod 的生命周期
- en: When a pod is created on a cluster node, it first enters the *pending* status.
    Once all the containers of the pod are up and running, the pod enters the *running*
    status. The pod only enters into this state if all its containers run successfully.
    If the pod is asked to terminate, it will request all its containers to terminate.
    If all containers terminate with exit code zero, then the pod enters into the
    *succeeded* status. This is the happy path.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Pod 在集群节点上创建时，它首先进入 *待处理* 状态。一旦 Pod 的所有容器都启动并运行，Pod 就进入 *运行中* 状态。只有当所有容器成功运行时，Pod
    才会进入此状态。如果要求 Pod 终止，它将请求所有容器终止。如果所有容器以退出代码零终止，则 Pod 进入 *成功* 状态。这是理想路径。
- en: 'Now, let’s look at some scenarios that lead to the pod being in a *failed*
    state. There are three possible scenarios:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看一些导致 Pod 处于 *失败* 状态的场景。可能有三种情况：
- en: If, during the startup of the pod, at least one container is not able to run
    and fails (that is, it exits with a nonzero exit code), the pod goes from the
    *pending* state into the failed state.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果在 Pod 启动期间，至少有一个容器无法运行并失败（即它退出时返回非零退出代码），则 Pod 会从*待处理*状态转入失败状态。
- en: If the pod is in the *running* status and one of the containers suddenly crashes
    or exits with a nonzero exit code, then the pod transitions from the *running*
    state into the *failed* state.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 Pod 处于 *运行中* 状态，而其中一个容器突然崩溃或以非零退出代码退出，则 Pod 将从 *运行中* 状态转换为 *失败* 状态。
- en: If the pod is asked to terminate and, during the shutdown, at least one of the
    containers, exits with a nonzero exit code, then the pod also enters into the
    *failed* state.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果要求 Pod 终止，并且在关闭过程中，至少有一个容器以非零退出代码退出，则 Pod 也会进入 *失败* 状态。
- en: Now let’s look at the specifications for a pod.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看 Pod 的规范。
- en: Pod specifications
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pod 规范
- en: When creating a pod in a Kubernetes cluster, we can use either an imperative
    or a declarative approach. We discussed the difference between the two approaches
    earlier in this book but, to rephrase the most important aspect, using a declarative
    approach signifies that we write a manifest that describes the end state we want
    to achieve. We’ll leave out the details of the orchestrator. The end state that
    we want to achieve is also called the desired state. In general, the declarative
    approach is strongly preferred in all established orchestrators, and Kubernetes
    is no exception.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 集群中创建 Pod 时，我们可以使用命令式或声明式的方法。我们在本书前面已经讨论过这两种方法的区别，但为了重新表述最重要的方面，使用声明式方法意味着我们编写一个描述我们想要实现的最终状态的清单。我们将省略协调器的细节。我们想要实现的最终状态也被称为期望状态。一般来说，声明式方法在所有成熟的协调器中都受到强烈推荐，Kubernetes
    也不例外。
- en: 'Thus, in this chapter, we will exclusively concentrate on the declarative approach.
    Manifests or specifications for a pod can be written using either the `YAML` or
    `JSON` formats. In this chapter, we will concentrate on `YAML` since it is easier
    to read for us humans. Let’s look at a sample specification. Here is the content
    of the `pod.yaml` file, which can be found in the `ch16` subfolder of our `labs`
    folder:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本章中，我们将专注于声明式方法。Pod 的清单或规范可以使用 `YAML` 或 `JSON` 格式编写。在本章中，我们将专注于 `YAML`，因为它对我们人类来说更易于阅读。让我们来看一个示例规范。以下是
    `pod.yaml` 文件的内容，该文件可以在我们 `labs` 文件夹的 `ch16` 子文件夹中找到：
- en: '[PRE42]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Each specification in Kubernetes starts with the version information. Pods have
    been around for quite some time and thus the API version is `v1`. The second line
    specifies the type of Kubernetes object or resource we want to define. Obviously,
    in this case, we want to specify a pod. Next follows a block containing metadata.
    At a bare minimum, we need to give the pod a name. Here, we call it `web-pod`.
    The next block that follows is the `spec` block, which contains the specification
    of the pod. The most important part (and the only one in this simple sample) is
    a list of all containers that are part of this pod. We only have one container
    here, but multiple containers are possible. The name we chose for our container
    is `web` and the container image is `nginx:alpine`. Finally, we define a list
    of ports the container is exposing.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 中的每个规范都以版本信息开头。Pod 已经存在了一段时间，因此 API 版本是 `v1`。第二行指定了我们想要定义的 Kubernetes
    对象或资源类型。显然，在这个例子中，我们想要指定一个 pod。接下来是一个包含元数据的块。最基本的要求是给 pod 起个名字。这里我们称其为 `web-pod`。接下来的块是
    `spec` 块，包含 pod 的规范。最重要的部分（也是这个简单示例中唯一的部分）是列出所有属于该 pod 的容器。我们这里只有一个容器，但也可以有多个容器。我们为容器选择的名字是
    `web`，容器镜像是 `nginx:alpine`。最后，我们定义了容器暴露的端口列表。
- en: 'Once we have authored such a specification, we can apply it to the cluster
    using the Kubernetes CLI, `kubectl`:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们编写了这样的规范，就可以使用 Kubernetes CLI `kubectl` 将其应用到集群中：
- en: 'Open a new terminal window and navigate to the `ch16` subfolder:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的终端窗口，导航到 `ch16` 子文件夹：
- en: '[PRE43]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'In this example, we’re going to use Docker Desktop’s Kubernetes cluster. Thus,
    make sure that you are using the right context for the `kubectl` CLI:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用 Docker Desktop 的 Kubernetes 集群。因此，确保你正在使用正确的 `kubectl` CLI 上下文：
- en: '[PRE44]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This will switch the context to our Kubernetes cluster provided by Docker Desktop.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这将切换上下文到由 Docker Desktop 提供的 Kubernetes 集群。
- en: In this folder, create a new file called `pod.yml` and add the mentioned pod
    specification to it. Save the file.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此文件夹中，创建一个名为 `pod.yml` 的新文件，并将提到的 pod 规范添加到该文件中。保存该文件。
- en: 'Execute the following command:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下命令：
- en: '[PRE45]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This will respond with `pod "``web-pod" created`.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这将回应 `pod "web-pod" created`。
- en: 'We can then list all the pods in the cluster:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们可以列出集群中的所有 pod：
- en: '[PRE46]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Doing so will provide us with this output:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做将为我们提供以下输出：
- en: '[PRE47]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: As expected, we have one of one pod in the `Running` state. The pod is called
    `web-pod`, as defined.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，我们有一个处于 `Running` 状态的 pod，名称为 `web-pod`，正如定义的那样。
- en: 'We can get more detailed information about the running pod by using the `describe`
    command:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过使用 `describe` 命令来获取有关运行中的 pod 的更详细信息：
- en: '[PRE48]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This gives us something similar to this:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 这会给我们类似这样的输出：
- en: '![Figure 16.17 – Describing a pod running in the cluster](img/Figure_16.17_B19199.jpg)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.17 – 描述运行在集群中的 pod](img/Figure_16.17_B19199.jpg)'
- en: Figure 16.17 – Describing a pod running in the cluster
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.17 – 描述运行在集群中的 pod
- en: Note
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The `pod/web-pod` notation in the previous section includes the `describe` command.
    Other variants are possible. For example, `pods/web-pod`, `po/web-pod`, `pod`,
    and `po` are aliases of `pods`.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 前面部分的 `pod/web-pod` 表示法包括 `describe` 命令。其他变体也是可能的。例如，`pods/web-pod`、`po/web-pod`、`pod`
    和 `po` 都是 `pods` 的别名。
- en: The `kubectl` tool defines many aliases to make our lives a bit easier.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl` 工具定义了许多别名，以使我们的生活更加轻松。'
- en: The `describe` command gives us a plethora of valuable information about the
    pod, not the least of which is a list of events that happened and affected this
    pod. The list is shown at the end of the output.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '`describe` 命令为我们提供了大量有关 pod 的有价值的信息，其中之一是发生并影响该 pod 的事件列表。该列表会显示在输出的最后。'
- en: The information in the `Containers` section is very similar to what we find
    in a `docker container` `inspect` output.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '`Containers` 部分中的信息与我们在 `docker container` `inspect` 输出中找到的非常相似。'
- en: We can also see a `Volumes` section with a `Projected` entry type. It contains
    the root certificate of the cluster as a secret. We will discuss Kubernetes secrets
    in the next chapter. Volumes, on the other hand, will be discussed next.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到一个 `Volumes` 部分，其中有一个 `Projected` 条目类型。它包含集群的根证书作为机密。我们将在下一章讨论 Kubernetes
    的机密。另一方面，卷将在接下来讨论。
- en: Pods and volumes
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pod 和卷
- en: 'In the chapter about containers, we learned about volumes and their purpose:
    accessing and storing persistent data. Since containers can mount volumes, pods
    can do so as well. In reality, it is really the containers inside the pod that
    mount the volumes, but that is just a semantic detail. First, let’s see how we
    can define a volume in Kubernetes. Kubernetes supports a plethora of volume types,
    so we won’t delve into too much detail about this.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在关于容器的章节中，我们了解了卷及其作用：访问和存储持久数据。由于容器可以挂载卷，因此pod也可以。实际上，真正挂载卷的是pod中的容器，但这只是一个语义上的细节。首先，让我们看看如何在Kubernetes中定义一个卷。Kubernetes支持各种卷类型，因此我们不会深入探讨这个话题。
- en: 'Let’s just create a local volume implicitly by defining a `PersistentVolumeClaim`
    claim called `my-data-claim`:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过定义一个名为`my-data-claim`的`PersistentVolumeClaim`声明，隐式地创建一个本地卷：
- en: 'Create a file called `volume-claim.yaml` and add the following specification
    to it:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`volume-claim.yaml`的文件，并将以下规范添加到文件中：
- en: '[PRE49]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: We have defined a claim that requests 2 GB of data.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个请求2GB数据的声明。
- en: 'Let’s create this claim:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建这个声明：
- en: '[PRE50]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'This will resulting in the following output:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下输出：
- en: '[PRE51]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We can list the claim using `kubectl` (`pvc` is a shortcut for `PersistentVolumeClaim`)
    with the following:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用`kubectl`列出声明（`pvc`是`PersistentVolumeClaim`的快捷方式），命令如下：
- en: '[PRE52]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'This gives us this output:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下输出：
- en: '![Figure 16.18 – List of PersistentStorageClaim objects in the cluster](img/Figure_16.18_B19199.jpg)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![图16.18 – 集群中PersistentStorageClaim对象的列表](img/Figure_16.18_B19199.jpg)'
- en: Figure 16.18 – List of PersistentStorageClaim objects in the cluster
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.18 – 集群中PersistentStorageClaim对象的列表
- en: In the output, we can see that the claim has implicitly created a volume called
    `pvc-<ID>`.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在输出中，我们可以看到该声明已经隐式地创建了一个名为`pvc-<ID>`的卷。
- en: 'Remove the pod before you continue:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在继续之前，请先移除该pod：
- en: '[PRE53]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Alternatively, use the original file defining the pod with the following command:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，使用定义pod的原始文件，命令如下：
- en: '[PRE54]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We are now ready to use the volume created by the claim in a pod. Let’s use
    a modified version of the pod specification that we used previously:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以在pod中使用该声明创建的卷了。让我们使用之前使用的修改版pod规范：
- en: 'Create a file called `pod-with-vol.yaml` and add the following specification
    to it:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`pod-with-vol.yaml`的文件，并将以下规范添加到文件中：
- en: '[PRE55]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: In the last four lines, in the `volumes` block, we define a list of volumes
    we want to use for this pod. The volumes that we list here can be used by any
    of the containers of the pod. In our particular case, we only have one volume.
    We specify that we have a volume called `my-data`, which is a persistent volume
    claim whose claim name is the one we just created.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后四行的`volumes`块中，我们定义了一个我们希望在该pod中使用的卷列表。我们在这里列出的卷可以被pod的任何容器使用。在我们的例子中，我们只有一个卷。我们指定了一个名为`my-data`的卷，它是一个持久卷声明，声明名称就是我们刚刚创建的那个。
- en: Then, in the container specification, we have the `volumeMounts` block, which
    is where we define the volume we want to use and the (absolute) path inside the
    container where the volume will be mounted. In our case, we mount the volume to
    the `/data` folder of the container filesystem.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在容器规范中，我们有`volumeMounts`块，在这里我们定义了要使用的卷，以及容器内卷将挂载的（绝对）路径。在我们的例子中，我们将卷挂载到容器文件系统的`/data`文件夹。
- en: 'Let’s create this pod:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建这个pod：
- en: '[PRE56]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'We can also use the declarative way:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用声明式的方式：
- en: '[PRE57]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Then, we can `exec` into the container to double-check that the volume has
    mounted by navigating to the `/data` folder, creating a file there, and exiting
    the container using:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以`exec`进入容器，通过导航到`/data`文件夹，创建一个文件并使用以下命令退出容器，以检查卷是否已经挂载：
- en: '[PRE58]'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: If we are right, then the data in this container must persist beyond the life
    cycle of the pod.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没错的话，那么这个容器中的数据应该在pod的生命周期结束后仍然存在。
- en: 'Thus, let’s delete the pod:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，让我们删除这个pod：
- en: '[PRE59]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Then, we’ll recreate it:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将重新创建它：
- en: '[PRE60]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'We’ll then `exec` into the container of the pod:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将`exec`进入pod的容器：
- en: '[PRE61]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Finally, we output the data:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们输出数据：
- en: '[PRE62]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'This is the output produced by the preceding command:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 这是前面命令产生的输出：
- en: '[PRE63]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: It is what we expected.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们所预期的。
- en: Exit the container by pressing *Ctrl* + *D*.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按*Ctrl* + *D*退出容器。
- en: Delete the pod and the persistent volume claim before you continue. By now,
    you should know the command to do so. Otherwise, have a look back at *step 4*.
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在继续之前，请删除pod和持久卷声明。到现在为止，你应该知道怎么做。如果不知道，请回头查看*步骤4*。
- en: Now that we have a good understanding of pods, let’s investigate how those pods
    are managed with the help of ReplicaSets.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对Pods有了较好的理解，让我们研究一下ReplicaSets如何帮助管理这些Pods。
- en: Kubernetes ReplicaSets
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes ReplicaSets
- en: A single pod in an environment with high availability requirements is insufficient.
    What if the pod crashes? What if we need to update the application running inside
    the pod but cannot afford any service interruption? These questions and more indicate
    that pods alone are not enough, and we need a higher-level concept that can manage
    multiple instances of the same pod. In Kubernetes, the ReplicaSet is used to define
    and manage such a collection of identical pods that are running on different cluster
    nodes. Among other things, a ReplicaSet defines which container images are used
    by the containers running inside a pod and how many instances of the pod will
    run in the cluster. These properties and many others are called the **desired
    state**.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个对高可用性有要求的环境中，仅有一个Pod是远远不够的。如果Pod崩溃了怎么办？如果我们需要更新Pod内部的应用程序，但又不能承受任何服务中断怎么办？这些问题表明仅有Pods是不足够的，我们需要一个更高级的概念来管理多个相同的Pod实例。在Kubernetes中，ReplicaSet用于定义和管理在不同集群节点上运行的多个相同Pod的集合。ReplicaSet定义了容器在Pod中运行时使用的容器镜像，以及在集群中运行的Pod实例数量等。这些属性以及其他许多属性被称为**期望状态**。
- en: 'The ReplicaSet is responsible for reconciling the desired state at all times
    if the actual state ever deviates from it. Here is a Kubernetes ReplicaSet:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet负责始终确保实际状态与期望状态的一致性，如果实际状态偏离期望状态。以下是一个Kubernetes ReplicaSet：
- en: '![Figure 16.19 – Kubernetes ReplicaSet](img/Figure_16.19_B19199.jpg)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![图16.19 – Kubernetes ReplicaSet](img/Figure_16.19_B19199.jpg)'
- en: Figure 16.19 – Kubernetes ReplicaSet
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.19 – Kubernetes ReplicaSet
- en: In the preceding diagram, we can see a ReplicaSet that governs a number of pods.
    The pods are called `pod-api`. The ReplicaSet is responsible for making sure that,
    at any given time, there is always the desired number of pods running. If one
    of the pods crashes for whatever reason, the ReplicaSet schedules a new pod on
    a node with free resources instead. If there are more pods than the desired number,
    then the ReplicaSet kills superfluous pods. With this, we can say that the ReplicaSet
    guarantees a self-healing and scalable set of pods. There is no limit to how many
    pods a ReplicaSet can hold.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示意图中，我们可以看到一个ReplicaSet管理着多个Pods。这些Pods被称为`pod-api`。ReplicaSet负责确保在任何给定时间，始终有期望数量的Pods在运行。如果某个Pod因为某种原因崩溃，ReplicaSet会在一个有空闲资源的节点上调度一个新的Pod替代它。如果Pod的数量超过了期望的数量，ReplicaSet会杀死多余的Pod。通过这种方式，我们可以说ReplicaSet保证了一个自愈且可扩展的Pod集合。ReplicaSet可以包含的Pod数量没有上限。
- en: ReplicaSet specification
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReplicaSet规格
- en: 'Similar to what we have learned about pods, Kubernetes also allows us to either
    imperatively or declaratively define and create a ReplicaSet. Since the declarative
    approach is by far the most recommended one in most cases, we’re going to concentrate
    on this approach. Let’s work with a sample specification for a Kubernetes ReplicaSet:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我们对Pods的学习，Kubernetes也允许我们以命令式或声明式的方式定义和创建ReplicaSet。由于在大多数情况下声明式方法是最推荐的方式，我们将专注于这种方法。让我们来看看一个Kubernetes
    ReplicaSet的示例规格：
- en: 'Create a new file called `replicaset.yaml` and add the following content to
    it:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`replicaset.yaml`的新文件，并在其中添加以下内容：
- en: '[PRE64]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: This looks an awful lot like the pod specification we introduced earlier. Let’s
    concentrate on the differences, then. First, on line 2, we have the kind, which
    was a pod, and is now `ReplicaSet`. Then, on lines 6–8, we have a selector, which
    determines the pods that will be part of the ReplicaSet. In this case, it is all
    the pods that have `app` as a label with the value `web`. Then, on line 9, we
    define how many replicas of the pod we want to run; three, in this case. Finally,
    we have the `template` section, which first defines the metadata, and then the
    spec, which defines the containers that run inside the pod. In our case, we have
    a single container using the `nginx:alpine` image and exporting `80` port.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来与我们之前介绍的Pod规格非常相似。那么，我们来集中注意其区别。首先，在第2行，我们看到的是`kind`，之前是Pod，现在是`ReplicaSet`。接着，在第6到第8行，我们有一个选择器，它决定哪些Pods将成为ReplicaSet的一部分。在这个例子中，它选择所有标签为`app`且值为`web`的Pods。然后，在第9行，我们定义了希望运行的Pod副本数量；在这个例子中是三个副本。最后，我们有`template`部分，它首先定义了元数据，然后定义了规格，其中包含运行在Pod内部的容器。在我们的例子中，我们有一个使用`nginx:alpine`镜像并暴露`80`端口的单一容器。
- en: The really important elements are the number of replicas and the selector, which
    specifies the set of pods governed by the ReplicaSet.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 其中真正重要的元素是副本数和选择器，选择器指定了由ReplicaSet管理的Pod集合。
- en: 'Let’s use this file to create the ReplicaSet:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用这个文件来创建ReplicaSet：
- en: '[PRE65]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'This results in the following:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下结果：
- en: '[PRE66]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Now we list all the ReplicaSets in the cluster (`rs` is a shortcut for ReplicaSet):'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们列出集群中所有的ReplicaSets（`rs`是ReplicaSet的快捷方式）：
- en: '[PRE67]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'We get the following:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了以下结果：
- en: '[PRE68]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: In the preceding output, we can see that we have a single ReplicaSet called
    `rs-web`, the desired state of which is three (pods). The current state also shows
    three pods and tells us that all three pods are ready.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们看到有一个名为`rs-web`的ReplicaSet，其期望状态是三个（Pod）。当前状态也显示了三个Pod，并告诉我们所有三个Pod都已准备就绪。
- en: 'We can also list all the pods in the system:'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以列出系统中的所有Pod：
- en: '[PRE69]'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'This results in the following output:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '[PRE70]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Here we can see our three expected pods. The names of the pods use the `ReplicaSet`
    name with a unique ID appended for each pod. In the `READY` column, we can see
    how many containers have been defined in the pod and how many of them are ready.
    In our case, we only have a single container per pod and, in each case, it is
    ready. Thus, the overall status of the pod is `Running`. We can also see how many
    times each pod had to be restarted. In our case, we don’t have any restarts.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们预期的三个Pod。Pod的名称使用了`ReplicaSet`的名称，并附加了一个唯一的ID。在`READY`列中，我们可以看到Pod中定义了多少个容器以及它们中有多少个已准备就绪。在我们的案例中，每个Pod只有一个容器，并且每个容器都已准备好。因此，Pod的整体状态是`Running`。我们还可以看到每个Pod被重启了多少次。在我们的例子中，没有任何Pod被重启。
- en: Next, let’s see how the ReplicaSet helps us with self-healing.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看ReplicaSet是如何帮助我们实现自愈的。
- en: Self-healing
  id: totrans-378
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自愈
- en: 'Now, let’s test the magic powers of the self-healing ReplicaSet by randomly
    killing one of its pods and observing what happens:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过随机杀死其中一个Pod来测试自愈ReplicaSet的魔力，并观察会发生什么：
- en: 'Let’s delete the first pod from the previous list. Make sure to replace the
    name of the pod (`rs-web-nbc8m`) with the name you have in your own example:'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们删除前面列表中的第一个Pod。确保将Pod的名称（`rs-web-nbc8m`）替换为您自己示例中的名称：
- en: '[PRE71]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The previous command produces the following output:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个命令生成了以下输出：
- en: '[PRE72]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Now, let’s list all the pods again. We expect to see only two pods, right?
    You’re wrong:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们再次列出所有Pod。我们期望只看到两个Pod，对吗？你错了：
- en: '[PRE73]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: OK. Evidently, the first pod in the list has been recreated, as we can see from
    the `AGE` column. This is auto-healing in action.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，显然，列表中的第一个Pod已经被重新创建，正如我们从`AGE`列中看到的那样。这是自愈功能在起作用。
- en: 'Let’s see what we discover if we describe the ReplicaSet:'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看描述ReplicaSet时会发现什么：
- en: '[PRE74]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'This will give us this output:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们以下输出：
- en: '![Figure 16.20 – Describe the ReplicaSet](img/Figure_16.20_B19199.jpg)'
  id: totrans-390
  prefs: []
  type: TYPE_IMG
  zh: '![图16.20 – 描述ReplicaSet](img/Figure_16.20_B19199.jpg)'
- en: Figure 16.20 – Describe the ReplicaSet
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.20 – 描述ReplicaSet
- en: And indeed, we find an entry under `Events` that tells us that the ReplicaSet
    created a new pod called `rs-web-4r587`.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，我们在`Events`下找到了一个条目，告诉我们ReplicaSet创建了一个名为`rs-web-4r587`的新Pod。
- en: 'Before you continue, please delete the ReplicaSet:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在继续之前，请删除ReplicaSet：
- en: '[PRE75]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Now it’s time to talk about the Kubernetes Deployment object.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候讨论Kubernetes的Deployment对象了。
- en: Kubernetes Deployments
  id: totrans-396
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes部署
- en: Kubernetes takes the single-responsibility principle very seriously. All Kubernetes
    objects are designed to do one thing and one thing only, and they are designed
    to do this one thing very well. In this regard, we must understand Kubernetes
    ReplicaSets and Deployments. A ReplicaSet, as we have learned, is responsible
    for achieving and reconciling the desired state of an application service. This
    means that the ReplicaSet manages a set of pods.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes非常重视单一职责原则。所有Kubernetes对象都被设计为执行一项任务，而且只执行这一项任务，而且它们的设计目标是非常出色地完成这项任务。在这方面，我们必须理解Kubernetes的ReplicaSets和Deployments。正如我们所学，ReplicaSet负责实现和协调应用服务的期望状态。这意味着ReplicaSet管理一组Pod。
- en: 'A **Deployment** augments a ReplicaSet by providing rolling updates and rollback
    functionality on top of it. In Docker Swarm, the Swarm service incorporates the
    functionality of both a ReplicaSet and Deployment. In this regard, SwarmKit is
    much more monolithic than Kubernetes. The following diagram shows the relationship
    of a Deployment to a ReplicaSet:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: '**部署（Deployment）**通过在ReplicaSet基础上提供滚动更新和回滚功能来增强ReplicaSet。在Docker Swarm中，Swarm服务结合了ReplicaSet和Deployment的功能。从这个角度来看，SwarmKit比Kubernetes更加单体化。以下图示展示了Deployment与ReplicaSet的关系：'
- en: '![Figure 16.21 – Kubernetes Deployment](img/Figure_16.21_B19199.jpg)'
  id: totrans-399
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.21 – Kubernetes 部署](img/Figure_16.21_B19199.jpg)'
- en: Figure 16.21 – Kubernetes Deployment
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.21 – Kubernetes 部署
- en: In the preceding diagram, the ReplicaSet defines and governs a set of identical
    pods. The main characteristics of the ReplicaSet are that it is self-healing,
    scalable, and always does its best to reconcile the desired state. The Kubernetes
    Deployment, in turn, adds rolling updates and rollback functionality to this.
    In this regard, a Deployment is a wrapper object for a ReplicaSet.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图示中，ReplicaSet 定义并管理一组相同的 pods。ReplicaSet 的主要特点是自我修复、可扩展，并始终尽最大努力使其状态与期望状态一致。而
    Kubernetes 部署（Deployment）则在此基础上增加了滚动更新和回滚功能。在这方面，Deployment 是 ReplicaSet 的封装对象。
- en: We will learn more about rolling updates and rollbacks in [*Chapter 17*](B19199_17.xhtml#_idTextAnchor374),
    *Deploying, Updating, and Securing an Application* *with Kubernetes*.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 [*第 17 章*](B19199_17.xhtml#_idTextAnchor374) 中深入学习滚动更新和回滚，*使用 Kubernetes
    部署、更新和保护应用程序*。
- en: In the next section, we will learn more about Kubernetes services and how they
    enable service discovery and routing.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入了解 Kubernetes 服务以及它们如何实现服务发现和路由。
- en: Kubernetes Services
  id: totrans-404
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 服务
- en: 'The moment we start to work with applications consisting of more than one application
    service, we need service discovery. The following diagram illustrates this problem:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们开始处理由多个应用服务组成的应用程序，就需要服务发现。以下图示说明了这个问题：
- en: '![Figure 16.22 – Service discovery](img/Figure_16.22_B19199.jpg)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.22 – 服务发现](img/Figure_16.22_B19199.jpg)'
- en: Figure 16.22 – Service discovery
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.22 – 服务发现
- en: 'In the preceding diagram, we have a `Web API` service that needs access to
    three other services: `payments`, `shipping`, and `ordering`. The `Web API` service
    should never have to care about how and where to find those three services. In
    the API code, we just want to use the name of the service we want to reach and
    its port number. A sample would be the following URL, [http://payments:3000](http://payments:3000),
    which is used to access an instance of the `payments` service.'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图示中，我们有一个 `Web API` 服务，需要访问另外三个服务：`payments`、`shipping` 和 `ordering`。`Web
    API` 服务不应关心如何以及在哪里找到这三个服务。在 API 代码中，我们只需要使用我们想要访问的服务名称和其端口号。一个示例是以下 URL，[http://payments:3000](http://payments:3000)，它用于访问
    `payments` 服务的一个实例。
- en: In Kubernetes, the payments application service is represented by a ReplicaSet
    of pods. Due to the nature of highly distributed systems, we cannot assume that
    pods have stable endpoints. A pod can come and go on a whim. But that’s a problem
    if we need to access the corresponding application service from an internal or
    external client. If we cannot rely on pod endpoints being stable, what else can
    we do?
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，支付应用服务由一个 ReplicaSet 的 pods 表示。由于高度分布式系统的特性，我们不能假设 pods 拥有稳定的端点。pod
    可以随时出现或消失。如果我们需要从内部或外部客户端访问相应的应用服务，这将是个问题。如果我们不能依赖 pod 端点的稳定性，我们还能做什么呢？
- en: 'This is where **Kubernetes Services** come into play. They are meant to provide
    stable endpoints to ReplicaSets or Deployments, as follows:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 **Kubernetes 服务** 发挥作用的地方。它们旨在为 ReplicaSets 或 Deployments 提供稳定的端点，如下所示：
- en: '![Figure 16.23 – Kubernetes service providing stable endpoints to clients](img/Figure_16.23_B19199.jpg)'
  id: totrans-411
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.23 – Kubernetes 服务为客户端提供稳定的端点](img/Figure_16.23_B19199.jpg)'
- en: Figure 16.23 – Kubernetes service providing stable endpoints to clients
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.23 – Kubernetes 服务为客户端提供稳定的端点
- en: In the preceding diagram, in the center, we can see such a Kubernetes Service.
    It provides a reliable cluster-wide IP address, also called a `app=web`; that
    is, all pods that have a label called `app` with a value of `web` are proxied.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图示中，我们可以看到一个 Kubernetes 服务。它提供了一个可靠的集群级 IP 地址，也叫做 `app=web`；也就是说，所有具有名为
    `app` 且值为 `web` 的标签的 pod 都会被代理。
- en: In the next section, we will learn more about context-based routing and how
    Kubernetes alleviates this task.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入了解基于上下文的路由以及 Kubernetes 如何减轻这一任务。
- en: Context-based routing
  id: totrans-415
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于上下文的路由
- en: 'Often, we want to configure context-based routing for our Kubernetes cluster.
    Kubernetes offers us various ways to do this. The preferred and most scalable
    way currently is to use IngressController. The following diagram tries to illustrate
    how this ingress controller works:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常需要为 Kubernetes 集群配置基于上下文的路由。Kubernetes 提供了多种方式来实现这一点。目前，首选且最具可扩展性的方法是使用
    IngressController。以下图示尝试说明这个 ingress 控制器是如何工作的：
- en: '![Figure 16.24 – Context-based routing using a Kubernetes ingress controller](img/Figure_16.24_B19199.jpg)'
  id: totrans-417
  prefs: []
  type: TYPE_IMG
  zh: '![图 16.24 – 使用 Kubernetes Ingress 控制器的基于上下文的路由](img/Figure_16.24_B19199.jpg)'
- en: Figure 16.24 – Context-based routing using a Kubernetes ingress controller
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.24 – 使用 Kubernetes Ingress 控制器的基于上下文的路由
- en: 'In the preceding diagram, we can see how context-based (or layer 7) routing
    works when using an IngressController, such as Nginx. Here, we have the Deployment
    of an application service called `web`. All the pods of this application service
    have the following label: `app=web`. Then, we have a Kubernetes Service called
    `web` that provides a stable endpoint to those pods. The Service has a VIP of
    `52.14.0.13` and exposes a `30044` port. That is, if a request comes to any node
    of the Kubernetes cluster for the name `web` and `30044` port, then it is forwarded
    to this Service. The Service then load balances the request to one of the pods.'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，我们可以看到当使用 IngressController（如 Nginx）时，基于上下文（或第七层）路由是如何工作的。在这里，我们有一个名为
    `web` 的应用服务的部署。这个应用服务的所有 Pod 都有以下标签：`app=web`。然后，我们有一个名为 `web` 的 Kubernetes 服务，它为这些
    Pod 提供一个稳定的端点。该服务的虚拟 IP 是 `52.14.0.13`，并且暴露了 `30044` 端口。也就是说，如果有请求到达 Kubernetes
    集群的任何节点，并请求 `web` 名称和 `30044` 端口，那么这个请求会被转发到这个服务。然后，服务会将请求负载均衡到其中一个 Pod。
- en: 'So far, so good, but how is an ingress request from a client to the http[s]://example.com/web
    URL routed to our web service? First, we must define routing from a context-based
    request to a corresponding `<service name>/<port>` request. This is done through
    an Ingress object:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切顺利，但如何将来自客户端的 ingress 请求路由到 `http[s]://example.com/web` URL 并定向到我们的
    Web 服务呢？首先，我们必须定义从基于上下文的请求到相应的 `<服务名>/<端口>` 请求的路由。这是通过 Ingress 对象实现的：
- en: In the Ingress object, we define the Host and Path as the source and the (service)
    name, and the port as the target. When this Ingress object is created by the Kubernetes
    API server, then a process that runs as a sidecar in IngressController picks up
    this change.
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Ingress 对象中，我们将 Host 和 Path 定义为源，(服务) 名称和端口为目标。当 Kubernetes API 服务器创建这个 Ingress
    对象时，作为 sidecar 运行的 IngressController 进程会拾取这个变化。
- en: The configuration file of the Nginx reverse proxy is modified.
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改 Nginx 反向代理的配置文件。
- en: By adding the new route, Nginx is then asked to reload its configuration and
    thus, will be able to correctly route any incoming requests to `http[s]://example.com/web`.
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过添加新路由，要求 Nginx 重新加载其配置，因此，它将能够正确地将任何传入的请求路由到 `http[s]://example.com/web`。
- en: In the next section, we are going to compare Docker SwarmKit with Kubernetes
    by contrasting some of the main resources of each orchestration engine.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将通过对比每种调度引擎的一些主要资源，来比较 Docker SwarmKit 和 Kubernetes。
- en: Comparing SwarmKit with Kubernetes
  id: totrans-425
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较 SwarmKit 和 Kubernetes
- en: 'Now that we have learned a lot of details about the most important resources
    in Kubernetes, it is helpful to compare the two orchestrators, SwarmKit and Kubernetes,
    by matching the important resources. Let’s take a look:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 Kubernetes 中一些最重要资源的许多细节，接下来比较这两种调度器 SwarmKit 和 Kubernetes 时，通过匹配重要资源来帮助理解。让我们来看看：
- en: '| **SwarmKit** | **Kubernetes** | **Description** |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| **SwarmKit** | **Kubernetes** | **描述** |'
- en: '| --- | --- | --- |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Swarm | Cluster | Set of servers/nodes managed by the respective orchestrator.
    |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| Swarm | 集群 | 由各自的调度器管理的服务器/节点集。|'
- en: '| Node | Cluster member | Single host (physical or virtual) that’s a member
    of the Swarm/cluster. |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| 节点 | 集群成员 | 作为 Swarm/集群成员的单个主机（物理或虚拟）。|'
- en: '| Manager node | Master | Node managing the Swarm/cluster. This is the control
    plane. |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| 管理节点 | 主节点 | 管理 Swarm/集群的节点。这是控制平面。|'
- en: '| Worker node | Node | Member of the Swarm/cluster running application workload.
    |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 工作节点 | 节点 | 运行应用工作负载的 Swarm/集群成员。|'
- en: '| Container | Container** | An instance of a container image running on a node.**Note:
    In a Kubernetes cluster, we cannot run a container directly. |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| 容器 | 容器** | 运行在节点上的容器镜像实例。**注：在 Kubernetes 集群中，我们不能直接运行容器。|'
- en: '| Task | Pod | An instance of a Service (Swarm) or ReplicaSet (Kubernetes)
    running on a node. A task manages a single container while a Pod contains one
    to many containers that all share the same network namespace. |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | Pod | 运行在节点上的服务实例（Swarm）或副本集（Kubernetes）。一个任务管理一个容器，而一个Pod包含一个或多个容器，这些容器共享相同的网络命名空间。|'
- en: '| Service | ReplicaSet | Defines and reconciles the desired state of an application
    service consisting of multiple instances. |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| 服务 | 副本集 | 定义并协调由多个实例组成的应用服务的期望状态。|'
- en: '| Service | Deployment | A Deployment is a ReplicaSet augmented with rolling
    updates and rollback capabilities. |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 服务 | 部署 | 部署是带有滚动更新和回滚功能的 ReplicaSet。|'
- en: '| Routing mesh | Service | The Swarm Routing Mesh provides L4 routing and load
    balancing using IPVS. A Kubernetes Service is an abstraction that defines a logical
    set of pods and a policy that can be used to access them. It is a stable endpoint
    for a set of pods |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 路由网格 | 服务 | Swarm 路由网格提供基于 IPVS 的 L4 路由和负载均衡。Kubernetes 服务是一个抽象，定义了一组逻辑上的
    pods 和一种可用于访问它们的策略。它是一个稳定的端点，指向一组 pods |'
- en: '| Stack | Stack** | The definition of an application consists of multiple (Swarm)
    services.**Note: While stacks are not native to Kubernetes, Docker’s tool, Docker
    Desktop, will translate them for Deployment onto a Kubernetes cluster |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| 堆栈 | 堆栈** | 应用程序的定义由多个（Swarm）服务组成。**注意：虽然堆栈在 Kubernetes 中并不是原生支持的，但 Docker
    工具 Docker Desktop 会将它们转换为 Kubernetes 集群的部署 |'
- en: '| Network | Network policy | Swarm **software-defined networks** (**SDNs**)
    are used to firewall containers. Kubernetes only defines a single flat network.
    Every pod can reach every other pod and/or node unless network policies are explicitly
    defined to constrain inter-pod communication |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| 网络 | 网络策略 | Swarm **软件定义网络**（**SDNs**）用于防火墙容器。Kubernetes 只定义了一个单一的扁平网络。除非显式定义网络策略来约束
    pod 之间的通信，否则每个 pod 都可以访问其他 pod 和/或节点 |'
- en: This concludes our introduction to Kubernetes, currently the most popular container
    orchestration engine.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们对 Kubernetes 的介绍，它目前是最流行的容器编排引擎。
- en: Summary
  id: totrans-441
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about the basics of Kubernetes. We took an overview
    of its architecture and introduced the main resources that are used to define
    and run applications in a Kubernetes cluster. We also introduced minikube and
    Kubernetes support in Docker Desktop.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了 Kubernetes 的基础知识。我们概述了其架构，并介绍了用于在 Kubernetes 集群中定义和运行应用程序的主要资源。我们还介绍了
    minikube 和 Docker Desktop 中的 Kubernetes 支持。
- en: In the next chapter, we’re going to deploy an application into a Kubernetes
    cluster. Then, we’re going to be updating one of the services of this application
    using a zero-downtime strategy. Finally, we’re going to instrument application
    services running in Kubernetes with sensitive data using secrets. Stay tuned!
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将把应用程序部署到 Kubernetes 集群中。然后，我们将使用零停机策略更新该应用程序的某个服务。最后，我们将使用密钥对在 Kubernetes
    中运行的应用程序服务进行敏感数据的加密。敬请期待！
- en: Further reading
  id: totrans-444
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Here is a list of articles that contain more detailed information about the
    various topics that we discussed in this chapter:'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是包含有关我们在本章中讨论的各种主题的详细信息的文章列表：
- en: '*The Raft Consensus* *Algorithm*: [https://raft.github.Io/](https://raft.github.Io/)'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Raft 共识* *算法*：[https://raft.github.Io/](https://raft.github.Io/)'
- en: '*Kubernetes* *Documentation*: [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/)'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kubernetes* *文档*：[https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/)'
- en: Questions
  id: totrans-448
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Please answer the following questions to assess your learning progress:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 请回答以下问题以评估您的学习进度：
- en: What is the high-level architecture of a Kubernetes cluster?
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes 集群的高层次架构是什么？
- en: Explain in a few short sentences what the role of a Kubernetes master is.
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用几句话简要解释 Kubernetes master 的角色。
- en: List the elements that need to be present on each Kubernetes (worker) node.
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出每个 Kubernetes（工作节点）节点上需要具备的元素。
- en: We cannot run individual containers in a Kubernetes cluster.
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们无法在 Kubernetes 集群中运行单独的容器。
- en: 'True'
  id: totrans-454
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确
- en: 'False'
  id: totrans-455
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误
- en: What are the three main characteristics of a Kubernetes pod?
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes pod 的三个主要特性是什么？
- en: Explain the reason why the containers in a pod can use `localhost` to communicate
    with each other.
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释为什么 pod 中的容器可以使用 `localhost` 相互通信。
- en: What is the purpose of the so-called `pause` container in a pod?
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: pod 中所谓的 `pause` 容器的作用是什么？
- en: 'Bob tells you, “Our application consists of three Docker images: `web`, `inventory`,
    and `db`. Since we can run multiple containers in a Kubernetes pod, we are going
    to deploy all the services of our application in a single pod.” List three to
    four reasons why this is a bad idea.'
  id: totrans-459
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bob 告诉你：“我们的应用程序由三个 Docker 镜像组成：`web`、`inventory` 和 `db`。由于我们可以在 Kubernetes
    pod 中运行多个容器，所以我们打算将应用程序的所有服务部署到一个 pod 中。”列出三到四个原因，解释为什么这是一个不好的主意。
- en: Explain in your own words why we need Kubernetes ReplicaSets.
  id: totrans-460
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用您自己的话解释为什么我们需要 Kubernetes ReplicaSets。
- en: Under what circumstances do we need Kubernetes Deployments?
  id: totrans-461
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在什么情况下我们需要 Kubernetes Deployments？
- en: What are the main responsibilities of a Kubernetes Service?
  id: totrans-462
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes 服务的主要职责是什么？
- en: List at least three types of Kubernetes Services and explain their purposes
    and their differences.
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出至少三种 Kubernetes 服务类型，并解释它们的目的及其差异。
- en: How do you create a Kubernetes Service to expose an application service internally
    within the cluster?
  id: totrans-464
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何创建一个 Kubernetes 服务，将应用程序服务内部暴露在集群中？
- en: Answers
  id: totrans-465
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 答案
- en: 'Here are some sample answers to the questions presented in this chapter:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是本章中提出问题的一些示例答案：
- en: A Kubernetes cluster consists of a control plane (Kubernetes Master) and several
    worker nodes. The control plane is responsible for maintaining the desired state
    of the cluster, such as which applications are running and which container images
    they use. Worker nodes are the servers where applications are deployed and run.
  id: totrans-467
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes 集群由控制平面（Kubernetes Master）和多个工作节点组成。控制平面负责维持集群的期望状态，例如正在运行的应用程序和它们使用的容器镜像。工作节点是应用程序部署和运行的服务器。
- en: The Kubernetes master is responsible for managing the cluster. All requests
    to create objects, reschedule pods, manage ReplicaSets, and more happen on the
    master. The master does not run the application workload in a production or production-like
    cluster.
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes master 负责管理集群。所有创建对象、重新调度 Pod、管理 ReplicaSet 等请求都发生在 master 上。master
    不在生产环境或类似生产环境的集群中运行应用程序工作负载。
- en: On each worker node, we have the kubelet, the proxy, and container runtime.
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个工作节点上，我们有 kubelet、代理和容器运行时。
- en: The answer is *A. True*. You cannot run standalone containers on a Kubernetes
    cluster. Pods are the atomic units of Deployment in such a cluster.
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案是 *A. 正确*。你不能在 Kubernetes 集群上运行独立的容器。Pod 是该集群中部署的最小单元。
- en: 'A Kubernetes pod is the smallest deployable unit in Kubernetes. It can run
    one or multiple co-located containers. Here are three main characteristics:'
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes Pod 是 Kubernetes 中最小的可部署单元。它可以运行一个或多个共址的容器。以下是三个主要特点：
- en: A pod can encapsulate multiple containers that are tightly coupled and need
    to share resources.
  id: totrans-472
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个 Pod 可以封装多个紧密耦合且需要共享资源的容器。
- en: All containers in a pod share the same network namespace, meaning they can communicate
    with each other using `localhost`.
  id: totrans-473
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pod 中的所有容器共享相同的网络命名空间，这意味着它们可以使用 `localhost` 相互通信。
- en: Each pod has a unique IP address within the cluster.
  id: totrans-474
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个 Pod 在集群内都有一个独特的 IP 地址。
- en: All containers running inside a pod share the same Linux kernel network namespace.
    Thus, all processes running inside those containers can communicate with each
    other through `localhost` in a similar way to how processes or applications directly
    running on the host can communicate with each other through `localhost`.
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有在 Pod 内运行的容器共享相同的 Linux 内核网络命名空间。因此，这些容器内运行的所有进程可以通过 `localhost` 互相通信，类似于在主机上直接运行的进程或应用程序如何通过
    `localhost` 进行通信。
- en: The `pause` container’s sole role is to reserve the namespaces of the pod for
    containers that run in it.
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`pause` 容器的唯一作用是为在 Pod 中运行的容器保留命名空间。'
- en: This is a bad idea since all containers of a pod are co-located, which means
    they run on the same cluster node. Also, if multiple containers run in the same
    pod, they can only be scaled up or down all at once. However, the different components
    of the application (that is, `web`, `inventory`, and `db`) usually have very different
    requirements concerning scalability or resource consumption. The `web` component
    might need to be scaled up and down depending on the traffic and the `db` component,
    in turn, has special requirements regarding storage that the others don’t have.
    If we do run every component in its own pod, we are much more flexible in this
    regard.
  id: totrans-477
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一个不好的想法，因为一个 Pod 的所有容器是共址的，这意味着它们运行在同一个集群节点上。而且，如果多个容器运行在同一个 Pod 中，它们只能一起扩展或缩减。然而，应用程序的不同组件（即
    `web`、`inventory` 和 `db`）通常在可扩展性或资源消耗方面有非常不同的需求。`web` 组件可能需要根据流量进行扩展和缩减，而 `db`
    组件则有其他组件没有的存储特殊需求。如果我们将每个组件都运行在各自的 Pod 中，我们在这方面会更具灵活性。
- en: We need a mechanism to run multiple instances of a pod in a cluster and make
    sure that the actual number of pods running always corresponds to the desired
    number, even when individual pods crash or disappear due to network partitions
    or cluster node failures. The ReplicaSet is the mechanism that provides scalability
    and self-healing to any application service.
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要一种机制来在集群中运行多个 Pod 实例，并确保实际运行的 Pod 数量始终与期望数量相符，即使个别 Pod 由于网络分区或集群节点故障而崩溃或消失。ReplicaSet
    是提供任何应用程序服务可扩展性和自愈能力的机制。
- en: We need Deployment objects whenever we want to update an application service
    in a Kubernetes cluster without causing downtime to the service. Deployment objects
    add rolling updates and rollback capabilities to ReplicaSets.
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们希望在 Kubernetes 集群中更新应用服务而不导致服务停机时，需要使用 Deployment 对象。Deployment 对象为 ReplicaSets
    增加了滚动更新和回滚功能。
- en: 'A Kubernetes Service is an abstract way to expose an application running on
    a set of pods as a network service. The main responsibilities of a Kubernetes
    service include the following:'
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes 服务是一种抽象方式，用于将运行在一组 Pods 上的应用暴露为网络服务。Kubernetes 服务的主要职责包括以下几点：
- en: Providing a stable IP address and DNS name to the set of pods, helping in the
    discovery, and allowing for load balancing
  id: totrans-481
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为一组 Pods 提供稳定的 IP 地址和 DNS 名称，帮助发现服务，并支持负载均衡。
- en: Routing network traffic to distribute it across a set of pods provides the same
    functionality
  id: totrans-482
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 路由网络流量，将其分发到一组 Pods 上，从而提供相同的功能。
- en: Allowing for the exposure of services to external clients if necessary
  id: totrans-483
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如有必要，允许将服务暴露给外部客户端。
- en: 'Kubernetes Service objects are used to make application services participate
    in Service discovery. They provide a stable endpoint to a set of pods (normally
    governed by a ReplicaSet or a Deployment). Kube services are abstractions that
    define a logical set of pods and a policy regarding how to access them. There
    are four types of Kube Services:'
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes 服务对象用于使应用服务参与服务发现。它们为一组 Pods 提供稳定的端点（通常由 ReplicaSet 或 Deployment
    管理）。Kubernetes 服务是定义逻辑 Pods 集合和访问策略的抽象。Kubernetes 服务有四种类型：
- en: '`30000` to `32767` on every cluster node.'
  id: totrans-485
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个集群节点上的 `30000` 到 `32767`。
- en: '**LoadBalancer**: This type exposes the application service externally using
    a cloud provider’s load balancer, such as ELB on AWS.'
  id: totrans-486
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LoadBalancer**：此类型通过云服务提供商的负载均衡器（如 AWS 上的 ELB）将应用服务暴露到外部。'
- en: '**ExternalName**: Used when you need to define a proxy for a cluster’s external
    service such as a database.'
  id: totrans-487
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ExternalName**：当需要为集群的外部服务（例如数据库）定义代理时使用。'
- en: To create a Kubernetes Service, you typically create a service configuration
    file (`YAML` or `JSON`) that specifies the desired service type (e.g., ClusterIP
    for internal communication), and selector labels to identify the target pods and
    the ports for network traffic. This file is then applied using the `kubectl apply`
    command. This creates a service that routes traffic across the set of pods matching
    the selector labels.
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Kubernetes 服务时，通常会创建一个服务配置文件（`YAML` 或 `JSON`），该文件指定所需的服务类型（例如，ClusterIP 用于内部通信），以及选择器标签以识别目标
    Pods 和网络流量的端口。然后使用 `kubectl apply` 命令应用此文件。这将创建一个服务，将流量路由到匹配选择器标签的 Pods。
