- en: '16'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introducing Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter introduces the current most popular container orchestrator. It
    introduces the core Kubernetes objects that are used to define and run a distributed,
    resilient, robust, and highly available application in a cluster. Finally, it
    introduces minikube as a way to locally deploy a Kubernetes application and also
    the integration of Kubernetes with Docker Desktop.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Kubernetes architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes master nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cluster nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to Play with Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes support in Docker Desktop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to pods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes ReplicaSets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Context-based routing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparing SwarmKit with Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After reading this chapter, you should have acquired the following skills:'
  prefs: []
  type: TYPE_NORMAL
- en: Drafting the high-level architecture of a Kubernetes cluster on a napkin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explaining three to four main characteristics of a Kubernetes pod
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describing the role of Kubernetes ReplicaSets in two to three short sentences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explaining the two to three main responsibilities of a Kubernetes service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a pod in minikube
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring Docker Desktop to use Kubernetes as an orchestrator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Deployment in Docker Desktop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Kubernetes Service to expose an application service internally (or
    externally) to the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, if you want to follow along with the code, you need Docker
    Desktop and a code editor—preferably Visual Studio Code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Please navigate to the folder in which you have cloned the sample repository.
    Normally, this should be `~/The-Ultimate-Docker-Container-Book`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new subfolder called `ch16` and navigate to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A complete set of sample solutions to all the examples discussed in this chapter
    can be found in the `sample-solutions/ch16` folder or directly on GitHub: [https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch16](https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch16).'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Kubernetes architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Kubernetes cluster consists of a set of servers. These servers can be VMs
    or physical servers. The latter is also called bare metal. Each member of the
    cluster can have one of two roles. It is either a Kubernetes master or a (worker)
    node. The former is used to manage the cluster, while the latter will run an application
    workload. I have put worker in parentheses since, in Kubernetes parlance, you
    only talk about a node when you’re talking about a server that runs application
    workloads. But in Docker and Swarm parlance, the equivalent is a worker node.
    I think that the notion of a worker node better describes the role of the server
    than a simple node.
  prefs: []
  type: TYPE_NORMAL
- en: In a cluster, you have a small and odd number of masters and as many worker
    nodes as needed. Small clusters might only have a few worker nodes, while more
    realistic clusters might have dozens or even hundreds of worker nodes. Technically,
    there is no limit to how many worker nodes a cluster can have. In reality, though,
    you might experience a significant slowdown in some management operations when
    dealing with thousands of nodes.
  prefs: []
  type: TYPE_NORMAL
- en: On the Kubernetes worker nodes, we run pods. This is a new concept not present
    in Docker or Docker Swarm. A pod is an atomic unit of execution on a Kubernetes
    cluster. In many cases, a pod contains a single container, but a pod can consist
    of many containers running co-located. We will describe pods in much more detail
    later in this section.
  prefs: []
  type: TYPE_NORMAL
- en: All members of the cluster need to be connected by a physical network, the so-called
    **underlay network**. Kubernetes defines one flat network for the whole cluster.
    Kubernetes does not provide any networking implementation out of the box. Instead,
    it relies on plugins from third parties.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes just defines the **Container Network Interface** (**CNI**) and leaves
    the implementation to others. The CNI is pretty simple. It states that each pod
    running in the cluster must be able to reach any other pod also running in the
    cluster without any **Network Address Translation** (**NAT**) happening in between.
    The same must be true between cluster nodes and pods, that is, applications or
    daemons running directly on a cluster node must be able to reach each pod in the
    cluster and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the high-level architecture of a Kubernetes
    cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.1 – High-level architecture diagram of Kubernetes](img/Figure_16.01_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.1 – High-level architecture diagram of Kubernetes
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram is explained as follows.
  prefs: []
  type: TYPE_NORMAL
- en: In the top box, in the middle, we have a cluster of `etcd` nodes. An `etcd`
    node is a distributed key-value store that, in a Kubernetes cluster, is used to
    store all the states of the cluster. The number of `etcd` nodes has to be odd,
    as mandated by the Raft consensus protocol, which states which nodes are used
    to coordinate among themselves. When we talk about the Cluster State, we do not
    include data that is produced or consumed by applications running in the cluster.
    Instead, we’re talking about all the information on the topology of the cluster,
    what services are running, network settings, secrets used, and more. That said,
    this `etcd` cluster is mission-critical to the overall cluster and thus, we should
    never run only a single `etcd` server in a production environment or any environment
    that needs to be highly available.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we have a cluster of Kubernetes master nodes, which also form a Consensus
    Group among themselves, similar to the `etcd` nodes. The number of master nodes
    also has to be odd. We can run clusters with a single master but we should never
    do that in a production or mission-critical system. There, we should always have
    at least three master nodes. Since the master nodes are used to manage the whole
    cluster, we are also talking about the management plane.
  prefs: []
  type: TYPE_NORMAL
- en: Master nodes use the `etcd` cluster as their backing store. It is good practice
    to put a **load balancer** (**LB**) in front of master nodes with a well-known
    **Fully Qualified Domain Name** (**FQDN**), such as [https://admin.example.com](https://admin.example.com).
    All tools that are used to manage the Kubernetes cluster should access it through
    this LB rather than using the public IP address of one of the master nodes. This
    is shown on the upper left side of the preceding diagram.
  prefs: []
  type: TYPE_NORMAL
- en: Toward the bottom of the diagram, we have a cluster of worker nodes. The number
    of nodes can be as low as one and does not have an upper limit.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes master and worker nodes communicate with each other. It is a bidirectional
    form of communication that is different from the one we know from Docker Swarm.
    In Docker Swarm, only manager nodes communicate with worker nodes and never the
    other way around. All ingress traffic accessing applications running in the cluster
    should go through another load balancer.
  prefs: []
  type: TYPE_NORMAL
- en: This is the application load balancer or reverse proxy. We never want external
    traffic to directly access any of the worker nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an idea about the high-level architecture of a Kubernetes cluster,
    let’s delve a bit more deeply and look at the Kubernetes master and worker nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes master nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes master nodes are used to manage a Kubernetes cluster. The following
    is a high-level diagram of such a master:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.2 – Kubernetes master](img/Figure_16.02_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.2 – Kubernetes master
  prefs: []
  type: TYPE_NORMAL
- en: At the bottom of the preceding diagram, we have the infrastructure, which can
    be a VM on-premises or in the cloud or a server (often called bare metal) on-premises
    or in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'Currently, Kubernetes masters only run on Linux. The most popular Linux distributions,
    such as RHEL, CentOS, and Ubuntu, are supported. On this Linux machine, we have
    at least the following four Kubernetes services running:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl` use to manage the cluster and applications in the cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Controller**: The controller, or more precisely the controller manager, is
    a control loop that observes the state of the cluster through the API server and
    makes changes, attempting to move the current or effective state toward the desired
    state if they differ.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scheduler**: The scheduler is a service that tries its best to schedule pods
    on worker nodes while considering various boundary conditions, such as resource
    requirements, policies, quality-of-service requirements, and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`etcd` that is used to store all information about the state of the cluster.
    To be more precise, `etcd`, which is used as a cluster store, does not necessarily
    have to be installed on the same node as the other Kubernetes services. Sometimes,
    Kubernetes clusters are configured to use standalone clusters of `etcd` servers,
    as shown in *Figure 16**.1*. But which variant to use is an advanced management
    decision and is outside the scope of this book.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need at least one master, but to achieve high availability, we need three
    or more master nodes. This is very similar to what we have learned about the manager
    nodes of a Docker Swarm. In this regard, a Kubernetes master is equivalent to
    a Swarm manager node.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes masters never run application workloads. Their sole purpose is to
    manage the cluster. Kubernetes masters build a Raft consensus group. The Raft
    protocol is a standard protocol used in situations where a group of members needs
    to make decisions. It is used in many well-known software products such as MongoDB,
    Docker SwarmKit, and Kubernetes. For a more thorough discussion of the Raft protocol,
    see the link in the *Further* *reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: Running workload on master
  prefs: []
  type: TYPE_NORMAL
- en: At times, specifically in development and test scenarios, it can make sense
    to work with a single-node Kubernetes cluster, which then naturally becomes a
    master and a worker node at the same time. But this scenario should be avoided
    in production.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned in the previous section, the state of the Kubernetes cluster
    is stored in an `etcd` node. If the Kubernetes cluster is supposed to be highly
    available, then the `etcd` node must also be configured in HA mode, which normally
    means that we have at least three `etcd` instances running on different nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s state once again that the whole cluster state is stored in an `etcd` node.
    This includes all the information about all the cluster nodes, all the ReplicaSets,
    Deployments, secrets, network policies, routing information, and so on. It is
    therefore crucial that we have a robust backup strategy in place for this key-value
    store.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at the nodes that will be running the actual workload of the
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Cluster nodes are the nodes with which Kubernetes schedules application workloads.
    They are the workhorses of the cluster. A Kubernetes cluster can have a few, dozens,
    hundreds, or even thousands of cluster nodes. Kubernetes has been built from the
    ground up for high scalability. Don’t forget that Kubernetes was modeled on Google
    Borg, which has run tens of thousands of containers for years:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.3 – Kubernetes worker node](img/Figure_16.03_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.3 – Kubernetes worker node
  prefs: []
  type: TYPE_NORMAL
- en: A worker node – which is a cluster node, as are the master nodes – can run on
    a VM, bare metal, on-premises, or in the cloud. Originally, worker nodes could
    only be configured on Linux. But since version 1.10 of Kubernetes, worker nodes
    can also run on Windows Server 2010 or later. It is perfectly fine to have a mixed
    cluster with Linux and Windows worker nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'On each node, we have three services that need to run, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`YAML` or `JSON` format and they declaratively describe a pod. We will get
    to know what pods are in the next section. `PodSpecs` is provided to Kubelet primarily
    through the API server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`containerd` since version 1.9 as its container runtime. Prior to that, it
    used the Docker daemon. Other container runtimes, such as `rkt` or `CRI-O`, can
    be used. The container runtime is responsible for managing and running the individual
    containers of a pod.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kube-proxy**: Finally, there is kube-proxy. It runs as a daemon and is a
    simple network proxy and load balancer for all application services running on
    that particular node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have learned about the architecture of Kubernetes and the master
    and worker nodes, it is time to introduce the tooling that we can use to develop
    applications targeted at Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Play with Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Play with Kubernetes is a free playground sponsored by Docker, where users
    can learn how to use Docker containers and deploy them to Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to [https://labs.play-with-k8s.com/](https://labs.play-with-k8s.com/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in using your GitHub or Docker credentials.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once successfully logged in, create a first cluster node or instance by clicking
    the **+ ADD NEW INSTANCE** button on the left side of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Follow the instructions on the screen to create a first master node for your
    Kubernetes sandbox cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Initialize the cluster master node with the command as indicated in *step 1*
    of the instructions in the terminal window. It’s best if you directly copy the
    command from there. It should look like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The first command argument uses the name of the host to advertise the address
    of the Kubernetes API server and the second one defines the subnet the cluster
    is supposed to use.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, as indicated in Point 2 of the instructions in the console, initialize
    networking in our Kubernetes cluster (note, the following command should be on
    a single line):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create a second cluster node by again clicking the **ADD NEW** **INSTANCE**
    button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the node is ready, run the `join` command that was output during *step
    4*, where `<token-1>` and `<token-2>` are specific to your cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It is best if you just copy the correct command from your command line in Play
    with Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the second node has joined the cluster, run the following command on the
    first node, where you initialized the cluster, to list the set of nodes in your
    new cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output should look similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note how Play with Kubernetes, at the time of writing, uses version 1.20.1 of
    Kubernetes, which even now is a rather old version. The latest stable version
    available is currently 1.27.x. But worry not; for our example version, 1.20.x,
    is enough.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s try to deploy a pod to this cluster. Don’t worry about what a *pod*
    is for now; we will delve into all the details about it later in this chapter.
    For the moment, just take it as is.
  prefs: []
  type: TYPE_NORMAL
- en: 'In your chapter code folder, create a new file called `sample-pod.yaml` and
    add the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, to run the aforementioned pod on Play with Kubernetes, we need to copy
    the content of the preceding `yaml` file and create a new file on `node1` of our
    cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use `vi` to create a new file called `sample-pod.yaml`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hit *I* (the letter “i”) to switch into the insert mode of `vi`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste the copied code snippet with *Ctrl* + *V* (or *Command* + *V* on a Mac)
    into this file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Press *Esc* to go into the command mode of `vi`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Input `:wq` and hit *Enter* to save the file and quit `vi`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: 'Why are we using the Vi editor in our examples? It’s the editor that is installed
    on any Linux (or Unix) distribution and is thus always available. You can find
    a quick tutorial for the Vi editor here: [https://www.tutorialspoint.com/unix/unix-vi-editor.htm](https://www.tutorialspoint.com/unix/unix-vi-editor.htm).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s use the Kubernetes CLI called `kubectl` to deploy this pod. The `kubectl`
    CLI is already installed on each of the cluster nodes of your Play with Kubernetes
    cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Doing so results in this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we list all of the pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'To be able to access this pod, we need to create a Service. Let’s use the `sample-service.yaml`
    file, which has the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Again, don’t worry about what exactly a *Service* is at this time. We’ll explain
    this later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s just create this Service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now let’s see what Kubernetes created and list all Services defined on the
    cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should see something similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.4 – List of services](img/Figure_16.04_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.4 – List of services
  prefs: []
  type: TYPE_NORMAL
- en: Please note the `PORT(S)` column. In my case, Kubernetes mapped the `80` container
    port of Nginx to the `31384` node port. We will use this port in the next command.
    Make sure you use the port number assigned on your system instead!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can use `curl` to access the service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We should receive the Nginx welcome page as an answer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you continue, please remove the two objects you just created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that in the aforementioned commands, the `po` shortcut is equivalent to
    `pod` or `pods`. The `kubectl` tool is very flexible and allows such abbreviations.
    Similarly, `svc` is a shortcut for `service` or `services`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we are going to use Docker Desktop and its support for
    Kubernetes to run the same pod and service as we did in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes support in Docker Desktop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Starting from version 18.01-ce, Docker Desktop started to support Kubernetes
    out of the box. Developers who want to deploy their containerized applications
    to Kubernetes can use this orchestrator instead of SwarmKit. Kubernetes support
    is turned off by default and has to be enabled in the settings. The first time
    Kubernetes is enabled, Docker Desktop will need a moment to download all the components
    that are needed to create a single-node Kubernetes cluster. Contrary to minikube,
    which is also a single-node cluster, the version provided by the Docker tools
    uses **containerized** versions of all Kubernetes components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.5 – Kubernetes support in Docker Desktop](img/Figure_16.05_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.5 – Kubernetes support in Docker Desktop
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding diagram gives us a rough overview of how Kubernetes support has
    been added to Docker Desktop. Docker Desktop for macOS uses hyperkit to run a
    LinuxKit-based VM. Docker Desktop for Windows uses Hyper-V to achieve the result.
    Inside the VM, Docker Engine is installed. Part of the engine is SwarmKit, which
    enables Swarm mode. Docker Desktop uses the `kubeadm` tool to set up and configure
    Kubernetes in that VM. The following three facts are worth mentioning: Kubernetes
    stores its cluster state in `etcd`; thus, we have `etcd` running on this VM. Then,
    we have all the services that make up Kubernetes and, finally, some services that
    support the Deployment of Docker stacks from the Docker CLI into Kubernetes. This
    Service is not part of the official Kubernetes distribution, but it is Docker-specific.'
  prefs: []
  type: TYPE_NORMAL
- en: All Kubernetes components run in containers in the LinuxKit VM. These containers
    can be hidden through a setting in Docker Desktop. Later in this section, we’ll
    provide a complete list of Kubernetes system containers that will be running on
    your laptop, if you have Kubernetes support enabled.
  prefs: []
  type: TYPE_NORMAL
- en: One big advantage of Docker Desktop with Kubernetes enabled over minikube is
    that the former allows developers to use a single tool to build, test, and run
    a containerized application targeted at Kubernetes. It is even possible to deploy
    a multi-service application into Kubernetes using a Docker Compose file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s get our hands dirty:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we have to enable Kubernetes. On macOS, click on the Docker icon in
    the menu bar. On Windows, go to the command tray and select **Preferences**. In
    the dialog box that opens, select **Kubernetes**, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.6 – Enabling Kubernetes in Docker Desktop](img/Figure_16.06_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.6 – Enabling Kubernetes in Docker Desktop
  prefs: []
  type: TYPE_NORMAL
- en: Then, tick the **Enable Kubernetes** checkbox. Also, tick the **Show system
    containers (****advanced)** checkboxes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, click the **Apply & restart** button. Installing and configuring Kubernetes
    takes a few minutes. It’s time to take a break and enjoy a nice cup of tea.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the installation is finished (which Docker notifies us of by showing a
    green status icon in the `kubectl` to access the latter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, let’s list all the contexts that we have. We can use the following command
    for this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the case of the author’s laptop, we get this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.7 – List of contexts for kubectl](img/Figure_16.07_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.7 – List of contexts for kubectl
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that, on the author’s laptop, we have three contexts, two of
    them stemming from his use of `kind`. Currently, the `kind` context with the `kind-demo`
    name is still active, flagged by the asterisk in the `CURRENT` column.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can switch to the `docker-desktop` context using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Doing so results in this ouput:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can use `kubectl` to access the cluster that Docker Desktop just created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should see something simliar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: OK, this looks very familiar. It is pretty much the same as what we saw when
    working with Play with Kubernetes. The version of Kubernetes that the author’s
    Docker Desktop is using is 1.25.9\. We can also see that the node is a `master`
    node, indicated by the role `control-plane`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we list all the containers that are currently running on our Docker Desktop,
    we get the list shown in the following screenshot (note that we use the `--format`
    argument to output the container ID and names of the containers):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.8 – List of Kubernetes system containers](img/Figure_16.08_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.8 – List of Kubernetes system containers
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding list, we can identify all the now-familiar components that
    make up Kubernetes, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: API server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`etcd`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-proxy`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DNS service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-controller`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-scheduler`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normally, we don’t want to clutter our list of containers with these system
    containers. Therefore, we can uncheck the **Show system containers (advanced)**
    checkbox in the settings for Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s try to deploy a Docker Compose application to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the `ch16` subfolder of our `~/``The-Ultimate-Docker-Container-Book`
    folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Copy the `docker-compose.yml` file from the sample solutions to this location:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install the `kompose` tool on your machine by following the instructions on
    https://kompose.io/installation/:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On a Mac, it can be installed using `$ brew` `install kompose`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: On Windows, use `$ choco` `install kubernetes-kompose`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Run the `kompose` tool as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The tool should create four files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`db-deployment.yaml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pets-data-persistentvolumeclaim.yaml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`web-deployment.yaml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`web-service.yaml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Open the `web-service.yaml` file and after line 11 (the `spec` entry), add
    the `NodePort` entry type so that it looks as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we can use `kubectl` to deploy these four resources to our Kubernetes cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should see this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to find out to which host port Kubernetes has mapped the `3000` service
    port. Use the following command for this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should see something similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: In my case, we can see that the service web has the `3000` port mapped to the
    `32134` host (or node) port. In the following command, I have to use that port.
    In your case, the number likely will be different. Use the number you are getting
    from the previous command!
  prefs: []
  type: TYPE_NORMAL
- en: 'We can test the application using `curl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will see that it is running as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.9 – Pets application running in Kubernetes on Docker Desktop](img/Figure_16.09_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.9 – Pets application running in Kubernetes on Docker Desktop
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s see exactly what resources we have on Kubernetes after the previous
    Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use `kubectl` to find out:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This gives us this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.10 – Listing all Kubernetes objects created by Docker stack deploy](img/Figure_16.10_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.10 – Listing all Kubernetes objects created by Docker stack deploy
  prefs: []
  type: TYPE_NORMAL
- en: Docker created a Deployment for the `web` service and `db` service. It also
    automatically created a Kubernetes service for `web` so that it can be accessed
    inside the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: This is pretty cool, to say the least, and tremendously decreases friction in
    the development process for teams targeting Kubernetes as their orchestration
    platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you continue, please remove the stack from the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have had an introduction to the tools we can use to develop applications
    that will eventually run in a Kubernetes cluster, it is time to learn about all
    the important Kubernetes objects that are used to define and manage such an application.
    We will start with pods.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to pods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Contrary to what is possible in Docker Swarm, you cannot run containers directly
    in a Kubernetes cluster. In a Kubernetes cluster, you can only run pods. **Pods**
    are the atomic units of Deployment in Kubernetes. A pod is an abstraction of one
    or many co-located containers that share the same kernel namespaces, such as the
    network namespace. No equivalent exists in Docker SwarmKit. The fact that more
    than one container can be co-located and shared with the same network namespace
    is a very powerful concept. The following diagram illustrates two pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.11 – Kubernetes pods](img/Figure_16.11_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.11 – Kubernetes pods
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, we have two pods, `10.0.12.3` and `10.0.12.5`. Both
    are part of a private subnet managed by the Kubernetes network driver.
  prefs: []
  type: TYPE_NORMAL
- en: A pod can contain one or many containers. All those containers share the same
    Linux kernel namespaces, and in particular, they share the network namespace.
    This is indicated by the dashed rectangle surrounding the containers. Since all
    containers running in the same pod share the network namespace, each container
    needs to make sure to use its own port since duplicate ports are not allowed in
    a single network namespace. In this case, in Pod 1, the main container is using
    the `80` port while the supporting container is using the `3000` port.
  prefs: []
  type: TYPE_NORMAL
- en: Requests from other pods or nodes can use the pod’s IP address combined with
    the corresponding port number to access the individual containers. For example,
    you could access the application running in the main container of Pod 1 through
    `10.0.12.3:80`.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing Docker container and Kubernetes pod networking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s compare Docker’s container networking and Kubernetes pod networking.
    In the following diagram, we have Docker on the left-hand side and Kubernetes
    on the right-hand side:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.12 – Containers in a pod sharing the same network namespace](img/Figure_16.12_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.12 – Containers in a pod sharing the same network namespace
  prefs: []
  type: TYPE_NORMAL
- en: When a Docker container is created and no specific network is specified, then
    Docker Engine creates a virtual ethernet (`veth`) endpoint. The first container
    gets `veth0`, the next one gets `veth1`, and so on. These virtual ethernet endpoints
    are connected to the Linux bridge, `docker0`, that Docker automatically creates
    upon installation. Traffic is routed from the `docker0` bridge to every connected
    `veth` endpoint. Every container has its own network namespace. No two containers
    use the same namespace. This is on purpose, to isolate applications running inside
    the containers from each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a Kubernetes pod, the situation is different. When creating a new pod,
    Kubernetes first creates a so-called `pause` container, the purpose of which is
    to create and manage the namespaces that the pod will share with all containers.
    Other than that, it does nothing useful; it is just sleeping. The `pause` container
    is connected to the `docker0` bridge through `veth0`. Any subsequent container
    that will be part of the pod uses a special feature of Docker Engine that allows
    it to reuse an existing network namespace. The syntax to do so looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The important part is the `--net` argument, which uses `container:<container
    name>` as a value. If we create a new container this way, then Docker does not
    create a new `veth` endpoint; the container uses the same one as the pause container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important consequence of multiple containers sharing the same network
    namespace is the way they communicate with each other. Let’s consider the following
    situation: a pod containing two containers, one listening at the `80` port and
    the other at the `3000` port:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.13 – Containers in pods communicating via localhost](img/Figure_16.13_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.13 – Containers in pods communicating via localhost
  prefs: []
  type: TYPE_NORMAL
- en: When two containers use the same Linux kernel network namespace, they can communicate
    with each other through `localhost`, similarly to how, when two processes are
    running on the same host, they can communicate with each other through `localhost`
    too.
  prefs: []
  type: TYPE_NORMAL
- en: This is illustrated in the preceding diagram. From the `main` container, the
    containerized application inside it can reach out to the service running inside
    the supporting container through http://localhost:3000.
  prefs: []
  type: TYPE_NORMAL
- en: Sharing the network namespace
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After all this theory, you might be wondering how a pod is actually created
    by Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes only uses what Docker provides. So, how does this network namespace
    share work? First, Kubernetes creates the so-called `pause` container, as mentioned
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'This container has no other function than to reserve the kernel namespaces
    for that pod and keep them alive, even if no other container inside the pod is
    running. Let’s simulate the creation of a pod, then. We start by creating the
    pause container and use Nginx for this purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we add a second container called `main` and attach it to the same network
    namespace as the pause container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the `pause` and sample `containers` are both parts of the same network
    namespace, they can reach each other through `localhost`. To show this, we have
    to exec into the main container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can test the connection to Nginx running in the pause container and
    listening on the `80` port. The following is what we get if we use the `wget`
    utility to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Doing so gives us this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.14 – Two containers sharing the same network namespace](img/Figure_16.14_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.14 – Two containers sharing the same network namespace
  prefs: []
  type: TYPE_NORMAL
- en: 'The output shows that we can indeed access Nginx on `localhost`. This is proof
    that the two containers share the same namespace. If that is not enough, we can
    use the `ip` tool to show `eth0` inside both containers and we will get the exact
    same result, specifically, the same IP address, which is one of the characteristics
    of a pod; all its containers share the same IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.15 – Displaying the properties of eth0 with the ip tool](img/Figure_16.15_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.15 – Displaying the properties of eth0 with the ip tool
  prefs: []
  type: TYPE_NORMAL
- en: 'We inspect the `bridge` network with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we can see that only the pause container is listed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The preceding output has been shortened for readability.
  prefs: []
  type: TYPE_NORMAL
- en: The main container didn’t get an entry in the `Containers` list since it is
    reusing the `pause` container’s endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you continue, please remove the two `pause` and `main` containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will be looking at the pod life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Pod life cycle
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Earlier in this book, we learned that containers have a life cycle. A container
    is initialized, run, and ultimately exited. When a container exits, it can do
    this gracefully with an exit code zero or it can terminate with an error, which
    is equivalent to a non-zero exit code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, a pod has a life cycle. Because a pod can contain more than one
    container, this life cycle is slightly more complicated than that of a single
    container. The life cycle of a pod can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.16 – The life cycle of Kubernetes pods](img/Figure_16.16_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.16 – The life cycle of Kubernetes pods
  prefs: []
  type: TYPE_NORMAL
- en: When a pod is created on a cluster node, it first enters the *pending* status.
    Once all the containers of the pod are up and running, the pod enters the *running*
    status. The pod only enters into this state if all its containers run successfully.
    If the pod is asked to terminate, it will request all its containers to terminate.
    If all containers terminate with exit code zero, then the pod enters into the
    *succeeded* status. This is the happy path.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s look at some scenarios that lead to the pod being in a *failed*
    state. There are three possible scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: If, during the startup of the pod, at least one container is not able to run
    and fails (that is, it exits with a nonzero exit code), the pod goes from the
    *pending* state into the failed state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the pod is in the *running* status and one of the containers suddenly crashes
    or exits with a nonzero exit code, then the pod transitions from the *running*
    state into the *failed* state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the pod is asked to terminate and, during the shutdown, at least one of the
    containers, exits with a nonzero exit code, then the pod also enters into the
    *failed* state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s look at the specifications for a pod.
  prefs: []
  type: TYPE_NORMAL
- en: Pod specifications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When creating a pod in a Kubernetes cluster, we can use either an imperative
    or a declarative approach. We discussed the difference between the two approaches
    earlier in this book but, to rephrase the most important aspect, using a declarative
    approach signifies that we write a manifest that describes the end state we want
    to achieve. We’ll leave out the details of the orchestrator. The end state that
    we want to achieve is also called the desired state. In general, the declarative
    approach is strongly preferred in all established orchestrators, and Kubernetes
    is no exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, in this chapter, we will exclusively concentrate on the declarative approach.
    Manifests or specifications for a pod can be written using either the `YAML` or
    `JSON` formats. In this chapter, we will concentrate on `YAML` since it is easier
    to read for us humans. Let’s look at a sample specification. Here is the content
    of the `pod.yaml` file, which can be found in the `ch16` subfolder of our `labs`
    folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Each specification in Kubernetes starts with the version information. Pods have
    been around for quite some time and thus the API version is `v1`. The second line
    specifies the type of Kubernetes object or resource we want to define. Obviously,
    in this case, we want to specify a pod. Next follows a block containing metadata.
    At a bare minimum, we need to give the pod a name. Here, we call it `web-pod`.
    The next block that follows is the `spec` block, which contains the specification
    of the pod. The most important part (and the only one in this simple sample) is
    a list of all containers that are part of this pod. We only have one container
    here, but multiple containers are possible. The name we chose for our container
    is `web` and the container image is `nginx:alpine`. Finally, we define a list
    of ports the container is exposing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have authored such a specification, we can apply it to the cluster
    using the Kubernetes CLI, `kubectl`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new terminal window and navigate to the `ch16` subfolder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In this example, we’re going to use Docker Desktop’s Kubernetes cluster. Thus,
    make sure that you are using the right context for the `kubectl` CLI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will switch the context to our Kubernetes cluster provided by Docker Desktop.
  prefs: []
  type: TYPE_NORMAL
- en: In this folder, create a new file called `pod.yml` and add the mentioned pod
    specification to it. Save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will respond with `pod "``web-pod" created`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then list all the pods in the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Doing so will provide us with this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: As expected, we have one of one pod in the `Running` state. The pod is called
    `web-pod`, as defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can get more detailed information about the running pod by using the `describe`
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This gives us something similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.17 – Describing a pod running in the cluster](img/Figure_16.17_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.17 – Describing a pod running in the cluster
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The `pod/web-pod` notation in the previous section includes the `describe` command.
    Other variants are possible. For example, `pods/web-pod`, `po/web-pod`, `pod`,
    and `po` are aliases of `pods`.
  prefs: []
  type: TYPE_NORMAL
- en: The `kubectl` tool defines many aliases to make our lives a bit easier.
  prefs: []
  type: TYPE_NORMAL
- en: The `describe` command gives us a plethora of valuable information about the
    pod, not the least of which is a list of events that happened and affected this
    pod. The list is shown at the end of the output.
  prefs: []
  type: TYPE_NORMAL
- en: The information in the `Containers` section is very similar to what we find
    in a `docker container` `inspect` output.
  prefs: []
  type: TYPE_NORMAL
- en: We can also see a `Volumes` section with a `Projected` entry type. It contains
    the root certificate of the cluster as a secret. We will discuss Kubernetes secrets
    in the next chapter. Volumes, on the other hand, will be discussed next.
  prefs: []
  type: TYPE_NORMAL
- en: Pods and volumes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the chapter about containers, we learned about volumes and their purpose:
    accessing and storing persistent data. Since containers can mount volumes, pods
    can do so as well. In reality, it is really the containers inside the pod that
    mount the volumes, but that is just a semantic detail. First, let’s see how we
    can define a volume in Kubernetes. Kubernetes supports a plethora of volume types,
    so we won’t delve into too much detail about this.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s just create a local volume implicitly by defining a `PersistentVolumeClaim`
    claim called `my-data-claim`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file called `volume-claim.yaml` and add the following specification
    to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We have defined a claim that requests 2 GB of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create this claim:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will resulting in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'We can list the claim using `kubectl` (`pvc` is a shortcut for `PersistentVolumeClaim`)
    with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This gives us this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.18 – List of PersistentStorageClaim objects in the cluster](img/Figure_16.18_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.18 – List of PersistentStorageClaim objects in the cluster
  prefs: []
  type: TYPE_NORMAL
- en: In the output, we can see that the claim has implicitly created a volume called
    `pvc-<ID>`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remove the pod before you continue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Alternatively, use the original file defining the pod with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now ready to use the volume created by the claim in a pod. Let’s use
    a modified version of the pod specification that we used previously:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file called `pod-with-vol.yaml` and add the following specification
    to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the last four lines, in the `volumes` block, we define a list of volumes
    we want to use for this pod. The volumes that we list here can be used by any
    of the containers of the pod. In our particular case, we only have one volume.
    We specify that we have a volume called `my-data`, which is a persistent volume
    claim whose claim name is the one we just created.
  prefs: []
  type: TYPE_NORMAL
- en: Then, in the container specification, we have the `volumeMounts` block, which
    is where we define the volume we want to use and the (absolute) path inside the
    container where the volume will be mounted. In our case, we mount the volume to
    the `/data` folder of the container filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create this pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can also use the declarative way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can `exec` into the container to double-check that the volume has
    mounted by navigating to the `/data` folder, creating a file there, and exiting
    the container using:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If we are right, then the data in this container must persist beyond the life
    cycle of the pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, let’s delete the pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we’ll recreate it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We’ll then `exec` into the container of the pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we output the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This is the output produced by the preceding command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: It is what we expected.
  prefs: []
  type: TYPE_NORMAL
- en: Exit the container by pressing *Ctrl* + *D*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete the pod and the persistent volume claim before you continue. By now,
    you should know the command to do so. Otherwise, have a look back at *step 4*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have a good understanding of pods, let’s investigate how those pods
    are managed with the help of ReplicaSets.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes ReplicaSets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A single pod in an environment with high availability requirements is insufficient.
    What if the pod crashes? What if we need to update the application running inside
    the pod but cannot afford any service interruption? These questions and more indicate
    that pods alone are not enough, and we need a higher-level concept that can manage
    multiple instances of the same pod. In Kubernetes, the ReplicaSet is used to define
    and manage such a collection of identical pods that are running on different cluster
    nodes. Among other things, a ReplicaSet defines which container images are used
    by the containers running inside a pod and how many instances of the pod will
    run in the cluster. These properties and many others are called the **desired
    state**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ReplicaSet is responsible for reconciling the desired state at all times
    if the actual state ever deviates from it. Here is a Kubernetes ReplicaSet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.19 – Kubernetes ReplicaSet](img/Figure_16.19_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.19 – Kubernetes ReplicaSet
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, we can see a ReplicaSet that governs a number of pods.
    The pods are called `pod-api`. The ReplicaSet is responsible for making sure that,
    at any given time, there is always the desired number of pods running. If one
    of the pods crashes for whatever reason, the ReplicaSet schedules a new pod on
    a node with free resources instead. If there are more pods than the desired number,
    then the ReplicaSet kills superfluous pods. With this, we can say that the ReplicaSet
    guarantees a self-healing and scalable set of pods. There is no limit to how many
    pods a ReplicaSet can hold.
  prefs: []
  type: TYPE_NORMAL
- en: ReplicaSet specification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Similar to what we have learned about pods, Kubernetes also allows us to either
    imperatively or declaratively define and create a ReplicaSet. Since the declarative
    approach is by far the most recommended one in most cases, we’re going to concentrate
    on this approach. Let’s work with a sample specification for a Kubernetes ReplicaSet:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new file called `replicaset.yaml` and add the following content to
    it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This looks an awful lot like the pod specification we introduced earlier. Let’s
    concentrate on the differences, then. First, on line 2, we have the kind, which
    was a pod, and is now `ReplicaSet`. Then, on lines 6–8, we have a selector, which
    determines the pods that will be part of the ReplicaSet. In this case, it is all
    the pods that have `app` as a label with the value `web`. Then, on line 9, we
    define how many replicas of the pod we want to run; three, in this case. Finally,
    we have the `template` section, which first defines the metadata, and then the
    spec, which defines the containers that run inside the pod. In our case, we have
    a single container using the `nginx:alpine` image and exporting `80` port.
  prefs: []
  type: TYPE_NORMAL
- en: The really important elements are the number of replicas and the selector, which
    specifies the set of pods governed by the ReplicaSet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use this file to create the ReplicaSet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we list all the ReplicaSets in the cluster (`rs` is a shortcut for ReplicaSet):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding output, we can see that we have a single ReplicaSet called
    `rs-web`, the desired state of which is three (pods). The current state also shows
    three pods and tells us that all three pods are ready.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also list all the pods in the system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Here we can see our three expected pods. The names of the pods use the `ReplicaSet`
    name with a unique ID appended for each pod. In the `READY` column, we can see
    how many containers have been defined in the pod and how many of them are ready.
    In our case, we only have a single container per pod and, in each case, it is
    ready. Thus, the overall status of the pod is `Running`. We can also see how many
    times each pod had to be restarted. In our case, we don’t have any restarts.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s see how the ReplicaSet helps us with self-healing.
  prefs: []
  type: TYPE_NORMAL
- en: Self-healing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s test the magic powers of the self-healing ReplicaSet by randomly
    killing one of its pods and observing what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s delete the first pod from the previous list. Make sure to replace the
    name of the pod (`rs-web-nbc8m`) with the name you have in your own example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The previous command produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s list all the pods again. We expect to see only two pods, right?
    You’re wrong:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: OK. Evidently, the first pod in the list has been recreated, as we can see from
    the `AGE` column. This is auto-healing in action.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see what we discover if we describe the ReplicaSet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will give us this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.20 – Describe the ReplicaSet](img/Figure_16.20_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.20 – Describe the ReplicaSet
  prefs: []
  type: TYPE_NORMAL
- en: And indeed, we find an entry under `Events` that tells us that the ReplicaSet
    created a new pod called `rs-web-4r587`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you continue, please delete the ReplicaSet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now it’s time to talk about the Kubernetes Deployment object.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes takes the single-responsibility principle very seriously. All Kubernetes
    objects are designed to do one thing and one thing only, and they are designed
    to do this one thing very well. In this regard, we must understand Kubernetes
    ReplicaSets and Deployments. A ReplicaSet, as we have learned, is responsible
    for achieving and reconciling the desired state of an application service. This
    means that the ReplicaSet manages a set of pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'A **Deployment** augments a ReplicaSet by providing rolling updates and rollback
    functionality on top of it. In Docker Swarm, the Swarm service incorporates the
    functionality of both a ReplicaSet and Deployment. In this regard, SwarmKit is
    much more monolithic than Kubernetes. The following diagram shows the relationship
    of a Deployment to a ReplicaSet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.21 – Kubernetes Deployment](img/Figure_16.21_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.21 – Kubernetes Deployment
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, the ReplicaSet defines and governs a set of identical
    pods. The main characteristics of the ReplicaSet are that it is self-healing,
    scalable, and always does its best to reconcile the desired state. The Kubernetes
    Deployment, in turn, adds rolling updates and rollback functionality to this.
    In this regard, a Deployment is a wrapper object for a ReplicaSet.
  prefs: []
  type: TYPE_NORMAL
- en: We will learn more about rolling updates and rollbacks in [*Chapter 17*](B19199_17.xhtml#_idTextAnchor374),
    *Deploying, Updating, and Securing an Application* *with Kubernetes*.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn more about Kubernetes services and how they
    enable service discovery and routing.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The moment we start to work with applications consisting of more than one application
    service, we need service discovery. The following diagram illustrates this problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.22 – Service discovery](img/Figure_16.22_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.22 – Service discovery
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding diagram, we have a `Web API` service that needs access to
    three other services: `payments`, `shipping`, and `ordering`. The `Web API` service
    should never have to care about how and where to find those three services. In
    the API code, we just want to use the name of the service we want to reach and
    its port number. A sample would be the following URL, [http://payments:3000](http://payments:3000),
    which is used to access an instance of the `payments` service.'
  prefs: []
  type: TYPE_NORMAL
- en: In Kubernetes, the payments application service is represented by a ReplicaSet
    of pods. Due to the nature of highly distributed systems, we cannot assume that
    pods have stable endpoints. A pod can come and go on a whim. But that’s a problem
    if we need to access the corresponding application service from an internal or
    external client. If we cannot rely on pod endpoints being stable, what else can
    we do?
  prefs: []
  type: TYPE_NORMAL
- en: 'This is where **Kubernetes Services** come into play. They are meant to provide
    stable endpoints to ReplicaSets or Deployments, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.23 – Kubernetes service providing stable endpoints to clients](img/Figure_16.23_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.23 – Kubernetes service providing stable endpoints to clients
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, in the center, we can see such a Kubernetes Service.
    It provides a reliable cluster-wide IP address, also called a `app=web`; that
    is, all pods that have a label called `app` with a value of `web` are proxied.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn more about context-based routing and how
    Kubernetes alleviates this task.
  prefs: []
  type: TYPE_NORMAL
- en: Context-based routing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Often, we want to configure context-based routing for our Kubernetes cluster.
    Kubernetes offers us various ways to do this. The preferred and most scalable
    way currently is to use IngressController. The following diagram tries to illustrate
    how this ingress controller works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.24 – Context-based routing using a Kubernetes ingress controller](img/Figure_16.24_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.24 – Context-based routing using a Kubernetes ingress controller
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding diagram, we can see how context-based (or layer 7) routing
    works when using an IngressController, such as Nginx. Here, we have the Deployment
    of an application service called `web`. All the pods of this application service
    have the following label: `app=web`. Then, we have a Kubernetes Service called
    `web` that provides a stable endpoint to those pods. The Service has a VIP of
    `52.14.0.13` and exposes a `30044` port. That is, if a request comes to any node
    of the Kubernetes cluster for the name `web` and `30044` port, then it is forwarded
    to this Service. The Service then load balances the request to one of the pods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, so good, but how is an ingress request from a client to the http[s]://example.com/web
    URL routed to our web service? First, we must define routing from a context-based
    request to a corresponding `<service name>/<port>` request. This is done through
    an Ingress object:'
  prefs: []
  type: TYPE_NORMAL
- en: In the Ingress object, we define the Host and Path as the source and the (service)
    name, and the port as the target. When this Ingress object is created by the Kubernetes
    API server, then a process that runs as a sidecar in IngressController picks up
    this change.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The configuration file of the Nginx reverse proxy is modified.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By adding the new route, Nginx is then asked to reload its configuration and
    thus, will be able to correctly route any incoming requests to `http[s]://example.com/web`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the next section, we are going to compare Docker SwarmKit with Kubernetes
    by contrasting some of the main resources of each orchestration engine.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing SwarmKit with Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have learned a lot of details about the most important resources
    in Kubernetes, it is helpful to compare the two orchestrators, SwarmKit and Kubernetes,
    by matching the important resources. Let’s take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **SwarmKit** | **Kubernetes** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Swarm | Cluster | Set of servers/nodes managed by the respective orchestrator.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Node | Cluster member | Single host (physical or virtual) that’s a member
    of the Swarm/cluster. |'
  prefs: []
  type: TYPE_TB
- en: '| Manager node | Master | Node managing the Swarm/cluster. This is the control
    plane. |'
  prefs: []
  type: TYPE_TB
- en: '| Worker node | Node | Member of the Swarm/cluster running application workload.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Container | Container** | An instance of a container image running on a node.**Note:
    In a Kubernetes cluster, we cannot run a container directly. |'
  prefs: []
  type: TYPE_TB
- en: '| Task | Pod | An instance of a Service (Swarm) or ReplicaSet (Kubernetes)
    running on a node. A task manages a single container while a Pod contains one
    to many containers that all share the same network namespace. |'
  prefs: []
  type: TYPE_TB
- en: '| Service | ReplicaSet | Defines and reconciles the desired state of an application
    service consisting of multiple instances. |'
  prefs: []
  type: TYPE_TB
- en: '| Service | Deployment | A Deployment is a ReplicaSet augmented with rolling
    updates and rollback capabilities. |'
  prefs: []
  type: TYPE_TB
- en: '| Routing mesh | Service | The Swarm Routing Mesh provides L4 routing and load
    balancing using IPVS. A Kubernetes Service is an abstraction that defines a logical
    set of pods and a policy that can be used to access them. It is a stable endpoint
    for a set of pods |'
  prefs: []
  type: TYPE_TB
- en: '| Stack | Stack** | The definition of an application consists of multiple (Swarm)
    services.**Note: While stacks are not native to Kubernetes, Docker’s tool, Docker
    Desktop, will translate them for Deployment onto a Kubernetes cluster |'
  prefs: []
  type: TYPE_TB
- en: '| Network | Network policy | Swarm **software-defined networks** (**SDNs**)
    are used to firewall containers. Kubernetes only defines a single flat network.
    Every pod can reach every other pod and/or node unless network policies are explicitly
    defined to constrain inter-pod communication |'
  prefs: []
  type: TYPE_TB
- en: This concludes our introduction to Kubernetes, currently the most popular container
    orchestration engine.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the basics of Kubernetes. We took an overview
    of its architecture and introduced the main resources that are used to define
    and run applications in a Kubernetes cluster. We also introduced minikube and
    Kubernetes support in Docker Desktop.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’re going to deploy an application into a Kubernetes
    cluster. Then, we’re going to be updating one of the services of this application
    using a zero-downtime strategy. Finally, we’re going to instrument application
    services running in Kubernetes with sensitive data using secrets. Stay tuned!
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here is a list of articles that contain more detailed information about the
    various topics that we discussed in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The Raft Consensus* *Algorithm*: [https://raft.github.Io/](https://raft.github.Io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kubernetes* *Documentation*: [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please answer the following questions to assess your learning progress:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the high-level architecture of a Kubernetes cluster?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain in a few short sentences what the role of a Kubernetes master is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List the elements that need to be present on each Kubernetes (worker) node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We cannot run individual containers in a Kubernetes cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the three main characteristics of a Kubernetes pod?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain the reason why the containers in a pod can use `localhost` to communicate
    with each other.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of the so-called `pause` container in a pod?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Bob tells you, “Our application consists of three Docker images: `web`, `inventory`,
    and `db`. Since we can run multiple containers in a Kubernetes pod, we are going
    to deploy all the services of our application in a single pod.” List three to
    four reasons why this is a bad idea.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain in your own words why we need Kubernetes ReplicaSets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under what circumstances do we need Kubernetes Deployments?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the main responsibilities of a Kubernetes Service?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List at least three types of Kubernetes Services and explain their purposes
    and their differences.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you create a Kubernetes Service to expose an application service internally
    within the cluster?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: A Kubernetes cluster consists of a control plane (Kubernetes Master) and several
    worker nodes. The control plane is responsible for maintaining the desired state
    of the cluster, such as which applications are running and which container images
    they use. Worker nodes are the servers where applications are deployed and run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Kubernetes master is responsible for managing the cluster. All requests
    to create objects, reschedule pods, manage ReplicaSets, and more happen on the
    master. The master does not run the application workload in a production or production-like
    cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On each worker node, we have the kubelet, the proxy, and container runtime.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The answer is *A. True*. You cannot run standalone containers on a Kubernetes
    cluster. Pods are the atomic units of Deployment in such a cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A Kubernetes pod is the smallest deployable unit in Kubernetes. It can run
    one or multiple co-located containers. Here are three main characteristics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A pod can encapsulate multiple containers that are tightly coupled and need
    to share resources.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: All containers in a pod share the same network namespace, meaning they can communicate
    with each other using `localhost`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Each pod has a unique IP address within the cluster.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: All containers running inside a pod share the same Linux kernel network namespace.
    Thus, all processes running inside those containers can communicate with each
    other through `localhost` in a similar way to how processes or applications directly
    running on the host can communicate with each other through `localhost`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `pause` container’s sole role is to reserve the namespaces of the pod for
    containers that run in it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is a bad idea since all containers of a pod are co-located, which means
    they run on the same cluster node. Also, if multiple containers run in the same
    pod, they can only be scaled up or down all at once. However, the different components
    of the application (that is, `web`, `inventory`, and `db`) usually have very different
    requirements concerning scalability or resource consumption. The `web` component
    might need to be scaled up and down depending on the traffic and the `db` component,
    in turn, has special requirements regarding storage that the others don’t have.
    If we do run every component in its own pod, we are much more flexible in this
    regard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We need a mechanism to run multiple instances of a pod in a cluster and make
    sure that the actual number of pods running always corresponds to the desired
    number, even when individual pods crash or disappear due to network partitions
    or cluster node failures. The ReplicaSet is the mechanism that provides scalability
    and self-healing to any application service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We need Deployment objects whenever we want to update an application service
    in a Kubernetes cluster without causing downtime to the service. Deployment objects
    add rolling updates and rollback capabilities to ReplicaSets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A Kubernetes Service is an abstract way to expose an application running on
    a set of pods as a network service. The main responsibilities of a Kubernetes
    service include the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Providing a stable IP address and DNS name to the set of pods, helping in the
    discovery, and allowing for load balancing
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Routing network traffic to distribute it across a set of pods provides the same
    functionality
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Allowing for the exposure of services to external clients if necessary
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Kubernetes Service objects are used to make application services participate
    in Service discovery. They provide a stable endpoint to a set of pods (normally
    governed by a ReplicaSet or a Deployment). Kube services are abstractions that
    define a logical set of pods and a policy regarding how to access them. There
    are four types of Kube Services:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`30000` to `32767` on every cluster node.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LoadBalancer**: This type exposes the application service externally using
    a cloud provider’s load balancer, such as ELB on AWS.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ExternalName**: Used when you need to define a proxy for a cluster’s external
    service such as a database.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: To create a Kubernetes Service, you typically create a service configuration
    file (`YAML` or `JSON`) that specifies the desired service type (e.g., ClusterIP
    for internal communication), and selector labels to identify the target pods and
    the ports for network traffic. This file is then applied using the `kubectl apply`
    command. This creates a service that routes traffic across the set of pods matching
    the selector labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
