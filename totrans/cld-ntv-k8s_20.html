<html><head></head><body>
		<div><h1 id="_idParaDest-324"><a id="_idTextAnchor341"/>Assessments</h1>
			<h1 id="_idParaDest-325"><a id="_idTextAnchor342"/>Chapter 1 – Communicating with Kubernetes</h1>
			<ol>
				<li>Container orchestration is a software pattern where multiple containers are controlled and scheduled in order to serve an application.</li>
				<li>The Kubernetes API server (<code>kube-apiserver</code>) handles requests to update Kubernetes resources. The scheduler (<code>kube-scheduler</code>) decides where to place (schedule) containers. The controller manager (<code>kube-controller-manager</code>) ensures that the desired configuration of Kubernetes resources is reflected in the cluster. <code>etcd</code> provides a data store for the cluster configuration.</li>
				<li>The <code>kube-apiserver</code> must be started with the <code>--authorization-mode=ABAC</code> and <code>--authorization-policy-file=filename</code> parameters.</li>
				<li>For high availability of the control plane, in case of a failure of one of the master nodes.</li>
				<li>In the event that a resource has already been created, <code>kubectl create</code> will fail because the resource already exists, while <code>kubectl apply</code> will attempt to apply any YAML changes to the resource.</li>
				<li>The <code>kubectl use-context</code> command can be used to switch between multiple contexts within a <code>kubeconfig</code> file. To change between <code>kubeconfig</code> files, the <code>KUBECONFIG</code> environment variable can be set to the path of the new file.</li>
				<li>Imperative commands do not provide a history of changes to a resource.</li>
			</ol>
			<h1 id="_idParaDest-326"><a id="_idTextAnchor343"/>Chapter 2 – Setting Up Your Kubernetes Cluster</h1>
			<ol>
				<li value="1">Minikube makes it easy to set up a local Kubernetes cluster for development.</li>
				<li>In some cases, there may be a fixed minimum cost for the cluster that is larger than a self-provisioned cluster. Some managed options also have license costs in addition to the cost of compute.</li>
				<li>Kubeadm is agnostic to infrastructure providers, while Kops supports only several major providers with deeper integration and compute provisioning. </li>
				<li>As of the writing of this book, AWS, Google Cloud Platform, Digital Ocean, VMware, and OpenStack, in various levels of production readiness.</li>
				<li>Typically, the cluster components are defined in the <code>systemd</code> service definitions, which allows the automatic restart of services if a node shuts down and restarts at the OS level.</li>
			</ol>
			<h1 id="_idParaDest-327"><a id="_idTextAnchor344"/>Chapter 3 – Running Application Containers on Kubernetes</h1>
			<ol>
				<li value="1">If you had development, staging, and production environments, you could make one namespace for each.</li>
				<li>The Node that the Pod is running in could be in a <em class="italic">broken</em> state where the control plane cannot reach it. Typically, when a Node gracefully exits the cluster, the Pod will simply be rescheduled instead of showing an <em class="italic">Unknown</em> status.</li>
				<li>To prevent memory-hungry Pods from taking over the entire Node and causing indeterminate behavior in other Pods on the Node.</li>
				<li>You should add more delay to the <em class="italic">Startup</em> probe if you have one. If not, you will need to add one, or add a delay to the <em class="italic">Readiness</em> probe.</li>
			</ol>
			<h1 id="_idParaDest-328"><a id="_idTextAnchor345"/>Chapter 4 – Scaling and Deploying Your Application</h1>
			<ol>
				<li value="1">ReplicationControllers have less flexibility in how the selector is configured – only key-value selectors are allowed.</li>
				<li>Deployments allow you to specify how updates are rolled out.</li>
				<li>Jobs work well for batch tasks, or tasks that can be scaled horizontally with a clear completion target.</li>
				<li>StatefulSets provide an ordinal Pod identity that stays the same when those Pods restart.</li>
				<li>In addition to an existing version, a new Deployment can be created with the canary version. Then, both versions can be accessed in parallel.</li>
			</ol>
			<h1 id="_idParaDest-329"><a id="_idTextAnchor346"/>Chapter 5 – Services and Ingress – Communicating with the Outside World</h1>
			<ol>
				<li value="1">You would use a ClusterIP service.</li>
				<li>You can use the <code>kubectl describe</code> command to see what port on the Nodes a NodePort service is active on.</li>
				<li>In a cloud environment where you often have to pay per load balancer, Ingress allows you to specify multiple routing rules while only having to pay for one load balancer.</li>
				<li>ExternalName services can be used to easily route to other pieces of infrastructure in your cloud environment – such as managed databases and object storage.</li>
			</ol>
			<h1 id="_idParaDest-330"><a id="_idTextAnchor347"/>Chapter 6 – Kubernetes Application Configuration</h1>
			<ol>
				<li value="1">Secrets are stored encoded and optionally encrypted in <code>etcd</code>. ConfigMaps are stored in plain text.</li>
				<li>They are Base64-encoded.</li>
				<li>The data will be more visible when describing the ConfigMap. The key-value pattern is also easier to use when mounting the ConfigMap as an environment variable.</li>
				<li>Depending on how you set up your cluster, your secrets may not be encrypted at all. If a cluster's EncryptionConfiguration is not set, secrets will only be Base64-encoded – and they can easily be decoded. By creating your cluster with an EncryptionConfiguration, your secrets will be stored encrypted in <code>etcd</code>. This is not a security panacea, but encryption at rest is certainly necessary to improve security for secrets.</li>
			</ol>
			<h1 id="_idParaDest-331"><a id="_idTextAnchor348"/>Chapter 7 – Storage on Kubernetes</h1>
			<ol>
				<li value="1">Volumes are tied to the life cycle of a Pod and are deleted when the Pod is deleted. Persistent Volumes will remain until a cluster is deleted, or they are specifically deleted themselves.</li>
				<li>StorageClasses define the <em class="italic">type</em> of a Persistent Volume. They can be used to distinguish between different types of storage, such as between faster SSD storage and slower hard drives – or different types of cloud storage. StorageClasses determine where a PersistentVolumeClaim and Persistent Volume will go to get provisioned storage.</li>
				<li>Use a managed Kubernetes service with integrated storage provisioning or add a <strong class="bold">cloud-controller-manager</strong> configuration to your cluster.</li>
				<li>Any application that needs to store state for longer than the life of an individual Pod would not work with Volumes. Any application that needs to have state that is tolerant to Pod failure needs a Persistent Volume.</li>
			</ol>
			<h1 id="_idParaDest-332"><a id="_idTextAnchor349"/>Chapter 8 – Pod Placement Controls</h1>
			<ol>
				<li value="1">Node Selectors can be used to match against Node labels and multiple Nodes can fulfill the requirements. Using a Node name means that you specify the single Node where the Pod must be placed.</li>
				<li>Kubernetes implements some default taints to ensure that Pods do not get scheduled on Nodes that are malfunctioning or lack resources. In addition, Kubernetes taints the master Nodes to prevent scheduling of user applications on the masters.</li>
				<li>Too many affinities and anti-affinities can slow down the scheduler or cause it to become unresponsive. Determining Pod placement in cases with a lot of affinities or anti-affinities is very compute-heavy.</li>
				<li>Using anti-affinities, you could prevent Pods from co-existing with like Pods in the same failure domain. Nodes in the same failure domain would be labeled with a failure domain or zone identifier. Anti-affinity would look for Pods matching the specific tier of the application level in the same failure domain, and prevent scheduling on Nodes matching that domain. The end result would be each tier of the three-tier application being spread out among multiple failure domains.</li>
			</ol>
			<h1 id="_idParaDest-333"><a id="_idTextAnchor350"/>Chapter 9 – Observability on Kubernetes</h1>
			<ol>
				<li value="1">Metrics correspond to numerical values that present application/compute performance and/or usage across many categories, including disk, CPU, memory, latency, and so on. Logs correspond to the application, Node, or control plane text logs.</li>
				<li>The Grafana UI is highly customizable and can be used to present complex Prometheus (or another data source's) queries in an elegant, flexible way.</li>
				<li>FluentD would need to run on the production cluster in order to collect logs. Elasticsearch and Kibana could run on a separate cluster or other infrastructure.</li>
			</ol>
			<h1 id="_idParaDest-334"><a id="_idTextAnchor351"/>Chapter 10 – Troubleshooting Kubernetes</h1>
			<ol>
				<li value="1">One of the strengths of Kubernetes is the ability to scale the cluster easily by adding nodes or changing Pod placement by using controls such as taints and tolerations. In addition, Pod restarts can result in completely different IPs for the same application. This means that both the compute and network topologies can be ever-changing.</li>
				<li>The <code>kubelet</code> is typically run as a Linux service with <code>systemd</code>, with control available using <code>systemctl</code> and logs in <code>journalctl</code>.</li>
				<li>There are a few different methodologies to use, but generally, you would want to check whether all Nodes are ready and schedulable; whether there are any Pod Placement Controls precluding scheduling of the Pod; and whether there is any dependent storage, ConfigMaps, or secrets that do not exist.</li>
			</ol>
			<h1 id="_idParaDest-335"><a id="_idTextAnchor352"/>Chapter 11 – Template Code Generation and CI/CD on Kubernetes</h1>
			<ol>
				<li value="1">Helm Charts use templates and variables, while Kustomize uses a patch-based strategy. Kustomize is built into recent versions of kubectl, while Helm uses a separate CLI tool.</li>
				<li>The configuration should emphasize security, since deploy credentials could be used to deploy attacker workloads to your cluster. Using either secure environment variables or access management controls on your cloud provider are two good strategies. The credentials should absolutely not be placed in any Git repository.</li>
				<li>In-cluster setups can be preferable since Kubernetes credentials are not required to be provided by an external system. Out-of-cluster setups are usually simpler, and more synchronous than in-cluster setups, where a control loop determines when changes are made to the resource configuration.</li>
			</ol>
			<h1 id="_idParaDest-336"><a id="_idTextAnchor353"/>Chapter 12 – Kubernetes Security and Compliance</h1>
			<ol>
				<li value="1">MutatingAdmissionWebhook and ValidatingAdmissionWebhook.</li>
				<li>A NetworkPolicy with a blank Pod Selector has the effect of selecting all Pods. A NetworkPolicy with all Pods selected, and Ingress and Egress types added without any rules, will have the effect of automatically denying all ingress and egress to all Pods in the namespace of the NetworkPolicy.</li>
				<li>We would want to track any API requests where resources are patched or updated, because attackers could update a Deployment, Pod, or another resource with malicious containers.</li>
			</ol>
			<h1 id="_idParaDest-337"><a id="_idTextAnchor354"/>Chapter 13 – Extending Kubernetes with CRDs</h1>
			<ol>
				<li value="1">The stored version is the version that is actually stored in the data store. Served versions are any versions that are accepted by the API for read or write operations. The served versions are converted into the stored version when stored in <code>etcd</code>.</li>
				<li>Measure, Analyze, and Update (typically).</li>
				<li>Depending on the cloud provider, the <strong class="bold">cluster-autoscaler</strong> addon will directly update autoscaling groups in order to add or remove Nodes.</li>
			</ol>
			<h1 id="_idParaDest-338"><a id="_idTextAnchor355"/>Chapter 14 – Service Meshes and Serverless</h1>
			<ol>
				<li value="1">A static Envoy configuration refers to an Envoy configuration that is manually created or written by a user. A dynamic Envoy configuration (like those provided by Istio) will constantly adapt to new containers, as well as new routing and filter rules, from an external controller or data plane.</li>
				<li>Listeners, Routes, Clusters, and Endpoints.</li>
				<li>Knative requires many components in order to run. This allows for plenty of customization but makes it more difficult to set up and operate than OpenFaaS.</li>
			</ol>
			<h1 id="_idParaDest-339"><a id="_idTextAnchor356"/>Chapter 15 – Stateful Workloads on Kubernetes</h1>
			<ol>
				<li value="1">Minio is an AWS S3-compatible storage tool.</li>
				<li>StatefulSets assist self-clustering applications such as distributed databases by providing stable, ordinal Pod identities, in addition to Persistent Volume stability.</li>
				<li>In Kubernetes, Pods can be short-lived, and stateful applications can be distributed. This means that the process of maintaining state between Pods (for instance, the database consensus) can become difficult if Pods change identity and storage needs to be replicated from scratch.</li>
			</ol>
		</div>
	</body></html>