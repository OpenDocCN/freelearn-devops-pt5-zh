<html><head></head><body>
        

                            
                    Introduction to Orchestration
                
            
            
                
<p>In this chapter, we will talk about orchestration concepts that can be applied to container environments. We will learn why we need orchestration to deploy applications based on container components on a pool of nodes. Orchestrators provide new features to an environment but they also introduce new management challenges. We will also look at new definitions so that we can provide Docker Engine features in a distributed orchestrated environment. This chapter will introduce important concepts that will help you understand the Swarm and Kubernetes orchestrators.</p>
<p>We will learn about orchestration as a concept and we will also introduce some interesting topics, such as the importance of orchestration in distributed and dynamic environments, and the fact that it allows us to easily scale up and down and update application components. We will also learn how to manage stateless and stateful components and provide data persistency on distributed deployments.</p>
<p>By the end of this chapter, you will know what an orchestrator is and how it applies to container-based application environments.</p>
<p>We will cover the following topics in this chapter:</p>
<ul>
<li>Introducing orchestration concepts</li>
<li>Learning about container orchestration</li>
<li>Scheduling applications cluster-wide</li>
<li>Managing data and persistency</li>
<li>Scaling and updating application components</li>
</ul>
<p>This chapter does not include any labs as it is an introductory chapter with theoretical and general concepts.</p>
<p>Let's start by introducing orchestration as a key concept for managing distributed applications.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<h1 id="uuid-26f5aadc-1985-4534-98cf-c34af27a1213">Introducing orchestration concepts</h1>
<p class="mce-root">Understanding orchestration concepts is key in this chapter so that we can learn more about Docker Swarm or Kubernetes. Let's imagine an orchestra: there are violinists, pianists, percussionists, and so on; every player has studied for many years to become a professional musician. They can play alone perfectly, but things get difficult when we add more instruments. Players can read the musical score and each one will play their part. But even the best musicians need someone to guide them when they're playing together. The orchestra director is key to making all the instruments work together.</p>
<p>When we divide our applications into small pieces – microservices – orchestration is required. An application requires a lot of components to work together. Remember that splitting a monolithic application into different functionalities also creates a new development workflow. We can have different groups of developers working who are focused on just one functionality. Each application component is an atomic piece.</p>
<p>Deploying an application requires the execution and management of all its components at the same time. An orchestrator will manage these components and the application life cycle.</p>
<p>Orchestration will also manage components' dependencies, or will at least provide some tools to allow us to implement application logic.</p>
<p>Orchestration is even more necessary when applications run their components distributed in a pool of computation nodes. We can even distribute these components on different cloud providers or mix on-premises and cloud infrastructures.</p>
<p>Time synchronization is critical on distributed environments and it is even more important when we are securing connections using <strong>Secure Sockets Layer</strong>/<strong>Transport Layer Security</strong> (<strong>SSL</strong>/<strong>TLS</strong>) or other certificate-based solutions.</p>
<p>To summarize, we can say that orchestration provides the tools that we need to manage an application's components in a seamless way across distributed environments.</p>
<p>Now that we know what an orchestrator should do on distributed applications, let's deep dive into container environments.</p>
<h1 id="uuid-56e8792c-ec89-422b-8f9c-3448514ef532">Learning about container orchestration</h1>
<p class="mce-root">Orchestration helps us manage applications running multiple components. In our case, these components or microservices will run on containers. Therefore, let's summarize what features are required in a container environment:</p>
<ul>
<li><strong>Deployment</strong>: All application components must run in a coordinated manner. An orchestrator should help us deploy application components as they are required and they should run in the right order.</li>
<li><strong>Configuration</strong>: It is not easy to manage configuration in distributed environments. An orchestrator should manage this configuration and the configuration should be available anywhere a container needs it.</li>
<li><strong>Resilience</strong>: If one application component fails, the orchestrator should keep the application healthy, if possible.</li>
<li><strong>Scaling up/down</strong>: The microservices concept allows application components to be replicated to increase application performance if needed. If no extra power is required, we should be able to decommission these replicas to save resources.</li>
<li><strong>Node distribution</strong>: To ensure high availability, we will provide a pool of orchestrated compute nodes. This way, we will distribute all application components on different nodes. If some of these nodes die, the orchestrator should ensure that the components running on those nodes run automatically on other healthy ones.</li>
<li><strong>Networking</strong>: Because we distribute applications within different hosts, the orchestrator will need to provide the required application component interactions. Networking is key in this situation.</li>
<li><strong>Publishing</strong>: The orchestrator should also ensure a way to interact with running application components since our application's purpose is to provide a service to customers.</li>
<li><strong>State</strong>: An application component's state is hard to manage. Therefore, it is easier to orchestrate stateless components. This is why people think of containers as ephemeral artifacts. We learned that containers have their own life cycles and that they are not really ephemeral. They exist on hosts until someone deletes them, but orchestration should schedule these components wherever it is permitted. This means that a container's state should be managed in a coordinated way and that components should run with the same properties everywhere. Application components have to maintain their status when they are moved to another host. In most cases, we will run a new, fresh container if a component dies, instead of trying to restart an unhealthy one.</li>
<li><strong>Storage</strong>: If some application components require storage, such as for persistence data, the orchestrator should provide an interface to interact with the host's available storage providers.</li>
</ul>
<p>As you can see, orchestration helps us to maintain application logic, but it cannot do magic. In fact, an orchestrator does not know anything about your application logic. We must provide that logic in some kind of configuration.</p>
<p>In this chapter, we are introducing concepts that can be applied to well-known container orchestrators. Kubernetes and Swarm are the most commonly used, although there are others.</p>
<p>Orchestration will not run containers. Containers are packaged into other orchestration structures. These atomic structures will be scheduled cluster-wide, depending on certain properties or key values. The orchestrator should decide on the best place to launch these atomic components. All orchestrators need a database-like component to store orchestration objects, their properties, and their state.</p>
<p>In Kubernetes, we deploy Pods, which are multiple containers running together. In Swarm, we deploy services, which are based on tasks – which, in the end, are containers. Therefore, we never launch containers. We have other units of deployment. If we deploy a container on a host as-is, it will not be managed by the orchestrator.</p>
<p>In the API era, orchestrators are managed using their exposed API. In fact, we will use the <kbd>kubectl</kbd> and <kbd>docker</kbd> commands to interact with orchestration processes via their APIs. This will be transparent for us. Client applications will do the job with different arguments and actions applied.</p>
<p>Orchestrators are also based on microservices architectures. They have many distributed components. At least a database is required, as we mentioned previously, and an API server and a scheduler to decide where to run the defined application workloads. We will think about applications as groups of logical components, defined using scheduling units.</p>
<p class="mce-root">In the next section, we will cover how orchestration decides where to run application components in cluster-wide environments.</p>
<h1 id="uuid-be03fc9b-4f0c-4103-921f-d551511a0b08">Scheduling applications cluster-wide</h1>
<p class="mce-root">So far, we have learned what to expect from an orchestrator and the basic components required to make it work. We mentioned distributing application components on different hosts. To be able to distribute application components, we will need to deploy a cluster. A cluster is a set of nodes working together. Deploying an application to a host should be similar to deploying the same application to a cluster. The orchestrator will manage the entire workflow, and this process should be transparent for us.</p>
<p>Orchestrators usually manage nodes with different roles. Depending on the kind of processes those nodes run, we will define manager and worker nodes. The names may differ for each orchestrator implementation, but the logic will be the same. Manager nodes execute the orchestration control plane, while workers execute the application deployments. Worker nodes, therefore, are compute nodes.</p>
<p>Control plane nodes manage all the actions required for an orchestration framework to work. The aforementioned database, which is required for storing all object definitions and states, will run on these nodes. The scheduler logic will also run on these nodes. Depending on the database used, for the orchestration to work, it may require a number of odd nodes. Many orchestrators rely on key-value databases (very fast databases accessible via HTTP/HTTPS protocols).</p>
<p>In these cases, databases use the Raft consensus protocol. This means that a defined number of nodes have to vote for every change in the environment before they are stored in the database by just one of them. Once all the required votes are correctly received, database values are synced to other nodes. This ensures that all the nodes have the same information and that the database is safe if some of them go down. This is a very important feature in these environments. And this is the reason why Swarm and Kubernetes, among others, require a specific number of manager nodes to work correctly.</p>
<p>All orchestrated objects have labels. Some of them are automatically added by the orchestrator, for example, to set cluster node architectures. Other labels can be manually configured to define some special behaviors or characteristics, such as to define the application tier or layer for a component. Layers are key to managing cluster object interactions.</p>
<p>The orchestrator will also manage all node resources (CPU, memory, and the ports that are available, among other things) and review whether there are enough resources to run a defined workload before it is deployed.</p>
<p class="mce-root"/>
<p>The orchestrator will review all the node resources, labels, and other application requirements before deciding where to execute workloads. We will be able to set some affinity and anti-affinity features to specify some special requirements and, of course, we will be able to use labels to help the orchestrator choose the right place for them. We will use these labels to associate application components with faster nodes, closer to some required components, or distributed on each node in the cluster.</p>
<p>Remember that application components can be deployed cluster-wide. The orchestrator should manage their network interactions and provide access to these deployments.</p>
<p>These are the basic components for orchestration and the logic behind orchestration scheduling. In the next section, we will take a quick look at how data and application states are managed. Remember that this chapter is just a quick introduction to some orchestration concepts that Docker Swarm and Kubernetes will implement on their workflows, with different architectures and more complexity.</p>
<h1 id="uuid-54d04cce-e7cf-49e2-8d96-f9a5483b9f69">Managing data and persistency</h1>
<p class="mce-root">In many cases, application components need to store some data. This can be very complicated in distributed environments. That is why we usually talk about containers as ephemeral components. Stateless components are easy to implement, but in stateful components, we try to decouple persistent data from a container's filesystems. Remember that data in containers can be lost. In fact, orchestration does not care about data and therefore, if a container dies, it will just run a new one. In these cases, we need to persist data out of a container's environment. We can use what we learned about volume objects in <a href="e7804d8c-ed8c-4013-8449-b746ee654210.xhtml">Chapter 4</a>, <em>Container Persistency and Networking</em>, to do this. We defined volumes to bypass a container's filesystem to improve performance and to store data out of the container's life cycle.</p>
<p>In distributed environments, using the host's local storage will leave application components in inconsistent states when they are moved from one host to another. To avoid these situations, we will use the host's external volumes. In fact, we will choose a storage driver that will allow us to run our application components everywhere, alongside their required storage. All orchestrators can provide NFS storage to containers as required, but in some cases, this is not enough and specialized drivers are required. Cloud providers and many on-premises <strong>software-defined storage</strong> (<strong>SDS</strong>) manufacturers provide REST API interfaces. Storage drivers use these definitions to allow an orchestrator to find the right node to run our application components.</p>
<p class="mce-root">An orchestrator does not know anything about our application logic. It is our responsibility to implement application logic in its code. Some orchestrators, for example, will not manage any kind of dependencies between components. We will also need to implement component health checks, rules, and procedures to follow in case any dependent component dies. We should implement retry procedures if a required component is not accessible.</p>
<p>Docker Swarm and Kubernetes provide objects to ensure configuration files and secrets (authentication files or credentials) are distributed cluster-wide. As we mentioned previously, orchestration will not manage data, just these kinds of configuration objects.</p>
<p>In the next section, we will learn how orchestrators allow us to implement replicated components and how application upgrades are easier in these environments.</p>
<h1 id="uuid-f9c4d288-49a8-42a2-a789-9356d3991d77">Scaling and updating application components</h1>
<p class="mce-root">Orchestrators provide another great feature. If my application is prepared to run more than one instance of some components, the orchestrator will help us easily manage this replication. This is easy because components are based on containers, so if we need to run more than one replica of a component, we can ask the orchestrator to execute more containers. In fact, this feature is key because, in orchestration, we define an application component with the number of required healthy replicas. If all required replicas are alive, that application component will be healthy. If one replica dies, a new one will be executed to ensure that the required number is accomplished.</p>
<p>The management of replicas is one of the features provided by orchestrators. If application performance is compromised and application logic allows replication, we will be able to scale up or down the number of replicas or instances of a component.</p>
<p class="mce-root">On the other hand, we learned that the microservices application model is better for components' life cycles. Developers can focus on each component, and fixing errors and upgrades is easier. Each component is treated as an isolated piece of functionality. This allows us to manage each piece separately from others. We are able to upgrade this component without impacting others. The orchestrator also manages these procedures. We set a new definition or property, such as a new image for an application component or a different port, and the orchestrator deploys these changes for us. We are able to set how this process has to be done. For example, we decide how many instances will be updated at a time or the interval between updates, among other interesting settings.</p>
<p>We will review all these features in depth in each orchestrator chapter. We will learn about Docker Swarm and Kubernetes in <a href="78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml">Chapter 8</a>, <em>Orchestration Using Docker Swarm</em>, and <a href="abcbf266-c469-4d84-ad4f-abd321a64b53.xhtml">Chapter 9</a>, <em>Orchestration Using Kubernetes</em>.</p>
<h1 id="uuid-770643c5-f939-41ea-9325-4b00a944586b">Summary</h1>
<p>In this short chapter, we learned about some important concepts that will help us understand Docker Swarm and Kubernetes. We reviewed the orchestration concept in general before taking a look at the features that orchestration provides. Thanks to orchestration, we are able to distribute application components cluster-wide on different nodes to provide better performance and availability. Application stability is also improved because we are able to execute many instances of one component. We can define an application component with the number of replicas required to be considered healthy. The orchestrator will manage the application's health and will deploy new instances if some of them die. We are also able to scale up and down components as required in our environment if the application permits this behavior.</p>
<p>Orchestration uses new cluster objects. They are stored in a distributed database for high availability. A component's status and other orchestration data will be also stored in this database. The application's components' data and the necessary logic are not managed by the orchestrator. We use external components to share information and the orchestrator interacts with them to ensure the required data is available whenever a component is deployed on a different host.</p>
<p>In the next chapter, we will deep dive into Docker Swarm and learn how Docker implements the orchestration features we have reviewed.</p>
<h1 id="uuid-b1f8eba6-f2df-4c0a-97db-a6a4785ed030" class="mce-root">Questions</h1>
<p>In this chapter, we learned about orchestration in general. We will review some of the topics presented here with some questions:</p>
<ol>
<li>Which of these sentences is true?</li>
</ol>
<p style="padding-left: 90px">a) Kubernetes and Swarm are orchestrators that run distributed applications.<br/>
b) Orchestration replicates application logic into container-based objects.<br/>
c) It is not possible to manage application data in distributed environments.<br/>
d) All of the preceding sentences are false.</p>
<ol start="2">
<li>What do orchestrators manage?</li>
</ol>
<p style="padding-left: 90px">a) Application components' data.<br/>
b) Application components' logic.<br/>
c) Application components' resilience.<br/>
d) All of the preceding options are incorrect.</p>
<ol start="3">
<li>What challenges do we have when we deploy applications with multiple components in distributed environments?</li>
</ol>
<p style="padding-left: 90px">a) Application component networking.<br/>
b) Application component logic.<br/>
c) Application component resilience.<br/>
d) None of the preceding options are correct.</p>
<ol start="4">
<li>What features does orchestration provide to application deployments?</li>
</ol>
<p style="padding-left: 90px">a) We deploy application components by setting the number of replicas required to be considered healthy.<br/>
b) Application components can be scaled up or down as required in your environment and the orchestrator will launch the required instances.<br/>
c) Application components are updated all at once.<br/>
d) None of the preceding options are correct.</p>
<ol start="5">
<li>How does an orchestrator choose where to run application components?</li>
</ol>
<p style="padding-left: 90px">a) Nodes with enough resources can receive workloads.<br/>
b) We can label nodes to fix some components on specific nodes.<br/>
c) The orchestrator will review the defined rules to choose where to run each component<br/>
d) All of the preceding sentences are correct.</p>
<h1 id="uuid-ac3d0fc9-61f1-4863-b588-e4503eda9f3c">Further reading</h1>
<ul>
<li>Raft consensus algorithm: <a href="https://raft.github.io/">https://raft.github.io/</a></li>
<li>Docker Swarm features: <a href="https://docs.docker.com/engine/swarm/">https://docs.docker.com/engine/swarm/</a></li>
<li>Kubernetes introduction and features: <a href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/">https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/</a></li>
</ul>


            

            
        
    </body></html>