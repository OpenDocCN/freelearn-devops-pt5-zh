<html><head></head><body>
		<div><h1 id="_idParaDest-43"><em class="italic"><a id="_idTextAnchor044"/>Chapter 3</em>: Sharing Containers Using Docker Hub</h1>
			<p>In the previous chapter, we learned how to build a container and run it on our workstation using Docker. We used a Debian image as our starting point, but where did that image come from? The answer is that it came from Docker Hub. Docker Hub is the official container image library for Docker, run by the same folk who brought us Docker itself.</p>
			<p>The container library contains the official images for numerous programs, servers, services, and so on that you might install within your own containers. For example, there are official images for various Linux distributions, versions of <a href="http://Node.js">Node.js</a>, versions of MySQL and MongoDB, and so on.</p>
			<p>You can think of Docker Hub as being like GitHub. You can explore existing organizations and pre-made containers, as well as upload your own containers and create your own organizations.</p>
			<p>We will demonstrate how to use the Docker Hub website to search and get information for third-party containers that you can use in your applications. We will also demonstrate how to use third-party containers from Docker Hub using the command line. We will use the official MongoDB container from Docker Hub, which is published by MongoDB, Inc. </p>
			<p>Entire backend applications can be implemented as a combination of multiple Docker containers working together. This application structure allows each of our custom container implementations to be simple and minimal. We'll apply microservices architecture to build a simple application. This demonstrates how containers can work together to create a complete working application. Lastly, we'll see how you can share your ready-for-production containers with third parties and your development team using Docker Hub.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Introducing Docker Hub</li>
				<li>Implementing a MongoDB container for our application</li>
				<li>Introducing the microservices architecture</li>
				<li>Implementing a sample microservices application</li>
				<li>Sharing your containers on Docker Hub</li>
			</ul>
			<h1 id="_idParaDest-44"><a id="_idTextAnchor045"/>Technical requirements</h1>
			<p>The only technical requirements are to have Docker installed on your host, and a browser, such as Google Chrome, Firefox, or Microsoft Edge. This is one of the best parts of Docker—you don't have to install the complex servers/services on your host; we install them in Docker containers.</p>
			<p>We have prepared examples that you can use directly without modification in a public GitHub repository, which can be found at <a href="https://github.com/PacktPublishing/Docker-for-Developers">https://github.com/PacktPublishing/Docker-for-Developers</a>.</p>
			<p>Check out the following video to see the Code in Action:</p>
			<p><a href="https://bit.ly/2PTADjH">https://bit.ly/2PTADjH</a></p>
			<h1 id="_idParaDest-45"><a id="_idTextAnchor046"/>Introducing Docker Hub</h1>
			<p>You will typically interact with Docker Hub from the command line or in Dockerfiles, but you can use <a id="_idIndexMarker109"/>the Docker Hub website (<a href="https://hub.docker.com">https://hub.docker.com</a>) to search for any pre-built containers that <a id="_idIndexMarker110"/>you know you want to use. You can also use the website to discover pre-built containers that might be of interest to you.</p>
			<p>In general, you will inherit from some pre-built Docker containers on Docker Hub to create your own custom containers. For example, you might inherit from a Linux distribution container and install the software you want for your project within that inherited/custom container.  </p>
			<p>When you inherit from the Linux distribution, some of that distribution's base software packages are installed. If you inherit from a Debian-flavor Linux container, you will be able to use the <code>apt</code> package manager within the container to install software as if you were running that Debian-flavor Linux container on a dedicated or virtual machine.</p>
			<p>Some pre-built containers inherit from a Linux flavor and provide pre-installed packages that are specific to the offering. When you inherit from a <a href="http://Node.js">Node.js</a> container, that <a href="http://Node.js">Node.js</a> container might inherit from a Linux distribution container and will have <a href="http://Node.js">Node.js</a>, <code>npm</code>, and <code>yarn</code> already installed.</p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor047"/>Interacting with Docker Hub from the command line</h2>
			<p>The easiest <a id="_idIndexMarker111"/>way to see Docker Hub and Docker working together is to run the official <code>hello-world</code> container. The command to run a container from Docker Hub is <code>docker run name-of-container</code>; we'll type <code>docker run hello-world</code>:</p>
			<pre># docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world 1b930d010525: Pull complete Digest: sha256:4fe721ccc2e8dc7362278a29dc660d833570ec2682f4e 4194f4ee23e415e1064 Status: Downloaded newer image for hello-world:latest
Hello from Docker!
This message shows that your installation appears to be working correctly.
To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.
To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash
Share images, automate workflows, and more with a free Docker ID:
 <a href="https://hub.docker.com/">https://hub.docker.com/</a>
For more examples and ideas, visit:
 <a href="https://docs.docker.com/get-started/">https://docs.docker.com/get-started/</a></pre>
			<p>Docker did <a id="_idIndexMarker112"/>not find the container in its local container cache, so it automatically downloaded it and then ran it within the Docker engine. This code in the container is simple—it just prints the preceding messages.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You can run any container you find on the Docker Hub website in the same way!</p>
			<p>If your output does not resemble the preceding output, you either have an issue with your Docker installation or the Docker Hub servers are not accessible from your host. One possible problem may be that your installation of Docker requires you to run the <code>docker</code> commands as root or an administrator.</p>
			<p>The installation instructions<a id="_idIndexMarker113"/> can be found at <a href="https://docs.docker.com/install/">https://docs.docker.com/install/</a>, while the post-installation instructions for Docker can be found at <a href="https://docs.docker.com/install/linux/linux-postinstall/">https://docs.docker.com/install/linux/linux-postinstall/</a>. These post-installation <a id="_idIndexMarker114"/>instructions explain how to set up Docker so that you can manage it as a non-root user.</p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor048"/>Using the Docker Hub website</h2>
			<p>Let's go <a id="_idIndexMarker115"/>find the <code>hello-world</code> container page in Docker Hub—<a href="https://hub.docker.com/_/hello-world">https://hub.docker.com/_/hello-world</a>. The page <a id="_idIndexMarker116"/>will look something like this:</p>
			<div><div><img src="img/B11641_03_001.jpg" alt="Figure 3.1 – The hello-world image page on Docker Hub"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.1 – The hello-world image page on Docker Hub</p>
			<p>This is typical of what you'll see for most containers shared on Docker Hub. Specific software packages encapsulated in a container, such as MongoDB, offer official images for various versions of the software. This allows you to deal with software that depends on a specific version of a Docker Hub package.</p>
			<p>The MongoDB page on Docker Hub is <a href="https://hub.docker.com/_/mongo">https://hub.docker.com/_/mongo</a>. To find it, simply type <code>mongodb</code> into the search box at the top of the <strong class="bold">hello-world</strong> (or any other package) page and select it from the search results page. You can use the search box to find any shared images for whatever software you might want.</p>
			<p>Of interest are the <strong class="bold">Simple Tags</strong> and <strong class="bold">Shared Tags</strong> sections of the page. The various version images of MongoDB are tagged with simple tags and shared tags. </p>
			<p>For example, the <strong class="bold">3.4-xenial</strong> simple tag means there is an image for version 3.4 of MongoDB running in an Ubuntu Xenial container. </p>
			<p>The <strong class="bold">3.4</strong> shared tag means there are images of version 3.4 of MongoDB that run on more than one host operating system—typically, Windows Server, Linux, or macOS. The Docker daemon will choose the appropriate image for the host operating system.</p>
			<p>As of the <a id="_idIndexMarker117"/>time of writing, there are images for the MongoDB 3.4, 3.6, 4.0, and 4.2 major versions, as well as minor point versions of these major versions:</p>
			<div><div><img src="img/B11641_03_002.jpg" alt="Figure 3.2 – Simple tags and shared tags for hello-world"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.2 – Simple tags and shared tags for hello-world</p>
			<p>The process for finding the available pre-built third-party containers is the same. You can search for <a id="_idIndexMarker118"/>Redis, for example, and you will get a similar page with details about the available Redis containers.</p>
			<h1 id="_idParaDest-48"><a id="_idTextAnchor049"/>Implementing a MongoDB container for our application</h1>
			<p>We can <a id="_idIndexMarker119"/>explore using pre-built containers from Docker Hub by implementing a MongoDB container. We'll use this container <a id="_idIndexMarker120"/>later as part of a demo application that is made up of several containers that work together.</p>
			<p>We will <a id="_idIndexMarker121"/>use the official Docker image for MongoDB, found on the Docker Hub website at <a href="https://hub.docker.com/_/mongo">https://hub.docker.com/_/mongo</a>. We will create a <code>.sh</code> script to start running our image within Docker so that the startup process is easy and repeatable.</p>
			<p>We learned in <a href="B11641_02_Final_NM_ePub.xhtml#_idTextAnchor028"><em class="italic">Chapter 2</em></a>, <em class="italic">Using VirtualBox and Docker Containers for Development</em>, that we can expose a container's network ports to the host. That means we can run this MongoDB container image in Docker and access the running MongoDB server within that container by accessing the MongoDB port on the host.</p>
			<p>In the GitHub repository (<a href="https://github.com/PacktPublishing/Docker-for-Developers">https://github.com/PacktPublishing/Docker-for-Developers</a>) for this book, there is a <code>chapter3/</code> directory, which is a companion for this chapter. Within that directory is a shell script, <a href="http://start-mongodb.sh">start-mongodb.sh</a>. This script is a bit more elaborate than the simple ones we used in the previous chapter. We're going to use environment variables to configure MongoDB, and we're going to use a directory on the host for MongoDB's data files—this makes backing up the data as easy as copying those files to back-up media:</p>
			<pre>#!/bin/bash
# <a href="http://start-mongodb.sh">start-mongodb.sh</a>
SERVICE=mongodb # name of the service
# You can set these in this script (uncomment and edit the lines) or set them in your .zshrc/.bashrc/etc.
# Change this to an EXISTING directory on the HOST where the mongodb database files will be created #!/bin/bash
# <a href="http://start-mongodb.sh">start-mongodb.sh</a>
SERVICE=mongodb # name of the service
# Change this to an EXISTING directory on the HOST where the mongodb database files will be created and maintained.
#MONGO_DATADIR="$HOME/data"
# Stop any running MongoDB container, remove previous container, pull newer version
docker stop $SERVICE
docker rm $SERVICE
docker pull mongo:3.4
# Now we run it!
docker run …</pre>
			<p>You do <a id="_idIndexMarker122"/>need a Dockerfile to create a container image. However, if you are using a pre-made container image from Docker <a id="_idIndexMarker123"/>Hub that is standalone, such as MongoDB, you won't need one. The developers at MongoDB use Dockerfiles to generate the images before uploading them to Docker Hub.  </p>
			<p>In fact, you can see from the <strong class="bold">Supported tags</strong> section of the MongoDB page in Docker Hub that they produce and support quite a few images, including different versions—some for Windows OS, some for Linux, and so on. The MongoDB developers must have quite a few Dockerfiles—one for each image!</p>
			<p>We must provide one environment variable to <a href="http://start-mongodb.sh:">start-mongodb.sh:</a> <code>MONGO_DATADIR</code>, which is an existing directory on your workstation where you want MongoDB in the container to store its data files. There are a few ways to set this variable:</p>
			<ul>
				<li>You can add <code>export MONGODB_DATADIR=/path/to/data/dir</code> to your shell startup file (<code>.zshrc</code>, <code>.bashrc</code>, and so on).</li>
				<li>You can do the <code>export</code> (environment variable) operation by hand in the shell before running the script.</li>
				<li>You can set the value of the environment variable when using the command line to run the <a href="http://start-mongodb.sh">start-mongodb.sh</a> script: <code># MONGODB_DATADIR=~/data ./</code><a href="http://start-mongodb.sh">start-mongodb.sh</a>.</li>
				<li>You can uncomment the line that sets <code>MONGO_DATADIR</code> in the <a href="http://start-mongodb.sh">start-mongodb.sh</a> script file and edit it to set it to your desired data directory each time you run the script.</li>
			</ul>
			<p>The last line in the <a href="http://start-mongodb.sh">start-mongodb.sh</a> script is a single command line. The backslash (<code>\</code>) character at the end of the line signifies that the line is being continued or joined with the next line. This command is the one that starts the container. As you can imagine, if you had to type in this long command every time to start your MongoDB container, it would be painful. The <code>.sh</code> script makes it rather painless:</p>
			<pre>docker run \
  --name $SERVICE \
  -d \
  --restart always \
  -e TITLE=$SERVICE \
  -p 27017:27017 \
  -v "$MONGO_DATADIR":/data/db \
  mongo:3.4</pre>
			<p>Let's take <a id="_idIndexMarker124"/>a look at the different <a id="_idIndexMarker125"/>parts of the preceding command:</p>
			<ul>
				<li>The <code>docker run</code> command names the <code>mongodb</code> running container.  </li>
				<li>The <code>-d</code> switch runs the container in detached mode. The container will automatically start when your workstation is rebooted. </li>
				<li>The <code>-e</code> switch allows you to pass environment variables to the container; in this case, we pass the <code>TITLE=mongodb</code> environment variable. You can have multiple <code>-e</code> switches if you want to pass more than one variable.</li>
				<li>The <code>-p</code> switch exposes port <code>27017</code> in the container to port <code>27017</code> on the host. You can remap an exposed port in the container to a different port number on the host. You would do this if you have a MongoDB server already running in a container or on your host. However, Docker provides us the flexibility to always run MongoDB within a container, so we'll never have to install it on our host.<p>We might want to install MongoDB client programs on the host so that we can access MongoDB using the MongoDB REPL/shell. Once port <code>27017</code> is exposed on the host, any program can access the MongoDB database, using it as if it were running on the host.</p></li>
				<li>The <code>-v</code> switch maps a directory on the host to the directory in the container where MongoDB will manage its database and other files.</li>
				<li>We choose to download and run <code>mongo:3.4</code> (tag/version 3.4) from Docker Hub.<p class="callout-heading">Note</p><p class="callout">The <code>docker run</code> command only downloads the container from Docker Hub if it doesn't exist on your workstation yet or if the container image on Docker Hub is newer.</p></li>
			</ul>
			<p>You can run any container you find on Docker Hub in the same way!</p>
			<p>Let's run the script by using the following commands:</p>
			<pre># mkdir -p ~/mongodb
# MONGO_DATADIR=~/mongodb ./<a href="http://start-mongodb.sh">start-mongodb.sh</a></pre>
			<p>The following <a id="_idIndexMarker126"/>output contains <a id="_idIndexMarker127"/>a few warnings about not being able to stop an already-running container named <code>mongodb</code> (this is expected):</p>
			<pre># mkdir -p ~/mongodb &amp;&amp; MONGO_DATADIR=~/mongodb ./<a href="http://start-mongodb.sh">start-mongodb.sh</a> stopping mongodb Error response from daemon: No such container: mongodb removing old mongodb Error: No such container: mongodb pulling mongodb 3.4: Pulling from library/mongo 976a760c94fc: Pull complete c58992f3c37b: Pull complete 0ca0e5e7f12e: Pull complete …
3757d63ce2b9: Pull complete Digest: sha256:4c7003e140fc7dce5f12817d510b5a9bd265f2 c3bbd6f81d50a60cc11f6395d9 Status: Downloaded newer image for mongo:3.4 <a href="http://docker.io/library/mongo">docker.io/library/mongo</a>:3.4 e3854f6931e1aa4b64557d5a54e652653123f84a 544fedf39a5cf68d2ee9d0af  # docker ps CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                      NAMES e3854f6931e1        mongo:3.4           "docker-entrypoint.s…"   5 seconds ago       Up 3 seconds        0.0.0.0:27017-&gt;27017/tcp   mongodb  #</pre>
			<p>Docker pulled the proper MongoDB image and ran it in the background in the Docker engine. You can observe the following:</p>
			<ul>
				<li>The MongoDB image consists of several layers that were downloaded (<code>Pull complete</code>).  </li>
				<li>There was already an existing (but older) image on the workstation (<code>Downloaded newer image…</code>).</li>
				<li>The container is running via the <code>docker ps</code> command.</li>
			</ul>
			<p>If the <a id="_idIndexMarker128"/>container encounters errors, it may <a id="_idIndexMarker129"/>exit and print diagnostic messages in the output. You can run a shell in the container to perform forensic diagnosis.</p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor050"/>Running a shell within a container</h2>
			<p>Generally, you would run a shell within the container so that you can discover more about the container's environment. For example, you may have a bug in your Dockerfile—such as forgetting <a id="_idIndexMarker130"/>to copy a file into the container. You can run a shell in the container and list directories and you will see that the file is missing.</p>
			<p>In the case <a id="_idIndexMarker131"/>of the MongoDB container, you might want to run the MongoDB client commands from within the container. The Docker Hub page for the MongoDB container says we can run the client commands by simply attaching to the running container (<a href="https://hub.docker.com/_/mongo">https://hub.docker.com/_/mongo</a>). The command from the MongoDB Docker Hub page is as follows:</p>
			<pre>docker exec -it mongodb bash</pre>
			<p>The different parts of this command are as follows:</p>
			<ul>
				<li><code>docker exec</code> runs a command in a running container (<a href="https://docs.docker.com/engine/reference/commandline/exec/">https://docs.docker.com/engine/reference/commandline/exec/</a>).</li>
				<li>The <code>-it</code> switches specify that Docker is to run the container interactively—this means it gets input from the keyboard and sends output to the Terminal window.</li>
			</ul>
			<p>Within the container, we can list directories using the <code>ls</code> command:</p>
			<pre># docker exec -it mongodb bash root@e3854f6931e1:/# ls bin   data  docker-entrypoint-initdb.d  etc   js-yaml.js  lib64  mnt  proc  run   srv  tmp  var boot  dev   entrypoint.sh               home  lib         media  opt  root  sbin  sys  usr</pre>
			<p>We can see that the Docker containers are running using the <code>ps</code> command within the container:</p>
			<pre>root@e3854f6931e1:/# ps -aux USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND mongodb        1  0.7  0.0 954676 62028 ?        Ssl  22:37   0:02 mongod root          40  2.8  0.0  18240  3248 pts/0    Ss   22:41   0:00 bash root          51  0.0  0.0  34420  2848 pts/0    R+   22:41   0:00 ps -aux root@e3854f6931e1:/# </pre>
			<p>We can <a id="_idIndexMarker132"/>run the command-line MongoDB tools inside the container. We did not have to install these on our workstation! Here, we run the MongoDB <a id="_idIndexMarker133"/>command and then run the <code>show collections</code> and <code>show databases</code> commands within the Mongo REPL:</p>
			<pre>root@e3854f6931e1:/# mongo MongoDB shell version v3.4.23 connecting to: mongodb://127.0.0.1:27017 MongoDB server version: 3.4.23 Welcome to the MongoDB shell.For interactive help, type "help".For more comprehensive documentation, see         http://docs.mongodb.org/Questions? Try the support group         http://groups.google.com/group/mongodb-user Server has startup warnings:2019-12-13T22:37:12.342+0000 I CONTROL  [initandlisten]2019-12-13T22:37:12.342+0000 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.2019-12-13T22:37:12.342+0000 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.2019-12-13T22:37:12.342+0000 I CONTROL  [initandlisten]&gt; show collections &gt; show databases admin  0.000GB local  0.000GB &gt;root@e3854f6931e1:/# exit</pre>
			<p>We're all set to go—MongoDB is running and we were able to use the REPL. The <code>show collections</code> command returned no collections because we haven't created any. The <code>show databases</code> command shows that MongoDB has, by default, two databases: <code>admin</code> and <code>local</code>.</p>
			<p>The <code>docker logs</code> command shows us the <code>stdout</code> and <code>stderr</code> output of the container:</p>
			<pre># docker logs mongodb 2019-12-13T22:37:09.161+0000 I CONTROL  [initandlisten] MongoDB starting : pid=1 port=27017 dbpath=/data/db 64-bit host=e3854f6931e1 2019-12-13T22:37:09.162+0000 I CONTROL  [initandlisten] db version v3.4.23 2019-12-13T22:37:09.162+0000 I CONTROL  [initandlisten] git version: 324017ede1dbb1c9554dd2dceb15f8da3c59d0e8 2019-12-13T22:37:09.162+0000 I CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.0.2g  1 Mar 2016 2019-12-13T22:37:09.162+0000 I CONTROL  [initandlisten] allocator: tcmalloc 2019-12-13T22:37:09.162+0000 I CONTROL  [initandlisten] modules: none 2019-12-13T22:37:09.162+0000 I CONTROL  [initandlisten] build environment:2019-12-13T22:37:09.162+0000 I CONTROL  [initandlisten]     distmod: ubuntu1604 2019-12-13T22:37:09.162+0000 I CONTROL  [initandlisten]     distarch: x86_64 2019-12-13T22:37:09.162+0000 I CONTROL  [initandlisten]     target_arch: x86_64 2019-12-13T22:37:09.162+0000 I CONTROL  [initandlisten] options: {}2019-12-13T22:37:09.165+0000 I STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=31491M,session_max=20000,eviction=(threads_min=4,threads_m ax=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),checkpoint=(w ait=60,log_size=2GB),statistics_log=(wait=0),verbose=(recovery_progress),2019-12-13T22:37:14.335+0000 I INDEX    [initandlisten]          building index using bulk method; build may temporarily use up to 500 megabytes of RAM     2019-12-13T22:37:14.342+0000 I INDEX    [initandlisten] build index done.  scanned 0 total records. 0 secs 2019-12-13T22:37:14.344+0000 I COMMAND  [initandlisten] setting featureCompatibilityVersion to 3.4 (
…</pre>
			<p>You will likely use the <code>docker logs</code> command to see the debugging output from your containers. </p>
			<p>What we <a id="_idIndexMarker134"/>see in our preceding logs is that MongoDB seems to be running just fine within the container. There are no error messages printed.</p>
			<p>You can <a id="_idIndexMarker135"/>have the <code>docker logs</code> command follow the log file using the <code>-f</code> command-line switch. When the command is in follow mode, any new lines written to the log as the application is running will be appended to the display on the screen.</p>
			<p>Up to point, we have explored using Docker to run a complex server application (MongoDB) without having to install MongoDB on our workstation. Using Docker, we have access to MongoDB.</p>
			<p>We can start MongoDB using our <code>.sh</code> script, and we can also stop it—we can do this at will so that we <a id="_idIndexMarker136"/>don't have to always have MongoDB running in the background.</p>
			<p>Now that <a id="_idIndexMarker137"/>we know how to run a Docker container, let's have a look at how to work with multiple containers that work together.</p>
			<h1 id="_idParaDest-50"><a id="_idTextAnchor051"/>Introducing the microservices architecture</h1>
			<p>Docker and Docker Hub enable development using the microservices architecture. This architecture emphasizes building and running containers that focus on a single aspect of the overall application. When all the containers are running, you have your complete backend application. The containers <a id="_idIndexMarker138"/>can be complex, such as a full-blown database server, or simple, such as a short shell script. Ideally, the containers you implement for your application will be simple, short, and focused. Each microservice you write should be simple to debug since you don't need many lines of code.</p>
			<p>Suppose we want to develop a backend application that uses MongoDB and Redis and whose application code is written using <a href="http://Node.js">Node.js</a>. We have the option to create a Dockerfile and start with the MongoDB image. We would then add Redis by installing it using <code>apt</code>, and then add our program to it as we did with the Debian image in <a href="B11641_02_Final_NM_ePub.xhtml#_idTextAnchor028"><em class="italic">Chapter 2</em></a>, <em class="italic">Using VirtualBox and Docker Containers for Development</em>. The problem with creating the application using this method is that when you stop the container for development reasons, you're also stopping the running MongoDB and Redis servers.</p>
			<p>Instead of a monolithic container with everything installed, you can run MongoDB, Redis, and your custom application containers separately. You can even divide your custom application into multiple containers. All you need is a mechanism to communicate between your application containers.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">It is far better to avoid using monolithic containers in your design! While it might seem that a large and complex program such as MongoDB is a monolithic sort of thing, it's just one dedicated service you can use as a microservice.</p>
			<p>Now that we have a brief understanding of microservices architecture, we can examine some of the benefits and requirements of containers as microservices.</p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor052"/>Scalability</h2>
			<p>Scalability is almost always a huge consideration for backend implementations. For example, a simple HTTP/WWW (web page) server can grind to a halt if enough people are trying to fetch our <a id="_idIndexMarker139"/>pages from it at the same time. For this reason, server farms exist so that you can deploy two or more of these HTTP/WWW servers that <a id="_idIndexMarker140"/>duplicate the functionality of serving our pages. For a two-server farm, you basically get double the number of people fetching your pages from it than for a single server. As traffic grows—for example, if the site gains in popularity—you can add a third server, then a fourth server, and so on. The capability of the backend to serve pages grows as you need it.</p>
			<p>In a microservices architecture, we achieve a similar means of scalability. We can run multiple instances of our MongoDB container to achieve more capacity for database operations. The only trick is to configure MongoDB as a cluster or as shards and the application containers to use this database setup.</p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor053"/>Inter-container communication</h2>
			<p>Inter-container communication usually involves some technology that allows messages to be sent <a id="_idIndexMarker141"/>from one container to <a id="_idIndexMarker142"/>another and for responses or statuses to be sent in return. Being able to communicate between running containers can be done via a few technologies, including the following:</p>
			<ul>
				<li>Sockets</li>
				<li>The filesystem</li>
				<li>Database records</li>
				<li>HTTP</li>
				<li>MQTT</li>
			</ul>
			<p>Let's discuss each of them now.</p>
			<h3>Using sockets</h3>
			<p>Using sockets <a id="_idIndexMarker143"/>is a non-trivial way to communicate <a id="_idIndexMarker144"/>between containers. If you have five containers, you might have five sockets per container to provide communication paths between them all. As you scale, more sockets need to be created in each container, and you really want to automate this. There's quite a bit of business logic involved.</p>
			<h3>Using the filesystem</h3>
			<p>Using the filesystem involves sharing something such as a network drive among all the containers. To <a id="_idIndexMarker145"/>send a message, a container writes to a file in the filesystem. To receive a message, the container reads from a file in the filesystem. The receiver <a id="_idIndexMarker146"/>needs to poll, or repeatedly check, the filesystem to detect when the file is written to. This is not ideal because we don't really want to share a network drive like this—the performance is going to be on the slow side.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Polling is a programming technique where you continuously check the status of a machine state (such as whether a file has changed).</p>
			<h3>Using database records</h3>
			<p>Using database records is similar to the filesystem method, except the messages to be sent are simply <a id="_idIndexMarker147"/>written to records in the database and the receivers only need to poll the database records for changes. Some databases <a id="_idIndexMarker148"/>provide a notification mechanism to tell a client (receiver) that the database has changed.</p>
			<p>Both filesystem and database schemes require a good amount of business logic and debugging. You have to consider the order of messages sent and received and avoid missing a message because an older message is overwritten in the database or filesystem.</p>
			<h3>Using HTTP</h3>
			<p>HTTP is a <a id="_idIndexMarker149"/>stateless protocol, so you don't have to maintain a mesh of open sockets for communication. The protocol is well-defined and human-readable (for example, in text). To <a id="_idIndexMarker150"/>send a message, you send an HTTP request to the container you want to communicate with and wait for the response. You can close or persist the connection (keep it alive) as the HTTP protocol permits. Additionally, to avoid having to poll for messages or state change via HTTP, you can use WebSockets.</p>
			<h3>Using MQTT</h3>
			<p>MQTT is a <a id="_idIndexMarker151"/>well-designed message bus. It works <a id="_idIndexMarker152"/>much like IRC or Slack in that you have rooms (topics) and people in rooms (subscribers). Messages sent to a room (topic) are received by the people (subscribers). The people (subscribers) can join multiple rooms (topics) and they receive the messages for those rooms (topics).</p>
			<p>For an MQTT application, there must be one MQTT server (broker) container that is accessible from the other containers. The other containers do not have to know about one another, only the address of the MQTT broker. </p>
			<p>The MQTT <a id="_idIndexMarker153"/>broker accepts connections from one or more clients. The clients can subscribe to one or more topics. The topics are as arbitrary as the channel/room names <a id="_idIndexMarker154"/>are in IRC or Slack; they are typically strings. When a message is sent to the MQTT broker for a specific topic, the broker sends the message to all the clients who are subscribed to that topic.</p>
			<p>Mosca (<a href="https://hub.docker.com/r/matteocollina/mosca">https://hub.docker.com/r/matteocollina/mosca</a>) is an MQTT broker written in JavaScript. You can <a id="_idIndexMarker155"/>run it in a container, as you do with MongoDB or Redis.  </p>
			<p>There are several other MQTT brokers to choose from, as well—you can find them on Docker Hub.</p>
			<h3>HTTP versus MQTT</h3>
			<p>MQTT is a protocol specifically designed for passing messages of key/value pairs. Its strength is in <a id="_idIndexMarker156"/>its broadcast capability. Each client is responsible for asking for modifications to values based on the specific keys it cares about. Each client can be assured that their updates are received by any and all <a id="_idIndexMarker157"/>other interested clients. MQTT also has the capability to retain specific key/value pairs, so when a new client subscribes, it can be notified of the current key/value pair (the most recently sent one).  </p>
			<p>MQTT does <a id="_idIndexMarker158"/>not provide a request/response protocol, although it is simple to implement one. The downside of using MQTT for request/response-type transactions is that the response is not guaranteed to happen as soon as possible. </p>
			<p>HTTP requires custom programming to provide the message-passing services that MQTT provides. You could implement a message bus sort of system that mimics MQTT's functionality, but that means more programming work for you and additional maintenance costs down the line. HTTP's strength is that it is a request/response protocol, so you can typically expect a response right away. The downside is that if the server is maintaining a set of key/value pairs, you would be required to poll the server from the clients to see whether the values have changed and post to the server to update the values. Polling causes the server to burn CPU, even when values haven't changed, and this can add up in a way that grinds your server to a halt if enough clients are polling frequently enough. You could use WebSockets, but in the end, you've reinvented MQTT.</p>
			<p>HTTP is a good choice if you need more than what MQTT provides. Certainly, HTTP supports PHP or <a href="http://Node.js">Node.js</a> (and others) backend services.</p>
			<p>It's possible <a id="_idIndexMarker159"/>to combine HTTP and MQTT. Use HTTP for request/response-type transactions and MQTT for state updates.  </p>
			<p>MQTT is <a id="_idIndexMarker160"/>a good choice for our purposes.</p>
			<p>The <code>chapter3/</code> directory in the companion GitHub repository contains a simple microservices-based <a id="_idIndexMarker161"/>backend demonstration application. It uses MongoDB, Redis, and MQTT, along with some publisher and subscriber applications that you can find in the GitHub repository for this book (<a href="https://github.com/PacktPublishing/Docker-for-Developers">https://github.com/PacktPublishing/Docker-for-Developers</a>). Later in this chapter, we'll learn how to share our subscriber and publisher containers via Docker Hub.</p>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor054"/>Implementing a sample microservices application</h1>
			<p>We can <a id="_idIndexMarker162"/>use the Mosca, MongoDB, and Redis containers, along with a couple of custom containers, to implement a simple but complete application:</p>
			<div><div><img src="img/B11641_03_003.jpg" alt="Figure 3.3 – Diagram of our sample microservices application"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.3 – Diagram of our sample microservices application</p>
			<p>The publisher and subscriber will communicate with each other using MQTT. The subscriber will listen for a handful of MQTT topics that direct it to operate on or retrieve information from the MongoDB and Redis databases. The publisher will send these MQTT topics and print the responses.</p>
			<p>The publisher <a id="_idIndexMarker163"/>will be based on <a href="http://Node.js">Node.js</a> version 11 and the subscriber will be based on <a href="http://Node.js">Node.js</a> version 12. Without Docker or a virtual machine, running two <a href="http://Node.js">Node.js</a> versions on the same machine concurrently requires the use of <strong class="bold">Node Version Manager</strong> (<strong class="bold">nvm</strong>) and having multiple versions of <a href="http://Node.js">Node.js</a> installed on <a id="_idIndexMarker164"/>your workstation. Docker containers make it simple to use as many versions as you need and to package the version, along with the app that uses it, in a nice package (a container).</p>
			<p>The publisher and subscriber apps are in their own <code>publisher/</code> and <code>subscriber/</code> subdirectories of <code>chapter3/</code> in the companion repository. These programs each need their own Dockerfile so that we can build the two separate containers. They also have their own helper <code>.sh</code> scripts (<a href="http://debug.sh">debug.sh</a>, <a href="http://run.sh">run.sh</a>, <a href="http://build.sh">build.sh</a>, and so on). The publisher app only needs to have an MQTT library. The subscriber app needs the MQTT library and a MongoDB library and a Redis library. These libraries will be installed using <code>np</code>m (the <a href="http://Node.js">Node.js</a> package manager) within the containers.</p>
			<p>The publisher and subscriber apps demonstrate how a microservices architecture works, using multiple Docker containers.</p>
			<p>The subscriber connects to the MongoDB and Redis containers using <a href="http://Node.js">Node.js</a> packages/libraries, which are installed in the container with <code>npm</code>. The subscriber provides basic <strong class="bold">Create, Read, Update, and Delete</strong> (<strong class="bold">CRUD</strong>) functions for adding, listing, removing, and retrieving <a id="_idIndexMarker165"/>count of records in each of the MongoDB and Redis databases. The publisher sends MQTT messages to the subscriber to invoke this functionality.</p>
			<p>Our topics are strings that are derived from a <a id="_idTextAnchor055"/>pattern: container/command. If we want to communicate <a id="_idIndexMarker166"/>with the subscriber, the pattern is subscriber/command. If we want to communicate with the publisher, the pattern is publisher/command. This convention makes it obvious which topics each microservice would want to subscribe or publish to.</p>
			<p>The MQTT topics and messages are as follows:</p>
			<ul>
				<li><code>subscriber/mongo-count</code>: Responds with the count of records in the MongoDB database.</li>
				<li><code>subscriber/mongo-add</code>: Adds the message content to the MongoDB database.</li>
				<li><code>subscriber/mongo-list</code>: Returns a JSON object that contains a list of records in the MongoDB database. If the message is a non-zero length string, it is used to filter the list of records returned.</li>
				<li><code>subscriber/mongo-remove</code>: Removes a record from the MongoDB database.  The message may contain a string or an object (JSON) suitable for passing to MongoDB's <code>collection.deleteOne()</code> method.</li>
				<li><code>subscriber/mongo-removeall</code>: Deletes all records from the MongoDB database.</li>
				<li><code>subscriber/redis-count</code>: Responds with the count of records in the Redis database.</li>
				<li><code>subscriber/redis-flushall</code>: Removes all the records from the Redis database.</li>
				<li><code>subscriber/redis-set</code>: Adds a record to the Redis database; the message is of the <code>key=value</code> form.</li>
				<li><code>subscriber/redis-list</code>: Lists all the records in the Redis database and returns a JSON array of records.</li>
				<li><code>subscriber/redis-del</code>: Deletes a record from the Redis database.</li>
				<li><code>subscriber/commands</code>: Returns a list of available commands (MQTT topics).</li>
			</ul>
			<p>There are shell scripts in the root of the <code>chapter3/</code> directory that individually start Redis (<a href="http://start-redis.sh">start-redis.sh</a>), MongoDB (<a href="http://start-mongodb.sh">start-mongodb.sh</a>), and the Mosca MQTT broker (<a href="http://start-mosca.sh">start-mosca.sh</a>), as well as a script, <a href="http://start-all.sh">start-all.sh</a> that starts all three.</p>
			<p>We've already detailed the workings of the <a href="http://start-mongodb.sh">start-mongodb.sh</a> script earlier. The <a href="http://start-redis.sh">start-redis.sh</a> and <a href="http://start-mosca.sh">start-mosca.sh</a> scripts are roughly the same; just the names of the programs that are started (Redis and Mosca) are changed.</p>
			<p>It is important <a id="_idIndexMarker167"/>to note that the <a href="http://start-mongodb.sh">start-mongodb.sh</a> script connects the host's port <code>27017</code> to the container's port <code>27017</code>. This is so that other containers can reach MongoDB via the default port. The <a href="http://start-mosca.sh">start-mosca.sh</a> script connects ports <code>1883</code> and <code>80</code> to the host so that MQTT and MQTT, over WebSocket, can be used from any of the containers. The <a href="http://start-redis.sh">start-redis.sh</a> script connects port <code>6379</code> to the host so that Redis can be accessed from the containers via the default Redis port. Of course, the host can access any of the containers as well.</p>
			<p>The subscriber/start-subscriber.sh and <a href="http://publisher-start-publisher.sh">publisher-start-publisher.sh</a> scripts both run the applications locally on the host, not in containers.  This allows host native debugging functionality, using WebStorm or another IDE or <a href="http://Node.js">Node.js</a> debugger. Developing and debugging our publisher and subscriber entirely within Docker containers is covered in the next chapter.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To use the <a href="http://start-subscriber.sh">start-subscriber.sh</a> and <a href="http://start-publisher.sh">start-publisher.sh</a> scripts, you will need to install <a href="http://Node.js">Node.js</a> and <code>yarn</code> on your development workstation. Ensure that you run <code>yarn install</code> in both <code>subscriber/</code> and <code>publisher/</code> directories.</p>
			<p>This is what <a href="http://start-subscriber.sh">start-subscriber.sh</a> looks like:</p>
			<pre>#!/bin/sh
# <a href="http://start-subscriber.sh">start-subscriber.sh</a>
yarn start</pre>
			<p>The <a href="http://start-publisher.sh">start-publisher.sh</a> script is identical to the <a href="http://start-subscriber.sh">start-subscriber.sh</a> script.  The <code>package.json</code> file in the publisher directory signals <code>yarn start</code> to launch the publisher program.</p>
			<p>The <code>HOSTIP</code> variable must be set to your host machine's IP, available to our publisher and subscriber, and is used by our Node.js programs to address the MQTT broker, MongoDB server, and Redis server when connecting.</p>
			<p>To find your IP on macOS (assuming you use <code>192.168.*.*</code> as your home network IP address range):</p>
			<pre># ifconfig | grep 192
inet 192.168.0.19 netmask 0xffff0000 broadcast 192.168.255.255</pre>
			<p>The IP of the host is <code>192.168.0.19</code>.</p>
			<p>To find your IP on Linux, use the following command:</p>
			<pre>$ ip address | grep 192
inet 192.168.0.21/16 brd 192.168.255.255 scope global dynamic enp0s31f6</pre>
			<p>The IP of this host is <code>192.168.0.21</code>.</p>
			<p>You will run the <code>start-publisher.sh</code> script using the following command:</p>
			<pre>HOSTIP=192.168.0.19 ./start-publisher.sh</pre>
			<p>To run the <code>start-subscriber.sh</code> script use the following command:</p>
			<pre>HOSTIP=192.168.0.19 ./start-subscriber.sh</pre>
			<p>The publisher <a id="_idIndexMarker168"/>program is relatively simple. It connects to the MQTT broker and listens for topics starting with <code>publisher/</code>. The topics and messages received are then converted into the <code>subscriber/</code> format topics and published to MQTT. The subscriber responds with the <code>publisher</code> topic and the response message.</p>
			<p>With both the publisher and subscriber running, we use the MQTT command-line tool to send messages to the publisher. In the following screenshot, you can see how we exercise a few of the subscriber commands.</p>
			<p>These two scripts assume that we have Mosca installed on our host. We don't need to install it for the MQTT broker, but for the command-line tools. Being able to send MQTT topics/commands <a id="_idIndexMarker169"/>from the command line on the host, in <code>.sh</code> scripts on the host, and in crontabs on the host is very useful. You can also use Mosca as a library to implement a broker in your own <a href="http://Node.js">Node.js</a> code.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">For curious readers, the screenshot is of a Terminal window running tmux with three panes. <strong class="bold">tmux</strong> is a <strong class="bold">terminal multiplexer</strong>: it enables several terminals to be created, accessed, and controlled from a single screen. The tmux GitHub repository can be found at <a href="https://github.com/tmux/tmux">https://github.com/tmux/tmux</a>.</p>
			<p>In the <a id="_idIndexMarker170"/>following screenshot, you can see how we exercise a <a id="_idIndexMarker171"/>few of the subscriber commands:</p>
			<p class="figure-caption"> </p>
			<div><div><img src="img/B11641_03_004.jpg" alt="Figure 3.4 – Three shells demonstrating the publisher and subscriber working together"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.4 – Three shells demonstrating the publisher and subscriber working together</p>
			<p>As we can see, the publisher and subscriber work as expected, as do the database queries between containers and the host. We can edit and debug the publisher and subscriber programs <a id="_idIndexMarker172"/>to get them working to our satisfaction.</p>
			<p>Now that we have these working publisher and subscriber containers, we want to share them with the rest of the development team.</p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor056"/>Sharing your containers on Docker Hub</h1>
			<p>To share our containers, we'll use Docker Hub and publish the two containers. The rest of the team <a id="_idIndexMarker173"/>can pull the pre-built containers from Docker Hub and use them without having to deal with the source code repository at all. They are <a id="_idIndexMarker174"/>just microservices to them, just as we don't need the source to Mosca, MongoDB, or Redis with those containers. </p>
			<p>Of course, the development team is going to have to run them.</p>
			<p>We have created an organization on Docker Hub, <code>dockerfordevelopers</code>, which we will use to publish the containers for this book. You won't be able to push to it, but we can. In order to publish to Docker Hub, you will need to use the <code>docker login</code> command, and you must have already created an account on <a href="https://hub.docker.com/">https://hub.docker.com/</a>.</p>
			<p>You can also create your own organization on Docker Hub where you can share your own containers. If you want to use the examples in the GitHub repository for this chapter, you will have to edit the scripts to replace <code>dockerfordevelopers</code> with your own organization name.</p>
			<p>Since we are creating our own custom containers, we will need some <code>.sh</code> scripts for each container, as explained in the previous chapter. There are a set of <code>.sh</code> scripts for the publisher and the subscriber.</p>
			<p>The Dockerfile used to build the container for the publisher is almost identical to the one used in the previous chapter:</p>
			<pre># we will inherit from the NodeJS v12 image on Docker Hub
FROM node:12
# set time zone so files' timestamps are correct
ENV TZ=America/Los_Angeles
# we include procps and telnet so you can use these with <a href="http://shell.sh">shell.sh</a> prompt
RUN apt-get update -qq &gt;/dev/null &amp;&amp; apt-get install -y -qq curl procps telnet &gt;/dev/null
# add a user - this user will own the files in /home/app
RUN useradd --user-group --create-home --shell /bin/false app
# set up and copy files to /home/app
ENV HOME=/usr/app
WORKDIR /home/app
COPY . /home/app
# install our NodeJS packages (from package.json)
RUN yarn install
# we run a script to stat the server; the array syntax makes it so ^C will work as we want
CMD  ["yarn", "start"]</pre>
			<p>The major difference in this Dockerfile and the one in the previous chapter is that we are not installing <a id="_idIndexMarker175"/>Apache and PHP, but we are inheriting from <code>node:12</code> and installing our <a href="http://Node.js">Node.js</a> program's required packages.</p>
			<p>We are inheriting from <code>node:12</code> in this Dockerfile for the publisher. The Dockerfile for the subscriber <a id="_idIndexMarker176"/>is identical, except that it inherits from <code>node:13</code>. This illustrates how you can have containers with different base software versions on the same host; this would be unpleasant to deal with on a host without containers.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <code>node:12</code> and <code>node:13</code> containers are pulled from Docker Hub and updated each time we build the containers.</p>
			<p>The following is the <a href="http://build.sh">build.sh</a> script that is used to build the publisher:</p>
			<pre>#!/bin/sh
# <a href="http://build.sh">build.sh</a>
# we use the "docker build" command to build a container named "dockerfordevelopers/publisher" from . (current directory)
# Dockerfile is found in the current directory, and determines how the container is built.
docker build -t dockerfordevelopers/publisher .</pre>
			<p>The <a href="http://build.sh">build.sh</a> script is very short and only really consists of the line, a single command. It is easier to type <code>./</code><a href="http://build.sh">build.sh</a> instead of the whole <code>docker build -t dockerfordevelopers/publisher .</code> command. This also makes the process less error-prone and you don't have to memorize the command-line switches and format.</p>
			<p>There is a nearly identical <a href="http://build.sh">build.sh</a> script for the subscriber, too. Only the name of the container <a id="_idIndexMarker177"/>built is different: <code>dockerfordevelopers/subscriber</code>.</p>
			<p>The output <a id="_idIndexMarker178"/>of the <a href="http://build.sh">build.sh</a> script for the publisher is as follows:</p>
			<pre># ./build.sh
Sending build context to Docker daemon  4.902MB
Step 1/9 : FROM node:12
Step 2/9 : ENV TZ=America/Los_Angeles
Step 3/9 : RUN apt-get update -qq &gt;/dev/null &amp;&amp; apt-get install -y -qq curl procps telnet &gt;/dev/null
Step 4/9 : RUN useradd --user-group --create-home --shell /bin/false app
Step 5/9 : ENV HOME=/usr/app
Step 6/9 : WORKDIR /home/app
Step 7/9 : COPY . /home/app
Step 8/9 : RUN yarn install
yarn install v1.16.0
[1/4] Resolving packages...
[2/4] Fetching packages...
[3/4] Linking dependencies...
[4/4] Building fresh packages...
Done in 1.55s.
Step 9/9 : CMD  ["yarn", "start"]
 ---&gt; Running in f882d870bc6a
Removing intermediate container f882d870bc6a
 ---&gt; b8f9439e36fa
Successfully built b8f9439e36fa
Successfully tagged dockerfordevelopers/publisher:latest</pre>
			<p>You can see that the <code>1/9</code>, <code>2/9</code>, <code>3/9</code>, and so on steps map one to one to the lines in our Dockerfile. The first line in our Dockerfile reads <code>From Node:12</code> and the <code>Step 1/1</code> line reads <code>From Node:12</code>. Similarly, <code>Step 2/2</code> is the second line in the Dockerfile. The build process follows the Dockerfile as a series of steps to build the final container image.</p>
			<p>The last line in the output tells us that the name of the container is <code>dockerfordevelopers/publisher:latest</code>. We use this name to push our build container to Docker Hub.</p>
			<p>We use the <a href="http://push.sh">push.sh</a> script to perform the commands to push the publisher container to the organization on Docker Hub:</p>
			<pre>#!/bin/sh
# <a href="http://push.sh">push.sh</a>
docker push dockerfordevelopers/publisher</pre>
			<p>This is <a id="_idIndexMarker179"/>another one-line <code>.sh</code> script for our convenience.</p>
			<p>The following <a id="_idIndexMarker180"/>is the output of the <a href="http://push.sh">push.sh</a> script for the publisher:</p>
			<pre># ./<a href="http://push.sh">push.sh</a>
The push refers to repository [<a href="http://docker.io/dockerfordevelopers/publisher">docker.io/dockerfordevelopers/publisher</a>]
9502c45a0d0e: Pushed
79b7f0047832: Pushed
bca5484440a2: Pushed
…
6a335755bda7: Pushed
latest: digest: sha256:e408ae01416511ad8451c31e532e3c2c6eb3324 ad43834a966ff161f9062e9ad size: 3056
#</pre>
			<p>We have a sort of template or pattern for working with custom containers in our microservices architecture project:</p>
			<ol>
				<li>We edit and debug the code for our container.</li>
				<li>We run the <a href="http://build.sh">build.sh</a> script to build a container image.</li>
				<li>We run the <a href="http://push.sh">push.sh</a> script to push the container to Docker Hub.</li>
			</ol>
			<p>Your fellow developers can now run the publisher image. This is run on a second machine, such as a developer's workstation:</p>
			<pre># docker run --rm dockerfordevelopers/publisher
Unable to find image 'dockerfordevelopers/publisher:latest' locally
latest: Pulling from dockerfordevelopers/publisher
c5e155d5a1d1: Pull complete
221d80d00ae9: Pull complete
4250b3117dca: Pull complete
69df12c70287: Pull complete
…
Digest: sha256:e408ae01416511ad8451c31e532e3c2c6eb3324ad 43834a966ff161f9062e9ad
Status: Downloaded newer image for dockerfordevelopers/publisher:latest
yarn run v1.16.0
$ node ./<a href="http://index.js">index.js</a></pre>
			<p>Of course, on this <a id="_idIndexMarker181"/>second machine, the developer has installed and run the required microservices: Mosca, MongoDB, and Redis. The application <a id="_idIndexMarker182"/>will not run without all the microservices running within Docker.</p>
			<p>Pushing to Docker Hub on your development host and pulling from Docker Hub on a production host is a simple way to deploy containers for production. It is not very robust, however. We will cover better schemes for deployment in later chapters.</p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor057"/>Summary</h1>
			<p>In this chapter, we learned how to break up an application that would normally be run in a virtual machine with multiple services (MongoDB, Redis, and Mosca) into a microservices-based architecture run as containers within Docker.</p>
			<p>We learned how to navigate the Docker Hub website and find useful pre-made Docker containers that you simply download and run.</p>
			<p>We also learned how to package our own microservices as Docker containers and how we can push them to Docker Hub for the public or development team members to use.</p>
			<p>Several containers were used to launch the complete application as microservices communicated through ports mapped to the host's ports. This is not ideal, especially if you already have a WWW server running on port <code>80</code>; Mosca uses port <code>80</code>, too.</p>
			<p>In the next chapter, we will discuss how we can use the Docker Compose tool to design complete microservice architecture applications and run them so that they have a private internal network and so host ports are not required.</p>
			<h1 id="_idParaDest-56"><a id="_idTextAnchor058"/>Further reading</h1>
			<p>You can refer to the following links for more information on the topics covered in this chapter:</p>
			<ul>
				<li>The official Docker documentation: <a href="https://docs.docker.com">https://docs.docker.com</a></li>
				<li>The Dockerfile reference: <a href="https://docs.docker.com/engine/reference/builder/">https://docs.docker.com/engine/reference/builder/</a></li>
				<li>The Docker Hub site: <a href="https://hub.docker.com/">https://hub.docker.com/</a></li>
				<li>The documentation for Docker Hub: <a href="https://docs.docker.com/docker-hub/">https://docs.docker.com/docker-hub/</a></li>
				<li>The documentation for the Node.js containers on Docker Hub: <a href="https://hub.docker.com/_/node">https://hub.docker.com/_/node</a></li>
				<li>The documentation for the Redis containers on Docker Hub: <a href="https://hub.docker.com/_/redis">https://hub.docker.com/_/redis</a></li>
				<li>The documentation for the MongoDB containers on Docker Hub: <a href="https://hub.docker.com/_/mongo">https://hub.docker.com/_/mongo</a></li>
				<li>The documentation for the Mosca containers on Docker Hub: <a href="https://hub.docker.com/r/matteocollina/mosca">https://hub.docker.com/r/matteocollina/mosca</a></li>
			</ul>
		</div>
	</body></html>