<html><head></head><body><div><div><p id="_idParaDest-285" class="chapter-number"><a id="_idTextAnchor823"/><em class="italic">Chapter 15</em></p>
			<h1 id="_idParaDest-286"><a id="_idTextAnchor824"/>Docker Workflows</h1>
			<p>By now, you should already be thinking about how you can start to introduce Docker into your everyday workflow. In this chapter, we'll put all the pieces together so you can start using Docker in your local development environment. We'll also look at some of the considerations that you need to take when planning your production environments. </p>
			<p>We will be covering the following topics in this chapter, all of which will build on what we have learned in the previous chapters:</p>
			<ul>
				<li>Docker for development</li>
				<li>Monitoring Docker and Kubernetes</li>
				<li>What does production look like?</li>
			</ul>
			<h1 id="_idParaDest-287"><a id="_idTextAnchor825"/>Technical requirements</h1>
			<p>In this chapter, we will be using Docker on the desktop. As with previous chapters, I will be using my preferred operating system, which is macOS. The Docker commands we will be running will work on all three of the operating systems we have installed Docker on so far; however, some of the supporting commands, which will be few and far between, may only apply to macOS- and Linux- based operating systems.</p>
			<h1 id="_idParaDest-288"><a id="_idTextAnchor826"/>Docker for development</h1>
			<p>We <a id="_idIndexMarker1057"/>are going to start our look at the workflows by discussing how Docker can be used to aid developers. Right back at the start of <a href="B15659_01_Final_JM_ePub.xhtml#_idTextAnchor046"><em class="italic">Chapter 1</em></a>,<em class="italic"> Docker Overview</em>, one of the first things we discussed in the <em class="italic">Understanding Docker</em> section was developers and the, works on my machine, problem. So far, we have not really fully addressed this, so let's do that now.</p>
			<p>In this section, we are going to look at how a developer could develop their WordPress project on their local machine using Docker for macOS or Docker for Windows, along with Docker Compose.</p>
			<p>The aim of<a id="_idIndexMarker1058"/> this is for us to launch a WordPress installation, which is what you will do by going through the following steps:</p>
			<ol>
				<li>Download and<a id="_idIndexMarker1059"/> install WordPress.</li>
				<li>Allow access to the WordPress files from desktop editors—such as Atom, Visual Studio Code, or Sublime Text—on your local machine.</li>
				<li>Configure and manage WordPress using the <strong class="bold">WordPress command-line</strong> tool (<strong class="bold">WPCLI</strong>). This allows you to stop, start, and even remove containers without losing your work.</li>
			</ol>
			<p>Before we launch our WordPress installation, let's take a look at the Docker Compose file, which you can find in the <code>chapter14/docker-wordpress</code> folder of the accompanying repositor<a id="_idTextAnchor827"/>y<a id="_idTextAnchor828"/>:</p>
			<pre>version: '3'
services:</pre>
			<p>We will be launching four different services, starting with <code>web</code>:</p>
			<pre>  web:
    image: nginx:alpine
    ports:
      - '8080:80'
    volumes:
      - './wordpress/web:/var/www/html'
      - './wordpress/nginx.conf:/etc/nginx/conf.d/default.conf'
    depends_on:
      - wordpress</pre>
			<p>Followed by the <code>wordpress</code> service:</p>
			<pre>  wordpress:
    image: wordpress:php7.2-fpm-alpine
    volumes:
      - './wordpress/web:/var/www/html'
    depends_on:
      - mysql</pre>
			<p>Next up, we <a id="_idIndexMarker1060"/>have the <code>mysql</code> database service:</p>
			<pre>  mysql:
      image: mysql:5
      environment:
        MYSQL_ROOT_PASSWORD: 'wordpress'
        MYSQL_USER: 'wordpress'
        MYSQL_PASSWORD: 'wordpress'
        MYSQL_DATABASE: 'wordpress'
      volumes:
        - './wordpress/mysql:/var/lib/mysql'</pre>
			<p>Finally, we have a<a id="_idIndexMarker1061"/> supporting service simply called <code>wp</code>:</p>
			<pre>  wp:
    image: wordpress:cli-2-php7.2
    volumes:
      - './wordpress/web:/var/www/html'
      - './wordpress/export:/export'</pre>
			<p>We can visualize the Docker Compose file using<a id="_idTextAnchor829"/> <a id="_idTextAnchor830"/>the <code>docker-compose-viz</code> tool from <code>PMSIpilot</code>. </p>
			<p>To do this, run the following command in the same folder as the <code>docker-compose.yml</code> f<a id="_idTextAnchor831"/>il<a id="_idTextAnchor832"/>e<a id="_idTextAnchor833"/>:</p>
			<pre>$ docker container run --rm -it --name dcv -v $(pwd):/input 
pmsipilot/docker-compose-viz render -m image docker-compose.yml</pre>
			<p>This will output <a id="_idIndexMarker1062"/>a file called <code>docker-compose.png</code>, and you should get something that looks like this:</p>
			<div><div><img src="img/Figure_15.01_B15659.jpg" alt="Figure 15.1: Output of the running docker-compose-viz against our WordPress Docker Compose file&#13;&#10;" width="988" height="443"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.1: Output of the running docker-compose-viz against our WordPress Docker Compose file</p>
			<p>The first service is called <a id="_idIndexMarker1063"/>web. This service is the only one of the four services that is exposed to the host network, and it acts as a frontend to our WordPress installation. It runs the official NGINX image from <a href="https://store.docker.com/images/nginx/">https://store.docker.com/images/nginx/</a> and it performs two roles. Take a look at the NGINX configuration and see if you can guess what they are:</p>
			<pre>server {
  server_name _;
  listen 80 default_server;
  root /var/www/html;
  index index.php index.html;
  access_log /dev/stdout;
  error_log /dev/stdout info;
  location / { 
    try_files $uri $uri/ /index.php?$args; 
  }
  location ~ .php$ {
    include fastcgi_params;
    fastcgi_pass wordpress:<a id="_idTextAnchor834"/>9<a id="_idTextAnchor835"/>000;
    fastcgi_index index.php;
    fastcgi_param SCRIPT_FILENAME    $document_root$fastcgi_script_name;
    fastcgi_buffers 16 16k;
    fastcgi_buffer_size 32k; 
  }
}</pre>
			<p>You can see that <a id="_idIndexMarker1064"/>we are <a id="_idIndexMarker1065"/>serving all content, apart from PHP, using the NGINX from <code>/var/www/html/</code>, which we are mounting from our host machine using NGINX, and all requests for PHP files are being proxied to our second service, which is called <code>wordpress</code>, on port <code>9000</code>. The NGINX configuration itself is being mounted from our host machine to <code>/etc/nginx/conf.d/default.conf</code>.</p>
			<p>What this means is that our NGINX container is acting as a web server for the static content, the first role, and also as a proxy through to the WordPress container for the dynamic content, which is the second role the container takes on—did you guess right?</p>
			<p>The second service is <code>wordpress</code>. This is the official WordPress image from <a href="https://hub.docker.com/images/wordpress">https://hub.docker.com/images/wordpress</a>, and I am using the <code>php7.2-fpm-alpine</code> tag. This gives<a id="_idIndexMarker1066"/> us a WordPress installation running on PHP 7.2 using <code>PHP-FPM</code> built<a id="_idIndexMarker1067"/> on top of an Alpine Linux base.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout"><strong class="bold">PHP FastCGI Process Manager </strong>(<strong class="bold">PHP-FPM</strong>) is <a id="_idIndexMarker1068"/>a PHP FastCGI implementation with some great features. For us, it allows PHP to run as a service that we can bind to a port and pass requests to; this fits in with the Docker method of running a single service on each container.</p>
			<p>We are mounting the same web root as we are using for the web service, which on the host machine is <code>wordpress/web</code> and on the service is <code>/var/www/html/</code>. To start off with, the folder on our host machine will be empty; however, once the WordPress service starts, it will detect that there isn't a core WordPress installation and copy one to that location, effectively bootstrapping our WordPress installation and copying it to our host machine, ready for us to start working on it.</p>
			<p>The third service is MySQL, which uses the official MySQL image, which can be found at <a href="https://hub.docker.com/images/mysql">https://hub.docker.com/images/mysql</a> and is the only image out of the four we are using that doesn't use Alpine Linux (come on MySQL; pull your finger out and publish an Alpine Linux-based image!). Instead, it uses <code>debian:buster-slim</code>. </p>
			<p>We are passing a few environment variables so that a database, username, and password are all created when the container first runs; the password is something you should change if you ever use this as a base for one of your projects.</p>
			<p>Like the web and <code>wordpress</code> containers, we are mounting a folder from our host machine. In this case, it is <code>wordpress/mysql</code>, and we are mounting it to <code>/var/lib/mysql/</code>, which is the default folder where MySQL stores its databases and associated files.</p>
			<p>The fourth and final service is simply called <code>wp</code>. It differs from the other three services: this service will immediately exit when executed because there is no long-running process within the container. Instead of a long-running process, we have a single process that is used to interact with and manage our WordPress installation.</p>
			<p>The advantage of running this tool in a container is that the environment we are running the command-line tool in exactly matches our main <code>wordpress</code> container.</p>
			<p>You will notice that we are mounting the web root as we have done on the web and WordPress, meaning that the container has full access to our WordPress installation as well as a second mount<a id="_idIndexMarker1069"/> called <code>/export</code>; we will look at this in more detail once we have WordPress configured.</p>
			<p>To start WordPress, we just <a id="_idIndexMarker1070"/>need to run the following command to pull the images:</p>
			<pre>$ docker-compose pull</pre>
			<p>This will pull the images and start the web, <code>wordpress</code>, and <code>mysql</code> services, as well as readying the <code>wp</code> service. Before the services start, our <code>wordpress</code> folder looks like this:</p>
			<div><div><img src="img/Figure_15.02_B15659.jpg" alt="Figure 15.2: Before launching WordPress&#13;&#10;" width="654" height="269"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.2: Before launching WordPress</p>
			<p>As you can see, we only have <strong class="bold">nginx.conf</strong> in there, which is part of the Git repository. Then we can use the following commands to start the containers and check thei<a id="_idTextAnchor836"/><a id="_idTextAnchor837"/><a id="_idTextAnchor838"/>r<a id="_idTextAnchor839"/> status:</p>
			<pre>$ docker-comp<a id="_idTextAnchor840"/><a id="_idTextAnchor841"/>ose up -d
$ docker-compose ps</pre>
			<p>Your Terminal output should look similar to the following screen:</p>
			<div><div><img src="img/Figure_15.03_B15659.jpg" alt="Figure 15.3: Launching and checking the status of our WordPress installation&#13;&#10;" width="1263" height="474"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.3: Launching and checking the status of our WordPress installation</p>
			<p>You <a id="_idIndexMarker1071"/>should see that three <a id="_idIndexMarker1072"/>folders have been created in the <code>wordpress</code> folder: <code>export</code>, <code>mysql</code>, and <code>web</code>. Also, remember that we are expecting <code>dockerwordpress_wp_1</code> to have an exit state of <code>Exit 1</code>, so that's fine:</p>
			<div><div><img src="img/Figure_15.04_B15659.jpg" alt="Figure 15.4: Checking the folders created by launching WordPress&#13;&#10;" width="726" height="298"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.4: Checking the folders created by launching WordPress</p>
			<p>Opening a browser a<a id="_idTextAnchor842"/>n<a id="_idTextAnchor843"/>d going to <code>http://localhost:8080/</code> should show you the standard WordPress preinstallation welcome page, where you can select the language you wish to use for your installation:</p>
			<div><div><img src="img/Figure_15.05_B15659.jpg" alt="Figure 15.5: The WordPress setup screen&#13;&#10;" width="1016" height="655"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.5: The WordPress setup screen</p>
			<p>Do not click on <strong class="bold">Continue</strong>, as it will take you to the next screen of the GUI-based installation. Instead, return to your Terminal.</p>
			<p>Rather than <a id="_idIndexMarker1073"/>using the GUI to<a id="_idIndexMarker1074"/> complete the installation, we are going to use <code>wp-cli</code>. There are two steps to this. The first step is to create a <code>wp-config.php</code> file. To do this, run the followin<a id="_idTextAnchor844"/><a id="_idTextAnchor845"/>g command:</p>
			<pre>$ docker-compose run wp core config \
    --dbname=wordpress \
    --dbuser=wordpress \
    --dbpass=wordpress \
    --dbhost=mysql \
    --dbprefix=wp_</pre>
			<p>As you will see in the following Terminal output, before I ran the command, I just had the <code>wp-config-sample.php</code> file, which ships with core WordPress. Then, after running the command, I had my own <code>wp-config.php</code> file:</p>
			<div><div><img src="img/Figure_15.06_B15659.jpg" alt="Figure 15.6: Creating the wp-config.php file using wp-cli&#13;&#10;" width="1258" height="364"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.6: Creating the wp-config.php file using wp-cli</p>
			<p>You will notice <a id="_idIndexMarker1075"/>that in the command, we are passing the database details that we defined in the Docker Compose file and telling WordPress that it can connect to the database service at the address of <code>mysql</code>.</p>
			<p>Now that we have configured<a id="_idIndexMarker1076"/> database connection details, we need to configure our WordPress site, as well as create an admin user and set a password. To do this, run the following command:</p>
			<pre>$ docker-compose run wp core install \
    --title='Blog Title' \
    --url='http://localhost:8080' \
    --admin_user='admin' \
    --admin_password='password' \
    --admin_email='email@domain.com'</pre>
			<p>Running this command will produce an error in the email service; do not worry about this message, as this is only a local development environment. We are not too worried about emails leaving our WordPress installation:</p>
			<div><div><img src="img/Figure_15.07_B15659.jpg" alt="Figure 15.7: Configuring WordPress using cp-cli&#13;&#10;" width="1257" height="309"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.7: Configuring WordPress using cp-cli</p>
			<p>We have used wp-cli to <a id="_idIndexMarker1077"/>configure the following in WordPress:</p>
			<ul>
				<li>Our URL is <strong class="bold">http://localhost:8080</strong>.</li>
				<li>Our site title should be <strong class="bold">Blog Title</strong>.</li>
				<li>Our admin username is <strong class="bold">admin</strong> and our password is <strong class="bold">password</strong>, and the user has the email address <strong class="bold">email@domain.com</strong>.</li>
			</ul>
			<p>Going back to your browser and entering <code>http://localhost:8080/</code> should present you with a vanilla WordPress site:</p>
			<div><div><img src="img/Figure_15.08_B15659.jpg" alt="Figure 15.8: A default WordPress site&#13;&#10;" width="1176" height="551"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.8: A default WordPress site</p>
			<p>Before we do anything further, let's customize our installation a little, first by installing and enabling the <strong class="bold">JetPack</strong> plugin:</p>
			<pre>$ docker-compose run wp plugin install jetpack –activate</pre>
			<p>The output of the<a id="_idIndexMarker1078"/> command is<a id="_idTextAnchor846"/> g<a id="_idTextAnchor847"/>iven here:</p>
			<div><div><img src="img/Figure_15.09_B15659.jpg" alt="Figure 15.9: Installing the JetPack plugin&#13;&#10;" width="1256" height="336"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.9: Installing the JetPack plugin</p>
			<p>Then, <code>install</code> and enable the <strong class="bold">Syd<a id="_idTextAnchor848"/>n<a id="_idTextAnchor849"/>ey</strong> theme:</p>
			<pre>$ docker-compose run wp theme install sydney --activate</pre>
			<p>The output of the command is given here:</p>
			<div><div><img src="img/Figure_15.10_B15659.jpg" alt="Figure 15.10: Installing the Sydney theme&#13;&#10;" width="1258" height="336"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.10: Installing the Sydney theme</p>
			<p>Refreshing our WordPr<a id="_idTextAnchor850"/>e<a id="_idTextAnchor851"/>ss page at <code>http://localhost:8080/</code> should show something like the following:</p>
			<div><div><img src="img/Figure_15.11_B15659.jpg" alt="Figure 15.11: Viewing our site with the updated theme&#13;&#10;" width="880" height="510"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.11: Viewing our site with the updated theme</p>
			<p>Before we open our IDE, let's destroy the containers running our WordPress installation using the following <a id="_idTextAnchor852"/>c<a id="_idTextAnchor853"/>ommand:</p>
			<pre>$ docker-compose down</pre>
			<p>The output of the <a id="_idIndexMarker1079"/>command is given here:</p>
			<div><div><img src="img/Figure_15.12_B15659.jpg" alt="Figure 15.12: Stopping and removing the containers that are running WordPress&#13;&#10;" width="1257" height="446"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.12: Stopping and removing the containers that are running WordPress</p>
			<p>As our entire WordPress installation, including all of the files and the database, is stored on our local machine, we should be able to run the following command to return our WordPress site where we left it:</p>
			<pre>$ docker-compose up -d</pre>
			<p>Once you have confirmed that it is up and running as expected by going to <code>http:// localhost:8080/</code>, open the <code>docker-wordpress</code> folder in your desktop editor. I used Visual Studio Code. </p>
			<p>In your editor, open the <code>wor<a id="_idTextAnchor854"/>d<a id="_idTextAnchor855"/>p<a id="_idTextAnchor856"/>ress/web/wp-blog-header.php</code> file, add the following line to the opening PHP statement, an<a id="_idTextAnchor857"/>d<a id="_idTextAnchor858"/> save it:</p>
			<pre>echo 'Testing editing in the IDE';</pre>
			<p>The file should look <a id="_idIndexMarker1080"/>something like the following:</p>
			<div><div><img src="img/Figure_15.13_B15659.jpg" alt="Figure 15. 13: Editing wp-blog-header.php in Visual Studio Code&#13;&#10;" width="987" height="737"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15. 13: Editing wp-blog-header.php in Visual Studio Code</p>
			<p>Once saved, refresh your browser. You should see the message <strong class="bold">Testing editing in the IDE</strong> at the very bottom of the page (the following screen is zoomed; it may be more difficult to spot if you are following along on screen, as the text is quite small):</p>
			<div><div><img src="img/Figure_15.14_B15659.jpg" alt="Figure 15.14: Viewing our edit on the page&#13;&#10;" width="935" height="217"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.14: Viewing our edit on the page</p>
			<p>The final thing we are going to look at is why we had the <code>wordpress/export</code> folder mounted on the <code>wp</code> container.</p>
			<p>As already mentioned earlier in the chapter, you shouldn't really be touching the contents of the <code>wordpress/mysql</code> folder; this also includes sharing it. While it would probably work if you were to zip up your project folder and pass it to a colleague, this is not considered best practice. Because of this, we have mounted the export folder to allow us to use WPCLI to<a id="_idIndexMarker1081"/> make a database dump and import it.</p>
			<p>To do this, run the followin<a id="_idTextAnchor859"/><a id="_idTextAnchor860"/>g <a id="_idTextAnchor861"/><a id="_idTextAnchor862"/><a id="_idTextAnchor863"/>c<a id="_idTextAnchor864"/>ommand:</p>
			<pre>$ docker-compose run wp db export --add-drop-table /export/
wordpress.sql</pre>
			<p>Depending on the version of Docker you are running, you may receive a permission-denied error when running the preceding command; if you do, then run the following command instead:</p>
			<pre>$ docker-compose run wp db export --add-drop-table /var/www/
html/wor<a id="_idTextAnchor865"/><a id="_idTextAnchor866"/>dpress.sql</pre>
			<p>This will copy the database dump to <code>wordpress/wordpress</code> rather than <code>wordpress/export</code>. The reason for this is that different host operating systems handle the creation of local files differently, which can cause permission issues within the container itself.</p>
			<p>The following Terminal output shows the export and also the c<a id="_idTextAnchor867"/><a id="_idTextAnchor868"/><a id="_idTextAnchor869"/><a id="_idTextAnchor870"/>ontents of <code>wordpress/export</code> before and after the command being run, and lastly, the top few lines of the MySQL dump file:</p>
			<div><div><img src="img/Figure_15.15_B15659.jpg" alt="Figure 15.15: Dumping the WordPress database&#13;&#10;" width="1244" height="639"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.15: Dumping the WordPress database</p>
			<p>If I had, say, made a <a id="_idIndexMarker1082"/>mistake during development and accidently trashed part of my database, I could roll back to the backup of the database I made by running the following <a id="_idTextAnchor871"/>c<a id="_idTextAnchor872"/>ommand:</p>
			<pre>$ docker-compose run wp db import /export/wordpress.sql</pre>
			<p>The output of the command is given here:</p>
			<div><div><img src="img/Figure_15.16_B15659.jpg" alt="Figure 15.16: Importing the WordPress database&#13;&#10;" width="1254" height="144"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.16: Importing the WordPress database</p>
			<p>As you can seen, we have installed WordPress, interacted with it using both the WordPress command-line tool, <code>wp-cli</code>, and also in a web browser, edited the code, and backed up and restored the database, all without having to install or configure <code>NGINX</code>, <code>PHP</code>, <a id="_idTextAnchor873"/><code>M<a id="_idTextAnchor874"/>ySQL</code>, or <code>wp-cli</code> on our local machine. Nor did we have to log in to a container. By mounting volumes from our host machine, our content was safe when we tore our WordPress containers down and we didn't lose any work.</p>
			<p>Also, if needed, we could have easily passed a copy of our project folder to a colleague who has Docker installed, and with a single command, they could be working on our code, knowing that it is running in the same exact environment as our own installation.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">If you like, you can stop and remove your WordPress containers by running <code>docker-compose</code> down. If you are following along, you might want to keep WordPress for the next section so that you have running containers to monitor.</p>
			<p>Finally, as we're using official<a id="_idIndexMarker1083"/> images from the Docker Hub, we know we can safely ask to have them deployed into production, as they have been built with Docker's best practices in mind.</p>
			<p>One thing that you may find really useful is how well Docker can be integrated in your IDE of choice. A few pages back, when we edited the <code>wp-blog-header.php</code> file, you may have noticed a Docker icon on the left-hand side of the screen. Before we finish this section of the chapter, let's quickly discuss how Microsoft have integrated Docker support into Visual Studio Code, or VS Code, as we will be calling it from now on.</p>
			<p>The first thing you need to do is install VS Code, which you can find at <a href="https://code.visualstudio.com/">https://code.visualstudio.com/</a>, and the Microsoft Docker extension, which can found in the Visual Studio Market place at <a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker">https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker</a>.</p>
			<p>You will notice that the extension is not in your face. This is because it integrates quite d<a id="_idTextAnchor875"/>e<a id="_idTextAnchor876"/>eply with VS Code—for example,  if you were to right-click over the <code>docker-compose.yml</code> file in the explorer, you will notice that the menu has some options that allow you to interact with Docker Compose:</p>
			<div><div><img src="img/Figure_15.17_B15659.jpg" alt="Figure 15.17: Running Docker Compose from VS Code&#13;&#10;" width="1181" height="1063"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.17: Running Docker Compose from VS Code</p>
			<p>Clicking on the <strong class="bold">Docker</strong> icon on the<a id="_idIndexMarker1084"/> left-hand side will bring up a list running Containers, available Images, Registries that you are connected to, Networks, and Volumes:</p>
			<div><div><img src="img/Figure_15.18_B15659.jpg" alt="Figure 15.18: Viewing your running containers&#13;&#10;" width="1107" height="515"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.18: Viewing your running containers</p>
			<p>Right-clicking over a container gives you the option to attach to the running container using the terminal that is built into VS Code:</p>
			<div><div><img src="img/Figure_15.19_B15659.jpg" alt="Figure 15.19: Attaching to a container using the built-in terminal&#13;&#10;" width="1184" height="669"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.19: Attaching to a container using the built-in terminal </p>
			<p>Opening the folder from the Git<a id="_idIndexMarker1085"/> repository that accompanies this title in VS Code<a id="_idTextAnchor877"/> <a id="_idTextAnchor878"/>and then pressing <em class="italic">CMD +Shift + P</em> will open the command prompt in VS Code. From here, type <code>Dockerfile</code> files and ask you which one you want to build:</p>
			<div><div><img src="img/Figure_15.20_B15659.jpg" alt="Figure 15.20: Choosing a Dockerfile to build&#13;&#10;" width="1084" height="668"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.20: Choosing a Dockerfile to build</p>
			<p>Once built, your image will be<a id="_idIndexMarker1086"/> listed in the Docker section, and you can right-click over the tag to push it to any of the registries you are connected to:</p>
			<div><div><img src="img/Figure_15.21_B15659.jpg" alt="Figure 15.21: Pushing our newly built image&#13;&#10;" width="1150" height="664"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.21: Pushing our newly built image</p>
			<p>You can also run the container. Once it is running, you can then right-click on it and select <strong class="bold">Open in browser</strong> to go straight to the application:</p>
			<div><div><img src="img/Figure_15.22_B15659.jpg" alt="Figure 15.22: Opening a running container in your browser&#13;&#10;" width="1204" height="666"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.22: Opening a running container in your browser</p>
			<p>The final trick up the VS Code<a id="_idIndexMarker1087"/> Docker extension's sleeve that we are going to cover is an extremely useful one. Let's say that you have a repository with no <code>Dockerfile</code>—for example, the Go Training <code>helloworld</code> repository, which can be found at <a href="https://github.com/go-training/helloworld/">https://github.com/go-training/helloworld/</a>, has no <code>Dockerfile</code> or <code>docker-compose.yml</code> files. Grab a copy of it and open it in VS Code.</p>
			<p>Once open, press <em class="italic">CMD +Shift + P</em>, type in <code>Add Docker</code>, and then select <code>3000</code>. Once you hit <code>Dockerfile</code>, which looks like the following, will be opened:</p>
			<div><div><img src="img/Figure_15.23_B15659.jpg" alt="Figure 15.23: A VS-Code-generated, multistage Dockerfile&#13;&#10;" width="610" height="357"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.23: A VS-Code-generated, multistage Dockerfile</p>
			<p>You will also notice that a <code>docker-compose.yml</code> file along with a <code>.dockerignore</code> and a few other files have been generated. From here, you can build the image, and then run it. I recommend using the <strong class="bold">Run interactive</strong> option as all the application does is print <strong class="bold">Hello World!</strong> and then exit, as shown in the following screenshot:</p>
			<div><div><img src="img/Figure_15.24_B15659.jpg" alt="Figure 15.24: Running the application&#13;&#10;" width="1102" height="370"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.24: Running the application</p>
			<p>As I am sure you have seen, the<a id="_idIndexMarker1088"/> Docker integration with VS Code is extremely powerful, and enables you to run pretty much every Docker command that we have covered in previous chapters from within VS Code. There are similar extensions for other IDEs. These are linked in the <em class="italic">Further reading</em> section.</p>
			<h2 id="_idParaDest-289">Doc<a id="_idTextAnchor879"/>k<a id="_idTextAnchor880"/>er and Azure De<a id="_idTextAnchor881"/>v<a id="_idTextAnchor882"/>Ops</h2>
			<p>In <a href="B15659_03_Final_JM_ePub.xhtml#_idTextAnchor109"><em class="italic">Chapter 3</em></a><em class="italic">, Storing and Distributing Images</em> in the <em class="italic">Reviewing third-party registries</em> section, we<a id="_idIndexMarker1089"/> looked at how we can use GitHub to both host and <a id="_idIndexMarker1090"/>also build our container images. We also discussed Azure Container Registry.</p>
			<p>To close this section of the chapter, we are going to quickly look at getting an Azure DevOps pipeline configured that builds the multistage Dockerfile that we covered in <a href="B15659_02_Final_JM_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 2</em></a><em class="italic">, Building Container Images</em>. </p>
			<p>Before we configure our pipeline, let's discuss what Azure DevOps is. It is a service offered by Microsoft that provides the following capabilities:</p>
			<ul>
				<li>Version control</li>
				<li>Reporting</li>
				<li>Requirements management</li>
				<li>Project management</li>
				<li>Automated builds</li>
				<li>Testing</li>
				<li>Release management</li>
			</ul>
			<p>That might seem like a lot of different services, and it is, but Azure DevOps is the glue that can bind together various Microsoft services in both the Microsoft Azure ecosystem and their programming languages, such as .NET, and tools, such as Visual Studio. Covering everything would take up an entire book; in fact, there are several on the subject, so we will only be touching upon the basic functionality needed to build our container and push it to the Docker Hub.</p>
			<p>The only requirement you need <a id="_idIndexMarker1091"/>to get started with Azure DevOps is an account—to sign <a id="_idIndexMarker1092"/>up for free, go to <a href="https://dev.azure.com/%20">https://dev.azure.com/ </a>and follow the on-screen prompts. Once you have created your account, click on the <strong class="bold">+ New project</strong> button.</p>
			<p>Once you are on the <strong class="bold">Create new project</strong> page, you will find the option to fill in a <strong class="bold">Project</strong><strong class="bold"> </strong><strong class="bold">Name</strong> and <strong class="bold">Description</strong> and choose the <strong class="bold">Visibility</strong>; by default, projects are <strong class="bold">Private</strong>, but you can also make them <strong class="bold">Public</strong>.</p>
			<p>Fill in the details and then click on <strong class="bold">Create</strong>. I would recommend making your project <strong class="bold">Private</strong>.</p>
			<p>Once your project has been created, click on the <strong class="bold">Project Settings</strong> option, which can be found at the very bottom of the left-hand side menu. Once the <strong class="bold">Project Settings</strong> page loads, click on <strong class="bold">Service connections</strong>, which can be found under <strong class="bold">Pipelines</strong>.</p>
			<p>From there, click the <strong class="bold">Create Service</strong> connection button and select <strong class="bold">Docker Registry </strong>from the list of services you are presented with.</p>
			<p>From here, select the radio icon next to <strong class="bold">Docker Hub</strong>, enter your Docker ID, and then enter your <strong class="bold">Docker password</strong>. If your Docker Hub account is protected by multifactor authentication, which I really recommend you configure, then you will need a user access token—we covered this in the Docker Hub section of <a href="B15659_03_Final_JM_ePub.xhtml#_idTextAnchor109"><em class="italic">Chapter 3</em></a><em class="italic">, Storing and Distributing Images</em>:</p>
			<div><div><img src="img/Figure_15.25_B15659.jpg" alt="Figure 15.25: Setting up the service connection to Docker Hub&#13;&#10;" width="966" height="627"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.25: Setting up the service connection to Docker Hub</p>
			<p>Once you have entered<a id="_idIndexMarker1093"/> your details, click on the <strong class="bold">Verify</strong> button, and if the details you entered are correct, you will get a green tick. Before you click on the <strong class="bold">Verify and save</strong> button, you<a id="_idIndexMarker1094"/> need to enter a <strong class="bold">Service connection name</strong>; I entered <strong class="bold">Docker</strong>, but you can use whatever you like—just make a note of it as we will need it shortly.</p>
			<p>Next up, you wil<a id="_idTextAnchor883"/>l<a id="_idTextAnchor884"/> need a Git repository that contains the <code>Dockerfile</code> as well as a file called <code>azure-pipelines.yml</code>—there is an example repository at <a href="https://github.com/russmckendrick/DevOpsContainerBuild">https://github.com/russmckendrick/DevOpsContainerBuild</a> that you can fork. </p>
			<p>Once you have your repository, return to your Azure DevOps project and then click on <strong class="bold">Pipelines</strong> in the left-hand side menu—here, you will be presented with the following screen:</p>
			<div><div><img src="img/Figure_15.26_B15659.jpg" alt="Figure 15.26: Viewing the Pipelines page for the first time&#13;&#10;" width="819" height="452"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.26: Viewing the Pipelines page for the first time</p>
			<p>As you may have guessed, you need to click on <strong class="bold">Create Pipeline</strong>, this will ask you for several pieces of information:</p>
			<ol>
				<li value="1"><strong class="bold">Where is your code?</strong> Select GitHub. You will notice that YAML is next to it. We will be talking<a id="_idIndexMarker1095"/> about the YAML file once we have the pipeline <a id="_idIndexMarker1096"/>configured.</li>
				<li>Follow the onscreen instructions to link Azure DevOps to your GitHub account. Once it is linked, you will be aske<a id="_idTextAnchor885"/>d<a id="_idTextAnchor886"/> to <strong class="bold">Select a repository</strong>. Select the repository that you forked earlier.</li>
				<li>If the <code>azure-pipelines.yml</code> file is not automatically selected and you stay on the <strong class="bold">Configure</strong> screen, click on the <strong class="bold">Existing Azure Pipelines YAML file</strong> option, select the file from the drop-down list, and then click on <strong class="bold">Continue</strong>.</li>
				<li>The <strong class="bold">Review</strong> page gives you the option to <strong class="bold">Review your pipeline YAML</strong> file, as well as the option to <strong class="bold">Run</strong> it; however, before we do, click on <strong class="bold">Variables</strong>.</li>
				<li>We need to add two variables. The first will let the pipeline know the name of the service connection to Docker Hub that we configured earlier in this section and the second one will let the pipeline know the name of the Docker Hub repository we would like our Azure DevOps pipeline to push the image to once it has been built.</li>
				<li>Click on the <code>targetRegistry</code> in the <code>Docker</code>. Click on the <code>targetRepo</code>, then for the <code>russmckendrick/AzureDevOpsBuild</code>. Click on <strong class="bold">OK</strong> and then <strong class="bold">Save</strong>. Once saved, click on the <strong class="bold">Run</strong> button to trigger yo<a id="_idTextAnchor889"/>u<a id="_idTextAnchor890"/>r build.</li>
			</ol>
			<p>The <code>azure-pipeline.yml</code> file looks like the following. First, we have the <strong class="bold">trigger</strong> configuration; this is set to <strong class="bold">master</strong>, which <a id="_idIndexMarker1097"/>means that a build is triggered every time that <a id="_idIndexMarker1098"/>the master branch is updated:</p>
			<pre>trigger:
- master</pre>
			<p>Next up, we have <strong class="bold">pool</strong>. This tells Azure DevOps which virtual image to launch when the pipeline is being executed; as you can see, we are using Ubuntu:</p>
			<pre>pool:
  vmImage: 'ubuntu-latest'</pre>
			<p>The remainder of the <code>azure-pipeline.yml</code> file is the build <code>Docker@2</code> task to log in to Docker Hub:</p>
			<pre>steps:
- task: 'Docker@2'
  displayName: 'Login to Docker Hub'
  inputs:
    command: 'login'
    con<a id="_idTextAnchor891"/>t<a id="_idTextAnchor892"/>a<a id="_idTextAnchor893"/>inerRegistry: '$(targetRegistry)'</pre>
			<p>We are using the variable that we defined when setting up the pipeline by entering <code>$(targetRegistry)</code>. This lets the task know which service connection to use. The next task builds and pushes our container image:</p>
			<pre>- task: Docker@2
  displayName: 'Build &amp; Push container'
  inputs:
    command: 'buildAndPush'
    containerRegistry: '$(targetRegistry)'
<a id="_idTextAnchor894"/>    repository: '$(targetRepo)'
    tags: |
      latest</pre>
			<p>As you can see, the syntax is <a id="_idIndexMarker1099"/>easy to follow. We are also using the second <a id="_idIndexMarker1100"/>variable <code>$(targetRepo)</code> to define the target for our image to be pushed to. The final task logs out of Docker Hub:</p>
			<pre>- task: 'Docker@2'
  displayName: 'Logout of Docker Hub'
  inputs:
    command: 'logout'
    containerRegistry: '$(targetRegistry)'</pre>
			<p>While the last task is probably not really needed, as, while Azure DevOps spins up to build our image, the virtual machine is terminated once the build finishes, it will also be terminated if there are any errors, so we do not have to worry about the virtual machine being reused or our login being accessed by a third party.</p>
			<p>A completed pipeline run looks something like the following:</p>
			<div><div><img src="img/Figure_15.27_B15659.jpg" alt="Figure 15.27: A completed pipeline run&#13;&#10;" width="979" height="483"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.27: A completed pipeline run</p>
			<p>Once finished, you should <a id="_idIndexMarker1101"/>see the newly built container in your Docker Hub account. As mentioned before we started to configure our Azure DevOps pipeline, we have<a id="_idIndexMarker1102"/> hardly scratched the surface of what Azure DevOps can do; see the <em class="italic">Further reading</em> section of this chapter for some interesting links on Azure DevOps.</p>
			<p>Next, we are going to take a look at how to monitor our containers and Docker hosts. </p>
			<h1 id="_idParaDest-290">Mon<a id="_idTextAnchor895"/>i<a id="_idTextAnchor896"/>toring Docker and Kubernetes</h1>
			<p>In <a href="B15659_04_Final_JM_ePub.xhtml#_idTextAnchor133"><em class="italic">Chapter 4</em></a>, <em class="italic">Managing Containers</em>, we discussed the <code>docker container top</code> and <code>docker container stats</code> commands. You <a id="_idIndexMarker1103"/>may recall that both of these commands show real-time information only—there is no historical data that is kept.</p>
			<p>This is great if you are trying to debug a problem as it is running or want to quickly get an idea of what is going on inside your containers; however, it is not too helpful if you need to look back at a problem. For example, you may have configured your containers to restart if they have become unresponsive. While that will help with the availability of your application, it isn't much of a help if you need to look at why your container became unresponsive.</p>
			<p>In the GitHub repository in the <code>/chapter14</code> folder, there<a id="_idTextAnchor897"/> <a id="_idTextAnchor898"/>is a folder called <code>prometheus</code> in which there is a Docker Compose file that launches three different containers on two networks. Rather than looking at the Docker Compose file itself, l<a id="_idTextAnchor899"/>et'<a id="_idTextAnchor900"/>s take a look at a visualization:</p>
			<div><div><img src="img/Figure_15.28_B15659.jpg" alt="Figure 15.28: Visualization of the Prometheus Docker Compose file&#13;&#10;" width="1208" height="556"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.28: Visualization of the Prometheus Docker Compose file</p>
			<p>You can generate this <a id="_idIndexMarker1104"/>yourself by running the f<a id="_idTextAnchor901"/>o<a id="_idTextAnchor902"/>llowing command:</p>
			<pre>$ docker container run --rm -it --name dcv -v $(pwd):/input 
pmsipilot/docker-compose-viz render -m image docker-compose.yml</pre>
			<p>As you can see, there is a lot going on. The three services that we are running are as follows:</p>
			<ul>
				<li>Cadvisor</li>
				<li>Prometheus</li>
				<li>Grafana</li>
			</ul>
			<p>Before we launch and configure our Docker Compose services, we should talk about why each one is needed, starting with <code>cadvisor</code>:</p>
			<p>The <code>cadvisor</code> service is a project that was released by Google. As you can see from the Docker Hub username in the image we are using, the service section in the Docker Compose file looks like the following:</p>
			<pre>  cadvisor:
    image: google/cadvisor:latest
    container_name: cadvisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    restart: unless-stopped
    expose:
      - 8080
    networks:
      - back</pre>
			<p>We are mounting the <a id="_idIndexMarker1105"/>various parts of our host's filesystem to allow <code>cadvisor</code> access to our Docker installation in much the same way as we did in <a href="B15659_09_Final_JM_ePub.xhtml#_idTextAnchor261"><em class="italic">Chapter 9</em></a>, <em class="italic">Portainer</em> – <em class="italic">A GUI for Docker</em>. The reason for this is that, in our case, we are going to be using <code>cadvisor</code> to collect statistics on our containers. While it can be used as a standalone container-monitoring service, we do not want to publicly expose the <code>cadvisor</code> container. Instead, we are just making it available to other containers within our Docker Compose stack on the back network.</p>
			<p>The <code>cadvisor</code> service is a self-contained web frontend to the Docker container stat command, displaying graphs and allowing you to drill down from your Docker host into your containers using an easy-to-use interface; however, it doesn't keep more than five minutes' worth of metrics.</p>
			<p>As we are attempting to record metrics that can be available hours or even days later, having no more than five minutes' worth of metrics means that we are going to have to use additional tools to record the metrics it processes. The <code>cadvisor</code> service exposes the information that we want to record in our containers as structured data at <code>http://cadvisor:8080/metrics/</code>.</p>
			<p>We will look at why this is important in a moment. The <code>cadvisor</code> endpoint is being scraped automatically by our next service, <code>prometheus</code>. This is where most of the heavy lifting happens. The <code>prometheus</code> is a monitoring tool that is written and open sourced by SoundCloud:</p>
			<pre>  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.
yml
      - prometheus_data:/prometheus
    restart: unless-stopped
    expose:
      - 9090
    depends_on:
      - cadvisor
    networks:
      - back</pre>
			<p>As you can see from the preceding service definition, we are mounting a configuration file called <code>./prometheus/prometheus.yml</code> and a volume called <code>prometheus_data</code>. The configuration file contains <a id="_idIndexMarker1106"/>information about the sources we want to scrape, as you can see from the following configuration:</p>
			<pre>global:
  scrape_interval:     15s 
  evaluation_interval: 15s
  external_labels:
      monitor: 'monitoring'
rule_files:
scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']</pre>
			<p>We are instructing Prometheus to scrape data from our endpoints every 15 seconds. The endpoints are defined in the <code>scrape_configs</code> section, and as you can see, we have <code>cadvisor</code> defined in there, as well as Prometheus itself. The reason we are creating and mounting the <code>prometheus_data</code> volume is that <a id="_idIndexMarker1107"/>Prometheus is going to be storing all of our metrics, so we need to keep it safe.</p>
			<p>At its core, Prometheus is a time-series database. It takes the data it has scraped, processes it to find the metric name and value, and then stores it along with a timestamp.</p>
			<p>Prometheus<a id="_idIndexMarker1108"/> also comes with a powerful query engine and API, making it the perfect database for this kind of data. While it does come with basic graphing capabilities, it is recommended that you use <em class="italic">Grafana</em>, which is our final service, and also the only one to be exposed publicly.</p>
			<p><em class="italic">Grafana</em> is an <a id="_idIndexMarker1109"/>open source tool for displaying monitoring graphs and metric analytics, which allows you to create dashboards using time-series databases, such as Graphite, InfluxDB, and also Prometheus. There are also further backend database options that are available as plugins.</p>
			<p>The Docker Compose definition for Grafana follows a similar pattern to our other services:</p>
			<pre>  grafana:
    image: grafana/grafana
    container_name: grafana
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/:/etc/grafana/provisioning/
    env_file:
      - ./grafana/grafana.config
    restart: unless-stopped
    ports:
      - 3000:3000
    depends_on:
      - prometheus
    networks:
      - front
      - back</pre>
			<p>We are <a id="_idIndexMarker1110"/>using the <code>grafana_data</code> volume to store <a id="_idIndexMarker1111"/>Grafana's own internal configuration database, and rather than storing the environment variables in the Docker Compose file, we are loading them from an external file called <code>./grafana/grafana.config</code>.</p>
			<p>The variables are as follows:</p>
			<pre>GF_SECURITY_ADMIN_USER=admin
GF_SECURITY_ADMIN_PASSWORD=password
GF_USERS_ALLOW_SIGN_UP=false</pre>
			<p>As you can see, we are setting the username and password here, so having them in an external file means that you can change these values without editing the core Docker Compose file.</p>
			<p>Now that we know the role that each of the three services fulfills, let's launch them. </p>
			<p>To do this, simply run the f<a id="_idTextAnchor903"/>o<a id="_idTextAnchor904"/>llowing commands from the <code>prometheus</code> folder:</p>
			<pre>$ docker-compose pull
$ docker-compose up -d</pre>
			<p>This will create a network and the volumes and pull the images from the Docker Hub. It will then go about launching the three services:</p>
			<div><div><img src="img/Figure_15.29_B15659.jpg" alt="Figure 15.29: Running docker-compose up -d to launch our Prometheus application&#13;&#10;" width="1253" height="309"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.29: Running docker-compose up -d to launch our Prometheus application</p>
			<p>You may be tempted to go immediately to your <a id="_idIndexMarker1112"/>Grafana dashboard. If you did, you would not see anything, as Grafana takes a few minutes to initialize itself. You can follow its progress<a id="_idTextAnchor905"/> <a id="_idTextAnchor906"/>b<a id="_idTextAnchor907"/>y looking at the logs:</p>
			<pre>$ docker-compose logs -f grafana</pre>
			<p>The output of the command is given here:</p>
			<div><div><img src="img/Figure_15.30_B15659.jpg" alt="Figure 15.30: Checking the logs to see if Grafana is ready&#13;&#10;" width="1257" height="309"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.30: Checking the logs to see if Grafana is ready</p>
			<p>Once you see the <code>HTTP Server Listen</code> message, Grafana will be available. From Grafana version <code>5</code>, you can import data sources and dashboards, which is why we are mounting the <code>./grafana/provisioning/</code> folder from our host machine to <code>/etc/grafana/provisioning/</code>.</p>
			<p>This folder contains the configuration that automatically configures Grafana to talk to our Prometheus service and imports the dashboard, which will display the data that Prometheus is scraping from <code>cadvisor</code>.</p>
			<p>Op<a id="_idTextAnchor908"/>e<a id="_idTextAnchor909"/>n your browser and enter <a href="http://localhost:3000/">http://localhost:3000/</a>; you should be greeted with a login screen:</p>
			<div><div><img src="img/Figure_15.31_B15659.jpg" alt="Figure 15.31: The Grafana login page&#13;&#10;" width="1169" height="730"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.31: The Grafana login page</p>
			<p>Enter the <code>a<a id="_idTextAnchor911"/>dmin</code> with a <code>password</code>. Once logged in, if you have configured the data source, you <a id="_idIndexMarker1113"/>should see the following page:</p>
			<div><div><img src="img/Figure_15.32_B15659.jpg" alt="Figure 15.32: Logging into Grafana&#13;&#10;" width="1097" height="423"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.32: Logging into Grafana</p>
			<p>As you can see, the<a id="_idIndexMarker1114"/> initial steps of <strong class="bold">Add your first data source</strong> and <strong class="bold">Create your first dashboard</strong> have all been completed. Clicking on the <strong class="bold">Home</strong> button in the top left will bring up a menu that lists the available dashboards:</p>
			<div><div><img src="img/Figure_15.33_B15659.jpg" alt="Figure 15.33: Viewing the available dashboards&#13;&#10;" width="698" height="387"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.33: Viewing the available dashboards</p>
			<p>As you can see, we have <a id="_idIndexMarker1115"/>one called <strong class="bold">Docker Monitoring</strong>. Clicking on it will take yo<a id="_idTextAnchor912"/>u t<a id="_idTextAnchor913"/>o the following page:</p>
			<div><div><img src="img/Figure_15.34_B15659.jpg" alt="Figure 15.34: The Docker Monitoring dashboard&#13;&#10;" width="1225" height="701"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.34: The Docker Monitoring dashboard</p>
			<p>As you can see from the timing information in the top right of the screen, by default, it displays the last five minutes' worth of data. Clicking on it will allow you to change the time frame displays. For example, the following screen shows the last 15 minutes, which is obviously more than the <a id="_idIndexMarker1116"/>five minutes that <code>cadvisor</code> is recording:</p>
			<div><div><img src="img/Figure_15.35_B15659.jpg" alt="Figure 15.35: Viewing 15 minutes of data&#13;&#10;" width="1232" height="706"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.35: Viewing 15 minutes of data</p>
			<p>I have already mentioned that this is a complex solution; eventually, Docker will expand the recently built-in Prometheus endpoint, which currently only exposes information about Docker Engine and not the containers themselves. For more information on the built-in endpoint, check out the official Docker documentation, which can be found at <a href="https://docs.docker.com/config/daemon/prometheus/">https://docs.docker.com/config/daemon/prometheus/</a>.</p>
			<p>There are other monitoring solutions out there; most of them take the form of third-party <strong class="bold">software as a service</strong> (<strong class="bold">SaaS</strong>). As you <a id="_idIndexMarker1117"/>can see from the list of services in the <em class="italic">Further reading</em> section, there are a few well-established monitoring solutions out there. In fact, you may already be using them, so it would be easy for you when expanding your configuration to take this into account when monitoring your containers.</p>
			<p><em class="italic">What about Kubernetes?</em> you may be asking yourself. I have already mentioned that Prometheus was originally developed by <em class="italic">SoundCloud</em>, but it was also one of the first projects outside of Kubernetes<a id="_idIndexMarker1118"/> to be donated<a id="_idIndexMarker1119"/> to the <strong class="bold">Cloud Native Computing Foundation</strong> (<strong class="bold">CNCF</strong>).</p>
			<p>This means that there is support for Prometheus within Kubernetes and external services, such as Azure AKS—for example, Azure Monitor has seamless integration with Prometheus.</p>
			<p>For a demonstration of this, see the Azure Friday presentation <em class="italic">How to use Prometheus to monitor containers in Azure Monitor</em> by <em class="italic">Keiko Harada with Scott Hanselman</em>, which can be found at the Microsoft Azure YouTube channel at <a href="https://www.youtube.com/watch?v=5ARJ6DzqTYE">https://www.youtube.com/watch?v=5ARJ6DzqTYE</a>.</p>
			<h1 id="_idParaDest-291"><a id="_idTextAnchor914"/>What does production look like?</h1>
			<p>For the final section of this <a id="_idIndexMarker1120"/>chapter, we are going to discuss what production should look like. This section isn't going to be as long as you think it will be, as the sheer number of options that are available means that it would be impossible to cover them all. You should also already have a good idea of what would work best for you based on the previous sections and chapters.</p>
			<p>Instead, we are going to be looking at some questions that you should be asking yourself when planning your environments.</p>
			<h2 id="_idParaDest-292"><a id="_idTextAnchor915"/>Your Docker hosts</h2>
			<p>Docker hosts are the<a id="_idIndexMarker1121"/> key component of your environment. Without these, you won't have anywhere to run your containers. As we have already seen in previous chapters, there are a few considerations to bear in mind when it comes to running your Docker hosts.</p>
			<p>The first thing you need to take into account is that, if your hosts are running Docker, they should not run any other services.</p>
			<h3>Mixing of processes</h3>
			<p>You should resist the <a id="_idIndexMarker1122"/>temptation of quickly installing Docker on an existing host and launching a container. This might not only have implications for security, with you having a mixture of isolated and nonisolated processes on a single host, but it can also cause performance issues as you are not able to add resource limits to your noncontainerized applications, meaning that, potentially, they can also have a negative impact on your running containers.</p>
			<h3>Multiple isolated Docker hosts</h3>
			<p>If you have more than a <a id="_idIndexMarker1123"/>few Docker hosts, how are you going to manage them? Running a tool, such as Portainer, is great, but it can become troublesome when attempting to manage more than a few hosts. Also, if you are running multiple isolated Docker hosts, you do not have the option of moving containers between hosts.</p>
			<p>Sure, you can use tools such as Weave Net to span the container network across multiple individual Docker hosts. Depending on your hosting environment, you may also have the option of creating volumes on external storage and presenting them to Docker hosts as needed, but you are very much creating a manual process to manage the migration of containers between hosts.</p>
			<h3>Routing to your containers</h3>
			<p>You need to consider how you are<a id="_idIndexMarker1124"/> going to route requests among your containers if you have multiple hosts.</p>
			<p>For example, if you have an external load balancer, such as an ELB in AWS, or a dedicated device in front of an on-premise cluster, do you have the ability to dynamically add routes for traffic hitting port <strong class="bold">x</strong> on your load balancer to port <strong class="bold">y</strong> on your Docker hosts, at which point the traffic is then routed through to your container?</p>
			<p>If you have multiple containers that all need to be accessible on the same external port, how are you going handle that?</p>
			<p>Do you need to install a proxy, such as Traefik, HAProxy, or NGINX to accept and then route your requests based on virtual hosts based on domains or subdomains, rather than just using port-based routing?</p>
			<h2 id="_idParaDest-293"><a id="_idTextAnchor916"/>Clustering</h2>
			<p>A lot of what we have discussed in the previous section can be solved by introducing clustering<a id="_idIndexMarker1125"/> tools, such as Docker Swarm and Kubernetes.Let's quickly discuss some of the things that you should be asking yourself when assessing clustering technologies.</p>
			<h3>Compatibility</h3>
			<p>Even though an <a id="_idIndexMarker1126"/>application might work fine on a developer's local Docker installation, you need to be able to guarantee that if you take the application and deploy it to, for example, a Kubernetes cluster, it works in the same way.</p>
			<p>Nine times out of ten, you will not have a problem, but you do need to consider how the application is communicating internally with other containers within the same application set.</p>
			<h3>Reference architectures</h3>
			<p>Are there reference architectures<a id="_idIndexMarker1127"/> available for your chosen clustering technology? It is always best to check when deploying a cluster. There are best-practice guides that are close to or match your proposed environment. After all, no one wants to create one big single point of failure.</p>
			<p>Also, what are the recommended resources? There is no point in deploying a cluster with five management nodes and a single Docker host, just like there is little point in deploying five Docker hosts and a single management server, as you have quite a large single point of failure.</p>
			<p>What supporting technologies does your cluster technology support (for example, remote storage, load balancers, and firewalls)?</p>
			<h3>Cluster communication</h3>
			<p>What are the requirements when it <a id="_idIndexMarker1128"/>comes to the cluster communicating with either management or Docker hosts? Do you need an internal or separate network to isolate the cluster traffic?</p>
			<p>Can you easily lock a cluster member down to only your cluster? Is the cluster communication encrypted? What information about your cluster could be exposed? Does this make it a target for hackers?</p>
			<p>What external access does the cluster need to APIs, such as your public cloud providers? How securely are any API/access credentials stored?</p>
			<h2 id="_idParaDest-294">Imag<a id="_idTextAnchor917"/>e registries</h2>
			<p>How is your application <a id="_idIndexMarker1129"/>packaged? Have you baked the code into the image? If so, do you need to host a private local image registry or are you okay with using an external service, such as Docker Hub, <strong class="bold">Docker Trusted Registry</strong> (<strong class="bold">DTR</strong>), or Quay?</p>
			<p>If you need to host your own private registry, where in your environment should it sit? Who has or needs access? Can it hook into your directory provider, such as an Active Directory installation?</p>
			<h1 id="_idParaDest-295"><a id="_idTextAnchor918"/>Summary</h1>
			<p>In this chapter, we looked at a few different workflows for Docker, along with how to get some monitoring for your containers and Docker hosts up and running.</p>
			<p>The best thing you can do when it comes to your own environment is build a proof of concept and try as hard as you can to cover every disaster scenario you can think of. You can get a head start by using the container services provided by your cloud provider or by looking for a good reference architecture, which should both reduce your trial and error rates.</p>
			<p>In the next chapter, we are going to take a look at what your next step in the w<a id="_idTextAnchor919"/>orld of containers could be.</p>
			<h1 id="_idParaDest-296"><a id="_idTextAnchor920"/>Questions</h1>
			<ol>
				<li value="1">Which container serves our WordPress website?</li>
				<li>Why doesn't the <code>wp</code> container remain running?</li>
				<li>In minutes, how long does <code>cadvisor</code> keep metrics for?</li>
				<li>What Docker Compose command can be used to remove everything to do with the application?</li>
			</ol>
			<h1 id="_idParaDest-297"><a id="_idTextAnchor921"/>Further reading</h1>
			<p>You can find details on the software we have used in this chapter at the following sites:</p>
			<ul>
				<li>WordPress: <a href="http://wordpress.org/">http://wordpress.org/</a></li>
				<li>WP-CLI: <a href="https://wp-cli.org/">https://wp-cli.org/</a></li>
				<li>PHP-FPM: <a href="https://php-fpm.org/">https://php-fpm.org/</a></li>
				<li>Cadvisor: <a href="https://github.com/google/cadvisor/">https://github.com/google/cadvisor/</a></li>
				<li>Prometheus: <a href="https://prometheus.io/">https://prometheus.io/</a></li>
				<li>Grafana: <a href="https://grafana.com/">https://grafana.com/</a></li>
				<li>Prometheus data model: <a href="https://prometheus.io/docs/concepts/data_model/">https://prometheus.io/docs/concepts/data_model/</a></li>
				<li>Traefik: <a href="https://containo.us/traefik/">https://containo.us/traefik/</a></li>
				<li>HAProxy: <a href="https://www.haproxy.org/">https://www.haproxy.org/</a></li>
				<li>NGINX: <a href="https://nginx.org/">https://nginx.org/</a></li>
			</ul>
			<p>For more information on Docker and Azure DevOps, go to the following links:</p>
			<ul>
				<li>Azure DevOps Docker Build Task: <a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/build/docker?view=azure-devops">https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/build/docker?view=azure-devops</a></li>
				<li>Azure DevOps Docker Compose Build Task: <a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/build/docker-compose?view=azure-devops">https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/build/docker-compose?view=azure-devops</a></li>
				<li>Azure DevOps and Azure Container Registry: <a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/containers/acr-template?view=azure-devops">https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/containers/acr-template?view=azure-devops</a></li>
				<li>Azure DevOps titles at Packt Publishing: <a href="https://www.packtpub.com/catalogsearch/result/?q=Azure%20DevOps">https://www.packtpub.com/catalogsearch/result/?q=Azure%20DevOps</a></li>
			</ul>
			<p>Other externally hosted Docker monitoring platforms include the following:</p>
			<ul>
				<li>Sysdig Cloud: <a href="https://sysdig.com/">https://sysdig.com/</a></li>
				<li>Datadog: <a href="https://docs.datadoghq.com/agent/docker/?tab=standard%20">https://docs.datadoghq.com/agent/docker/?tab=standard </a></li>
				<li>SignalFx: <a href="https://signalfx.com/docker-monitoring/">https://signalfx.com/docker-monitoring/</a></li>
				<li>New Relic: <a href="https://newrelic.com/partner/docker">https://newrelic.com/partner/docker</a></li>
				<li>Sematext: <a href="https://sematext.com/docker/">https://sematext.com/docker/</a> </li>
			</ul>
			<p>There are also other self-hosted options, such as the following:</p>
			<ul>
				<li>Elastic Beats: <a href="https://www.elastic.co/products/beats">https://www.elastic.co/products/beats</a></li>
				<li>Sysdig: <a href="https://sysdig.com/opensource/">https://sysdig.com/opensource/</a> </li>
				<li>Zabbix: <a href="https://github.com/monitoringartist/zabbix-docker-monitoring">https://github.com/monitoringartist/zabbix-docker-monitoring</a> </li>
			</ul>
			<p>The following list shows some extensions for other IDEs:</p>
			<ul>
				<li>Atom Docker Package: <a href="https://atom.io/packages/docker">https://atom.io/packages/docker</a></li>
				<li>Sublime Text Docker Plugin: <a href="https://github.com/domeide/sublime-docker">https://github.com/domeide/sublime-docker</a></li>
				<li>Jetbrains Docker support: <a href="https://www.jetbrains.com/help/idea/docker.html">https://www.jetbrains.com/help/idea/docker.html</a></li>
			</ul>
		</div>
	</div>



  </body></html>