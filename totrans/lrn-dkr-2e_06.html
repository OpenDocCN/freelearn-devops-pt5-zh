<html><head></head><body>
  
    
      <h1>Debugging Containers</h1>
    

    
      <p>Debugging has been an artistic component in the field of software engineering. All kinds of software building blocks individually, as well as collectively, need to go through a stream of deeper and decisive investigations by software development and testing professionals to ensure the security and safety of the resulting software applications. As Docker containers are said to be key runtime environments for next generation mission-critical software workloads, it is pertinent and paramount for containers, crafters, and composers to embark on a systematic and sagacious verification and validation of containers.</p>

      <p>This chapter has been dedicatedly written to enable technical guys who have all the accurateÂ and relevant information to meticulously debug both the applications running inside containers and the containers themselves. In this chapter, we will also look at the theoretical aspects of process isolation for processes running as containers. A Docker container runs at a user-level process on host machines and typically has the same isolation level as provided by the operating system. With the latest Docker releases, many debugging tools are available which can be efficiently used to debug your applications. We will also cover the primary Docker debugging tools, such as <code>docker exec</code>, <code>stats</code>, <code>ps</code>, <code>top</code>, <code>events</code>, and <code>logs</code>. The current version of Docker is written in Go and it takes advantage of several features of the Linux kernel to deliver its functionality.</p>

      <p>The list of topics that will be covered in this chapter is as follows:</p>

      <ul>
        <li>Process-level isolation for Docker containers</li>

        <li>Debugging a <code>Dockerfile</code></li>

        <li>Debugging a containerized application</li>
      </ul>

      <p>All the commands in this chapter are tested on an Ubuntu environment and if you are running them on a local Mac environment, the results would differ.
      </p>

      <p>After installing the Docker Engine on your host machine, the Docker daemon can be started with the <code>-D</code> debug option:</p>

      <pre><strong>$ docker -D login</strong><br/><strong>Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.</strong><br/><strong>Username (vinoddandy): </strong>  
</pre>

      <p>This <code>-D</code> debug flag can be enabled to the Docker configuration file (<code>/etc/default/docker</code>) also in the debug mode:</p>

      <pre><strong>DOCKER_OPTS="-D"</strong>  
</pre>

      <p>After saving and closing the configuration file, restart the Docker daemon.</p>
    
  

  
    
      <h2 id="sigil_toc_id_132">Process-level isolation for Docker containers</h2>
    

    
      <p>In the virtualization paradigm, the hypervisor emulates computing resources and provides a virtualized environment called a VM to install the operating system and applications on top of it. Whereas, in the case of the container paradigm, a single system (bare metal or VM) is effectively partitioned to run multiple services simultaneously without interfering with each other. These services must be isolated from each other in order to prevent them from stepping on each other's resources or dependency conflict (also known as dependency hell). The Docker container technology essentially achieves process-level isolation by leveraging the Linux kernel constructs, such as namespaces and cgroups, particularly, the namespaces. The Linux kernel provides the following five powerful namespace levers for isolating the global system resources from each other. These are the <strong>Interprocess Communication</strong> (<strong>IPC</strong>) namespaces used to isolate the IPC resources:</p>

      <ul>
        <li><strong>network</strong>: This namespace is used to isolate networking resources such as the network devices, network stack, and port number</li>

        <li><strong>mount</strong>: This namespace isolates the filesystem mount points</li>

        <li><strong>PID</strong>: This namespace isolates the process identification number</li>

        <li><strong>user</strong>: This namespace is used to isolate the user ID and group ID</li>

        <li><strong>UTS</strong>: This namespace is used to isolate the hostname and the NIS domain name</li>
      </ul>

      <p>These namespaces add an additional level of complexity when we have to debug the services running inside the containers, which you will learn more about in detail in the next section.</p>

      <p>In this section, we will discuss how the Docker Engine provides process-level isolation by leveraging the Linux namespaces through a series of practical examples, and one of them is listed here:</p>

      <ol>
        <li>Start by launching an Ubuntu container in an interactive mode using the <code>docker run</code> subcommand, as shown here:</li>
      </ol>

      <pre><strong> $ sudo docker run -it --rm ubuntu /bin/bash</strong><br/><strong> root@93f5d72c2f21:/#</strong>
</pre>

      <ol start="2">
        <li>Proceed to find the process ID of the preceding <code>93f5d72c2f21</code> container, using the <code>docker inspect</code> subcommand in a different Terminal:</li>
      </ol>

      <pre><strong> $ sudo docker inspect \</strong><br/><strong> --format "{{ .State.Pid }}" 93f5d72c2f21</strong><br/><strong> 2543</strong>
</pre>

      <p style="padding-left: 60px">Apparently, from the preceding output, the process ID of the container <code>93f5d72c2f21</code> is <code>2543</code>.</p>

      <ol start="3">
        <li>Having got the process ID of the container, let's continue to see how the process associated with the container looks in the Docker host, using the <code>ps</code> command:</li>
      </ol>

      <pre><strong> $ ps -fp 2543</strong><br/><strong> UID PID PPID C STIME TTY TIME </strong><br/><strong> CMD</strong><br/><strong> root 2543 6810 0 13:46 pts/7 00:00:00 </strong><br/><strong> /bin/bash</strong>
</pre>

      <p style="padding-left: 60px">Amazing, isn't it? We launched a container with <code>/bin/bash</code> as its command, and we have the <code>/bin/bash</code> process in the Docker host as well.</p>

      <ol start="4">
        <li>Let's go one step further and display the <code>/proc/2543/environ</code> file in the Docker host using the <code>cat</code> command:</li>
      </ol>

      <pre><strong> $ sudo cat -v /proc/2543/environ</strong><br/><strong> PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin /bin^@HOSTNAME=93f5d72c2f21^@TERM=xterm^@HOME=/root^@$</strong>
</pre>

      <p style="padding-left: 60px">In the preceding output, <code>HOSTNAME=93f5d72c2f21</code> stands out from the other environment variables because <code>93f5d72c2f21</code> is the container ID, as well as the hostname of the container, which we launched previously.</p>

      <ol start="5">
        <li>Now, let's get back to the Terminal, where we are running our interactive container <code>93f5d72c2f21</code>, and list all the processes running inside this container using the <code>ps</code> command:</li>
      </ol>

      <pre><strong> root@93f5d72c2f21:/# ps -ef</strong><br/><strong> UID PID PPID C STIME TTY TIME CMD</strong><br/><strong> root 1 0 0 18:46 ? 00:00:00 /bin/bash</strong><br/><strong> root 15 1 0 19:30 ? 00:00:00 ps -ef</strong>
</pre>

      <p>Surprising, isn't it? Inside the container, the process ID of the <code>/bin/bash</code> process is <code>1</code>, whereas outside the container, in the Docker host, the process ID is <code>2543</code>. Besides, the <strong>Parent Process ID</strong> (<strong>PPID</strong>) is <code>0</code> (zero).</p>

      <p>In the Linux world, every system has just one <code>root</code> process with the PID <code>1</code> and PPID <code>0</code>, which is the root of the complete process tree of that system. The Docker framework cleverly leverages the Linux PID namespace to spin a completely new process tree; thus, the processes running inside a container have no access to the parent process of the Docker host. However, the Docker host has a complete view of the child PID namespace spun by the Docker Engine.</p>

      <p>The network namespace ensures that all containers have independent network interfaces on the host machine. Also, each container has its own Loopback interface. Each container talks to the outside world using its own network interface. You will be surprised to know that the namespace not only has its own routing table, but also has its own iptables, chains, and rules. The author of this chapter is running three containers on his host machine. Here, it is natural to expect three network interfaces for each container. Let's run the <code>docker ps</code> command:</p>

      <pre><strong>$ sudo docker ps</strong><br/><strong>41668be6e513 docker-apache2:latest "/bin/sh -c 'apachec</strong><br/><strong>069e73d4f63c nginx:latest "nginx -g ' </strong><br/><strong>871da6a6cf43 ubuntu "/bin/bash" </strong>  
</pre>

      <p>So, there are three interfaces, one for each container. Let's get their details by running the following command:</p>

      <pre><strong>$ ifconfig</strong><br/><strong>veth2d99bd3 Link encap:EthernetHWaddr 42:b2:cc:a5:d8:f3</strong><br/><strong>inet6addr: fe80::40b2:ccff:fea5:d8f3/64 Scope:Link</strong><br/><strong> UP BROADCAST RUNNING MTU:9001 Metric:1</strong><br/><strong>veth422c684 Link encap:EthernetHWaddr 02:84:ab:68:42:bf</strong><br/><strong>inet6addr: fe80::84:abff:fe68:42bf/64 Scope:Link</strong><br/><strong> UP BROADCAST RUNNING MTU:9001 Metric:1</strong><br/><strong>vethc359aec Link encap:EthernetHWaddr 06:be:35:47:0a:c4</strong><br/><strong>inet6addr: fe80::4be:35ff:fe47:ac4/64 Scope:Link</strong><br/><strong> UP BROADCAST RUNNING MTU:9001 Metric:1</strong>  
</pre>

      <p>The mount namespace ensures that the mounted filesystem is accessible only to the processes within the same namespace. The container A cannot see the mount points of the container B. If you want to check your mount points, you need to first log in to your container using the <code>exec</code> command (described in the next section), and then go to <code>/proc/mounts</code>:</p>

      <pre><strong>root@871da6a6cf43:/# cat /proc/mounts</strong><br/><strong>rootfs / rootfsrw 0 0/dev/mapper/docker-202:1-149807 871da6a6cf4320f625d5c96cc24f657b7b231fe89774e09fc771b3684bf405fb / ext4 rw,relatime,discard,stripe=16,data=ordered 0 0 proc /procproc rw,nosuid,nodev,noexec,relatime 0 0 </strong>  
</pre>

      <p>Let's run a container with a mount point that runs as the <strong>Storage Area Network</strong> (<strong>SAN</strong>) or <strong>Network Attached Storage</strong> (<strong>NAS</strong>) device and access it by logging in to the container. This is given to you as an exercise. I have implemented this in one of my projects at work.</p>

      <p>There are other namespaces that these containers/processes can be isolated into, namely, user, IPC, and UTS. The user namespace allows you to have root privileges within the namespace without giving that particular access to processes outside the namespace. Isolating a process with the IPC namespace gives it its own IPC resources, for example, System V IPC and POSIX messages. The UTS namespace isolates the hostname of the system.</p>

      <p>Docker has implemented this namespace using the <code>clone</code> system call. On the host machine, you can inspect the namespace created by Docker for the container (with PID <code>3728</code>):</p>

      <pre><strong>$ sudo ls /proc/3728/ns/</strong><br/><strong>cgroup ipc mnt netpid user uts</strong>  
</pre>

      <p>In most industrial deployments of Docker, people are extensively using patched Linux kernels to provide specific needs. Also, a few companies have patched their kernels to attach arbitrary processes to the existing namespaces because they feel that this is the most convenient and reliable way to deploy, control, and orchestrate containers.</p>
    
  

  
    
      <h3 id="sigil_toc_id_133">Control groups</h3>
    

    
      <p>Linux containers rely on <strong>Control groups</strong> (<strong>cgroups</strong>), which not only track groups of processes, but also expose metrics of the CPU, memory, and block I/O usage. You can access these metrics and obtain network usage metrics as well. Cgroups are another important component of Linux containers. Cgroups have been around for a while and were initially merged into the Linux kernel code 2.6.24. They ensure that each Docker container will get a fixed amount of memory, CPU, and disk I/O, so that any container will not able to bring the host machine down at any point of time under any circumstances. Cgroups do not play a role in preventing one container from being accessed, but they are essential to fend off some <strong>Denial of Service</strong> (<strong>DoS</strong>) attacks.</p>

      <p>On Ubuntu 16.04, a cgroup is implemented in the <code>/sys/fs/cgroup</code> path. The memory information of Docker is available at the <code>/sys/fs/cgroup/memory/docker/</code> path.</p>

      <p>Similarly, the CPU details are made available in the <code>/sys/fs/cgroup/cpu/docker/</code> path.</p>

      <p>Let's find out the maximum limit of memory that can be consumed by the container (<code>41668be6e513e845150abd2dd95dd574591912a7fda947f6744a0bfdb5cd9a85</code>).</p>

      <p>For this, you can go to the cgroup memory path and check for the <code>memory.max_usage_in_bytes</code> file:</p>

      <pre>/sys/fs/cgroup/memory/docker/41668be6e513e845150abd2dd95dd574591912a7
fda947f6744a0bfdb5cd9a85
</pre>

      <p>Execute the following command to see the contents:</p>

      <pre><strong>$ cat memory.max_usage_in_bytes</strong><br/><strong>13824000</strong>
</pre>

      <p>So, by default, any container can use up to 13.18 MB memory only. Similarly, CPU parameters can be found in the following path:</p>

      <pre>/sys/fs/cgroup/cpu/docker/41668be6e513e845150abd2dd95dd574591912a7fda
947f6744a0bfdb5cd9a85
</pre>

      <p>Traditionally, Docker runs only one process inside the containers. So typically, you have seen people running three containers each for PHP, NGINX, and MySQL. However, this is a myth. You can run all your three processes inside a single container also.</p>

      <p>Docker isolates many aspects of the underlying host from an application running in a container without the root privileges. However, this separation is not as strong as that of virtual machines, which run independent OS instances on top of a hypervisor without sharing the kernel with the underlying OS. It's not a good idea to run applications with different security profiles as containers on the same host, but there are security benefits to encapsulate different applications into containerized applications that would otherwise run directly on the same host.</p>
    
  

  
    
      <h3 id="sigil_toc_id_134">Debugging a containerized application</h3>
    

    
      <p>Computer programs (software) sometimes fail to behave as expected. This is due to faulty code or due to the environmental changes between the development, testing, and deployment systems. Docker container technology eliminates the environmental issues between development, testing, and deployment as much as possible by containerizing all the application dependencies. Nonetheless, there could be still anomalies due to faulty code or variations in the kernel behavior, which needs debugging. Debugging is one of the most complex processes in the software engineering world and it becomes much more complex in the container paradigm because of the isolation techniques. In this section, we are going to learn a few tips and tricks to debug a containerized application using the tools native to Docker, as well as the tools provided by external sources.</p>

      <p>Initially, many people in the Docker community individually developed their own debugging tools, but later Docker started supporting native tools, such as <code>exec</code>, <code>top</code>, <code>logs</code>, and <code>events</code>. In this section, we will dive deep into the following Docker tools:</p>

      <ul>
        <li><code>exec</code></li>

        <li><code>ps</code></li>

        <li><code>top</code></li>

        <li><code>stats</code></li>

        <li><code>events</code></li>

        <li><code>logs</code></li>

        <li><code>attach</code></li>
      </ul>

      <p>We shall also consider debugging a <code>Dockerfile</code>.</p>
    
  

  
    
      <h2 id="sigil_toc_id_135">The docker exec command</h2>
    

    
      <p>The <code>docker exec</code> command provides the much-needed help to users, who are deploying their own web servers or have other applications running in the background. Now, it is not necessary to log in to run the SSH daemon in the container.</p>

      <ol>
        <li>First, create a Docker container:</li>
      </ol>

      <pre><strong> $ sudo docker run --name trainingapp \ </strong><br/><strong> training/webapp:latest </strong><br/><strong> Unable to find image </strong><br/><strong> 'training/webapp:latest' locally</strong><br/><strong> latest: Pulling from training/webapp</strong><br/><strong> 9dd97ef58ce9: Pull complete </strong><br/><strong> a4c1b0cb7af7: Pull complete </strong><br/><strong> Digest: sha256:06e9c1983bd6d5db5fba376ccd63bfa529e8d02f23d5079b8f74a616308fb11d</strong><br/><strong> Status: Downloaded newer image for </strong><br/><strong> training/webapp:latest</strong>
</pre>

      <ol start="2">
        <li>Next, run the <code>docker ps -a</code> command to get the container ID:</li>
      </ol>

      <pre>      <strong>$ sudo docker ps -a</strong><br/><strong> a245253db38b training/webapp:latest </strong><br/><strong> "python app.py"</strong>
</pre>

      <ol start="3">
        <li>Then, run the <code>docker exec</code> command to log in to the container:</li>
      </ol>

      <pre><strong> $ sudo docker exec -it a245253db38b bash</strong><br/><strong> root@a245253db38b:/opt/webapp#</strong>
</pre>

      <ol start="4">
        <li>Note that the <code>docker exec</code> command can only access the running containers, so if the container stops functioning, then you need to restart the stopped container in order to proceed. The <code>docker exec</code> command spawns a new process in the target container using the Docker API and CLI. So if you run the <code>ps -aef</code> command inside the target container, it looks like this:</li>
      </ol>

      <pre><strong> # ps -aef</strong><br/><strong> UID PID PPID C STIME TTY TIME </strong><br/><strong> CMD</strong><br/><strong> root 1 0 0 Nov 26 ? 00:00:53 </strong><br/><strong> python app.py</strong><br/><strong> root 45 0 0 18:11 ? 00:00:00 </strong><br/><strong> bash</strong><br/><strong> root 53 45 0 18:11 ? 00:00:00 </strong><br/><strong> ps -aef</strong>
</pre>

      <p>Here, <code>python app.y</code> is the application that is already running in the target container, and the <code>docker exec</code> command has added the <code>bash</code> process inside the container. If you run <code>kill -9 pid(45)</code>, you will be automatically logged out of the container.</p>

      <p>If you are an enthusiastic developer, and you want to enhance the <code>exec</code> functionality, you can refer to <a href="https://github.com/chris-rock/docker-exec">https://github.com/chris-rock/docker-exec</a>.</p>

      <p>Using the <code>docker exec</code> command only for monitoring and diagnostic purposes is recommended, and I personally believe in the concept of one process per container, which is one of the best practices widely accentuated.</p>
    
  

  
    
      <h2 id="sigil_toc_id_136">The docker ps command</h2>
    

    
      <p>The <code>docker ps</code> command, which is available inside the container, is used to see the status of the process. This is similar to the standard <code>ps</code> command in the Linux environment and is <em>not</em> a <code>docker ps</code> command that we run on the Docker host machine.</p>

      <p>This command runs inside the Docker container:</p>

      <pre><strong>root@5562f2f29417:/# ps -s</strong><br/><strong>UID PID PENDING BLOCKED IGNORED CAUGHT STAT TTY TIME COMMAND</strong><br/><strong>0 1 00000000 00010000 00380004 4b817efb Ss <br/>? 0:00 /bin/bash</strong><br/><strong>0 33 00000000 00000000 00000000 73d3fef9 R+ ? 0:00 ps -s</strong><br/><strong>root@5562f2f29417:/# ps -l</strong><br/><strong>F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD</strong><br/><strong>4 S 0 1 0 0 80 0 - 4541 wait ? 00:00:00 bash</strong><br/><strong>root@5562f2f29417:/# ps -t</strong><br/><strong>PID TTY STAT TIME COMMAND</strong><br/><strong> 1 ? Ss 0:00 /bin/bash</strong><br/><strong> 35 ? R+ 0:00 ps -t</strong><br/><strong>root@5562f2f29417:/# ps -m</strong><br/><strong>PID TTY TIME CMD</strong><br/><strong> 1 ? 00:00:00 bash</strong><br/><strong> - - 00:00:00 -</strong><br/><strong> 36 ? 00:00:00 ps</strong><br/><strong> - - 00:00:00 -</strong><br/><strong>root@5562f2f29417:/# ps -a</strong><br/><strong>PID TTY TIME CMD</strong><br/><strong> 37 ? 00:00:00 ps</strong> 
</pre>

      <p>Use <code>ps --help &lt;simple|list|output|threads|misc|all&gt;</code> or <code>ps --help &lt;s|l|o|t|m|a&gt;</code> for additional help text.</p>
    
  

  
    
      <h2 id="sigil_toc_id_137">The docker top command</h2>
    

    
      <p>You can run the <code>top</code> command from the Docker host machine using the following command:</p>

      <pre><strong>docker top [OPTIONS] CONTAINER [ps OPTIONS]</strong>  
</pre>

      <p>This gives a list of the running processes of a container without logging in to the container, as follows:</p>

      <pre><strong>$ sudo docker top a245253db38b</strong><br/><strong>UID PID PPID C</strong><br/><strong>STIME TTY TIME CMD</strong><br/><strong>root 5232 3585 0</strong><br/><strong>Mar22 ? 00:00:53 python app.py </strong><br/><strong>$ sudo docker top a245253db38b -aef</strong><br/><strong>UID PID PPID C</strong><br/><strong>STIME TTY TIME CMD</strong><br/><strong>root 5232 3585 0</strong><br/><strong>Mar22 ? 00:00:53 python app.py</strong>  
</pre>

      <p>The Docker <code>top</code> command provides information about the CPU, memory, and swap usage if you run it inside a Docker container:</p>

      <pre><strong>root@a245253db38b:/opt/webapp# top</strong><br/><strong>top - 19:35:03 up 25 days, 15:50, 0 users, load average: 0.00, 0.01, 0.05</strong><br/><strong>Tasks: 3 total, 1 running, 2 sleeping, 0 stopped, 0 zombie</strong><br/><strong>%Cpu(s): 0.0%us, 0.0%sy, 0.0%ni, 99.9%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st</strong><br/><strong>Mem: 1016292k total, 789812k used, 226480k free, 83280k buffers</strong><br/><strong>Swap: 0k total, 0k used, 0k free, 521972k cached</strong><br/><strong>PID USER PR NI VIRT RES SHR S %CPU %MEM <br/>TIME+ COMMAND</strong><br/><strong> 1 root 20 0 44780 10m 1280 S 0.0 1.1 0:53.69 python</strong><br/><strong> 62 root 20 0 18040 1944 1492 S 0.0 0.2 0:00.01 bash</strong><br/><strong> 77 root 20 0 17208 1164 948 R 0.0 0.1 0:00.00 top</strong>  
</pre>

      <p>In case you get theÂ <code>error - TERM environment variable not set</code>Â error while running the <code>top</code> command inside the container, perform the following steps to resolve it:</p>

      <p>Run the <code>echo $TERM</code> command. You will get the result as <code>dumb</code>. Then, run the following command:</p>

      <pre><strong>$ export TERM=dumb </strong>
</pre>

      <p>This will resolve the error.</p>
    
  

  
    
      <h2 id="sigil_toc_id_138">The docker stats command</h2>
    

    
      <p>The <code>docker stats</code> command provides you with the capability to view the memory, CPU, and the network usage of a container from a Docker host machine, as illustrated here:</p>

      <pre><strong>$ sudo docker stats a245253db38b</strong><br/><strong>CONTAINER CPU % MEM USAGE/LIMIT MEM % </strong><strong>NET I/O</strong><br/><strong>a245253db38b 0.02% 16.37 MiB/992.5 MiB 1.65%</strong><br/><strong>3.818 KiB/2.43 KiB</strong>  
</pre>

      <p>You can run the <code>stats</code> command to also view the usage for multiple containers:</p>

      <pre><strong>$ sudo docker stats a245253db38b f71b26cee2f1 </strong>  
</pre>

      <p>Docker provides access to container statistics <em>read only</em> parameters. This streamlines the CPU, memory, network IO, and block IO of containers. This helps you choose the resource limits and also in profiling. The Docker <code>stats</code> utility provides you with these resource usage details only for running containers.</p>
    
  

  
    
      <h2 id="sigil_toc_id_139">The Docker events command</h2>
    

    
      <p>Docker containers will report the following real-time events: <code>create</code>, <code>destroy</code>, <code>die</code>, <code>export</code>, <code>kill</code>, <code>omm</code>, <code>pause</code>, <code>restart</code>, <code>start</code>, <code>stop</code>, and <code>unpause</code>. The following are a few examples that illustrate how to use these commands:</p>

      <pre><strong>$ sudo docker pause a245253db38b</strong><br/><strong>a245253db38b<br/></strong><br/><strong>$ sudo docker ps -a</strong><br/><strong>a245253db38b training/webapp:latest "python app.py" <br/>4 days ago Up 4 days (Paused) 0.0.0.0:5000-&gt;5000/tcp sad_sammet<br/></strong><br/><strong>$ sudo docker unpause a245253db38b</strong><br/><strong>a245253db38b<br/></strong><br/><strong>$ sudo docker ps -a</strong><br/><strong>a245253db38b training/webapp:latest "python app.py" <br/>4 days ago Up 4 days 0.0.0.0:5000-&gt;5000/tcpsad_sammet</strong>  
</pre>

      <p>The Docker image will also report the untag and delete events.</p>

      <p>The usage of multiple filters will be handled as an AND operation; for example,</p>

      <p><code>--filter container= a245253db38b --filter event=start</code> will display events for the container <code>a245253db38b</code> and the event type is <code>start</code>.</p>

      <p>Currently, the supported filters are container, event, and image.</p>
    
  

  
    
      <h2 id="sigil_toc_id_140">The docker logs command</h2>
    

    
      <p>This command fetches the log of a container without logging in to the container. It batch-retrieves logs present at the time of execution. These logs are the output of stdout and stderr. The general usage is shown in <code>docker logs [OPTIONS] CONTAINER</code>.</p>

      <p>The <code>-follow</code> option will continue to provide the output till the end,Â <code>-t</code>Â will provide the timestamp, and <code>--tail= &lt;number of lines&gt;</code>Â will show the number of lines of the log messages of your container:</p>

      <pre><strong>$ sudo docker logs a245253db38b</strong><br/><strong>* Running on http://0.0.0.0:5000/</strong><br/><strong>172.17.42.1 - - [22/Mar/2015 06:04:23] "GET / HTTP/1.1" 200 -</strong><br/><strong>172.17.42.1 - - [24/Mar/2015 13:43:32] "GET / HTTP/1.1" 200 -</strong><br/><strong><br/></strong><strong>$ sudo docker logs -t a245253db38b</strong><br/><strong>2015-03-22T05:03:16.866547111Z * Running on http://0.0.0.0:5000/</strong><br/><strong>2015-03-22T06:04:23.349691099Z 172.17.42.1 - - [22/Mar/2015 06:04:23] "GET / HTTP/1.1" 200 -</strong><br/><strong>2015-03-24T13:43:32.754295010Z 172.17.42.1 - - [24/Mar/2015 13:43:32] "GET / HTTP/1.1" 200 -</strong>  
</pre>

      <p>We also used the <code>docker logs</code> utility in <a href="../Text/Ch02.xhtml">Chapter 2</a>, <em>Handling Docker Containers</em> and <a href="../Text/Ch06.xhtml">Chapter 6</a>, <em>Running Services in a Container</em>, to view the logs of our containers.</p>
    
  

  
    
      <h2 id="sigil_toc_id_141">The docker attach command</h2>
    

    
      <p>The <code>docker attach</code> command attaches the running container and it is very helpful when you want to see what is written in stdout in real time:</p>

      <pre><strong>$ sudo docker run -d --name=newtest alpine /bin/sh -c "while true; do sleep 2; df -h; done"</strong><br/><strong>Unable to find image 'alpine:latest' locally</strong><br/><strong>latest: Pulling from library/alpine</strong><br/><strong>3690ec4760f9: Pull complete </strong><br/><strong>Digest: sha256:1354db23ff5478120c980eca1611a51c9f2b88b61f24283ee8200bf9a54f2e5c</strong><br/><strong>1825927d488bef7328a26556cfd72a54adeb3dd7deafb35e317de31e60c25d67</strong><br/><strong>$ sudo docker attach newtest</strong><br/><strong>Filesystem Size Used Available Use% Mounted on</strong><br/><strong>none 7.7G 3.2G 4.1G 44% /</strong><br/><strong>tmpfs 496.2M 0 496.2M 0% /dev</strong><br/><strong>tmpfs 496.2M 0 496.2M 0% /sys/fs/cgroup</strong><br/><strong>/dev/xvda1 7.7G 3.2G 4.1G 44% /etc/resolv.conf</strong><br/><strong>/dev/xvda1 7.7G 3.2G 4.1G 44% /etc/hostname</strong><br/><strong>/dev/xvda1 7.7G 3.2G 4.1G 44% /etc/hosts</strong><br/><strong>shm 64.0M 0 64.0M 0% /dev/shm</strong><br/><strong>tmpfs 496.2M 0 496.2M 0% /proc/sched_debug</strong><br/><strong>Filesystem Size Used Available Use% Mounted on</strong><br/><strong>none 7.7G 3.2G 4.1G 44% /</strong><br/><strong>tmpfs 496.2M 0 496.2M 0% /dev</strong>
</pre>

      <p>By default, this command attaches stdin and proxies signals to the remote process. Options are available to control both of these behaviors. To detach from the process,Â use the default <em>Ctrl</em> + <em>C</em> sequence.</p>
    
  

  
    
      <h2 id="sigil_toc_id_142">Debugging a Dockerfile</h2>
    

    
      <p>Sometimes creating a <code>Dockerfile</code> may not start with everything working. A <code>Dockerfile</code>Â does not always build images and sometimes it does, but starting a container would crash on startup.</p>

      <p>Every instruction we set in the <code>Dockerfile</code> is going to be built as a separate, temporary image for the other instruction to build itself on top of the previous instruction. The followingÂ example explains this:</p>

      <ol>
        <li>Create a <code>Dockerfile</code> using your favorite editor:</li>
      </ol>

      <pre>      FROM busybox <br/>      RUN ls -lh <br/>      CMD echo Hello world 
</pre>

      <ol start="2">
        <li>Now, build the image by executing the following command:</li>
      </ol>

      <pre><strong> $ docker build .</strong><br/><strong> Sending build context to Docker daemon 2.048 kB</strong><br/><strong> Step 1 : FROM busybox</strong><br/><strong> latest: Pulling from library/busybox</strong><br/><strong> 56bec22e3559: Pull complete </strong><br/><strong> Digest: sha256:29f5d56d12684887bdfa50dcd29fc31eea4aaf4ad3bec43daf19026a7ce69912</strong><br/><strong> Status: Downloaded newer image for busybox:latest</strong><br/><strong> ---&gt; e02e811dd08f</strong><br/><strong> Step 2 : RUN ls -lh</strong><br/><strong> ---&gt; Running in 7b47d3c46cfa</strong><br/><strong> total 36</strong><br/><strong> drwxr-xr-x 2 root root 12.0K Oct 7 18:18 bin</strong><br/><strong> dr-xr-xr-x 130 root root 0 Nov 27 01:36 proc</strong><br/><strong> drwxr-xr-x 2 root root 4.0K Oct 7 18:18 root</strong><br/><strong> dr-xr-xr-x 13 root root 0 Nov 27 01:36 sys</strong><br/><strong> drwxrwxrwt 2 root root 4.0K Oct 7 18:18 tmp</strong><br/><strong> ---&gt; ca5bea5887d6</strong><br/><strong> Removing intermediate container 7b47d3c46cfa</strong><br/><strong> Step 3 : CMD echo Hello world</strong><br/><strong> ---&gt; Running in 490ecc3d10a9</strong><br/><strong> ---&gt; 490d1c3eb782</strong><br/><strong> Removing intermediate container 490ecc3d10a9</strong><br/><strong> Successfully built 490d1c3eb782</strong><br/><strong><br/><strong> $ </strong> </strong>  
</pre>

      <p>Notice the <code>---&gt; Running in 7b47d3c46cfa</code> line. <code>7b47d3c46cfa</code> is a valid image and can be used to retry the failed instruction and see what's happening</p>

      <p>To debug this image, we need to create a container and then log in to analyze the error. Debugging is a process of analyzing what's going on and it's different for every situation, but usually, the way we start debugging is by trying to manually make the instruction that fails work manually and understand the error. When I get the instruction to work, I usually exit the container, update my <code>Dockerfile</code>, and repeat the process until I have something working.</p>
    
  

  
    
      <h2 id="sigil_toc_id_143">Summary</h2>
    

    
      <p>In this chapter, you have seen the isolation of containers using the Linux container technology, such as LXC and now Libcontainer. Libcontainer is Docker's own implementation in the Go programming language to access the kernel namespace and cgroups. This namespace is used for process-level isolation, while cgroups are used for restricting the resource usage of running containers. Since the containers run as independent processes directly over the Linux kernel, the <strong>Generally Available</strong> (<strong>GA</strong>) debugging tools are not fit enough to work inside the containers to debug the containerized processes. Docker now provides you with a rich set of tools to effectively debug the container as well as processes inside the container itself. The <code>docker exec</code>Â command will allow you to log in to the container without running an SSH daemon in the container. You have seen the details of each debugging tool in this chapter.</p>

      <p>The <code>docker stats</code>Â command provides information about the container's memory and CPU usage. The <code>docker events</code> command reports the events, such as create, destroy, and kill. Similarly, the <code>docker logs</code> command fetches the logs from the container without logging in to the container.</p>

      <p>As a next step, you can try the latest Microsoft Visual Studio Tools for Docker. It provides a consistent way to develop and validate your application in the Linux Docker container. For details, you can refer toÂ <a href="https://docs.microsoft.com/en-us/azure/vs-azure-tools-docker-edit-and-refresh" target="_blank">https://docs.microsoft.com/en-us/azure/vs-azure-tools-docker-edit-and-refresh</a>.</p>

      <p>Also, if you would like to debug the Node.js application live running in IDE (Visual Studio Code), try this blog:Â <a href="https://blog.docker.com/2016/07/live-debugging-docker/" target="_blank">https://blog.docker.com/2016/07/live-debugging-docker/</a>.</p>

      <p>The next chapter expounds the plausible security threats of Docker containers and how they can be subdued with a variety of security approaches, automated tools, best practices, key guidelines, and metrics. We will discuss the security of containers versus virtual machines with Docker's adaptability of third-party security tools and practices.</p>
    
  
</body></html>