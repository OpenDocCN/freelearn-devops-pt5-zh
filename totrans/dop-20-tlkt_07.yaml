- en: Chapter 7. Implementation of the Deployment Pipeline – Intermediate Stages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We could not complete the basic implementation of the deployment pipeline without
    the production server being set up. We didn''t need much. At the moment, Docker
    is our only prerequisite for the deployment and that gave us a good excuse to
    make a side trip into the world of configuration management. Now, with the Ansible
    playbook that will set up our prod server, we can continue where we left and deploy
    the container to the production server:'
  prefs: []
  type: TYPE_NORMAL
- en: Checkout the code - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run pre-deployment tests - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compile and/or package the code - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the container - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the container to the registry - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the container to the production server - Pending
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Integrate the container - Pending
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run post-deployment tests - Pending
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the tests container to the registry - Pending![Implementation of the Deployment
    Pipeline – Intermediate Stages](img/B05848_07_01.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 7-1 – The initial stages of the deployment pipeline with Docker
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We are missing only four steps from the manual deployment pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Containers to the Production Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s create and configure VMs we''ll use throughout this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first command brought up the `cd` and `prod` VMs while the second got us
    inside the `cd` VM. Finally, the last command configured the `prod` VM.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that the production server is properly configured, we can deploy the `books-ms`
    container. Even though we don''t have is pulled to the destination server, we
    already pushed it to the Docker registry in the `cd` node (that maps into the
    host directory) and can retrieve it from there. What we do not have, however,
    is the Docker Compose configuration that specifies how the container should be
    run. I prefer keeping everything related to a service in the same repository and
    `**docker-compose.yml*` is no exception. We can retrieve it GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'With the `docker-compo` `se.yml` downloaded, let us take a quick look at it
    (targets that won''t be used in this chapter have been excluded):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `base` target contains the base definition of our container. The next target
    (`app`) is extending the `base` service allowing us to avoid duplicating the definitions.
    By extending services, we can override arguments or add new ones. The `app` target
    will run the container we stored in the registry on the `cd` server and is linked
    to the third target that represent the database required by the service. You might
    notice that we changed the way ports are specified. In the `docker-compose-d`
    `ev.yml` we had two numbers separated by a colon (`8080:8080`). The first one
    was the port Docker would expose to the host while the second one is the internal
    port used by the server inside the container. The `docker-compose.yml` is a bit
    different and has only the internal port set. The reason behind that is the elimination
    of potential conflicts. While in the development environment we tend to run only
    a small number of services (those we need at the moment), in production we might
    run tens, hundreds, or even thousands of them at the same time. Having predefined
    ports can easily result in conflicts. If two of them are using the same port,
    the result will be a failure. For that reason, we'll let Docker expose a random
    port to the host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us run the Docker Compose `app` target:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We exported the `DOCKER_HOST` variable that tells local Docker client to send
    commands to the remote one located on the `prod` node and port `2375`. The second
    command run the Docker Compose target `app`. Since `DOCKER_HOST` is pointing to
    the remote host, the `app` target and linked container `db` were deployed to the
    `prod` server. We did not even have to enter the destination server. The deployment
    was done remotely.
  prefs: []
  type: TYPE_NORMAL
- en: 'For security reasons, the ability to invoke remote Docker API is disabled by
    default. However, one of the Ansible playbook tasks was to change that behaviour
    by modifying the `/etc/default/docker` configuration file. Its content is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `--insecure-registry` allows Docker to pull images from our private registry
    located in the `cd` node (`10.100.198.200`). The `-H` argument tells Docker to
    listen to remote requests from any address (`0.0.0.0`) on the port `2375`. Please
    note that in the real production environment, we would need to be much more restrictive
    and allow only trusted addresses to access the remote Docker API.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can confirm that both containers are indeed running on the `prod` VM by
    executing another remote call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Since Docker assigned a random port to the service's internal port `8080`, we
    need to find it out. That can be done with the `inspect` command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The part of the output that interests us should be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The original output is much bigger than this and it contains all the info we
    might (or might not) need. What we are interested in right now is the `NetworkSettings.Ports`
    section that, in my case, gives us `HostPort 32770` mapped to the internal port
    `8080`. We can do better than that and use the `--format` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Do not get scared by the `--format` value syntax. It uses Go's `text/template`
    format and indeed can be a bit daunting. The good news is that we'll use much
    better ways to do this once we get to [Chapter 8](ch08.html "Chapter 8. Service
    Discovery – The Key to Distributed Services"), *Service Discovery – The Key to
    Distributed Services* chapter. This is only the temporary workaround.
  prefs: []
  type: TYPE_NORMAL
- en: 'We got our port and stored it to the `PORT` variable. Now we can repeat `curl`
    commands we already got familiar with and confirm that the service is running
    and is connected to the DB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the last command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As before, when we run the same command in the development environment, we inserted
    three books to the database and confirmed that they can be retrieved from the
    database. However, this is not an efficient way of verifying whether the service
    was deployed correctly. We can do better than that and run the integration tests.
  prefs: []
  type: TYPE_NORMAL
- en: The important thing to note is that we have not even entered into the `prod`
    node. All the deployment commands were done through the remote Docker API.
  prefs: []
  type: TYPE_NORMAL
- en: Docker UI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This might be a good opportunity to introduce a nice open source project DockerUI.
    It is defined as part of the *docker* Ansible role so it is running on all servers
    where we configure Docker. We can, for example, see the instance running on the
    `prod` node by opening `http://10.100` `.198.201:9000` from any browser.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please note that all IPs created through Vagrant are set to be private, meaning
    that they can be accessed only from the host machine. If that happens to be your
    laptop, you should not have a problem to open the DockerUI address in your browser.
    On the other hand, if you are running the examples on one of your corporate servers,
    please make sure that you can access it''s desktop and that a browser is installed.
    If you need to access that server remotely, please try one of remote desktop solutions
    like VNC:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker UI](img/B05848_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-2 – DockerUI dashboard screen
  prefs: []
  type: TYPE_NORMAL
- en: While it is much more efficient to operate containers through CLI, the DockerUI
    provides a very useful way to gain a general overview of the system and details
    related to each container, network, and images. It true usefulness can be seen
    when a big number of containers is running in a cluster. It is very lightweight
    so it won't use much of your resources.
  prefs: []
  type: TYPE_NORMAL
- en: Unless specified otherwise, you'll find it running on each VM we set up.
  prefs: []
  type: TYPE_NORMAL
- en: The Checklist
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we move on, let''s see where we are with our basic implementation of
    the deployment pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: Checkout the code - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run pre-deployment tests - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compile and/or package the code - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the container - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the container to the registry - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the container to the production server - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Integrate the container - Pending
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run post-deployment tests - Pending
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the tests container to the registry - Pending![The Checklist](img/B05848_07_03.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 7-3 – The intermediate stages of the deployment pipeline with Docker
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Please note that, unlike the steps we did in the previous chapter, the deployment
    was performed in the production environment through remote Docker API. If we deployed
    the second release, we would have a period which neither the old nor the new release
    were operational. One would need to be stopped while the other would require some
    time to be brought up. No matter whether this period was short or not, we would
    have *down-time* that, in itself, would prevent us from moving towards *continues
    deployment*. All we'll do for now is take a note of this problem. Later on, we'll
    explore the *blue-green deployment* procedure that will help us overcome this
    issue and proceed towards the quest for zero-downtime deployments.
  prefs: []
  type: TYPE_NORMAL
- en: We're making progress and only three tasks are left on the checklist. However,
    the application is not yet integrated and, therefore, we cannot run integration
    tests. In order to proceed, there are two more concepts we need to explore; *service
    discovery* and *reverse proxy*.
  prefs: []
  type: TYPE_NORMAL
- en: We'll use a new set of virtual machines while experimenting with service discovery
    tools, so let us save some resources and destroy the VMs we're running. We'll
    create those that we need in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
