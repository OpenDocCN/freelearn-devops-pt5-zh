<html><head></head><body>
        

                            
                    <h1 class="header-title">Working with Ansible Container</h1>
                
            
            
                
<p>As we saw in <a href="61a61ca8-60d4-48a0-8987-6f719d6a2c36.xhtml">Chapter 1</a>, <em>Building Containers with Docker</em>, containerization is changing the way critical IT infrastructure is maintained and deployed. As DevOps methodologies and mindsets evolve across organizations, the lines between development and operations roles are becoming blurred. While tools such as Docker continue to grow and evolve, tools need to be developed to leverage the ever-increasing need to scale and deploy containerized applications.</p>
<p>Ansible is a unique framework for automation, as we saw in <a href="61a61ca8-60d4-48a0-8987-6f719d6a2c36.xhtml" target="_blank">Chapter 1</a><em>, Building Containers with Docker, </em>as it relies on an agent-less architecture, bringing servers and virtualized applications into the desired state from a centralized location over the SSH protocol. Compared to the other core automation tools discussed, Ansible brings a different approach from other configuration management tools, such as Chef and Puppet, which rely on agents and centralized servers to store and maintain configuration states.</p>
<p>The Ansible Container project was launched to address the need to bring critical configuration management techniques to the currently manual process of building and deploying Docker container images with the standard Docker toolchain. Currently, Docker and Docker tools are built with an emphasis on deploying containers to Docker native environments using Swarm and Docker Compose. Ansible Container is a wrapper around many of the standard Docker tools, and provides the functionality to deploy your projects to various cloud providers, Kubernetes, and OpenShift. At the time of writing other container orchestration tools such as Docker Swarm and Apache Mesos are not currently supported. If Dockerfiles are akin to shell scripts during the era of monolithic application deployments, then Ansible Container is a solution for bringing automation and repeatability to the container ecosystem. As Ansible Core uses playbooks and SSH as an interface for bringing about desired states, Ansible Container can use your same playbooks and native container APIs to build and deploy containers.</p>
<p>If you or your organization is already using Ansible roles for customized deployments of applications and services, these same roles can be leveraged to turn these applications and services into containers, helping to streamline your container build pipeline. When making the leap from bare-metal and virtualized deployments, you can be confident that your customized configurations and settings will be preserved when building your containers.</p>
<p>In this chapter we will learn:</p>
<ul>
<li>An introduction to Ansible Container and the microservice architecture</li>
<li>A quick introduction to Docker Compose</li>
<li>Ansible Container workflow</li>
<li>Ansible Container quick start</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">An introduction to Ansible Container and the microservice architecture</h1>
                
            
            
                
<p>While using Ansible Container has a great number of benefits in reusing existing Ansible artifacts, modules, and playbooks, careful consideration has to be given to any changes required in porting over your existing services. Ansible gives you a large amount of freedom in the way you write playbooks and roles to suite the uniqueness of your organization's architecture and resource constraints. A typical web application, for example, may have three distinct layers of functionality: a web server, which provides your end users with a website; a database for storing data; and a cache, providing the web server with commonly accessed data from the database. Depending on the architecture and any resource constraints, these services might be implemented in any number of ways. You may have your web server, caching layer, and database on three separate and distinct clusters of servers. You could opt to deploy the web server and caching layer on the same cluster, and the database on a secondary cluster. Or all three layers might be deployed on the same bare-metal or virtualized server cluster, with a load balancer providing redundancy as necessary. Your infrastructure is a unique snowflake that Ansible gives you the freedom to write and deploy playbook roles in almost any configuration that fits your needs.</p>
<p><em>Microservice architecture</em> is a term used to describe the independent and modular breakout of application services to distinct and deployable units. In the world of containers, you want each of your containers to conform to the microservice architecture, creating each service as a separate container that can be deployed and scaled independently of the other services. While it is possible to deploy multiple services in the same container, it is generally a bad idea, as each service adds layers to your containers, creating unnecessary overhead when building and deploying new containers.</p>
<p>In the preceding example, each of the core services (web server, cache, and database) will be a separate microservice you want to isolate and encapsulate into containers. Having the flexibility to dynamically deploy more cache or database containers on demand creates a huge advantage if your web application goes into production and you realize that the projected traffic is much higher than originally anticipated and database queries are becoming a bottleneck. Having a microservice-oriented design to your containers will allow your infrastructure to be simplified, more easily deployed, and more quickly scaled to meet the needs of demanding users.</p>
<p>The key takes-away when thinking about porting existing Ansible roles into Ansible Container projects is to think through how tightly integrated your roles currently are. Ideally, Ansible roles should be able to be standalone, with little to no reliance on other environmental characteristics. Isn't this starting to sound a lot like the containerized microservices we described before? This is what makes Ansible Container a unique platform among other configuration management tools. Ansible primitives are already designed to fit nicely into a containerized ecosystem. Even if you are not currently using Ansible as your configuration management tool, Ansible Container is still a fantastic tool for building, maintaining, and deploying containers, from development all the way through to production.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">A quick introduction to Docker Compose</h1>
                
            
            
                
<p>Docker Compose is one of the Docker workflow tools that allow you to easily build and run multiple containers at once. It is important to have a basic understanding of how Docker Compose works before we start working with Ansible Container since a lot of Ansible Container's core functionality is wrapped around Docker Compose.</p>
<p>In the previous chapter, I illustrated an example in which three Apache web server containers were created to demonstrate running multiple containers simultaneously leveraging the same container base image. With Docker Compose, instead of providing three separate docker <kbd>run</kbd> commands, one can simply provide a <kbd>YAML</kbd> definition file that describes the containers you want to run, any docker <kbd>run</kbd> parameters you want the containers to run with (ports, volumes, and so on), and any links or dependencies you want to create for the containers prior to running them. When Docker Compose is executed, it will automatically try to bring up the containers described in the <kbd>YAML</kbd> file. If the images are not yet cached locally, it will try to download them from the internet or will build the container images if the Dockerfiles are provided. Let's do a quick exercise to get a feel for how Docker Compose works.</p>
<p>If you are not using the provided Vagrant lab environment, as discussed in <a href="61a61ca8-60d4-48a0-8987-6f719d6a2c36.xhtml" target="_blank">Chapter 1</a><em>,</em> <em>Building Containers with Docker,</em> you will first need to download Docker Compose using the following command. The steps provided assume you have Docker Engine already installed and running on a Linux or macOS machine. Make sure you install Docker Compose with the same version number as the Docker Engine you already have running to ensure maximum compatibility. Execute the following commands to download the Docker Compose executable and copy it to <kbd>/usr/local/bin</kbd> with <kbd>execute</kbd> privileges.</p>
<pre class="western"><strong>sudo curl -L https://github.com/docker/compose/releases/download/1.17.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose

sudo chmod +x /usr/local/bin/docker-compose</strong></pre>
<p>The most up-to-date installation documentation can be found at <a href="https://docs.docker.com/compose/install">https://docs.docker.com/compose/install</a>.</p>
<p>By default, Docker Compose looks for a file in your current working directory called <kbd>docker-compose.yml</kbd>. I have provided a sample <kbd>docker-compose.yml</kbd> file as an example. On your workstation, create a directory called <kbd>docker-compose</kbd> and create a blank <kbd>docker-compose.yml</kbd> file in that directory. Paste in the following content:</p>
<pre class="western">version: '2'
services:
  Cache_Server:
    image: memcached:1.4.36
    ports:
      - 11211:11211
    volumes:
      - .:/var/lib/MyVolume</pre>
<p>Let's look at this file line by line:</p>
<ul>
<li class="mce-root"><kbd>version</kbd>: This line indicates which version of the Docker Compose API to use. In this case, we are using version 2. At the time of writing, there is also version 3 of the API, which provides some new features. For our purposes, however, we are content to use version 2. The version parameter usually starts a Docker Compose file and has no indentation.</li>
<li class="mce-root"><kbd>services</kbd>: The <kbd>services</kbd> line starts the section of your <kbd>docker-compose.yml</kbd> file that lists each service container you are going to create. In this particular Docker Compose file, we are going to create a service called <kbd>Cache_Server</kbd>, which spins up a single <kbd>memcached</kbd> container. Each service you specify should be indented two spaces under the <kbd>services</kbd> declarative. It should also be noted that the service names are user-defined and are used to generate the container name. When creating multi-container Docker Compose files, Docker provides simple DNS resolution between containers, based on the service names. More on this in <a href="f734178a-8a55-4fc5-9961-13e8182fdda7.xhtml" target="_blank">Chapter 8</a>,<em> Building and Deploying Multi-Container Projects.</em></li>
<li class="mce-root"><kbd>image</kbd>: <kbd>image</kbd> is used to specify the container image you want your container to be based on. For this example, we are using the official <kbd>memcached</kbd> image from Docker Hub, specifying version 1.4.36. We could also have used the latest keyword in place of the version number if we had wanted to always have the latest version of the image.</li>
<li class="mce-root"><kbd>ports</kbd>: The <kbd>ports</kbd> parameter indicate which ports on the host you want to be forwarded to the container. In this case, we will forward port <kbd>11211</kbd> to the exposed container port <kbd>11211</kbd>. Similar to <kbd>docker run</kbd>, ports must be specified in the format <kbd>host:container</kbd>. This is a <kbd>YAML</kbd> list, so each port must be indented and prefixed with a hyphen (<kbd>-</kbd>).</li>
<li class="mce-root"><kbd>volumes</kbd>: This parameter specifies any directories or storage volumes on the Docker host you would like to make accessible to the container. This is useful if there is data in the container you may want to back up, export, or otherwise share with the container. This volume mounting merely serves as an example of the syntax. Similar to the <kbd>ports</kbd> parameter, <kbd>volumes</kbd> takes a list in the form of <kbd>hostDirectory:containerDirectory</kbd>.</li>
</ul>
<p>To start our container using Docker Compose, you simply execute the command <kbd>docker-compose up</kbd>. This will, by default, start all of the containers in the Docker Compose file one by one, unless container dependencies are specified. Containers started using <kbd>docker-compose</kbd> will be started in <kbd>attached</kbd> mode, meaning that the container process will run, taking over the Terminal you are using. Similar to <kbd>docker run</kbd>, we can supply the <kbd>-d</kbd> flag to run the containers in <kbd>detached</kbd> mode, so we can run some validations in the same Terminal:</p>
<pre class="western"><strong>docker-compose up -d</strong> </pre>
<p>You will observe that, similarly to <kbd>docker run</kbd>, Docker Compose automatically determines that the container image is not present on the Docker host and successfully downloads the image and corresponding layers from the internet.</p>
<pre class="western"><strong>ubuntu@node01:/vagrant/Docker_Compose/test$ docker-compose up -d
Creating network "test_default" with the default driver
Pulling Cache_Server (memcached:1.4.36)...
1.4.36: Pulling from library/memcached
56c7afbcb0f1: Pull complete
49acdc7c75c9: Pull complete
152590a2a704: Pull complete
4dc7b8165378: Pull complete
4cb74c11bcdd: Pull complete
Digest: sha256:a2dfef5700944ec8bb2d2c0d6f5b2819324b1b91647dc09847ce81e7a91e3fe4n
Status: Downloaded newer image for memcached:1.4.36
Creating test_Cache_Server_1 ...
Creating test_Cache_Server_1 ... done</strong></pre>
<p>Running <kbd>docker ps -a</kbd> will reveal that Docker Compose was able to successfully create the running container with the properly exposed ports and volume mounts listed in our <kbd>docker-compose.yml</kbd> file:</p>
<pre class="western"><strong>ubuntu@node01:/vagrant/Docker_Compose/test$ docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                      NAMES
cacf58b455f3        memcached:1.4.36    "docker-entrypoint.sh"   7 minutes ago       Up 7 minutes        0.0.0.0:11211-&gt;11211/tcp   test_Cache_Server_1</strong></pre>
<p>We can use <kbd>telnet</kbd> to ensure the <kbd>memcached</kbd> application is functioning and forwarded through the host networking. Using <kbd>telnet</kbd>, we can store and retrieve data from <kbd>Memcached</kbd> directly:</p>
<pre class="western"><strong>ubuntu@node01:/vagrant/Docker_Compose/test$ telnet localhost 11211
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
STAT active_slabs 0<br/>STAT total_malloced 0<br/>END
</strong></pre>
<p>Running the <kbd>stats slabs</kbd> command lets us know that <kbd>memcached</kbd> has been deployed and is functioning as expected.</p>
<p>Now that we have had a brief introduction to Docker and Docker Compose, we have acquired the basic skills needed to start working with Ansible Container.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Ansible Container workflow</h1>
                
            
            
                
<p>Similar to other orchestration and automation tools, Ansible Container contains a set of utilities that constitute a containerized workflow. Using Ansible Container, you can create, build, run, and deploy containers, from development all the way through to production, using the suite of tools included with Ansible Container out of the box. Ansible Core's <em>batteries-included</em> methodology carries over to Ansible Container to provide developers and system administrators with a complete containerized workflow solution. The following is an overview of the primary Ansible Container functions and how they correspond to the typical lifecycle of a containerized application:</p>
<ul>
<li class="mce-root"><kbd>ansible-container init</kbd>: Used to initially start an Ansible Container project. <kbd>init</kbd> builds and creates the directory scaffolding and base files that are required to start an Ansible Container project.</li>
<li><kbd>ansible-container build</kbd>: Similar to what the name suggests, <kbd>build</kbd> will parse the primary files in your project and attempt to build the containers described. Ansible Container is able to do this by first creating what is known as a <kbd>conductor</kbd> container. The <kbd>conductor</kbd> container is a master container that is created during the build phase of your project and contains a running copy of Ansible. Once the other containers launch, the <kbd>conductor</kbd> container is responsible for running the Ansible roles and playbooks against them to bring the containers into the desired state.</li>
<li class="mce-root"><kbd>ansible-container run</kbd>: <kbd>run</kbd> works in a very similar way to <kbd>docker run</kbd> in the respect that, when executed, <kbd>run</kbd> takes the built containers and attempts to run them in the container engine on the host. By default, the <kbd>run</kbd> command takes into consideration any development options listed in the <kbd>container.yml</kbd> file, unless the <kbd>-- production</kbd> flag is passed in at runtime.</li>
<li class="mce-root"><kbd>ansible-container destroy</kbd>: Stops any running containers and also removes any built image files. This command is useful when testing an end-to-end deployment from scratch.</li>
<li class="mce-root"><kbd>ansible-container push</kbd>: This command pushes the container images you built with Ansible Container to a container registry of your choice, such as Docker Hub, Quay, or GCR. This command is similar to <kbd>docker push</kbd>.</li>
<li class="mce-root"><kbd>ansible-container deploy</kbd>: <kbd>deploy</kbd> (formerly <kbd>ShipIt</kbd>) takes your current project and generates a customized Ansible playbook and role to deploy your container to a cloud service provider. At the time of writing, <kbd>deploy</kbd> supports only OpenShift and Kubernetes. Running this playbook using the <kbd>ansible-playbook</kbd> command, will deploy your containers to the specified provider.</li>
</ul>
<p>As you can see, Ansible Container comes prebuilt with an end-to-end lifecycle management system that allows you to manage containers from development through to production. Ansible Container leverages the powerful and customizable Ansible configuration management system to allow containers to be created and deployed similarly to bare-metal or virtual nodes.</p>
<p>All Ansible Container subcommands can be found by running <kbd>ansible-container --help</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Ansible Container quick-start</h1>
                
            
            
                
<p>This portion of the chapter is going to focus on getting started with Ansible Container, initializing a base project, and recreating the <kbd>memcached</kbd> example from earlier. If you are not following along with the Vagrant lab provided on GitHub, the first step is to install Ansible Container using the <kbd>python-pip</kbd> package manager. The following steps will install Ansible Container with support for Docker on a Debian-based distribution of Linux:</p>
<pre class="western"><strong>sudo apt-get update
sudo apt-get install python-pip
sudo pip install ansible-container docker</strong></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Ansible Container init</h1>
                
            
            
                
<p>You should now have Ansible Container installed and ready to run in your environment. The first command that's required to start a new Ansible Container project is the <kbd>ansible-container init</kbd> command. After logging in to your vagrant VM, create an empty directory in the <kbd>/vagrant</kbd> directory and type:</p>
<pre class="western"><strong>ubuntu@node01:~$ mkdir /vagrant/demo
ubuntu@node01:~$ cd /vagrant/demo
ubuntu@node01:/vagrant/demo$ ansible-container init 
Ansible Container initialized.</strong></pre>
<p>It is important to note that the final lab exercise can be found in the official book GitHub repository, in the directory: <kbd>AnsibleContainer/demo</kbd>.</p>
<p>When Ansible Container has successfully created a new project, it will return the response <kbd>Ansible Container initialized</kbd>.</p>
<p>As discussed previously, <kbd>init</kbd> creates the basic directory structure and layout required to start building Ansible Container projects. Navigating to that directory and looking at the directory listing will give you an idea of what an Ansible Container project looks like:</p>
<pre class="western">demo
├── ansible.cfg
├── ansible-requirements.txt
├── container.yml
├── meta.yml
└── requirements.yml</pre>
<p>Let's look at these files individually to understand their purpose in an Ansible Container project:</p>
<ul>
<li class="mce-root"><kbd>ansible.cfg</kbd>: The primary configuration file for the Ansible engine. Any settings you want the Ansible <kbd>conductor</kbd> container to leverage will go in this file. If you're familiar with using Ansible for configuration management tasks, you will already have a basic familiarity with the <kbd>ansible.cfg</kbd> file. For the most part, you can safely leave this file alone, unless there is a specific way Ansible needs to run during the container build process. More information about Ansible configuration options can be found in the Ansible documentation at <a href="https://docs.ansible.com">https://docs.ansible.com.</a></li>
<li class="mce-root"><kbd>ansible-requirements.txt</kbd>: The <kbd>ansible-requirements.txt</kbd> file is used to specify any Python pip dependencies that your playbooks may need to run successfully. Ansible Engine is built on a series of modules that perform the tasks described in the playbooks. Any additional Python packages that are required to run the Ansible roles are listed in this file.</li>
<li class="mce-root"><kbd>container.yml</kbd>: Describes the state of your containers, including base images, exposed ports, and volume mounts. The syntax for <kbd>container.yml</kbd> is similar to the Docker Compose format, with a few differences we will look at throughout this book.</li>
<li class="mce-root"><kbd>meta.yml</kbd>: The <kbd>meta.yml</kbd> file includes any metadata about your container project, including the name of the author, version information, software licensing details, and tags. This information makes it easy for other users to find your project should you choose to share it on Ansible Galaxy.</li>
<li class="mce-root"><kbd>requirements.yml</kbd>: Defines any Ansible Galaxy roles and version information your container project will use. In this file, you can describe the exact roles and role versions your project requires. Ansible Container will download these roles from Ansible Galaxy prior to building your container project. By specifying your roles in the <kbd>requirements.yml</kbd> file, you can be sure that your projects consistently use the same roles to build the base container images. It is important to keep in mind the distinction between <kbd>ansible-requirements.yml</kbd> and <kbd>requirements.yml</kbd>. <kbd>requirements.yml</kbd> is used to manage the Ansible roles your project depends on, whereas <kbd>ansible-requirements.yml</kbd> is used to manage the Python pip packages those roles may require.</li>
</ul>
<p>Now that we have a feel for what an Ansible Container project looks like, we can dive in and start experimenting with creating a simple Ansible Container project. Remember our Docker Compose project we created earlier? Let's use that as a starting point and port this project to Ansible Container by editing the <kbd>container.yml</kbd> file. In a text editor, open the <kbd>container.yml</kbd> file. By default <kbd>container.yml</kbd> comes with a prepopulated structure, which in many ways resembles a Docker Compose file. Your <kbd>container.yml</kbd> file should resemble the following. To conserve space, I have removed many of the comments and example data:</p>
<pre class="western">version: "2"
settings:
  conductor_base: centos:7

services: {}

registries: {}</pre>
<p>Each of these sections has a particular purpose for structuring your Ansible Container project. It is important to understand what each of these <kbd>YAML</kbd> definitions is used to describe. The comments that come in the file by default show examples of the various settings each of these sections uses. The following is a list of the key sections of the <kbd>container.yml</kbd> file and how to use these sections in your Ansible Container project:</p>
<ul>
<li><kbd>version</kbd>: The <kbd>version</kbd> section signifies which version of the Docker Compose API to use. As we discussed before, Ansible Container is a wrapper around many of the Docker Compose services. Here, we can specify which version of the Docker Compose API we want our containers to use.</li>
<li><kbd>settings</kbd>: The <kbd>settings</kbd> section is used to specify additional integrations or modify any default behaviors of our Ansible Container project. By default, there is one setting enabled.</li>
<li><kbd>conductor_base</kbd>:  This indicates which base image we want our project to use. The <kbd>conductor</kbd> container is responsible for creating a Python environment used for running Ansible playbooks and roles. The <kbd>conductor</kbd> image will connect to the other containers that it creates, providing access to its own Python environment during the build process. Therefore, it is very important to use the same base container operating system as the container images you plan on building. This will ensure complete compatibility in terms of Python and Ansible. Think of the conductor image as a container that works in a similar way to the Ansible controller node in a standard Ansible implementation. This container will reach out to the other nodes (containers), leveraging the Docker API directly to bring our other containers into the desired state. Once we are done building our containers, the <kbd>conductor</kbd> container deletes itself by default, unless you instruct Ansible Container to retain the conductor image for debugging purposes. As well as specifying our conductor image, we can also specify other integrations in the settings section, such as Kubernetes credentials or OpenShift endpoints. We will dig deeper into these in later chapters.</li>
<li><kbd>services</kbd>: The <kbd>services</kbd> section is almost identical to the <kbd>services</kbd> section in our Docker Compose file. In this section, we will provide our <kbd>YAML</kbd> definitions, which describe the running state of our containers: which base image we will use, the container name, exposed ports, volumes, and more. Each container described in the services section is a <em>node</em> that will be configured by our conductor image running Ansible. By default the <kbd>services</kbd> section is disabled with two curly braces next to the <kbd>YAML</kbd> definition: <kbd>{}</kbd>. Before adding container definitions, delete the curly braces so that Ansible Container can access the child data.</li>
<li><kbd>registries</kbd>: The final section of our <kbd>container.yml</kbd> file is the <kbd>registries</kbd> section. It is here that you can specify container registries, from which Ansible container will pull images. By default, Ansible Container uses Docker Hub, but you may also specify other registries, such as Quay, <kbd>gcr.io</kbd>, or locally hosted container registries. This section is also used in conjunction with the <kbd>ansible-container</kbd> push command to push your built containers to the registry service of your choice.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Ansible Container build</h1>
                
            
            
                
<p>The second part of our Ansible Container workflow is the build process. Now that we have our first project initialized, we can explore how the <kbd>ansible-container build</kbd> function works even though we do not have any services or roles defined. From the <kbd>demo</kbd> directory, run the <kbd>ansible-container build</kbd> command. You should see output similar to the following:</p>
<pre class="western"><strong>ubuntu@node01:/vagrant/AnsibleContainer/demo$ ansible-container build
Building Docker Engine context...
Starting Docker build of Ansible Container Conductor image (please be patient)...
Parsing conductor CLI args.
Docker™ daemon integration engine loaded. Build starting.       project=demo
All images successfully built.
Conductor terminated. Cleaning up.      command_rc=0 conductor_id=c4f7806f8afb0910e4f7d25e5c37be32800ed8b41618d246f70da0508322c479 save_container=False</strong></pre>
<p>Running Ansible Container build for the first time on your local workstation might take a few minutes to complete, as it needs to build the <kbd>conductor</kbd> container before it can start. Keeping in mind that the conductor container is responsible for connecting to the service containers using the Docker API and executing Ansible playbooks and roles on them. Since this is a basic example of the <kbd>ansible-container build</kbd> command, there are no Ansible playbooks to run on the containers we are creating. Later in the book we will write our own roles to really explore how the conductor container functions. The below illustration demonstrates the how the conductor container connects to the service containers:</p>
<div><img height="264" width="425" src="img/9fa32db1-533e-4304-b32b-d598665972b4.png"/></div>
<p>Figure 1: Conductor container bringing the service containers into the desired state</p>
<p>However, in this example, Ansible Container will first connects to the Docker API on the localhost to determine the build context, download the required image dependencies, and execute the build of the <kbd>conductor</kbd> container. You can see in the preceding output that our <kbd>conductor</kbd> container was successfully built for our project, <kbd>demo</kbd>. It also lists the return code, which confirms that our image was successfully built, as well as an internal conductor ID, which Ansible Container generates.</p>
<p>If we execute the command <kbd>docker ps -a</kbd>, we will see that no containers are currently running or exited. This is expected since we have not yet defined any containers in the <kbd>services </kbd>section of our <kbd>container.yml</kbd> file. You may also see that, since we did not pass in any arguments or configuration to instruct Ansible Container to save our <kbd>conductor</kbd> container, Ansible Container deleted the conductor after it had finished running.</p>
<pre class="western"><strong>ubuntu@node01:demo$ docker ps -a
CONTAINER ID  IMAGE  COMMAND  CREATED  STATUS  PORTS  NAMES</strong></pre>
<p>However, if we take a look at our <kbd>docker images</kbd> output, you will find that the <kbd>conductor</kbd> image we built is cached, as well as the base image used to create it. Note that the conductor image is prefixed with <kbd>demo-*</kbd>. Ansible Container automatically names container images based on the <kbd>project-service</kbd> nomenclature. This ensures that, if you are building and running multiple container projects at once, it is easy to tell which containers belong to which projects.</p>
<p>In this case, our project is called, <kbd>demo </kbd>and the service we are building is <kbd>conductor</kbd>.</p>
<pre class="western"><strong>ubuntu@node01:demo$ docker images
REPOSITORY  TAG  IMAGE ID  CREATED  SIZE
demo-conductor  latest  a24fbeee16e2  38 seconds ago  574.5 MB
centos  7  3bee3060bfc8  3 weeks ago  192.6 MB</strong></pre>
<p>We can also build our project by passing in the <kbd>--save-conductor-container</kbd> flag to keep our <kbd>conductor</kbd> container after the <kbd>ansible-container build</kbd> process finishes. This is useful for debugging failed builds by having the ability to view our containers from the context that Ansible is running from. Let's try rebuilding our <kbd>demo</kbd> project, this time saving the <kbd>conductor</kbd> container:</p>
<pre class="western"><strong>ubuntu@node01:demo$ ansible-container build --save-conductor-container
Building Docker Engine context...
Starting Docker build of Ansible Container Conductor image (please be patient)...
Parsing conductor CLI args.
Docker™ daemon integration engine loaded. Build starting.       project=demo
All images successfully built.
Conductor terminated. Preserving as requested.  command_rc=0 conductor_id=ff84fa95d5908b076ce432d1076533679d945104e506ad5599e417cece7c3a5d save_container=True</strong></pre>
<p>This time, you will see the output reflect a slight difference: <kbd>Conductor terminated. Preserving as requested</kbd>, in addition to the output we observed earlier. This indicates that, while the conductor has stopped due to it having finished its job, the container, <kbd>demo_conductor</kbd>, remains for us to look at with <kbd>docker ps -a</kbd>:</p>
<pre class="western"><strong>ubuntu@node01:/vagrant/AnsibleContainer/demo$ docker ps -a
CONTAINER ID  IMAGE  COMMAND  CREATED  STATUS  PORTS  NAMES
c3c7dc04d251  a24fbeee16e2  "conductor build –pr"  3 minutes ago Exited (0) 3 minutes ago  demo_conductor</strong></pre>
<p>With a firm understanding of how the Ansible Container build process works, as well as how Ansible Container builds the conductor image, we can use this knowledge to recreate the Docker Compose project we introduced at the beginning of this chapter. We can use Ansible Container to spin up the <kbd>memcached</kbd> server container we created before.</p>
<p>In your text editor, open the <kbd>conductor.yml</kbd> document we looked at earlier. Delete the curly braces after our <kbd>services: {}</kbd> declaration, and add the following beneath it, indented two spaces as per the <kbd>YAML</kbd> syntax:</p>
<pre class="western">services:
  AC_Cache_Server:
    from: memcached:1.4.36
    ports:
      - "11211:11211"
    volumes:
      - ".:/var/lib/MyVolume"</pre>
<p>You can see that the syntax we are using to specify our service is remarkably similar to the Docker Compose syntax we created earlier. For the purposes of this demonstration, we are going to use the same parameters for <kbd>ports</kbd> and <kbd>volume</kbd> that we used with Docker Compose earlier, so that the reader may easily see the slight differences in the syntax. You will note that the <kbd>container.yml</kbd> syntax and Docker Compose syntax have many similarities, but the primary differences allow Ansible Container to be more flexible with how container services are built and deployed.</p>
<p>Save and close the file. If you execute the <kbd>ansible-container build</kbd> command again, you should see the following output:</p>
<pre class="western"><strong>ubuntu@node01:demo$ ansible-container build
Building Docker Engine context...
Starting Docker build of Ansible Container Conductor image (please be patient)...
Parsing conductor CLI args.
Docker™ daemon integration engine loaded. Build starting.       project=demo
Building service...     project=demo service=AC_Cache_Server
Service had no roles specified. Nothing to do.  service=AC_Cache_Server
All images successfully built.
Conductor terminated. Cleaning up.      command_rc=0 conductor_id=22126436967e7810aff44c83fb75d2276bb9a66352ddbd44a68d44219fe97344 save_container=False</strong></pre>
<p>After Ansible Container has built our conductor image, we can observe from this output that Ansible Container now recognizes that we have a service called <kbd>AC_Cache_Server</kbd> enabled and it is attempting to build it. However, we do not have any Ansible roles associated with this service, so it returns the message <kbd>Nothing to do</kbd>. This would usually be the step in the process during which our playbooks would be executed to build the services we are creating. Since we do not have any roles defined, Ansible Container is going to skip this step and terminate the <kbd>conductor</kbd> container as usual.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Ansible Container run</h1>
                
            
            
                
<p class="mce-root">Now that we have a service defined, we can use the <kbd>ansible-container run</kbd> command to start our service. The run command quickly generates a small Ansible playbook that is responsible for starting the containers specified in the <kbd>container.yml</kbd> file. This playbook leverages the <kbd>docker_service</kbd> Ansible module for starting, stopping, restarting, and destroying containers. The <kbd>docker_service</kbd> module is also useful for interfacing with the Docker daemon installed on the host OS to pull and delete images from the Docker image cache. While it's not super important to understand the implementation details behind the module at this point, it is helpful to understand how Ansible Container is working behind the scenes to run containers. Executing the <kbd>ansible-container run</kbd> command will display the stages of the playbook run, as well as <kbd>play recap</kbd>, similar to the following output:</p>
<pre class="western"><strong>ubuntu@node01:demo$ ansible-container run
Parsing conductor CLI args.
Engine integration loaded. Preparing run.       engine=Docker™ daemon
WARNING Image memcached:1.4.36 for service AC_Cache_Server not found. An attempt will be made to pull it.

PLAY [localhost] ***************************************************************

TASK [docker_service] **********************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=1    changed=1    unreachable=0    failed=0

All services running.   playbook_rc=0
Conductor terminated. Cleaning up.      command_rc=0 conductor_id=17aaa7aac99ff12427a7f4fb2671b24cc1ec33b774c701723dabb27eb6d75b07 save_container=False</strong></pre>
<p>As you can see by reading through the playbook run output, you can easily follow the key highlights of our project as we bring it into a running state:</p>
<ul>
<li>Our project cannot find the <kbd>memcached</kbd> image we specified, so Ansible Container pulls it from the default repository (Docker Hub)</li>
<li>A single change has been made on our host to bring our container into a running state</li>
<li>None of our plays failed; one task succeeded (bringing up our container), and this successful task made a change on our host in order to bring up the container</li>
<li>The conductor service was terminated</li>
</ul>
<p>Understanding the highlights from the Ansible Container playbook is critical to seeing how Ansible orchestration deploys and maintains our applications. As we discussed previously, the Ansible team works very hard to ensure that Ansible playbook execution is very simple to understand and easy to debug. By displaying all of the steps required to bring up container projects, it is very easy to debug failures and see potential areas for improvement as we move forward into developing more complex projects. The playbook that was just executed is generated on-the-fly when <kbd>ansible-container run</kbd> is executed, and is located in the <kbd>ansible-deployment</kbd> directory. Leveraging Ansible Container to run projects takes away much of the complexity of deploying and maintaining projects since all of the deployment complexity is abstracted away. From the perspective of the user, you are concerned with ensuring the containers run and are built properly. Ansible Container becomes an end-to-end lifecycle management tool that enables containers to be built consistently and to run in an expected state every time. As we will see later in the book, having Ansible Container streamline the deployment complexity is especially useful in environments that leverage Kubernetes or OpenShift.</p>
<p>Now that our container run has completed, let's take a look to see what containers are running on our host using the <kbd>docker ps -a</kbd> command:</p>
<pre><strong>ubuntu@node01:/vagrant/AnsibleContainer/demo$ docker ps -a</strong><br/><strong>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong>c4a7792fb1fb memcached:1.4.36 "docker-entrypoint.sh" 14 seconds ago Up 13 seconds 0.0.0.0:11211-&gt;11211/tcp demo_AC_Cache_Server_1</strong></pre>
<p class="mce-root">As expected, it is easy to see that our <kbd>memcached</kbd> container (version 1.4.36) is in a running state. Also, note that the <kbd>conductor</kbd> container is not running or showing up in our <kbd>docker ps</kbd> output. Ansible Container only runs the containers defined in the <kbd>container.yml</kbd> file as the <em>desired state</em>, unless you choose to keep the <kbd>conductor</kbd> container for debugging purposes. The name of the container, as we specified in our <kbd>container.yml</kbd> file, is <kbd>demo_AC_Cache_Server_1</kbd>. You may ask yourself why this is the case, as we observed when we created the <kbd>container.yml</kbd> file that we had specifically named our container <kbd>AC_Cache_Server</kbd>. One of the great features of Ansible Container is that it understands that, as developers, we might be running and testing multiple versions of our projects at once on the same host or group of hosts. By default, when Ansible Container starts containers, it automatically appends the name of our project (<kbd>demo</kbd> in this case) to the front of the name of the running container, and a number indicating the instance ID of the running container.</p>
<p class="mce-root">In this case, since we have one instance of this container running, Ansible Container automatically appended <kbd>demo_</kbd> and <kbd>_1</kbd> to the beginning and end of our container name so that it would not conflict if we were testing multiple versions of this container on the same host.</p>
<p class="mce-root">Since we are recreating the exercise we started at the beginning of the chapter on this host, let's run the same <kbd>telnet</kbd> test using the <kbd>stats slabs</kbd> command we executed earlier to see if our <kbd>memcached</kbd> container is running and responding as expected:</p>
<pre class="mce-root"><strong>ubuntu@node01:/vagrant/AnsibleContainer/demo$ telnet localhost 11211</strong><br/><strong>Trying 127.0.0.1...</strong><br/><strong>Connected to localhost.</strong><br/><strong>Escape character is '^]'.</strong><br/><strong>STAT active_slabs 0<br/>STAT total_malloced 0<br/>END</strong></pre>
<p>It appears that our containerized service is running and properly accepting requests, listening on the network interfaces of our Docker host. Keep in mind, we specified in our <kbd>container.yml</kbd> file that our localhost port (<kbd>11211</kbd>) should be forwarded to the container's listening port (also <kbd>11211</kbd>).</p>
<p>Let's take a quick peek at the image cache on the Docker host. We can do this by executing the <kbd>docker images</kbd> command:</p>
<pre class="western"><strong>ubuntu@node01:/vagrant/AnsibleContainer/demo$ docker images
REPOSITORY  TAG  IMAGE ID  CREATED  SIZE
demo-conductor  latest  a24fbeee16e2  48 minutes ago  574.5 MB
centos  7  3bee3060bfc8  3 weeks ago  192.6 MB
memcached  1.4.36  6c32c12d9101  6 weeks ago  83.88 MB</strong></pre>
<p>Based on this output, we can understand more clearly how Ansible Container is working on the backend. In order to bring up our <kbd>demo</kbd> project, Ansible Container had to leverage three images: <kbd>CentOS 7</kbd>, <kbd>memcached</kbd>, and <kbd>demo-conductor</kbd>. The container image named <kbd>demo-conductor</kbd> is the conductor image that was created during the build process. To build the conductor image, Ansible Container had to download and cache the <kbd>CentOS 7</kbd> base image also seen in this output. Finally, <kbd>memcached</kbd> is the container that Ansible had to pull from the image repository, as it was specified in the <kbd>services</kbd> section of our <kbd>container.yml</kbd> file. The reader may also note that the conductor image is prefaced with the name of our project <kbd>demo</kbd>, similarly to the running state of our service container in the preceding output. This is again to avoid name conflicts and to have the flexibility to run multiple container projects at once on the same host.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Ansible Container destroy</h1>
                
            
            
                
<p>Once you have finished experimenting with the <kbd>demo</kbd> project, we can use the <kbd>ansible-container destroy</kbd> command to stop all running instances of our container and remove all traces of it from our system. <kbd>destroy</kbd> is useful for cleaning up existing deployments and testing our containers by rebuilding them from scratch. To destroy a container, simply run <kbd>ansible-container destroy</kbd> in your project directory.<br/></p>
<pre class="western"><strong>ubuntu@node01:/vagrant/AnsibleContainer/demo$ ansible-container destroy
Parsing conductor CLI args.
Engine integration loaded. Preparing to stop+delete all containers and built images.    engine=Docker™ daemon

PLAY [localhost] ***************************************************************

TASK [docker_service] **********************************************************
changed: [localhost]

TASK [docker_image] ************************************************************
changed: [localhost]

TASK [docker_image] ************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=3    unreachable=0    failed=0

All services destroyed. playbook_rc=0
Conductor terminated. Cleaning up.      command_rc=0 conductor_id=1dc36baefde06235a8c7c18733479501bfd48f7c8da0915f4bde1b196e3eff65 save_container=False</strong></pre>
<p>Similar to the <kbd>run</kbd> command seen earlier, destroy executes the same playbook that was autogenerated by the <kbd>run</kbd> process. However, this time, it stops and deletes the containers specified in the <kbd>container.yml</kbd> file. You may find that the <kbd>docker ps -a</kbd> output now displays no running containers on our host:</p>
<p>Similarly, the <kbd>destroy</kbd> function has wiped out the <kbd>conductor</kbd> container image, as well as the service container images on the Docker host. We can validate this with the <kbd>docker images</kbd> command:</p>
<pre class="western"><strong>ubuntu@node01:/vagrant/AnsibleContainer/demo$ docker images
REPOSITORY  TAG  IMAGE ID  CREATED  SIZE
&lt;none&gt;  &lt;none&gt;  e23c420b896a  43 minutes ago  576.3 MB
centos  3bee3060bfc8  4 weeks ago  192.6 MB</strong></pre>
<p>Note that the only container left on the system is the base <kbd>CentOS</kbd> container. This can be manually deleted but, by default, Ansible Container leaves this on the system to speed up the process of destroying and rebuilding projects.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>Over the course of this chapter, we have learned some fundamental concepts about how Ansible Container works, how it leverages the Docker Compose APIs, as well as basic lifecycle management tools built-in to Ansible Container, including <kbd>init</kbd>, <kbd>build</kbd>, <kbd>run</kbd>, and <kbd>destroy</kbd>. Having a firm grasp and understanding of what these features do and how they work is foundational when it comes to going forward and digging deeper into more complex projects we will create in Ansible Container. Although this example is included in the official Git repository of the book, feel free to recreate and tweak these examples to experiment further with how Ansible Container works. In the next chapter, we will learn how to use Ansible Container with existing roles, leveraging those roles to create reusable container artifacts.</p>
<p> </p>
<p class="mce-root"/>


            

            
        
    </body></html>