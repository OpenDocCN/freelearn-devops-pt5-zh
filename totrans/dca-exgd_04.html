<html><head></head><body>
        

                            
                    Running Docker Containers
                
            
            
                
<p>This chapter is dedicated to the Docker command line. We have run some containers in the previous chapters, but we did not go into detail regarding the arguments and options used.</p>
<p>In this chapter, we will talk about different Docker objects, such as images, containers, and volumes, and their associated actions. Not all objects will have the same features and, consequently, they will not have the same actions and arguments.</p>
<p>Remember that image building is based on container execution. Each layer is the result of executing commands on a container that is automatically "committed" in a Docker node's filesystem. All these layers, when grouped together, constitute an image.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Reviewing the Docker command line in depth</li>
<li>Learning about Docker objects</li>
<li>Running containers</li>
<li>Interacting with containers</li>
<li>Limiting host resources</li>
<li>Converting containers into images</li>
<li>Formatting and filtering information</li>
<li>Managing devices</li>
</ul>
<p>Let's begin by looking at how to work with the Docker command line.</p>
<h1 id="uuid-c634da56-8d4f-472d-8706-8f96c5df4cd6">Technical requirements</h1>
<p>In this chapter, we will learn about Docker container concepts. We'll provide some labs at the end of this chapter that will help you understand and learn about the concepts covered. These labs can be run on your laptop or PC using the provided Vagrant standalone environment or any Docker host of your own that you've deployed. Additional information can be found in this book's GitHub repository at <a href="https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git">https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git</a>.</p>
<p>Check out the following video to see the Code in Action:</p>
<p>"<a href="https://bit.ly/32AEGHU" target="_blank">https://bit.ly/32AEGHU</a>"</p>
<h1 id="uuid-3b1ffcff-a1ff-4744-b6c0-822979900f91">Reviewing the Docker command line in depth</h1>
<p>As we learned in the previous chapters, Docker is a client-server application. Previous versions of the software installed both components at the same time, but the newer versions allow us to just install the client for using remote servers.</p>
<p>We learned about the various Docker daemon options and arguments in <a href="c5ecd7bc-b7ed-4303-89a8-e487c6a220ed.xhtml">Chapter 1</a>, <em>Modern Infrastructures and Applications with Docker</em>. In this chapter, we are going to review the Docker client command line.</p>
<p>When we use the Docker command line on either Linux or Windows, we are always referencing the Docker client and, usually, the binary or executable program is <kbd>/usr/bin/docker</kbd> or <kbd>C:\ProgramData\Docker</kbd> on Linux and Windows, respectively.</p>
<p>Docker's command-line usage format is <kbd>docker [OPTIONS] COMMAND</kbd>. Various options are used to define the daemon we will connect to and how this communication will be created. Debugging and the level of logging are managed at this point too. Some of these options can be set using Docker client configuration in each user' s <kbd>config.json</kbd> file under their <kbd>home</kbd> directory.</p>
<p>The Docker client configuration file, <kbd>config.json</kbd>, will manage filtering options, which we will learn about at the end of this chapter. It also stores login access to registries.</p>
<p>Environment variables can also be used to configure Docker client behavior. Here is a list of the most frequently used ones:<strong><br/></strong></p>
<ul>
<li><kbd>DOCKER_CONFIG</kbd>: This will set the Docker client's config file path.</li>
<li><kbd>DOCKER_CERT_PATH</kbd>: This sets the path for client-server certificates.</li>
<li><kbd>DOCKER_HOST</kbd>: We can use remote Docker engines. By default, we will use the local Docker daemon.</li>
<li><kbd>DOCKER_TLS</kbd>: This option enables TLS communication (requires certificates to work).</li>
<li><kbd>DOCKER_TLS_VERIFY</kbd>: This option will not validate remote daemon certificates.</li>
<li><kbd>DOCKER_CONTENT_TRUST</kbd>: We will use this option to use content trust features (image immutability and ownership).</li>
</ul>
<p>Docker commands will always require a Docker daemon and they will be executed against <strong>objects</strong><em><strong>.</strong></em> These are internal resources managed by Docker, distributed on categories with different features and properties. We'll look at this in more detail in the next section.</p>
<p>All Docker objects have their own IDs. Names are tags associated with these IDs and therefore, in some cases, we will be able to have many names for an object. The object ID will uniquely identify each object and thus, Docker can show or manage information regarding that object without using its category. We recommend using categories that are always on the Docker command line.</p>
<p>The following table shows the commands that will be common to all objects:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td style="width: 10.6241%">
<p class="mce-root"/>
<p><kbd>ls</kbd> or <kbd>list</kbd></p>
</td>
<td style="width: 87.3759%">
<p>This will show a list of all objects in that category. The output may be different, depending on which objects are queried, but we will usually obtain object names and their IDs.We will use the <kbd>--all</kbd> or <kbd>-a</kbd> modifiers to show all the objects from a selected category because, in some cases, the output will only show a subset. For example, if we list container objects, by default, we will just get running containers. Dead (exited) containers will not be shown unless you use the <kbd>--all</kbd> command modifier. Filtering will allow us to retrieve only a subset of objects. We will use the <kbd>--filter</kbd> or <kbd>-f</kbd> arguments for this. Each object category will have its own keys for easy filtering. We will learn how to filter information later in this chapter.</p>
<p class="mce-root">Formatting is also very important. We will use the <kbd>--format</kbd> option to format the output's information. The usual formats are <kbd>table</kbd> and <kbd>json</kbd> for obtaining table-like information and JSON formats, respectively. We can customize and sort obtained information. All filters should be constructed using the Go templates format.</p>
<p>Formatting output is an art! We will see many options later in this chapter. A good starting point will always be to use <kbd>--format='{{json .}}'</kbd> to review which JSON keys can be used for formatting. We can avoid a full command's output using <kbd>--quiet</kbd> or <kbd>-q</kbd>. This parameter will show only listed object IDs in that category. This is very useful for concatenating or piping output to other commands.</p>
</td>
</tr>
<tr>
<td style="width: 10.6241%"><kbd>rm</kbd> or <kbd>remove</kbd></td>
<td style="width: 87.3759%">
<p class="mce-root">This action will remove defined objects. We can remove them using their IDs or their names. Once deleted, they cannot be recovered.</p>
<p>To avoid confirmation of object deletion, we will use the <kbd>--force</kbd> argument.</p>
</td>
</tr>
<tr>
<td style="width: 10.6241%"><kbd>create</kbd></td>
<td style="width: 87.3759%">
<p>All objects can be created and removed, but each object will have its own arguments. Therefore, we will learn about each object's arguments in different chapters. We will start with container arguments in the next section.</p>
</td>
</tr>
<tr>
<td style="width: 10.6241%"><kbd>inspect</kbd></td>
<td style="width: 87.3759%">
<p class="mce-root">To review object-defined properties, we will use the <kbd>inspect</kbd> action. By default, the object description will be shown in JSON format.</p>
<p class="mce-root">We can also use <kbd>--format</kbd> to format its output. In this case, we can format the output of the object's description. This is very useful for getting just a few required values, as shown in the following example:</p>
<p><kbd><strong>$ docker image inspect nginx:alpine --format "{{ json .Config.Cmd }}"</strong></kbd></p>
<p><kbd><strong>["nginx","-g","daemon off;"]</strong></kbd></p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>The Docker client was programmed in Go and it contains many Go template formatting and filtering options.</p>
<p>Every time we use <kbd>docker ps</kbd>, we are actually executing <kbd>docker container ls</kbd><strong><em>.</em></strong></p>
<p>In the next section, we will introduce the different resources or objects we have available in Docker.</p>
<h1 id="uuid-7b9b5887-87a1-4282-8ce7-0bc6b15f2fa5">Learning about Docker objects</h1>
<p>Let's define the different categories of objects that are available for a standalone Docker daemon:</p>
<ul>
<li><strong>Images</strong>: These are the basis for creating containers. In <a href="3952ec16-ca49-4bc2-b7e6-d6f17fec3fab.xhtml">Chapter 2</a>, <em>Building Docker Images</em>, we learned the concept of multi-layered templates for providing a root filesystem for the container's main process and all the meta-information required to execute it.</li>
<li><strong>Containers</strong>: As we learned in <a href="c5ecd7bc-b7ed-4303-89a8-e487c6a220ed.xhtml">Chapter 1</a>, <em>Modern Infrastructures and Applications with Docker</em>, a container is a compound of isolated namespaces, resources, and files for a process (or multiple processes). This process will run inside a wrapped environment as if it was alone in its own system, sharing the host kernel and its resources.</li>
<li><strong>Volumes</strong>: Volumes are used to bypass copy-on-write containers' filesystems. As a result, we will be able to store data out of containers, avoiding their life cycle. We will learn more about volumes in <a href="e7804d8c-ed8c-4013-8449-b746ee654210.xhtml">Chapter 4</a>, <em>Container Persistency and Networking</em>.</li>
<li><strong>Networks</strong>: Containers run on their own network namespace, but they need to reach real infrastructure networks. They will use host physical interfaces in bridge mode, creating virtual interfaces for each container interface. We will learn more about this working model and many other options in <a href="e7804d8c-ed8c-4013-8449-b746ee654210.xhtml"/><a href="e7804d8c-ed8c-4013-8449-b746ee654210.xhtml">Chapter 4</a>, <em>Container Persistency and Networking</em>.</li>
<li><strong>Plugins</strong>: Docker plugins extend engine functionality using processes that will run alongside a Docker daemon. They will share information and configuration with the daemon to provide new features. There are three different kinds of plugins: authorization, volume, and network plugins. The Docker client command line provides the interface for installing and managing plugins. Their configurations will be deployed under the <kbd>/usr/lib/docker/plugins</kbd> or <kbd>/etc/docker/plugins</kbd> directories.</li>
</ul>
<p>These objects are available in a standalone Docker Daemon, but there are other objects when the host participates in a distributed Docker Swarm cluster. We will talk about these in the orchestration chapters, but we will provide a brief synopsis here:</p>
<ul>
<li><strong>Swarm</strong>: This object provides cluster properties. It allows us to create new clusters and join or leave previously created ones. It also maintains cluster security by managing certificate authority or locking access to cluster certificates.   </li>
<li><strong>Nodes</strong>: Nodes are hosts that are part of the cluster. We can update node roles within the cluster and remove them when needed. We can also modify which nodes will run the defined workloads.</li>
<li><strong>Services</strong>:<strong> </strong>Docker Swarm will not manage containers. The minimum scheduling unit in Docker Swarm is the service. They will create tasks, and those will be represented by containers. In Docker Swarm, we deploy services by declaring their state and the number of tasks required to be healthy. We will be able to create services, update their properties (replicas, images used for containers, and so on), or remove them.</li>
<li><strong>Stacks</strong>: When we talk about deploying workloads on Swarm, we usually use stacks, which are multi-service applications. We will define all the components required by an application to run. These components will be services and all their volumes, networks, and so on, as well as their interactions.</li>
</ul>
<p>Swarm objects have all the actions described previously. However, we can also use the <kbd>update</kbd> action to set and change object properties. This action is only available using Docker Swarm.</p>
<p>In the next section, we will learn how to run containers securely using the command line described.</p>
<h1 id="uuid-8d8d8764-59a8-4b3b-92f9-4a4ada26b3a8">Running containers</h1>
<p>Containers are just processes that run in an isolated manner on the Docker host. All the features or properties required for the process to run may be tweaked on container creation.</p>
<h2 id="uuid-9be7dd8e-1cd9-4842-938d-2866e50de274">Main container actions</h2>
<p>Containers can be created, executed, and stopped when required. The following table will introduce the main container actions for this workflow:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p><kbd>create</kbd></p>
</td>
<td>
<p>Because containers are Docker objects, we can create them. When we create a container, we configure how this container will work, without starting it. This stage will prepare a container and we can review its static configuration using <kbd>inspect</kbd>. Any dynamic configuration will not be present because the container is not running yet.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>start</kbd></p>
</td>
<td>
<p>Once the container has been created, it can be started using <kbd>start</kbd>. This means that the container-defined process will be executed with the configured isolation (memory, CPU, networking, and so on) and the external resources that are required. Once the container is started, we will be able to list it or review its state.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>run</kbd></p>
</td>
<td>
<p>This action will create and then start a container. This is how we usually launch a container. There are some command aliases for many objects and actions; for example, <kbd>docker run</kbd>. We recommend using full sentences, including the object in which you are executing the action. A Docker container started with either <kbd>docker container run</kbd> or <kbd>docker run</kbd> will run in the foreground. Your Terminal, by default, will be attached to the container's output. To avoid this behavior, we must use <kbd>--detach</kbd> or <kbd>-d</kbd> to launch the container in the background, detached from the current Terminal.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>pause/unpause</kbd></p>
</td>
<td>
<p>We can freeze the container's process using cgroups in Linux. The process will stay suspended until it is unfrozen.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>stop</kbd></p>
</td>
<td>
<p>Stopping a container will follow the next workflow described. First, the main process will receive a <kbd>SIGTERM</kbd> signal. This will try to shut down and terminate the process normally. By default, the Docker daemon will wait 10 seconds before sending a second signal. Then, the daemon will send a <kbd>SIGKILL</kbd> signal to kill the process completely. Therefore, the daemon will first try to terminate the container's main process gracefully and will kill it if it was not stopped. We can configure what signal to send to stop a container using <kbd>--stop-signal</kbd>. It defaults to <kbd>SIGTERM</kbd>, as mentioned previously.</p>
<p>Also, we can change the number of seconds to wait (10 seconds by default) before sending the second <kbd>SIGKILL</kbd> signal using the <kbd>--time</kbd> argument. This can be configured on container creation or execution using <kbd>--stop-timeout</kbd> when it is already running.<em><br/></em></p>
</td>
</tr>
<tr>
<td>
<p><kbd>kill</kbd></p>
</td>
<td>
<p>As we mentioned earlier, when we run <kbd>docker container stop</kbd>, Docker daemon will first try to stop it gracefully. There are some cases where we want to kill the main process completely without waiting. In these cases, we can use <kbd>docker container kill</kbd> to stop the container immediately. A signal that's been sent can be changed using <kbd>-s</kbd> and, by default, a <kbd>SIGKILL</kbd> signal will be sent.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>restart</kbd></p>
</td>
<td>
<p>The <kbd>restart</kbd> action will stop and start a container. This means that previously learned procedures will be taken and the Docker container's <kbd>stop</kbd> and <kbd>start</kbd> operations will be executed. Therefore, the previously described arguments will also be valid.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>rm</kbd></p>
</td>
<td>
<p>Containers are not ephemeral, as we have learned in previous chapters. They will remain in our system until someone deletes them. We will use <kbd>docker container rm</kbd><em><strong> </strong></em>to remove them.</p>
<p>Running containers cannot be removed unless we use the <kbd>--force/-f</kbd> argument. It is recommended to stop containers in production before deleting them to avoid removing an important one by mistake.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>prune</kbd></p>
</td>
<td>
<p>This command will remove all stopped containers. They can be forced using <kbd>--force</kbd>, and we can limit containers to be removed using filters with the <kbd>--filter</kbd> argument.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>rename</kbd></p>
</td>
<td>
<p>With this action, we change the container name.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>update</kbd></p>
</td>
<td>
<p>Using the <kbd>update</kbd> action, we can change the container's host resource limits and its restart policy.</p>
</td>
</tr>
</tbody>
</table>
<p>Only containers using Hyper-V isolation can be paused on Windows.</p>
<p>By default, all containers will be executed using non-limited resources. They will not run isolated unless we limit their access to host resources. To limit the number of resources available for a container, we must specify its thresholds during creation. We will use the same arguments for <kbd>docker container create</kbd> or <kbd>docker container run</kbd>. We will review how to manage container resources in the <em>Limiting host resources</em> section of this chapter.</p>
<p>We can use the <kbd>--rm</kbd> option to remove a container after its execution. It will also remove all unnamed volumes created during its lifetime. These volumes are defined ephemerally to override copy-on-write filesystems. We must remove them manually or use the <kbd>-v</kbd> argument with the <kbd>docker container rm</kbd> action.</p>
<h2 id="uuid-b1a026e6-6a28-410a-b561-9231e901a7b2">Container network properties</h2>
<p class="mce-root">Containers run in their own network namespace. They will get their own IP addresses and network resources. By default, a Docker daemon will use bridge networking, and containers will get their own name resolution configuration by copying the host values. We can change this behavior on container creation and execution. Let's review some options we can use to configure networking within containers:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p><kbd>--name</kbd></p>
</td>
<td style="width: 84.6631%">
<p>We can provide a name for each container. If we do not specify any container name, a random one will be generated. This way, we can manage containers using this defined name. It will be used as a hostname by default.</p>
</td>
</tr>
<tr>
<td>
<p class="mce-root"/>
<p><kbd>--add-host</kbd></p>
</td>
<td style="width: 84.6631%">
<p>Using this parameter, we are allowed to add hosts and their IP addresses. We will use <kbd>host:ip</kbd> formatted entries.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--dns</kbd></p>
</td>
<td style="width: 84.6631%">
<p>This option will allow us to avoid default DNS resolution. Every time a name cannot be resolved by the embedded DNS server, a query is forwarded to the defined external DNS servers (copied from hosts by default).</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--dns-option</kbd></p>
</td>
<td style="width: 84.6631%">
<p class="mce-root">This will add container-related options to an embedded DNS server.</p>
</td>
</tr>
</tbody>
</table>
<p>Each bridge network will be provided with internal name resolution using the Docker-embedded DNS server, on <kbd>127.0.0.11</kbd>. There is only one exception: the default bridge interface. In this case, we will need to use <kbd>--link</kbd> to allow access to a deployed container from another one on a bridge interface according to its name.</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p><kbd>--dns-search</kbd></p>
</td>
<td style="width: 84.6631%">
<p>This option sets the search domain names for name resolutions.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--domainname</kbd></p>
</td>
<td style="width: 84.6631%">
<p>This option sets the domain name for the container.</p>
</td>
</tr>
<tr>
<td>
<p class="mce-root"><kbd>--ip</kbd></p>
<p>and</p>
<p><kbd>--ip6</kbd></p>
</td>
<td style="width: 84.6631%">
<p>Sometimes, we need to specify a container IP address, either for IPv4 or IPv6. We will just pass version 4 or version 6 addresses as arguments on container creation or execution. Internal IPAM will assign internal IP addresses from the bridged network interface range.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--hostname</kbd></p>
</td>
<td style="width: 84.6631%">
<p>We can set an internal container hostname. It defaults to the container ID.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--link</kbd></p>
</td>
<td style="width: 84.6631%">
<p>We can add internal name resolution to other containers using <kbd>CONTAINER_NAME:DNS_ALIAS</kbd>. These added linked names will be accessible to other containers using their names or IP addresses (this is the default option).</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--mac-address</kbd></p>
</td>
<td style="width: 84.6631%">
<p>This option allows us to set a container MAC address.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--network</kbd></p>
</td>
<td style="width: 84.6631%">
<p>We can choose what type of network connectivity we will provide to containers. By default, all the containers will run on the default bridged network. In this chapter, we will just use the default networking mode, but there are other options as well, which we will learn about in the following chapters.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--network-alias</kbd></p>
</td>
<td style="width: 84.6631%">
<p>This option helps us specify an alias for the container on a network. We will have more name resolutions for a container IP.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>We need to define a restart policy to manage the container's life. We require containers to stop/die and start fast. Resilience is the new key to an application's availability. We can manage this container's behavior with the <kbd>--restart</kbd> parameter. There are four options:</p>
<ul>
<li><kbd>no</kbd>: This is the default option. The container will remain stopped if it died or it was stopped manually.</li>
<li><kbd>on-failure</kbd>: This option will restart the container only if it died because of the main process's failure.</li>
<li><kbd>always</kbd>: We don't care whether someone stopped the container or whether it died by itself. We require the container to be running; therefore, Docker daemon will always try to restart it.</li>
<li><kbd>unless-stopped</kbd>: This option will not restart the container if we have executed a Docker <kbd>stop</kbd> command.</li>
</ul>
<p>These options are very important as they manage what a Docker daemon has to do with the containers when the Daemon is restarted; for example, when we have to reboot the host.</p>
<h2 id="uuid-8a4d9289-8c0c-4371-99fb-cd7c48145078">Container behavior definition</h2>
<p>The following table shows some options that can be used to overwrite image predefined values:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p><kbd>--entrypoint</kbd></p>
</td>
<td>
<p>We can overwrite a defined entry point on container creation or execution. Don't rely on your security for this feature. Anyone can change your entry point for any other binary or script included in your image.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--env</kbd> or <kbd>-e</kbd> or <kbd>--env-file</kbd></p>
</td>
<td>
<p>We can overwrite variables defined within the base image or add new ones for new containers.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--expose</kbd></p>
</td>
<td>
<p>We can expose new ports for containers. These ports will be internally available. They are not published.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--health-cmd,</kbd></p>
<p><kbd>--health-interval,</kbd></p>
<p><kbd>--health-retries,</kbd></p>
<p><kbd>--health-start-period,</kbd></p>
<p><kbd>--health-timeout</kbd></p>
</td>
<td>
<p>All these options will overwrite health check base image values.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--no-healthcheck</kbd></p>
</td>
<td>
<p>This option disables the image-defined health check.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--label</kbd> or <kbd>-l</kbd> or <kbd>--label-file</kbd></p>
</td>
<td>
<p>This option allows labels to be added upon container creation or execution. These labels will help us filter or find information pertaining to processes. There are some labels that are automatically added by the Docker daemon or orchestrators to identify grouped objects.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--user</kbd> or <kbd>-u</kbd></p>
</td>
<td>
<p>This option overwrites the image-defined user.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--volume</kbd> or <kbd>-v</kbd></p>
</td>
<td>
<p>This option uses a defined volume or host path mounted inside the container. This option is very important because ephemeral volumes (also referenced as unnamed volumes) that are used to bypass copy-on-write filesystems will be created under <kbd>/var/lib/docker/volumes</kbd> (or the equivalent path on MS Windows hosts). They are identified by a random ID. Volumes will not follow the container's life cycle and must be removed manually unless we use the <kbd>-v</kbd> argument with the <kbd>docker container rm</kbd> action.</p>
</td>
</tr>
</tbody>
</table>
<p>Arguments passed on container creation will be added to the image-defined entry point as arguments. Therefore, image-defined CMD values will be overwritten with arguments passed upon container execution. Other arguments such as <kbd>--user</kbd>, <kbd>--env</kbd>, <kbd>--entrypoint</kbd>, or <kbd>--health-cmd</kbd>, <kbd>--health-timeout</kbd>, and so on will overwrite image-defined values, modifying the image's process behavior. Notice that the argument syntax is related to the image's defined keys.</p>
<p>Once a container has been created and executed, by default, the Terminal will be attached to its standard and error outputs. We will get all the main process errors and output. We can also launch containers interactively using the <kbd>--interactive</kbd> or <kbd>-i</kbd> options. We usually allocate a pseudo-Terminal using <kbd>--tty</kbd> or <kbd>-t</kbd> in order to have a fully functional Terminal attached to the main process.</p>
<h2 id="uuid-0a2080c6-115b-44d3-994c-a9cc9bc52f70">Executing containers</h2>
<p>A simple example will help us understand this behavior. We will launch a small web server using an <kbd>nginx:alpine</kbd> image. In this case, we are using the official <kbd>nginx</kbd> image from the <kbd>docker.io</kbd> registry tagged <kbd>alpine</kbd>, which is the smallest one based on Alpine Linux:</p>
<pre><strong>$ docker container run nginx:alpine</strong><br/><strong> Unable to find image 'nginx:alpine' locally</strong><br/><strong> alpine: Pulling from library/nginx</strong><br/><strong> 9d48c3bd43c5: Already exists</strong><br/><strong> 1ae95a11626f: Pull complete</strong><br/><strong> Digest: sha256:77f340700d08fd45026823f44fc0010a5bd2237c2d049178b473cd2ad977d071</strong><br/><strong> Status: Downloaded newer image for nginx:alpine</strong></pre>
<p>The output may vary if the image was already on your Docker host. All the object IDs will be different on your system as they are created automatically for you.</p>
<p>We can exit from running the container's standard output by executing either the <kbd>exit</kbd> command or the <em>Ctrl + C</em> keyboard combination.</p>
<p>We are stuck on this Terminal because we started a container with Nginx as the main process. What happened? Well, we are attached to the container's main process. If we issue a <em>Ctrl</em> + <em>C</em> sequence, since we are attached to that process, we will send an interruption to the container's main process and <kbd>nginx</kbd> will die. However, if we open another Terminal and list the running containers, it will be listed as expected:</p>
<pre><strong>$ docker container ls</strong><br/><strong> CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong> f84f6733537c nginx:alpine "nginx -g 'daemon of…" 11 seconds ago Up 10 seconds 80/tcp gallant_lederberg</strong></pre>
<p>Since we have not set a name for our container, we get a random one; in this case, <kbd>gallant_lederberg</kbd>.</p>
<p>All names will be created using random combinations of names and adjectives.</p>
<p>We can also inspect this running container to get its current IP address. To access its information, we can use either its ID or name. We will obtain all object information managed by the Docker daemon. We will now take a look at the <kbd>NetworkSettings</kbd> section from the <kbd>docker container inspect</kbd> command's output:</p>
<pre><strong>$ docker container inspect gallant_lederberg</strong><br/><strong>[</strong><br/><strong> {</strong><br/><strong> "Id": "f84f6733537c3733bda67387b394cabce3f35cf7ee50a46937cb1f59f2a7a680",</strong><br/><strong> "Created": "2019-10-20T09:34:46.179017074Z",</strong><br/><strong> "Path": "nginx",</strong><br/><strong>......</strong><br/><strong>......</strong><br/><strong>......</strong><br/><strong>"NetworkSettings": {</strong><br/><strong> "Bridge": "",</strong><br/><strong> "SandboxID": "7bb519745e9b7becc806f36bc16b141317448388f7c19a3bd86e1bc392bea469",</strong><br/><strong> "HairpinMode": false,</strong><br/><strong>......</strong><br/><strong>......</strong><br/><strong>"Gateway": "172.17.0.1",</strong><br/><strong> "IPAddress": "172.17.0.2",</strong><br/><strong>......</strong><br/><strong>......</strong></pre>
<p>This output shows that the container was created and that it is running on our system with an IP of <kbd>172.17.0.2</kbd>. We have not exposed its service to the world, although we did notice its port and protocol (<kbd>80</kbd>/<kbd>tcp</kbd>) on the <kbd>docker container ls</kbd> output earlier. The people who created the <kbd>nginx:alpine</kbd> image declared this port to access the container's main process. We are not going to continue reviewing the networking aspects of this container here as we have a complete chapter on networking, that is, <a href="e7804d8c-ed8c-4013-8449-b746ee654210.xhtml">Chapter 4</a>, <em>Container Persistency and Networking</em>. Just be aware that we have a running <kbd>nginx</kbd> process in our system that is not accessible for users:</p>
<pre><strong>$ ps -fea |grep -v grep |egrep -e nginx -e f84f67</strong><br/><strong> zero 1524 5881 0 11:34 pts/0 00:00:00 docker container run nginx:alpine</strong><br/><strong> root 1562 1693 0 11:34 ? 00:00:00 containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/f84f6733537c3733bda67387b394cabce3f35cf7ee50a46937cb1f59f2a7a680 -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc</strong><br/><strong> root 1594 1562 0 11:34 ? 00:00:00 nginx: master process nginx -g daemon off;</strong><br/><strong> systemd+ 1644 1594 0 11:34 ? 00:00:00 nginx: worker process</strong><br/><strong> systemd+ 1646 1594 0 11:34 ? 00:00:00 nginx: worker process</strong><br/><strong> systemd+ 1647 1594 0 11:34 ? 00:00:00 nginx: worker process</strong><br/><strong> systemd+ 1648 1594 0 11:34 ? 00:00:00 nginx: worker process</strong></pre>
<p>We have not changed any of the parameters from the original image, so we are using image creator options and declared values. For example, <kbd>nginx</kbd> is running as root inside the container. Container port <kbd>80</kbd> is not accessible from outside the bridged network.</p>
<p>We have already learned that there are some parameters that allow container interaction, so let's start a simple <kbd>busybox</kbd> to access the previous container's service:</p>
<pre><strong>$ docker run -ti busybox</strong><br/><strong> Unable to find image 'busybox:latest' locally</strong><br/><strong> latest: Pulling from library/busybox</strong><br/><strong> 7c9d20b9b6cd: Pull complete</strong><br/><strong> Digest: sha256:fe301db49df08c384001ed752dff6d52b4305a73a7f608f21528048e8a08b51e</strong><br/><strong> Status: Downloaded newer image for busybox:latest</strong><br/><strong># wget http://172.17.0.2 -q -O -</strong><br/><strong> &lt;!DOCTYPE html&gt;</strong><br/><strong> &lt;html&gt;</strong><br/><strong> &lt;head&gt;</strong><br/><strong> &lt;title&gt;Welcome to nginx!&lt;/title&gt;</strong><br/><strong> &lt;style&gt;</strong><br/><strong> body {</strong><br/><strong> width: 35em;</strong><br/><strong> margin: 0 auto;</strong><br/><strong> font-family: Tahoma, Verdana, Arial, sans-serif;</strong><br/><strong> }</strong><br/><strong> &lt;/style&gt;</strong><br/><strong> &lt;/head&gt;</strong><br/><strong> &lt;body&gt;</strong><br/><strong> &lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</strong><br/><strong> &lt;p&gt;If you see this page, the nginx web server is successfully installed and</strong><br/><strong> working. Further configuration is required.&lt;/p&gt;</strong><br/> <br/><strong> &lt;p&gt;For online documentation and support please refer to</strong><br/><strong> &lt;a href="http://nginx.org/"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</strong><br/><strong> Commercial support is available at</strong><br/><strong> &lt;a href="http://nginx.com/"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</strong><br/> <br/><strong> &lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</strong><br/><strong> &lt;/body&gt;</strong><br/><strong> &lt;/html&gt;</strong><br/><strong>/ # exit</strong></pre>
<p>In the running <kbd>nginx</kbd> container's output, we will read a few lines. These are <kbd>nginx</kbd> logfile lines because the main <kbd>nginx</kbd> process is redirected to standard output. In fact, both error and access logs are redirected to the container's output. If we go back to the first Terminal, this is what we get from running the <kbd>nginx</kbd> container's standard output and error:</p>
<pre><strong>$ docker container run nginx:alpine</strong><br/><strong> 172.17.0.3 - - [20/Oct/2019:10:26:56 +0000] "GET / HTTP/1.1" 200 612 "-" "Wget" "-"</strong><br/><strong> 172.17.0.3 - - [20/Oct/2019:10:27:09 +0000] "GET / HTTP/1.1" 200 612 "-" "Wget" "-"</strong></pre>
<p>Notice that the <kbd>busybox</kbd> container's IP (running from the second Terminal) is shown on <kbd>nginx</kbd> requests.</p>
<p>We have learned that running two containers together on the same network subnet will have unlimited access. This happens because we don't have any rules to disallow this interaction. Both containers use the default bridge network, which is why they run in the same network.</p>
<p>If we exit the <kbd>busybox</kbd> container using a simple <kbd>exit</kbd> command line on the container's shell, we will exit the main process (shell) and consequently, the container will die.</p>
<p>We can list non-running containers by using <kbd>--all</kbd> or <kbd>-a</kbd> because, by default, <kbd>docker container ls</kbd> will only show running containers:</p>
<pre><strong>$ docker container ls --all</strong><br/><strong> CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong> 4848ed569f61 busybox "sh" 34 minutes ago Exited (0) 31 minutes ago interesting_yalow</strong><br/><strong> f84f6733537c nginx:alpine "nginx -g 'daemon of…" About an hour ago Up About an hour 80/tcp gallant_lederberg</strong></pre>
<p>Here, we can see that we can review running and stopped containers. We will stop the <kbd>gallant_lederberg</kbd> container (ID: <kbd>f84f6733537c</kbd>). Remember that executing <kbd>docker container stop</kbd> will first try to issue a graceful stop before killing the main process:</p>
<pre><strong>$ docker stop gallant_lederberg</strong><br/><strong> gallant_lederberg</strong></pre>
<p>The container is stopped immediately. Now, let's run another container that is not so easy to stop. We can run a <kbd>busybox</kbd> image executing an infinite ping to <kbd>www.google.com</kbd>, for example, and review what happens when we try to stop it:</p>
<pre class="mce-root"><strong>$ docker container run --name ping busybox ping www.google.com</strong><br/><strong> PING www.google.com (172.217.16.228): 56 data bytes</strong><br/><strong> 64 bytes from 172.217.16.228: seq=0 ttl=56 time=694.384 ms</strong><br/><strong> 64 bytes from 172.217.16.228: seq=1 ttl=56 time=291.257 ms</strong><br/><strong> 64 bytes from 172.217.16.228: seq=2 ttl=56 time=365.674 ms</strong><br/><strong> 64 bytes from 172.217.16.228: seq=3 ttl=56 time=433.928 ms</strong><br/><strong> 64 bytes from 172.217.16.228: seq=4 ttl=56 time=718.424 ms</strong></pre>
<p class="mce-root">We have changed the <kbd>busybox</kbd> image-defined CMD with the passed argument, <kbd>ping www.google.com</kbd>. As a result, we will get an infinite ping output. To stop this container and review how much time it takes to die, we can send a <kbd>stop</kbd> command from another Terminal:</p>
<pre><strong>$ time docker container stop ping</strong><br/><strong> ping</strong><br/><strong> real 0m10,721s</strong><br/><strong> user 0m0,019s</strong><br/><strong> sys 0m0,032s</strong></pre>
<p>We added <kbd>time</kbd> before the Docker command to review how many seconds the container took to stop. As we expected, the ping had to be killed and, as a result, the <kbd>stop</kbd> command took more than the default 10 seconds.</p>
<p>We launched a named container using the <kbd>--name</kbd> argument. To ensure the uniqueness of containers, once a container is created with a name, it is not possible to create another one with the same name. When we get into the orchestration chapters of this book, we will learn how orchestrators manage the naming of containers. To deploy another ping container, in this case, we will need to remove the first ping container using <kbd>docker container rm ping</kbd>.</p>
<p>We have seen how to launch a container using the <kbd>docker container run</kbd> command and how to stop it. Let's now review container creation to understand the container's life cycle:</p>
<pre class="mce-root"><strong>$ docker container create --name webserver nginx:alpine</strong><br/><strong> 6121184dd136781ceb87a210049b25334ce140968dd110ea7d6945ced3ca6668</strong></pre>
<p>We obtained the container's identification, but it is not running. We can verify this situation by executing <kbd>docker container ls --filter name=webserver</kbd>.</p>
<p>If we filter using all containers, including those that are not running, we can see that the container was created:</p>
<pre><strong>$ docker container ls --all --filter name=webserver</strong><br/><strong> CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</strong><br/><strong> 6121184dd136        nginx:alpine        "nginx -g 'daemon of…"   2 minutes ago       Created                                 webserver</strong></pre>
<p>Now that the container has been created, we can start it using <kbd>docker container start</kbd>:</p>
<pre><strong>$ docker container start webserver</strong><br/><strong> webserver</strong></pre>
<p>The container was started, but we are not attached to its main process's input/output. Container creation is different from running a container. As we will learn, Docker Swarm services and Kubernetes pods will create container configurations and they will also start a defined number of replicas. This is different from starting a single container.</p>
<p>The <kbd>STATUS</kbd> column shows that the container is now running:</p>
<pre><strong>$ docker container ls --filter name=webserver</strong><br/><strong> CONTAINER         ID       IMAGE    COMMAND        CREATED     STATUS PORTS NAMES</strong><br/><strong> 6121184dd136 nginx:alpine "nginx -g 'daemon of…" 10 minutes ago  Up     3 minutes 80/tcp webserver</strong></pre>
<p>We can add attachments to the container's input/output by adding the <kbd>--attach</kbd> argument to the <kbd>docker container run</kbd> action. This way, we will run the container interactively. Remember that your interaction with the container's main process will depend on the parameters that are passed when it was created. We can also use <kbd>--interactive</kbd> as the <kbd>start</kbd> parameter.</p>
<h2 id="uuid-22c95a14-98ad-41fe-89ce-889a4762d594">Container security options</h2>
<p>There are a number of options for container creation and execution related to its security. Let's review the most important ones with some examples:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p><kbd>--cap-add or --cap-drop</kbd></p>
</td>
<td style="width: 76.4765%">
<p>Remember that not all system calls are available inside containers. We can add or drop default ones using this option. For example, if a container needs some special networking features for creating interfaces or allowing ports under 1024, we will add <kbd>NET_ADMIN</kbd> capability.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--disable-content-trust</kbd></p>
</td>
<td style="width: 76.4765%">
<p>We use this option to disable any content trust verification (check image origin or ownership, for example). This is not recommended in production environments.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--isolation</kbd></p>
</td>
<td style="width: 76.4765%">
<p>This option is only used on MS Windows containers. Allowed values are <kbd>process</kbd> or <kbd>hyper-v</kbd>. We will choose which isolation will be used in our container. Remember that they have different features, as we learned in <a href="c5ecd7bc-b7ed-4303-89a8-e487c6a220ed.xhtml">Chapter 1</a>, <em>Modern Infrastructures and Applications with Docker</em>.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--privileged</kbd></p>
</td>
<td style="width: 76.4765%">
<p>Privileged containers will run with all capabilities and without any resource limitations. Be careful with these kinds of containers and always try to establish what capabilities are required by your application instead of using the privileged mode.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--read-only</kbd></p>
</td>
<td style="width: 76.4765%">
<p>We can run containers using a read-only root filesystem. This is a very good practice in general but we must ensure that all the required container storage will use volumes.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--security-opt</kbd></p>
</td>
<td style="width: 76.4765%">
<p>We will be able to change container options when changing default security behavior; for example, using a different seccomp profile or specifying that the container will run unconfined. Custom SELinux policies will also use this parameter to inform SELinux of non-default values.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>All the security options described here must be used with care. It is very important to understand what capabilities or requirements the applications have instead of using default or insecure configurations.</p>
<p>It is very important to understand that executing containers using privileged mode will bypass all resource restrictions. Be sure that the <kbd>--privileged</kbd> option is only used in specific situations where you really understand the implications of running a container with all capabilities and without any resource limits. Users allowed to execute privileged containers can run processes without CPU or memory limits and can modify important system files.</p>
<p>Take your time to review the application requirements before executing the privileged containers. Only use them under very clear circumstances and watch out for any suspicious behavior on those containers.</p>
<p>Executing containers in read-only mode is very useful. We can ensure that the applications will not change during their lifetime. Of course, using read-only mode depends on your application, but it is good to take some time to analyze the process and try to make it work with a read-only filesystem. We will separate writable directories into ephemeral volumes to store process data. This is a very good practice for improving security easily.</p>
<h2 id="uuid-6426aaac-0f84-4e0c-bbf5-f77a2f84e48c">Using host namespaces</h2>
<p>The following options are not directly related to security, but they are very important. These are related to container isolation and must be managed with care because any misuse may cause significant security problems:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td style="width: 14.8831%">
<p class="mce-root"><kbd>--ipc</kbd></p>
<p><kbd>--pid</kbd></p>
<p><kbd>--uts</kbd></p>
</td>
<td style="width: 84.524%">
<p>We can share host namespaces if needed. For example, if we are executing a monitoring application inside a container and we need to be able to watch for host processes, we will include a host <kbd>pid</kbd> namespace using <kbd>--pid host</kbd>. Take care of these options as this container will be able to manage host processes if we also use extra capabilities or privileged mode.</p>
</td>
</tr>
<tr>
<td style="width: 14.8831%">
<p><kbd>--network</kbd></p>
</td>
<td style="width: 84.524%">
<p>We have mentioned this option before, but not in this context. We can use a host network. In this case, we will use the host's network inside a container. Therefore, all host interfaces will be available inside the container. Other containers' interfaces will also be included.</p>
</td>
</tr>
<tr>
<td style="width: 14.8831%"><kbd>--userns</kbd></td>
<td style="width: 84.524%">
<p>In the first chapter, we talked about user namespaces inside containers. We learned about process isolation when we introduced the main container's concepts. This option will allow us to implement an isolated user namespace inside a container. We must first prepare user mappings and then we will set which one to use on container creation or execution.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>We can easily verify some of the options mentioned in our Docker host. For example, we can run a container using the host network mode and retrieve the container's interface:</p>
<pre><strong>$ docker container run busybox ip add</strong><br/><strong> 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000</strong><br/><strong> link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</strong><br/><strong> inet 127.0.0.1/8 scope host lo</strong><br/><strong> valid_lft forever preferred_lft forever</strong><br/><strong> 37: eth0@if38: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue</strong><br/><strong> link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff</strong><br/><strong> inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0</strong><br/><strong> valid_lft forever preferred_lft forever</strong></pre>
<p>Now, we can launch another container using the same image but with a host network:</p>
<pre><strong>$ docker container run --network=host busybox ip add</strong><br/><strong> 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000</strong><br/><strong> link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</strong><br/><strong> inet 127.0.0.1/8 scope host lo</strong><br/><strong> valid_lft forever preferred_lft forever</strong><br/><strong> inet6 ::1/128 scope host</strong><br/><strong> valid_lft forever preferred_lft forever</strong><br/><strong> 2: enp0s25: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc fq_codel qlen 1000</strong><br/><strong> link/ether 68:f7:28:c1:bc:13 brd ff:ff:ff:ff:ff:ff</strong><br/><strong> 3: wlp3s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq qlen 1000</strong><br/><strong> link/ether 34:02:86:e3:f6:25 brd ff:ff:ff:ff:ff:ff</strong><br/><strong> inet 192.168.200.161/24 brd 192.168.200.255 scope global dynamic wlp3s0</strong><br/><strong> valid_lft 49sec preferred_lft 49sec</strong><br/><strong> inet6 fe80::ee87:e44f:9189:f720/64 scope link</strong><br/><strong> valid_lft forever preferred_lft forever</strong><br/><strong> 6: virbr1: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue qlen 1000</strong><br/><strong> link/ether 52:54:00:f7:57:34 brd ff:ff:ff:ff:ff:ff</strong><br/><strong> inet 192.168.39.1/24 brd 192.168.39.255 scope global virbr1</strong><br/><strong> valid_lft forever preferred_lft forever</strong><br/><strong> ......</strong></pre>
<p>All host interfaces are available inside this small busybox container. This is very useful for monitoring host resources. This can help us solve host network problems without installing any software, especially in a production environment.</p>
<p>In the next section, we will learn how to interact with running containers, execute new processes inside them, and copy content to or from them.</p>
<h1 id="uuid-825d3eff-ed16-46c3-886a-58f95005e563">Interacting with containers</h1>
<p>We can interact with running or stopped containers. We need to interact with containers to run some processes within them, review some of their files, or retrieve the main process output. These are the main actions we will use to interact with containers:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p><kbd>attach</kbd></p>
</td>
<td style="width: 89%">
<p>Using <kbd>attach</kbd>, we will be able to connect to the main process's <kbd>STDIN/STDOUT/STDERR</kbd>. In other terms, we will be attached to this process to interact with it. Be careful because sending a signal with your keyboard may interrupt the process and container's life (we can omit this behavior using <kbd>--sig-proxy false</kbd>). We can only attach to running containers.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>cp</kbd></p>
</td>
<td style="width: 89%">
<p>This action will allow us to send /receive content to/from the container's filesystem. It acts as a normal copy but we can maintain file ownership using <kbd>--archive</kbd>. We will just use the source path and destination and we will use the <kbd>&lt;container&gt;:&lt;/path_to_file&gt;</kbd> notation to reference files inside containers. Containers can be stopped when we copy files to/from the Docker host.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>exec</kbd></p>
</td>
<td style="width: 89%">
<p>Using <kbd>exec</kbd>, we will be able to execute a command inside the container's isolation. This new command inherits all main process namespaces. As a result, the new command seems to be running inside the container because they share namespaces.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>logs</kbd></p>
</td>
<td style="width: 89%">
<p class="mce-root">We can review all the container's output by accessing the container's <kbd>STDERR</kbd> and <kbd>STDOUT</kbd>. Logging can be improved using logging drivers to extend its functionality; for example, sending these logs to an external host or logging backend. Logging is fundamental when we execute background containers or services. The only way to know what is happening inside a container is by supervising its log.</p>
</td>
</tr>
</tbody>
</table>
<p>Once attached to a container, we can detach using the <em>Ctrl</em> + <em>P</em> + <em>Q</em> keyboard sequence, but we can change this keyboard combination using the <kbd>--detach-keys</kbd> option while attaching, and when creating or starting a container.</p>
<p>We will now take a quick look at our running containers (if you do not have any, run one container, as described in the previous section):</p>
<pre><strong>$ docker container ls</strong><br/><strong> CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong> 4b2806790a4f nginx:alpine "nginx -g 'daemon of…" 2 hours ago Up 40 minutes 80/tcp webserver</strong></pre>
<p>Now, we execute <kbd>ps -ef</kbd> inside the container using <kbd>docker exec</kbd>:</p>
<pre><strong>$ docker container exec webserver ps -ef</strong><br/><strong> PID USER TIME COMMAND</strong><br/><strong> 1 root 0:00 nginx: master process nginx -g daemon off;</strong><br/><strong> 6 nginx 0:00 nginx: worker process</strong><br/><strong> 7 nginx 0:00 nginx: worker process</strong><br/><strong> 8 nginx 0:00 nginx: worker process</strong><br/><strong> 9 nginx 0:00 nginx: worker process</strong><br/><strong> 10 root 0:00 ps -ef</strong></pre>
<p>We executed the command inside the container's isolation using the main process declared user (<kbd>root</kbd>, in this example).</p>
<p>If we want to execute an interactive command – a shell, for example – we can do so by specifying <kbd>--interactive</kbd> (or <kbd>-i</kbd>) and allocating a pseudo-tty using <kbd>--tty</kbd> (or <kbd>-t</kbd>). We can set environment variables for this new process with <kbd>--env</kbd> or change the execution user using <kbd>--user</kbd>. If we need to execute the new command with special privileges inside a container, we can also use <kbd>--privileged</kbd>. This can be very useful in debugging on test environments:</p>
<pre><strong>$ docker exec -ti --user nginx --env ENVIRONMENT=test webserver /bin/sh</strong><br/><strong> / $ id</strong><br/><strong> uid=101(nginx) gid=101(nginx) groups=101(nginx)</strong><br/><strong> / $ env|grep ENVIRON</strong><br/><strong> ENVIRONMENT=test</strong></pre>
<p>We can copy a file located in the host <kbd>/tmp</kbd> directory, for example, inside our container using <kbd>docker container cp</kbd>:</p>
<pre><strong>$ docker container cp /tmp/TEST webserver:/tmp/TEST</strong></pre>
<p>As we mentioned previously, logging is an important aspect of managing containers. We can use <kbd>docker container logs</kbd> on running or stopped containers. These are very useful options to improve the manner in which logs are shown:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p><kbd>--follow</kbd> or <kbd>-f</kbd></p>
</td>
<td style="width: 82.9562%">
<p>With this option, we can obtain the online output of a running container. The output will be updated with every new entry.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--tail</kbd></p>
</td>
<td style="width: 82.9562%">
<p>With this option, we can specify how many previous lines we want to show. By default, all the lines will be shown.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--since</kbd> or <kbd>--until</kbd></p>
</td>
<td style="width: 82.9562%">
<p class="mce-root">Both of these options are very useful for showing logging only from or before a timestamp or relative period of time (30 minutes or 30 m, for example).</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Now, let's review some of the <kbd>docker container logs</kbd> arguments in the previously executed web server container. In the following example, we will retrieve all the lines from the <kbd>webserver</kbd> container's output:</p>
<pre><strong>$ docker container logs --tail all webserver</strong><br/><strong> 172.17.0.3 - - [20/Oct/2019:18:39:52 +0000] "GET / HTTP/1.1" 200 612 "-" "Wget" "-"</strong><br/><strong> 172.17.0.3 - - [20/Oct/2019:18:39:55 +0000] "GET / HTTP/1.1" 200 612 "-" "Wget" "-"</strong><br/><strong> 172.17.0.3 - - [20/Oct/2019:18:39:57 +0000] "GET / HTTP/1.1" 200 612 "-" "Wget" "-"</strong></pre>
<p>In the next section, we will review how to avoid host problems by limiting container access to host resources.</p>
<h1 id="uuid-4409734a-f180-4c97-bd26-f8a275d40144">Limiting host resources</h1>
<p>We have seen some options for limiting the container's resource consumption. We will be able to limit access to CPU, memory, and block devices. There are two types of limits when we focus on memory resources: soft and hard limits.</p>
<p>Soft limits will represent a reservation of resources. This means that a container could consume more memory than declared, but this value will be reserved.</p>
<p>On the other hand, a hard limit will ensure that no more than the declared value will be consumed. In fact, the container will die if this limit is surpassed. An <strong>out-of-memory</strong> (also known as <strong>OOM</strong>) killer will kill the main process to prevent host problems.</p>
<p>Remember that, by default, if you do not specify any limits, containers will be able to consume all your host resources.</p>
<p>There are many options available to ensure limited access to resources. We can modify default cgroups settings automatically with these parameters:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p class="mce-root"><kbd>--cpu-period</kbd></p>
<p>and</p>
<p><kbd>--cpu-quota</kbd></p>
</td>
<td style="width: 76.5851%">
<p>CFS is the Linux kernel CPU scheduler and, with these parameters, we modify the scheduler period. Both must be configured in microseconds and will modify the CPU limits.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--cpu-shares</kbd></p>
</td>
<td style="width: 76.5851%">
<p>This parameter manages the weights for the container's main process. By default, it will start with a value of 1024 and we can set the proportion of CPU cycles by increasing or decreasing this value. This is a soft limit, which means that the Docker daemon will not prevent container scheduling on Docker Swarm.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--cpus</kbd></p>
or <kbd>-c</kbd></td>
<td style="width: 76.5851%">
<p>This option helps us set the amount of available CPU resources that will be provided to a container process. It is related to the number of CPUs available in the host. For example, in a host with three CPUs, using a value of <kbd>--cpus=1.5</kbd> will guarantee half of the CPU resources for this container.</p>
</td>
</tr>
<tr>
<td><kbd>--cpuset-cpus</kbd></td>
<td style="width: 76.5851%">
<p>This CPU setting is simpler than CPU shares or setting how many CPUs to use. We will just specify a comma-separated list of host CPUs where the container can run (we will start at 0 when writing a CPU range).</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--memory</kbd></p>
or <kbd>-m</kbd></td>
<td style="width: 76.5851%">
<p class="mce-root">This will set the maximum amount of memory available for a container's process. This is a threshold and the Docker daemon will not allow the container to surpass this limit. Whenever this limit is surpassed, the kernel will kill the container's main process. We will obtain an out-of-memory error. This procedure is known as <kbd>oom-killer</kbd>. We can disable <kbd>oom-killer</kbd> using <kbd>--oom-kill-disable</kbd>. This can be dangerous and you must be careful with this option as containers could take all the host memory resources.</p>
</td>
</tr>
<tr>
<td><kbd>--memory-reservation</kbd></td>
<td style="width: 76.5851%">
<p>With this parameter, we will configure a reservation of memory for our processes. It should be set to a lower value than the previously mentioned <kbd>--memory</kbd> threshold value.</p>
</td>
</tr>
<tr>
<td>
<p class="mce-root"><kbd>--blkio-weight</kbd></p>
<p>and</p>
<p><kbd>--blkio-weight-device</kbd></p>
</td>
<td style="width: 76.5851%">
<p>The first argument will manage how much total block direct I/O bandwidth will be available for a container, while the second one will manage how much bandwidth will be available for a specific block device. By default, all containers run with the same bandwidth. This value is 500, and we can increase or decrease this value so that it's between 10 and 1,000. </p>
</td>
</tr>
</tbody>
</table>
<p>Many of the features we will use to isolate access to resources require that the host kernel supports Linux capabilities. We can review all disabled capabilities using <kbd>docker system info</kbd>, looking for any <kbd>WARNING</kbd> messages.</p>
<p>Whenever we need to update the container limits, we can use the <kbd>docker container update</kbd> action, which allows us to change memory, CPU, and block device usage limits on containers.</p>
<p>There are a few actions that will help us in reviewing the container's resource usage.</p>
<p>We will use <kbd>docker container stats</kbd> to retrieve container usage metrics. By default, only CPU usage percentage, memory usage and its limit, network and block I/O, and the number of processes inside containers will be shown. We can format its output using the <kbd>--format</kbd> parameter, with common Go language format patterns. We will usually use a table format:</p>
<pre><strong>$ docker stats --all --format "table [{{.Container}}] {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}"</strong><br/><strong> [CONTAINER] NAME CPU % MEM USAGE / LIMIT</strong><br/><strong> [8ab15ccdc42f] stress 0.00% 0B / 0B</strong><br/><strong> [ed19e4376cdc] intelligent_easley 0.00% 0B / 0B</strong><br/><strong> [0ca76903840f] vigilant_mendeleev 0.00% 0B / 0B</strong><br/><strong> [afa67a5a2162] inspiring_mclaren 0.00% 0B / 0B</strong><br/><strong> [49229db83166] mystifying_maxwell 0.00% 0B / 0B</strong><br/><strong> [4cef73c07691] naughty_diffie 0.00% 0B / 0B</strong><br/><strong> [5dcc40de271e] adoring_wright 0.00% 0B / 0B</strong><br/><strong> [07aeb6f9c6df] focused_fermi 0.00% 0B / 0B</strong><br/><strong> [bbe4cb0d9cac] magical_chaplygin 0.00% 0B / 0B</strong><br/><strong> [4b2806790a4f] webserver 0.00% 4.676MiB / 11.6GiB</strong></pre>
<p>We can specify a container's name or ID to only show its statistics. It is important to know that <kbd>docker stats</kbd> is a stream-like command. This means that it will be continuously refreshing content with new data unless we use the <kbd>--no-stream</kbd> argument to obtain static output on a single page.</p>
<p>Depending on the amount of data shown, sometimes, values are truncated. This can happen in many other objects' actions. To avoid the truncation of important data, we can use <kbd>--no-trunc</kbd> any time we need to retrieve all column data.</p>
<p>On the other hand, <kbd>docker container top</kbd> will show us information in a top-like format regarding all the container's internal processes. Using our web server from the previous examples, we can execute <kbd>docker container top webserver</kbd> to obtain the <kbd>nginx</kbd> main process and its child's states:</p>
<pre><strong>$ docker container top webserver</strong><br/><strong> UID PID PPID C STIME TTY TIME CMD</strong><br/><strong> root 17878 17848 0 19:06 ? 00:00:00 nginx: master process nginx -g daemon off;</strong><br/><strong> systemd+ 17924 17878 0 19:06 ? 00:00:00 nginx: worker process</strong><br/><strong> systemd+ 17925 17878 0 19:06 ? 00:00:00 nginx: worker process</strong><br/><strong> systemd+ 17927 17878 0 19:06 ? 00:00:00 nginx: worker process</strong><br/><strong> systemd+ 17928 17878 0 19:06 ? 00:00:00 nginx: worker process</strong></pre>
<p>We can add swap access using <kbd>--memory-swap</kbd> and <kbd>--memory-swappiness</kbd> but this is not recommended. Swapping could decrease application performance and it really breaks the logic of distributed microservices. Orchestration will allow us to run different components on different nodes, depending on their requirements.</p>
<p>In the next section, we will review actions related to images. With these, we will be able to create an image from a container, as we learned in <em><a href="3952ec16-ca49-4bc2-b7e6-d6f17fec3fab.xhtml">Chapter 2</a>, Building Docker Images</em>.</p>
<h1 id="uuid-5872ff18-8ff7-499d-9b11-2015b4e9e9c2">Converting containers into images</h1>
<p>We have learned about three different methods for building images, and all of them use containers in some shape or form. Let's review the container actions that can be used to create images:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p><kbd>commit</kbd></p>
</td>
<td style="width: 88%">
<p><kbd>docker commit</kbd> will allow us to create an image from a container. We will add a container's layer as a new image layer. As a result, we obtain a new image. We will set a new image name (although we learned that we can change image names whenever we need to) with its tag. The container will be paused during the commit to avoid file changes during its execution.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>export</kbd></p>
</td>
<td style="width: 88%">
<p>This action will create a <kbd>.tar</kbd> file containing the container's filesystem (including data from all of its layers). By default, this command will stream binary content to <kbd>STDOUT</kbd>, but we can use <kbd>--output</kbd> or <kbd>-o</kbd> to define a file for this content.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>When we need to know about the changes we made to the original image layers, we can use <kbd>docker container diff</kbd>. This will show a list of all the files that have been modified or created on the container's layer.</p>
<p>Using the container web server from the previous examples, we can observe all the changes that were made during its execution:</p>
<pre><strong>$ docker container diff webserver</strong><br/><strong> C /var</strong><br/><strong> C /var/cache</strong><br/><strong> C /var/cache/nginx</strong><br/><strong> A /var/cache/nginx/client_temp</strong><br/><strong> A /var/cache/nginx/fastcgi_temp</strong><br/><strong> A /var/cache/nginx/proxy_temp</strong><br/><strong> A /var/cache/nginx/scgi_temp</strong><br/><strong> A /var/cache/nginx/uwsgi_temp</strong><br/><strong> C /root</strong><br/><strong> A /root/.ash_history</strong><br/><strong> C /run</strong><br/><strong> A /run/nginx.pid</strong><br/><strong> C /tmp</strong><br/><strong> A /tmp/TEST</strong> </pre>
<p>This list shows added files, marked as <kbd>A</kbd>, as well as changed files and directories, marked with <kbd>C</kbd>. Notice that every time we add a file to a directory, the directory is also changed.</p>
<p>We will usually deploy tens, hundreds, or even thousands of containers within Docker hosts. It is important to be able to retrieve information about them in order to manage their properties and states. In the next section, we will review some of the options available to format and filter information in container environments.</p>
<h1 id="uuid-036d04ef-9744-43a1-bc20-d9d542812c63">Formatting and filtering information</h1>
<p>Formatting and filtering the output of any command is always useful. In Docker commands with long lists or outputs, it is really necessary. Let's begin with formatting some command output.</p>
<p>Almost all actions that represent or show any kind of information can be formatted. Docker uses Go templates to modify the output format. It is very useful to be able to format output for our specific needs. We will use the table format here. Each column will represent a specified key.</p>
<p>We will consider a brief example output listing all the deployed containers in a host using <kbd>docker container ls</kbd> with the table format:</p>
<pre class="mce-root"><strong>$ docker container ls --all --format "table {{.Names}}: {{.Image}} {{.Command}}" --no-trunc </strong><br/><strong>NAMES: IMAGE COMMAND</strong><br/><strong>loving_diffie: alpine "/bin/sh"</strong><br/><strong>recursing_fermi: alpine "/bin/sh"</strong><br/><strong>silly_payne: centos "/bin/bash"</strong><br/><strong>wonderful_visvesvaraya: centos "/bin/bash"</strong><br/><strong>optimistic_lamarr: centos "/bin/bash"</strong><br/><strong>focused_shtern: centos "/bin/bash"</strong><br/><strong>stress: frjaraur/stress-ng:alpine "stress-ng stress-ng --vm 2 --vm-bytes 1G --timeout 60s"</strong><br/><strong>vibrant_faraday: baseimage:development "curl"</strong><br/><strong>lucid_wright: baseimage:production "curl"</strong><br/><strong>elastic_cori: baseimage:production "env"</strong></pre>
<p>We have used <kbd>--no-trunc</kbd> to disable the truncation of printed values. Without using this option, all long strings will be truncated and will only show a few characters. Usually, they will be enough to identify a value, but sometimes, we need the entire string; for example, to review the container's main executed command.</p>
<p>It is very useful to know what keys can be queried for formatting. To obtain all allowed keys for formatting, we will use <kbd>--format='{{json .}}'</kbd>. This will show all the columns or keys for a specified action (for example, try <kbd>docker container ls --all --format='{{json .}}'</kbd>). The output will be shown in unformatted JSON.</p>
<p>The unformatted JSON output is not easy to read. We can use <strong>jq</strong> (<a href="https://stedolan.github.io/jq/">https://stedolan.github.io/jq/</a>), which is a command-line JSON processor for better reading. Using jq, we will obtain more prettily formatted JSON.</p>
<p>There are a number of customized options for formatting:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr style="height: 14.5332px">
<td>
<p><kbd>json</kbd></p>
</td>
<td style="height: 14.5332px;width: 79.7924%">
<p>As we have seen, this option will format the output as a single-line JSON string. For example, we can use <kbd>--format='{{json .Config}}'</kbd> with <kbd>docker inspect</kbd> output for a container to obtain all its configuration keys and values.</p>
</td>
</tr>
<tr style="height: 14.5332px">
<td>
<p><kbd>table</kbd></p>
</td>
<td style="height: 14.5332px;width: 79.7924%">
<p>The table format option is not available in all outputs, but it will work pretty well on lists.</p>
</td>
</tr>
<tr style="height: 10px">
<td>
<p class="mce-root"/>
<p><kbd>join/split</kbd></p>
</td>
<td style="height: 10px;width: 79.7924%">
<p>With these options, we will be able to join or split key outputs; for example, <kbd>'{{json .Mounts}}'</kbd> or <kbd>'{{split .Image ":"}}'</kbd>.</p>
</td>
</tr>
<tr style="height: 10px">
<td>
<p class="mce-root"/>
<p><kbd>lower/upper/title</kbd></p>
</td>
<td style="height: 10px;width: 79.7924%">
<p>These options allow us to change strings to lowercase, uppercase, or just capitalize the first character; for example, <kbd>'{{title .Name}}'</kbd> will show all names with a capitalized first character.</p>
</td>
</tr>
<tr style="height: 10px">
<td>
<p><kbd>range</kbd></p>
</td>
<td style="height: 10px;width: 79.7924%">
<p>This option will help us format list/array values. You have to use <kbd>'{{range &lt;JSON keys&gt; }}{{end}}'</kbd> to correctly manage the listed values.</p>
</td>
</tr>
<tr style="height: 10px">
<td>
<p class="mce-root"/>
<p><kbd>println</kbd></p>
</td>
<td style="height: 10px;width: 79.7924%">
<p>This option will print each queried value in a new line. It is very interesting for formatting range values.</p>
</td>
</tr>
</tbody>
</table>
<p>The <kbd>--pretty</kbd> option is available for inspecting some objects. It is very useful but, as we mentioned previously, it is not available for all objects. For example, you can use it to inspect services, which we will learn about in <a href="78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml">Chapter 8</a>, <em>Orchestration Using Docker Swarm</em>.</p>
<p>Formatting will help us to obtain only required pieces of information, but it will not be easy when we have to manage a lot of items. We will filter the information using the <kbd>--filter</kbd> option to retrieve only specific objects matching some keys and values. Not all keys will be available for filtering. We will use keys with their values for filters and we can use as many filter options as required. If we add more than one filter with the same key, they will be used as <kbd>OR</kbd>. But if we use different keys, this will be an <kbd>AND</kbd> filter. We will use "equal" (using <kbd>=</kbd>) or "different" (using <kbd>&lt;&gt;</kbd> ) to compare key values.</p>
<p>Container objects can be filtered by means of the following:</p>
<ul>
<li><strong>ID or name</strong>: With these options, we can find containers by their IDs or names.</li>
<li><strong>Label</strong>: This case is special as we can express the query using a key to match all the containers with that label or key-value format, in order to find a specific value for that key.</li>
<li><strong>Exited</strong>: We will use this option with an exited integer when using <kbd>--all</kbd> to filter containers stopped with errors, for example.</li>
<li><strong>Status</strong>: We use this option to filter by container state (<kbd>created</kbd>, <kbd>restarting</kbd>, <kbd>running</kbd>, <kbd>removing</kbd>, <kbd>paused</kbd>, <kbd>exited</kbd> or <kbd>dead</kbd>).</li>
<li><strong>Ancestor</strong>: This is very important because it will allow us to filter by image name and tags.</li>
<li><strong>Before/since</strong>: This filter allows us to specify dates, for example, to find a container running for a long time or filter by its creation date.</li>
<li><strong>Volume/network</strong>: This option allows us to filter which containers are using a volume or network. It is useful for removing old resources.</li>
<li><strong>Publish or expose</strong>: These options filter which containers are publishing or exposing specified ports. We can use a range of ports and protocols (<kbd>&lt;startport-endport&gt;</kbd>/<kbd>[&lt;proto&gt;]</kbd>).</li>
<li><strong>Health</strong>: This filter allows us to search containers by their health check status (healthy, unhealthy, starting, or none).</li>
<li><strong>Is-task</strong>: This option is very interesting because it allows us to filter containers created by tasks when using Docker Swarm orchestration.</li>
</ul>
<p>Notice that <kbd>--format</kbd> is used for filtering on the <kbd>docker &lt;object&gt; inspect</kbd> command. We can only query specific object keys and subkeys. For example, using <kbd>--format='{{json .Config}}'</kbd> will just show keys and values under the <kbd>Config</kbd> key<em><strong>.</strong></em></p>
<p>In the next section, we will review how to use host attached devices as if they were inside containers.</p>
<h1 id="uuid-2d085eda-bc2d-43e8-ab5a-c6a161d76677">Managing devices</h1>
<p>We can provide access to host devices inside containers. We use the <kbd>--device</kbd> argument with <kbd>docker container create</kbd> or <kbd>docker container run</kbd> for this. We will be able to use hardware devices connected directly to a host, such as serial controllers, block storage, or audio devices.</p>
<p>By default, devices will have read and write permissions. To be able to manipulate special devices, the <kbd>mknod</kbd> permission is also added by default. We can override these default settings using <kbd>r</kbd>, <kbd>w</kbd>, and <kbd>m</kbd> in the command line as modifiers of the <kbd>--device</kbd> option.</p>
<p>As an example, we can mount our <kbd>lvm</kbd> mapped block device to a defined directory; notice that the mounting capability must be added. In this example, we added <kbd>SYS_ADMIN</kbd> capabilities:</p>
<pre><strong>$ docker run -ti --cap-add SYS_ADMIN --device /dev/mapper/centos-root:/dev/sdx centos</strong><br/><strong> [root@5ccb0ef8ce84 /]# mkdir /data</strong><br/><strong> [root@5ccb0ef8ce84 /]# mount /dev/sdx /data</strong><br/><strong> [root@5ccb0ef8ce84 /]# cd /data</strong><br/><strong> [root@5ccb0ef8ce84 data]# ls</strong><br/><strong> bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  vagrant  var</strong></pre>
<p>In the following example, we are using our host sound device inside a container. Adding these devices to containers will allow us to run some applications with sound:</p>
<pre><strong>$ docker container run -ti --device /dev/snd alpine</strong><br/><strong> / # apk add --update -q alsa-utils</strong><br/><strong> / # speaker-test -t wav -c 6 -l1</strong><br/> <br/><strong> speaker-test 1.1.9</strong><br/> <br/><strong> Playback device is default</strong><br/><strong> Stream parameters are 48000Hz, S16_LE, 6 channels</strong><br/><strong> WAV file(s)</strong><br/><strong> Rate set to 48000Hz (requested 48000Hz)</strong><br/><strong> Buffer size range from 2048 to 16384</strong><br/><strong> Period size range from 1024 to 1024</strong><br/><strong> Using max buffer size 16384</strong><br/><strong> Periods = 4</strong><br/><strong> was set period_size = 1024</strong><br/><strong> was set buffer_size = 16384</strong><br/><strong>  0 - Front Left</strong><br/><strong>  1 - Front Right</strong><br/><strong>  2 - Unused</strong><br/><strong>  3 - Unused</strong><br/><strong>  4 - Unused</strong><br/><strong>  5 - Unused</strong><br/><strong> Time per period = 8.298695</strong></pre>
<p>Here, we have learned that not just files or directories can be accessed inside containers. We can use special devices as if they were directly attached to containers.</p>
<h1 id="uuid-7664dfa0-890a-4cac-82a5-5c8f4ff76a7f">Chapter labs</h1>
<p>In the labs in this chapter, we will run containers and interact with them. We will also review some examples, limiting their resources and formatting and filtering the command output.</p>
<p>To run these labs, deploy <kbd>environments/standalone-environment</kbd> from this book's GitHub repository (<a href="https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git">https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git</a>) if you have not done so yet. You can use your own CentOS 7 server. Use <kbd>vagrant up</kbd> from the <kbd>environments/standalone-environment</kbd> folder to start your virtual environment.</p>
<p>If you are using <kbd>standalone-environment</kbd>, wait until it is running. We can check the statuses of our nodes using <kbd>vagrant status</kbd>. Connect to your lab node using <kbd>vagrant ssh standalone</kbd>. <kbd>standalone</kbd> is the name of your node. You will be using the <kbd>vagrant</kbd> user with root privileges using <kbd>sudo</kbd>. You should get the following output:</p>
<pre><strong>Docker-Certified-Associate-DCA-Exam-Guide/environments/standalone$ vagrant up</strong><br/><strong>Bringing machine 'standalone' up with 'virtualbox' provider...</strong><br/><strong>...</strong><br/><strong>Docker-Certified-Associate-DCA-Exam-Guide/environments/standalone$ vagrant status</strong><br/><strong>Current machine states:</strong><br/><strong>standalone running (virtualbox)</strong><br/><strong>...</strong><br/><strong>Docker-Certified-Associate-DCA-Exam-Guide/environments/standalone$</strong></pre>
<p class="mce-root">We can now connect to the <kbd>standalone</kbd> node using <kbd>vagrant ssh standalone</kbd>. This process may vary if you've already deployed a <kbd>standalone</kbd> virtual node before and you just started it using <kbd>vagrant up</kbd>:</p>
<pre><strong>Docker-Certified-Associate-DCA-Exam-Guide/environments/standalone$ vagrant ssh standalone</strong><br/><strong>[vagrant@standalone ~]$</strong> </pre>
<p>If you are reusing your <kbd>standalone-environment</kbd>, this means Docker Engine is installed. If you started a new instance, please execute the <kbd>/vagrant/install_requirements.sh</kbd> script so that you have all the required tools (Docker Engine and docker-compose):</p>
<pre><strong>[vagrant@standalone ~]$ /vagrant/install_requirements.sh</strong> </pre>
<p>Now, you are ready to start the labs.</p>
<h2 id="uuid-1b4c8a4a-bbed-4c6a-b0d6-fabe79b4509b">Reviewing Docker command-line object options</h2>
<p>The Docker command line will allow us to interact with Docker daemons. We will use Docker objects or resources with their allowed actions. In the following screenshot, we can easily review this behavior in the Docker <kbd>help</kbd> command's output:</p>
<div><img src="img/d6824a64-9226-4ae4-ac05-f40a7896651d.jpg" style=""/></div>
<p>Objects will appear in the first part, after common options. At the bottom, we will have all the options allowed. As we mentioned in this chapter, not all objects have the same actions. This chapter is dedicated to containers. So, let's review what actions are allowed with containers (the output is truncated):</p>
<pre><strong>[vagrant@standalone ~]$ docker container --help</strong><br/><strong>Usage: docker container COMMAND</strong><br/><strong>Manage containers</strong><br/><strong>Commands:</strong><br/><strong> attach Attach local standard input, output, and error streams to a running container</strong><br/><strong> commit Create a new image from a container's changes</strong><br/><strong>.....</strong><br/><strong>.....</strong><br/><strong>.....</strong><br/><strong> unpause Unpause all processes within one or more containers</strong><br/><strong> update Update configuration of one or more containers</strong><br/><strong> wait Block until one or more containers stop, then print their exit codes</strong><br/><strong>Run 'docker container COMMAND --help' for more information on a command.</strong></pre>
<p>We should use <kbd>--help</kbd> with each kind of object to review what actions are available for them. If we have not set any <kbd>DOCKER_HOST</kbd> variable (nor using <kbd>-H</kbd> ), we will interact with the local Docker daemon. We will use these arguments in the command line to connect to remote daemons.</p>
<p>Actually, there are many well-known Docker command-line aliases:</p>
<ul>
<li><kbd>docker run</kbd>: <kbd>docker container run</kbd></li>
<li><kbd>docker ps</kbd>: <kbd>docker container ls</kbd></li>
<li><kbd>docker rm</kbd>: <kbd>docker container rm</kbd></li>
<li><kbd>docker start/stop</kbd>: <kbd>docker container start/stop</kbd></li>
<li><kbd>docker port</kbd>: <kbd>docker container port</kbd></li>
<li><kbd>docker rmi</kbd>: <kbd>docker image rm</kbd></li>
</ul>
<p>It is recommended to use long command-line terms as they actually indicate an object and action. This will avoid confusion or the misspelling of commands.</p>
<h2 id="uuid-4c2aa3f5-c380-4be9-8ce6-023500f26395">Executing containers</h2>
<p>This is a long lab in which we are going to review many actions and options available to containers. Let's get started:</p>
<ol>
<li>Execute an interactive container based on an Alpine image in the background:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container run -ti -d alpine</strong><br/><strong>aa73504ba37299aa7686a1c5d8023933b09a0ff13845a66be0aa69203eea8de7</strong></pre>
<ol start="2">
<li>Now, we will review and rename the container <kbd>myalpineshell</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container ls -l</strong><br/><strong>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong>aa73504ba372 alpine "/bin/sh" About a minute ago Up About a minute elastic_curran</strong></pre>
<p>We use <kbd>-l</kbd> or <kbd>--last</kbd> to obtain the latest container that was executed on our Docker host. Notice that we will use <kbd>-q</kbd> in the following code to obtain the container's ID.</p>
<p style="padding-left: 60px">Now, we rename the previously launched container using its ID:</p>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container rename $(docker container ls -ql) myalpineshell</strong></pre>
<p style="padding-left: 60px">If we review the latest container again, we will see that we have a different name. Notice that the container is running (the output will show different dates for you):</p>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container ls -l</strong><br/><strong>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong>aa73504ba372 alpine "/bin/sh" 11 minutes ago Up 11 minutes myalpineshell</strong></pre>
<ol start="3">
<li>We attach our Terminal to the running <kbd>myalpineshell</kbd> container and we create an empty file named <kbd>TESTFILE</kbd> under the <kbd>/tmp</kbd> directory. Then, we <kbd>exit</kbd> from the container:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container attach myalpineshell</strong><br/><strong>/ # touch /tmp/TESTFILE</strong><br/><strong>/ # exit</strong></pre>
<ol start="4">
<li>If we review the container's status again, we will find that it has stopped, but that it exited correctly:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container ls -l</strong><br/><strong>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong>aa73504ba372 alpine "/bin/sh" 14 minutes ago Exited (0) 46 seconds ago myalpineshell</strong></pre>
<p style="padding-left: 60px">The container now shows an <kbd>Exited (0)</kbd> status. The Alpine image's main process is a shell. Its CMD is <kbd>/bin/sh</kbd>. We exited by issuing the <kbd>exit</kbd> command. Therefore, the exit status was <kbd>0</kbd>. No problem was identified during execution.</p>
<ol start="5">
<li>Now, we are going to force a failure status by executing, for example, a command that doesn't exist in the image. We will execute the <kbd>curl</kbd> command on a new container:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container run alpine curl www.google.com</strong><br/><strong>docker: Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused "exec: \"curl\": executable file not found in $PATH": unknown.</strong><br/><strong>ERRO[0001] error waiting for container: context canceled</strong> </pre>
<p style="padding-left: 60px">As the <kbd>curl</kbd> binary does not exist, we cannot even execute the desired command. As a result, the container was created but not executed:</p>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container ls -l</strong><br/><strong>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong>466cc346e5d3 alpine "curl www.google.com" 17 seconds ago Created fervent_tharp</strong></pre>
<ol start="6">
<li>Now, we will execute <kbd>ls -l /tmp/TESTFILE</kbd> on a new container:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container run alpine ls -l /tmp/TESTFILE</strong><br/><strong>ls: /tmp/TESTFILE: No such file or directory</strong><br/><br/><strong>[vagrant@standalone ~]$ docker container ls -l</strong><br/><strong>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong>7c328b9a0609 alpine "ls -l /tmp/TESTFILE" 8 seconds ago Exited (1) 6 seconds ago priceless_austin</strong></pre>
<p style="padding-left: 60px">As expected, the <kbd>/tmp/TESTFILE</kbd> file does not exist in this new container. We only created it in the <kbd>myalpineshell</kbd> container. In fact, the file is still there. Notice that this time, the container was executed and that the exit status shows an error code. This is the exit code of the execution of the <kbd>ls</kbd> command against a non-existent file.</p>
<ol start="7">
<li>Let's rename the last executed container again:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container rename $(docker container ls -ql) secondshell</strong></pre>
<ol start="8">
<li>Now, we will create the <kbd>/tmp/TESTFILE</kbd> file on our own host filesystem and copy it to the <kbd>secondshell</kbd> container:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ touch /tmp/TESTFILE</strong><br/><br/><strong>[vagrant@standalone ~]$ docker container cp /tmp/TESTFILE secondshell:/tmp/TESTFILE</strong></pre>
<p>It is not possible to copy files from one container to another using <kbd>docker container cp</kbd>.</p>
<ol start="9">
<li>Now, let's start the <kbd>secondshell</kbd> container again and observe the new results:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container start secondshell</strong><br/><strong>secondshell</strong><br/><br/><strong>[vagrant@standalone ~]$ docker container ls -l</strong><br/><strong>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong>7c328b9a0609 alpine "ls -l /tmp/TESTFILE" 32 minutes ago Exited (0) 4 seconds ago secondshell</strong></pre>
<p style="padding-left: 60px">The file now exists inside the <kbd>secondshell</kbd> container and, as a result, the execution exited correctly. We can notice this new result in the <kbd>STATUS</kbd> column (<kbd>Exited (0)</kbd>). We have manipulated a dead container by copying a file inside it. Therefore, containers are still present in our host system until we remove them.</p>
<ol start="10">
<li>Now, we will remove the <kbd>secondshell</kbd> container and try to filter the container list's output. We will search for the <kbd>secondshell</kbd> and <kbd>myalpineshell</kbd> containers:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container rm secondshell</strong><br/><strong>secondshell</strong><br/><br/><strong>[vagrant@standalone ~]$ docker container ls --all --filter name=myalpineshell --filter name=secondshell</strong><br/><strong>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong>aa73504ba372 alpine "/bin/sh" 59 minutes ago Exited (0) 45 minutes ago myalpineshell</strong></pre>
<p style="padding-left: 60px">As expected, we only get the <kbd>myalpineshell</kbd> container.</p>
<ol start="11">
<li>To finish this lab, we will start the <kbd>myalpineshell</kbd> container once more using <kbd>docker container start -a -i</kbd> to attach our Terminal to the started container. Then, we will send the container to the background using the <em>Ctrl</em> + <em>P</em> + <em>Q</em> escape sequence. Finally, we will attach a second shell to the container using the <kbd>docker container exec</kbd> command:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container start -a -i myalpineshell</strong><br/><strong>&lt;PRESS Ctrl+p+q&gt;</strong><br/><strong>/ # read escape sequence</strong><br/><br/><strong>[vagrant@standalone ~]$ docker container exec -ti myalpineshell sh</strong><br/><strong>/ # ps -ef</strong><br/><strong>PID USER TIME COMMAND</strong><br/><strong> 1 root 0:00 /bin/sh</strong><br/><strong> 6 root 0:00 sh</strong><br/><strong> 11 root 0:00 ps -ef</strong><br/><strong>/ # exit</strong></pre>
<p style="padding-left: 60px">We can observe that exiting from the newly executed shell process does not kill the <kbd>myalpineshell</kbd> container. Both processes share the same namespaces:</p>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container ls --all --filter name=myalpineshell</strong><br/><strong>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong>aa73504ba372 alpine "/bin/sh" About an hour ago Up 4 minutes myalpineshell</strong></pre>
<h2 id="uuid-4d555244-a715-4314-bcd2-ecc836938fcf">Limiting container resources</h2>
<p>In this lab, we are going to use the <kbd>frjaraur/stress-ng:alpine</kbd> image from Docker Hub. This image is based on Alpine Linux with the <kbd>stress-ng</kbd> packages installed. It is small and will help us stress our containers.</p>
<p>We will start with testing memory limits. In this lab, we will use two Terminals on the same host. On the first Terminal, we will launch <kbd>docker container stats</kbd>. Keep this running during all these labs because, in this Terminal, we are going to observe different behaviors.</p>
<p>In the second Terminal, we will launch two containers that will try to consume 2 GB of memory. We will use <kbd>--vm 2 --vm-bytes 1024M</kbd> to create two processes with 1,024 MB of memory in each:</p>
<ol>
<li>We are going to launch a container with a memory reservation. This means that the Docker daemon will reserve at least that amount of memory for this container. Remember that this is not a limit; it is a reservation:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container run --memory-reservation=250m --name 2GBreserved -d frjaraur/stress-ng:alpine --vm 2 --vm-bytes 1024M</strong><br/><strong>b07f6319b4f9da3149d41bbe9a4b1440782c8203e125bd08fd433df8bac91ba7</strong></pre>
<ol start="2">
<li>Now, we will launch a limited container. Only 250 MB of memory will be allowed, although the container will try to consume 2 GB:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container run --memory=250m --name 2GBlimited -d frjaraur/stress-ng:alpine --vm 2 --vm-bytes 1024M</strong><br/><strong>e98fbdd5896d1d182608ea35df39a7a768c0c4b843cc3b425892bee3e394eb81</strong></pre>
<ol start="3">
<li>In the first Terminal, we have <kbd>docker container stats</kbd> running to review our container's resource consumption. We will have something like this (IDs and usage will vary):</li>
</ol>
<pre style="padding-left: 60px"><strong>CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS</strong><br/><strong>b07f6319b4f9 2GBreserved 203.05% 1.004GiB / 11.6GiB 8.65% 6.94kB / 0B 0B / 0B 5</strong><br/><strong>e98fbdd5896d 2GBlimited 42.31% 249.8MiB / 250MiB 99.94% 4.13kB / 0B 1.22GB / 2.85GB 5</strong></pre>
<p>If you obtain a warning message about limiting resources, this is normal. The <kbd>WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.</kbd> message indicates that your operating system will not limit <kbd>swap</kbd> for containers. It comes disabled by default on Debian/Ubuntu.</p>
<p style="padding-left: 60px">We can observe that the non-limited container is taking more than the specified memory. In the second case, the container was limited to 250 MB, although the process could consume more, it was limited and it will not get more than this memory. It is confined to 250 MB, as we can observe in the <kbd>MEM USAGE/LIMIT MEM</kbd> column. It could reach 100% of its confined memory, but it cannot surpass that limit.</p>
<ol start="4">
<li>Remove the <kbd>2GBreserved</kbd> and <kbd>2GBlimited</kbd> containers:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container rm -f 2GBlimited 2GBreserved</strong><br/><strong>2GBlimited</strong><br/><strong>2GBreserved</strong></pre>
<p style="padding-left: 60px">Now, we will limit the CPU consumption.</p>
<ol start="5">
<li>We will launch three containers with different CPU limitations and process requirements. The first container is limited to one CPU, but with two CPU requirements. This is not a genuine requirement, but the process will try to use two CPUs if they are present in this system:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container run -d --cpus=1 --name CPU2vs1 frjaraur/stress-ng:alpine --cpu 2 --timeout 120 </strong></pre>
<p style="padding-left: 60px">The second container is limited to two CPUs with a requirement of two CPUs. It will try to use both during execution:</p>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container run -d --cpus=2 --name CPU2vs2 frjaraur/stress-ng:alpine --cpu 2 --timeout 120</strong></pre>
<p style="padding-left: 60px">The third container is limited to four CPUs with two CPUs required. In this case, the processes could consume four CPUs, but as they will just use two CPUs, they will not have a real limitation unless we try to use more than four CPUs:</p>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container run -d --cpus=4 --name CPU2vs4 frjaraur/stress-ng:alpine --cpu 2 --timeout 120</strong></pre>
<ol start="6">
<li>If we observe the Docker container's stats output, we can confirm the expected results:</li>
</ol>
<pre style="padding-left: 60px"><strong>CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT    MEM %               NET I/O             BLOCK I/O           PIDS</strong><br/><strong>0dc652ed28b0        CPU2vs4             132.47%             7.379MiB / 11.6GiB   0.06%               4.46kB / 0B         0B / 0B             3</strong><br/><strong>ec62ee9ed812        CPU2vs2             135.41%             7.391MiB / 11.6GiB   0.06%               5.71kB / 0B         0B / 0B             3</strong><br/><strong>bb1034c8b588        CPU2vs1             98.90%              7.301MiB / 11.6GiB   0.06%               7.98kB / 0B         262kB / 0B          3</strong></pre>
<p>With that, we have reviewed how we can limit the container's resources. We tested CPU and memory usage with <kbd>docker container stats</kbd>, pushing them to their defined limits.</p>
<p>Now, let's review formatting and filtering with some labs.</p>
<h2 id="uuid-a486b0f1-244b-436b-9dcc-6dfd46aa81ef">Formatting and filtering container list output</h2>
<p>In this lab, we will review the <kbd>docker container ls</kbd> output. Let's get started:</p>
<ol>
<li>Launch a number of containers. For this example, we will run three <kbd>nginx:alpine</kbd> instances with sequence names:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker run -d --name web1 --label stage=production nginx:alpine</strong><br/><strong>bb5c63ec7427b6cdae19f9172f5b0770f763847c699ff2dc9076e60623771da3</strong><br/><br/><strong>[vagrant@standalone ~]$ docker run -d --name web2 --label stage=development nginx:alpine</strong><br/><strong>4e7607f3264c52c9c14b38412c95dfc8c286835fd1ffab1d7898c5cfab47c9b8</strong><br/><br/><strong>[vagrant@standalone ~]$ docker run -d --name web3 --label stage=development nginx:alpine</strong><br/><strong>fcef82c80ed0b049705609885bc9c518bf062a39bbe2b6d68b7017bcc6dcaa14</strong></pre>
<ol start="2">
<li>Let's list the running containers using the <kbd>docker container ls</kbd> default output:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container ls</strong><br/><strong>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</strong><br/><strong>fcef82c80ed0 nginx:alpine "nginx -g 'daemon of…" About a minute ago Up 59 seconds 80/tcp web3</strong><br/><strong>4e7607f3264c nginx:alpine "nginx -g 'daemon of…" About a minute ago Up About a minute 80/tcp web2</strong><br/><strong>bb5c63ec7427 nginx:alpine "nginx -g 'daemon of…" About a minute ago Up About a minute 80/tcp web1</strong></pre>
<ol start="3">
<li>Since we want to be able to review the current status of the containers, we can format the output so that it includes label information:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container ls \<br/>--format "table {{.Names}} {{.Command}}\\t{{.Labels}}"<br/></strong><br/><strong>NAMES COMMAND                 LABELS</strong><br/><strong>web3 "nginx -g 'daemon of…"   maintainer=NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;,stage=development</strong><br/><strong>web2 "nginx -g 'daemon of…"   stage=development,maintainer=NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;</strong><br/><strong>web1 "nginx -g 'daemon of…"   stage=production,maintainer=NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;</strong></pre>
<ol start="4">
<li>Now, let's filter just the development containers (<kbd>stage=development</kbd>):</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container ls --format "table {{.Names}} {{.Command}}\\t{{.Labels}}" --filter label=stage=development</strong><br/><strong>NAMES COMMAND LABELS</strong><br/><strong>web3 "nginx -g 'daemon of…" maintainer=NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;,stage=development</strong><br/><strong>web2 "nginx -g 'daemon of…" maintainer=NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;,stage=development</strong></pre>
<ol start="5">
<li>Now, let's kill just those development containers using the list output:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ docker container kill $(docker container ls --format "{{.ID}}" --filter label=stage=development)</strong><br/><br/><strong>[vagrant@standalone ~]$ docker container ls --format "table {{.Names}}\\t{{.Labels}}"</strong><br/><strong>NAMES               LABELS</strong><br/><strong>web1                maintainer=NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;,stage=production</strong></pre>
<p>Only <kbd>web1</kbd>, labeled as <kbd>production</kbd>, is still running as expected.</p>
<p>Filtering and formatting are very useful. Practice these methods because they are important for the Docker Certified Associate exam.</p>
<h1 id="uuid-ee93a12c-3977-4604-8f77-980247051251">Summary</h1>
<p>This chapter was dedicated to the Docker command line and running containers. We found a powerful command line that allowed us to create containers from image artifacts, share them between hosts, and execute the already built application components.</p>
<p>We learned how to interact with different Docker objects, as well as what kind of objects are available in standalone Docker host environments and what objects are available in orchestrated environments.</p>
<p>We then reviewed how containers can be created, executed, paused/unpaused, and stopped or killed. They will stay in our Docker host until they are removed from the system. We also learned how to manipulate the container's execution behavior and how they exist within the network. To improve security, we introduced a number of options and we also learned how executing containers in read-only mode can be very useful.</p>
<p>Limiting the container's resources is necessary for production. By default, they will be able to consume all the host's resources, which can be very dangerous. We learned how to avoid this situation using soft and hard limits to ensure that our applications will run on a host with enough resources and does not disturb others.</p>
<p>Formatting and filtering specific information is needed while deploying applications on dynamic environments. We learned how format and filter actions will help us retrieve specific information.</p>
<p>We concluded this chapter by learning how to use a host's devices as if they were attached directly to containers.</p>
<p>In the next chapter, we will look at container persistency and their networking features.</p>
<h1 id="uuid-5694d42a-fa74-4e01-a036-d92a23e23968" class="mce-root">Questions</h1>
<ol>
<li> Which of the following options is not available for containers?</li>
</ol>
<p style="padding-left: 90px">a) <kbd>build<br/></kbd>b) <kbd>update<br/></kbd>c) <kbd>destroy<br/></kbd>d) <kbd>create</kbd></p>
<ol start="2">
<li>Which of the following sentences is false?</li>
</ol>
<p style="padding-left: 90px">a) A container's life is managed using <kbd>start</kbd> and <kbd>stop</kbd> commands<br/>
b) Containers always stop after 10 seconds<br/>
c) Containers can be created and then started<br/>
d) Volumes created during the container's lifetime must be deleted by hand unless we use the <kbd>-v</kbd> option when deleting the container</p>
<ol start="3">
<li>Which of the following sentences is true in relation to <kbd>docker kill</kbd>?</li>
</ol>
<p style="padding-left: 90px">a) It will kill all container processes<br/>
b) It will send a <kbd>SIGKILL</kbd> signal to the container's main process<br/>
c) It will remove the container once it is killed<br/>
d) It will wait 10 seconds by default before really killing the container</p>
<ol start="4">
<li>We executed a container named <kbd>webserver</kbd>. Which of the following sentences is false?</li>
</ol>
<p style="padding-left: 90px">a) It can be removed using <kbd>docker container rm --force<br/></kbd>b) We can update its image using <kbd>docker container update<br/></kbd>c) We can rename the <kbd>webserver</kbd> container to <kbd>websrv</kbd> using <kbd>docker container rename<br/></kbd>d) We can view the container's output using <kbd>docker container logs</kbd></p>
<ol start="5">
<li><strong> </strong>We have executed the <kbd>docker container run --name app1 --user 1000 --memory 100m --privileged alpine touch /testfile</kbd> command. Which of the following sentences are true?</li>
</ol>
<p style="padding-left: 90px">a) <kbd>/testfile</kbd> was created as root because the container was executed with all capabilities.<br/>
b) The container will not be able to consume more than 100 m of host memory.<br/>
c) <kbd>/testfile</kbd> was not created because we used a user with an ID of <kbd>1000</kbd> and it will not be able to write on <kbd>/</kbd>, the root directory.<br/>
d) We used <kbd>--privileged</kbd>. This option will disable all root capabilities inside the container and, as a result, the file can't be created.</p>
<h1 id="uuid-5c5a987f-b191-4343-b599-7f813dc06f05">Further reading</h1>
<p>Refer to the following links to find out more about the topics that were covered in this chapter:</p>
<ul>
<li>Docker command-line reference: <a href="https://docs.docker.com/engine/reference/commandline/docker/">https://docs.docker.com/engine/reference/commandline/docker/</a></li>
<li>Memory limits behavior: <a href="https://medium.com/faun/understanding-docker-container-memory-limit-behavior-41add155236c">https://medium.com/faun/understanding-docker-container-memory-limit-behavior-41add155236c</a></li>
</ul>


            

            
        
    </body></html>