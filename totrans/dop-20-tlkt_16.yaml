- en: Chapter 16. Centralized Logging and Monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第16章 集中式日志记录与监控
- en: '|   | *I have so much chaos in my life, it''s become normal. You become used
    to it. You have just to relax, calm down, take a deep breath and try to see how
    you can make things work rather than complain about how they''re wrong.* |   |'
  id: totrans-1
  prefs: []
  type: TYPE_TB
  zh: '|   | *我的生活充满了混乱，这已经变成了一种常态。你会习惯它。你只需要放松，冷静下来，深呼吸，试着找到让事情运作的办法，而不是抱怨它们的错误。*
    |   |'
- en: '|   | --*Tom Welling* |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '|   | --*汤姆·韦林* |'
- en: Our exploration of DevOps practices and tools led us towards clustering and
    scaling. As a result, we developed a system that allows us to deploy services
    to a cluster, in an easy and efficient way. The result is an ever increasing number
    of containers running on a cluster consisting of, potentially, many servers. Monitoring
    one server is easy. Monitoring many services on a single server poses some difficulties.
    Monitoring many services on many servers requires a whole new way of thinking
    and a new set of tools. As you start embracing microservices, containers, and
    clusters, the number of deployed containers will begin increasing rapidly. The
    same holds true for servers that form the cluster. We cannot, anymore, log into
    a node and look at logs. There are too many logs to look at. On top of that, they
    are distributed among many servers. While yesterday we had two instances of a
    service deployed on a single server, tomorrow we might have eight instances deployed
    to six servers. The same holds true for monitoring. Old tools, like Nagios, are
    not designed to handle constant changes in running servers and services. We already
    used Consul that provides a different, not to say new, approach to managing near
    real-time monitoring and reaction when thresholds are reached. However, that is
    not enough. Real-time information is valuable to detect that something is wrong,
    but it does not give us information why the failure happened. We can know that
    a service is not responding, but we cannot know why.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对DevOps实践和工具的探索引导我们走向了集群和扩展。因此，我们开发了一个系统，使我们能够以简单而高效的方式将服务部署到集群中。结果是，运行在由多个服务器组成的集群上的容器数量不断增加。监控单个服务器很容易，但监控一个服务器上的多个服务就会带来一些困难。监控多个服务器上的多个服务需要全新的思维方式和一整套新的工具。当你开始采用微服务、容器和集群时，部署的容器数量将开始迅速增加。集群中形成的服务器数量也同样如此。我们不能再像以前那样登录到一个节点查看日志，因为需要查看的日志太多了。更重要的是，这些日志分布在许多服务器之间。昨天我们可能在一台服务器上部署了两个服务实例，今天我们可能会将八个实例部署到六台服务器上。监控也同样如此。旧有的工具，比如Nagios，并没有设计用来处理运行中的服务器和服务的不断变化。我们已经使用了Consul，它提供了一种不同的，甚至可以说是新的方法来管理接近实时的监控和在阈值达到时的反应。然而，这还不够。实时信息对于检测某些东西出现故障很有价值，但它并不能告诉我们为什么故障发生了。我们可以知道某个服务没有响应，但我们无法知道原因。
- en: We need historical information about our system. That information can be in
    the form of logs, hardware utilization, health checking, and many other things.
    The need to store historical data is not new and has been in use for a long time.
    However, the direction that information travels changed over time. While, in the
    past, most solutions were based on a centralized data collectors, today, due to
    very dynamic nature of services and servers, we tend to have data collectors decentralized.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要关于我们系统的历史信息。这些信息可以以日志、硬件利用率、健康检查以及其他许多形式存在。存储历史数据的需求并不新鲜，已经使用了很长时间。然而，信息流动的方向随着时间发生了变化。过去，大多数解决方案基于集中式数据收集器，而今天，由于服务和服务器的高度动态特性，我们倾向于采用分散式的数据收集器。
- en: What we need for cluster logging and monitoring is a combination of decentralized
    data collectors that are sending information to a centralized parsing service
    and data storage. There are plenty of products specially designed to fulfill this
    requirement, ranging from on-premise to cloud solutions, and everything in between.
    FluentD, Loggly, GrayLog, Splunk, and DataDog are only a few of the solutions
    we can employ. I chose to show you the concepts through the ELK stack (ElasticSearch,
    LogStash, and Kibana). The stack has the advantage of being free, well documented,
    efficient, and widely used. ElasticSearch established itself as one of the best
    databases for real-time search and analytics. It is distributed, scalable, highly
    available, and provides a sophisticated API. LogStash allows us to centralize
    data processing. It can be easily extended to custom data formats and offers a
    lot of plugins that can suit almost any need. Finally, Kibana is an analytics
    and visualization platform with intuitive interface sitting on top of ElasticSearch.
    The fact that we'll use the ELK stack does not mean that it is better than the
    other solutions. It all depends on specific use cases and particular needs. I'll
    walk you through the principles of centralized logging and monitoring using the
    ELK stack. Once those principles are understood, you should have no problem applying
    them to a different stack if you choose to do so.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 对于集群日志记录和监控，我们需要的是一组合并的去中心化数据收集器，这些收集器将信息发送到一个集中式解析服务和数据存储。市面上有许多专门为满足这一需求而设计的产品，从本地解决方案到云端解决方案应有尽有。FluentD、Loggly、GrayLog、Splunk
    和 DataDog 只是我们可以使用的一些解决方案。我选择通过 ELK 堆栈（ElasticSearch、LogStash 和 Kibana）来向你展示这些概念。这个堆栈的优势在于它是免费的，文档齐全，效率高，而且广泛使用。ElasticSearch
    已经成为实时搜索和分析的最佳数据库之一。它是分布式的、可扩展的、高可用的，并提供了复杂的 API。LogStash 使我们能够集中数据处理。它可以轻松扩展以支持自定义数据格式，并提供了许多插件，几乎可以满足任何需求。最后，Kibana
    是一个分析和可视化平台，具有直观的界面，位于 ElasticSearch 之上。我们将使用 ELK 堆栈并不意味着它比其他解决方案更好，这完全取决于特定的使用场景和需求。我将带你了解如何使用
    ELK 堆栈进行集中式日志记录和监控。一旦这些原则被理解，你应该可以毫不费力地将其应用到其他堆栈中，如果你选择这样做的话。
- en: We switched the order of things and chose the tools before discussing the need
    for centralized logging. Let's remedy that.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们改变了事物的顺序，选择了工具后才讨论集中式日志记录的需求。让我们来纠正这一点。
- en: The Need for Centralized Logging
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集中式日志记录的需求
- en: In most cases, log messages are written to files. That is not to say that files
    are the only, nor the most efficient way of storing logs. However, since most
    teams are using file-based logs in one form or another, for the time being, I'll
    assume that is your case as well.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，日志消息被写入文件。这并不是说文件是存储日志的唯一方式，也不是最有效的方式。然而，由于大多数团队在某种形式下都使用基于文件的日志，因此暂时我假设你的情况也是如此。
- en: If we are lucky, there is one log file per a service or application. However,
    more often than not, there are multiple files into which our services are outputting
    information. Most of the time, we do not care much what is written in logs. When
    things are working well, there is not much need to spend valuable time browsing
    through logs. A log is not a novel we read to pass the time, nor it is a technical
    book we spend time with as a way to improve our knowledge. Logs are there to provide
    valuable info when something, somewhere, went wrong.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们幸运的话，每个服务或应用程序会有一个日志文件。然而，更常见的是，我们的服务会将信息输出到多个文件中。大多数时候，我们并不太关心日志中写了什么。当一切顺利时，我们没有必要浪费宝贵的时间浏览日志。日志不是我们用来打发时间的小说，也不是我们花时间去阅读的技术书籍。日志是用来在某些地方出现问题时提供有价值的信息的。
- en: The situation seems to be simple. We write information to logs that we ignore
    most of the time, and when something goes wrong, we consult them and find the
    cause of the problem in no time. At least, that's what many are hoping for. The
    reality is far more complicated than that. In all but most trivial systems, the
    debugging process is much more complex. Applications and services are, almost
    always, interconnected, and it is often not easy to know which one caused the
    problem. While it might manifest in one application, investigation often shows
    that the cause is in another. For example, a service might have failed to instantiate.
    After some time spent browsing its logs, we might discover that the cause is in
    the database. The service could not connect to it and failed to launch. We got
    the symptom, but not the cause. We need to switch to the database log to find
    it out. With this simple example, we already got to the point where looking at
    one log is not enough.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这个情况看似简单。我们将信息写入日志，平时大多数时候我们并不关注这些日志，而当出现问题时，我们查阅日志并迅速找出问题的原因。至少，这也是许多人所期望的。现实远比这复杂。除了最简单的系统外，调试过程通常更加复杂。应用程序和服务几乎总是相互关联的，往往并不容易知道是哪个造成了问题。虽然问题可能表现为某个应用程序的问题，但调查往往表明原因出在另一个地方。例如，一个服务可能没有成功实例化。花费一段时间浏览其日志后，我们可能会发现原因出在数据库上。服务无法连接到数据库，导致启动失败。我们看到了症状，但没有找到原因。我们需要切换到数据库的日志中去找出真相。通过这个简单的例子，我们已经到了仅查看一个日志是不够的阶段。
- en: With distributed services running on a cluster, the situation complicates exponentially.
    Which instance of the service is failing? Which server is it running on? What
    are the upstream services that initiated the request? What is the memory and hard
    disk usage in the node where the culprit resides? As you might have guessed, finding,
    gathering, and filtering the information needed for the successful discovery of
    the cause is often very complicated. The bigger the system, the harder it gets.
    Even with monolithic applications, things can easily get out of hand. If (micro)services
    approach is adopted, those problems are multiplied. Centralized logging is a must
    for all but simplest and smallest systems. Instead, many of us, when things go
    wrong, start running from one server to another, jumping from one file to the
    other. Like a chicken with its head cut off - running around with no direction.
    We tend to accept the chaos logging creates, and consider it part of our profession.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群上运行的分布式服务使得情况变得更加复杂。哪个服务实例出现了故障？它运行在哪台服务器上？有哪些上游服务发起了请求？故障所在节点的内存和硬盘使用情况如何？正如你可能猜到的，查找、收集和筛选出成功发现原因所需的信息往往非常复杂。系统越大，问题越难解决。即使是单体应用，情况也可能很容易失控。如果采用（微）服务架构，这些问题会被成倍增加。集中式日志对所有除最简单、最小的系统外都是必须的。相反，当事情出错时，我们中的许多人开始在不同的服务器之间奔波，从一个文件跳到另一个文件。就像无头的苍蝇一样，四处乱跑，毫无方向。我们往往接受日志所带来的混乱，并将其视为职业的一部分。
- en: 'What do we look for in centralized logging? As it happens, many things, but
    the most important are as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在集中式日志中，我们需要关注什么？其实有很多方面，但最重要的包括以下几点：
- en: A way to parse data and send them to a central database in near real-time.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种解析数据并将其近实时发送到中央数据库的方法。
- en: The capacity of the database to handle near real-time data querying and analytics.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库处理近实时数据查询和分析的能力。
- en: A visual representation of the data through filtered tables, dashboards, and
    so on.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过过滤后的表格、仪表板等方式，数据的可视化呈现。
- en: We already choose the tools that will be able to fulfill all those requirements
    (and more). The ELK stack (LogStash, ElasticSearch, and Kibana) can do all that.
    As in the case of all other tools we explored, this stack can easily be extended
    to satisfy the particular needs we'll set in front of us.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经选择了能够满足所有这些需求（甚至更多）工具。ELK 堆栈（LogStash、ElasticSearch 和 Kibana）可以做到这一点。与我们探索的其他所有工具一样，这个堆栈可以轻松扩展，以满足我们将面临的具体需求。
- en: Now that we have a vague idea what we want to accomplish, and have the tools
    to do that, let us explore a few of the logging strategies we can use. We'll start
    with the most commonly used scenario and, slowly, move towards more complicated
    and more efficient ways to define our logging strategy.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对要完成的目标有了模糊的概念，并且有了实现这些目标的工具，让我们来探索几种可以使用的日志策略。我们将从最常见的场景开始，逐渐过渡到更复杂、更高效的日志策略定义方法。
- en: 'Without further ado, let''s create the environments we''ll use to experiment
    with centralized logging and, later on, monitoring. We''ll create three nodes.
    You should already be familiar with the `cd` and `prod` VMs. The first one will
    be used mainly for provisioning while the second will act as a production server.
    We''ll introduce a new one called `logging`. It will be an imitation of a production
    server aimed at running all the logging and monitoring tools. Ideally, instead
    of a single production server (`prod`), we would run examples against the, let''s
    say, Swarm cluster. That would allow us to see the benefits in a more production-like
    setting. However, since the previous few chapters already stretched limits of
    what could be run on a single laptop, I did not want to risk it and opted for
    a single VM. That being said, all the examples are equally applicable to one,
    ten, hundred, or thousand servers. You should have no problem extending them to
    you entire cluster:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 不再多说，我们来创建将用于实验集中式日志记录以及后续监控的环境。我们将创建三个节点。你应该已经对`cd`和`prod`虚拟机很熟悉了。第一个主要用于配置，而第二个将作为生产服务器。我们将引入一个新的虚拟机，名为`logging`。它将模拟生产服务器，旨在运行所有日志记录和监控工具。理想情况下，替代单一的生产服务器（`prod`），我们可以将示例运行在Swarm集群上。这将使我们能够在更接近生产的环境中看到优势。然而，由于前几章已经把单台笔记本电脑能承载的极限拉得很远，我不想冒险，所以选择了单台虚拟机。话虽如此，所有示例同样适用于一台、十台、百台或千台服务器。你应该没有问题将它们扩展到整个集群：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Sending Log Entries to ElasticSearch
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将日志条目发送到ElasticSearch
- en: We'll start by provisioning the `logging` server with the ELK stack (ElasticSearch,
    LogStash, and Kibana). We'll continue using Ansible for provisioning since it
    converted itself into our favorite configuration management tool.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从使用ELK栈（ElasticSearch、LogStash和Kibana）来配置`logging`服务器开始。我们将继续使用Ansible进行配置，因为它已经转变为我们最喜欢的配置管理工具。
- en: 'Let''s run the elk.yml playbook and explore it while it''s executing:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行elk.yml剧本，并在执行过程中进行探索：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The definition of the playbook is as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 剧本的定义如下：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We used the `common` and the `docker` roles many times before, so we''ll skip
    them, and jump straight into `elasticsearch` tasks defined in the `roles/elasticsearch/tasks`
    `/main.yml` file:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已经使用了`common`和`docker`角色很多次，因此我们会跳过它们，直接进入在`roles/elasticsearch/tasks` `/main.yml`文件中定义的`elasticsearch`任务：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Thanks to Docker, all we have to do is run the official `elasticsearch` image.
    It exposes its API through the port `9200` and defines a single volume we'll use
    to persist data in the host.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了Docker，我们只需要运行官方的`elasticsearch`镜像。它通过端口`9200`暴露其API，并定义了一个我们将用来在主机上持久化数据的卷。
- en: 'The next in line is the `logstash` role. The tasks set in the `roles/logstash/tas`
    `ks/main.yml` file are as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是`logstash`角色。在`roles/logstash/tasks/main.yml`文件中定义的任务如下：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'While a big more numerous than the `elasticsearch` tasks, these are still pretty
    straightforward. The tasks create a directory, copy few configuration files we''ll
    use throughout this chapter, and run the official logstash image. Since we''ll
    experiment with quite a few scenarios, different ports need to be exposed and
    defined. The role exposes two volumes. The first one will hold configuration files
    while we''ll use the second as a directory to place some logs. Finally, the task
    creates the link to the `elasticsearch` container and specifies that the `command`
    should start `logstash` with the configuration file defined as the variable. The
    command we used to run the playbook contained the `logstash_config` variable set
    to `file.conf`. Let us take a quick look at it:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然比`elasticsearch`任务稍多一些，这些任务仍然相对简单。任务会创建一个目录，复制一些配置文件，这些文件将在本章中使用，并运行官方的logstash镜像。由于我们将实验许多不同的场景，需要暴露并定义不同的端口。这个角色暴露了两个卷。第一个卷将保存配置文件，而第二个卷则作为一个目录来存放日志。最后，任务会创建与`elasticsearch`容器的链接，并指定`command`应使用定义为变量的配置文件启动`logstash`。我们用来运行剧本的命令包含了设置为`file.conf`的`logstash_config`变量。我们快速看一下它：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'LogStash configurations consist of three main sections: `input`, `output`,
    and `filters`. We''ll skip `filter`, for now, and focus on the other two.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: LogStash的配置由三大部分组成：`input`、`output`和`filters`。我们暂时跳过`filter`，集中讨论其他两个部分。
- en: The `input` section defines one or more log sources. In this case, we defined
    that input should be handled through the file plugin, with the `path` set to `/logs/**/*`.
    One asterisk means any file or directory while two consecutive ones mean any file
    in any directory or subdirectory. The `/logs/**/*` value can be described as any
    file in the `/logs/` directory or any of its subdirectories. Bear in mind that,
    even though we specified only one input, there can, and often are, multiple inputs.
    For more information on all the supported input plugins, please consult the official
    input plugins page.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`input` 部分定义了一个或多个日志来源。在此案例中，我们定义了输入应该通过文件插件处理，`path` 设置为 `/logs/**/*`。一个星号表示任何文件或目录，而两个连续的星号表示任何目录或子目录中的文件。`/logs/**/*`
    这个值可以描述为 `/logs/` 目录中的任何文件或其任何子目录中的文件。请记住，尽管我们只指定了一个输入，但可能会有多个输入，并且通常是这样。有关所有支持的输入插件的更多信息，请参阅官方的输入插件页面。'
- en: The `output` section defines the destination of log entries collected through
    the input. In this case, we set two. The first one is using the stdout output
    plugin that will print everything to standard output using `rubydebug` codec.
    Please note that we are using `stdout` only for demonstration purposes so that
    we can quickly see the result. In a production setting, you should probably remove
    it for performance reasons. The second output is more interesting. It uses the
    ElasticSearch output plugin to send all the log entries to the database. Please
    note that the `hosts` variable is set to `db`. Since we linked the `logstash`
    and `elasticsearch` containers, Docker created the `db` entry in the `/etc/hosts`
    file. For more information on all supported output plugins, please consult the
    [https://www.elastic.co/guide/en/logstash/current/output-plugins.html](https://www.elastic.co/guide/en/logstash/current/output-plugins.html)
    page.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`output` 部分定义了通过输入收集的日志条目的目的地。在此案例中，我们设置了两个输出。第一个是使用 `stdout` 输出插件，它会通过 `rubydebug`
    编解码器将所有内容打印到标准输出。请注意，我们仅将 `stdout` 用于演示目的，以便快速查看结果。在生产环境中，出于性能考虑，您应该删除它。第二个输出更有趣，它使用
    ElasticSearch 输出插件将所有日志条目发送到数据库。请注意，`hosts` 变量设置为 `db`。由于我们已将 `logstash` 和 `elasticsearch`
    容器连接在一起，Docker 在 `/etc/hosts` 文件中创建了 `db` 条目。有关所有支持的输出插件的更多信息，请参阅 [https://www.elastic.co/guide/en/logstash/current/output-plugins.html](https://www.elastic.co/guide/en/logstash/current/output-plugins.html)
    页面。'
- en: 'This configuration file is probably one of the simplest we could start with.
    Before we see it in action, let us go through the last element in the stack. Kibana
    will provide user interface we can use to interact with ElasticSearch. The tasks
    of the kibana role are defined in the `roles/kibana/tasks/main.yml` file. It contains
    backup restoration tasks that we''ll skip, for now, and concentrate only on the
    part that runs the container:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配置文件可能是我们可以开始使用的最简单的文件。在我们看到它的实际效果之前，让我们来看看堆栈中的最后一个元素。Kibana 将提供一个用户界面，供我们与
    ElasticSearch 交互。kibana 角色的任务在 `roles/kibana/tasks/main.yml` 文件中定义。它包含了备份恢复任务，我们现在可以跳过这些任务，专注于运行容器的部分：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Just like the rest of the ELK stack, Kibana has the official Docker image. All
    we have to do is link the container to `elasticsearch`, and expose the port `6501`
    that we'll use to access the UI. We'll see Kibana in action soon.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 就像 ELK 堆栈中的其他组件一样，Kibana 也有官方的 Docker 镜像。我们只需要将容器链接到 `elasticsearch`，并暴露我们将用于访问
    UI 的 `6501` 端口。我们很快就能看到 Kibana 的实际效果。
- en: 'Before we simulate some log entries, we''ll need to enter the `logging` node
    where the ELK stack is running:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们模拟一些日志条目之前，我们需要进入运行 ELK 堆栈的 `logging` 节点：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Since the `/data/logstash/logs` volume is shared with the container, and LogStash
    is monitoring any file inside it, we can create a log with a single entry:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `/data/logstash/logs` 卷与容器共享，并且 LogStash 正在监视其中的任何文件，我们可以创建一个仅包含一个条目的日志：
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let us take a look at LogStash output and see what happened:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 LogStash 的输出，看看发生了什么：
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Please note that it might take a few seconds until the first log entry is processed,
    so, if the `docker logs` command did not return anything, please re-execute it.
    All new entries to the same file will be processed much faster:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，处理第一个日志条目可能需要几秒钟，如果 `docker logs` 命令没有返回任何内容，请重新执行它。所有新条目对同一文件的处理速度会快得多：
- en: 'The output is as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As you can see, LogStash processed our `my first log entry` and added a few
    additional pieces of information. We got the timestamp, host name, and the path
    of the log file:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，LogStash 处理了我们的 `my first log entry` 并添加了一些额外的信息。我们得到了时间戳、主机名以及日志文件的路径：
- en: 'Let''s add a few more entries:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再添加几个条目：
- en: '[PRE11]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output of the `docker logs` command is as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker logs`命令的输出如下：'
- en: '[PRE12]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As expected, all three log entries were processed by LogStash, and the time
    has come to visualize them through Kibana. Please open `http://` `10.100.198.202:5601/`
    from a browser. Since this is the first time we run Kibana, it will ask us to
    configure an index pattern. Luckily, it already figured out what the index format
    is (`logstash-*`), as well as which field contains timestamps (`@timestamp`).
    Please click the **Create** button, followed with **Discover** located in the
    top menu:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，所有三条日志条目都已被LogStash处理，现在是通过Kibana可视化它们的时候了。请从浏览器打开`http://10.100.198.202:5601/`。由于这是第一次运行Kibana，它会要求我们配置一个索引模式。幸运的是，它已经找到了索引格式（`logstash-*`）以及哪个字段包含时间戳（`@timestamp`）。请点击**Create**按钮，然后点击顶部菜单中的**Discover**：
- en: '![Sending Log Entries to ElasticSearch](img/B05848_16_01.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![发送日志条目到ElasticSearch](img/B05848_16_01.jpg)'
- en: Figure 16-01 – Kibana Discover screen with a few log entries
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图16-01 – 带有若干日志条目的Kibana Discover屏幕
- en: By default, the **Discover** screen displays all the entries generated in ElasticSearch
    during the last fifteen minutes. We'll explore functions this screen offers later
    on when we produce more logs. For now, please click the arrow on the left-most
    column of one of the log entries. You'll see all the fields LogStash generated
    and sent to ElasticSearch. At the moment, since we are not using any filters,
    those fields are limited to the *message* representing the whole log entry, and
    a few generic fields LogStash generated.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，**Discover**屏幕会显示过去十五分钟内在ElasticSearch中生成的所有条目。稍后当我们生成更多日志时，我们将探索此屏幕提供的功能。目前，请点击其中一个日志条目最左侧列的箭头。你将看到所有LogStash生成并发送到ElasticSearch的字段。目前，由于我们没有使用任何过滤器，这些字段仅限于表示整个日志条目的*消息*，以及LogStash生成的一些通用字段。
- en: 'The example we used was trivial, and it did not even look like a log entry.
    Let us increase the complexity of our logs. We''ll use a few entries I prepared.
    The sample log is located in the `/tmp/apache.log` file, and it contains a few
    log entries following the Apache format. Its content is as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的示例是简单的，甚至不像一个日志条目。让我们增加日志的复杂性。我们将使用我准备的一些条目。示例日志位于`/tmp/apache.log`文件中，包含了一些遵循Apache格式的日志条目。其内容如下：
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Since LogStash is expecting log files in the `/data/logstash/logs/` directory,
    let us copy the sample:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LogStash期望在`/data/logstash/logs/`目录中找到日志文件，让我们复制示例：
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let us take a look the output LogStash generated:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看LogStash生成的输出：
- en: '[PRE15]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'LogStash might need a few seconds to detect that there is a new file to monitor.
    If the `docker logs` output does not display anything new, please repeat the command.
    The output should be similar to the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: LogStash可能需要几秒钟才能检测到有新文件需要监控。如果`docker logs`输出没有显示任何新内容，请重复执行该命令。输出应该类似于以下内容：
- en: '[PRE16]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The same data can be observed from Kibana running on `http://10.100.198.202:5601/`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的数据可以从运行在`http://10.100.198.202:5601/`上的Kibana中观察到。
- en: We just started, and we already accomplished a vast improvement. When something
    fails on a server, we do not need to know which service failed, nor where its
    logs are. We can get all the log entries from that server from a single place.
    Anyone, be it a developer, tester, operator, or any other role, can open Kibana
    running on that node, and inspect all the logs from all services and applications.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚开始，但已经取得了巨大的进展。当服务器出现故障时，我们不需要知道是哪项服务失败，也不需要知道它的日志在哪里。我们可以从一个地方获取该服务器的所有日志条目。无论是开发人员、测试人员、操作员还是其他任何角色，都可以打开运行在该节点上的Kibana，检查所有服务和应用程序的日志。
- en: The last examples of the Apache log were more production-like than the first
    one we used. However, the entries are still stored as one big message. While ElasticSearch
    is capable of searching almost anything, in almost any format, we should help
    it a bit and try to split this log into multiple fields.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的Apache日志示例比我们使用的第一个更接近生产环境。然而，条目仍然作为一条大消息存储。虽然ElasticSearch几乎可以搜索任何格式的几乎任何内容，但我们应该稍微帮助它，并尝试将这条日志拆分成多个字段。
- en: Parsing Log Entries
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解析日志条目
- en: 'We mentioned earlier that LogStash configurations consist of three main sections:
    `input`, `output`, and `filters`. The previous examples used only `input` and
    `output`, and the time has come to get introduced to the third section. I already
    prepared an example configuration that can be found in the `roles/logstash/files/file-with-filters.conf`
    file. Its content is as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到过，LogStash的配置由三个主要部分组成：`input`、`output`和`filters`。之前的示例只使用了`input`和`output`，现在是时候介绍第三部分了。我已经准备好了一个示例配置文件，可以在`roles/logstash/files/file-with-filters.conf`文件中找到。它的内容如下：
- en: '[PRE17]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `input` and `output` sections are the same as before. The difference is
    the addition of the `filter`. Just like the other two, we can use one or more
    of the plugins. In this case, we specified that the grok filter plugin should
    be used. If for no other reason, the official description of the plugin should
    compel you to at least try it out.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`input`和`output`部分与之前相同。不同之处在于添加了`filter`。和其他两个部分一样，我们可以使用一个或多个插件。在这个例子中，我们指定了使用grok过滤器插件。如果没有其他理由，至少官方插件描述应该促使你尝试使用它。'
- en: Grok is currently the best way in logstash to parse **crappy unstructured log
    data** into something structured and queryable.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Grok目前是LogStash中解析**混乱的非结构化日志数据**为结构化并可查询数据的最佳方式。
- en: Grok sits on top of regular expressions, and LogStash already comes with quite
    a few patterns. They can be found in the [https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns](https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns)
    repository. In our case, since the log we used matches Apache format that is already
    included, all the had to do is tell LogStash to parse the `message` using the
    `COMBINEDAPACHELOG` pattern. Later on, we'll see how we can combine different
    patterns but, for now, `COMBINEDAPACHELOG` should do.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Grok基于正则表达式，LogStash本身已经包含了很多模式。这些模式可以在[https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns](https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns)库中找到。在我们的例子中，由于我们使用的日志匹配的是Apache格式，这个格式已经包含在内，所以我们只需要告诉LogStash使用`COMBINEDAPACHELOG`模式解析`message`。稍后我们会看到如何组合不同的模式，但目前`COMBINEDAPACHELOG`应该足够用了。
- en: The second filter we'll be using is defined through the date plugin. It will
    transform the timestamp from log entries into LogStash format.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的第二个过滤器是通过日期插件定义的。它将把日志条目的时间戳转换为LogStash格式。
- en: Please explore filter plugins in more details. Chances are you'll find one,
    or more, that suit your needs.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 请更详细地探索过滤器插件。你很可能会找到一个或多个适合你需求的插件。
- en: 'Let''s replace the `file.conf` with the `file-with-filters.conf` file, restart
    LogStash, and see how it behaves:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`file.conf`替换为`file-with-filters.conf`文件，重启LogStash，然后看看它的表现如何：
- en: '[PRE18]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'With the new LogStash configuration, we can add a few more Apache log entries:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新的LogStash配置，我们可以再添加一些Apache日志条目：
- en: '[PRE19]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `docker logs` output of the last entry is as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一条日志的`docker logs`输出如下：
- en: '[PRE20]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As you can see, the message is still there in its entirety. In addition, this
    time we got quite a few additional fields. The `clientip`, `verb`, `referrer`,
    `agent`, and other data, are all properly separated. This will allow us to filter
    logs much more efficiently.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，消息仍然完整显示。此外，这次我们得到了不少额外的字段。`clientip`、`verb`、`referrer`、`agent`以及其他数据都得到了正确的分离。这将使我们能够更高效地过滤日志。
- en: Let's open Kibana running on the address `http://10.100.198.202:5601/`. One
    of the things you'll notice is that Kibana claims that no results are found even
    though we just parsed three log entries. The reason behind that is in the second
    filter that transformed the log timestamp to the LogStash format. Since, by default,
    Kibana displays last 15 minutes of logs, and log entries were made during December
    2015, they are indeed older than 15 minutes. Click on the **Last 15 minutes**
    button located in the top-right corner of the screen, select **Absolute** and
    pick the range starting from December 1st to December 31th, 2015\. That should
    give us all logs made during December 2015.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打开Kibana，地址是`http://10.100.198.202:5601/`。你会注意到的一个问题是，Kibana显示没有找到结果，尽管我们刚刚解析了三条日志。原因在于第二个过滤器将日志时间戳转换为LogStash格式。由于默认情况下，Kibana显示的是最近15分钟的日志，而日志条目是在2015年12月生成的，它们确实超过了15分钟的时间范围。点击屏幕右上角的**Last
    15 minutes**按钮，选择**Absolute**并设置时间范围为2015年12月1日到2015年12月31日。这样我们就能看到2015年12月期间的所有日志。
- en: Click the **Go** button and observe that the three logs we just sent to ElasticSearch,
    through LogStash, are displayed on the screen. You'll notice that many new fields
    are available in the right-hand menu. We'll use them later when we explore Kibana
    filters. For now, the important thing to note is that this time we parsed the
    log entries before sending them to ElasticSearch.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**Go**按钮，观察到我们刚刚通过 LogStash 发送到 ElasticSearch 的三个日志条目已显示在屏幕上。你会注意到右侧菜单中出现了许多新字段。我们稍后会在探索
    Kibana 过滤器时使用这些字段。目前需要注意的是，这一次我们在发送日志条目到 ElasticSearch 之前对其进行了解析。
- en: 'By employing LogStash filters, we improved the data that is stored in ElasticSearch.
    The solution relies on the whole ELK stack being installed on the same server
    where logs are, and we can see all the logs we decided to tail from a single interface
    (Kibana). The problem is that the solution is limited to a single server. If,
    for example, we''d have ten servers, we''d need to install ten ELK stacks. That
    would introduce quite a significant overhead on resources. ElasticSearch is memory
    hungry, and LogStash can grab more CPU than what we would be willing to part from.
    Of equal importance is that, while what we have by now is an improvement, it is
    far from ideal. We would still need to know which server produced a problem and,
    potentially, go from one Kibana to another, when trying to cross-reference different
    services and applications involved:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 LogStash 过滤器，我们改善了存储在 ElasticSearch 中的数据。该解决方案依赖于将整个 ELK 堆栈安装在日志所在的同一台服务器上，并且我们可以通过单一接口（Kibana）查看所有我们决定跟踪的日志。问题在于，该解决方案仅限于单一服务器。例如，如果我们有十台服务器，我们将需要安装十个
    ELK 堆栈。这将引入相当大的资源开销。ElasticSearch 很占用内存，而 LogStash 会消耗更多的 CPU，这是我们不愿意让步的。与此同时，虽然我们目前所做的改进有所帮助，但仍远未理想。我们仍然需要知道哪个服务器产生了问题，并且可能需要在不同的
    Kibana 之间切换，尤其是在尝试交叉参考不同的服务和应用时：
- en: '![Parsing Log Entries](img/B05848_16_02.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![解析日志条目](img/B05848_16_02.jpg)'
- en: Figure 16-02 – ELK stack running on a single server
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16-02 – 在单台服务器上运行的 ELK 堆栈
- en: 'Before I introduce you to the concept of decentralized logs and centralized
    logs parsing, let us remove the LogStash instance and go back to the `cd` node:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在我向你介绍去中心化日志和集中式日志解析的概念之前，让我们先移除 LogStash 实例，并回到 `cd` 节点：
- en: '[PRE21]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Sending Log Entries to a Central LogStash Instance
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将日志条目发送到中央 LogStash 实例
- en: What we did by now is helpful, but it still does not solve the problem of having
    all logs in one place. At the moment, we have all logs from a single server in
    a single location. How can we change that?
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止我们所做的对解决问题有帮助，但仍然无法解决将所有日志集中到一个地方的问题。目前，我们只有单台服务器的所有日志在一个位置。我们该如何改变这一点？
- en: One simple solution would be to install LogStash on each server, and configure
    it to send entries to a remote ElasticSearch. At least, that's how most companies
    I worked with solved it. Should we do the same? The answer is no; we shouldn't.
    The problem lies in LogStash itself. While it is an excellent solution for collecting,
    parsing, and outputting logs, it uses too many resources. Having LogStash installed
    on each and every server would result in a huge waste. Instead, we'll use Filebeat.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一种简单的解决方案是将 LogStash 安装在每台服务器上，并配置它将日志条目发送到远程 ElasticSearch。至少，这就是我与之合作的大多数公司解决问题的方式。我们是否也应该这样做？答案是否定的；我们不应该。问题出在
    LogStash 本身。虽然它是一个用于收集、解析和输出日志的优秀解决方案，但它消耗的资源过多。在每台服务器上都安装 LogStash 会导致资源的巨大浪费。相反，我们将使用
    Filebeat。
- en: Filebeat is a lightweight shipper for log files and represents the next-generation
    of LogStash Forwarder. Just like LogStash, it tails log files. The difference
    is that it is optimized for just tailing and sending logs. It will not do any
    parsing. Another difference is that it is written in Go. Those two things alone
    make it much more resource efficient with such a small footprint that we can safely
    run it on all servers without noticing a significant increase in memory and CPU
    consumption.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Filebeat 是一个轻量级的日志文件传输工具，代表了 LogStash Forwarder 的下一代产品。与 LogStash 一样，它会跟踪日志文件。不同之处在于，它被优化为只负责跟踪和发送日志，不进行任何解析。另一个不同之处是它是用
    Go 语言编写的。这两点使得它比 LogStash 更加高效，占用更少的资源，具有如此小的资源占用，我们可以安全地在所有服务器上运行，而不会显著增加内存和
    CPU 的消耗。
- en: 'Before we see Filebeat in action, we need to change the `input` section of
    our LogStash configuration. The new configuration is located in the `roles/logstash/files/beats.conf`
    file and its content is as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们看到 Filebeat 的实际效果之前，我们需要更改 LogStash 配置中的 `input` 部分。新的配置位于 `roles/logstash/files/beats.conf`
    文件中，内容如下：
- en: '[PRE22]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you can see, the only difference is in the input section. It uses the beats
    plugin that is set to listen to the port `5044`. With this configuration, we can
    run a single LogStash instance, and have all the other servers send their logs
    to this port.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，唯一的区别在于输入部分。它使用了设置为监听端口 `5044` 的 beats 插件。通过此配置，我们可以运行一个 LogStash 实例，并让所有其他服务器将它们的日志发送到这个端口。
- en: 'Let''s deploy LogStash with these settings:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下设置部署 LogStash：
- en: '[PRE23]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'LogStash is now running inside the `logging` server and listening for beats
    packets on port `5044`. Before we proceed and deploy Filebeat on, let''s say,
    the `prod` node, let us take a quick look at the `prod3.yml` playbook:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: LogStash 现在在 `logging` 服务器上运行，并且正在监听端口 `5044` 上的 beats 数据包。在我们继续部署 Filebeat
    到，比如说，`prod` 节点之前，让我们快速看一下 `prod3.yml` playbook：
- en: '[PRE24]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'new addition is the `roles/filebe` `at` role. Its tasks, defined in the `roles/filebeat/tasks/main.yml`
    file, are as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 新增项是 `roles/filebe` `at` 角色。其任务在 `roles/filebeat/tasks/main.yml` 文件中定义，内容如下：
- en: '[PRE25]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The tasks will download the package, install it, copy the configuration, and,
    finally, run the service. The only thing worth looking at is the `r` `oles/filebeat/templates/filebeat.yml`
    configuration file:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这些任务将下载软件包、安装它、复制配置文件，并最终运行服务。唯一值得关注的是 `r` `oles/filebeat/templates/filebeat.yml`
    配置文件：
- en: '[PRE26]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The *filebeat* section specifies a list of prospectors which are used to locate
    and process log files. Each prospector item begins with a dash (`-`) and specifies
    prospector-specific configuration options, including the list of paths that are
    crawled to locate log files. In our case, we're having only one path set to `/var/log/**/*.log`.
    When started, Filebeat will look for all files ending in `.log located in the
    /var/log/*` directory, or any of its subdirectories. Since that happens to be
    the location where most of Ubuntu logs are located, we'll have quite a lot of
    log entries to process.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*filebeat* 部分指定了一个前景程序列表，用于定位和处理日志文件。每个前景程序项以破折号（`-`）开始，并指定特定于前景程序的配置选项，包括用于爬取日志文件的路径列表。在我们的情况下，只有一个路径被设置为
    `/var/log/**/*.log`。当启动时，Filebeat 将查找位于 `/var/log/*` 目录下或其任何子目录中的所有以 `.log` 结尾的文件。由于这个位置正是大多数
    Ubuntu 日志所在的位置，因此我们将处理大量的日志条目。'
- en: The *output* section is used to send log entries to various destinations. In
    our case, we specified LogStash as the only output. Since the current LogStash
    configuration does not have any filtering, we could have set ElasticSearch as
    output, and the result would be the same, but with less overhead. However, since
    it is very likely that we'll add some filters in the future, the output is set
    to logstash.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*output* 部分用于将日志条目发送到各种目标。在我们的例子中，我们指定了 LogStash 作为唯一的输出。由于当前的 LogStash 配置没有任何过滤功能，我们本可以将
    ElasticSearch 设置为输出，结果是相同的，但开销较小。然而，由于未来很可能会添加一些过滤器，因此输出被设置为 LogStash。'
- en: Please note that filters are a blessing and a curse at the same time. They allow
    us to split log entries into easier-to-manage fields. On the other hand, if log
    formats differ too much, you might spend an eternity writing parsers. Whether
    you should use filters, or depend on ElasticSearch filtering capabilities without
    specialized fields, is entirely up to you. I tend to go both ways. If log contains
    an important piece of information (as you will see in one of the following examples),
    filtering logs is a must. If log entries are generic messages without analytical
    value, I skip filtering altogether. With a bit of practice, you'll establish your
    rules.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，过滤器既是福音也是诅咒。它们让我们可以将日志条目拆分成更易于管理的字段。另一方面，如果日志格式差异过大，您可能会花费大量时间编写解析器。是否使用过滤器，或者依赖
    ElasticSearch 的过滤功能而不使用专门字段，完全取决于您。我个人的做法是两者兼顾。如果日志包含重要的信息（正如接下来某些例子所示），过滤日志是必须的。如果日志条目只是一些没有分析价值的普通信息，我则完全跳过过滤。通过一些练习，您会建立起自己的规则。
- en: For more information about configuration options, please consult the [https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-configuration-details.html](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-configuration-details.html)
    page.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 有关配置选项的更多信息，请参考 [https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-configuration-details.html](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-configuration-details.html)
    页面。
- en: Let's run the playbook and see Filebeat in action.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行 playbook，看看 Filebeat 的实际运行情况。
- en: '[PRE27]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Now that Filebeat is running in the `prod` node, we can take a look at logs
    generated by LogStash running on the `logging` server.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 Filebeat 已经在 `prod` 节点上运行，我们可以查看在 `logging` 服务器上运行的 LogStash 生成的日志。
- en: '[PRE28]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The last few lines of the `docker logs` command are as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker logs` 命令的最后几行如下：'
- en: '[PRE29]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: FileBeats sent all the log entries from the `/var/log/` directory in the `prod`
    node to LogStash running in the `logging` server. It did that without breaking
    a sweat and, as a result, we got over 350 log entries stored in ElasticSearch.
    OK, 350 log entries is not something to brag about, but, it there were 350000,
    it would still do it effortlessly.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: FileBeat 将 `prod` 节点中 `/var/log/` 目录下的所有日志条目发送到了 `logging` 服务器上运行的 LogStash。它毫不费力地完成了这一任务，结果是我们在
    ElasticSearch 中存储了超过 350 条日志条目。好吧，350 条日志条目不算值得炫耀，但如果是 350000 条，它也能轻松处理。
- en: Let's confirm that logs reached Kibana. Please open `http://10.100.198.202:5601/`.
    If you see no entries, it means that more than fifteen minutes passed, and you
    should increase the time by clicking the **time selector** button in the top-right
    corner of the screen.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确认日志是否已到达 Kibana。请打开 `http://10.100.198.202:5601/`。如果没有看到任何条目，说明已经过去了超过十五分钟，您需要通过点击屏幕右上角的**时间选择器**按钮来增加时间。
- en: Note
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Please note that every time a new field type is added to ElasticSearch index,
    we should recreate the pattern. We can do that by navigating to the **Settings**
    screen and clicking the **Create** button.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，每次向 ElasticSearch 索引中添加新的字段类型时，我们都应该重新创建模式。可以通过进入**设置**屏幕并点击**创建**按钮来完成。
- en: 'We, again, improved the solution quite a bit. There is a central place where
    logs are parsed (LogStash), stored (ElasticSearch), and explored (Kibana). We
    can plug in any number of servers with Filebeat running on each of them. It will
    tail logs and send them to LogStash:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次大大改进了解决方案。现在有一个中央位置处理日志的解析（LogStash）、存储（ElasticSearch）和查看（Kibana）。我们可以在每台服务器上运行
    Filebeat，并将任意数量的服务器连接到其中。它将尾随日志并将其发送到 LogStash：
- en: '![Sending Log Entries to a Central LogStash Instance](img/B05848_16_03.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![将日志条目发送到中央 LogStash 实例](img/B05848_16_03.jpg)'
- en: Figure 16-03 – ELK stack running on a single server with Filebeat distributed
    to the whole cluster
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16-03 – 在单一服务器上运行 ELK 堆栈，并将 Filebeat 分布到整个集群
- en: 'Let''s up the ante a bit and apply what we learned to Docker containers. Since
    we''ll change the LogStash configuration, let us end this section by removing
    the running instance:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微提高难度，将所学应用于 Docker 容器。由于我们需要更改 LogStash 配置，接下来我们通过移除正在运行的实例来结束本节：
- en: '[PRE30]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Sending Docker Log Entries to a Central LogStash Instance
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将 Docker 日志条目发送到中央 LogStash 实例
- en: Since we are using containers, we can run them with volume sharing the directory
    where the service is writing its logs. Shall we do that? The answer is no and,
    at this time, you probably think that I am continuously leading you from one wrong
    solution to another. What I'm really trying to do is to build the solution step
    by step and, at the same time, show you different paths that you might choose
    to take. My preferred solution does not necessarily have to be adopted by you.
    The more choices you have, the more informed decisions you'll make.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用的是容器，因此可以通过共享服务写入日志的目录来运行容器。我们这样做吗？答案是否定的，这时你可能会觉得我在不断带领你走向错误的解决方案。其实，我真正想做的是一步步构建解决方案，同时向你展示你可能选择的不同路径。我的首选解决方案不一定要被你采用。你有更多的选择，才能做出更明智的决策。
- en: Let's go back to the subject of writing logs to a file and shipping them to
    LogStash. My, strongly subjective, opinion is that all logs, no matter the way
    we package our services, should be sent to standard output or error (`stdout`
    or `stderr`). There are many practical reasons for this opinion which, be it as
    it may, I won't elaborate. I already received quite a few emails from people stating
    that my views and practices are too radical (most of them got a response saying
    that the century changed more than fifteen years ago). I'll just try to avoid
    another war on the logging subject in general terms, and skip to reasons for not
    writing logs to files when services are deployed inside containers. Two of them
    stick from the crowd. First of all, the less we use volumes, the less are containers
    dependent on the host they're running on, and easier it is to move them around
    (either in the case of a failure or for scaling purposes). The second reason is
    that Docker's logging drivers expect logs to be sent to `stdout` and `stderr`.
    By not writing logs to files, we avoid coupling with a server or particular logging
    technology.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到写日志到文件并将其发送到 LogStash 的话题。我的个人强烈观点是，不论我们如何打包服务，所有的日志都应该发送到标准输出或错误（`stdout`
    或 `stderr`）。对于这个观点有很多实际原因，虽然如此，我不会展开讲解。我已经收到了不少邮件，很多人表示我的观点和做法过于激进（大部分邮件的回复是：世纪已经变过十五年以上了）。我只想避免在日志话题上引发更多争论，并跳过在容器内写日志到文件的原因。两个原因在大众中脱颖而出。首先，我们使用卷的次数越少，容器对其运行的主机依赖性就越小，迁移它们也会更容易（无论是出于故障恢复还是扩展目的）。第二个原因是
    Docker 的日志驱动程序期望日志发送到 `stdout` 和 `stderr`。通过不将日志写入文件，我们避免了与服务器或特定日志技术的耦合。
- en: If you are about to send me a hate email stating that log files are a grace
    from heaven, please note that I am referring to their output destination when
    generated inside containers (even though I was applying the rule before I started
    using them).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正打算给我发一封讨厌的邮件，声称日志文件是天赐的恩典，请注意，我指的是在容器内部生成时日志的输出目的地（尽管在开始使用它们之前，我就已经在遵守这一规则）。
- en: What is the alternative to exposing container directory with logs as a volume?
    Docker introduced logging driver feature in its version 1.6\. While it passed
    mostly unnoticed, it is a very cool capability and was a huge step toward creating
    a comprehensive approach to logging in Docker environments. Since then, besides
    the default `json-file` driver, we got `syslog`, `journald`, `gelf`, `fluentd`,
    `splunk`, and `awslogs`. By the time you read this book, new ones might have arrived
    as well.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 曝露容器目录并将日志作为卷挂载的替代方案是什么？Docker 在其 1.6 版本中引入了日志驱动程序功能。虽然这一功能大多数时候未被注意到，但它是一个非常酷的能力，并且是朝着在
    Docker 环境中创建全面日志处理方法迈出的重要一步。从那时起，除了默认的 `json-file` 驱动程序外，我们还拥有了 `syslog`、`journald`、`gelf`、`fluentd`、`splunk`
    和 `awslogs`。等你读到这本书时，可能会有新的日志驱动程序出现。
- en: Now that we decided to use Docker's logging drivers, the question arises which
    one to choose. The GELF driver writes messages in *Greylog Extended Log Format*
    supported by LogStash. If all we need is to store logs generated by our containers,
    this is a good option. On the other hand, if we want not only logs generated by
    services running inside containers but also from the rest of the system, we might
    opt for `JournalD` or `syslog`. In such a case, we'd get truly (almost) complete
    information about everything that happens, not only inside containers but on the
    whole OS level. The latter option (`JournalD` or `syslog`) is preferable when
    there is a substantial available memory for ElasticSearch (more logs equals more
    memory consumption), and that is the one we'll explore deeper. Do not get scared
    by ElasticSearch's need for a lot of memory. With clever cleanups of old data,
    this can be easily mitigated. We'll skip the debate whether `JournalD` is a better
    or worse solution than `syslog`, and use the latter. It does not matter which
    one is your preference since the same set of principles applies to both.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们决定使用 Docker 的日志驱动程序，问题就来了：选择哪个？GELF 驱动程序以 *Greylog 扩展日志格式* 编写消息，这个格式被 LogStash
    支持。如果我们只需要存储容器生成的日志，这是一个不错的选择。另一方面，如果我们不仅希望获取容器内服务生成的日志，还想获取来自整个系统的日志，我们可以选择 `JournalD`
    或 `syslog`。在这种情况下，我们能获得关于所有发生的事件的（几乎）完整信息，不仅仅是容器内的，还包括整个操作系统层面的。后一种选择（`JournalD`
    或 `syslog`）在 ElasticSearch 可用内存充足的情况下更为理想（更多的日志意味着更多的内存消耗），这也是我们将深入探索的内容。不要被 ElasticSearch
    对大量内存的需求吓到，通过巧妙地清理旧数据，这个问题是可以轻松缓解的。我们将跳过关于 `JournalD` 是否比 `syslog` 更好的争论，并选择后者。无论你的偏好是哪个，因为这两者适用相同的原则。
- en: 'This time, we''ll use the `roles/logstash/files/syslog.conf` file as LogStash
    configuration. Let''s go through its sections one by one:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们将使用`roles/logstash/files/syslog.conf`文件作为LogStash配置。让我们逐一查看它的各个部分：
- en: '[PRE31]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The `input` section should be self-explanatory. We're using the `syslog plugin`
    with two settings. The first one adds a type field to all events handled by this
    input. It will help us distinguish logs coming from `syslog`, from those we're
    generating through other methods. The `port` setting states that LogStash should
    listen on `25826` for syslog events.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`input`部分应该不言自明。我们使用的是`syslog插件`，并有两个设置。第一个设置为所有通过此输入处理的事件添加一个`type`字段。它将帮助我们区分来自`syslog`的日志和通过其他方法生成的日志。`port`设置指定LogStash应在`25826`端口监听syslog事件。'
- en: 'The filter section of the config file is a bit more complicated. I decided
    to use it mostly as a way to showcase a fraction of what can be done through filters:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件的过滤部分稍微复杂一些。我决定主要使用它来展示过滤器可以做的一小部分：
- en: '[PRE32]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: It starts with an `if` statement. Docker will send logs to syslog with a value
    of the `program` field set in the `docker/[CONTAINER_ID]` format. We are leveraging
    that fact to distinguish log entries coming from Docker, from those generated
    through some other means. Inside the `if` statement, we are performing a few mutations.
    The first one is the addition of a new field called `container_id` that, for now,
    has the same value as the `program` field. The second mutation is the removal
    of the `docker/` part of that value so that we are left with only container ID.
    Finally, we change the value of the `program` field to `docker`.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 它从一个`if`语句开始。Docker将以`docker/[CONTAINER_ID]`格式将日志发送到syslog。我们利用这一点来区分来自Docker的日志条目和其他方式生成的日志。在`if`语句中，我们进行了一些变更。第一个变更是添加一个新的字段`container_id`，目前它的值与`program`字段相同。第二个变更是移除该值中的`docker/`部分，这样我们就只剩下容器ID。最后，我们将`program`字段的值更改为`docker`。
- en: 'Variables, and their values, before and after mutations, are as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 变量及其值，变更前后的情况如下：
- en: '| Variable name | Value before | Value after |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 变量名称 | 变更前的值 | 变更后的值 |'
- en: '| --- | --- | --- |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `program` | `docker/[CONTAINER_ID]` | `docker` |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| `program` | `docker/[CONTAINER_ID]` | `docker` |'
- en: '| `container_id` | `/` | `[CONTAINER_ID]` |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| `container_id` | `/` | `[CONTAINER_ID]` |'
- en: The second conditional starts by checking whether the `container_id` is set
    to `nginx`. If it is, it parses the message using the `COMBINEDAPACHELOG` pattern
    that we already saw in action and adds to it two new fields called `upstream_address`
    and `upstream_response_time`. Both of those fields also use predefined grok patterns
    `HOSTPORT` and `NOTSPACE`. If you'd like to dive deeper, and take a closer look
    at those patterns, please consult the [https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns](https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns)
    repository. If you are familiar with regular expressions, this should be easy
    to understand (if there is such a thing as easy with RegEx).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个条件语句通过检查`container_id`是否被设置为`nginx`来开始。如果是，它将使用我们之前看到的`COMBINEDAPACHELOG`模式来解析消息，并向其中添加两个新字段，分别为`upstream_address`和`upstream_response_time`。这两个字段也使用了预定义的grok模式`HOSTPORT`和`NOTSPACE`。如果你想深入了解并仔细查看这些模式，可以参考[https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns](https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns)这个仓库。如果你熟悉正则表达式，这应该容易理解（如果正则表达式能算得上容易的话）。
- en: 'Otherwise, you might want to rely on declared names to find the expression
    you need (at least until you learn regular expressions). The truth is that RegEx
    is a very powerful language for parsing text but, at the same time, very hard
    to master:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，你可能需要依赖声明的名称来找到你需要的表达式（至少在你学会正则表达式之前）。事实上，正则表达式是一种非常强大的文本解析语言，但与此同时，它也非常难以掌握：
- en: My wife claimed that my hair went gray at approximately the same time I worked
    on a project that required quite a lot of regular expressions. That is one of
    the few things we agreed on.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我的妻子说，我的头发大约在我处理一个需要大量正则表达式的项目时开始变灰的。这是我们为数不多的共识之一。
- en: Finally, the mutation inside `nginx` conditional transforms `upstream_response_time`
    field from `string` (default) to `float`. We'll use this information later on,
    and will need it to be a number.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`nginx`条件中的变更将`upstream_response_time`字段从`string`（默认）转换为`float`。我们稍后会用到这些信息，因此需要将其转换为数字。
- en: 'The third and the last section of the configuration file is `output`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件的第三个也是最后一个部分是`output`：
- en: '[PRE33]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: It is the same as the previous ones. We're sending filtered log entries to standard
    output and ElasticSearch.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这与之前的任务相同。我们将过滤后的日志条目发送到标准输出和 ElasticSearch。
- en: 'Now that we understand the configuration file, or, at least, pretend that we
    do, we can deploy LogStash one more time through the Ansible playbook `elk.` `yml`:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经理解了配置文件，或者至少假装我们理解了，我们可以通过 Ansible 剧本 `elk.yml` 再次部署 LogStash：
- en: '[PRE34]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now we have LogStash up and running, and configured to use `syslog` as input.
    Let''s remove the currently running `nginx` instance and run it again with Docker
    log driver set to `syslog`. While at it, we''ll also provision the `prod` node
    with `syslog`. The `prod4.yml` playbook that we''ll use is as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经启动并运行了 LogStash，并配置为使用 `syslog` 作为输入。让我们移除当前运行的 `nginx` 实例，并使用 Docker
    日志驱动程序设置为 `syslog` 重新运行它。与此同时，我们还会用 `syslog` 配置 `prod` 节点。我们将使用的 `prod4.yml` 剧本如下：
- en: '[PRE35]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: As you can see, this playbook is similar to the others we used for provisioning
    the `prod` server. The difference is in the `log_to_syslog` variable, and the
    addition of the `rsyslog` role.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个剧本与我们用于配置 `prod` 服务器的其他剧本类似。不同之处在于 `log_to_syslog` 变量，以及 `rsyslog` 角色的添加。
- en: 'The relevant part of the `nginx` tasks defined in the `roles/nginx/tasks/main.`
    `yml` file is as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `roles/nginx/tasks/main.yml` 文件中定义的与 `nginx` 相关的任务如下：
- en: '[PRE36]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The difference is in the addition of `log_driver` and `log_opt` declarations.
    The first one sets Docker log driver to `syslog`. The `log_opt` can be used to
    specify additional logging options, which depend on a driver. In this case, we
    are specifying the `tag`. Without it, Docker would use container ID to identify
    logs sent to syslog. That was, when we query ElasticSearch, it will be much easier
    to find `nginx` entries.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 不同之处在于添加了 `log_driver` 和 `log_opt` 声明。第一个设置 Docker 日志驱动程序为 `syslog`。`log_opt`
    可用于指定额外的日志选项，这取决于驱动程序。在这种情况下，我们指定了 `tag`。没有它，Docker 会使用容器 ID 来标识发送到 syslog 的日志。这样，当我们查询
    ElasticSearch 时，将更容易找到 `nginx` 条目。
- en: 'The `rsyslog` tasks defined in the `roles/rsyslog/tasks/mai` `n.yml` file are
    as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `roles/rsyslog/tasks/main.yml` 文件中定义的 `rsyslog` 任务如下：
- en: '[PRE37]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'It will make sure that `rsyslog` and `logrotate` packages are installed, copy
    the `10-logstash.conf` configuration file, and restart the service. The `roles/rsyslog/templates/10-logstash`
    `.conf` template is as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 它将确保 `rsyslog` 和 `logrotate` 包已安装，复制 `10-logstash.conf` 配置文件，并重启服务。`roles/rsyslog/templates/10-logstash.conf`
    模板如下：
- en: '[PRE38]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Please note that the file is an Ansible's template and that `{{ elk_ip }}` will
    be replaced with the IP. The configuration is dead simple. Everything sent to
    syslog will be re-sent to the LogStash running on the specified IP and port.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，该文件是 Ansible 的模板，`{{ elk_ip }}` 将被替换为实际的 IP 地址。配置非常简单。所有发送到 syslog 的内容都会转发到指定
    IP 和端口上运行的 LogStash。
- en: 'Now we''re ready to remove the currently running `nginx` container and run
    the playbook:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好移除当前运行的 `nginx` 容器并运行剧本：
- en: '[PRE39]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Let''s see what was sent to LogStash:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看发送到 LogStash 的内容：
- en: '[PRE40]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'You should see the syslog entries generated by the system. One of them might
    look as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能看到系统生成的 syslog 条目，其中之一可能如下所示：
- en: '[PRE41]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: We can also explore the same data through Kibana running on `http://10.100.198.20`
    `2:5601/`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过运行在 `http://10.100.198.20:5601/` 上的 Kibana 来查看相同的数据。
- en: 'Let''s see what happens when we deploy our services packed into containers.
    First we''ll enter the `prod` node from which we''ll run the `books-ms` service:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当我们将服务打包成容器并部署时会发生什么。首先，我们将进入 `prod` 节点，并在该节点上运行 `books-ms` 服务：
- en: '[PRE42]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Before we deploy the `books-ms` service, let us take a quick look at the `docker-compose-logg`
    `ing.yml` file:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们部署 `books-ms` 服务之前，让我们快速看一下 `docker-compose-logg-ing.yml` 文件：
- en: '[PRE43]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: As you can see, it follows the same logic as the one we used to provision `nginx`
    with Ansible. The only difference is that, in this case, it is Docker Compose
    configuration. It contains the same `log_driver` and `log_opt` keys.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，它遵循与我们用 Ansible 配置 `nginx` 时相同的逻辑。唯一不同的是，在这种情况下，它是 Docker Compose 配置。它包含相同的
    `log_driver` 和 `log_opt` 键。
- en: 'Now that we understand the changes we had to add to the Docker Compose configuration,
    we can deploy the service:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了需要在 Docker Compose 配置中添加的更改，我们可以部署该服务：
- en: '[PRE44]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Let''s double check that it is indeed running by listing and filtering Docker
    processes:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过列出并过滤 Docker 进程来再次检查它是否确实在运行：
- en: '[PRE45]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Now that the service is up and running, with the `syslog` logging driver, we
    should verify that log entries were indeed sent to LogStash:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在服务已启动并运行，且使用了 `syslog` 日志驱动程序，我们应该验证日志条目是否确实被发送到 LogStash：
- en: '[PRE46]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Part of the output is as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 部分输出如下：
- en: '[PRE47]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Service logs are indeed sent to LogStash. Please notice that LogStash filters
    did what we told them to do. The `program` field was transformed from `docker/books-ms`
    to `docker`, and a new field called `container_id` was created. Since we defined
    `message` parsing only when `container_id` is `nginx`, it stayed intact.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 服务日志确实已发送到 LogStash。请注意，LogStash 过滤器确实按照我们指示的方式执行。`program`字段从`docker/books-ms`转换为`docker`，并且创建了一个名为`container_id`的新字段。由于我们只在`container_id`为`nginx`时定义了解析`message`，所以它保持不变。
- en: 'Let us confirm that `message` parsing is indeed working correctly for log entries
    coming from `nginx`. We''ll need to make a few requests to the proxy, so we''ll
    start by configuring it properly:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确认`message`解析确实对来自`nginx`的日志条目有效。我们需要发出几个请求给代理，所以我们先来正确配置它：
- en: '[PRE48]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: You already used `nginx` configurations and Consul Template, so there is no
    need for an explanation of those commands.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经使用了`nginx`配置和 Consul 模板，因此不需要再解释这些命令。
- en: 'Now that the service is running, is integrated, and is sending logs to LogStash,
    let us generate a few `nginx` log entries by making a few requests:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在服务已经启动并运行，已集成并将日志发送到 LogStash，让我们通过发出几个请求来生成一些`nginx`日志条目：
- en: '[PRE49]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Let''s see what did LogStash receives this time:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这次 LogStash 收到了什么：
- en: '[PRE50]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Part of the output of the `docker logs` command is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker logs`命令的部分输出如下：'
- en: '[PRE51]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: This time, not only that we stored logs coming from containers, but we also
    parsed them. The main reason for parsing `nginx` logs lies in the `upstream_response_time`
    field. Can you guess why? While you think about possible usages of that field,
    let us take a closer look at a few of the features of the *Discover* screen in
    Kibana.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，不仅存储了来自容器的日志，我们还对它们进行了解析。解析`nginx`日志的主要原因在于`upstream_response_time`字段。你能猜到为什么吗？在你思考该字段可能的用途时，让我们仔细看看
    Kibana **Discover** 界面的一些功能。
- en: We generated quite enough logs, so we might, just as well, want to start using
    Kibana filters. Please open `http://10.10` `0.198.202:5601/`. Please change the
    time to, let's say, 24 hours, by clicking the top-right button. That will give
    us plenty of time to play with the few logs we created. Before we jump into filtering,
    please go to the **Settings** screen, and click **Create**. That will refresh
    our index pattern with new fields. When finished, please return to the **Discover**
    screen.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经生成了足够的日志，因此我们可能想开始使用 Kibana 过滤器。请打开`http://10.10` `0.198.202:5601/`。请点击右上角的按钮，将时间更改为，比如说，24
    小时。这将给我们足够的时间来操作我们创建的少量日志。在我们开始过滤之前，请进入**设置**界面，并点击**创建**。这将刷新我们的索引模式，添加新的字段。完成后，请返回到**发现**界面。
- en: 'Let us begin with the left-hand menu. It contains all the available fields,
    found in all logs that match given period. Clicking on any of those fields provides
    us with the list of values it holds. For example, `container_id` contains `books-ms`
    and `nginx`. Next to those values are icons with the magnifying glass. The one
    with the plus sign can be used to filter only entries that contain that value.
    Similarly, the icon with the minus sign can be used to exclude records. Click
    the icon with the plus sign next to `nginx`. As you can see, only log entries
    coming from `nginx` are displayed. The result of applied filters is located in
    the horizontal bar above. Hovering over one of the filters (in this case `container_id:
    "nginx"`), allows us to use additional options to enable, disable, pin, unpin,
    invert, toggle, and remove that filter:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们从左侧菜单开始。它包含所有可用字段，这些字段出现在所有匹配给定时间段的日志中。点击任何一个字段都会显示该字段包含的值列表。例如，`container_id`包含`books-ms`和`nginx`。这些值旁边有一个放大镜图标。带有加号的图标可以用来仅过滤包含该值的条目。类似地，带有减号的图标可以用来排除记录。点击`nginx`旁边的加号图标。正如你所看到的，只有来自`nginx`的日志条目会显示出来。应用的过滤器结果位于上方的横条中。将鼠标悬停在其中一个过滤器（在此为`container_id:
    "nginx"`）上，可以启用、禁用、固定、取消固定、反转、切换和移除该过滤器：'
- en: '![Sending Docker Log Entries to a Central LogStash Instance](img/B05848_16_04.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![将 Docker 日志条目发送到中央 LogStash 实例](img/B05848_16_04.jpg)'
- en: Figure 16-04 – Kibana Discover screen with log entries filtered by container_id
    nginx
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16-04 – Kibana Discover 界面，按 container_id nginx 过滤后的日志条目
- en: At the top of the main frame is a graph with the number of logs distributed
    over the specified period. Below it is a table with log entries. By default, it
    shows the `Time` and the `*_source*` columns. Please click the arrow icon on the
    left side of one of the rows. It expands the row to display all the fields available
    in that log entry. They are a combination of data generated by LogStash and those
    we parsed through its configuration. Each field has the same icons as those we
    found in the left-hand menu.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在主框架的顶部有一个图表，显示指定时间段内的日志数量。其下方是一个包含日志条目的表格。默认情况下，它显示 `时间` 和 `*_source*` 列。请点击某一行左侧的箭头图标，它会展开该行，显示该日志条目中的所有字段。这些字段是
    LogStash 生成的数据与我们通过其配置解析的数据的结合。每个字段都有与左侧菜单中相同的图标。
- en: Through them, we can *filter for value or filter out value*. The third button,
    represented by an icon that looks like a single row table with two columns, can
    be used to *toggle that column in table*. Since default columns are not very useful,
    not to say boring, please toggle `logsource`, `request`, `verb`, `upstream_address`,
    and `upstream_response_time`. Click, again, the arrow, to hide the fields. We
    just got ourselves a nice table that shows some of the most important pieces of
    information coming from `nginx`. We can see that the server where requests are
    made (`logsource`), the address of requests (`request`), the type of requests
    (`verb`), how much it took to receive responses (`upstream_response_time`), and
    where were the requests proxied to (`upstream_address`). If you think the *search*
    you created is useful, you can save it by clicking the **Save Search** button
    located in the top-right part of the screen.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 通过它们，我们可以 *按值筛选或排除值*。第三个按钮，图标像一个带有两列的单行表格，可以用来 *切换表格中的列*。由于默认列并不太有用，更不用说有些无聊了，请切换
    `logsource`、`request`、`verb`、`upstream_address` 和 `upstream_response_time`。再次点击箭头，可以隐藏这些字段。我们就得到了一个漂亮的表格，显示了来自
    `nginx` 的一些最重要的信息。我们可以看到请求所在的服务器（`logsource`），请求的地址（`request`），请求的类型（`verb`），接收响应所花费的时间（`upstream_response_time`），以及请求被代理到哪里（`upstream_address`）。如果你认为你创建的
    *搜索* 有用，可以通过点击位于屏幕右上角的 **保存搜索** 按钮将其保存。
- en: 'Next to it is the **Load Saved Search** button:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 它旁边是 **加载已保存搜索** 按钮：
- en: '![Sending Docker Log Entries to a Central LogStash Instance](img/B05848_16_05.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![将 Docker 日志条目发送到中央 LogStash 实例](img/B05848_16_05.jpg)'
- en: Figure 16-05 – Kibana Discover screen with log entries filtered by container_id
    nginx and custom columns
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16-05 – Kibana Discover 屏幕，显示由 container_id nginx 和自定义列筛选的日志条目
- en: We'll explore **Visualize** and **Dashboard** screens a bit later.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 稍后我们将稍微探索一下 **可视化** 和 **仪表板** 屏幕。
- en: 'Let''s us summarize the flow we have at this moment:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下目前的流程：
- en: Containers are deployed with Docker's logging driver set to `syslog`. With such
    a configuration, Docker redirects everything that is sent to standard output,
    or error (`stdout`/`stderr`), to `syslog`.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器通过 Docker 的日志驱动程序设置为 `syslog`。在这种配置下，Docker 将所有发送到标准输出或错误（`stdout`/`stderr`）的内容重定向到
    `syslog`。
- en: All the log entries, be it from containers or processes deployed through other
    methods, are redirected from syslog to LogStash.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有的日志条目，无论是来自容器还是通过其他方法部署的进程，都从 syslog 重定向到 LogStash。
- en: LogStash receives syslog events, applies filters and transformations, and re-sends
    them to ElasticSearch.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LogStash 接收 syslog 事件，应用过滤器和转换规则，然后将其重新发送到 ElasticSearch。
- en: Everybody is happy, because finding specific log entries is a breeze, and life,
    during office hours, is a bit easier to cope with.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大家都很高兴，因为找到特定的日志条目变得轻松，办公室工作时间也变得更容易应对。
- en: '![Sending Docker Log Entries to a Central LogStash Instance](img/B05848_16_06.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![将 Docker 日志条目发送到中央 LogStash 实例](img/B05848_16_06.jpg)'
- en: Figure 16-06 – ELK stack running on a single server with containers logging
    to syslog
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16-06 – ELK 堆栈在单台服务器上运行，容器日志记录到 syslog
- en: Self-Healing Based on Software Data
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于软件数据的自愈
- en: 'Let us put the response time we are logging through `nginx` to a good use.
    Since data is stored in ElasticSearch, we might do a few quick examples of using
    its API. We can, for instance, retrieve all entries stored inside the `logstash`
    index:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们充分利用通过 `nginx` 记录的响应时间。由于数据存储在 ElasticSearch 中，我们可以做一些快速的 API 示例。我们可以，例如，检索存储在
    `logstash` 索引中的所有条目：
- en: '[PRE52]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Elastic search returned the first ten entries (default page size), together
    with some additional information, like the total number of records. There''s not
    much use in retrieving all the entries, so let us try to narrow it down. We can,
    for example, request all records that have `nginx` as `container_id` value:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 'ElasticSearch 返回了前十条记录（默认的页面大小），并附带了一些额外的信息，比如总记录数。检索所有条目没有太大意义，因此让我们尝试缩小范围。例如，我们可以请求所有`container_id`值为`nginx`的记录：  '
- en: '[PRE53]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The results are the same three entries we observed from LogStash logs. Again,
    there's not much use of them. If this were a production system, we would get thousands
    upon thousands of results (distributed among multiple pages).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '结果与我们从 LogStash 日志中观察到的三个条目相同。同样，这些条目没有太大用处。如果这是一个生产系统，我们将得到成千上万的结果（分布在多个页面中）。  '
- en: 'This time, let us try something truly useful. We''ll analyze data and, for
    example, retrieve the average response time from `nginx` logs:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '这次，让我们尝试一些真正有用的东西。我们将分析数据，举个例子，从`nginx`日志中提取平均响应时间：  '
- en: '[PRE54]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output of the last command is as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '上一条命令的输出如下：  '
- en: '[PRE55]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: With something like that request, we can extend our self-healing system and,
    for example, retrieve average response time of a service during last hour. If
    responses were, on average, slow, we could scale the service. Similarly, if responses
    were fast, we can descale it.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '通过类似的请求，我们可以扩展我们的自愈系统，例如，检索服务在过去一小时的平均响应时间。如果平均响应时间较慢，我们可以进行扩容。同样，如果响应较快，我们可以进行缩容。  '
- en: Let's filter the results so that only those made by `nginx`, with a request
    to `/api/v1/books` (the address of our service), and created during the last hour,
    are retrieved. Once data is filtered, we'll aggregate all the results and get
    the average value of the `upstream_response_time` field.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们筛选结果，只返回那些由`nginx`生成的、请求路径为`/api/v1/books`（我们服务的地址）并且是在过去一小时内生成的记录。一旦数据被筛选，我们将汇总所有结果，得到`upstream_response_time`字段的平均值。  '
- en: 'The chances are that more than one hour passed since you sent a request to
    the service through `nginx`. If that''s the case, the resulting value would be
    `null` since there are no records that would match the filter we are about to
    make. We can easily fix that, by making, let''s say, a hundred new requests:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '你发送请求到服务通过`nginx`时，可能已经过去了超过一个小时。如果是这种情况，结果值会是`null`，因为没有任何记录符合我们将要做的筛选条件。我们可以通过发送，比如说，一百个新的请求，轻松解决这个问题：  '
- en: '[PRE56]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Now that we have recent data, we can ask ElasticSearch to give us the average
    response time:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '现在我们有了最新的数据，可以请求 ElasticSearch 给我们返回平均响应时间：  '
- en: '[PRE57]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The ElasticSearch API and the Lucene engine used in the background are so vast
    that it would require a whole book to describe it, so the explanation is out of
    the scope of this book. You can find detailed information in the [https://www.elastic.co/guide/en/elasticsearch/reference/current/docs.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs.html)
    page.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 'ElasticSearch API 和后台使用的 Lucene 引擎庞大到需要一本书来描述，因此解释超出了本书的范围。你可以在[https://www.elastic.co/guide/en/elasticsearch/reference/current/docs.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs.html)页面找到详细信息。  '
- en: 'The output of the request will vary from one case to another. My result was
    as follows:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '请求的输出会因情况而异。我的结果如下：  '
- en: '[PRE58]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: We can now take this response time and, depending on the rules we set, scale,
    descale, or do nothing. Right now we have all the elements to extend our self-healing
    system. We have the process that stores response times in ElasticSearch and the
    API to analyze data. We can create one more Consul watch that will, periodically,
    query the API and, if an action is needed, send a request to Jenkins to prevent
    the disease from spreading. I'll leave that to you, as a few exercises.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '我们现在可以根据响应时间，并依据设定的规则，进行扩容、缩容或不做任何操作。现在，我们已经具备了扩展自愈系统的所有要素。我们有存储响应时间到 ElasticSearch
    的过程和用于分析数据的 API。我们可以创建一个新的 Consul watch，它会定期查询 API，如果需要采取行动，就向 Jenkins 发送请求，防止故障蔓延。我将这部分留给你作为练习。  '
- en: Note
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '注意  '
- en: '**Exercise: Scaling the service if response time is too long**'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习：如果响应时间过长，则扩容服务**'
- en: Create a new Consul watch that will use the ElasticSearch request we created,
    and invoke a Jenkins job that will scale the service if the average response time
    is too long. Similarly, descale the service if the response time is too short,
    and more than two instances are running (less than two poses a downtime risk).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的Consul监视器，使用我们创建的ElasticSearch请求，并调用Jenkins任务，如果平均响应时间过长，则扩展服务。如果响应时间过短，并且运行了两个以上实例，则进行缩容（少于两个实例存在停机风险）。
- en: Without introducing more complexity, we can try other types of future predictions.
    We can, for example, predict the future by observing the previous day.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在不引入更多复杂性的情况下，我们可以尝试其他类型的未来预测。例如，我们可以通过观察前一天的数据来预测未来。
- en: Note
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Exercise: Predict the future by observing the past**'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习：通过观察过去来预测未来**'
- en: Repeat the process from the previous exercise with the different analysis.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 重复上一个练习的过程，进行不同的分析。
- en: '**Variables:**'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '**变量：**'
- en: 'T: The current time'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: T：当前时间
- en: 'AVG1: Average traffic between T and T+1h of the previous day.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AVG1：前一天T到T+1小时之间的平均流量。
- en: 'AVG2: Average traffic between T+1h and T+2h of the previous day.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AVG2：前一天T+1小时到T+2小时之间的平均流量。
- en: '**The task:**'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '**任务：**'
- en: Calculate the increase (or the decrease) of the traffic between `AVG1` and `AVG2`.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算`AVG1`和`AVG2`之间流量的增减。
- en: Decide whether to scale, de-scale, or do nothing.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决定是否进行扩容、缩容，或者什么都不做。
- en: We do not need to base our analysis only on the previous day. We can also evaluate
    the same day of the preceding week, of the past month, or even of the last year.
    Do we have an increase in traffic every first day of the month? What happened
    on Christmas day last year? Do people visit our store less after summer vacations?
    The beauty is not only that we have the data to answer those questions, but we
    can incorporate the analysis into the system and run it periodically.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要仅仅依赖前一天的数据来进行分析。我们还可以评估前一周的同一天、上个月的同一天，甚至是去年的同一天。每个月的第一天我们的网站流量是否增加？去年圣诞节发生了什么？暑假过后，人们是否更少访问我们的商店？美妙之处在于，我们不仅拥有回答这些问题的数据，而且还可以将分析整合到系统中，并定期运行。
- en: Bear in mind that some of the analysis are better of running as Consul watches,
    while the others belong to Jenkins. Tasks that should be run periodically with
    the same frequency are good use cases for Consul. While they can run as easily
    from Jenkins, Consul is more lightweight, and will use fewer resources. Examples
    would be every hour or every 5 minutes. On the other hand, Consul does not have
    a proper scheduler. If you'd like to run analysis at specific moments in time,
    Jenkins with its cron-like scheduler is a better fit. Examples would be each day
    at midnight, each first day of a month, two weeks before Christmas, and so on.
    You should evaluate both tools for each given case, and choose the one that fits
    better. An alternative would be to run all such analysis from Jenkins and benefit
    from having everything in one place. Then again, you might opt for an entirely
    different set of tools. I'll leave the choice to you. The importance lies in understanding
    the process and the goals we want to accomplish.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，有些分析最好作为Consul监视器来运行，而其他则属于Jenkins任务。那些需要定期以相同频率运行的任务适合使用Consul。虽然它们也可以轻松地从Jenkins运行，但Consul更轻量，资源占用更少。例如，每小时或每5分钟运行一次。另一方面，Consul没有合适的调度程序。如果你希望在特定的时间点运行分析，Jenkins及其类似cron的调度程序更为合适。例如，每天午夜、每个月的第一天、圣诞节前两周等等。你应该根据具体情况评估这两种工具，并选择更合适的一个。另一种选择是将所有此类分析都从Jenkins运行，这样你可以将一切集中在一个地方。或者，你可能会选择一整套不同的工具。我将这个选择留给你。重要的是理解整个过程以及我们想要实现的目标。
- en: Please note that I provided one example that can be used as a self-healing process.
    Response times analysis does not have to be the only thing we do. Look at the
    data you can collect, decide what is useful, and what isn't, and make other types
    of data crunching. Collect everything you need, but not more. Do not fall into
    the trap of storing all you can think of, without using it. That is a waste of
    memory, CPU, and hard disk space. Do not forget to set up a process that periodically
    cleans data. You won't need all the logs from a year ago. Heck, you probably won't
    need most of the logs older than a month. If a problem is not found within thirty
    days, the chances are that there is no problem and, even if there is, it relates
    to an old release not running anymore. If, after reading this book, your release
    cycle lasts for months, and you are not planning to shorten it, I failed miserably.
    Please do not send me an email confirming this. It would only make me feel depressed.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我提供了一个可以用作自愈过程的示例。响应时间分析不必是我们唯一要做的事情。看看你可以收集的数据，决定哪些是有用的，哪些没有用，然后进行其他类型的数据处理。收集你需要的一切，但不要过多。不要陷入存储所有能想到的数据而不使用它的陷阱。那样会浪费内存、CPU和硬盘空间。别忘了设置一个定期清理数据的过程。你不需要一年前的所有日志。天哪，你可能连一个月前的日志都不需要。如果一个问题在三十天内没有被发现，那很可能是没有问题，甚至即使有，也是与不再运行的旧版本相关的。如果在读完这本书后，你的发布周期仍然持续几个月，而且你不打算缩短它，那我真是彻底失败了。请不要给我发电子邮件确认这点，这只会让我感到沮丧。
- en: That was a short detour from the main subject of the chapter (logging and monitoring).
    Since the book is mostly based on hands-on examples, I could not explain *self-healing
    based on historical response times* without having data to work with. Therefore,
    this discussion was added here. Throughout the rest of this chapter, there will
    be at one more excursion into a subject that might just as well belong to the
    [Chapter 15](ch15.html "Chapter 15. Self-Healing Systems"), *Self-Healing Systems*
    chapter. Now, let's get back to logging and monitoring.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是从本章（日志记录与监控）主旨的一个短暂岔路。由于本书主要基于实践示例，我无法在没有数据的情况下解释*基于历史响应时间的自愈*。因此，这段讨论被加在这里。在本章的其余部分，将会有至少一次涉及可能本应属于[第15章](ch15.html
    "第15章 自愈系统")，*自愈系统*章节的内容。现在，我们回到日志记录与监控的主题。
- en: Since we have all the information representing the past and the present status
    of the cluster, we can... This is the moment I imagine you, dear reader, rolling
    your eyes and mumbling to yourself that software logs do not constitute the full
    information about the cluster. Only software (logs), together with hardware data
    (metrics), can be close to a complete information about the cluster. Then again,
    my imagination might not (and often doesn't) represent reality. You might not
    have rolled your eyes, or even noticed that hardware is missing.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们拥有表示集群过去和当前状态的所有信息，我们可以……在这一刻，我想象你，亲爱的读者，正在翻白眼并低声抱怨，认为软件日志并不能构成集群的完整信息。只有软件（日志）和硬件数据（指标）结合起来，才能接近关于集群的完整信息。再说一次，我的想象力可能并不（而且经常不）代表现实。你可能没有翻白眼，甚至没有注意到硬件数据的缺失。
- en: If that's the case, you are not paying close attention to what I wrote, and
    should have a good night sleep, or, at least, grab a coffee. Truth be told, we
    do have hardware information in Consul, but that is only the current status. We
    cannot analyze that data, see tendencies, find out why something happened, nor
    predict the future. If you are still awake, let's look at how we can log hardware
    status.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是这样，你没有仔细阅读我写的内容，应该好好休息一下，或者，至少去喝杯咖啡。说实话，我们确实在Consul中有硬件信息，但那只是当前状态。我们无法分析这些数据，看到趋势，了解发生了什么，也无法预测未来。如果你还没入睡，我们来看看如何记录硬件状态。
- en: 'Before we move on, we''ll remove the currently running LogStash instance, and
    exit the prod node:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，我们将移除当前正在运行的LogStash实例，并退出生产节点：
- en: '[PRE59]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Logging Hardware Status
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 记录硬件状态
- en: One of the first things they teach you when starting to learn to work on computers
    is that software runs on hardware. A software cannot run without hardware and
    hardware is useless without software. Since they are dependent on each other,
    any attempt to collects the information about the system needs to include both.
    We explored some of the ways to gather software data, so the next step is to try
    to accomplish a similar result with hardware.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始学习计算机操作时，最先教你的一件事就是软件运行在硬件上。没有硬件，软件无法运行；没有软件，硬件也没有用。由于它们相互依赖，任何收集系统信息的尝试都需要包括这两者。我们已经探索了一些收集软件数据的方法，接下来的步骤是尝试用硬件实现类似的结果。
- en: We need a tool that will collect statistics about the system it is running on
    and has the flexibility to send that information to LogStash. Once we find and
    deploy such a tool, we can start using statistics it provides to find past and
    current performance bottlenecks and predict future system requirements. Since
    LogStash will send the information received from that tool to ElasticSearch, we
    can create formulas that will allow us to perform performance analysis and capacity
    planning.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个工具来收集其运行系统的统计信息，并且具有将这些信息发送到LogStash的灵活性。一旦我们找到并部署了这样的工具，我们就可以开始使用它提供的统计数据，找出过去和现在的性能瓶颈，并预测未来的系统需求。由于LogStash将把从该工具接收到的信息发送到ElasticSearch，我们可以创建公式，从而执行性能分析和容量规划。
- en: One such tool is CollectD. It is free open source project written in C, making
    it high performant and very portable. It can easily handle hundreds of thousands
    of data sets, and it comes with over ninety plugins.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个工具是CollectD。它是一个免费的开源项目，使用C语言编写，使其性能高效且具有很强的可移植性。它可以轻松处理成千上万的数据集，并且自带超过90个插件。
- en: 'Luckily for us, LogStash has the CollectD input plugin that we can use to receive
    its events through a UDP port. We''ll use (`roles/logstash/files/syslog-collectd.conf`)[[https://github.com/vfarcic/ms-lifecycle/blob/master/ansible/roles/logstash/files/syslog-collectd.conf](https://github.com/vfarcic/ms-lifecycle/blob/master/ansible/roles/logstash/files/syslog-collectd.conf)]
    file to configure LogStash to accept *CollectD* input. It is a copy of the (`roles/logstash/files/syslog.conf`)[`https://github.com/vfarcic/ms-lifecycle/blob/master/ansible/roles/logstash/files/syslog.conf`]
    with an additional input definition. Let''s take a look at its `input` section:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，LogStash有一个CollectD输入插件，我们可以使用它通过UDP端口接收事件。我们将使用（`roles/logstash/files/syslog-collectd.conf`）[[https://github.com/vfarcic/ms-lifecycle/blob/master/ansible/roles/logstash/files/syslog-collectd.conf](https://github.com/vfarcic/ms-lifecycle/blob/master/ansible/roles/logstash/files/syslog-collectd.conf)]文件来配置LogStash以接收*CollectD*输入。它是（`roles/logstash/files/syslog.conf`）[`https://github.com/vfarcic/ms-lifecycle/blob/master/ansible/roles/logstash/files/syslog.conf`]的副本，增加了一个输入定义。让我们来看一下它的`input`部分：
- en: '[PRE60]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: As you can see, all we did was add a new input that listens on the UDP port
    `25827`, set buffer size, define that `collectd` codec should be used, and added
    a new field called type. With the value from the type field, we can distinguish
    `syslog` logs from those coming from `collectd`.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，我们所做的只是添加了一个新的输入，该输入监听UDP端口`25827`，设置了缓冲区大小，定义了应使用`collectd`编解码器，并添加了一个名为type的新字段。通过type字段的值，我们可以将`syslog`日志与来自`collectd`的日志区分开来。
- en: 'Let''s run the playbook that will provision the `logging` server with LogStash
    and configure it to accept both `syslog` and `collectd` input:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行将配置`logging`服务器并安装LogStash的playbook，并将其配置为接收`syslog`和`collectd`输入：
- en: '[PRE61]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: You might have noticed the usage of the `restore_backup` variable. One of *kibana*
    tasks is to restore an ElasticSearch backup with the definitions of Kibana Dashboards
    that will be discussed soon. Backup is restored through the `vfarcic/elastic-dump`
    container containing a nifty tool called `elasticsearch-dump` by *taskrabbit*.
    It can be used to create and restore ElasticSearch backups.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到使用了`restore_backup`变量。*kibana*的任务之一是通过`vfarcic/elastic-dump`容器恢复一个ElasticSearch备份，该备份包含Kibana仪表板的定义，稍后将讨论。备份通过包含由*taskrabbit*开发的`elasticsearch-dump`工具的`vfarcic/elastic-dump`容器恢复。该工具可用于创建和恢复ElasticSearch备份。
- en: 'Now that LogStash is configured to accept `CollectD` input, let''s turn our
    attention to the `prod` server, and install `Co` `llectD`. We''ll use the `prod5.yml`
    playbook that, in addition to the tools we used before, contains the `collectd`
    role. The tasks are defined in the (`roles/collectd/tasks/main.yml`)[[https://github.com/vfarcic/ms-lifecycle/tree/master/ansible/roles/collectd/tasks/main.yml](https://github.com/vfarcic/ms-lifecycle/tree/master/ansible/roles/collectd/tasks/main.yml)]
    file. Its content is as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 LogStash 已配置为接受 `CollectD` 输入，让我们将注意力转向 `prod` 服务器，并安装 `CollectD`。我们将使用 `prod5.yml`
    剧本，该剧本除了我们之前使用的工具外，还包含了 `collectd` 角色。任务定义在（`roles/collectd/tasks/main.yml`）[[https://github.com/vfarcic/ms-lifecycle/tree/master/ansible/roles/collectd/tasks/main.yml](https://github.com/vfarcic/ms-lifecycle/tree/master/ansible/roles/collectd/tasks/main.yml)]
    文件中。其内容如下：
- en: '[PRE62]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'By this time, you should probably consider yourself an expert in Ansible, and
    do not need an explanation of the role. The only thing worth commenting is the
    `roles/collectd/files/collectd.conf` template that represents the `CollectD` configuration.
    Let''s take a quick look at it:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 到这时，你可能已经可以认为自己是 Ansible 的专家，不再需要解释角色了。唯一值得评论的是 `roles/collectd/files/collectd.conf`
    模板，它代表了 `CollectD` 配置。我们快速看一下：
- en: '[PRE63]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: It starts by defining the hostname through the Ansible variable `ansible_hostname`,
    followed by the load of the plugins we'll use. Their names should be self-explanatory.
    Finally, few of the plugins have additional configurations. Please consult [https://collectd.org/documentation.shtml](https://collectd.org/documentation.shtml)
    documentation for more information about configuration format, all the plugins
    you can use, and their settings.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 它首先通过 Ansible 变量 `ansible_hostname` 定义主机名，接着加载我们将使用的插件。它们的名称应该是不言自明的。最后，一些插件有额外的配置。有关配置格式、可用插件及其设置的更多信息，请参阅
    [https://collectd.org/documentation.shtml](https://collectd.org/documentation.shtml)
    文档。
- en: 'Let''s run the playbook:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行剧本：
- en: '[PRE64]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Now that `CollectD` is running, we can give it a few seconds to kick in and
    take a look at LogStash logs:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 `CollectD` 正在运行，我们可以稍等几秒钟，看看 LogStash 日志：
- en: '[PRE65]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'A few of the entries are as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 其中的一些条目如下：
- en: '[PRE66]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: From that output, we can see that CollectD sent information about memory. The
    first entry contains `used`, the second `buffered`, the third `cached`, and, finally,
    the fourth represents `free` memory. Similar entries can be seen from the other
    plugins. CollectD will periodically repeat the process, thus allowing us to analyze
    both historical and near real-time tendencies and problems.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中，我们可以看到 CollectD 发送了关于内存的信息。第一个条目包含 `used`，第二个包含 `buffered`，第三个包含 `cached`，最后，第四个代表
    `free` 内存。从其他插件也可以看到类似的条目。CollectD 会定期重复这个过程，从而使我们能够分析历史和近乎实时的趋势和问题。
- en: Since CollectD generated the new fields, let us recreate index pattern by opening
    `http://10.100.198.202:5601/`, navigating to the **Settings** screen, and clicking
    the **Create** button.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 CollectD 生成了新的字段，让我们通过打开 `http://10.100.198.202:5601/`，导航到 **Settings** 屏幕，并点击
    **Create** 按钮，重新创建索引模式。
- en: 'While there are many reasons to visit Kibana''s **Discover** screen for software
    logs, there are only a few, if any, to use it for CollectD metrics, so we''ll
    concentrate on Dashboards. That being said, even if we are not going to look at
    hardware data from this screen, we still need to create searches required for
    visualization. An example search that would retrieve all records from `collectd`,
    made in the `prod` host, through the `memory` plugin, would be as follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有许多理由访问 Kibana 的 **Discover** 屏幕查看软件日志，但很少有理由使用它来查看 CollectD 指标，因此我们将重点关注仪表板。话虽如此，即使我们不打算在此屏幕上查看硬件数据，我们仍然需要创建用于可视化的搜索。以下是一个示例搜索，它将检索所有来自
    `prod` 主机，通过 `memory` 插件生成的 `collectd` 记录：
- en: '[PRE67]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: That line can be written (or pasted) to the *search* field in the **Discover**
    screen, and it will return all data matching that filter and the time set in the
    top-right corner of the screen. The backup we restored already contained a few
    saved searches that can be opened through the **Open Saved Search** button in
    the top-right corner of the screen. With those searches, we can proceed to visualizations.
    As an example, please open the `prod-df` saved search.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 该行可以写入（或粘贴）到 **Discover** 屏幕上的 *search* 字段中，它将返回与该过滤器和屏幕右上角设定的时间匹配的所有数据。我们恢复的备份已经包含了一些可以通过右上角的
    **Open Saved Search** 按钮打开的保存搜索。通过这些搜索，我们可以继续进行可视化操作。例如，请打开 `prod-df` 保存的搜索。
- en: 'Kibana Dashboards consist of one or more visualizations. They can be accessed
    by clicking the **Visualize** button. When you open the **Visualize** screen,
    you''ll see different types of graphs you can choose to create a new visualization.
    Since we restored a backup with a few visualizations I prepared, you can load
    one by clicking it from the **open a saved visualization** section located at
    the bottom of the screen. Please note that this screen appears only the first
    time and, from there on, the same action can be accomplished by the **Load Saved
    Visualization** button located on the top-right side of the screen. Go ahead and
    play a bit with Kibana visualizations. Once you''re done, we''ll move to dashboards:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana 仪表板由一个或多个可视化图表组成。点击 **Visualize** 按钮可以访问它们。当你打开 **Visualize** 页面时，你将看到不同类型的图表，可以选择创建一个新的可视化图表。由于我们已经恢复了一个包含我准备的几个可视化图表的备份，你可以通过点击屏幕底部的
    **open a saved visualization** 部分来加载其中之一。请注意，这个页面只会在第一次出现，从此以后，同样的操作可以通过屏幕右上角的
    **Load Saved Visualization** 按钮完成。继续试试 Kibana 可视化图表吧。完成后，我们将继续进入仪表板：
- en: '![Logging Hardware Status](img/B05848_16_07.jpg)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![Logging Hardware Status](img/B05848_16_07.jpg)'
- en: Figure 16-07 – Kibana visualization of hard disk usage
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16-07 – Kibana 磁盘使用情况可视化图
- en: Dashboard can be opened from the top menu. The backup we restored contains one
    so let's use it to see CollectD in action. Please click the **Dashboard** button,
    followed by the **Load Saved Dashboard** icon, and select the `prod` dashboard.
    It will display visualizations with one (and the only) *CPU* (`prod-cpu-0`), *hard
    disk* (`prod-df`), and *memory* (`prod-memory`) usage inside the `prod` VM. CollectD
    offers many more plugins than those we used. With more information coming in,
    this dashboard can be made much more colorful, not to say useful.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板可以从顶部菜单打开。我们恢复的备份包含了一个仪表板，所以我们用它来查看 CollectD 的实际情况。请点击 **Dashboard** 按钮，然后点击
    **Load Saved Dashboard** 图标，选择 `prod` 仪表板。它将展示 `prod` 虚拟机内的一个（也是唯一的）*CPU*（`prod-cpu-0`）、*硬盘*（`prod-df`）和
    *内存*（`prod-memory`）的使用情况。CollectD 提供了比我们使用的更多插件。随着更多数据的输入，这个仪表板可以变得更加丰富多彩，甚至更有用。
- en: 'However, even though the dashboard we created does not have much activity,
    you can probably imagine how it could be transformed into an indispensable tool
    for monitoring the cluster status. There could be a separate dashboard for each
    server, one for the whole cluster, and so on:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管我们创建的仪表板活动不多，你大概可以想象它如何转变为一个不可或缺的工具，用于监控集群状态。可以为每个服务器创建一个单独的仪表板，也可以有一个展示整个集群状态的仪表板，等等：
- en: '![Logging Hardware Status](img/B05848_16_08.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![Logging Hardware Status](img/B05848_16_08.jpg)'
- en: Figure 16-08 – Kibana dashboard with CPU, hard disk, and memory usage over time
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16-08 – Kibana 仪表板，展示 CPU、硬盘和内存使用情况随时间变化
- en: That was the basis of your future hardware monitoring dashboard. What else can
    with do with hardware information (besides looking at dashboards)?
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你未来硬件监控仪表板的基础。除了查看仪表板外，我们还可以用硬件信息做些什么呢？
- en: Self-Healing Based on Hardware Data
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于硬件数据的自愈功能
- en: Using hardware data for self-healing is as important as software information.
    Now that we have both, we can extend our system. Since we already went through
    all the tools and practices required for such a system, there is no real need
    for us to go through them in the hardware context. Instead, I'll just give you
    a few ideas.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 使用硬件数据进行自愈与使用软件信息一样重要。现在我们有了这两者，我们可以扩展我们的系统。既然我们已经了解了构建这样一个系统所需的所有工具和实践，就不必在硬件上下文中再逐一讲解了。相反，我将为你提供一些思路。
- en: Consul is already monitoring hardware utilization. With historical data in ElasticSearch,
    we can predict not only that the warning threshold is reached (for example 80%),
    but when it will get critical (for example 90%). We can analyze the data and see
    that, for instance, during last 30 days, disk utilization was increasing by an
    average rate of 0.5%, meaning that we have twenty days until it reaches the critical
    state. We could also draw a conclusion that even through the warning threshold
    is reached, it was a one time deal, and the available space is not shrinking anymore.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: Consul 已经在监控硬件利用率。通过 ElasticSearch 中的历史数据，我们不仅可以预测警告阈值的到达时间（例如 80%），还可以预测其何时变得危急（例如
    90%）。我们可以分析数据，看到例如，在过去的 30 天里，磁盘利用率平均增加了 0.5%，这意味着我们还有二十天的时间，直到它达到临界状态。我们还可以得出一个结论，尽管警告阈值已经达到，但这只是一次性事件，剩余空间不再收缩。
- en: We could combine software and hardware metrics. With only software data, we
    might conclude that at peak hours, when traffic increases, we need to scale our
    services, by adding hardware we might change that opinion after realizing that
    the problem was actually in the network that cannot support such a load.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以结合软件和硬件指标。仅仅依靠软件数据，我们可能会得出结论：在高峰时段，随着流量增加，我们需要扩展服务。但通过增加硬件后，我们可能会改变这个看法，因为我们意识到问题其实出在网络上，无法承载如此大的负载。
- en: Analysis combinations we can create are limitless, and the number of formulas
    we'll create will grow with time and experience. Every time we pass through one
    door, another one opens.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建的分析组合是无限的，我们将创建的公式数量将随着时间和经验的积累而增长。每当我们走过一扇门，另一扇门就会打开。
- en: Final Thoughts
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最后的思考
- en: This is my favorite chapter. It combines most of the practices we learned throughout
    the book into a grand finale. Almost everything happening on a server, be it software
    or hardware, system programs or those we deployed, is sent to LogStash and, from
    there, to ElasticSearch. And it's not only one server. With a simple `rsyslog`
    and `collectd` configurations applied to all your nodes, the whole cluster will
    be sending (almost) all the logs and events. You'll know who did what, which processes
    started, and which were stopped. You'll be aware what was added, and what was
    removed. You be alerted when a server is low on CPU, which one is about to get
    its hard disk full, and so on. You'll have the information about every service
    you deploy or remove. You'll know when were containers scaled, and when descaled.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我最喜欢的一章。它将我们在全书中学到的大多数实践结合在一起，形成了一个盛大的结局。几乎所有发生在服务器上的事情，无论是软件还是硬件，系统程序还是我们部署的程序，都被发送到LogStash，然后再传送到ElasticSearch。而且这不仅仅是一个服务器。通过将简单的`rsyslog`和`collectd`配置应用到所有节点，整个集群几乎会发送所有的日志和事件。你将知道谁做了什么，哪些进程被启动，哪些被停止。你会知道什么被添加，什么被移除。当某台服务器CPU不足时，你会收到警报，哪台服务器的硬盘快满了，你也会知道。当你部署或移除服务时，你将获得相关信息。你将知道容器何时进行了扩展，又何时进行了缩减。
- en: 'We created a logging and monitoring system that can be described through the
    following figure:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个日志记录和监控系统，可以通过以下图示来描述：
- en: '![Final Thoughts](img/B05848_16_09.jpg)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![最后的思考](img/B05848_16_09.jpg)'
- en: Figure 16-09 – Kibana dashboard with CPU, hard disk, and memory usage over time
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 图16-09 – Kibana仪表板，显示了CPU、硬盘和内存使用情况随时间的变化
- en: Knowing everything is a worthy goal and, with a system we designed, you are
    one step closer to fulfilling it. On top of knowing everything about the past
    and the present, you made the first step towards knowing the future. If you combine
    the practices from this chapter with those we learned in the [Chapter 15](ch15.html
    "Chapter 15. Self-Healing Systems"), *Self-Healing Systems*, your systems will
    be able to recuperate from failures and, in many cases, prevent a disease from
    happening in the first place.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 了解一切是一个值得追求的目标，借助我们设计的系统，你离实现这一目标又近了一步。除了了解过去和现在的一切，你还迈出了了解未来的第一步。如果你将本章中的实践与我们在[第15章](ch15.html
    "第15章 自愈系统")，*自愈系统*，中学到的内容相结合，你的系统将能够从故障中恢复，而且在许多情况下，能从根本上防止故障发生。
- en: 'Let us finish with some cleaning:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们结束时做一些清理工作：
- en: '[PRE68]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
