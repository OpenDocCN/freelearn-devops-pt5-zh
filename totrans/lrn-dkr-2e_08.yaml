- en: The Docker Platform – Distinct Capabilities and Use Cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Without any doubt, IT is the most happening and highly visible domain at any
    point in time. As every kind of enterprising business (small, medium, and large)
    is being enabled through the delectable advancements in the IT space, there is
    a direct and decisive relationship between IT and business. With the IT budgets
    being pruned by business behemoths year after year due to the stagnant, even sliding,
    world economy, it is a clear-cut mandate and timely reminder for IT professionals
    to do more with less. That is, there is a continued insistence for deeper and
    deft automation of various business operations by methodically leveraging the
    proven and promising technologies, tools, and tips. Infrastructure optimization
    through hybrid clouds, process excellence through integration and orchestration
    techniques, the fast spread of the DevOps culture, the foundational aspect of
    compartmentalization through virtualization and containerization approaches, the
    penetrative, pervasive, and persuasive nature of APIs, the fast emergence of MSA,
    the cognitive analytics, and so on, are being overwhelmingly recognized and reaped
    as the dominant and prominent ways forward toward business agility, affordability,
    adaptivity, and autonomy.
  prefs: []
  type: TYPE_NORMAL
- en: Docker-enabled containerization is an intensely reviewed mechanism that has
    the innate strength to bring in certain critical disruptions for the field of
    software engineering. The Docker paradigm is all about optimal packaging of any
    kinds of software applications along with their dependencies to be shipped, deployed,
    and executed across any on-premise and off-premise environments. Containerized
    applications (applications and their execution containers) are extremely lightweight,
    portable, scalable, reproducible, and repeatable packages compared with the currently
    available options in the software industry.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker idea facilitates many purposeful innovations. Docker (through its
    unique packaging format and the highly integrated platform) simplifies and accelerates
    the formation of publicly discoverable, network accessible, and remotely deployable
    containerized applications that are easily composable, consumable, and configurable.
    Further, there are software solutions for robust monitoring, measuring, and managing
    containers. In this chapter, we will discuss how the accelerated maturity and
    stability of the Docker paradigm ensures the much-needed business transformations.
    The literature talks about several game-changing implications of the Docker technology
    toward the next-generation IT and this chapter aims to unravel the Docker mystery.
  prefs: []
  type: TYPE_NORMAL
- en: Describing containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Compartmentalization that comprises both virtualization and containerization
    is the new norm for IT agility. Virtualization has been the enigmatic foundation
    for the enormous success of cloud computing. Now with the containerization idea
    becoming ubiquitous and usable, there is a renewed focus on using containers for
    faster application building, deployment, and delivery. Containers are distinctively
    fitted with a few game-changing capabilities and hence there is a rush in embracing
    and evolving the containerization technologies and tools.
  prefs: []
  type: TYPE_NORMAL
- en: Containers are very hot in the industry. Essentially, a container is lightweight,
    virtualized, and portable, and the **Software-Defined Environment** (**SDE**)
    in which software can run is in isolation of other software running on the same
    physical host. The software that runs inside a container is typically a single-purpose
    application. Containers bring forth the much-coveted modularity, portability,
    and simplicity for IT environments. Developers love containers because they speed
    up the software engineering, whereas the operation team loves containers because
    they can just focus on runtime tasks such as logging, monitoring, managing the
    life cycle, and utilizing the resource rather than managing deployment and dependency.
  prefs: []
  type: TYPE_NORMAL
- en: Distinguishing Docker containers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Precisely speaking, Docker containers wrap a piece of software in a complete
    filesystem that contains everything that is needed to run: source code, runtime,
    system tools, and system libraries (anything that can be installed on a server).
    This guarantees that the software will always run the same, regardless of its
    operating environment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main motivations of Docker-enabled containerization are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Containers running on a single machine share the same operating system kernel.
    They start instantly and use less RAM. Container images are constructed from layered
    filesystems and share common files, making disk usage and image downloads much
    more efficient.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker containers are based on open standards. This standardization enables
    containers to run on all major Linux distributions and other operating systems
    such as Microsoft Windows and Apple Macintosh.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are several benefits being associated with Docker containers, as listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Efficiency**:As mentioned earlier, there can be multiple containers on a
    single machine leveraging the same kernel so they are lightweight, can start instantly,
    and make more efficient use of RAM.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource sharing**: Thisamong workloads allows greater efficiency compared
    to the use of dedicated and single-purpose equipment. This sharing enhances the
    utilization rate of resources.'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource partitioning**: This ensures that resources are appropriately segmented
    in order to meet the system requirements of each workload. Another objective for
    this partitioning is to prevent any kind of untoward interactions among workloads.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource as a Service (RaaS)**: Various resources can be individually and
    collectively chosen, provisioned, and given to applications directly or to users
    to run applications.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Native performance**: Containers guarantee higher performance due to their
    lightweight nature and less wastage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Portability**: Applications, dependencies, and configura­tions are all bundled
    together in a complete filesystem, ensuring applications work seamlessly in any
    environ­ment (VMs, bare metal servers, local or remote, generalized or specialized
    machines, and so on). The main advantage of this portability is that it is possible
    to change the runtime dependencies (even programming language) between deployments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram illustrates how containers are being moved and swapped
    across multiple hosts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_12_001.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Real-****time scalability**: Any number of fresh containers can be provisioned
    in a few seconds in order to handle the user and data loads. On the reverse side,
    additionally provisioned containers can be knocked down when the demand goes down.
    This ensures higher throughput and capacity on demand. Tools such as Docker Swarm,
    Kubernetes, and Apache Mesos further simplify elastic scaling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High availability**: By running with multiple containers, redundancy can
    be built into the application. If one container fails, then the surviving peers—which
    are providing the same capability—continue to provide service. With orchestration,
    failed containers can be automatically recreated (rescheduled) either on the same
    or a different host, restoring full capacity and redundancy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maneuverability**: Applications running in Docker containers can be easily
    modified, updated, or extended without impacting other containers in the host.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexibility**: Developers are free to use the pro­gramming languages and
    development tools they prefer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clusterability**: Containers can be clustered for specific purposes on demand
    and there are integrated management platforms for cluster-enablement and management.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Composability**: Software services hosted in containers can be discovered,
    matched for, and linked to form business-critical, process-aware, and composite
    services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: Containers isolate applications from one another and the underlying
    infrastructure by providing an additional layer of protection for the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predictability**: With immutable images, the image always exhibits the same
    behavior everywhere because the code is contained in the image. This means a lot
    in terms of deployment and in the management of the application life cycle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Repeatability**: With Docker, one can build an image, test that image, and
    then use that same image in production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Replicability**: With containers, it is easy to instantiate identical copies
    of full application stack and configuration. These can then be used by new hires,
    partners, support teams, and others to safely experiment in isolation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Briefing the Docker platform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Linux containers are hugely complicated and not user-friendly. Having realized
    the fact that several complexities are coming in the way of massively producing
    and fluently using containers, an open-source project got initiated with the goal
    of deriving a sophisticated and modular platform comprising an enabling engine
    for simplifying and streamlining the life cycle phases of various containers.
    This means that the Docker platform is built to automate the crafting, packaging,
    shipping, deployment, and delivery of any software application embedded inside
    a lightweight, extensible, and self-sufficient container. Docker is positioned
    as the most flexible and futuristic containerization technology in realizing highly
    competent and enterprise-class distributed applications. This will make deft and
    decisive impacts on the IT industry, as instead of large monolithic applications
    distributed on a single physical or virtual server, companies are building smaller,
    self-defined and sustainable, easily manageable, and discrete ones. In short,
    services are becoming microservices these days in order to give the fillip to
    the containerization movement.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker platform enables artistically assembling applications from disparate
    and distributed components and eliminates any kind of deficiencies and deviations
    that could come when shipping the code. Docker, through a host of scripts and
    tools, simplifies the isolation of software applications and makes them self-sustainable
    by running them in transient containers. Docker brings the required separation
    for each of the applications from one another as well as from the underlying host.
    We have been hugely accustomed to VMs that are formed through an additional layer
    of indirection in order to bring the necessary isolation. This additional layer
    and overhead consumes a lot of precious resources and is hence an unwanted cause
    of the slowdown of the system. On the other hand, Docker containers share all
    the resources (compute, storage, and networking) to the optimal level and hence
    can run much faster. Docker images, being derived in a standard form, can be widely
    shared and stocked easily for producing bigger and better application containers.
    In short, the Docker platform lays a stimulating and scintillating foundation
    for optimal consumption, management, and maneuverability of various IT infrastructures.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker platform is an open-source containerization solution that smartly
    and swiftly automates the bundling of any software applications and services into
    containers and accelerates the deployment of containerized applications in any
    IT environments (local or remote systems, virtualized or bare metal machines,
    generalized or embedded devices, and so on). The container life cycle management
    tasks are fully taken care of by the Docker platform. The whole process starts
    with the formation of a standardized and optimized image for the identified software
    and its dependencies. Now the Docker platform takes the readied image to form
    the containerized software. There are image repositories made available publicly
    as well as in private locations. Developers and operations teams can leverage
    them to speed up software deployment in an automated manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Docker ecosystem is rapidly growing with a number of third-party product
    and tool developers in order to make Docker an enterprise-scale containerization
    platform. It helps to skip the setup and maintenance of development environments
    and language-specific tooling. Instead, it focuses on creating and adding new
    features, fixing issues, and shipping software. "Build once and run everywhere,"
    is the endemic mantra of the Docker-enabled containerization. Concisely speaking,
    the Docker platform brings in the following competencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Agility**: Developers have the freedom to define environments and the ability
    to create applications. IT operation teams can deploy applications faster, allowing
    the business to outpace the competition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Controllability**: Developers own all the code from infrastructure to application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manageability**: IT operation team members have the manageability to standardize,
    secure, and scale the operating environment while reducing overall costs to the
    organization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The evolving Docker platform components
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Docker is a platform for developing, shipping, and running powerful applications
    crafted out of distributed microservices. The platform is in the expansion mode
    with the persistent support rendered by a number of third-party product vendors
    and start-ups in the Docker space. For different use cases, additional automation
    tools are being built and released to the marketplace:'
  prefs: []
  type: TYPE_NORMAL
- en: Docker Hub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Trusted Registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Kitematic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Toolbox
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Swarm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Compose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Datacenter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the ongoing requirements, we can safely expect new additions to the preceding
    list in the days ahead. The Docker team is proactively and preemptively working
    on various tools in order to bring in the desired automation and simplicity for
    lessening the workloads of IT professionals.
  prefs: []
  type: TYPE_NORMAL
- en: Implications of the Docker technology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the systematic and sagacious usage of the Docker idea, enterprising businesses
    and organizations across the globe are bound to benefit immensely for their business
    transformation needs. This section will describe the paramount and potential impacts
    of the Docker paradigm. Without any doubt, containers are a hot topic these days.
    Corporates, service providers (cloud, communication, and so on), and consumers
    are pursuing the Docker dream. Docker has been creating multifaceted impressions
    and implications for enterprise and cloud IT. The systematic leverage of the Docker
    technology is assuredly accentuated to pour in delectable advancements for businesses.
  prefs: []
  type: TYPE_NORMAL
- en: Modern enterprise development
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Conceptually, a container image can be thought of as a snapshot of a container's
    filesystem that can be stored on disk. The container filesystem is typically arranged
    in layers and every change gets carefully captured in a separate layer. This allows
    the container image to indicate from which parent image it is derived. The Docker
    images, being represented through a standardized and simplified format, can ultimately
    lead to the rapid and rewarding deployment and execution of software applications.
    Containers are portable. This means that building images once and running them
    everywhere is the crux of the portability goal. Containers can run on any hardware
    that runs the relevant operating system.
  prefs: []
  type: TYPE_NORMAL
- en: There are challenges too. As there can be many containers in a single Docker
    host, there can be the issue of the container sprawl in a cloud environment (private,
    public, and hybrid). For effective monitoring and management, the concepts of
    clustering and orchestration are being leveraged in order to find and bind different
    and distributed containers. Further on, for constructing distributed applications
    through containerized applications, service composition through the orchestration
    technique is encouraged. Docker Compose is the key solution for making composite
    applications. For working at the container level, there are automated monitoring,
    measurement, management, and orchestration software solutions (Docker Swarm, Kubernetes,
    and Mesos). In the following sections, we explain how containers are the best
    fit for agile and adroit businesses. This does not mean that virtualization is
    out of business. There are certain situations and scenarios wherein the mixed
    and merged usage of virtualization and containerization is posted for wonders.
  prefs: []
  type: TYPE_NORMAL
- en: Combining these special powers with container images, resulting in a viable
    and venerable abstraction, enables a clean isolation between applications from
    the underlying operating systems. This neat decoupling of image and OS makes it
    possible to deploy software applications in development, testing, staging, and
    production environments without any hurdle or hitch. This Docker-enabled uniformity
    and ubiquity improves deployment reliability and speeds up modern enterprise development
    by decimating all kinds of inconsistencies and unnecessary frictions. The widely
    expressed recommendation is to have an airtight container image that can encompass
    and encapsulate all of an application's dependencies into a package. This then
    can be deployed into a container to enable shipping to run anytime anywhere.
  prefs: []
  type: TYPE_NORMAL
- en: MSA and Docker containers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The service-enablement has been going on successfully for a number of reasons
    and objectives. Every system (physical, mechanical, electrical, and electronic)
    is systematically enabled with easily consumable interfaces. RESTful interfaces
    and services have become pervasive due to their simplicity. In the recent past,
    with the surging popularity of the web, enterprise, mobile, and cloud applications,
    the REST idea has clearly captured a lot of attention and attraction. It has been
    quickly discovered that splitting out business functions into reusable services
    is very effective; however, at the same, it introduces a risk point. This means
    that every time a service gets updated, then all the other services that make
    use of the updated service have to be subjected to a variety of formal verifications
    and validations. This is because services inevitably have to find, bind, and leverage
    other services and their unique capabilities and data points to be right and relevant.
    This unbridled sharing can happen locally or with remote ones over networks.
  prefs: []
  type: TYPE_NORMAL
- en: Basically, the microservices approach, in a nutshell, dictates that instead
    of having one giant code base that all developers touch, that often becomes perilous
    to manage, it is better to have numerous smaller code bases managed by small and
    agile teams that sit across different time zones. Every code base has to interoperate
    through well-intended and defined APIs. Every code base is small in size but also
    totally decoupled from one another. The dependency is gone totally, resulting
    in better security, reliability, simplicity, scalability, availability, and so
    on. The code base is termed as microservices. The motives for the unprecedented
    take off of microservices are definitely many; specifically, the granular scaling,
    easy manageability, maneuverability, reconfigurability and extensibility, strong
    security through API access, the appropriateness of containers as the optimal
    runtime environment, and so on, are the widely articulated ones. Microservices
    can be independently deployable, horizontally scalable, supported by any backend
    databases (SQL, NoSQL, NewSQL, In-Memory, and so on), and built by any programming
    languages.
  prefs: []
  type: TYPE_NORMAL
- en: Docker containers are the best fit for hosting microservices. This intentional
    containerization of single services or processes makes it very simple to manage,
    update, and scale out these services. Now with the number of microservices in
    any IT environment growing very rapidly, the management complexity is to zoom.
    This means that the challenges include how to manage single services in a cluster
    and how to tackle multiple services spread across distributed and different hosts.
    Kubernetes, MaestroNG, Mesosphere, and Fleet spring up to answer this growing
    need.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, one prominent reason is the onset and rollout of microservices in
    droves and this has brought out the indispensability of containers. The various
    targets expected out of microservices are being fulfilled by stuffing microservices
    within containers. This interesting combination is bound to play a very stellar
    role for the IT teams of worldwide enterprising businesses. Practically speaking,
    the widespread usage of the containerization tenet has laid a stimulating foundation
    for the explosion of purpose-specific as well as agnostic microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Case study
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SA Home Loans faced challenges in development, as well as in production. SA
    currently has four scrum teams, each with a development and a system test lab.
    The team faced slow deployment times and was only able to build and deploy two
    applications in the dev labs, causing long deployment cycles and sometimes taking
    up to 2 weeks to get applications over to the testing environment. This issue
    got extended to production as well. The main home loan servicing software monolithic
    was built using legacy technologies.
  prefs: []
  type: TYPE_NORMAL
- en: The IT team made the conscious decision to adopt the MSA to gain the agility,
    portability, and extensibility, and the break-in resulted in 50 microservices.
    Having understood the significance of the blossoming Docker technology, the team
    could move all the microservices to containers.
  prefs: []
  type: TYPE_NORMAL
- en: The team also needed a production-ready orchestration service that could give
    it a single point from which to manage and distribute containers onto the nodes,
    as well as give the team a high-level oversight of all the containers. Docker
    Swarm is the orchestration tool. SA Home Loans now uses Docker Datacenter, the
    on-premises solution that brings container management and deployment services
    to the enterprise via a supported **Container as a Service** (**CaaS**) platform
    that is hosted locally. SA Home Loans now builds and deploys applications up to
    20-30 times a day. **Universal Control Plane** (**UCP**) has embedded Swarm to
    give the production-ready container orchestration solution.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure optimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Virtualization has been the main mechanism for hugely optimizing and organizing
    various IT infrastructures (server machines, storage appliances, networking, and
    security solutions). The proven divide and conquer technique accomplished through
    VMs is the main target for IT optimization. In the recent past, Docker containers
    emerged as a blessing in disguise. Containers contain only what is necessary to
    build, ship, and run software applications. Unlike VMs, there is no guest OS or
    hypervisor necessary for containers. This allows enterprises to radically reduce
    the amount of storage and totally eliminate hypervisor licensing costs. The number
    of containers that can be accommodated in a physical host or in a VM is more compared
    to the number of VMs being stuffed in a physical machine. This means that containers
    are fine-grained whereas VMs are coarse-grained. The wastage of resources is very
    minimal in the case of containerization. Every bit of IT infrastructures and resources
    is being methodically used by containers.
  prefs: []
  type: TYPE_NORMAL
- en: Portability is another factor. This enables IT operations teams to move workloads
    across different cloud services, physical servers, or VMs without locking them
    into using a specific infrastructure tooling. Workload consolidation or optimization
    through containers is error-free because containers can run everywhere. In the
    case of VMs, VM placement is a tricky and tough affair considering the diversity
    of hypervisors / **Virtual Machine Monitors** (**VMMs**). The point here is that
    Docker allows enterprises to optimize infrastructure utilization and decrease
    the cost of maintaining existing applications, which is incidentally the number
    one challenge enterprise IT teams face every day.
  prefs: []
  type: TYPE_NORMAL
- en: Docker greatly reduces the amount of time it takes to install an application,
    scale to meet customer demands, or simply start new containers. This means, taking
    new offerings to market is exceedingly fast because the underlying infrastructure
    (virtual or physical) is being readied in a few seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Case study
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A client with the need to establish and provide **Database as a Service** (**DaaS**)
    capability has resolved that every database instance is provisioned and stationed
    inside its own VM. There can be occasions wherein there are 100 VMs running 100
    databases. This is extremely inefficient, wasting a lot of expensive resources.
    Now the same number of database instances can be run on that number of containers,
    which in turn could run inside a few VMs. The result is huge cost savings. Another
    case study follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Customer details**: Swisscom is a Switzerland''s leading telecom provider
    offering a range of enterprise and consumer services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The business challenges**: This includes offering a reliable, easy-to-maintain
    DaaS to customers while achieving server density necessary to operate efficiently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The solution approach**: Flocker by ClusterHQ provides the ability to programmatically
    manage persistent data for Docker containers stored in EMC ScaleIO.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The business outcome**: This solution has substantially increased the density
    of applications hosted per server, improved operational management of databases,
    and laid out a stimulating and sparkling platform for sustainable innovation in
    consumer and enterprise IT sectors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enabling DevOps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Agile development is being increasingly followed in the IT industry these days
    in order to elegantly ensure business agility, adaptivity, and affordability.
    This means that it is true that the much-demanded business agility is being fulfilled
    by stringently embracing the competent methods for IT agility. There is a growing
    array of viable and venerable mechanisms to realize IT agility. Primarily, IT
    agility is being driven through agile programming methods such as pair programming,
    **Extreme Programming** (**XP**), Lean, Scrum and Kanban, **Test-Driven Development**
    (**TDD**), and **Behaviour-Driven Development** (**BDD**).
  prefs: []
  type: TYPE_NORMAL
- en: Now the software development process gets speeded up remarkably. However, there
    is a big disconnect between development and operation. This means that the real
    IT agility gets realized when the operation team also strictly follows agile,
    adaptive, and automated IT operations. Enterprise DevOps is the most promising
    way forward for establishing the beneficial connect between developers and operators
    so that the IT systems get up and running quickly. Containerization is the most
    positive development toward making DevOps pervasive, penetrative, and persuasive.
  prefs: []
  type: TYPE_NORMAL
- en: Docker is ideal for quickly setting up development and test environments as
    well as sandbox environments. Docker interestingly offers a better separation
    of concerns for guarantee-efficient DevOps; container crafters need to focus only
    on building Docker images and committing them to make them containers. The operation
    team could monitor, manage, and maintain the containers. Finally, Docker can be
    easily integrated into multiple DevOps tools to achieve better workflow automation
    and continuous integration. Also, it enables the DevOps teams to scale up development
    and test environments, quickly and cost-effectively, and to move applications
    from development, to test, to produc­tion in a seamless manner.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous integration and continuous deployment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Continuous Integration** (**CI**) and **Continuous Deployment** (**CD**)
    are the most sought-after technologies and tools for having agile IT. In the past,
    developers would automate their build process using any one of the build tools.
    Then they would hand over their code to the operation team to proceed with deployment,
    administration, management, and support. There are many configuration management
    and software deployment tools in order to automate the tedious and tough affair
    of software deployment and delivery. This segregated pattern brought forth a number
    of recurring issues. With containers, the operation team could build standard
    container images of the full stack that they want to deploy and deliver. Developers
    can use them to deploy their code to do unit testing. That same tested, refined,
    and hardened image can be used across all environments (development, test, stage,
    and production) to get the same results every time. This containerization-sponsored
    setup specifically accelerates the software deployment and delivery activities
    in a risk-free fashion.'
  prefs: []
  type: TYPE_NORMAL
- en: As per the Docker site, CI/CD typically merges development with testing, allowing
    developers to build code collaboratively, submit it to the master branch, and
    check for any issues. This means that developers can build and test their code
    to catch bugs early in the applications development life cycle. Since Docker can
    integrate with tools such as Jenkins and GitHub, developers can submit code in
    GitHub, test the code, and automatically trigger a build using Jenkins, and once
    the image is complete, it can be added to Docker registries. This ultimately streamlines
    the process and saves times on build and setup processes, all while allowing developers
    to run tests in parallel and automate them so that they can continue to work on
    other projects while tests are being run. The environment dependencies and inconsistencies
    get eliminated with the containerization.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous delivery
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **continuous delivery** approach involves fast software development iterations
    and frequent, safe updates to the deployed application. It is all about reducing
    risk and delivering value faster by producing reliable software in short iterations. Because
    Docker encapsulates both the application and the application''s environment or
    infrastructure configuration, it provides a key building block for two essential
    aspects of a continuous delivery pipeline. Docker makes it easy to test exactly
    what you are going to deploy. The possibility of making serious errors during
    the handoff or bringing in any undesirable changes is less likely in this case.
    Docker containers encourage a central tenet of continuous delivery: they reuse
    the same binaries at each step of the pipeline to ensure no errors are introduced
    in the build process itself.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As indicated earlier, Docker containers provide the basis for immutable infrastructures.
    Applications can be added, removed, cloned, and/or their constituencies can change
    without leaving any residues behind. IT infrastructures can be changed without
    affecting the applications that run on them. The Docker tool ecosystem is the
    growth trajectory and hence a lot of delivery-related works get simply automated
    and accelerated to add business value. As Martin Fowler says, you actually do
    continuous delivery in the following situations:'
  prefs: []
  type: TYPE_NORMAL
- en: If your software is deployable throughout its life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your team prioritizes keeping the software deployable over working on new
    features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If anybody can get fast, automated feedback on the production readiness of their
    systems anytime somebody makes a change to them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you can perform push-button deployments of any version of the software to
    any environment on demand
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker also easily integrates with CI and continuous delivery platforms enabling
    development and testing to deliver seamless updates to production. In the case
    of any kind of failure, it is possible to roll back to the previous working version.
  prefs: []
  type: TYPE_NORMAL
- en: Accurate testing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Docker accelerates DevOps by creating a common framework for building, testing,
    and administering distributed applications, inde­pendent of languages, development
    tools or environmen­tal variables. Docker improves collaboration by allowing developers,
    **Quality Assurance** (**QA**) teams, and system administrators to efficiently
    share code, exchange content, and integrate applications. We can be confident
    that our QA environment exactly matches what will be deployed in the production
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: Facilitating CaaS
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We have been fiddling with IT infrastructure and **Platform as a Service**
    (**PaaS**). Bare metal servers and VMs are the key computing resources in IT centers.
    Now with the successful proliferation of containers, **Container as a Service**
    (**CaaS**) is becoming hugely popular and tantalizing. There are certain issues
    with PaaS in traditional environments. CaaS is being touted as the solution approach
    for surmounting the prickling issues of PaaS:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_12_002.png)'
  prefs: []
  type: TYPE_IMG
- en: The high-level CaaS architecture
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding figure, developers on the left-hand side are pulling and pushing
    application content from a library of trusted and curated base images. Operations
    teams on the right-hand side are monitoring and managing deployed applications
    and infrastructures. The two teams can collaborate through a toolset that allows
    for a separation of concerns while unifying the two teams through the application
    life cycle. The Docker platform is that toolset empowering to build a CaaS that
    fits varying business requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Adding new technology components is greatly simplified. Let's say a company
    wants to add MongoDB to its portfolio. Now a certified image can be pulled down
    from Docker Hub and tweaked as needed, and then quickly deployed. This container
    can then be offered to developers for their consumption. Containers also allow
    for more experimentation. Since it is so easy to build and tear down containers,
    a developer can quickly compare the features of a stack component. For example,
    a developer wants to test the performance of three different NoSQL database technologies
    and they can simply fire up the appropriate container for each NoSQL technology
    without having to deal with the complexity of managing the infrastructure and
    the underlying technology stack. The developer could then run performance tests
    against each distinct container and select the appropriate one quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Containers have the innate and incredible power to offer JVM-like portability
    in terms of completely abstracting the underlying infrastructure. A true CaaS
    model is to pave the way for the deployment of multi-container applications in
    multi-cloud environments.
  prefs: []
  type: TYPE_NORMAL
- en: Accelerating workload modernization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are a variety of workloads in need of getting appropriately modernized
    and migrated to powerful environments (clouds) to be readily found, bound, and
    used by worldwide users for producing business-critical applications. Workloads
    typically represent software applications, middleware, platforms, and so on. In
    the past, **Service-Oriented Architecture** (**SOA**) was an enabler of software
    modernization through integration and composition. In the recent past, MSA is
    being touted as the best-in-class approach for modernizing legacy, monolithic,
    and massive applications. Applications are being fragmented accordingly in order
    to be easily manageable. The development, deployment, and management complexities
    are expected to go down with complex applications being expressed and exposed
    as a collection of interoperable, portable, and composable microservices. This
    means that application modules are being refactored and readied to be loosely
    or lightly coupled, even decoupled. Further, applications are recommended to be
    stateless to be scalable and independently deployable.
  prefs: []
  type: TYPE_NORMAL
- en: Some applications can take a "lift and shift" path to the cloud. This means
    that if some code modifications are brought in, they can be significantly refactored
    to take the distinct advantages of cloud centers. The applications are being redesigned,
    recoded, and repurposed for the specific cloud platform. This gives the legacy
    application a new life and a new purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Containers are the highly optimized and organized runtime for hosting and delivering
    microservices. Containers in conjunction with microservices are emerging as the
    most crucial combination for the IT world in many respects. The use of containers
    to "wrap" or containerize existing legacy applications comes with a few advantages.
    The containers take care of the underlying platforms and infrastructures and the
    complexities associated with them. Containerized applications are portable and
    enhances the speed in which legacy modernization is performed. The cloud migration
    is smoothened through the utilization of containers. Additional capabilities such
    as security, web and service enablement, and governance can be attached to containerized
    applications easily and quickly. Further, modernized legacy applications are a
    better fit for distributed computing.
  prefs: []
  type: TYPE_NORMAL
- en: A great way to modernize the current and conventional applications as we move
    them to the cloud is to leverage technologies such as Kubernetes and Mesos instead
    of building all of the **Non-Functional Requirements** (**NFRs**), such as scalability,
    security, and sustainability.
  prefs: []
  type: TYPE_NORMAL
- en: Docker for stateful applications
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Containers are typically stateless. However, for several applications, stateful
    compute resources are needed. Docker does not natively provide storage volume
    management or data persistence when porting these compute resources between hosts.
    The Flocker solution by ClusterHQ addresses these needs and enables the containers
    to be used for stateful applications, such as databases, by providing a framework
    for volume management and data persistence when moving compute resources from
    one host to another. Flocker works with all the major container managers (including
    Docker Swarm, Kubernetes, and Apache Mesos).
  prefs: []
  type: TYPE_NORMAL
- en: Containers for edge computing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The security fear along with the lack of visibility and controllability is being
    touted as the widely articulated and accepted drawback of cloud computing. Private
    clouds and cloudlets are the viable options. Yet, they too face certain limitations.
    However, the recent phenomenon of edge or fog computing has been pronounced as
    the most successful computing paradigm for surmounting all the cloud weaknesses.
  prefs: []
  type: TYPE_NORMAL
- en: Edge computing is all about shifting the data processing and storage from the
    centralized locations (cloud) to the distributed and decentralized environments
    (local). This means that by bringing in compute, network, and storage competencies
    closer to the users, the **Quality of Service** (**QoS**) attributes / the NFRs
    are readily and rewardingly accomplished. Traditionally, all the computing and
    storage takes place in cloud environments (on-premises and off-premises). However,
    certain scenarios such as real-time analytics and faster responses insist for
    computing at the user end. It is not an exaggeration to say that the QoS and experience
    goes up significantly when IT becomes people-centric, context-aware, adaptive,
    real-time, and multimodal. Real-world and real-time applications and services
    invariably pitch in for computing at the edges. There have been several architectural
    complications even for edge computing, and now with the faster maturity and stability
    of application and volume containers, edge computing innately gets the much-needed
    fillip.
  prefs: []
  type: TYPE_NORMAL
- en: Devices networking, service enablement, and clustering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Generally, edge devices such as implantables, wearables, portables, gateways,
    mobiles, handhelds, consumer electronics, and robots may be primarily resource-constrained.
    Most of these devices are not static and typically nomadic. Establishing seamless
    connectivity among them for process, application, and data integration is a tedious
    and tough affair indeed. Geo-distributed computation on edge devices, therefore,
    requires a lightweight, intrinsically extensible, and intelligent platform to
    handle extremely fragile service deployment, delivery, and management. **Open
    Service Gateway interface** (**OSGi**) is an interesting framework for elegantly
    activating and administering resource-constrained, embedded and connected devices,
    and their unique services. Any service or application can be containerized and
    can be loaded with all kinds of participating devices. Then an instance of the
    OSGi package can be containerized and hosted in a reasonably powerful device stationed
    at the user environment in order to discover and manage all kinds of devices and
    their service containers inside. This kind of setup enables centralized (from
    the cloud) as well as decentralized monitoring, measurement, and management of
    device services. The Dockerized platform is a proven mechanism to install, configure,
    manage, upgrade, and terminate running services.
  prefs: []
  type: TYPE_NORMAL
- en: Device service registry for discovery
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: There may be thousands of edge devices in a particular environment. To discover,
    index, and manage heterogeneous, dynamic, and distributed devices in a systematic
    manner, the need for service registry and discovery capabilities is being insisted
    upon. The management platform has to have this feature in order to find, bind,
    and leverage multiple devices in an automated manner.
  prefs: []
  type: TYPE_NORMAL
- en: Fault tolerance
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The platform must be fault-tolerant in order to guarantee high availability
    and reliability to ensure business continuity.
  prefs: []
  type: TYPE_NORMAL
- en: Caching
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Caching can be performed on the edge devices to enable faster access and to
    improve the overall application performance. If Docker images are stocked and
    cached at the edge, then application provisioning can be speeded up sharply. Another
    use case is to store application data in a cache in order to remarkably increase
    application performance.
  prefs: []
  type: TYPE_NORMAL
- en: Bukhary Ikhwan Ismail and the team have built a testbed in order to examine
    Docker as one of the candidate technologies for edge or fog computing. The testbed
    consists of a data center and three edge sites to simulate the environment. At
    each edge site, a Docker Registry is set up to store Docker images locally at
    the edge. A Docker daemon at the edge site will be able to search and pull the
    Docker image from the Docker Registry. Docker Swarm is configured on each edge
    site to manage multiple Docker daemons. Docker Swarm acts as a clustering and
    orchestration tool. Based on the experimentation and evaluation, Docker is found
    to be providing fast deployment, small footprint, and good performance, which
    make it potentially a viable edge computing platform.
  prefs: []
  type: TYPE_NORMAL
- en: Marcel Grossmann and the team have developed **Hypriot Cluster Lab** (**HCL**).
    This is an ARM-powered cloud solution utilizing Docker. Embedded systems and other
    **Single Board Computers** (**SBCs**) have gained tremendous computing power.
    With devices increasingly interconnected and web-enabled, a massive amount of
    machine data gets generated and the growing need is to collect and crunch them
    quickly in order to squeeze out real-time insights. As illustrated earlier, the
    era of edge/fog analytics is picking up fast. HCL can provide the basis for a
    virtualized edge because it runs on the ARM architecture, which behaves like a
    small data center and ships energy-efficient features by design.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker use cases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Containerization is emerging as the way forward for the software industry as
    it brings forth a newer and richer way of building and bundling any kind of software,
    shipping and running them everywhere. That is the fast-evolving aspect of containerization
    that promises and provides software portability, which has been a constant nuisance
    for IT developers and administrators for many decades now. The Docker idea is
    flourishing here because of a number of enabling factors and facets. This section
    is specially prepared for specifying the key use cases of the Docker idea.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating containers into workflows
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Workflows are a widely accepted and used abstraction for unambiguously representing
    the right details of any complicated and large-scale business and scientific applications
    and executing them on distributed computing systems such as clusters, clouds,
    and grids. However, workflow management systems have been largely evasive in conveying
    the relevant information of the underlying environment on which the tasks inscribed
    in the workflow are to run. This means that the workflow tasks can run perfectly
    on the environment for which they were designed. The real challenge is to run
    the tasks across multiple IT environments without tweaking and twisting the source
    codes of the required tasks. Increasingly, the IT environments are heterogeneous
    with the leverage of disparate operating systems, middleware, programming languages
    and frameworks, databases, and so on. Typically, workflow systems focus on data
    interchange between tasks and are environment-specific. A workflow, which is working
    fine in one environment, starts to crumble when it is being migrated and deployed
    on different IT environments. All kinds of known and unknown dependencies and
    incompatibilities spring up to denigrate the workflows delaying the whole job
    of IT setup, application installation and configuration, deployment, and delivery.
    Containers are the best bet for resolving this imbroglio once and for all.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the article, *Integrating Containers into Workflows: A Case Study Using
    Makeflow, Work Queue, and Docker, Chao Zheng* and *Douglas Thain* have done a
    good job of analyzing several methods in order to experimentally prove the unique
    contributions of containers in empowering workflow/process management systems.
    They have explored the performance of a large bioinformatics workload on a Docker-enabled
    cluster and observed the best configuration to be locally managed on containers
    that are shared between multiple tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: Docker for HPC and TC applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: According to Douglas M. Jacobsen and Richard Shane Canon, currently, containers
    are being overwhelmingly used for the web, enterprise, mobile, and cloud applications.
    However, there are questions being asked and doubts being raised on whether containers
    can be a viable runtime for hosting technical and scientific computing applications.
    Especially, there are many **High-Performance Computing** (**HPC**) applications
    yearning for a perfect deployment and execution environment. The authors of this
    research paper have realized that Docker containers can be a perfect answer for
    HPC workloads.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, users desire to have the ability to easily execute their scientific
    applications and workflows in the same environment used for development or adopted
    by their community. Some researchers have tried out the cloud option, but the
    challenges are many. The users need to solve how they handle workload management,
    filesystems, and basic provisioning. Containers promise to offer the flexibility
    of cloud-type systems coupled with the performance of bare-metal systems. Furthermore,
    containers have the potential to be more easily integrated into traditional HPC
    environments, which means that users can obtain the benefits of flexibility without
    the added burden of managing other layers of the system (that is, batch systems,
    filesystems, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: Minh Thanh Chung and the team have analyzed the performance of VMs and containers
    for high-performance applications and benchmarked the results that clearly show
    containers are the next-generation runtime for HPC applications. In short, Docker
    offers many attractive benefits in an HPC environment. To test these, IBM Platform
    LSF and Docker have been integrated outside the core of Platform LSF and the integration
    leverages the rich Platform LSF plugin framework.
  prefs: []
  type: TYPE_NORMAL
- en: We all know that the aspect of compartmentalization is for resource partitioning
    and provisioning. This means that physical machines are subdivided into multiple
    logical machines (VMs and containers). Now on the reverse side, such kinds of
    logical systems carved out of multiple physical machines can be linked together
    to build a virtual supercomputer to solve certain complicated problems. *Hsi-En
    Yu* and *Weicheng Huang* have described how they built a virtual HPC cluster in
    the research paper, *Building a Virtual HPC Cluster with Auto Scaling by the Docker.*
    They have integrated the autoscaling feature of service discovery with the lightweight
    virtualization paradigm (Docker) and embarked on the realization of a virtual
    cluster on top of physical cluster hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Containers for telecom applications
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Csaba Rotter and the team* have explored and published a survey article with
    the title, *Using Linux Containers in Telecom Applications.* Telecom applications
    exhibit strong performance and high availability requirements; therefore, running
    them in containers requires additional investigations**.** A telecom application
    is a single or multiple node application responsible for a well-defined task.
    Telecom applications use standardized interfaces to connect to other network elements
    and implement standardized functions. On top of the standardized functions, a
    telecom application can have vendor-specific functionality. There is a set of
    QoS and **Quality of Experience** (**QoE**) attributes such as high availability,
    capacity, and performance/throughput. The paper has clearly laid out the reasons
    for the unique contributions of containers in having next-generation telecom applications.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Efficient Prototyping of Fault Tolerant Map-Reduce Applications with Docker-Hadoop*
    by*Javier Rey and the team* advocated that distributed computing is the way forward
    for compute and data-intensive workloads. There are two major trends. Data becomes
    big and there are realizations that big data leads to big insights through the
    leverage of pioneering algorithms, scripts, and parallel languages such as Scala,
    integrated platforms, new-generation databases, and dynamic IT infrastructures.
    MapReduce is a parallel programming paradigm currently used to perform computations
    on massive amounts of data. Docker-Hadoop1 is a virtualization testbed conceived
    to allow the rapid deployment of a Hadoop cluster. With Docker-Hadoop, it is possible
    to control the characteristics of the node and run scalability and performance
    tests that otherwise would require a large computing environment. Docker-Hadoop
    facilitates simulation and reproduction of different failure scenarios for the
    validation of an application.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Regarding interactive social media applications, Alin Calinciuc and the team
    have come out with a research publication titled as *OpenStack and Docker: Building
    a high-performance IaaS platform for interactive social media applications*. It
    is a well-known truth that interactive social media applications face the challenge
    of efficiently provisioning new resources in order to meet the demands of the
    growing number of application users. The authors have given the necessary description
    on how Docker can run as a hypervisor, and how the authors can manage to enable
    the fast provisioning of computing resources inside of an OpenStack IaaS using
    the `nova-docker` plugin that they had developed.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point in time, Docker is nothing short of an epidemic and every enterprising
    business across the globe is literally obsessed with the containerization mania
    for their extreme automation, transformation, and disruption. With the blossoming
    of hybrid IT, the role of Docker-enabled containerization is steadily growing
    in order to smartly empower IT-enabled businesses. In this chapter, we discussed
    the prime capabilities and contributions of the Docker paradigm. We described
    how a typical software package can be containerized. Further, you can come across
    industrial and enterprise-scale use cases.
  prefs: []
  type: TYPE_NORMAL
