- en: '*Chapter 6*: Deploying Applications with Docker Compose'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The simplest possible practical deployment scenario of an application packaged
    with Docker involves running Docker Compose on a single host. Many of the commands
    that you use as a developer, such as `docker-compose up -d`, also apply to deploying
    Docker applications on a single host.
  prefs: []
  type: TYPE_NORMAL
- en: Running Docker applications on a single host is easier to understand than running
    them using one of the more complex container orchestration systems because many
    of the same techniques you might use to run a non-Docker application apply; however,
    it has some significant drawbacks in terms of performance and availability.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will discover why this is the simplest practical option,
    learn how to configure Docker for production on a single host, and master some
    techniques for managing and monitoring a simple setup efficiently. Furthermore,
    you will better understand the drawbacks of running Docker on a single host, including
    the problems you may face.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Selecting a host and operating system for single-host deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing the host for Docker and Docker Compose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying using configuration files and support scripts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring small deployments—logging and alerting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations of single-host deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To complete the exercises in this chapter, you'll need Git and Docker on your
    local workstation, and you will need a single host capable of running Linux and
    Docker for your production server, connected to a network that you can SSH into
    and that your users can reach.
  prefs: []
  type: TYPE_NORMAL
- en: The GitHub repository for this chapter can be found at [https://github.com/PacktPublishing/Docker-for-Developers](https://github.com/PacktPublishing/Docker-for-Developers)—please
    refer to the `chapter6` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://bit.ly/31OSi1H](https://bit.ly/31OSi1H)'
  prefs: []
  type: TYPE_NORMAL
- en: Example application – ShipIt Clicker v2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The version of ShipIt Clicker in this chapter is more polished than the one
    we used in [*Chapter 5*](B11641_05_Final_NM_ePub.xhtml#_idTextAnchor080), *Alternatives
    for Deploying and Running Containers in Production*. It has the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: An improved Dockerfile and `docker-compose.yml` file suitable for basic production
    use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storage of game state in Redis tied to a server session, leading to distinct
    game states for different client devices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improved visual and audio assets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use this enhanced version of ShipIt Clicker as the application to deploy
    on a single host using Docker Compose.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting a host and operating system for single-host deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying your application on a single host is the simplest possible way to
    run an application in production. In many ways, it resembles the user experience
    of performing local development using Docker and Docker Compose. If you can package
    the parts of your application using a `docker-compose.yml` file, you are already
    70 percent of the way there. If you already have basic UNIX or Linux system administration
    skills, this will be very easy—this strategy requires the least effort and you
    can master the essentials in an hour or two.
  prefs: []
  type: TYPE_NORMAL
- en: Requirements for single-host deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to proceed with deployment, you will need a computer running a modern
    Linux operating system of the same architecture as your development system, with
    enough memory and processor and storage capacity to run your application. If you
    are developing on a Windows 10 64-bit desktop using Docker Community Edition,
    you need a Linux system that also uses the x86_64 architecture. If you're using
    Docker on a Raspberry Pi 4 running Raspbian, you need an ARM architecture server.
    Really, you could use any bare metal or virtual machine server, either on-premises
    or in the cloud, as long as it supports Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Some cloud providers, such as **Amazon Web Services** (**AWS**), offer a free
    tier for their smallest virtual machine deployments, at least for the first year.
    The example in this chapter will work on a host like this, but if you have a larger
    application, you may need to use a larger and more expensive system.
  prefs: []
  type: TYPE_NORMAL
- en: Production applications often must run *24*7*, and the users of these applications
    may have reliability concerns. While running Docker applications on a single host
    is possibly the least reliable way to proceed, it might be good enough for your
    application. All the single-host reliability measures that vendors such as HP,
    Dell, and IBM have built can be enough in many cases to ensure adequate reliability
    if your application requires that.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need one of the following Linux operating system distributions that
    support Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: Red Hat Enterprise Linux (or CentOS) 7 or 8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ubuntu 16.04 or 18.04 or newer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Linux 2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debian Stretch 9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buster 10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To minimize time to production and to maximize ease, pick one that you know
    already, or use CentOS 7, which is used in the following examples.
  prefs: []
  type: TYPE_NORMAL
- en: Only select a Docker-focused distribution, such as Container Linux or CoreOS,
    if you want to take a slower, more advanced path to production, as your system
    administration skills may be less effective in those environments. User management
    in CoreOS, for example, works quite differently than it does in more mainstream
    distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Because this strategy depends only on having a host that the users of your application
    can reach, you have tremendous flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the host for Docker and Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before you configure the software on the host, you should ensure that it has
    a stable IP address. Sometimes these are referred to as static IP addresses, or
    Elastic IP addresses, in an AWS context. You may need to specially allocate these
    IP address through your provider, which can often be done through the provider's
    console, such as with the **Network** tab in AWS Lightsail, or the **Elastic IPs**
    settings in the AWS EC2 console.
  prefs: []
  type: TYPE_NORMAL
- en: Also, you should map an address (type `shipitclicker.example.com` instead of
    a raw IP address, such as `192.2.0.10`. All public cloud systems have the ability
    to manage DNS entries—for example, [AWS Route 53 (https://docs.aws.amazon.com/rout](https://docs.aws.amazon.com/route53/index.html)e53/index.html),
    and most virtual hosting systems have this capacity as well.
  prefs: []
  type: TYPE_NORMAL
- en: Using operating system packages to install Docker and Git
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You will need to install Docker on the host. For production use, avoid the outdated
    Docker versions that ships with operating system distributions, and try to use
    the operating system  packages that Docker publishes for Docker Community Edition.
    You can find instructions on installing Docker Community Edition on the Docker
    website for various operating systems, a[s follows:](https://docs.docker.com/install/linux/docker-ce/centos/)
  prefs: []
  type: TYPE_NORMAL
- en: '[**CentOS**: https://docs.docker.com/install/linu](https://docs.docker.com/install/linux/docker-ce/centos/)x/docker-[ce/centos/](https://docs.docker.com/install/linux/docker-ce/debian/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Debian**: https://docs.docker.com/install/linu](https://docs.docker.com/install/linux/docker-ce/debian/)x/docker-[ce/debian/](https://docs.docker.com/install/linux/docker-ce/fedora/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Fedora**: https://docs.docker.com/install/linu](https://docs.docker.com/install/linux/docker-ce/fedora/)x/docker-[ce/fedora/](https://docs.docker.com/install/linux/docker-ce/ubuntu/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Ubuntu**: https://docs.docker.com/install/linu](https://docs.docker.com/install/linux/docker-ce/ubuntu/)x/docker-ce[/ubuntu/](https://docs.docker.com/install/linux/docker-ce/binaries/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Binaries**: https://docs.docker.com/install/linux/](https://docs.docker.com/install/linux/docker-ce/binaries/)docker-ce/binaries/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use the following commands for a fresh installation of CentOS 7:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Add your normal, non-root user to the Docker user group, and become a member
    of that group for this Terminal session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure the Docker service is enabled so that it will start on boot, and
    that the Docker service is started:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Install `docker-compose` by foll[owing the directions at https://docs.do](https://docs.docker.com/compose/install/)cker.com/compose/install/.
    `1.25.3` is the latest version as of January 2020, but please check the version
    number on that page for the latest to put in the following command, which should
    all be one line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now that you have the Docker daemon running and enabled, and you also have `docker-compose`
    installed, you can deploy your application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, install `git` through your operating system''s package manager. For Red
    Hat family distributions (such as RHEL, CentOS, Fedora, and Amazon Linux), use
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'For Debian family distributions (including Ubuntu), run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: At this point, the host is ready to deploy Docker applications. In order to
    complete deployment, we will use a strategy that relies on shell scripts and Docker
    environment configuration files.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying using configuration files and support scripts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To deploy our application to a production server, we will use a combination
    of simple commands and support scripts that start or update the running set of
    containers. Let''s start by taking a close look at the two most important files
    required for deployment: `Dockerfile` and `docker-compose.yml`.'
  prefs: []
  type: TYPE_NORMAL
- en: Re-examining the initial Dockerfile
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Dockerfile from [*Chapter 5*](B11641_05_Final_NM_ePub.xhtml#_idTextAnchor080),
    *Alternatives for Deploying and Running Containers in Production*, has good layering
    and has `package.json` and `package.json.lock` copied into the image before `RUN
    npm -s install` executes and before the main parts of the app are copied into
    the image. However, it has some rough edges, which we are going to smooth out
    in this chapter to prepare a solid production deployment. First, let''s take a
    look at the initial Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The preceding Dockerfile for the ShipIt Clicker game prototype gets many things
    right from a local development perspective, but has some limitations, which we
    will address in the Dockerfile for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Very often, developers start with a base image (such as `FROM ubuntu:bionic`)
    that mirrors what they know best: traditional Linux distributions that you might
    run on your workstation. This may help with debugging the Dockerfile initially,
    but it comes at a steep cost because both the base and generated images are large,
    consisting of hundreds of megabytes. Also, the package installation for Ubuntu
    is quite verbose, so the `apt-get install` command has to redirect `stdout` to
    `/dev/null` to prevent verbose output [from taking over our Terminal (](https://askubuntu.com/a/1134785)see
    [https://askubuntu.com/a/1134785](https://askubuntu.com/a/1134785)).'
  prefs: []
  type: TYPE_NORMAL
- en: The rest of the initial Dockerfile has some common quirks that you should avoid
    for production, such as copying configuration files for all of the development
    tooling (see the `COPY` command, which copies dotfiles). The initial Dockerfile
    has an entry point (`ENTRYPOINT`) that refers to a server that is best suited
    for development, not production, because it was quick and easy to define that
    way. A real production setup requires a build step that will create a set of assets
    suitable for distribution, as well as a different `npm` command that launches
    the app using those assets.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Dockerfile for this chapter has corrections for all of these issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In this revised Dockerfile, we use Alpine Linux instead of Ubuntu for smaller
    images, and we pin the version of Alpine for consistent builds. The container
    image based on Alpine Linux is 71% smaller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In the revised Dockerfile, we also create an `app` user so that Docker runs
    the application as a normal UNIX user, not the `root` user, as that can exacerbate
    security problems.
  prefs: []
  type: TYPE_NORMAL
- en: After installing the operating system packages and `npm` packages as silently
    as possible, we can copy the application files and the `.babelrc` configuration
    file into `/app`, and then run `RUN npm run compile` in order to prepare the production
    version of the node application, which we run as the `app` user with `ENTRYPOINT
    npm start`.
  prefs: []
  type: TYPE_NORMAL
- en: Re-examining the initial docker-compose.yml file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The initial `docker-compose.yml` file from the previous chapter gets the job
    done of starting both a web and a Redis container, but it has some deficiencies.
    The initial `docker-compose.yml` file was adapted from the barebones e[xample
    in the Docker documentati](https://docs.docker.com/compose/)on at [https://docs.docker.com/compose/](https://docs.docker.com/compose/),
    so it has some gaps in how ready it is for production use. Many developers adapt
    these examples without considering certain nuances that matter when you have to
    deploy an application to production. You can think of it as a starting point,
    rather than the final destination. The initial `docker-compose.yml` file is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The revised `docker-compose.yml` file for this chapter is much more robust.
    This file [is inspired in part by the samples at https://gith](https://github.com/docker-library/redis/issues/111)ub.com/docker-library/redis/issues/111
    and especially by an example by GitHub user `@lagden`, which has a nice example
    of a `docker-compose.yml` file that supports Redis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we define all the environment variables explicitly for the application,
    and that several of them are defined with a `${VARIABLE_NAME:-default_value}`
    syntax that uses the value of an environment variable. These can be specified
    on the command line, in the usual configuration file: `$HOME/.profile`, `$HOME/.bashrc`,
    or the `.env` file in the same directory as the `docker-compose.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding `ports` section defines the networking configuration for the
    main container; it defines a private network called `private-redis-shipit-clicker-v2`,
    which links the two containers. Note the use of `depends_on` in this section.
    This means that the ShipIt Clicker container will wait until the Redis container
    is started before starting. Next, let''s examine the Redis container definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This has many environment variable entries—for example, `LOG_LEVEL`, `REDIS_HOST`,
    and `REDIS_PORT`—that allow easy overrides. It allows the override of Redis host
    settings, both for easier debugging and to pave the way for easy connection to
    cloud Redis services. It starts Redis with command-line parameters that enable
    persistence and allocates a Docker persistent volume to store Redis append-only
    log files. Otherwise, the data would vanish every time the Redis container is
    restarted. It makes the network where Redis and the web server communicates private.
    This is especially important with Redis because, with the default configuration,
    the Redis server operates without any authentication or authorization—it is wide
    open to whoever can connect!
  prefs: []
  type: TYPE_NORMAL
- en: In this minimalistic, production-ready `docker-compose.yml` file, we expose
    the web server directly on port `80` to the world. This works, but modern browsers
    will show a security warning for plain HTTP content. It will work to get you to
    production, but many production applications require more security safeguards
    than running over plain HTTP. You can get around this by using either a proxy
    or external load balancer that terminates HTTPS on port `443`, or by configuring
    SSL certificates. We will cover this in more detail in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: One of the features of the `docker-compose` v3 configuration is that it sets
    the default behavior for when a container fails to *always restart*. This should
    happen even if the host is rebooted, and will definitely happen if a process exits
    due to an unhandled exception. If you need to configure the restart behavior of
    your application more directly, you can do so with the settings listed in the
    documentation at [https://docs.docker.com/compose/compose-file/#restart_policy](https://docs.docker.com/compose/compose-file/#restart_policy).
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the production .env file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Clone the repository and prepare to configure `docker-compose`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In order to configure your application for production, you should create a file
    called `.env` in the directory where your `docker-compose.yml` file lives. If
    you want to change any of the defaults—for example, to change the level of debugging
    shown in production from `info` to `debug`—you should do so through creating and
    editing the `.env` file associated with the production deployment. Copy the file,
    `env.sample`, to `.env` and edit it to suit your preferences for production.
  prefs: []
  type: TYPE_NORMAL
- en: Handling secrets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This demo application uses environment variables and an `.env` file to store
    secrets. This is in accordance wit[h the 12-factor application](https://12factor.net/config)
    principles (see https://12factor.net/config), but it is certainly not the only
    way, or the most secure way, to deal with secrets. You could use a secret management
    system, such as HashiCorp Vault or Amazon Secrets Manager, to store and retrieve
    secrets. We will cover this in detail in both [*Chapter 8*](B11641_08_Final_AM_ePub.xhtml#_idTextAnchor157),
    *Deploying Docker Apps to Kubernetes*, and [*Chapter 14*](B11641_14_Final_NM_ePub.xhtml#_idTextAnchor316),
    *Advanced Docker Security – Secrets, Secret Commands, Tagging, and Labels*; but
    for now, let's just use environment variables for the secrets.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should replace the secret in the environment variable, `SESSION_SECRET`,
    with a random secret and confirm whether you want to expose port `80` to the world.
    Use whatever editor you are comfortable with, whether that is `vi`, `emacs`, or
    `nano`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Once you have set the environment variable overrides, you can deploy the application.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying for the first time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once you have copied your `.env` file in place, start the services in the background
    to deploy the application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Verify that the services are running, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Check whether the system logs show any errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: As long as you don't see a stream of error messages in the logs, you should
    then be able to reach the website at [the IP address o](http://192.0.2.10)f the
    server—for example, at `http://192.0.2.10`—substituting your IP address. If you
    assigned a hostname using DNS, you should be able to [reach it using that hostname—f](http://shiptclicker.example.com)or
    example, at [http://shiptclicker.example.com](http://shiptclicker.example.com)—substituting
    the full canonical domain name for this one.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting common errors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you get an error like this, you need to ensure that the host is not running
    another web server, such as Apache HTTPD or NGINX:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If you get this issue, you should either uninstall the web server that is running
    on the host or change what port it uses to listen for requests. You could also
    change the port that ShipIt Clicker runs on by changing the `PORT` variable in
    the `.env` file. For Red Hat family systems, a server listening on port `80` is
    likely to be Apache HTTPd, and you can remove it with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'For Debian family systems, it is also likely to be Apache, and you will need
    to use the following command to remove it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'It is possible that you might have some other web server running. You can find
    out what the process name of your web server is with `netstat`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: You may not need to do any troubleshooting to get your application running in
    Docker, but in a single-host deployment scenario, you can use your system administration
    troubleshooting skills to figure out what might be going wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have the application running, you may find that you run some of the
    same operations repeatedly, such as rebuilding the application when you have made
    changes. This is where support scripts come in handy.
  prefs: []
  type: TYPE_NORMAL
- en: Supporting scripts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When running a site in production, you might have to do some operations frequently.
    It becomes tiresome to remember the exact sequence of the Docker commands required
    to restart and update the running system or to connect to the database.
  prefs: []
  type: TYPE_NORMAL
- en: You should continue to develop your application on your local workstation and
    use the production system to deploy changes to your users, once you have tested
    things locally.
  prefs: []
  type: TYPE_NORMAL
- en: With the improved networking setup in this chapter, it is no longer possible
    to connect directly to the Redis container via a direct TCP port, so we will use
    `docker exec` within a script to do that.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are in the `Docker-for-Developers``/chapter6` directory, you can permanently
    add this directory to `PATH` with the following commands to make running these
    scripts more convenient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The most common operations for this application are probably restarting the
    application, deploying changes, and connecting to Redis to troubleshoot. For these
    operations, we will use the `restart.sh` script, the `deploy.sh` script, and the
    `redis-cli.sh` script.
  prefs: []
  type: TYPE_NORMAL
- en: Restarting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `restart.sh` script will restart all the containers. You should run this
    after you make a change to the configuration file, `.env`. You could just run
    `docker-compose up -d`, but that alone will not tell you whether the changes took
    hold. This will also run `docker-compose ps` for you, which will show you whether
    your containers are running correctly after the change, including what the port
    mappings are. In the following example session, we remove the `.env` file entirely
    and then recreate it with just a single setting for `PORT=80`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the `chapter6_shipit-clicker-web-v2_1` application was recreated
    the second time that `restart.sh` was run, and that the server is now connected
    to the wildcard IPv4 `0.0.0.0` address on port `80`. This will allow the server
    to respond to an HTTP request without a special port number in the URL.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `deploy.sh` script pulls changes from the `git` upstream repository, builds
    the container, and restarts any containers requiring an update. You should use
    this after you have made changes to the code and tested them locally.
  prefs: []
  type: TYPE_NORMAL
- en: Redis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `redis-cli.sh` script will allow you to connect to the running Redis server
    in the command line. It uses a `docker exec` command, which attaches to the running
    container and starts a new `redis-cli` command within it This is needed in part
    because now, Redis is running in an isolated network, and you should not be able
    to reach it via TCP sockets, even from the production host. This will let you
    troubleshoot any issues with the backend server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a sample session showing `redis-cli.sh` in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Note that you can use this `redis-cli.sh` script to connect to the Redis server,
    even though it is on a private virtual network that would be inaccessible if you
    had installed the standard `redis-cli` program on the host. Being able to rely
    on tools in a container can allow you to reach deep into the configuration of
    an application, even though it is protected from being directly exposed to the
    internet.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise – keeping builds off the production server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The deployment script for this chapter does the simplest thing possible for
    updates: it rebuilds the container on the production server. This might, however,
    lead to resource exhaustion and bringing the production server down.'
  prefs: []
  type: TYPE_NORMAL
- en: Given what you learned about Docker Hub in [*Chapter 4*](B11641_04_Final_NM_ePub.xhtml#_idTextAnchor059),
    *Composing Systems Using Containers*, how might you change the workflow of application
    development to revise the `docker-compose.yml` file and the `deploy.sh` script
    to avoid building the Docker container on the production server?
  prefs: []
  type: TYPE_NORMAL
- en: Write down one or two sentences describing the workflow that you would use and
    what alterations to the `docker-compose.yml` configuration file would be needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note:'
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple ways to achieve these goals, and there is no single answer
    to how to achieve them. You can compare your answer with the `docker-compose.yml`
    file in the next chapter to see how your ideas compare to the solution for building
    the containers highlighted in that chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise – planning to secure the production site
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Imagine that you hear from your boss that the ShipIt Squirrel code and production
    systems are going to get some attention from your company''s chief information
    security officer, who is going to go through everything looking for weaknesses.
    He is concerned that in the rush to get this live, too many shortcuts have been
    taken, and he wants you to provide some more information to him. Please write
    down the answers to these three questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What could be done to secure communication between the clients and the server
    with SSL? Which of the following should you do?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Terminate SSL within the program itself.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. Use an external load balancer to terminate SSL.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Use a web server on the host, but outside Docker, to terminate SSL.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Use Docker and a web server container to terminate SSL.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How do you plan on renewing the SSL certificate periodically?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are there other weaknesses in the security of the current system that you can
    find, either at the Docker layer or the API layer?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have deployed the application and considered some enhancements to its
    security, you should learn how to monitor the deployment so that you can find
    out when something goes wrong before the users of your application notice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Answers for how to secure the production site:'
  prefs: []
  type: TYPE_NORMAL
- en: Any of the four options for *Question 1* could work, but options *b* and *d*
    are the most robust and stable in practice. Option *a* is tricky to get right,
    and option *c* requires separate updates to the application environment.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding *Question 2*, you can either purchase an SSL certificate from a vendor,
    which you must renew and reinstall every year, you can rely on the vendor of your
    load balancer to automatically renew your certificate (if they offer that as an
    option), or you can use Let's Encrypt to automatically renew the certificate.
    See the *Further reading* section of the next chapter for more about using Let's
    Encrypt to renew the certificate, as well as using a set of Docker containers
    to terminate SSL.
  prefs: []
  type: TYPE_NORMAL
- en: '*Question 3* is open-ended, but the first thing that you should notice is that
    there is no authentication or authorization built into the web services in the
    `chapter6` code base.'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring small deployments – logging and alerting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the nice things about starting small is that you may be able to rely
    on very simple mechanisms for both logging and alerting. For any deployment using
    Docker and `Docker Compose` on a single host—for example, a deployment of ShipIt
    Clicker—you can use some basic tools and commands to deal with logging, and a
    variety of simple alerting services provided by third parties to deal with alerting.
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For logging, in many cases, all that is required is to use the logs built into
    Docker. Docker captures the standard output and standard error file handles of
    every process it starts and makes them available as logs for each container. You
    can review the consolidated logs for all the services started since the last container
    restart with the following command, assuming you are in the directory where your
    `docker-compose.yml` file is present (`less -R` will interpret the ANSI color
    escapes that the `logs` command produces):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also do `docker ps` in order to find the name of the running containers
    so that you can retrieve their log streams:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have the names of the containers, you can retrieve the individual
    log files for each running container separately. You can pipe them to `less`,
    or redirect the output of the logs to a file, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This procedure does require you to log into the production server and run some
    commands there, but in practice, this is a good way to examine the logs of an
    application running on a single host.
  prefs: []
  type: TYPE_NORMAL
- en: Alerting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To begin, it would be enough to monitor the HTTP server on port `80` of the
    production server to ensure it stays alive. If you have access to a network monitoring
    system for your company—for example, a Nagios or Icinga server—you could use that.
    If the system is accessible via the internet, you can use a free monitoring service,
    such as [https://uptimerobot.com](https://uptimerobot.com), to monitor the server.
  prefs: []
  type: TYPE_NORMAL
- en: In order to extend monitoring deeper, you might want to also monitor the internal
    services, such as Redis. This is more challenging in a simple setup like this
    one, though. We will go into more depth about advanced monitoring systems in [*Chapter
    10*](B11641_10_Final_AM_ePub.xhtml#_idTextAnchor226), *Monitoring Docker Using
    Prometheus, Grafana, and Jaeger*.
  prefs: []
  type: TYPE_NORMAL
- en: The basic idea here is that you want to get either an email, an SMS message,
    or both if the system goes down.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of single-host deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What could go wrong with deploying a Docker application to a single host? Plenty!
    While single-host deployment offers operational simplicity, it has some major
    limitations. Let's look at some of the limitations in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: No automatic failover
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If either the database server container or the web service container fails and
    cannot be restarted automatically, the site will be down and will require manual
    intervention. This might be as simple as noticing that your monitoring system
    says that the site is down, and so you need to SSH in and reboot the server. But
    sometimes, a single server will be so low on memory that it must be manually rebooted
    from a higher-level console or even power-cycled manually. This tends to lead
    to significant periods of time where an application is down and not available
    to serve requests.
  prefs: []
  type: TYPE_NORMAL
- en: Inability to scale horizontally to accept more load
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What happens if the traffic for the system exceeds the current capacity? In
    single-host deployment, you may be able to switch the host to a larger computer
    with more memory and processors, which is called *vertical scaling*. That is much
    easier in a cloud environment than it is in an environment, where you have to
    deal with physical hardware, such as an on-premises or data center environment.
    It would be much harder to adapt these simple deployment techniques to a whole
    fleet of server instances—which is called *horizontal scaling*.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking down unstable behavior based on incorrect host tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Depending on your hosting provider, the base operating system you start with,
    and how the Docker containers are configured, you might experience instability
    that is hard to track down. Maybe your host gets rebooted frequently due to the
    provider's network detecting unstable hardware or network conditions. Maybe you
    have configured your operating system to install automatic updates and applying
    them causes periods of outages. Maybe the application grows in memory until it
    triggers a failure of some kind.
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity's sake, the examples in this chapter do not specify memory limits
    at an application or container level. This means that the Redis container could
    consume all available memory on the host since it lacks a `max_memory` setting
    in its application-level main configuration file. It also means that the node
    container running the Express web application could leak memory until the operating
    system **Out-Of-Memory** (**OOM**) killer terminates it or the Docker daemon.
  prefs: []
  type: TYPE_NORMAL
- en: One way of mitigating this problem is by configuring virtual memory on the host
    using a swap file or swap partition, which makes the system look as if it has
    more physical memory than it actually does. If you do not configure a swap file
    on the host, you may find that running the `deploy.sh` script will fail. You might
    not see any messages in the console when this happens, but if you check `/var/log/messages`,
    you will find traces of the Linux kernel's OOM killer terminating the `npm` install
    program or another part of the Docker container build process.
  prefs: []
  type: TYPE_NORMAL
- en: 'See the Docker documentation for more on the dangers of not configuring the
    memory for your containers and operating system appropriately:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.docker.com/config/containers/resource_constraints/](https://docs.docker.com/config/containers/resource_constraints/)'
  prefs: []
  type: TYPE_NORMAL
- en: Loss of single host could be disastrous – backups are essential
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have hosted your application on a single physical or virtual server,
    you should ensure that the system is backed up regularly. Many providers have
    an image backup service that you can configure to take daily backups and preserve
    them for some period of time for an extra cost. You could also script backups
    of the critical volumes using old-school methods, such as using [TAR and SSH or
    using a modern backup sy](https://restic.readthedocs.io/en/latest/)stem, such
    as `restic` (see [https://restic.readthedocs.io/en/latest/](https://restic.readthedocs.io/en/latest/)),
    to back up the files and volumes to a cloud storage system.
  prefs: []
  type: TYPE_NORMAL
- en: Case study – migrating from CoreOS and Digital Ocean to CentOS 7 and AWS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the authors, Richard Bul[lington-McGuire, maintained](https://freezingsaddles.org/)
    a winter cycling competition website, [https://freezingsaddles.org/](https://freezingsaddles.org/),
    on a Digital Ocean droplet using CoreOS for more than a year. This system would
    frequently be knocked offline after a reboot, and it was difficult to track down
    exactly what the problems were that caused the periodic outages. Lack of console
    access to the Digital Ocean control panel and a lack of familiarity with CoreOS
    made troubleshooting the system even more difficult. To ensure that the system
    was backed up, `restic` was installed and configured to send backups to Amazon
    S3\. After many frustrating system administration experiences, the system was
    moved over to AWS using Lightsail, running CentOS 7 as a host operating system.
    To guard against OOM conditions, the new system ran with a swap file equal in
    size to RAM. After this, the system stopped randomly failing every few days and
    operations became much more smooth. Additionally, the new system had daily automatic
    snapshot backups enabled, lessening the need to back up the system with an application-level
    tool such as `restic`. Even so, if the system reboots, the web server does not
    always come up smoothly, with manual intervention required to restore the service.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The simplest way to get your Docker-based application to production is to deploy
    it onto a single host with Docker Compose. If you have properly prepared the host
    with the right software, including Docker Compose, you can deploy your application
    there in a production-ready configuration. This can be completed in a matter of
    hours and can serve applications with low to moderate performance and availability
    demands efficiently. If you make the right adjustments to your configuration files,
    your application will be ready to deploy to production. By using shell scripts
    that encapsulate long, verbose commands, you can more easily handle regular maintenance
    and updates for your applications. In the simplest case, you can use external
    monitoring and alerting for this class of application and handle this concern
    with low effort.
  prefs: []
  type: TYPE_NORMAL
- en: You can apply what you have learned in this chapter to increase the sophistication
    of the Dockerfile and the `docker-compose.yml` file that support your application.
    You can craft simple shell scripts to automate the most common applications. You
    will have learned [that you can rely on e](https://uptimerobot.com)xternal monitoring
    through services such as [https://uptimerobot.com](https://uptimerobot.com) to
    provide simple availability monitoring, and that you can use the built-in Docker
    logging facilities to provide insights into the operations of your application.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have an application deployed, it would be a good idea to increase the
    level of automation surrounding it, particularly related to how you can build
    and deploy the application. In the next chapter, we will see how you can use Jenkins,
    a common continuous integration system, to [automate deployment and testing.](https://www.packtpub.com/free-ebooks/virtualization-and-cloud/docker-cookbook-second-edition/9781788626866)
  prefs: []
  type: TYPE_NORMAL
- en: '[Further reading](https://www.packtpub.com/free-ebooks/virtualization-and-cloud/docker-cookbook-second-edition/9781788626866)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Docker Cookbook*: https://www.packtpub.com/free-ebooks/vi](https://www.packtpub.com/free-ebooks/virtualization-and-cloud/docker-cookbook-second-edition/9781788626866)rtualization-and-cloud/docke[r-cookbook-second-edition/9781788626866](https://docs.docker.com/compose/production/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Use*](https://docs.docker.com/compose/production/) *Compose in production*:
    https:/[/docs.docker.com/compose/production/](https://geekflare.com/best-open-source-monitoring-software/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Open source monitoring](https://geekflare.com/best-open-source-monitoring-software/)
    tools: https://geekflar[e.com/best-open-source-monitoring-software/](https://www.dnsstuff.com/free-network-monitoring-software)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Free monitori](https://www.dnsstuff.com/free-network-monitoring-software)ng
    tools: https://www.dnsstuff.com/free-ne[twork-monitoring-software](https://vsupalov.com/docker-compose-production/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Is `docker-compose` sui](https://vsupalov.com/docker-compose-production/)ted
    for production? [https://vsupalov.com/docker-compose-production/](https://vsupalov.com/docker-compose-production/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Docker tip 2: the difference between `COPY` and `ADD` in a Dockerfile: [https://nickjanetakis.com/blog/docker-tip-2-the-difference-between-copy-and-add-in-a-dockerile](https://nickjanetakis.com/blog/docker-tip-2-the-difference-between-copy-and-add-in-a-dockerile)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you are running a real production application on a single host with docker-compose,
    you should strongly consider securing your site with SSL. You can use Let''s Encrypt
    and a host of Docker sidecar containers to achieve this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'How to use Let''s Encrypt, NGINX, and Docker to secure your site with SSL:
    [https://github.com/nginx-proxy/docker-letsencrypt-nginxproxy-companion](https://github.com/nginx-proxy/docker-letsencrypt-nginxproxy-companion)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using `docker-compose.yml` to configure Let''s Encrypt with NGINX and Docker:
    [https://github.com/nginx-proxy/docker-letsencryptnginx-proxy-companion/blob/master/docs/Docker-Compose.md](https://github.com/nginx-proxy/docker-letsencryptnginx-proxy-companion/blob/master/docs/Docker-Compose.md)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
