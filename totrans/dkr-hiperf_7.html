<html><head></head><body>
<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch07" class="calibre1"/>Chapter 7. Troubleshooting Containers</h1></div></div></div><p class="calibre8">Sometimes, instrumentation, such as the monitoring and logging system we set up in <a class="calibre1" title="Chapter 4. Monitoring Docker Hosts and Containers" href="part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e">Chapter 4</a>, <em class="calibre9">Monitoring Docker Hosts and Containers</em>, is not enough. Ideally, we should put in place a way to troubleshoot our Docker deployments in a scalable fashion. However, sometimes, we have no choice but to log in to the Docker host and look at the Docker containers themselves.</p><p class="calibre8">In this chapter, we will cover the following topics:</p><div><ul class="itemizedlist"><li class="listitem">Inspecting containers with <code class="literal">docker exec</code></li><li class="listitem">Debugging from outside Docker</li><li class="listitem">Other debugging suites</li></ul></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_1"><a id="ch07lvl1sec40" class="calibre1"/>Inspecting containers</h1></div></div></div><p class="calibre8">When <a id="id277" class="calibre1"/>troubleshooting servers, the traditional way to debug is to log in and poke around the machine. With Docker, this typical workflow is split into two steps: the first is logging in to the Docker host using standard remote access tools such as <code class="literal">ssh</code>, and the second is entering the desired running container's process namespace with <code class="literal">docker exec</code>. This is useful as a last resort to debug what is happening inside our application.</p><p class="calibre8">For most of this chapter, we will troubleshoot and debug a Docker container running HAProxy. To prepare this container, create a configuration file for HAProxy named <code class="literal">haproxy.cfg</code> with the following content:</p><div><pre class="programlisting">defaults
  mode http
  timeout connect 5000ms
  timeout client 50000ms
  timeout server 50000ms

frontend stats
  bind 127.0.0.1:80
  stats enable

listen http-in
  bind *:80
  server server1 www.debian.org:80</pre></div><p class="calibre8">Next, using the official Docker image for HAProxy (<code class="literal">haproxy:1.5.14</code>), we will run the container together with the configuration we created earlier. Run the following command in our Docker host to start HAProxy with our prepared configuration:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ docker run -d -p 80:80 --name haproxy \</strong>
<strong class="calibre2">    -v `pwd`/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg \</strong>
<strong class="calibre2">    haproxy:1.5.14</strong>
</pre></div><p class="calibre8">Now, we can begin <a id="id278" class="calibre1"/>inspecting our container and debugging it. A good first example is to confirm that the HAProxy container is listening to port <code class="literal">80</code>. The <code class="literal">ss</code> program dumps a summary of sockets statistics available in most Linux distributions, such as our Debian Docker host. We can run the following command to display the statistics of the listening sockets inside our Docker container:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ docker exec haproxy /bin/ss -l</strong>
<strong class="calibre2">State   Recv-Q Send-Q   Local Address:Port  Peer Address:Port</strong>
<strong class="calibre2">LISTEN  0      128                  *:http             *:*</strong>
<strong class="calibre2">LISTEN  0      128          127.0.0.1:http             *:*</strong>
</pre></div><p class="calibre8">This approach with <code class="literal">docker exec</code> only worked because <code class="literal">ss</code> is included by default in the <code class="literal">debian:jessie</code> parent container of <code class="literal">haproxy:1.5.14</code>. We cannot use a similar tool that is not installed by default, such as <code class="literal">netstat</code>. Typing an equivalent <code class="literal">netstat</code> command will give the following error:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ docker exec haproxy /usr/bin/netstat -an</strong>
<strong class="calibre2">dockerhost$ echo $?</strong>
<strong class="calibre2">255</strong>
</pre></div><p class="calibre8">Let's investigate what happened by looking at the logs of Docker Engine Service. Typing the following command shows that the <code class="literal">netstat</code> program doesn't exist inside our container:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ journalctl -u docker.service –o cat</strong>
<strong class="calibre2">...</strong>
<strong class="calibre2">time="..." level=info msg="POST /v1.20/containers/haproxy/exec"</strong>
<strong class="calibre2">time="..." level=info msg="POST /v1.20/exec/c64fcf22b5c4.../start"</strong>
<strong class="calibre2">time="..." level=warning msg="signal: killed"</strong>
<strong class="calibre2">time="..." level=error msg="Error running command in existing...:"</strong>
<strong class="calibre2">       " [8] System error: exec: \"/usr/bin/netstat\":"</strong>
<strong class="calibre2">       " stat /usr/bin/netstat: no such file or directory"</strong>
<strong class="calibre2">time="..." level=error msg="Handler for POST /exec/{n.../start..."</strong>
<strong class="calibre2">time="..." level=error msg="HTTP Error" err="Cannot run exec c..."</strong>
<strong class="calibre2">2015/11/18 17:58:12 http: response.WriteHeader on hijacked conn...</strong>
<strong class="calibre2">2015/11/18 17:58:12 http: response.Write on hijacked connect...</strong>
<strong class="calibre2">time="..." level=info msg="GET /v1.20/exec/c64fcf22b5c47be8278..."</strong>
<strong class="calibre2">...</strong>
</pre></div><p class="calibre8">An alternative way to find out whether <code class="literal">netstat</code> is installed in our system is to enter our container interactively. The <code class="literal">docker exec</code> command has the <code class="literal">-it</code> flags that we can use to spawn an interactive shell session to perform the debugging. Type the following command to use the <code class="literal">bash</code> shell to get inside our container:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ docker exec -it haproxy /bin/bash</strong>
<strong class="calibre2">root@b397ffb9df13:/#    </strong>
</pre></div><p class="calibre8">Now that we are in a standard shell environment, we can debug with all the standard Linux utilities available inside our container. We will cover some of these commands in the next section. For now, let's take a look at why <code class="literal">netstat</code> doesn't work inside our container, as follows:</p><div><pre class="programlisting">
<strong class="calibre2">root@b397ffb9df13:/# netstat</strong>
<strong class="calibre2">bash: netstat: command not found</strong>
<strong class="calibre2">root@b397ffb9df13:/# /usr/bin/netstat -an</strong>
<strong class="calibre2">bash: /usr/bin/netstat: No such file or directory </strong>
</pre></div><p class="calibre8">As we can see here, <code class="literal">bash</code> is telling us that at this point, we have figured out that we don't have <code class="literal">netstat</code> <a id="id279" class="calibre1"/>installed through a more interactive debugging session.</p><p class="calibre8">We can provide a quick workaround by installing it inside our container, similar to what we do in a normal Debian environment. While we are still inside the container, we will type the following command to install <code class="literal">netstat</code>:</p><div><pre class="programlisting">
<strong class="calibre2">root@b397ffb9df13:/# apt-get update</strong>
<strong class="calibre2">root@b397ffb9df13:/# apt-get install -y net-tools</strong>
</pre></div><p class="calibre8">Now, we can run <code class="literal">netstat</code> successfully, as follows:</p><div><pre class="programlisting">
<strong class="calibre2">root@b397ffb9df13:/# netstat -an</strong>
<strong class="calibre2">Active Internet connections (servers and established)</strong>
<strong class="calibre2">Proto Recv-Q Send-Q Local Address   Foreign Address      State</strong>
<strong class="calibre2">tcp        0      0 0.0.0.0:80      0.0.0.0:*            LISTEN</strong>
<strong class="calibre2">tcp        0      0 127.0.0.1:80    0.0.0.0:*            LISTEN</strong>
<strong class="calibre2">Active UNIX domain sockets (servers and established)</strong>
<strong class="calibre2">Proto RefCnt Flags       Type       State         I-Node   Path</strong>
</pre></div><p class="calibre8">This approach of ad hoc container debugging is not recommended! We should have proper instrumentation and monitoring in place the next time we iterate on the design of our Docker infrastructure. Let's improve on what we initially built in <a class="calibre1" title="Chapter 4. Monitoring Docker Hosts and Containers" href="part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e">Chapter 4</a>, <em class="calibre9">Monitoring Docker Hosts and Containers</em>, next time! The following are some limitations of this last-resort approach:</p><div><ol class="orderedlist"><li class="listitem" value="1">When we stop and recreate the container, the <code class="literal">netstat</code> package we installed will not be available anymore. This is because the original HAProxy Docker image doesn't contain it in the first place. Installing ad hoc packages to run containers defeats the main feature of Docker, enabling an immutable infrastructure.</li><li class="listitem" value="2">In case we want to package all the debugging tools inside our Docker image, its size will increase correspondingly. This means that our deployments will get larger and  become <a id="id280" class="calibre1"/>slower. Remember that in the <a class="calibre1" title="Chapter 2. Optimizing Docker Images" href="part0018_split_000.html#H5A42-afc4585f6623427885a0b0c8e5b2e22e">Chapter 2</a>, <em class="calibre9">Optimizing Docker Images</em>, we optimized to reduce our container's size.</li><li class="listitem" value="3">In the case of minimal containers with just the required binaries, we are now mostly blind. The <code class="literal">bash</code> shell is not even available! There is no way to enter our container; take a look at the following command:<div><pre class="programlisting">
<strong class="calibre2">dockerhost$ docker exec -it minimal_image /bin/bashdockerhost$ echo $?</strong>
<strong class="calibre2">255</strong>
</pre></div></li></ol><div></div><p class="calibre8">In summary, <code class="literal">docker exec</code> is a powerful tool to get inside our containers and debug by running various commands. Coupled with the <code class="literal">-it</code> flags, we can get an interactive shell to perform deeper debugging. This approach has limitations because it assumes that all the tools available inside our Docker container are ready to use.</p><div><h3 class="title2"><a id="note42" class="calibre1"/>Note</h3><p class="calibre8">More information <a id="id281" class="calibre1"/>about the <code class="literal">docker exec</code> command can be found in the official documentation at <a class="calibre1" href="https://docs.docker.com/reference/commandline/exec">https://docs.docker.com/reference/commandline/exec</a>.</p></div><p class="calibre8">The next section deals with how to go around this limitation by having tools from outside Docker inspect the state of our running container. We will provide a brief overview on how to use some of these tools.</p></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch07lvl1sec41" class="calibre1"/>Debugging from the outside</h1></div></div></div><p class="calibre8">Even though <a id="id282" class="calibre1"/>Docker isolates the network, memory, CPU, and storage resources inside containers, each individual container will still have to go to the Docker host's operating system to perform the actual command. We can take advantage of this trickling down of calls to the host operating system to intercept and debug our Docker containers from the outside. In this section, we will cover some selected tools and how to use them to interact with our Docker containers. We can perform the interaction from the Docker host itself or from inside a sibling container with elevated privileges to see some components of the Docker host.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch07lvl2sec33" class="calibre1"/>Tracing system calls</h2></div></div></div><p class="calibre8">A <strong class="calibre2">system call tracer</strong> is <a id="id283" class="calibre1"/>one of the essential tools for server operations. It is a utility that intercepts and traces calls made by the application to the operating system. Each operating system has its own variation. Even if we run various applications and processes inside our Docker containers, it will eventually enter our Docker host's Linux operating system as a series of system calls.</p><p class="calibre8">On Linux systems, the <code class="literal">strace</code> program is used to trace these system calls. This interception and logging functionality of <code class="literal">strace</code> can be used to inspect our Docker containers from the outside. The list of system calls made throughout our container's lifetime can give a profile-level view on how it behaves.</p><p class="calibre8">To get started using <code class="literal">strace</code>, simply type the following command to install it inside our Debian Docker host:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ apt-get install strace</strong>
</pre></div><div><h3 class="title2"><a id="tip11" class="calibre1"/>Tip</h3><p class="calibre8">With the <code class="literal">--pid=host</code> option added to <code class="literal">docker run</code>, we can set a container's PID namespace to be of the Docker host's. This way, we'll be able to install and use <code class="literal">strace</code> inside a Docker container to inspect all the processes in the Docker host itself. We can also install <code class="literal">strace</code> from a different Linux distribution, such as CentOS or Ubuntu if we use the corresponding base image for our container.</p><p class="calibre8">More <a id="id284" class="calibre1"/>information describing this option is at <a class="calibre1" href="http://docs.docker.com/engine/reference/run/#pid-settings-pid">http://docs.docker.com/engine/reference/run/#pid-settings-pid</a>.</p></div><p class="calibre8">Now that we have <code class="literal">strace</code> installed in our Docker host, we can use it to inspect the system calls inside the HAProxy container we created in the previous section. Type the following commands to begin tracing the system calls from the <code class="literal">haproxy</code> container:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ PID=`docker inspect -f '{{.State.Pid}}' haproxy`dockerhost$ strace -p $PID</strong>
<strong class="calibre2">epoll_wait(3, {}, 200, 1000)            = 0</strong>
<strong class="calibre2">epoll_wait(3, {}, 200, 1000)            = 0</strong>
<strong class="calibre2">epoll_wait(3, {}, 200, 1000)            = 0</strong>
<strong class="calibre2">epoll_wait(3, {}, 200, 1000)            = 0</strong>
<strong class="calibre2">...</strong>
</pre></div><p class="calibre8">As you can see, our HAProxy container makes <code class="literal">epoll_wait()</code> calls to wait for incoming network connections. Now, in a separate terminal, type the following command to make an HTTP request to our running container:</p><div><pre class="programlisting">
<strong class="calibre2">$ curl http://dockerhost</strong>
</pre></div><p class="calibre8">Now, let's go back to our running <code class="literal">strace</code> program earlier. We can see the following lines printed out:</p><div><pre class="programlisting">
<strong class="calibre2">...</strong>
<strong class="calibre2">epoll_wait(3, {}, 200, 1000)            = 0</strong>
<strong class="calibre2">epoll_wait(3, {{EPOLLIN, {u32=5, u64=5}}}, 200, 1000) = 1</strong>
<strong class="calibre2">accept4(5, {sa_family=AF_INET, sin_port=htons(56470), sin_addr...</strong>
<strong class="calibre2">setsockopt(6, SOL_TCP, TCP_NODELAY, [1], 4) = 0</strong>
<strong class="calibre2">accept4(5, 0x7ffc087a6a50, [128], SOCK_NONBLOCK) = -1 EAGAIN (...</strong>
<strong class="calibre2">recvfrom(6, "GET / HTTP/1.1\r\nUser-Agent: curl"..., 8192, 0, ...</strong>
<strong class="calibre2">socket(PF_INET, SOCK_STREAM, IPPROTO_TCP) = 7</strong>
<strong class="calibre2">fcntl(7, F_SETFL, O_RDONLY|O_NONBLOCK)  = 0</strong>
<strong class="calibre2">setsockopt(7, SOL_TCP, TCP_NODELAY, [1], 4) = 0</strong>
<strong class="calibre2">connect(7, {sa_family=AF_INET, sin_port=htons(80), sin_addr=in...</strong>
<strong class="calibre2">epoll_wait(3, {}, 200, 0)               = 0</strong>
<strong class="calibre2">sendto(7, "GET / HTTP/1.1\r\nUser-Agent: curl"..., 74, MSG_DON...</strong>
<strong class="calibre2">recvfrom(6, 0x18c488e, 8118, 0, 0, 0)   = -1 EAGAIN (Resource ...</strong>
<strong class="calibre2">epoll_ctl(3, EPOLL_CTL_ADD, 7, {EPOLLOUT, {u32=7, u64=7}}) = 0...</strong>
<strong class="calibre2">epoll_ctl(3, EPOLL_CTL_ADD, 6, {EPOLLIN|EPOLLRDHUP, {u32=6, u6...</strong>
<strong class="calibre2">epoll_wait(3, {{EPOLLOUT, {u32=7, u64=7}}}, 200, 1000) = 1</strong>
<strong class="calibre2">sendto(7, "GET / HTTP/1.1\r\nUser-Agent: curl"..., 74, MSG_DON...</strong>
<strong class="calibre2">epoll_ctl(3, EPOLL_CTL_DEL, 7, 6bbc1c)  = 0</strong>
<strong class="calibre2">epoll_wait(3, {}, 200, 0)               = 0</strong>
<strong class="calibre2">recvfrom(7, 0x18c88d4, 8192, 0, 0, 0)   = -1 EAGAIN (Resource ...</strong>
<strong class="calibre2">epoll_ctl(3, EPOLL_CTL_ADD, 7, {EPOLLIN|EPOLLRDHUP, {u32=7, u6...</strong>
<strong class="calibre2">epoll_wait(3, {{EPOLLIN, {u32=7, u64=7}}}, 200, 1000) = 1</strong>
<strong class="calibre2">recvfrom(7, "HTTP/1.1 200 OK\r\nDate: Fri, 20 N"..., 8192, 0, ...</strong>
<strong class="calibre2">epoll_wait(3, {}, 200, 0)               = 0</strong>
<strong class="calibre2">sendto(6, "HTTP/1.1 200 OK\r\nDate: Fri, 20 N"..., 742, MSG_DO...</strong>
<strong class="calibre2">epoll_wait(3, {{EPOLLIN|EPOLLRDHUP, {u32=6, u64=6}}}, 200, 100...</strong>
<strong class="calibre2">recvfrom(6, "", 8192, 0, NULL, NULL)    = 0</strong>
<strong class="calibre2">shutdown(6, SHUT_WR)                    = 0</strong>
<strong class="calibre2">close(6)                                = 0</strong>
<strong class="calibre2">setsockopt(7, SOL_SOCKET, SO_LINGER, {onoff=1, linger=0}, 8) =...</strong>
<strong class="calibre2">close(7)                                = 0</strong>
<strong class="calibre2">epoll_wait(3, {}, 200, 1000)            = 0</strong>
<strong class="calibre2">...</strong>
</pre></div><p class="calibre8">We can see here that <a id="id285" class="calibre1"/>HAProxy made standard BSD-style socket system calls, such as <code class="literal">accept4()</code>, <code class="literal">socket()</code>, and <code class="literal">close()</code>, to accept, process, and terminate network connections from our HTTP client. Finally, it goes back to <code class="literal">epoll_wait()</code> again to wait for the next connections. Also, take note that <code class="literal">epoll_wait()</code> calls are spread throughout the trace even while HAProxy processes a connection. This shows how HAProxy can handle concurrent connections.</p><p class="calibre8">Tracing system calls is a very useful technique to debug live production systems. People in operations sometimes get paged and don't have access to the source code right away. Alternatively, there are instances where we are only given compiled binaries (or plain Docker images) running in production where there is no source code (nor <code class="literal">Dockerfile</code>). The only clue we can get <a id="id286" class="calibre1"/>from a running application is to trap the system calls it makes to the Linux kernel.</p><div><h3 class="title2"><a id="note43" class="calibre1"/>Note</h3><p class="calibre8">The <code class="literal">strace</code> <a id="id287" class="calibre1"/>webpage can be found at <a class="calibre1" href="http://sourceforge.net/projects/strace/">http://sourceforge.net/projects/strace/</a>. More information can be accessed through its man page as well by typing the following command:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ man 1 strace</strong>
</pre></div><p class="calibre8">For a more <a id="id288" class="calibre1"/>comprehensive list of system calls in Linux systems, refer to <a class="calibre1" href="http://man7.org/linux/man-pages/man2/syscalls.2.html">http://man7.org/linux/man-pages/man2/syscalls.2.html</a>. This will be useful in understanding the various outputs given by <code class="literal">strace</code>.</p></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch07lvl2sec34" class="calibre1"/>Analyzing network packets</h2></div></div></div><p class="calibre8">Most Docker <a id="id289" class="calibre1"/>containers that we deploy revolve around providing some form of network service. In the example of HAProxy in this chapter, our container basically serves HTTP network traffic. No matter what kind of container we have running, the network packets will eventually have to get out of the Docker host for it to complete a request that we send it. By dumping and analyzing the content of these packets, we can gain some insight into the nature of our Docker container. In this section, we will use a packet analyzer called <code class="literal">tcpdump</code> to view the traffic of network packets being received and sent by our Docker containers.</p><p class="calibre8">To begin using <code class="literal">tcpdump</code>, we can issue the following command in our Debian Docker host to install it:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ apt-get install -y tcpdump</strong>
</pre></div><div><h3 class="title2"><a id="tip12" class="calibre1"/>Tip</h3><p class="calibre8">We can also expose the Docker host's network interfaces to a container. With this approach, we can install t<code class="literal">cpdump</code> in a container and not pollute our main Docker host with ad hoc debugging packages. This can be done by specifying the <code class="literal">--net=host</code> flag on <code class="literal">docker run</code>. With this, we can access the <code class="literal">docker0</code> interface from inside our Docker container with <code class="literal">tcpdump</code>.</p></div><p class="calibre8">The example of using <code class="literal">tcpdump</code> will be very specific to the Vagrant VMware Fusion provider for VMware Fusion 7.0. Assuming we have a Docker Debian host as a Vagrant VMware Fusion box, run the following command to suspend and unsuspend our Docker host's virtual machine:</p><div><pre class="programlisting">
<strong class="calibre2">$ vagrant suspend</strong>
<strong class="calibre2">$ vagrant up</strong>
<strong class="calibre2">$ vagrant ssh</strong>
<strong class="calibre2">dockerhost$</strong>
</pre></div><p class="calibre8">Now that we are back inside our Docker host, run the following command and note that we cannot resolve <code class="literal">www.google.com</code> anymore inside our interactive <code class="literal">debian:jessie</code> container, as follows:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ docker run -it debian:jessie /bin/bash</strong>
<strong class="calibre2">root@fce09c8c0e16:/# ping www.google.com</strong>
<strong class="calibre2">ping: unknown host</strong>
</pre></div><p class="calibre8">Now, let's run <a id="id290" class="calibre1"/>
<code class="literal">tcpdump</code> in a separate terminal. While running the preceding ping command, we will notice the following output from our <code class="literal">tcpdump</code> terminal:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ tcpdump -i docker0</strong>
<strong class="calibre2">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</strong>
<strong class="calibre2">listening on docker0, link-type EN10MB (Ethernet), capture size 262144 bytes</strong>
<strong class="calibre2">22:03:34.512942 ARP, Request who-has 172.17.42.1 tell 172.17.0.7, length 28</strong>
<strong class="calibre2">22:03:35.512931 ARP, Request who-has 172.17.42.1 tell 172.17.0.7, length 28</strong>
<strong class="calibre2">22:03:38.520681 ARP, Request who-has 172.17.42.1 tell 172.17.0.7, length 28</strong>
<strong class="calibre2">22:03:39.520099 ARP, Request who-has 172.17.42.1 tell 172.17.0.7, length 28</strong>
<strong class="calibre2">22:03:40.520927 ARP, Request who-has 172.17.42.1 tell 172.17.0.7, length 28</strong>
<strong class="calibre2">22:03:43.527069 ARP, Request who-has 172.17.42.1 tell 172.17.0.7, length 28</strong>
</pre></div><p class="calibre8">As we can see, the interactive <code class="literal">/bin/bash</code> container is looking for <code class="literal">172.17.42.1</code>, which is normally the IP address attached to the Docker Engine network device, <code class="literal">docker0</code>. With this figured out, take a look at <code class="literal">docker0</code> by typing the following command:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ ip addr show dev docker0</strong>
<strong class="calibre2">3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</strong>
<strong class="calibre2">    link/ether 02:42:46:66:64:b8 brd ff:ff:ff:ff:ff:ff</strong>
<strong class="calibre2">    inet6 fe80::42:46ff:fe66:64b8/64 scope link</strong>
<strong class="calibre2">       valid_lft forever preferred_lft forever</strong>
</pre></div><p class="calibre8">Now, we can view the problem. The <code class="literal">docker0</code> device doesn't have an IPv4 address attached to it. Somehow, VMware unsuspending our Docker host removes the mapped IP address in <code class="literal">docker0</code>. Fortunately, the solution is to simply restart the Docker Engine, and Docker will reinitialize the <code class="literal">docker0</code> network interface by itself. Restart Docker Engine by typing the following command in our Docker host:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ systemctl restart docker.service</strong>
</pre></div><p class="calibre8">Now, when we run the same command as earlier, will see that the IP address is attached, as follows:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ ip addr show dev docker0</strong>
<strong class="calibre2">3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noque...</strong>
<strong class="calibre2">    link/ether 02:42:46:66:64:b8 brd ff:ff:ff:ff:ff:ff</strong>
<strong class="calibre2">    inet 172.17.42.1/16 scope global docker0</strong>
<strong class="calibre2">       valid_lft forever preferred_lft forever</strong>
<strong class="calibre2">    inet6 fe80::42:46ff:fe66:64b8/64 scope link</strong>
<strong class="calibre2">       valid_lft forever preferred_lft forever</strong>
</pre></div><p class="calibre8">Let's go back to our <a id="id291" class="calibre1"/>initial command showing the problem; we will see that it is now solved, as follows:</p><div><pre class="programlisting">
<strong class="calibre2">root@fce09c8c0e16:/# ping www.google.com</strong>
<strong class="calibre2">PING www.google.com (74.125.21.105): 56 data bytes</strong>
<strong class="calibre2">64 bytes from 74.125.21.105: icmp_seq=0 ttl=127 time=65.553 ms</strong>
<strong class="calibre2">64 bytes from 74.125.21.105: icmp_seq=1 ttl=127 time=38.270 ms</strong>
<strong class="calibre2">...</strong>
</pre></div><div><h3 class="title2"><a id="note45" class="calibre1"/>Note</h3><p class="calibre8">More information <a id="id292" class="calibre1"/>about the <code class="literal">tcpdump</code> packet dumper and analyzer can be found at <a class="calibre1" href="http://www.tcpdump.org">http://www.tcpdump.org</a>. We can also access the documentation from where we installed it by typing the following command:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ man 8 tcpdump</strong>
</pre></div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch07lvl2sec35" class="calibre1"/>Observing block devices</h2></div></div></div><p class="calibre8">Data being accessed <a id="id293" class="calibre1"/>from our Docker containers will mostly reside in physical storage devices, such as hard disks or solid state drives. Underneath Docker's copy-on-write filesystems is a physical device that is randomly accessed. These drives are grouped together as block devices. Data here is randomly accessed fixed-size data called <em class="calibre9">blocks</em>.</p><p class="calibre8">So, in case our Docker containers have peculiar I/O behavior and performance issues, we can trace and troubleshoot what is happening inside our block devices using a tool called <code class="literal">blktrace</code>. All events the kernel generates to interact with the block devices from processes are intercepted by this program. In this section, we will set up our Docker host to observe the block device supporting our containers underneath.</p><p class="calibre8">To use <code class="literal">blktrace</code>, let's prepare our Docker host by installing the <code class="literal">blktrace</code> program. Type the following command to install it inside our Docker host:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ apt-get install -y blktrace</strong>
</pre></div><p class="calibre8">In addition, we need to enable the debugging of the filesystem. We can do this by typing the following command in our Docker host:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ mount -t debugfs debugfs /sys/kernel/debug</strong>
</pre></div><p class="calibre8">After the preparations, we need to figure out how to tell <code class="literal">blktrace</code> where to listen for I/O events. To trace I/O <a id="id294" class="calibre1"/>events for our containers, we need to know where the root of the Docker runtime is. In the default configuration of our Docker host, the runtime points to <code class="literal">/var/lib/docker</code>. To figure out which partition it belongs to, type the following command:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ df -h                                               </strong>
<strong class="calibre2">Filesystem      Size  Used Avail Use% Mounted on                </strong>
<strong class="calibre2">/dev/dm-0       9.0G  7.6G  966M  89% /                             </strong>
<strong class="calibre2">udev             10M     0   10M   0% /dev                      </strong>
<strong class="calibre2">tmpfs            99M   13M   87M  13% /run                      </strong>
<strong class="calibre2">tmpfs           248M   52K  248M   1% /dev/shm                  </strong>
<strong class="calibre2">tmpfs           5.0M     0  5.0M   0% /run/lock                 </strong>
<strong class="calibre2">tmpfs           248M     0  248M   0% /sys/fs/cgroup            </strong>
<strong class="calibre2">/dev/sda1       236M   34M  190M  15% /boot</strong>
</pre></div><p class="calibre8">As described in the preceding output, our Docker host's <code class="literal">/var/lib/docker</code> directory is under the <code class="literal">/</code> partition. This is where we will point <code class="literal">blktrace</code> to listen for events from. Type the following command to start listening for I/O events on this device:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ blktrace -d /dev/dm-0 -o dump</strong>
</pre></div><div><h3 class="title2"><a id="tip13" class="calibre1"/>Tip</h3><p class="calibre8">Using the <code class="literal">--privileged</code> flag in <code class="literal">docker run</code>, we can use <code class="literal">blktrace</code> within a container. Doing so will allow us to mount the debugged filesystem with the increased privileges.</p><p class="calibre8">More information on <a id="id295" class="calibre1"/>extended container privileges can be found at <a class="calibre1" href="https://docs.docker.com/engine/reference/run/#runtime-privilege-linux-capabilities-and-lxc-configuration">https://docs.docker.com/engine/reference/run/#runtime-privilege-linux-capabilities-and-lxc-configuration</a>.</p></div><p class="calibre8">To create a simple workload that will generate I/O events in our disk, we will create an empty file from a container until the / partition runs out of free space. Type the following command to generate this workload:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ docker run -d --name dump  debian:jessie \</strong>
<strong class="calibre2">    /bin/dd if=/dev/zero of=/root/dump bs=65000</strong>
</pre></div><p class="calibre8">Depending on the free space available in our root partition, this command may finish quickly. Right away, let's get the PID of the container we just ran using the following command:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ docker inspect -f '{{.State.Pid}}' dump</strong>
<strong class="calibre2">11099</strong>
</pre></div><p class="calibre8">Now that we know the PID of our Docker container that generated I/O events, we can look this up with the <code class="literal">blktrace</code> program's complementary tool, <code class="literal">blkparse</code>. The <code class="literal">blktrace</code> program only listens for the events in the Linux kernel's block I/O layer and dumps the results on a file. The <code class="literal">blkparse</code> program is the accompanying tool to view and analyze the events. In the workload we generated earlier, we can look for the I/O events that correspond to our <a id="id296" class="calibre1"/>Docker container's PID using the following command:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ blkparse -i dump.blktrace.0 | grep --color " $PID "</strong>
<strong class="calibre2">...</strong>
<strong class="calibre2">254,0    0      730    10.6267 11099  Q   R 13667072 + 24 [exe]</strong>
<strong class="calibre2">254,0    0      732    10.6293 11099  Q   R 5042728 + 16 [exe]</strong>
<strong class="calibre2">254,0    0      734    10.6299 11099  Q   R 13900768 + 152 [exe]</strong>
<strong class="calibre2">254,0    0      736    10.6313 11099  Q  RM 4988776 + 8 [exe]</strong>
<strong class="calibre2">254,0    0     1090    10.671 11099   C  W 11001856 + 1024 [0]</strong>
<strong class="calibre2">254,0    0     1091    10.6712 11099  C  W 11002880  +  1024  [0]</strong>
<strong class="calibre2">254,0    0     1092    10.6712 11099  C  W 11003904  +  1024 [0]</strong>
<strong class="calibre2">254,0    0     1093    10.6712 11099  C  W 11004928  +  1024 [0]</strong>
<strong class="calibre2">254,0    0     1094    10.6713 11099  C  W 11006976  +  1024 [0]</strong>
<strong class="calibre2">254,0    0     1095    10.6714 11099  C  W 11005952  +  1024 [0]</strong>
<strong class="calibre2">254,0    0     1138    10.6930 11099  C  W 11239424  +  1024 [0]</strong>
<strong class="calibre2">254,0    0     1139    10.6931 11099  C  W 11240448  +  1024 [0]</strong>
<strong class="calibre2">...</strong>
</pre></div><p class="calibre8">In the preceding highlighted output, we can see that the <code class="literal">/dev/dm-0</code> block offset the position of <code class="literal">11001856</code>, and there was a writing (<code class="literal">W</code>) of <code class="literal">1024</code> bytes of data that just completed (<code class="literal">C</code>). To probe further, we can look at this offset position on the events that it generated. Type the following command to filter out this offset position:</p><div><pre class="programlisting">
<strong class="calibre2">dockerhost$ blkparse -i dump.blktrace.0 | grep 11001856</strong>
<strong class="calibre2">...</strong>
<strong class="calibre2">254,0  0  1066  10.667  8207  Q   W 11001856 + 1024 [kworker/u2:2]</strong>
<strong class="calibre2">254,0  0  1090  10.671 11099  C   W 11001856 + 1024 [0]</strong>
<strong class="calibre2">...</strong>
</pre></div><p class="calibre8">We can see the write (<code class="literal">W</code>) being queued (<code class="literal">Q</code>) to our device by the <code class="literal">kworker</code> process, which means the write was queued by the kernel. After 40 milliseconds, the write request registered was completed for our Docker container process.</p><p class="calibre8">The debugging walkthrough we just performed is just a small sample of what we can do by tracing block I/O events with <code class="literal">blktrace</code>. For example, we can also probe our Docker container's I/O behavior in greater detail and figure out the bottlenecks that are happening to our application. Are there a lot of writes being made? Are the reads so much that they need caching? Having the actual events rather than only the performance metrics provided by the built-in <code class="literal">docker stats</code> command is helpful in very deep troubleshooting scenarios.</p><div><h3 class="title2"><a id="note46" class="calibre1"/>Note</h3><p class="calibre8">More information on the different output values of <code class="literal">blkparse</code> and flags to capture I/O <a id="id297" class="calibre1"/>events in <code class="literal">blktrace</code> can be found in the user guide located at <a class="calibre1" href="http://www.cse.unsw.edu.au/~aaronc/iosched/doc/blktrace.html">http://www.cse.unsw.edu.au/~aaronc/iosched/doc/blktrace.html</a>.</p></div></div></div>
<div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch07lvl1sec42" class="calibre1"/>A stack of troubleshooting tools</h1></div></div></div><p class="calibre8">Debugging applications <a id="id298" class="calibre1"/>inside Docker containers required a different approach from normal applications in Linux. However, the actual programs being used are the same because all the calls from inside the container will eventually go to the Docker host's kernel operating system. By knowing how calls go outside of our containers, we can use any other debugging tools we have to troubleshoot.</p><p class="calibre8">In addition to standard Linux tools, there are several container-specific utilities that package the preceding standard utilities to be more friendly for container usage. The following are some of these tools:</p><div><ul class="itemizedlist"><li class="listitem">Red Hat's <code class="literal">rhel-tools</code> Docker <a id="id299" class="calibre1"/>image is a huge container containing a combination of the tools we discussed earlier. Its documentation page at <a class="calibre1" href="https://access.redhat.com/documentation/en/red-hat-enterprise-linux-atomic-host/version-7/getting-started-with-containers/#using_the_atomic_tools_container_image">https://access.redhat.com/documentation/en/red-hat-enterprise-linux-atomic-host/version-7/getting-started-with-containers/#using_the_atomic_tools_container_image</a> shows how to run it with the proper Docker privileges for it to function correctly.</li><li class="listitem">The CoreOS t<code class="literal">oolbox</code> <a id="id300" class="calibre1"/>program is a small script utility that creates a small Linux container using Systemd's <code class="literal">systemd-nspawn</code> program. By copying the root filesystem from popular Docker images, we can install any tool we want without polluting the Docker host's filesystem with ad hoc debugging tools. Its use is documented on its webpage at <a class="calibre1" href="https://coreos.com/os/docs/latest/install-debugging-tools.html">https://coreos.com/os/docs/latest/install-debugging-tools.html</a>.</li><li class="listitem">The <code class="literal">nsenter</code> program is a utility to enter a Linux control group's process namespace. It is the predecessor to the <code class="literal">docker exec</code> program and is considered unmaintained. To get a history of how docker exec came to be, visit the <code class="literal">nsenter</code> <a id="id301" class="calibre1"/>program's project page at <a class="calibre1" href="https://github.com/jpetazzo/nsenter">https://github.com/jpetazzo/nsenter</a>.</li></ul></div></div>
<div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch07lvl1sec43" class="calibre1"/>Summary</h1></div></div></div><p class="calibre8">Remember that logging in to Docker hosts isn't scalable. Adding instrumentation at the application level, in addition to the ones given by our operating system, helps in faster and more efficient diagnosing of the problems that we may encounter in the future. Remember, nobody likes waking up at two in the morning to run <code class="literal">tcpdump</code> to debug a Docker container on fire!</p><p class="calibre8">In the next chapter, we will wrap up and look again at what it takes to get our Docker-based workloads to production.</p></div></body></html>