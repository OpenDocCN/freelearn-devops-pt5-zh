- en: Chapter 15. Self-Healing Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第15章 自我修复系统
- en: '|   | *Healing takes courage, and we all have courage, even if we have to dig
    a little to find it.* |   |'
  id: totrans-1
  prefs: []
  type: TYPE_TB
  zh: '|   | *修复需要勇气，我们都有勇气，即使我们需要挖掘一些才能找到它。* |   |'
- en: '|   | --*Tori Amos* |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '|   | --*Tori Amos* |'
- en: Let's face it. The systems we are creating are not perfect. Sooner or later,
    one of our applications will fail, one of our services will not be able to handle
    the increased load, one of our commits will introduce a fatal bug, a piece of
    hardware will break, or something entirely unexpected will happen.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们面对现实吧。我们正在创建的系统并不完美。迟早，我们的某个应用会失败，我们的某个服务无法承受增加的负载，我们的某个提交会引入致命的bug，某个硬件会损坏，或者某些完全意想不到的事情会发生。
- en: How do we fight the unexpected? Most of us are trying to develop a bullet proof
    system. We are attempting to create what no one did before. We strive for the
    ultimate perfection, hoping that the result will be a system that does not have
    any bugs, is running on hardware that never fails, and can handle any load. Here's
    a tip. There is no such thing as perfection. No one is perfect, and nothing is
    without fault. That does not mean that we should not strive for perfection. We
    should, when time and resources are provided. However, we should also embrace
    the inevitable, and design our systems not to be perfect, but able to recuperate
    from failures, and able to predict likely future. We should hope for the best
    but prepare for the worst.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何应对意外情况？大多数人都在尝试开发一个防弹系统。我们试图创造前所未有的东西。我们追求终极完美，希望结果是一个没有任何bug、运行在永不故障的硬件上的、能够处理任何负载的系统。这里有一个提示。没有完美这个东西。没有人是完美的，也没有什么是没有缺陷的。这并不意味着我们不应该追求完美。在时间和资源允许的情况下，我们应该追求完美。然而，我们也应该接受不可避免的事实，并设计我们的系统，不是为了完美，而是为了能够从故障中恢复，能够预测未来可能发生的情况。我们应该为最好的结果做好准备，但也要为最坏的情况做好准备。
- en: There are plenty of examples of resilient systems outside software engineering,
    none of them better than life itself. We can take ourselves, humanity, as an example.
    We're the result of a very long experiment based on small and incremental evolutionary
    improvements, performed over millions of years. We can learn a lot from a human
    body, and apply that knowledge to our software and hardware. One of the fascinating
    abilities we (humans) possess is the capacity to self-heal.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件工程之外，有许多坚韧系统的例子，而没有哪个比生命本身更好。我们可以以我们自己，人类，作为例子。我们是一个经过漫长实验的结果，这些实验基于小而渐进的进化改善，经过了数百万年。我们可以从人体中学到很多，并将这些知识应用于我们的软件和硬件。我们（人类）拥有的一个迷人能力就是自我修复的能力。
- en: Human body has an amazing capacity to heal itself. The most fundamental unit
    of human body is cell. Throughout our life, cells inside our body are working
    to bring us back to a state of equilibrium. Each cell is a dynamic, living unit
    that is continuously monitoring and adjusting its own processes, working to restore
    itself according to the original DNA code it was created with, and to maintain
    balance within the body. Cells have the ability to heal themselves, as well as
    to make new cells that replace those that have been permanently damaged or destroyed.
    Even when a large number of cells are destroyed, the surrounding cells replicate
    to make new cells, thereby quickly replacing the cells that were destroyed. This
    ability does not make us, individuals, immune to death, but it does make us very
    resilient. We are continuously attacked by viruses. We succumb to diseases and
    yet, in most cases, we come out victorious. However, looking at us as individuals
    would mean that we are missing the big picture. Even when our own lives end, the
    life itself not only survives, but thrives, ever growing, and ever adapting.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 人体具有惊人的自我修复能力。人体最基本的单位是细胞。在我们的一生中，体内的细胞不断工作，帮助我们恢复到平衡状态。每个细胞都是一个动态的、活跃的单元，不断监控和调整自身的过程，努力根据其最初的DNA代码恢复自我，并维持体内的平衡。细胞不仅具备自我修复的能力，还能生成新的细胞，替代那些被永久损坏或摧毁的细胞。即使大量细胞被摧毁，周围的细胞也会复制生成新细胞，从而迅速替代已被摧毁的细胞。这种能力并不能使我们免于死亡，但它确实让我们具有了很强的韧性。我们不断受到病毒的攻击，我们会生病，但在大多数情况下，我们最终会胜利。然而，把我们当作个体来看待就意味着我们忽视了更大的图景。即使我们自身的生命终结，生命本身不仅会生存下来，还会繁荣发展，持续生长，不断适应。
- en: We can think of a computer system as a human body that consists of cells of
    various types. They can be hardware or software. When they are software units,
    the smaller they are, the easier it is for them to self-heal, recuperate from
    failures, multiply, or even get destroyed when that is needed. We call those small
    units microservices, and they can, indeed, have behaviors similar to those observed
    in a human body. The microservices-based system we are building can be made in
    a way that is can self-heal. That is not to say that self-healing we are about
    to explore is applicable only to microservices. It is not. However, like most
    other techniques we explored, self-healing can be applied to almost any type of
    architecture, but provides best results when combined with microservices. Just
    like life that consists of individuals that form a whole ecosystem, each computer
    system is part of something bigger. It communicates, cooperates, and adapts to
    other systems forming a much larger whole.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以把计算机系统看作由各种类型的细胞组成的人体。这些细胞可以是硬件或软件。当它们是软件单元时，越小的单元越容易自愈、从故障中恢复、复制，甚至在需要时销毁。我们称这些小单元为微服务，它们的行为实际上类似于人体中的一些行为。我们正在构建的基于微服务的系统可以设计成具有自愈能力。并不是说我们即将探讨的自愈仅适用于微服务，它并非如此。然而，就像我们探讨的其他大多数技术一样，自愈可以应用于几乎任何类型的架构，但与微服务结合时能获得最佳效果。就像由个体组成的整体生态系统一样，每个计算机系统都是更大系统的一部分。它与其他系统进行通信、合作，并适应其他系统，形成一个更大的整体。
- en: Self-Healing Levels and Types
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自愈的层级与类型
- en: In software systems, the self-healing term describes any application, service,
    or a system that can discover that it is not working correctly and, without any
    human intervention, make the necessary changes to restore itself to the normal
    or designed state. Self-healing is about making the system capable of making its
    decisions by continually checking and optimizing its state and automatically adapting
    to changing conditions. The goal is to make fault tolerant and responsive system
    capable of responding to changes in demand and recuperation from failures.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件系统中，"自愈"一词描述的是任何能够发现自身工作不正常，并且在没有任何人工干预的情况下，做出必要的调整以恢复到正常或设计状态的应用程序、服务或系统。自愈的关键在于使系统能够通过持续检查和优化自身状态，自动适应变化的条件，从而做出决策。其目标是使系统具备容错性和响应性，能够应对需求的变化并从故障中恢复。
- en: 'Self-healing systems can be divided into three levels, depending on size and
    type of resources we are monitoring, and acting upon. Those levels are as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 自愈系统可以根据我们所监控和处理的资源的大小和类型分为三个层级，这些层级如下：
- en: Application level
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用层级
- en: System level
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统层级
- en: Hardware level
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件层级
- en: We'll explore each of those three types separately.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分别探讨这三种类型。
- en: Self-Healing on the Application Level
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用层的自愈
- en: Application level healing is the ability of an application, or a service, to
    heal itself internally. Traditionally, we're used to capturing problems through
    exceptions and, in most cases, logging them for further examination. When such
    an exception occurs, we tend to ignore it and move on (after logging), as if nothing
    happened, hoping for the best in the future. In other cases, we tend to stop the
    application if an exception of certain type occurs. An example would be a connection
    to a database. If the connection is not established when the application starts,
    we often stop the whole process. If we are a bit more experienced, we might try
    to repeat the attempt to connect to the database. Hopefully, those attempts are
    limited, or we might easily enter a never ending loop, unless database connection
    failure was temporary and the DB gets back online soon afterwards. With time,
    we got better ways to deal with problems inside applications. One of them is Akka.
    It's usage of supervisor, and design patterns it promotes, allow us to create
    internally self-healing applications and services. Akka is not the only one. Many
    other libraries and frameworks enable us to create fault tolerant applications
    capable of recuperation from potentially disastrous circumstances. Since we are
    trying to be agnostic to programming languages, I'll leave it to you, dear reader,
    investigation of ways to self-heal your applications internally. Bear in mind
    that self-healing in this context refers to internal processes and does not provide,
    for example, recuperation from failed processes. Moreover, if we adopt microservices
    architecture, we can quickly end up with services written in different languages,
    using different frameworks, and so on. It is truly up to developers of each service
    to design it in a way that it can heal itself and recuperate from failures.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 应用层自愈是指应用程序或服务能够在内部自我修复的能力。传统上，我们习惯通过异常捕获问题，并在大多数情况下将其记录以便后续检查。当发生此类异常时，我们往往会忽略它并继续前进（在记录日志之后），仿佛什么都没有发生，期待未来一切顺利。在其他情况下，如果发生某种类型的异常，我们往往会停止应用程序。例如，连接数据库时。如果应用程序启动时未能建立连接，我们通常会停止整个过程。如果我们稍微有经验一点，可能会尝试重复连接数据库。希望这些尝试是有限的，否则我们很容易陷入一个永无止境的循环，除非数据库连接失败是暂时性的，并且数据库很快恢复在线。随着时间的推移，我们找到了更好的方法来处理应用程序内部的问题。其中之一就是Akka。它使用的监督者机制和它所推广的设计模式，让我们能够创建具有自愈能力的内部应用程序和服务。Akka并不是唯一的，还有许多其他库和框架让我们能够创建具备容错能力的应用程序，从潜在的灾难性情况下恢复。由于我们尽量保持编程语言的独立性，我将把如何实现内部自愈留给你，亲爱的读者，去探索。请记住，这里的自愈是指内部过程的自我修复，并不包括例如从失败的进程中恢复。而且，如果我们采用微服务架构，我们可能会很快遇到使用不同语言、不同框架编写的服务等等。每个服务的开发人员真正决定了它如何设计，使其能够自我修复并从故障中恢复。
- en: Let's jump into the second level.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入第二个层次。
- en: Self-Healing on the System Level
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统层级的自愈
- en: Unlike the application level healing that depends on a programming language
    and design patterns that we apply internally, system level self-healing can be
    generalized and be applied to all services and applications, independently from
    their internals. This is the type of self-healing that we can design on the level
    of the whole system. While there are many things that can happen at the system
    level, the two most commonly monitored aspects are failures of processes and response
    time. If a process fails, we need to redeploy the service, or restart the process.
    On the other hand, if the response time is not adequate, we need to scale, or
    descale, depending whether we reached upper or lower response time limits. Recuperating
    from process failures is often not enough. While such actions might restore our
    system to the desired state, human intervention is often still needed. We need
    to investigate the cause of the failure, correct the design of the service, or
    fix a bug. That is, self-healing often goes hand in hand with investigation of
    the causes of that failure. The system automatically recuperates and we (humans)
    try to learn from those failures, and improve the system as a whole. For that
    reason, some kind of a notification is required as well. In both cases (failures
    and increased traffic), the system needs to monitor itself and take some actions.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与依赖于编程语言和我们内部应用的设计模式的应用级自愈不同，系统级自愈可以广泛应用于所有服务和应用，无论其内部结构如何。这是我们可以在整个系统级别设计的自愈类型。虽然在系统级别上可能会发生许多情况，但最常监控的两个方面是进程失败和响应时间。如果进程失败，我们需要重新部署服务或重启进程。另一方面，如果响应时间不合适，我们需要进行扩展或缩减，具体取决于我们是否已达到响应时间的上限或下限。从进程失败中恢复通常是不够的。尽管这样的操作可能会将系统恢复到所需状态，但通常仍然需要人工干预。我们需要调查故障原因，修正服务的设计或修复
    Bug。也就是说，自愈往往伴随故障原因的调查。系统会自动恢复，而我们（人类）则尝试从这些失败中学习，并改进整个系统。因此，某种类型的通知也是必需的。在故障和流量增加的两种情况下，系统都需要自我监控并采取措施。
- en: How does the system monitor itself? How does it check the status of its components?
    There are many ways, but two most commonly used are TTLs and pings.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 系统如何监控自己？它如何检查组件的状态？有许多方法，但最常用的两种是 TTL 和 Ping。
- en: Time-To-Live
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生存时间
- en: '**Time-to-live** (**TTL**) checks expect a service, or an application, to periodically
    confirm that it is operational. The system that receives TTL signals keeps track
    of the last known reported state for a given TTL. If that state is not updated
    within a predefined period, the monitoring system assumes that the service failed
    and needs to be restored to its designed state. For example, a healthy service
    could send an HTTP request announcing that it is alive. If the process the service
    is running in fails, it will be incapable to send the request, TTL will expire,
    and reactive measures will be executed.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**生存时间**（**TTL**）检查期望服务或应用程序定期确认其正常运行。接收 TTL 信号的系统会跟踪给定 TTL 的最后已知报告状态。如果该状态在预定时间内没有更新，监控系统会认为服务失败，并需要恢复到其设计状态。例如，一个健康的服务可以发送一个
    HTTP 请求，宣布它仍然活着。如果服务运行的进程失败，它将无法发送该请求，TTL 会过期，且会执行相应的应急措施。'
- en: 'The main problem with TTL is coupling. Applications and services need to be
    tied to the monitoring system. Implementing TTL would be one of the microservices
    anti-patterns since we are trying to design them in a way that they are as autonomous
    as possible. Moreover, microservices should have a clear function and a single
    purpose. Implementing TTL requests inside them would add additional functionality
    and complicate the development:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: TTL 的主要问题是耦合性。应用程序和服务需要与监控系统绑定。实现 TTL 会成为一种微服务反模式，因为我们试图以尽可能自主的方式设计它们。此外，微服务应该具有明确的功能和单一的目的。在它们内部实现
    TTL 请求会增加额外的功能，且会使开发过程更加复杂：
- en: '![Time-To-Live](img/B05848_15_01.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![生存时间](img/B05848_15_01.jpg)'
- en: Figure 15-01 – System level self-healing with time-to-live (TTL)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-01 – 系统级自愈与生存时间（TTL）
- en: Pinging
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Ping 操作
- en: The idea behind pinging is to check the state of an application, or a service,
    externally. The monitoring system should ping each service periodically and, if
    no response is received, or the content of the response is not adequate, execute
    healing measures. Pinging can come in many forms. If a service exposes HTTP API,
    it is often a simple request, where desired response should be HTTP status in
    2XX range. In other cases, when HTTP API is not exposed, pinging can be done with
    a script, or any other method that can validate the state of the service.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Ping 的想法是从外部检查应用程序或服务的状态。监控系统应定期 ping 每个服务，如果未收到响应，或响应的内容不合适，则执行自愈措施。Ping 可以有多种形式。如果服务暴露了
    HTTP API，通常只需要一个简单的请求，其中期望的响应应该是 2XX 范围内的 HTTP 状态。在其他情况下，当没有暴露 HTTP API 时，ping
    可以通过脚本或任何其他能够验证服务状态的方法来完成。
- en: Pinging is opposite from TTL, and, when possible, is a preferable way of checking
    the status of individual parts of the system. It removes repetition, coupling,
    and complications that could occur when implementing TTL inside each service.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Ping 检查与 TTL 相反，当可能时，它是检查系统各个部分状态的首选方式。它消除了重复、耦合和实现 TTL 时可能出现的复杂性。
- en: '![Pinging](img/B05848_15_02.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![Ping](img/B05848_15_02.jpg)'
- en: Figure 15-02 – System level self-healing with pings
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-02 – 使用 ping 的系统级自愈
- en: Self-Healing on the Hardware Level
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 硬件级自愈
- en: 'Truth be told, there is no such a thing as hardware self-healing. We cannot
    have a process that will automatically heal failed memory, repare broken hard
    disk, fix malfunctioning CPU, and so on. What healing on this level truly means
    is redeployment of services from an unhealthy to one of the healthy nodes. As
    with the system level, we need to periodically check the status of different hardware
    components, and act accordingly. Actually, most healing caused due to hardware
    level will happen at the system level. If hardware is not working correctly, chances
    are that the service will fail, and thus be fixed by system level healing. Hardware
    level healing is more related to preventive types of checks that we''ll discuss
    shortly:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 说实话，硬件自愈并不存在。我们无法拥有一个能够自动修复失败的内存、修复损坏的硬盘、修复故障的 CPU 等的过程。硬件级自愈真正的含义是将服务从一个不健康的节点重新部署到一个健康的节点。与系统级别一样，我们需要定期检查不同硬件组件的状态，并根据情况采取相应的行动。实际上，大多数因硬件级故障引起的自愈将在系统级别发生。如果硬件工作不正常，那么服务很可能会失败，从而通过系统级的自愈来修复。硬件级自愈更多是与我们稍后将讨论的预防性检查相关：
- en: '![Self-Healing on the Hardware Level](img/B05848_15_03.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![硬件级自愈](img/B05848_15_03.jpg)'
- en: Figure 15-03 – Hardware level self-healing
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-03 – 硬件级自愈
- en: Besides the division based on the check levels, we can also divide it based
    on the moment actions are taken. We can react to a failure, or we can try to prevent
    it.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 除了根据检查级别进行划分外，我们还可以根据采取行动的时机进行划分。我们可以对故障做出反应，或者我们可以尝试预防故障。
- en: Reactive healing
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反应性自愈
- en: Most of the organizations that implemented some kind of self-healing systems
    focused on reactive healing. After a failure is detected, the system reacts and
    restores itself to the designed state. A service process is dead, ping returns
    the code 404 (not found), corrective actions are taken, and the service is operational
    again. This works no matter whether service failed because its process failed,
    or the whole node stopped being operational (assuming that we have a system that
    can redeploy to a healthy node). This is the most important type of healing and,
    at the same time, the easiest one to implement. As long as we have all the checks
    in place, as well as actions that should be performed in case of a failure, and
    we have each service scaled to at least two instances distributed on separate
    physical nodes, we should (almost) never have downtime. I said almost never because,
    for example, the whole datacenter might loose power, thus stopping all nodes.
    It's all about evaluating risks against costs of preventing those risks.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数实施某种自愈系统的组织集中在反应性自愈上。在检测到故障后，系统会做出反应并将自身恢复到设计状态。服务进程崩溃，ping 返回 404（未找到）代码，采取纠正措施后，服务恢复正常。这无论服务是因为进程失败还是整个节点停止工作而导致失败（假设我们有一个可以重新部署到健康节点的系统），都有效。这是最重要的自愈类型，同时也是最容易实现的。只要我们做好所有检查，并且在故障发生时能执行应采取的行动，并且每个服务至少有两个实例分布在不同的物理节点上，我们就应该（几乎）永远不会有停机时间。我之所以说几乎永远不，因为例如整个数据中心可能会失去电力，从而导致所有节点停止工作。一切都在于评估风险与防范这些风险的成本之间的平衡。
- en: Sometimes, it is worthwhile to have two datacenters in different locations,
    and in other cases it's not. The objective is to strive towards zero-downtime,
    while accepting that some cases are not worthwhile trying to prevent.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，拥有两个位于不同地点的数据中心是值得的，而在其他情况下则不然。我们的目标是争取零停机时间，同时也要接受一些情况下，防止的努力并不值得。
- en: No matter whether we are striving for zero-downtime, or almost zero-downtime,
    reactive self-healing should be a must for any but smallest settings, especially
    since it does not require big investment. You might invest in spare hardware,
    or you might invest in separate datacenters. Those decisions are not directly
    related with self-healing, but with the level of risks that are acceptable for
    a given use case. Reactive self-healing investment is primarily in knowledge how
    to do it, and time to implement it. While time is an investment in itself, we
    can spend it wisely, and create a general solution that would work for (almost)
    all cases, thus reducing the time we need to spend implementing such a system.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们是在争取零停机时间，还是几乎零停机时间，反应式自愈应该是除了最小规模环境之外的所有环境必须具备的，尤其是因为它不需要大量投资。你可以投资备用硬件，或者投资独立的数据中心。这些决策与自愈没有直接关系，而是与特定用例可接受的风险水平有关。反应式自愈的投资主要是知识和实施时间。虽然时间本身就是一种投资，但我们可以明智地利用它，创造一个通用的解决方案，适用于（几乎）所有情况，从而减少我们在实施该系统时需要投入的时间。
- en: Preventive healing
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预防性修复
- en: The idea behind preventive healing is to predict the problems we might have
    in the future, and act in a way that those problems are avoided. How do we predict
    the future? To be more precise, what data do we use to predict the future?
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 预防性修复的理念是预测我们未来可能遇到的问题，并采取措施避免这些问题的发生。我们如何预测未来呢？更准确地说，我们使用什么数据来预测未来？
- en: Relatively easy, but less reliable way of predicting the future, is to base
    assumptions on (near) real-time data. For example, if one of the HTTP requests
    we're using to check the health of a service responded in more than 500 milliseconds,
    we might want to scale that service. We can even do the opposite. Following the
    same example, if it took less than 100 milliseconds to receive the response, we
    might want to descale the service, and reassign those resources to another one
    that might need it more. The problem with taking into account the current status
    when predicting the future is variability. If it took a long time between the
    request and the response, it might indeed be the sign that scaling is needed,
    but it might also be a temporary increase in traffic, and the next check (after
    the traffic spike is gone) will deduce that there is a need to descale. If microservices
    architecture is applied, this can be a minor issue, since they are small and easy
    to move around. They are easy to scale, and descale. Monolithic applications are
    often much more problematic if this strategy is chosen.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一种相对容易，但不太可靠的预测未来的方法，是基于（近）实时数据来做假设。例如，如果我们用来检查服务健康状况的某个HTTP请求响应时间超过了500毫秒，我们可能会考虑扩展该服务。我们甚至可以做相反的事情。沿用同样的例子，如果响应时间少于100毫秒，我们可能想要缩减该服务，并将资源重新分配给另一个可能更需要的服务。考虑当前状态来预测未来的问题是其变动性。如果请求和响应之间的时间较长，这可能确实是扩展的信号，但也可能是流量的暂时性增加，下一次检查（流量高峰过后）会推测需要缩减。如果应用了微服务架构，这可能是一个小问题，因为它们小且易于移动，容易扩展和缩减。选择这种策略时，单体应用往往会更加棘手。
- en: If historical data is taken into account, preventive healing becomes much more
    reliable but, at the same time, much more complicated to implement. Information
    (response times, CPU, memory, and so on) needs to be stored somewhere and, often
    complex, algorithms need to be employed to evaluate tendencies, and make conclusions.
    For example, we might observe that, during the last hour, memory usage has been
    steadily increasing, and that it reached a critical point of, let's say, 90%.
    That would be a clear indication that the service that is causing that increase
    needs to be scaled. The system could also take into account longer period of time,
    and deduce that every Monday there is a sudden increase in traffic, and scale
    services well in advance to prevent long responses. What would be, for example,
    the meaning of a steady increase in memory usage from the moment a service is
    deployed, and sudden decrease when a new version is released? Probably memory
    leaks and, in such a case, the system would need to restart the application when
    certain threshold is reached, and hope that developers would fix the issue (hence
    the need for notifications).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果考虑到历史数据，预防性修复变得更加可靠，但同时也更加复杂，实施起来也更加困难。信息（响应时间、CPU、内存等）需要存储在某个地方，且通常需要使用复杂的算法来评估趋势并得出结论。例如，我们可能会观察到，在过去的一小时内，内存使用量稳步上升，达到了一个临界点，假设是90%。这将清楚地表明，导致这一增长的服务需要进行扩展。系统还可以考虑更长时间段的数据，并推测每周一会突然出现流量激增，提前扩展服务以避免响应延迟。例如，如果一个服务部署后内存使用量持续增加，而当发布新版本时突然下降，这可能意味着存在内存泄漏问题。在这种情况下，系统可能需要在达到某个阈值时重启应用程序，并希望开发人员修复该问题（因此需要通知功能）。
- en: Let us change the focus, and discuss architecture.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们改变焦点，讨论一下架构。
- en: Self-Healing Architecture
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自愈架构
- en: No matter the internal processes and tools, every self-healing system will have
    some common elements.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 无论内部流程和工具如何，每个自愈系统都会有一些共同的元素。
- en: 'In the very beginning, there is a cluster. A single server cannot be made fault
    tolerant. If a piece of its hardware fails, there is nothing we can do to heal
    that. There is no readily available replacement. Therefore, the system must start
    with a cluster. It can be composed out of two or two hundred servers. The size
    is not of the essence, but the ability to move from one hardware to another in
    the case of a failure. Bear in mind that we always need to evaluate benefits versus
    costs. If financially viable, we would have at least two physically and geographically
    separated datacenters. In such a case, if there is a power outage in one, the
    other one would be fully operational. However, in many instances that is not a
    financially viable option:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一开始，首先是集群。单个服务器无法做到容错。如果其硬件发生故障，我们无法修复它，也没有现成的替代品。因此，系统必须从集群开始。集群可以由两台或两百台服务器组成。规模不是关键，关键在于在发生故障时能够从一台硬件迁移到另一台硬件。记住，我们始终需要评估收益与成本的关系。如果财务上可行，我们会至少拥有两个物理和地理上分离的数据中心。这样，如果一个数据中心发生停电，另一个数据中心将能够完全运作。然而，在很多情况下，这不是一个经济可行的选择：
- en: '![Self-Healing Architecture](img/B05848_15_04.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![自愈架构](img/B05848_15_04.jpg)'
- en: 'Figure 15-04 – Self-healing system architecture: Everything starts with a cluster'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图15-04 – 自愈系统架构：一切从集群开始
- en: 'Once we have the cluster up and running, we can begin deploying our services.
    However, managing services inside a cluster without some orchestrator is tedious,
    at best. It requires time and often ends up with a very unbalanced usage of resources:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们让集群启动并运行，我们就可以开始部署我们的服务。然而，在没有某种调度器的情况下管理集群中的服务，充其量也只是繁琐。这需要时间，且常常导致资源使用非常不平衡：
- en: '![Self-Healing Architecture](img/B05848_15_05.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![自愈架构](img/B05848_15_05.jpg)'
- en: 'Figure 15-05 – Self-healing system architecture: Services are deployed to the
    cluster, but with a very unbalanced usage of resources'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图15-05 – 自愈系统架构：服务被部署到集群中，但资源使用非常不平衡
- en: 'In most cases, people treat a cluster as a set of individual servers, which
    is wrong, knowing that today we have tools at our disposal that can help us do
    the orchestration in a much better way. With Docker Swarm, Kubernetes, or Apache
    Mesos, we can solve the orchestration within a cluster. Cluster orchestration
    is important, not only to ease the deployment of our services, but also as a way
    to provide fast re-deployments to healthy nodes in case of a failure (be it of
    software or hardware nature). Bear in mind that we need at least two instances
    of every service running behind a proxy. Given such a situation, if one instance
    fails, the others can take over its load, thus avoiding any downtime while the
    system re-deploys the failed instance:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，人们把集群看作一组独立的服务器，这是错误的。如今我们手头有一些工具，可以帮助我们更好地进行编排。通过 Docker Swarm、Kubernetes
    或 Apache Mesos，我们可以解决集群中的编排问题。集群编排不仅有助于简化服务的部署，而且在发生故障（无论是软件故障还是硬件故障）时，还可以快速重新部署到健康节点。记住，我们需要在代理后面至少运行每个服务的两个实例。在这种情况下，如果某个实例发生故障，其他实例可以接管它的负载，从而避免系统在重新部署故障实例时发生停机：
- en: '![Self-Healing Architecture](img/B05848_15_06.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![自愈架构](img/B05848_15_06.jpg)'
- en: 'Figure 15-06 – Self-healing system architecture: Some deployment orchestrator
    is required to distribute services across the cluster'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-06 – 自愈系统架构：需要某种部署编排器来在集群中分发服务
- en: 'The basis of any self-healing system is monitoring of the state of deployed
    services, or applications, as well as the underlying hardware. The only way we
    can monitor them is to have information about their existence. That information
    can be available in many different forms, ranging from manually maintained configuration
    files, through traditional databases, all the way until highly available distributed
    service registries like `Consul`, `etcd`, or `Zookeeper`. In some cases, the service
    registry can be chosen by us, while in others it comes as part of the cluster
    orchestrator. For example, Docker Swarm has the flexibility that allows it to
    work with a couple of registries, while Kubernetes is tied to `etcd`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 任何自愈系统的基础都是监控已部署服务或应用程序的状态，以及底层硬件的状态。监控它们的唯一方法是掌握关于它们存在的信息。这些信息可以有多种不同形式，从手动维护的配置文件、传统的数据库，到像
    `Consul`、`etcd` 或 `Zookeeper` 这样高可用的分布式服务注册表。在某些情况下，服务注册表由我们自行选择，而在另一些情况下，它是集群编排器的一部分。例如，Docker
    Swarm 具有灵活性，允许它与多个注册表一起工作，而 Kubernetes 则与 `etcd` 紧密集成：
- en: '![Self-Healing Architecture](img/B05848_15_07.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![自愈架构](img/B05848_15_07.jpg)'
- en: 'Figure 15-07 – Self-healing system architecture: Primary requirement for monitoring
    the state of the system is to have the information of the system stored service
    registry'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-07 – 自愈系统架构：监控系统状态的主要要求是将系统信息存储在服务注册表中
- en: 'No matter the tool we choose to act as a service registry, the next obstacle
    is to put the information into the service registry of choice. The principle is
    a simple one. Something needs to monitor hardware and services and update the
    registry whenever a new one is added, or an existing one is removed. There are
    plenty of tools that can do that. We are already familiar with Registrator, which
    fulfills this role pretty well. As with service registries, some cluster orchestrators
    already come with their own ways to register and de-register services. No matter
    which tool we choose, the primary requirement is to be able to monitor the cluster
    and send information to service registry in near-realtime:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们选择哪个工具作为服务注册表，接下来的障碍就是将信息放入所选的服务注册表中。原则很简单：需要有某种方式来监控硬件和服务，并在新增或移除某个服务时更新注册表。市面上有很多工具能够实现这一点。我们已经熟悉`Registrator`，它很好地完成了这一角色。与服务注册表类似，一些集群编排器已经自带了注册和注销服务的方式。无论选择哪种工具，主要的要求是能够监控集群并实时将信息发送到服务注册表：
- en: '![Self-Healing Architecture](img/B05848_15_08.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![自愈架构](img/B05848_15_08.jpg)'
- en: 'Figure 15-08 – Self-healing system architecture: Service registry is useless
    if no mechanism will monitor the system and store new information'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-08 – 自愈系统架构：如果没有机制来监控系统并存储新信息，服务注册表就没有意义
- en: 'Now that we have the cluster with services up and running, and we have the
    information about the system in the service registry, we can employ some health
    monitoring that will detect anomalies. Such a tool needs to know not only what
    the desired state is, but, also, what the actual situation is at any moment. Consul
    Watches can fulfill this role while Kubernetes and Mesos come with their own tools
    for this type of tasks. In a more traditional environment, Nagios or Icinga (only
    to name a few), can fulfill this role as well:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经有了运行中的集群服务，并且我们在服务注册表中有了系统信息，我们可以使用一些健康监控工具来检测异常。这样的工具不仅需要知道期望的状态是什么，还需要随时了解当前的实际状态。Consul
    Watches 可以履行这一角色，而 Kubernetes 和 Mesos 自带了针对这类任务的工具。在更传统的环境中，Nagios 或 Icinga（仅举几例）也能胜任这一角色：
- en: '![Self-Healing Architecture](img/B05848_15_09.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![自愈架构](img/B05848_15_09.jpg)'
- en: 'Figure 15-09 – Self-healing system architecture: With all the relevant information
    stored in a service registry, some health monitoring tools can utilize it to verify
    whether the desired state is maintained'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-09 – 自愈系统架构：所有相关信息都存储在服务注册表中，一些健康监控工具可以利用这些信息来验证是否保持了期望的状态
- en: 'The next piece of the puzzle is a tool that would be able to execute corrective
    actions. When the health monitor detects an anomaly, it would send a message to
    perform a corrective measure. As a minimum, that corrective action should send
    a signal to the cluster orchestrator, which, in turn, would redeploy the failed
    service. Even if a failure was caused by a hardware problem, cluster orchestrator
    would (temporarily) fix that by redeploying the service to a healthy node. In
    most cases, corrective actions are not that simple. There could be a mechanism
    to notify interested parties, record what happened, revert to an older version
    of the service, and so on. We already adopted Jenkins, and it is a perfect fit
    to act as the tool that can receive a message from the health monitor and, as
    a result, initiate corrective actions:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个关键部分是一个能够执行修正操作的工具。当健康监控器检测到异常时，它将发送一个消息来执行修正措施。最低要求是，该修正操作应向集群调度器发送信号，进而重新部署失败的服务。即使故障是由硬件问题引起的，集群调度器也会（临时）通过将服务重新部署到健康的节点上来修复这个问题。在大多数情况下，修正措施并不像那么简单。可能会有一个机制来通知相关方、记录发生的事件、回滚到旧版本的服务等。我们已经采用了
    Jenkins，它非常适合作为接收来自健康监控器消息并触发修正措施的工具：
- en: '![Self-Healing Architecture](img/B05848_15_10.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![自愈架构](img/B05848_15_10.jpg)'
- en: 'Figure 15-10 – Self-healing system architecture: As a minimum, corrective action
    should send a signal to the cluster orchestrator to redeploy the service that
    failed'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-10 – 自愈系统架构：最低要求是，修正操作应向集群调度器发送信号，重新部署失败的服务
- en: 'The process, as it is for now, is dealing only with reactive healing. The system
    is continuously monitored and, if a failure is detected, corrective actions are
    taken, which, in turn, will restore the system to the desired state. Can we take
    it a step further and try to accomplish preventive healing? Can we predict the
    future and act accordingly? In many cases we can, in some we can''t. We cannot
    know that a hard disk will fail tomorrow. We cannot predict that there will be
    an outage today at noon. However, in some cases, we can see that the traffic is
    increasing, and will soon reach a point that will require some of our services
    to be scaled. We can predict that a marketing campaign we are about to launch
    will increase the load. We can learn from our mistakes, and teach the system how
    to behave in certain situations. The essential elements of such a set of processes
    are similar to those we should employ for reactive healing. We need a place to
    store data and a process that collects them. Unlike service registry that deals
    with a relatively small amount of data and benefits from being distributed, preventive
    healing requires quite bigger storage and capabilities that would allow us to
    perform some analytic operations:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的流程仅处理反应式自愈。系统会持续监控，并在发现故障时采取纠正性措施，从而将系统恢复到期望的状态。我们能否更进一步，尝试实现预防性自愈？我们能否预测未来并相应采取行动？在许多情况下，我们可以做到，有些则不行。我们无法知道硬盘明天会故障，无法预测今天中午会发生停机。但是，在某些情况下，我们可以看到流量正在增加，很快就会达到需要扩展某些服务的临界点。我们可以预测即将启动的营销活动会增加负载。我们可以从错误中吸取教训，并教会系统在特定情况下如何反应。这样一套流程的核心要素与我们用于反应式自愈的流程类似。我们需要一个存储数据的地方，并且需要一个收集这些数据的过程。与处理相对较小数据量并且从分布式中受益的服务注册不同，预防性自愈需要更大的存储空间和能够进行一些分析操作的能力：
- en: '![Self-Healing Architecture](img/B05848_15_11.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![自愈架构](img/B05848_15_11.jpg)'
- en: 'Figure 15-11 – Self-healing system architecture: Preventive healing requires
    historical data to be analyzed'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-11 – 自愈系统架构：预防性自愈需要分析历史数据
- en: 'Similarly to the registrator service, we''ll also need some data collector
    that will be sending historical data. That data can be quite massive and include,
    but not be limited by, CPU, HD, network traffic, system and service logs, and
    so on. Unlike the registrator that listens to events, mostly generated by the
    cluster orchestrator, data collector should be continuously collecting data, digesting
    the input, and producing an output that should be stored as historical data:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 registrator 服务，我们还需要一些数据收集器来发送历史数据。那些数据可能会非常庞大，包括但不限于 CPU、硬盘、网络流量、系统和服务日志等等。与主要监听由集群编排器生成事件的
    registrator 不同，数据收集器应持续收集数据，消化输入内容，并生成输出，作为历史数据进行存储：
- en: '![Self-Healing Architecture](img/B05848_15_12.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![自愈架构](img/B05848_15_12.jpg)'
- en: 'Figure 15-12 – Self-healing system architecture: Preventive healing requires
    vast quantities of data to be collected continuously'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-12 – 自愈系统架构：预防性自愈需要持续收集大量数据
- en: 'We already used some of the tools needed for reactive self-healing. Docker
    Swarm can be used as the cluster orchestrator, Registrator and Consul for service
    discovery, and Jenkins for performing, among other duties, corrective actions.
    The only tool that we haven''t used are two subsets of Consul; checks and watches.
    Preventive healing will require exploration of some new processes and tools, so
    we''ll leave it for later on:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用了一些实现反应式自愈所需的工具。Docker Swarm 可以作为集群编排器，Registrator 和 Consul 用于服务发现，而 Jenkins
    则用于执行包括纠正性操作在内的其他任务。唯一没有使用的工具是 Consul 的两个子集：检查和监控。预防性自愈将需要探索一些新的流程和工具，因此我们将稍后再处理：
- en: '![Self-Healing Architecture](img/B05848_15_13.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![自愈架构](img/B05848_15_13.jpg)'
- en: 'Figure 15-13 – Self-healing system architecture: One of the combinations of
    tools'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-13 – 自愈系统架构：工具组合之一
- en: Let's see if we can set up a sample reactive self-healing system.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看是否能够设置一个示例反应式自愈系统。
- en: Self-Healing with Docker, Consul Watches, and Jenkins
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Docker、Consul 监控和 Jenkins 进行自愈
- en: The good news is that we already used all the tools that we require to make
    a reactive self-healing system. We have Swarm that will make sure that containers
    will be deployed to healthy nodes (or at least nodes that are operational). We
    have Jenkins that can be used to execute the healing process and, potentially,
    send notifications. Finally, we can use Consul not only to store service information,
    but also to perform health checks and send requests to Jenkins. The only piece
    we haven't used until now are Consul watches that can be programmed to perform
    health checks.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，我们已经使用了所有需要的工具来构建一个响应式自我修复系统。我们有Swarm，它会确保容器部署到健康的节点（或者至少是正常运行的节点）。我们有Jenkins，它可以用来执行修复过程，并且可能会发送通知。最后，我们可以使用Consul，不仅可以存储服务信息，还可以执行健康检查并向Jenkins发送请求。直到现在，我们唯一还没有使用的工具是Consul的watch功能，它可以编程执行健康检查。
- en: One thing to note about how Consul does health checks is that it differs from
    traditional way Nagios and other similar tools are operating. Consul avoids the
    thundering herd problem by using gossip, and only alerts on state changes.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Consul如何进行健康检查，有一点需要注意，那就是它与传统的Nagios以及其他类似工具的工作方式不同。Consul通过使用gossip避免了“雷鸣般的集群”问题，并且仅在状态发生变化时发出警报。
- en: As always, we'll start by creating VMs we'll use throughout the rest of the
    chapter. We'll create the familiar combination of one `cd` and three `swarm` servers
    (one master and two nodes).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，我们将从创建我们将在本章其余部分使用的虚拟机（VM）开始。我们将创建一个`cd`节点和三个`swarm`服务器（一个主节点和两个节点）。
- en: Setting Up the Environments
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置环境
- en: The following command will create the four VMs we'll use in this chapter. We'll
    create the `cd` node and use it to provision the other nodes with Ansible. This
    VM will also host Jenkins, that will be an important part of the self-healing
    process. The other three VMs will form the Swarm cluster.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将创建我们在本章中将使用的四个虚拟机。我们将创建`cd`节点，并使用它通过Ansible为其他节点进行配置。这个虚拟机还将托管Jenkins，它将是自我修复过程中的一个重要部分。其他三个虚拟机将组成Swarm集群。
- en: '[PRE0]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: With all the VMs operational, we can proceed and set up the Swarm cluster. We'll
    start by provisioning the cluster in the same way as we did before, and then discuss
    changes we need to make it self-heal.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 所有虚拟机正常运行后，我们可以继续设置Swarm集群。我们将以与之前相同的方式配置集群，然后讨论我们需要进行哪些更改来实现自我修复。
- en: '[PRE1]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Finally, the time has come to provision the `cd` server with Jenkins.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，时机已到，我们将使用Jenkins配置`cd`服务器。
- en: '[PRE2]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We reached the point where the whole cluster is operational, and Jenkins server
    will be up and running soon. We set one Swarm master (`swarm-master`), two Swarm
    nodes (`swarm-node-1` and `swarm-node-2`), and one server with Ansible and, soon
    to be running, Jenkins (`cd`). Feel free to continue reading while Jenkins provisioning
    is running. We won't need it right away.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经达到整个集群都可以正常运行的阶段，Jenkins服务器很快也将启动。我们设置了一个Swarm主节点（`swarm-master`），两个Swarm节点（`swarm-node-1`和`swarm-node-2`），以及一个搭载Ansible的服务器，并且即将启动Jenkins（`cd`）。在Jenkins配置运行时，您可以继续阅读。我们暂时不会立即需要它。
- en: Setting Up Consul Health Checks and Watches for Monitoring Hardware
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置Consul健康检查和监控硬件的watch功能
- en: We can send instructions to Consul to perform periodic checks of services or
    entire nodes. It does not come with predefined checks. Instead, it runs scripts,
    performs HTTP requests, or wait for TTL signals defined by us. While the lack
    of predefined checks might seem like a disadvantage, it gives us the freedom to
    design the process as we see fit. In case we're using scripts to perform checks,
    Consul will expect them to exit with certain codes. If we exit from the check
    script with the `code 0`, Consul will assume that everything works correctly.
    Exit `code 1` is expected to be a warning, and the exit `code 2` is an error.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以向Consul发送指令，定期检查服务或整个节点。它不提供预定义的检查，而是运行脚本、执行HTTP请求，或等待我们定义的TTL信号。虽然没有预定义检查看似是一个缺点，但它给了我们设计流程的自由。如果我们使用脚本来执行检查，Consul将期望它们以特定的代码退出。如果我们以`代码0`退出检查脚本，Consul将认为一切正常。退出`代码1`表示警告，而退出`代码2`表示错误。
- en: We'll start by creating a few scripts that will perform hardware checks. Getting
    information of, let's say, hard disk utilization is relatively easy with the `df`
    command.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从创建几个执行硬件检查的脚本开始。获取硬盘使用情况的信息，例如，使用`df`命令是相对简单的。
- en: '[PRE3]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We used the `-h` argument to output `human-readable` information, and the output
    is as follows.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`-h`参数来输出`人类可读`的信息，输出如下所示。
- en: '[PRE4]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Bear in mind that in your case the output might be slightly different.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在你的情况下，输出可能会稍有不同。
- en: 'What we truly need are numbers from the root directory (the third row in the
    output). We can filter the output of the `df` command so that only the row with
    the value `/` of the last column is displayed. After the filter, we should extract
    the percentage of used disk space (column 5). While we are extracting data, we
    might just as well get the disk size (column 2), and the amount of used space
    (column 3). Data that we extract should be stored as variables that we could use
    later on. The commands we can use to accomplish all that is as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们真正需要的是根目录的数据（输出中的第三行）。我们可以过滤 `df` 命令的输出，使其只显示最后一列值为 `/` 的那一行。过滤后，我们应该提取已使用磁盘空间的百分比（第
    5 列）。在提取数据的同时，我们也可以获取磁盘大小（第 2 列）和已使用空间量（第 3 列）。我们提取的数据应该存储为可以稍后使用的变量。我们可以使用以下命令来完成这一切：
- en: '[PRE5]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Since the value that represents the used space percentage contains the `%` sign,
    we removed the last character before assigning the value to the `used_percent`
    variable.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于表示已使用空间百分比的值包含 `%` 符号，我们在将值赋给 `used_percent` 变量之前去除了最后一个字符。
- en: 'We can double-check whether the variables we created contain correct values
    with a simple `printf` command:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过简单的 `printf` 命令来再次检查我们创建的变量是否包含正确的值：
- en: '[PRE6]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output of the last command is as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一条命令的输出如下：
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The only thing left is to exit with 1 (warning) or 2 (error) when a threshold
    is reached. We''ll define the error threshold as 95% and warning as 80%. The only
    thing missing is a simple `if`/`elif`/`else` statement:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的唯一任务是，当达到阈值时，以 1（警告）或 2（错误）退出。我们将错误阈值定义为 95%，警告阈值为 80%。唯一缺少的就是一个简单的 `if`/`elif`/`else`
    语句：
- en: '[PRE8]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For testing purposes, we put echos. The script that we are about to make should
    exit with `2`, `1` or `0`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 出于测试目的，我们加入了 echo。我们将要创建的脚本应该返回 `2`、`1` 或 `0` 作为退出代码。
- en: 'Let''s move into the `swarm-master` node, create the script, and test it:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入 `swarm-master` 节点，创建脚本并进行测试：
- en: '[PRE9]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We''ll start by creating a directory where Consul scripts will reside:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从创建一个目录开始，Consul 脚本将存放在该目录中：
- en: '[PRE10]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now we can create the script with the commands we practiced:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建包含我们练习过的命令的脚本：
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s try it out. Since there''s quite a lot of free disk space, the script
    should echo the disk usage and return zero:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试看。由于有相当多的空闲磁盘空间，脚本应该会输出磁盘使用情况并返回零：
- en: '[PRE13]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The command provided an output similar to the following.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 命令输出的结果类似于以下内容。
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can easily display the exit code of the last command with `$?`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过 `$?` 来轻松显示上一条命令的退出代码：
- en: '[PRE15]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The echo returned zero, and the script seems to be working. You can test the
    rest of exit codes by modifying the threshold to be below the current disk usage.
    I'll leave that to you, as a simple exercise.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: echo 返回了零，脚本似乎正常工作。你可以通过将阈值设置为低于当前磁盘使用率来测试其余的退出代码。我将这个简单的练习留给你完成。
- en: Note
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Consul check threshold exercise**'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**Consul 检查阈值练习**'
- en: Modify the `disk.sh` script in a way that warning and error thresholds are lower
    than the current HD usage. Test the changes by running the script and outputting
    the exit code. Once the exercise is done, revert the script to its original values.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 修改 `disk.sh` 脚本，使得警告和错误阈值低于当前的硬盘使用率。通过运行脚本并输出退出代码来测试更改。完成练习后，将脚本恢复到原始值。
- en: 'Now that we have the script that checks the disk usage, we should tell Consul
    about its existence. Consul uses JSON format for specifying checks. The definition
    that utilizes the script we just created is as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了检查磁盘使用情况的脚本，我们应该让 Consul 知道它的存在。Consul 使用 JSON 格式来指定检查。利用我们刚刚创建的脚本的定义如下：
- en: '[PRE16]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'That JSON would tell Consul that there is a check with the ID `disk`, name
    `Disk utilization` and notes `Critical 95% util`, `warning 80% util`. The `name`
    and `notes` are purely for visualization purposes (as you''ll see soon). Next,
    we are specifying the path to the script to be `/data/consul/scripts/disk.sh`.
    Finally, we are telling Consul to run the script every `10` seconds:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 该 JSON 文件会告诉 Consul，有一个 ID 为 `disk`、名称为 `Disk utilization`、注释为 `Critical 95%
    util` 和 `warning 80% util` 的检查。`name` 和 `notes` 只是用于可视化显示（正如你将很快看到的）。接下来，我们指定脚本的路径为
    `/data/consul/scripts/disk.sh`。最后，我们告诉 Consul 每 `10` 秒运行一次脚本：
- en: 'Let''s create the JSON file:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建 JSON 文件：
- en: '[PRE17]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'When we started Consul (through the Ansible playbook), we specified that configuration
    files are located in the `/data/consul/config/` directory. We still need to reload
    it, so that it picks up the new file we just created. The easiest way to reload
    Consul is by sending it the `HUP` signal:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们启动Consul（通过Ansible剧本）时，我们指定了配置文件位于`/data/consul/config/`目录下。我们仍然需要重新加载它，以便它能够识别我们刚刚创建的文件。重新加载Consul的最简单方法是向其发送`HUP`信号：
- en: '[PRE19]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We managed to create hard disk checks in Consul. It will run the script every
    ten seconds and, depending on its exit code, determine the health of the node
    it runs on (in this case `swarm-master`):'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功地在Consul中创建了硬盘检查。它将每十秒运行一次脚本，并根据退出代码判断它所运行的节点（此例中为`swarm-master`）的健康状态：
- en: '![Setting Up Consul Health Checks and Watches for Monitoring Hardware](img/B05848_15_14.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![为监控硬件设置Consul健康检查和Watch](img/B05848_15_14.jpg)'
- en: Figure 15-14 – Hard disk checks in Consul
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-14 – Consul中的硬盘检查
- en: 'Let''s take a look at the Consul UI by opening `http://10.100.192.200:8500/ui/`
    from a browser. Once the UI is opened, please click the **Nodes** button, and
    then the `swarm-master` node. Among other information, you''ll see two checks.
    One of them is `Serf Health Status`. It''s Consul''s internal check based on TTL.
    If one of the Consul nodes is down, that information will be propagated throughout
    the cluster. The check check, called `Disk utilization`, is the one we just created,
    and, hopefully, the status is `passing`:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在浏览器中打开`http://10.100.192.200:8500/ui/`来查看Consul UI。打开UI后，请点击**节点**按钮，然后选择`swarm-master`节点。在其他信息中，你将看到两个检查项。其中一个是`Serf健康状态`，这是Consul基于TTL的内部检查。如果某个Consul节点宕机，这个信息会被传播到整个集群。另一个检查项叫做`磁盘利用率`，这是我们刚刚创建的检查项，且希望其状态为`通过`：
- en: '![Setting Up Consul Health Checks and Watches for Monitoring Hardware](img/B05848_15_15.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![为监控硬件设置Consul健康检查和Watch](img/B05848_15_15.jpg)'
- en: Figure 15-15 – Hard disk checks in Consul UI
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15-15 – Consul UI中的硬盘检查
- en: Now that we know how easy it is to add a check in Consul, we should define what
    action should be performed when a check fails. We do that through Consul watches.
    As with checks, Consul does not offer an out-of-the-box final solution. It provides
    a mechanism for us to create the solution that fits our needs.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道在Consul中添加检查是多么简单，我们应该定义当检查失败时应执行的操作。我们可以通过Consul的watch功能来实现这一点。与检查一样，Consul并没有提供一个现成的最终解决方案，而是提供了一种机制，让我们能够创建符合我们需求的解决方案。
- en: 'Consul supports seven different types of watches:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Consul支持七种不同类型的watch：
- en: '**key**: Watch a specific KV pair'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**键**：查看特定的KV对'
- en: '**keyprefix**: Watch a prefix in the KV store'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**键前缀**：查看KV存储中的前缀'
- en: '**services**: Watch the list of available services'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务**：查看可用服务列表'
- en: '**nodes**: Watch the list of nodes'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点**：查看节点列表'
- en: '**service**: Watch the instances of a service'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务实例**：查看服务实例'
- en: '**checks**: Watch the value of health checks'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检查**：查看健康检查的值'
- en: '**event**: Watch for custom user events'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件**：查看自定义用户事件'
- en: Each of the types is useful in certain situations and, together, they provide
    a very comprehensive framework for building your self-healing, fault tolerant,
    system. We'll concentrate on the `checks` type, since it will allow us to utilize
    the hard disk check we created earlier. Please consult the watches documentation
    for more info.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 每种类型在特定情况下都有其用处，结合起来，它们为构建自愈、容错系统提供了一个非常全面的框架。我们将重点关注`检查`类型，因为它将允许我们使用之前创建的硬盘检查。请参考watch的文档以获取更多信息。
- en: 'We''ll start by creating the script that will be run by Consul watcher. The
    `manage_watches.sh` script is as follows (please don''t run it):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先创建一个由Consul Watcher运行的脚本。`manage_watches.sh`脚本如下（请不要运行它）：
- en: '[PRE20]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We started by defining `RED` and `NC` variables that will help us paint critical
    parts of the output in red. Then, we are reading the Consul input and storing
    it into the `JSON` variable. That is followed by the creation of `STATUS_ARRAY`
    and `CHECK_ID_ARRAY` arrays that will hold `Status` and `CheckID` values for each
    element from the JSON. Finally, those arrays allow us to iterate through each
    item, and send a POST request to Jenkins to build the `hardware-notification`
    job (we'll take a look at it later). The request uses Jenkins friendly format
    for passing the `CHECK_ID` and `STATUS` variables. Please consult Jenkins remote
    access API for more information.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义了`RED`和`NC`变量，这些变量将帮助我们将输出的关键部分标记为红色。然后，我们读取Consul输入并将其存储到`JSON`变量中。接下来，创建了`STATUS_ARRAY`和`CHECK_ID_ARRAY`数组，这些数组将存储每个JSON元素的`Status`和`CheckID`值。最后，这些数组使我们能够遍历每一项，并向Jenkins发送POST请求以构建`hardware-notification`作业（稍后我们会查看）。该请求使用Jenkins友好的格式传递`CHECK_ID`和`STATUS`变量。有关更多信息，请查阅Jenkins远程访问API。
- en: 'Let''s create the script:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建脚本：
- en: '[PRE21]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now that we have the script that will be executed whenever there is a check
    with the `warning` or `critical` status, we''ll inform Consul about its existence.
    The Consul watches definition is as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了每当检查状态为`warning`或`critical`时将执行的脚本，我们将通知Consul它的存在。Consul watch的定义如下：
- en: '[PRE23]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This definition should be self-explanatory. We defined two watches, both of
    type `checks`. The first one will be run in case of a `warning`, and the second
    when a check is in the `critical` state. We're trying to keep things simple by
    specifying, in both instances, the same handler `manage_watches.sh`. In a real
    world setting, you should differentiate those two states and run different actions.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定义应该是自解释的。我们定义了两个watch，它们都是`checks`类型的。第一个将在出现`warning`时运行，第二个则在检查处于`critical`状态时运行。为了简化操作，在这两个实例中，我们指定了相同的处理程序`manage_watches.sh`。在实际环境中，您应该区分这两种状态并执行不同的操作。
- en: 'Let''s create the watches file:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建watch文件：
- en: '[PRE24]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Before we proceed, and reload Consul, we should have a quick discussion about
    the Jenkins job `hardware-notification`. It was already created when we provisioned
    Jenkins. Its configuration can be seen by opening `http://10.100.198.200:8080/job/hardware-notification/configure`.
    It contains two parameters, `checkId` and `status`. We're using those two parameters
    as a way to avoid creating separate jobs for each hardware check. Whenever Consul
    watcher sends the POST request to build this job, it passes values to those two
    variables. In the build phase, we are simply running an `echo` command that sends
    values of those two variables to standard output (`STDOUT`). In a real world situation,
    this job would do some actions. For example, if disk space is low, it could remove
    unused logs and temporary files. Another example would be creation of additional
    nodes, if we're using one of the cloud services like Amazon AWS. In some other
    situations, no automated reaction is possible. In any case, besides concrete actions
    like those, this job should also send some kind of a notification (email, instant
    messaging, and so on) so that operators are informed about the potential problem.
    Since those situations would be difficult to reproduce locally, the initial definition
    of this job does nothing of the sort. I'll leave it up to you to extend it for
    your own needs.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续并重新加载Consul之前，应该简要讨论一下Jenkins作业`hardware-notification`。当我们为Jenkins配置时，它已经创建了该作业。可以通过打开`http://10.100.198.200:8080/job/hardware-notification/configure`来查看其配置。它包含两个参数，`checkId`和`status`。我们使用这两个参数作为避免为每个硬件检查创建单独作业的方式。每当Consul观察器发送POST请求以构建该作业时，它将这些值传递给这两个变量。在构建阶段，我们仅运行一个`echo`命令，将这两个变量的值输出到标准输出（`STDOUT`）。在实际情况中，这个作业会执行某些操作。例如，如果磁盘空间不足，它可能会删除未使用的日志和临时文件。另一个例子是，如果我们使用Amazon
    AWS等云服务，它可能会创建额外的节点。在其他一些情况下，可能无法进行自动化反应。无论如何，除了像这样的具体操作外，这个作业还应该发送某种形式的通知（如电子邮件、即时消息等），以便操作员得知潜在问题。由于这些情况在本地难以重现，该作业的初始定义并未执行此类操作。如何扩展这个作业以满足您的需求，就交给您了。
- en: Note
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The hardware-notification Jenkins job exercise**'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**hardware-notification Jenkins作业练习**'
- en: Modify the `hardware-notification` Jenkins job so that logs are deleted in case
    the `checkId` value is `disk`. Create mock logs (feel free to use the `touch`
    command to create files) on the server and run the job manually. Once the job
    build is finished, confirm that the logs were indeed removed.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Consul Health Checks and Watches for Monitoring Hardware](img/B05848_15_16.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
- en: Figure 15-16 – Settings screen of the Jenkins job hardware-notification
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem we have right now is that the hard disk on the `swarm-master` node
    is mostly empty, thus preventing us from testing the system we just set up. We''ll
    have to change the thresholds defined in the `disk.sh`. Let''s modify the 80%
    warning threshold to `2%`. Current HD usage is surely more than that:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Finally, let''s reload Consul and see what happens:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The first thing we should check is the watches log:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The relevant part of the output is as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Please note that it might take a few seconds until Consul's check is run. If
    you did not receive the similar output from logs, repeat the `cat` command.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see the JSON that consul sent to the script and that the request to
    build the Jenkins job `hardware-notification` has been dispatched. We can also
    take a look at the Jenkins Console Output of this job by opening `http://10.100.198.200:8080/job/hardware-notification/lastBuild/console`
    URL in a browser:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Consul Health Checks and Watches for Monitoring Hardware](img/B05848_15_17.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
- en: Figure 15-17 – Console output of the Jenkins job hardware-notification
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Since, at this moment, we have only one Consul check used for hard disk utilization,
    we should implement at least one more. The suitable candidate is memory. Even
    if we do not do any corrective action when some hardware check fails, having the
    information in Consul is already very useful in itself.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand the process, we can do better, and use Ansible to set
    up everything. Besides, different checks should be set up not only in the `swarm-master`
    node but also in the rest of the cluster, and we don't want to do that manually
    unless it's for learning purposes.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we proceed, let''s exit the `swarm-master` node:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Automatically Setting Up Consul Health Checks and Watches for Monitoring Hardware
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this moment, we have one hardware watcher configured only in the `swarm-master`
    node. Now that we are familiar with the way Consul watches work, we can use Ansible
    to deploy hardware monitoring to all the nodes of the Swarm cluster.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll run the Ansible playbook first, and then explore the roles that were
    used to setup the checks:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The `swarm-healing.yml` playbook is as follows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The only difference, when compared with the `swarm.yml` playbook, is the usage
    of the `consul-healing` role. Those two roles (`consul` and `consul-healing`)
    are very similar. The major difference is that the latter copies few more files
    to destination servers (`roles/consul-healing/files/consul_check.json, roles/consul-healing/files/disk.sh`,
    and `roles/consul-healing/files/mem.sh`). We already created all those files manually,
    except the `mem.sh` that is used to check memory, and follows the similar logic
    as the `disk.sh` script. The `roles/consul-healing/templates/manage_watches.sh`
    and `roles/consul-healing/templates/watches.json` files are defined as templates
    so that a few things can be customized through Ansible variables. All in all,
    we are mostly replicating manual steps through Ansible, so that provisioning and
    configuration of the whole cluster can be done automatically.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 与`swarm.yml`剧本相比，唯一的不同之处是使用了`consul-healing`角色。这两个角色（`consul`和`consul-healing`）非常相似。主要的区别在于后者将更多文件复制到目标服务器（`roles/consul-healing/files/consul_check.json`、`roles/consul-healing/files/disk.sh`和`roles/consul-healing/files/mem.sh`）。我们已经手动创建了所有这些文件，除了`mem.sh`，它用于检查内存，逻辑与`disk.sh`脚本类似。`roles/consul-healing/templates/manage_watches.sh`和`roles/consul-healing/templates/watches.json`文件被定义为模板，这样就可以通过Ansible变量自定义一些内容。总的来说，我们主要是通过Ansible复制手动步骤，以便整个集群的配置和部署可以自动完成。
- en: Please open the `http://10.100.192.200:8500/ui/#/dc1/nodes` URL, and click on
    any of the nodes. You'll notice that each has `Disk utilization` and `Memory utilization`
    watches that, in the case of a failure, will start the build of the Jenkins job
    `hardware-notification/`.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 请打开`http://10.100.192.200:8500/ui/#/dc1/nodes`网址，然后点击任何一个节点。你会注意到，每个节点都有`磁盘使用情况`和`内存使用情况`监视器，在出现故障时，它们会启动Jenkins任务`hardware-notification/`的构建。
- en: While watching hardware resources, and performing predefined actions in case
    a threshold is reached, is interesting and useful, there is often a limitation
    to corrective actions that can be taken. If, for example, a whole node is down,
    the only thing we can do, in most cases, is to send a notification to someone
    who will manually investigate the problem. The real benefits are obtained by monitoring
    services.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在监控硬件资源并在达到阈值时执行预定义的操作是有趣且有用的，但通常会面临采取纠正措施的限制。例如，如果整个节点宕机，通常我们能做的唯一事情就是发送通知给某人，之后该人会手动调查问题。真正的好处是通过监控服务来实现的。
- en: Setting Up Consul Health Checks and Watches for Monitoring Services
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置Consul健康检查和监视以监控服务
- en: Before we dive into service checks and watches, let's initiate deployment of
    our `books-ms` container. That way we'll use our time wisely, and discuss the
    subject while Jenkins is working hard to have the service up and running.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解服务检查和监视之前，让我们先启动`books-ms`容器的部署。这样，我们可以更有效地利用时间，一边讨论这个话题，一边让Jenkins为服务启动而努力工作。
- en: We'll start by indexing the branches defined in the Jenkins job `books-ms`.
    Please open it in a browser, click the **Branch Indexing** link located in the
    left-hand menu, and follow it with **Run Now**. Once the indexing is done, Jenkins
    will detect that the `swarm` branch matches the filter, create the subproject,
    and run the first build. When finished, we'll have the `books-ms` service deployed
    to the cluster, and we'll be able to experiment with more self-healing techniques.
    You can monitor the build progress from the console screen.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从索引Jenkins任务`books-ms`中定义的分支开始。请在浏览器中打开它，点击左侧菜单中的**Branch Indexing**链接，然后点击**Run
    Now**。索引完成后，Jenkins会检测到`swarm`分支符合过滤条件，创建子项目并执行第一次构建。构建完成后，我们将把`books-ms`服务部署到集群中，并可以尝试更多自愈技术。你可以从控制台屏幕监控构建进度。
- en: The first step in self-healing is identifying that something is wrong. On the
    system level, we can observe services we're deploying and, if one of them does
    not respond, perform some corrective actions. We can continue using Consul checks
    in a similar manner as with did with memory and disk verifications. The major
    difference is that this time we'll be better of by using `http` instead `script`
    checks. Consul will perform periodic requests to our services, and send failures
    to the watches we already set up.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 自愈的第一步是识别出出现了问题。在系统层面上，我们可以观察正在部署的服务，如果其中某个服务没有响应，可以采取纠正措施。我们可以继续像之前使用内存和磁盘验证一样，使用Consul检查。主要的区别是，这次我们将使用`http`检查，而不是`script`检查。Consul会定期向我们的服务发送请求，并将失败信息发送到我们已设置的监视器。
- en: Before we proceed, we should discuss what should be checked. Should we check
    each service container? Should we check auxiliary containers like databases? Should
    we care about containers at all? Each of those checks can be useful depending
    on specific scenarios. In our case, we'll use a more general approach and monitor
    the service as a whole. Are we losing control if we are not monitoring each container
    separately? The answer to that question depends on the goals we're trying to accomplish.
    What do we care about? Do we care if all containers are running, or whether our
    services are working and performing as expected? If we'd need to choose, I'd say
    that the latter is more important. If our service is scaled to five instances
    and it continues performing well even after two of them stop working, there is
    probably nothing we should do. Only if service as a whole stops working, or if
    it doesn't perform as expected, some corrective actions should be taken.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike hardware checks that benefit from uniformity, and should be located
    in one place, system checks can vary from one service to another. In order to
    avoid dependencies between a team that maintains a service and a team in charge
    of the overall CD processes, we''ll keep check definitions inside the service
    code repository. That way, service team has full freedom to define checks they
    think are appropriate for the service they''re developing. Since parts of the
    checks are variables, we''ll define them through the Consul Template format. We''ll,
    also, employ naming convention and always use the same name for the file. The
    `consul_check.ctmpl` describes checks for the `books-ms` service, and is as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We defined not only checks but also the service named `books-ms`, the tag `service`,
    port it is running on and the address. Please note that, since this is the definition
    of the service as a whole, the port is `80`. In our case, the service as a whole
    is accessible through the proxy, no matter how many containers we deploy, nor
    ports they are running on. The address is obtained from Consul, through the `proxy/ip`
    key. This service should behave the same, no matter which color is currently deployed.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the service is defined, we proceed with the checks (in this case only
    one). Each check has an ID and a name, which are used for informational purposes
    only. The key entry is `http` that defines the address Consul will use to ping
    this service. Finally, we specified that ping should be performed every ten seconds
    and that the timeout should be one second. How do we use this template? To answer
    that question, we should explore the Jenkinsfile, located in the `master` branch
    of the `books-ms` repository:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The only significant difference, when compared with Jenkinsfiles we used in
    previous chapters, is the last line that invokes the `updateChecks` function from
    the `roles/jenkins/files/scripts/workflow-util.groovy` utility script. The function
    is as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'In a nutshell, the function copies the file `consul_check.ctmpl` to the `swarm-master`
    node, and runs Consul Template. The result is the creation of, yet another, Consul
    configuration file that will perform service checks:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: 'With the checks defined, we should take a closer look at the `roles/consul-healing/templates/manage_watches.sh`
    script. The relevant part is as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Since we aim at performing two types of checks (hardware and services), we
    had to introduce an `if`/`else` statement. When hardware failure is discovered
    (`mem` or `disk`), build request is sent to the Jenkins job `hardware-notification`.
    This part is the same as the definition we created earlier. On the other hand,
    we''re assuming that any other type of checks is related to services, and a request
    is sent to the `service-redeploy` job. In our case, when `books-ms` service fails,
    Consul will send a request to build the `service-redeploy` job, and pass `books-ms`
    as the `serviceName` parameter. We''re creating this job in Jenkins in the same
    way as we created others. The main difference is the usage of the `roles/jenkins/templates/service-redeploy.groovy`
    script. The content is as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: You probably noticed that the script is much shorter than the `Jenkinsfile`
    we used before. We could easily use the same script to redeploy as the one we're
    using for deployment, and the end result would be (almost) the same. However,
    the objectives differ. One of the crucial requirements is speed. If our service
    failed, we want to redeploy is as fast as possible, while having into account
    as many different scenarios as possible. One of the important differences is that
    we are not running tests during redeployment. All tests already passed during
    deployment, or the service would not be running in the first place and there would
    be nothing to fail. Besides, the same set of tests running against the same release
    will always produce the same result, or our tests are flaky and unreliable, indicating
    grave mistakes in the testing process. You'll also notice that building and pushing
    to the registry is missing. We do not want to build and deploy a new release,
    that's what deployment is for. We want to get the latest release back to production
    as soon as possible. Our need is to restore the system to the same state as it
    was before the service failed. Now that we covered what is, intentionally, missing
    from the redeployment script, let's go through it.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: 'The first change is in the way how we obtain the number of instances that should
    be running. Up until now, Jenkinsfile, residing in the service repository, was
    deciding how many instances to deploy. We had the statement `def instances = 1`
    in the Jenkinsfile. However, since this redeployment job should be used for all
    services, we had to create a new function called `getInstances` that will retrieve
    the number stored in Consul. It represents the `desired` number of instances,
    and corresponds with the value specified in the Jenkinsfile. Without it, we would
    risk deploying a fixed number of containers and, potentially, destroying someone
    else''s intention. Maybe developers decided to run two instances of the service,
    or maybe they scaled it to five after realizing that the load is too big. For
    that reason, we have to discover how many instances to deploy, and put that information
    to good use. The `getInstances` function defined in the `roles/jenkins/files/scripts/workflow-util.groovy`
    script is as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The function sends a simple request to Consul and returns the number of instances
    of the specified service.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Next, we are deleting the job workspace directory before cloning the code from
    GitHub. This removal of the files is necessary since the Git repository is different
    from one service to another, and Git repository cannot be cloned on top of the
    other. We don't need all the code, but rather few configuration files, specifically,
    those for Docker Compose and Consul. Never the less, it's easier if we clone everything.
    If the repository is big, you might consider getting only the files you need.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Now that all the files we'll need (and many more that we won't) are in the workspace,
    we can initiate the redeployment. Before we proceed, let's discuss what might
    have caused the failure in the first place. We can identify three main culprits.
    One of the nodes stopped working, one of the infrastructure services is down (Swarm,
    Consul, and so on), or our own service failed. We'll skip the first possibility
    and leave it for later. If one of the infrastructure services stopped working,
    we could fix that by running Ansible playbooks. On the other hand, if the cluster
    is operating as expected, all we have to do is redeploy the container with our
    service.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s explore provisioning with Ansible. The part of the script that runs
    Ansible playbooks is as follows:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The major difference, when compared with the previous Jenkins Workflow scripts,
    is that, this time, provisioning is inside the `try`/`catch` block. The reason
    is a possible node failure. If the culprit for this redeployment is one malfunctioning
    node, provisioning will fail. That''s not a problem in itself if the rest of the
    script is run. For that reason, we have this script block under `try`/`catch`,
    thus ensuring that the script continues running no matter the provisioning result.
    After all, if a node is not working, Swarm will redeploy the service somewhere
    else (explained in more detail later on). Let''s move onto the next use case:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Those two lines are the same as in the deployment script in the Jenkinsfile.
    The only, subtle, difference is that the number of instances is not hardcoded,
    but, as we saw earlier, discovered.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: That's it for now. With the script we explored, we have two out of three scenarios
    covered. Our system will recover if one of infrastructure or one of our services
    fails. Let's try it out.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: We'll stop one of the infrastructure services and see whether the system will
    get restored to the original state. There is probably no better candidate than
    `nginx`. It is part of our services infrastructure and, without it, none of our
    services work.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 'Without nginx, our service is not accessible through the port `80`. At no point,
    Consul will know that `nginx` failed. Instead, Consul checker will detect that
    the `books-ms` service is not operational, and initiate a new build of the Jenkins
    job `service-redeploy`. As a result, provisioning and redeployment will be executed.
    Part of Ansible provisioning is in charge of ensuring that, among others, nginx
    is running:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Let's enter the `swarm-master` node and stop the `nginx` container.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'With nginx process dead, the `books-ms` service is not accessible (at least
    not through the port `80`). We can confirm that by sending an HTTP request to
    it. Please bear in mind that Consul will initiate redeployment through Jenkins,
    so hurry up before it becomes operational again:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'As expected, `curl` returned the `Connection refused` error:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We can also take a look at the Consul UI. The Service `books-ms` check should
    be in the critical state. You can click on the `swarm-master` link to get more
    details about all the service running on that node and their statuses. As a side
    note, `books-ms` is registered as running on the `swarm-master` server because
    that''s where the proxy is. There is also `books-ms-blue` or `books-ms-green`
    service that contains data specific to deployed containers:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Consul Health Checks and Watches for Monitoring Services](img/B05848_15_18.jpg)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
- en: Figure 15-18 – Consul status screen with one check in the critical status
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Finally, We can take a look at the service-redeploy console screen. The redeployment
    process should be on the way, or, more likely, finished by now.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the build of the `service-redeploy` job is finished, everything should
    be restored to the original status, and we can use our service:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The output of the response is as follows:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The proxy service has been, indeed, redeployed, and everything is working as
    expected.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: 'What would happen if, instead stopping one of the infrastructure services,
    we remove the `book-ms` instance entirely? Let''s remove the service container,
    and see what happens:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Go ahead and open the `service-redeploy` Jenkins console screen. It might take
    a couple of seconds until Consul initiates a new build. Once started, all we need
    to do is wait a bit longer, until the build finishes running. Once you see the
    **Finished: Success** message, we can double check whether the service is indeed
    operational:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Consul Health Checks and Watches for Monitoring Services](img/B05848_15_19.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
- en: Figure 15-19 – Output of the service-redeploy build
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The combined output of both commands is as follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Our service is, indeed, running and accessible through the proxy. The system
    healed itself. We can stop almost any process, on any of the Swarm nodes, and,
    with a few seconds delay, system will restore itself to the previous state. The
    only thing we haven''t tried is to stop the whole node. Such an action would require
    a few more changes to our scripts. We''ll explore those changes later on. Please
    be aware that this is a demo setting and it does not mean that the system, as
    it is now, is ready for production. On the other hand, it''s not far either. With
    a bit of tweaking, you could consider applying this to you system. You might want
    to add some notifications (email, Slack, and so on) and adapt the process to your
    needs. The important part is the process. Once we understand what we want, and
    how to get there, the rest is usually only a question of time:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 'The process we have, at this moment, is as follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Consul performs periodic HTTP requests, runs custom scripts or waits for **time-to-live**
    (**TTL**) messages from services.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In case Consul's request does not return status code `200`, the script returns
    a non-zero exit code, or TTL message was not received, Consul sends a request
    to Jenkins.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Upon receiving a request from Consul, Jenkins initiates redeployment process,
    sends notification messages, and so on:'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Setting Up Consul Health Checks and Watches for Monitoring Services](img/B05848_15_20.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
- en: Figure 15-20 – Checking and healing Consul pinging services
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: We explored a few examples of reactive healing. Those were, by no means, exhaustive
    enough to provide you with everything you need to set up your own system, but,
    hopefully, provided you with a path that you should explore in more depth, and
    adapt to your own needs. Right now, we'll move our attention to preventive measure
    we can take. We'll examine scheduled scaling and descaling. It is a good candidate
    as an introduction to preventive healing since it is probably the easiest one
    to implement.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Preventive Healing through Scheduled Scaling and Descaling
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Preventive healing is a huge topic in itself and, in all but the simplest scenarios,
    requires historical data that can be used to analyze the system and predict the
    future. Since, at this moment, we neither have the data, nor the tools to generate
    them, we'll start with a very simple example that does not require any of those.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: The scenario we'll explore is as follows. We are working on an online book store.
    Marketing department decided that, starting from the new years eve, all readers
    will be able to purchase books with a discount. The campaign will last for a day,
    and we expect it to generate a huge interest. In technical terms, that means that
    during 24 hours, starting from midnight, January the first, our system will be
    under heavy load. What should we do? We already have processes and tools that
    allow us to scale our system (or parts that will be most affected). What we need
    to do is scale selected services before the campaign starts and, once it's finished,
    restore it to the original state. The problem is that no one wants to celebrate
    new years eve in the office. We can fix that easily with Jenkins. We can create
    a scheduled job that will scale, and, later on, descale our services. With this
    problem solved, another one emerges. To how many instances should we scale? We
    can define a number in advance but, in that way, we risk making a mistake. For
    example, we might decide to scale to three instances (at this moment we have only
    one). Between today and the start of the campaign, due to some other reason, the
    number of instances might increase to five. In such a scenario, not only that
    we would not increase the capacity of our system, but would accomplish quite contrary.
    Our scheduled job would descale the service from five to three. The solution might
    be to use relative values. Instead of specifying that the system should be scaled
    to three instances, we should set it up in a way that the number of instances
    should be increased by two. If there is one instance running, such a process would
    launch two more and increase the overall number to three. On the other hand, if
    someone already scaled the service to five, the end result would be seven containers
    running inside our cluster. The similar logic can be employed after the campaign
    is finished. We can create the second scheduled job that would decrease the number
    of running instances by two. From three, to one. From five, to three. It does
    not matter how many will be running at that moment since we would decrease that
    number by two.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: This process of preventive healing is similar to the usage of vaccinations.
    Their primary use is not to heal an existing infection, but to develop immunity
    that will prevent them from spreading in the first place. In the same way, we'll
    schedule scaling (and later on descaling), in order to prevent the increased load
    affecting our system in unexpected ways. Instead of healing an infected system,
    we'll prevent it from getting into bad shape.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: Let's see such the process in action.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Please open the Jenkins `books-ms-scale` configuration screen. The job configuration
    is very straightforward. It has one parameter called `scale` with the default
    value of `2`. It can be adjusted when starting a build. `Build Triggers` is set
    to `build periodically` with the value `45 23 31 12`. If you already used cron
    scheduling, this should look familiar. The format is `MINUTE HOUR DOM MONTH DOW`.
    The first number represents minutes, the second hours, the third is the day of
    a month, followed by month and the day of the week. Asterisk, can be translated
    to any. So, the value we are using is fourty fifth minute of the twenty third
    hour, on thirty first day of the twelfth month. In other words, fifteen minutes
    before new years eve. That is more than enough time for us to increase the number
    of instances before the campaign starts. For more information about the scheduling
    format, please click the icon with a question mark located right of the `Schedule*`
    field.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: 'The third, at last, part of the job configuration is the following Workflow
    script:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Since there is no real reason to duplicate the code, we are using the helper
    functions from the `roles/jenkins/files/scripts/workflow-util.groovy` script.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by defining the number of instances we want to run. We do that by
    adding the value of the `scale` parameter (defaults to two) to the number of instances
    our service is currently using. We get the latter by invoking the `getInstances`
    function we already utilized in a couple of cases throughout the book. That new
    value is put to Consul through the `putInstances` function. Finally, we run a
    build of the `service-redeploy` job which does the redeployment that we need.
    To summarize, since the `service-redeploy` job reads the number of instances from
    Consul, all we had to do in this script, before invoking the `service-redeploy`
    build, was to change the `scale` value in Consul. From there on, `service-redeploy`
    job will do what''s needed to scale the number of containers. By invoking the
    `service-redeploy` job, we avoided replicating the code that is already used elsewhere:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '![Preventive Healing through Scheduled Scaling and Descaling](img/B05848_15_21.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
- en: Figure 15-21 – Configuration of the books-ms-scale job representing scheduled
    scaling
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we have two paths we can take. One is to wait until new years eve and confirm
    that the job works. I will take liberty and assume that you do not have so much
    patience, and proceed with the alternative. We''ll run the job manually. Before
    we do that, let''s take a quick look at the current situation inside our Swarm
    cluster:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The combined output of the commands is as follows:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: We can see that only one instance of the books-ms service is running (`booksms_app-blue_1`)
    and that Consul has the value of `1` stored as the `books-ms/instances` key.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run the `books-ms-scale` Jenkins job. If everything works as expected,
    it should increase the number of `books-ms` instances by two, resulting in three
    in total. Please open the `books-ms-scale` build screen and click the **Build**
    button. You can monitor the progress by opening the `books-ms-scale` console screen.
    You''ll see that, after storing the new number of instances in Consul, it will
    invoke a build of the `service-redeploy` job. After a few seconds, the build will
    finish, and we''ll be able to verify the result:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The combined output of the commands is as follows.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'As we can see, this time, three instances of the service are running. We can
    observe the same result from the Consul UI, by navigating to the `key/value books-ms/instances
    screen`:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '![Preventive Healing through Scheduled Scaling and Descaling](img/B05848_15_22.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
- en: Figure 15-22 – Consul UI Key/Value books-ms/instances screen
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Our system is now ready to take the increased load during those 24 hours. As
    you saw, we were very generous by scheduling it to run 15 minutes before the due
    date. The execution of the build lasted only a couple of seconds. We could speed
    it even more by skipping the provisioning part of the `service-redeploy` job.
    I'll leave that to you as an exercise.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Add conditional to the service-redeploy job**'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: Modify the service-redeploy Jenkins job so that provisioning is optional. You'll
    have to add a new parameter that accepts boolean value and add an if/else statement
    to the workflow script. Make sure that the parameter has the default value set
    to true so that provisioning is always performed unless specified otherwise. Once
    finished, switch to the configuration of the `books-ms-scale` job and modify it
    so that the call to the service-redeploy job passes the signal to skip provisioning.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: What happens after 24 hours passes, and the campaign is over? The Jenkins job
    `books-ms-descale` will be run. It is the same as the `books-ms-scale` job with
    two notable differences. The `scale` parameter is set to `-2` and it is scheduled
    to run on the second of January, fifteen minutes after midnight (`15 0 2 1 *`).
    We gave our system fifteen minutes of cool-down time. The Workflow script is the
    same.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run it by opening the `books-ms-descale` build screen, and clicking
    the **Build** button. It will reduce the number of instances by two, and run a
    build of the `service-redeploy` job. Once finished, we can have another look at
    our cluster:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The combined output of the commands is as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: We are back where we started. The campaign is finished, and the service is reduced
    from three instances to one. The value in Consul is restored as well. The system
    survived horde of visitors desperately trying to benefit from our new years eve
    discount, business is happy that we were able to serve them all, and life continues
    as it was.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: We could have created different formulas to accomplish our goals. It could be
    as simple as multiplying the number of existing instances. That would give us
    a bit more realistic scenario. Instead of adding two new containers, we could
    have multiplied them by two. If three were running before, six would be running
    afterwards. As you can imagine, those formulas can often be much more complicated.
    More importantly, they would require much more consideration. If, instead of running
    one, we were running fifty different services, we would not apply the same formula
    to all of them. Some would need to be scaled a lot, some not so much, while other
    not at all. The best way to proceed would be to employ some kind of stress tests
    that would tell us which pieces of the system require scaling, and how much that
    scaling should be. There's plethora of tools that can run those tests, with JMeter
    and Gatling (my favorite) being only a few.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: I mentioned, at the beginning of this chapter, that preventive healing is based
    on historical data. This was a very poor, yet very efficient and simple way of
    demonstrating that. In this case, historical data was in our heads. We knew that
    a marketing campaign will increase the load on our service, and acted in a way
    that potential problems are avoided. The real, and much more complicated, way
    to create preventive healing require more than our memory. It requires a system
    capable of storing and analyzing data. We'll discuss requirements for such a system
    in the next chapter.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: Reactive Healing with Docker Restart Policies
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Those more familiar with Docker might be asking why I did not mention Docker
    restart policies. On a first look, they seem to be a very effective way to recuperate
    failed containers. They are, indeed, the easiest way to define when to restart
    containers. We can use the `--restart` flag on `docker run` (or the equivalent
    Docker Compose definition), and the container will be restarted on exit. The following
    table summarizes the currently supported restart policies:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '| Policy | Result |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
- en: '| `no` | Do not automatically restart the container when it exits. This is
    the default. |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
- en: '| `on-failure[:max-retries]` | Restart only if the container exits with a non-zero
    exit status. Optionally, limit the number of restart retries the Docker daemon
    attempts. |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
- en: '| `always` | Always restart the container regardless of the exit status. When
    you specify always, the Docker daemon will try to restart the container indefinitely.
    The container will also always start on daemon startup, regardless of the current
    state of the container. |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
- en: '| `unless-stopped` | Always restart the container regardless of the exit status,
    but do not start it on daemon startup if the container has been put to a stopped
    state before. |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
- en: An example of the usage of restart policy is as follows (please do not run it).
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: In that case, mongo would be restarted up to three times. The restart would
    occur only if the process running inside the mongo container exits with a non-zero
    status. If we stop that container, the restart policy would not be applied.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: The problem with restart policies is that there are too many corner cases not
    contemplated. The process running inside a container might fail due problems not
    directly related to the container that failed. For example, a service inside the
    container might be trying to connect to a database through a proxy. It might have
    been designed to stop if the connection could not be established. If, for some
    reason, the node with the proxy is not operational, it doesn't matter how many
    times we restart the container, the result will always be the same. There is nothing
    wrong in trying, but, sooner or later, someone needs to be notified about the
    problem. Maybe provisioning scripts need to be run to restore the system to the
    desired state. Maybe more nodes need to be added to the cluster. Maybe even the
    whole data center is not operational. No matter the cause, there are many more
    possible paths that could be taken than what restart policy permits. For those
    reasons, we do need a more robust system to deal with all those circumstances,
    and we are already on the way of creating it. The flow we have established is
    much more robust than simple restart policies, and it already covers the same
    problems as those that can be solved with the Docker restart policy. Actually,
    as it is now, we have many more paths covered. We perform containers orchestration
    with Docker Swarm that will make sure that our services are deployed to the most
    suited nodes inside the cluster. We use Ansible that is continuously (with each
    deploy) provisioning the cluster, thus ensuring that the whole infrastructure
    is in the correct state. We are using Consul in combination with Registrator and
    Consul Template for service discovery, making sure that the registry of all our
    services is always up to date. Finally, Consul health checks are continuously
    monitoring the state of our cluster and, in case of a failure, sends requests
    to Jenkins that will initiate appropriate corrective actions.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: We are utilizing the Docker's slogan *batteries included but removable* to our
    benefit by extending the system to suit our needs.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: Combining On-Premise with Cloud Nodes
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I won't start a discussion whether to use on-premise servers or cloud hosting.
    Both have their advantages and disadvantages. The decision what to use depends
    on individual needs. Besides, such an attempt would be better suited inside the
    clustering and scaling chapter. However, there is a clear use case in favour of
    cloud hosting that would suit very well the needs of, at least, one of the scenarios
    from this chapter.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: Cloud hosting shines when we need a temporary increase in the cluster capacity.
    A good example would be our fictional scenario with the new years eve campaign.
    We needed to boost our capacity for a day. If you are already hosting all your
    servers in the cloud, this scenario would require a few more nodes to be created
    and, later on, destroyed, once the load is reduced to its former size. On the
    other hand, if you use on-premise hosting, that would be an opportunity to contract
    cloud hosting only for those additional nodes. Buying a new set of servers that
    will be used only during a short period is very costly, especially if we take
    into account that the cost cosists not only of hardware price, but also maintenance.
    If, in such cases, we use cloud nodes, the invoice would be paid only for the
    time we use them (assuming that we destroy them afterwards). Since we have all
    the scripts for provisioning and deploying services, the setup of those nodes
    would be almost effortless.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Personally, I prefer the combination of on-premise and cloud hosting. My on-premise
    servers are fulfilling the need for the minimum capacity, while cloud hosting
    nodes are being created (and destroyed) whenever that capacity needs to be temporarily
    increased. Please note that such a combination is only my personal preference,
    and might not apply to your use cases.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: The important part is that everything you learned from this book is equally
    applicable to both situations (on-premise or cloud). The only significant difference
    is that you should not be using Vagrant on production servers. We are using it
    only to create quickly virtual machines on you laptop. If you are looking for
    a way to create production VMs in a similar way as with Vagrant, I suggest you
    explore another HashiCorp product called **Packer**.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: Self-Healing Summary (So Far)
  id: totrans-310
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What we built so far is, in some cases, close to what Kubernetes and Mesos offer
    out of the box, while in others exceeds their functionality. The real advantage
    of the system we are working on is its the ability to fine-tune it to your needs.
    That is not to say that Kubernetes and Mesos should not be used. You should, at
    least, be familiar with them. Do not take anyone's word for granted (not even
    mine). Try them out and make your own conclusions. There are as many use cases
    as there are projects, and each is different from the other. While in some cases
    the system we built would provides a good base to build upon, there are others
    where, for example, Kubernetes or Mesos might be more appropriate. I could not
    fit all the possible combinations in detail inside a single book. That would increase
    it to an unmanageable size.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Instead, I choose to explore ways we can build systems that are highly extensible.
    Almost any piece we used by now can be extended, or replaced with another. I feel
    that this approach gives you more possibilities to adapt examples to your own
    needs and, at the same time, learn not only how something works, but why we chose
    it.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: We went far from the humble beginnings of this book, and we are not yet done.
    The exploration of self-healing systems will continue. However, first we need
    turn our attention to different ways of collecting data generated inside our cluster.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: As the first part of the self-healing subject is closing to an end, let us destroy
    our VMs, and start the new chapter fresh.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: 'You know what follows next. We''ll destroy everything we did, and begin the
    next chapter fresh:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
