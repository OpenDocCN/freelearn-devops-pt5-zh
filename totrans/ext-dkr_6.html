<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Extending Your Infrastructure</h1></div></div></div><p>In <a class="link" href="ch02.html" title="Chapter 2. Introducing First-party Tools">Chapter 2</a>, <em>Introducing First-party Tools</em>, we looked at the tools Docker provides for extending the functionality of the core Docker engine. In this chapter, we will look at third-party tools that extend the way you manage your Docker configuration and build and launch <a id="id254" class="indexterm"/>containers. The tools that we are going to be discussing are as<a id="id255" class="indexterm"/> follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Puppet</strong>: <a class="ulink" href="http://puppetlabs.com/">http://puppetlabs.com/</a></li><li class="listitem" style="list-style-type: disc"><strong>Ansible</strong>: <a class="ulink" href="http://www.ansible.com/docker/">http://www.ansible.com/docker/</a></li><li class="listitem" style="list-style-type: disc"><strong>Vagrant</strong>: <a class="ulink" href="https://docs.vagrantup.com/v2/docker/">https://docs.vagrantup.com/v2/docker/</a></li><li class="listitem" style="list-style-type: disc"><strong>Packer</strong>: <a class="ulink" href="https://www.packer.io/docs/builders/docker.html">https://www.packer.io/docs/builders/docker.html</a></li><li class="listitem" style="list-style-type: disc"><strong>Jenkins</strong>: <a class="ulink" href="https://jenkins-ci.org/content/jenkins-and-docker/">https://jenkins-ci.org/content/jenkins-and-docker/</a></li></ul></div><p>For each<a id="id256" class="indexterm"/> of the <a id="id257" class="indexterm"/>tools, we will look at how to install, configure, and <a id="id258" class="indexterm"/>use them with Docker. Before we look at how to use the tools, let's discuss why we would want to use them.</p><div><div><div><div><h1 class="title"><a id="ch06lvl1sec29"/>Why use these tools?</h1></div></div></div><p>So far, we have been looking at tools that either use the main Docker client or use the tools that are <a id="id259" class="indexterm"/>provided by Docker and other third parties to support the main Docker client.</p><p>For quite a while, the functionality that some of these tools have now did not exist within a Docker support product. For example, if you wanted to launch a Docker host, you couldn't just use Docker Machine, instead you had to use something such as Vagrant to launch a virtual machine (locally or in the cloud) and then install Docker using a bash script, Puppet, or Ansible.</p><p>Once you had your Docker host up and running, you could use these tools to place your containers on hosts as there was no Docker Swarm or Docker Compose (remember Docker Compose started off as a third-party tool called Fig).</p><p>So while Docker has slowly been releasing their own tooling, some of these third-party options are actually <a id="id260" class="indexterm"/>more mature and have quite an active community behind them.</p><p>Let's start by looking at Puppet.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec30"/>Puppetize all the things</h1></div></div></div><p>Long before<a id="id261" class="indexterm"/> the following <em>Containerize all the things</em> meme regularly started to pop up in people's presentations:</p><div><img src="img/B05468_06_01.jpg" alt="Puppetize all the things"/></div><p>People were saying the same thing about Puppet. So, what is Puppet and why would you want to use it on all things?</p><p>Puppet Labs, the makers of Puppet, describe Puppet as:</p><div><blockquote class="blockquote"><p><em>"With Puppet, you define the state of your IT infrastructure, and Puppet automatically enforces the desired state. Puppet automates every step of the software delivery process, from provisioning of physical and virtual machines to orchestration and reporting; from early-stage code development through testing, production release and updates."</em></p></blockquote></div><p>Before tools such as Puppet, working as a sysadmin could sometimes be quite a tedious process: if you weren't looking into problems, you were writing your own scripts to bootstrap servers once they had been built, or even worse, you were copying and pasting commands from an internal wiki to install your software stack and configure it.</p><p>Servers would very quickly evolve away from your initial installation and when they broke, which all servers eventually do, things could get really interesting, complicated, scary, very bad, or all of them quickly.</p><p>This is where Puppet comes in; you define what you need your server to look like and Puppet does the heavy lifting for you, making sure that your configuration is not only applied, but also maintained.</p><p>For example, if I had several servers behind a load balancer for my PHP-powered website, it's important that the servers are all configured in the same way, meaning that they all have the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The same NGINX or Apache configuration</li><li class="listitem" style="list-style-type: disc">The same version of PHP along with the same configuration</li><li class="listitem" style="list-style-type: disc">The same PHP modules installed, at the same version</li></ul></div><p>To do this<a id="id262" class="indexterm"/> before Puppet, I would have to ensure that not only I kept a script that is used to do the initial installation, but I would also have to carefully manually apply the same configuration changes across the servers or write a script to synchronize my changes across the cluster.</p><p>I would also have to ensure that anyone who has access to the servers adheres to the processes and procedures I have put in place in order to maintain consistency across my load balanced web servers.</p><p>If they didn't, I would start to get configuration drift, or worse, still one in every x requests could be being served from a server that is running a different codebase/configuration from the other machines.</p><p>With Puppet, if I need to run an up-to-date version of PHP 5.6 because my application doesn't work correctly under PHP 7, then I can use the following definition to ensure that my requirements are met:</p><div><pre class="programlisting">package { 'php' :
  ensure =&gt; '5.6',
}</pre></div><p>This will make sure that the <code class="literal">php</code> package is installed and that the version is and stays at 5.6, I can then take this single configuration and apply it across all of my web servers.</p><p>So, what's this got to do with Docker?</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec47"/>Docker and Puppet</h2></div></div></div><p>Before Docker Machine, Docker Compose, and Docker Swarm, I used Puppet to bootstrap and <a id="id263" class="indexterm"/>manage my Docker hosts and containers. Let's <a id="id264" class="indexterm"/>take a look at the excellent Docker Puppet module written by Gareth Rushgrove.</p><p>To start off, we need a virtual machine to work on. In the previous chapters, we have been using Docker Machine to launch virtual machines that we can run our containers on.</p><p>However, as we want Puppet to manage the installation of Docker and the container on which we are going to be launching a local virtual machine using Vagrant, confusingly, we are also going to be looking at Vagrant later in this chapter, so we will not go into much detail here.</p><p>First of all, you<a id="id265" class="indexterm"/> need to ensure that you have Vagrant installed, you can get the latest release from <a class="ulink" href="https://www.vagrantup.com/">https://www.vagrantup.com/</a> and you can find a guide to perform the installation at <a class="ulink" href="https://www.vagrantup.com/docs/getting-started/">https://www.vagrantup.com/docs/getting-started/</a>.</p><p>Once you have <a id="id266" class="indexterm"/>Vagrant installed, you can a launch an Ubuntu 14.04 virtual<a id="id267" class="indexterm"/> server using VirtualBox by running the following command:</p><div><pre class="programlisting">
<strong>mkdir  ubuntu &amp;&amp; cd ubuntu/</strong>
<strong>vagrant init ubuntu/trusty64; vagrant up --provider VirtualBox</strong>
</pre></div><p>This will download and launch the virtual server, storing everything in the <code class="literal">ubuntu</code> folder. It will also mount the <code class="literal">ubuntu</code> folder as a filesystem share using the <code class="literal">/vagrant</code> path:</p><div><img src="img/B05468_06_02.jpg" alt="Docker and Puppet"/></div><p>Now that <a id="id268" class="indexterm"/>we have our virtual server up and running, let's connect to it <a id="id269" class="indexterm"/>and install the Puppet agent:</p><div><pre class="programlisting">
<strong>vagrant ssh</strong>
<strong>sudo su -</strong>
<strong>curl -fsS https://raw.githubusercontent.com/russmckendrick/puppet-install/master/ubuntu | bash</strong>
</pre></div><p>You should see something similar to the following terminal session:</p><div><img src="img/B05468_06_03.jpg" alt="Docker and Puppet"/></div><p>Now that <a id="id270" class="indexterm"/>we have the Puppet agent installed, the final step is to install <a id="id271" class="indexterm"/>the Docker module from Puppet Forge:</p><div><pre class="programlisting">
<strong>puppet module install garethr-docker</strong>
</pre></div><p>You may see warnings such as the one in the following terminal session; don't worry about these, they are to just inform you of the upcoming changes to Puppet:</p><div><img src="img/B05468_06_04.jpg" alt="Docker and Puppet"/></div><p>At this point, it's worth point out that we haven't actually installed Docker yet, so let's do that now by running our first puppet manifest. On your local machine, create a file called <code class="literal">docker.pp</code> in<a id="id272" class="indexterm"/> the <code class="literal">ubuntu</code> folder. The file should contain the <a id="id273" class="indexterm"/>following contents:</p><div><pre class="programlisting">include 'docker'

docker::image { 'russmckendrick/base': }

docker::run { 'helloworld':
  image   =&gt; 'russmckendrick/base',
  command =&gt; '/bin/sh -c "while true; do echo hello world; sleep 1; done"',
}</pre></div><p>When we run this manifest using <code class="literal">puppet apply</code>, Puppet will know that we need Docker installed to be able download the <code class="literal">russmckendrick/base</code> image and then launch the <code class="literal">helloworld</code> container.</p><p>Back on our virtual machine, let's apply the manifest by running the following command:</p><div><pre class="programlisting">
<strong>puppet apply /vagrant/docker.pp</strong>
</pre></div><p>You will see a lot of output from the command, as shown in the following screenshot:</p><div><img src="img/B05468_06_05.jpg" alt="Docker and Puppet"/></div><p>The first thing that happens is that Puppet will compile a catalogue, this is essentially a list of all the tasks that it needs to complete in order to apply the configuration that we have defined in the manifest file. Puppet will then execute these tasks. You should be able to see Puppet:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Add the official Docker APT repository</li><li class="listitem" style="list-style-type: disc">Perform an <code class="literal">apt</code> update to initialize the new repository</li><li class="listitem" style="list-style-type: disc">Install Docker and its prerequisites</li><li class="listitem" style="list-style-type: disc">Download the <code class="literal">russmckendrick/base</code> image</li><li class="listitem" style="list-style-type: disc">Launch the <code class="literal">helloworld</code> container</li></ul></div><p>Let's check whether this happened by confirming the Docker version, look at the images that are downloaded, check which containers are running, and finally attach to the <code class="literal">helloworld</code> container:</p><div><pre class="programlisting">
<strong>docker --version</strong>
<strong>docker images</strong>
<strong>docker ps</strong>
<strong>docker attach helloworld</strong>
</pre></div><p>To detach <a id="id274" class="indexterm"/>from the container, press <em>Ctrl</em> + <em>C</em> on your keyboard. This will <a id="id275" class="indexterm"/>not only return your prompt to the virtual machine, but also stop the <code class="literal">helloworld</code> container:</p><div><pre class="programlisting">
<strong>docker ps -a</strong>
</pre></div><p>You can see the output I got when running the commands in the following terminal session:</p><div><img src="img/B05468_06_06.jpg" alt="Docker and Puppet"/></div><p>So what happens if we apply the manifest again? Let's see it by running <code class="literal">puppet apply /vagrant/docker.pp</code> for a second time.</p><p>You should see a lot less output this time, in fact, the only output you should see other than the warnings is the confirmation that the <code class="literal">helloworld</code> container has started backing up:</p><div><img src="img/B05468_06_07.jpg" alt="Docker and Puppet"/></div><p>Now that we have an idea of how to get something basic up and running, let's deploy our WordPress installation. First of all, by default, our virtual machine has quite a limited vagrant <a id="id276" class="indexterm"/>configuration, so let's remove the virtual machine and<a id="id277" class="indexterm"/> bring up a more complex configuration.</p><p>To remove the virtual machine, type exit in your terminal until you are back on your local PC; once there, type the following command:</p><div><pre class="programlisting">
<strong>vagrant destroy</strong>
</pre></div><p>Once you hit Enter, you will receive a prompt asking <em>Are you sure you want to destroy the 'default' VM?</em>, answer yes and the virtual machine will be powered down and removed.</p><p>Next, replace the entire content of the file called <code class="literal">Vagrantfile</code> that can be found in your <code class="literal">ubuntu</code> folder:</p><div><pre class="programlisting"># -*- mode: ruby -*-
# vi: set ft=ruby :

VAGRANTFILE_API_VERSION = "2"

Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
    config.vm.box = "ubuntu/trusty64"
    config.vm.network "private_network", ip: "192.168.33.10"
    HOSTNAME = 'docker'
    DOMAIN   = 'media-glass.es'
    Vagrant.require_version '&gt;= 1.7.0'
    config.ssh.insert_key = false

  config.vm.host_name = HOSTNAME + '.' + DOMAIN

  config.vm.provider "VirtualBox" do |v|
    v.memory = 2024
    v.cpus = 2
  end

  config.vm.provider "vmware_fusion" do |v|
    v.vmx["memsize"] = "2024"
    v.vmx["numvcpus"] = "2"
  end

$script = &lt;&lt;SCRIPT
sudo sh -c 'curl -fsS https://raw.githubusercontent.com/russmckendrick/puppet-install/master/ubuntu | bash'
sudo puppet module install garethr-docker
SCRIPT

config.vm.provision "shell",
    inline: $script
end</pre></div><p>You can also<a id="id278" class="indexterm"/> find a copy of the file in the book's GitHub repository, which can be found at <a class="ulink" href="https://github.com/russmckendrick/extending-docker/blob/master/chapter06/puppet-docker/Vagrantfile">https://github.com/russmckendrick/extending-docker/blob/master/chapter06/puppet-docker/Vagrantfile</a>.</p><p>Once you<a id="id279" class="indexterm"/> have <code class="literal">Vagrantfile</code> in place, run <code class="literal">vagrant up</code> again and the<a id="id280" class="indexterm"/> virtual machine will boot.</p><p>The differences between this virtual machine and the previous one that we launched is that it will have an IP address of <code class="literal">192.168.33.10</code>, which is only accessible from your local PC. The <code class="literal">Vagrantfile</code> also runs the commands to install Puppet and the Docker Puppet module.</p><p>While the machine is booting, put a copy of the following Puppet manifest in your <code class="literal">ubuntu</code> folder, call it <code class="literal">wordpress.pp</code>:</p><div><pre class="programlisting">include 'docker'

docker::image { 'wordpress': }
docker::image { 'mysql': }

docker::run { 'wordpress':
  image           =&gt; 'wordpress',
  ports           =&gt; ['80:80'],
  links           =&gt; ['mysql:mysql'],
}

docker::run { 'mysql':
  image           =&gt; 'mysql',
  env             =&gt; ['MYSQL_ROOT_PASSWORD=password', 'FOO2=BAR2'],
}</pre></div><p>As you can see, the format itself resembles the Docker Compose file we used to launch our WordPress installation back in <a class="link" href="ch02.html" title="Chapter 2. Introducing First-party Tools">Chapter 2</a>, <em>Introducing First-party Tools</em>. Once the virtual machine has booted, connect to it, and apply the <code class="literal">wordpress.pp</code> manifest by running the <a id="id281" class="indexterm"/>following command:</p><div><pre class="programlisting">
<strong>vagrant ssh</strong>
<strong>sudo puppet apply /vagrant/wordpress.pp</strong>
</pre></div><p>As before, you<a id="id282" class="indexterm"/> will see quite a bit of output:</p><div><img src="img/B05468_06_08.jpg" alt="Docker and Puppet"/></div><p>Once the manifest has been applied, you should be able to point your browser to the IP address at <code class="literal">http:// 192.168.33.10/</code> or use the following URL at <a class="ulink" href="http://docker.media-glass.es/">http://docker.media-glass.es/</a>, this URL resolves to the IP address configured in <code class="literal">Vagrantfile</code> and will only be accessible once the virtual machine is running and then manifest applied.</p><p>From here, you can install WordPress as you have done in other chapters. Once you have finished, don't forget to destroy your virtual machine using the <code class="literal">vagrant destroy</code> command, as it will quite happily sit in the background using resources.</p><p>So, there you have it, a very basic practical introduction to running Puppet and Docker together.</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec48"/>A more advanced Puppet example</h2></div></div></div><p>So far, we have been <a id="id283" class="indexterm"/>running Puppet on a single virtual machine, this isn't actually where its strengths lie.</p><p>Where Puppet comes into its own is when you deploy a Puppet Master server and have the Puppet Agents on your hosts talk to the Master. Here, you are able to define exactly how you want your hosts to look. For example, the following diagram shows a single Puppet Master<a id="id284" class="indexterm"/> server controlling four Docker nodes:</p><div><img src="img/B05468_06_09.jpg" alt="A more advanced Puppet example"/></div><p>In this example, we could have a Puppet manifest on the Puppet Master for each of the hosts, along with a manifest for configuration this is common across all four of the nodes.</p><p>In the example, I have Weave installed on each of the nodes, check the Puppet Forge at <a class="ulink" href="https://forge.puppetlabs.com/">https://forge.puppetlabs.com/</a>, there is a module that allows you to manage Weave <a id="id285" class="indexterm"/>called <code class="literal">tayzlor/weave</code>, this module alongside <code class="literal">garethr/docker</code> will allow you to perform the following tasks:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Install Docker on each node</li><li class="listitem" style="list-style-type: disc">Install Weave on each node</li><li class="listitem" style="list-style-type: disc">Create a Weave network across all four nodes</li><li class="listitem" style="list-style-type: disc">Manage images on each node</li><li class="listitem" style="list-style-type: disc">Launch containers on each node and configure them to use the Weave network</li></ul></div><p>By default, the Puppet agent on each of the nodes will call back to the Puppet master server every 15 minutes; when it does this, it will work through the manifests that apply to the node. If there are any changes, these will be applied during the Puppet Agent run; if there are no changes to the manifests, then no action will be taken.</p><p>Add to this that the Puppet configuration, including the manifests, lends itself really well in order to being managed by a source control and you can create some really useful workflows.</p><p>The only downside of this configuration is that it does not replace Docker Swarm, as all of the logic as to where the containers are launched is defined manually within each of manifest files. That's not to say that you can't launch a Swarm cluster using Puppet, as you can, with a<a id="id286" class="indexterm"/> little more work.</p><p>We are<a id="id287" class="indexterm"/> not going to work through the example as we still have four more tools to work through in this chapter, there are plenty of resources available on the <a id="id288" class="indexterm"/>Puppetlabs website:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Learning VM</strong>: <a class="ulink" href="https://puppetlabs.com/download-learning-vm">https://puppetlabs.com/download-learning-vm</a> </li><li class="listitem" style="list-style-type: disc"><strong>Puppet Open Source Docs</strong>: <a class="ulink" href="https://docs.puppetlabs.com/puppet/">https://docs.puppetlabs.com/puppet/</a></li></ul></div><p>You can<a id="id289" class="indexterm"/> find more details on the two Puppet modules that I have<a id="id290" class="indexterm"/> mentioned:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Docker module</strong>: <a class="ulink" href="https://forge.puppetlabs.com/garethr/docker/">https://forge.puppetlabs.com/garethr/docker/</a></li><li class="listitem" style="list-style-type: disc"><strong>Weave module</strong>: <a class="ulink" href="https://forge.puppetlabs.com/tayzlor/weave/">https://forge.puppetlabs.com/tayzlor/weave/</a></li></ul></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec49"/>A final note about Puppet</h2></div></div></div><p>In the next part of this chapter, we are going to be looking at Ansible, which most people, I suspect, think that it does exactly the same job as Puppet. While its true that there is a lot of crossover between the two, I see Ansible's strengths as an orchestration tool and Puppet excels at being a configuration management tool.</p><p>As Puppet is a really great configuration management tool, there is the temptation to start bundling a Puppet Agent inside your containers, using it as part of your image build process, or even<a id="id291" class="indexterm"/> for real-time configuration, as the container launches.</p><p>Try to avoid this, as it may add unnecessary bloat to your containers as well as introduce additional processes. Remember in an ideal world, your containers should run a single process and be ready to work as soon as they are started.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec31"/>Orchestration with Ansible</h1></div></div></div><p>I suspect a lot of people will be expecting an Ansible versus Puppet opening to this section of the chapter. In fact, as mentioned at the end of the previous section, while the two tools have<a id="id292" class="indexterm"/> a lot of crossover, their strengths lie in doing two different jobs.</p><p>They also work in completely different ways. Rather than going into the details now, let's jump right in and install Ansible and then launch our WordPress containers using an Ansible playbook.</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec50"/>Preparation</h2></div></div></div><div><div><h3 class="title"><a id="note18"/>Note</h3><p>Note that if, for any reason, you are not able to work through this section of the chapter, I have recorded a screencast to show you what happens when you launch the <a id="id293" class="indexterm"/>Ansible playbook, which can be found at <a class="ulink" href="https://asciinema.org/a/39537">https://asciinema.org/a/39537</a>.</p></div></div><p>Before launching our <a id="id294" class="indexterm"/>containers, we need to do a few things. The first thing is to install Ansible.</p><p>If you are running<a id="id295" class="indexterm"/> OS X, I would recommend installing Ansible using Homebrew. Homebrew is <a id="id296" class="indexterm"/>available at <a class="ulink" href="http://brew.sh/">http://brew.sh/</a> and can be installed with the following single command:</p><div><pre class="programlisting">
<strong>/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"</strong>
</pre></div><p>Once you have followed the on-screen prompts, you should be in a position to install Ansible using the following command:</p><div><pre class="programlisting">
<strong>brew install ansible</strong>
</pre></div><p>Now that Ansible is installed, we need to install a certain version of the DigitalOcean Python library. To do this, we need to use the <code class="literal">pip</code> command. If you don't have the <code class="literal">pip</code> command installed, then you need to run:</p><div><pre class="programlisting">
<strong>sudo easy_install pip</strong>
</pre></div><p>Now that <code class="literal">pip</code> is installed, run the following command to install the correct version of the Python library we need:</p><div><pre class="programlisting">
<strong>sudo pip install dopy==0.3.5</strong>
</pre></div><p>The final thing you will need is the name of your DigitalOcean key. The Ansible playbook we are going to run will create one for you and upload it if you don't have one already configured, so if that's the case, you can skip this part.</p><p>If you do happen to have one already associated with your DigitalOcean account, then you will name the name of it to launch the two instances and then connect to them.</p><p>To find this<a id="id297" class="indexterm"/> out, log in to the DigitalOcean control panel at <a class="ulink" href="https://cloud.digitalocean.com/">https://cloud.digitalocean.com/</a> and click on the <code class="literal">cog icon</code> on the top right-hand side of the screen and from the menu that pops up, click on the <strong>Settings</strong> button. Once the settings page loads, click on the <strong>Security</strong> button, you should then see a list of SSH keys, make a note of the name you want to use:</p><div><img src="img/B05468_06_10.jpg" alt="Preparation"/></div><p>In the preceding<a id="id298" class="indexterm"/> example, my SSH key is creatively called <code class="literal">Russ Home</code>.</p><p>Time to get a copy of the Ansible playbook we are going to be running. The code for this can be found in the <code class="literal">chapter06/docker-ansible</code> folder on the GitHub repository for this book, the<a id="id299" class="indexterm"/> complete URL is as follows:</p><p>
<a class="ulink" href="https://github.com/russmckendrick/extending-docker/tree/master/chapter06/docker-ansible">https://github.com/russmckendrick/extending-docker/tree/master/chapter06/docker-ansible</a>
</p><p>Once you have the playbook downloaded, open your terminal and go to the <code class="literal">docker-ansible</code> folder. Once in there, run the following command, replacing the DigitalOcean API with your own:</p><div><pre class="programlisting">
<strong>echo 'do_api_token: "sdnjkjdfgkjb345kjdgljknqwetkjwhgoih314rjkwergoiyu34rjkherglkhrg0"' &gt; group_vars/do.yml</strong>
<strong>echo 'ssh_key_name: "Your Key Name"' &gt;&gt; group_vars/do.yml</strong>
</pre></div><p>We are now in a position where we can run the playbook, but before we do, remember that this playbook will connect to your DigitalOcean account and launch two instances.</p><p>To launch the playbook, run the following command and wait:</p><div><pre class="programlisting">
<strong>ansible-playbook -i hosts site.yml</strong>
</pre></div><p>It will take several minutes to run through the entire process, but what you should have the end of it is two Ubuntu 14.04 Droplets launched in your DigitalOcean account. Each droplet will have the latest version of both Docker and Weave installed, Weave will be configured so that the two hosts can talk to each other.</p><p>One droplet <a id="id300" class="indexterm"/>will be running our WordPress container and the second will be running our MySQL container, both containers will be talking to each using the cross-host Weave network.</p><p>Once the task completes, you will should see something similar to the following screenshot:</p><div><img src="img/B05468_06_11.jpg" alt="Preparation"/></div><p>As you can see, in my case, I can go to <code class="literal">http://46.101.4.247</code> in my browser to start the WordPress installation.</p><p>If, for any reason, parts of the installation fail, for example, sometimes droplets can take a little longer to start and won't be available for Ansible to connect to when it tries to SSH to them, then don't worry, you will be able to rerun the Ansible playbook using the following command:</p><div><pre class="programlisting">
<strong>ansible-playbook -i hosts site.yml</strong>
</pre></div><p>Ansible will also work through the entire playbook again, this time, skipping anything that has<a id="id301" class="indexterm"/> already been created or actioned.</p><p>If you are not working through this example, or have problems, I have recorded an entire run-through of<a id="id302" class="indexterm"/> launching the playbook and then rerunning it, you can view this at <a class="ulink" href="https://asciinema.org/a/39537">https://asciinema.org/a/39537</a>.</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec51"/>The playbook</h2></div></div></div><p>There are<a id="id303" class="indexterm"/> quite a few parts of the playbook, as you can see from the following list of folders and files:</p><div><pre class="programlisting">├── ansible.cfg
├── group_vars
│   ├── do.yml
│   └── environment.yml
├── hosts
├── roles
│   ├── docker-install
│   │   └── tasks
│   │       └── main.yml
│   ├── docker-mysql
│   │   └── tasks
│   │       └── main.yml
│   ├── docker-wordpress
│   │   └── tasks
│   │       └── main.yml
│   ├── droplet
│   │   ├── tasks
│   │   │   └── main.yml
│   │   └── templates
│   │       └── dyn.yml.j2
│   ├── weave-connect
│   │   └── tasks
│   │       └── main.yml
│   └── weave-install
│       └── tasks
│           └── main.yml
└── site.yml</pre></div><p>The main file we called when launching the playbook was the <code class="literal">site.yml</code> file, this defines the order which tasks in defined in the roles folder are executed. Let's take a look at the content of this file and the roles that are being called.</p><div><div><div><div><h3 class="title"><a id="ch06lvl3sec16"/>Section one</h3></div></div></div><p>The file itself is split into four sections, the following first section deals with connecting to DigitalOcean's API from <a id="id304" class="indexterm"/>your local machine and launching the two Droplets:</p><div><pre class="programlisting">- name: "Provision two droplets in DigitalOcean"
  hosts: localhost
  connection: local
  gather_facts: True
  vars_files:
    - group_vars/environment.yml
    - group_vars/do.yml
  roles:
    - droplet</pre></div><p>It loads the both the main <code class="literal">environment.yml</code> variables file, this is where we define things such as which region the droplet is being launched in, name of the droplets, size to use, and also which image should be launched.</p><p>It also loads the <code class="literal">do.yml</code> file which contains your DigitalOcean API key and SSH keyname. If you look into the role task file in the <code class="literal">droplet</code> folder, you will see that along with launching the two droplets, it also creates the following three host groups:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">dockerhosts</code>: This group contains both droplets</li><li class="listitem" style="list-style-type: disc"><code class="literal">dockerhost01</code>: This contains our first droplet</li><li class="listitem" style="list-style-type: disc"><code class="literal">dockerhost02</code>: This group contains the second droplet</li></ul></div><p>The final action that is taken at this stage is that a file is written to the <code class="literal">group_vars</code> folder, which contains the public IP addresses of our two droplets.</p></div><div><div><div><div><h3 class="title"><a id="ch06lvl3sec17"/>Section Two</h3></div></div></div><p>The next section <a id="id305" class="indexterm"/>of the <code class="literal">site.yml</code> file deals with the installation<a id="id306" class="indexterm"/> of some basic prerequisites, Docker, and Weave on the droplets within the <code class="literal">dockerhosts</code> group:</p><div><pre class="programlisting">- name: "Install Docker &amp; Weave on our two DigitalOcean hosts"
  hosts: dockerhosts
  remote_user: root
  gather_facts: False
  vars_files:
    - group_vars/environment.yml
  roles:
    - docker-install
    - weave-install</pre></div><p>The first role deals with the installation of Docker, let's take a look at what's going within the task file for this role.</p><p>First of all, we will install curl using the <code class="literal">apt</code> package manager as we will need this later:</p><div><pre class="programlisting">- name: install curl
  apt: pkg=curl update_cache=yes</pre></div><p>Once curl has<a id="id307" class="indexterm"/> been installed, we will start configuring the<a id="id308" class="indexterm"/> official Docker APT repository by first adding the keys for the repo:</p><div><pre class="programlisting">- name: add docker apt keys
  apt_key: keyserver=p80.pool.sks-keyservers.net id=58118E89F3A912897C070ADBF76221572C52609D</pre></div><p>Then, we'll add the actual repository:</p><div><pre class="programlisting">- name: update apt
  apt_repository: repo='deb https://apt.dockerproject.org/repo ubuntu-trusty main' state=present</pre></div><p>Once the repository has been added, we can do the actual installation of Docker, making sure that we update the cached repository list before the package is installed:</p><div><pre class="programlisting">- name: install Docker
  apt: pkg=docker-engine update_cache=yes</pre></div><p>Now that Docker is installed, we need to ensure that the Docker daemon has started:</p><div><pre class="programlisting">- name: start Docker
  service: name=docker state=started</pre></div><p>Now we need to install the tools that Ansible will use to interact with the Docker daemon on our hosts, like Ansible, this is a Python program. To make sure that we can install it, we need to ensure that <code class="literal">pip</code>, the Python package manager, is installed:</p><div><pre class="programlisting">- name: install pip
  apt:
    pkg: "{{ item }}"
    state: installed
  with_items:
    - python-dev
    - python-pip</pre></div><p>Now that we know that pip is installed, we can install the <code class="literal">docker-py</code> package:</p><div><pre class="programlisting">- name: install docker-py
  pip:
    name: docker-py</pre></div><p>This package is a Docker client written in Python and supplied by Docker itself. More details on the client can be found at <a class="ulink" href="https://github.com/docker/docker-py">https://github.com/docker/docker-py</a>.</p><p>This ends the first role that is called in the second section of the <code class="literal">site.yml</code> file. Now that Docker is installed, it's time to install Weave, this is handled by the <code class="literal">weave-install</code> task.</p><p>First of all, we download the weave binary from the URL defined in the <code class="literal">environment.yml</code> file to the filesystem path that is also defined in the <code class="literal">environment.yml</code> file:</p><div><pre class="programlisting">- name: download and install weave binary
  get_url: url={{ weave_url }} dest={{ weave_bin }}</pre></div><p>Once we<a id="id309" class="indexterm"/> have the binary downloaded, we need to see<a id="id310" class="indexterm"/> the correct read, write, and execute permissions on the file so that it can be executed:</p><div><pre class="programlisting">- name: setup permissions on weave binary  
  file: path={{ weave_bin }} mode="u+rx,g+rx,o+rwx"</pre></div><p>Finally, we need to start weave and also pass it a password to enable encryption, the password is also defined in the <code class="literal">environment.yml</code> file:</p><div><pre class="programlisting">- name: download weave containers and launch with password
  command: weave launch --password {{ weave_password}}
  ignore_errors: true</pre></div><p>As you can see, at the end of this part of the task, we are telling Ansible to ignore any errors generated here. This is because, if the playbook was to be launched for a second time and weave was already running, it would complain saying that the weave router was already active. This will stop playbook from progressing any further, as Ansible interprets this message as a critical error.</p><p>Due to this, we have to tell Ansible to ignore what it thinks is a critical error here for the playbook to progress pass this stage.</p></div><div><div><div><div><h3 class="title"><a id="ch06lvl3sec18"/>Section three</h3></div></div></div><p>The next section of the <code class="literal">site.yml</code> file performs one last piece of configuration before launching the <a id="id311" class="indexterm"/>containers that go to make up our WordPress installation. All of these roles are run on our first droplet:</p><div><pre class="programlisting">- name: "Connect the two Weave hosts and start MySQL container"
  hosts: dockerhost01
  remote_user: root
  gather_facts: False
  vars_files:
    - group_vars/environment.yml
  roles:
    - weave-connect
    - docker-mysql</pre></div><p>The first role, which is called, connects the two weave networks on the two hosts together:</p><div><pre class="programlisting">- include_vars: group_vars/dyn.yml
- name: download weave containers and launch with password
  command: weave connect {{ docker_host_02 }}</pre></div><p>As you can <a id="id312" class="indexterm"/>see, the variable file that contains the IP address of our two droplets is loaded for the first time here and is used to get the IP address of the second droplet; this file, called <code class="literal">dyn.yml</code>, was created by the role that originally launched the two droplets.</p><p>Once we have the IP address of the second droplet, the <code class="literal">weave connect</code> command is executed and the configuration of the weave network is completed. We can now launch the containers.</p><p>The first container that we need to launch is the database container:</p><div><pre class="programlisting">- name: start mysql container
  docker:
    name: my-wordpress-database
    image: mysql
    state: started
    net: weave
    dns: ["172.17.0.1"]
    hostname: mysql.weave.local
    env:
      MYSQL_ROOT_PASSWORD: password
    volumes:
       - "database:/var/lib/mysql/"</pre></div><p>As you can see, this is quite a similar syntax to Docker Compose files; however, there may be slight differences, so double-check the Docker pages on the Ansible core module documentation site to ensure that you are using the right syntax.</p><p>Once the <code class="literal">my-wordpress-database</code> container has been started, it means that all the tasks we need to execute on <code class="literal">dockerhost01</code> are completed.</p></div><div><div><div><div><h3 class="title"><a id="ch06lvl3sec19"/>Section four</h3></div></div></div><p>The final section of the <a id="id313" class="indexterm"/><code class="literal">site.yml</code> file connects to our second droplet and then launches the WordPress container:</p><div><pre class="programlisting">- name: "Start the Wordpress container"
  hosts: dockerhost02
  remote_user: root
  gather_facts: False
  roles:
    - docker-wordpress</pre></div><p>All this role does is launch the WordPress container, again the file has close resemblance to the Docker Compose file:</p><div><pre class="programlisting">- include_vars: group_vars/dyn.yml
- name: start wordpress container
  docker:
    name: my-wordpress-app
    image: wordpress
    state: started
    net: weave
    dns: ["172.17.0.1"]
    hostname: wordpress.weave.local
    ports:
      - "80:80"
    env:
      WORDPRESS_DB_HOST: mysql.weave.local:3306
      WORDPRESS_DB_PASSWORD: password
    volumes:
       - "uploads:/var/www/html/wp-content/uploads/"
- debug: msg="You should be able to see a WordPress installation screen by going to http://{{ docker_host_02 }}"</pre></div><p>The final debug line prints the message at the end of the playbook run that contains the IP address <a id="id314" class="indexterm"/>of the second droplet.</p></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec52"/>Ansible and Puppet</h2></div></div></div><p>Like Puppet, Ansible, when used with a playbook like the one we have discussed, can be used as a<a id="id315" class="indexterm"/> replacement for Docker Machine and Docker Compose.</p><p>However, one<a id="id316" class="indexterm"/> thing you may have noticed is that unlike Puppet, we did not install an agent in the target machine.</p><p>When you run an Ansible playbook, it is compiled locally, and then the compiled script is pushed to your target servers using SSH and then executed.</p><p>This is one of the reasons why, during our playbook run, we have to install the Docker Python library on our two droplets, without which the compiled playbook would not have been able to launch the two containers.</p><p>Another important difference between the two tools is that Ansible executes the tasks in the order you define in the playbook.</p><p>The Puppet example we worked through wasn't complex enough to really demonstrate why this can be an issue when it comes to running Puppet manifests, but Puppet works using an eventual consistency concept, meaning that it may take a few manifest runs for your configuration to be applied.</p><p>It is possible to add requirements to Puppet manifests, for example, requiring XYZ to be executed after ABC has run. However, this can start to cause performance issues if your manifest is quite large; also, you could find yourself in a position where the manifest stops working altogether as Puppet is not able to successfully execute the manifest in the order you are <a id="id317" class="indexterm"/>defining.</p><p>This is why, in<a id="id318" class="indexterm"/> my opinion, Ansible is a lot better when it comes to orchestration than Puppet.</p><p>It's situations like this where it really matters that the tasks you have defined are executed in the exact order you need them to run in rather than leaving it up to the tool you are using to figure out the most efficient way of applying the tasks.</p><p>To me, this is the reason you should not approach any task with an attitude of "I need to choose one tool and only use that for everything," you should always choose the tool that works for the job you want to do.</p><p>This can probably be said for a lot of the tools we are looking at in this chapter; rather than assessing a tool in a "this versus that" manner, we should be asking "this or that" or even "this and that" and not limit ourselves.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec32"/>Vagrant (again)</h1></div></div></div><p>As we<a id="id319" class="indexterm"/> have already discovered earlier in this chapter, Vagrant can be used as a virtual machine manager. We have already used it to bring up a local Ubuntu 14.04 instance using VirtualBox on our local machine; however, if we wanted to, we could have done this using VMware Fusion, Amazon Web Services, DigitalOcean, or even OpenStack.</p><p>Like Puppet and Ansible, when Docker was first released, there were a lot of articles published around Vagrant versus Docker. In fact, when the question was asked on Stack Overflow, the<a id="id320" class="indexterm"/> authors of both Vagrant and Docker weighed in on the question. You can read the full discussion at <a class="ulink" href="http://stackoverflow.com/questions/16647069/should-i-use-vagrant-or-docker-for-creating-an-isolated-environment">http://stackoverflow.com/questions/16647069/should-i-use-vagrant-or-docker-for-creating-an-isolated-environment</a>
</p><p>So, in what ways can Vagrant support Docker? There are two main ones we are going to be looking at. The first is the provisioner.</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec53"/>Provisioning using Vagrant</h2></div></div></div><p>When we worked out way through Puppet, we used Vagrant to launch Ubuntu 14.04 locally using VirtualBox; as part of that, we used the Shell provisioner to install Puppet and deploy the Docker Puppet module. Vagrant has the following provisioners available:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>File</strong>: This <a id="id321" class="indexterm"/>copies files in place onto the Vagrant host</li><li class="listitem" style="list-style-type: disc"><strong>Shell</strong>: This <a id="id322" class="indexterm"/>compiles/copies bash scripts to the host and <a id="id323" class="indexterm"/>executes them</li><li class="listitem" style="list-style-type: disc"><strong>Ansible</strong>: This runs an <a id="id324" class="indexterm"/>Ansible playbook either on or against the host</li><li class="listitem" style="list-style-type: disc"><strong>Chef and Puppet</strong>: There<a id="id325" class="indexterm"/> are around dozen different ways <a id="id326" class="indexterm"/>you can use Chef or Puppet to provision your Vagrant host</li><li class="listitem" style="list-style-type: disc"><strong>Docker</strong>: This is<a id="id327" class="indexterm"/> what we will be using to provision our containers on the Vagrant host</li></ul></div><p>The <code class="literal">Vagrantfile</code> looks<a id="id328" class="indexterm"/> really close to the one we used to deploy our Puppet WordPress example:</p><div><pre class="programlisting"># -*- mode: ruby -*-
# vi: set ft=ruby :

VAGRANTFILE_API_VERSION = "2"

Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|

  config.vm.box = "ubuntu/trusty64"
  config.vm.network "private_network", ip: "192.168.33.10"
  HOSTNAME = 'docker'
  DOMAIN   = 'media-glass.es'
  Vagrant.require_version '&gt;= 1.7.0'
  config.ssh.insert_key = false
  config.vm.host_name = HOSTNAME + '.' + DOMAIN

  config.vm.provider "VirtualBox" do |v|
    v.memory = 2024
    v.cpus = 2
  end

  config.vm.provider "vmware_fusion" do |v|
    v.vmx["memsize"] = "2024"
    v.vmx["numvcpus"] = "2"
  end

  config.vm.provision "docker" do |d|
    d.run "mysql",
      image: "mysql",
      args: "-e 'MYSQL_ROOT_PASSWORD=password'"
    d.run "wordpress",
      image: "wordpress",
      args: "-p 80:80 --link mysql:mysql -e WORDPRESS_DB_PASSWORD=password"
  end

end</pre></div><p>As you can see, this<a id="id329" class="indexterm"/> will download (if you don't have it already) and launch an Ubuntu 14.04 server and then provision two containers, one WordPress and one MySQL.</p><p>To launch the host, run the following command:</p><div><pre class="programlisting">
<strong>vagrant up --provider VirtualBox</strong>
</pre></div><p>You should see <a id="id330" class="indexterm"/>something similar to the following terminal output:</p><div><img src="img/B05468_06_12.jpg" alt="Provisioning using Vagrant"/></div><p>You can also run the following command to open your browser and get to your WordPress installation screen (remember: we have launched the Vagrant host with a fixed local IP <a id="id331" class="indexterm"/>address, which means the following URL should resolve to your local installation):</p><div><pre class="programlisting">
<strong>open http://docker.media-glass.es/</strong>
</pre></div><p>You may have already <a id="id332" class="indexterm"/>noticed one thing that happened when we launched the Vagrant host: we didn't have to provide Vagrant any commands to install Docker; it took care of that for us.</p><p>Also, we had to launch our MySQL container before we launched our WordPress one. This is because we have linked our WordPress container to the MySQL one. If we tried to launch the WordPress container first, we would have received an error telling us that we are trying to reach a link that does not exist.</p><p>As you can see from the following terminal output, you can connect to your Vagrant host using the <code class="literal">vagrant ssh</code> command:</p><div><img src="img/B05468_06_13.jpg" alt="Provisioning using Vagrant"/></div><p>The other thing <a id="id333" class="indexterm"/>you may notice is that the Docker version installed<a id="id334" class="indexterm"/> isn't the most up-to-date one; this is because Vagrant installs the version that is available in the operating system's default repository rather than the latest version provided by Docker in their repository.</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec54"/>The Vagrant Docker provider</h2></div></div></div><p>As I mentioned, there<a id="id335" class="indexterm"/> are two ways in which you can use Docker with Vagrant: the one we just looked at is a provisioner, and the second way is to use a provider.</p><p>So, what's a provider? We have already used a provider twice in this chapter when we launched our Docker hosts. A provider is a virtual machine process, manager, or API that Vagrant can make a connection to and then launch a virtual machine from.</p><p>Vagrant has the following providers built in:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">VirtualBox</li><li class="listitem" style="list-style-type: disc">Docker</li><li class="listitem" style="list-style-type: disc">Hyper-V</li></ul></div><p>There is also a commercial plugin provided by the authors, which adds the following provider:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">VMware Fusion and Workstation</li></ul></div><p>Finally, Vagrant supports custom providers, such as ones for Amazon Web Services, libvirt, and even LXC, for example. A full list of custom providers and other Vagrant plugins<a id="id336" class="indexterm"/> can be found at <a class="ulink" href="http://vagrant-lists.github.io/">http://vagrant-lists.github.io/</a>.</p><p>Obviously, if you are using OS X, then you won't be able to use the Docker provider natively; however, Vagrant takes care of this you. Let's look at launching an NGINX container using<a id="id337" class="indexterm"/> the Docker provider rather than a provisioner.</p><p>The <code class="literal">Vagrantfile</code> looks a little different to the ones we have been using:</p><div><pre class="programlisting">VAGRANTFILE_API_VERSION = "2"
Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  config.vm.define "boot2docker", autostart: false do |dockerhost|
    dockerhost.vm.box = "russmckendrick/boot2docker"
    dockerhost.nfs.functional = false
    dockerhost.vm.network :forwarded_port, guest: 80, host: 9999
    dockerhost.ssh.shell = "sh"
    dockerhost.ssh.username = "docker"
    dockerhost.ssh.password = "tcuser"
    dockerhost.ssh.insert_key = false
  end
  config.vm.define "nginx", primary: true do |v|
    v.vm.provider "docker" do |d|
      d.vagrant_vagrantfile = "./Vagrantfile"
      d.vagrant_machine = "boot2docker"
      d.image = "russmckendrick/nginx"
      d.name  = "nginx"
      d.ports = ["80:80"]
    end
  end
end</pre></div><p>As you can see, it is split into two parts: one for a Boot2Docker virtual machine and the second part for the container itself. If you were to run <code class="literal">vagrant up</code>, you would see something like the following terminal output:</p><div><img src="img/B05468_06_14.jpg" alt="The Vagrant Docker provider"/></div><p>As you can see, as I <a id="id338" class="indexterm"/>am using OS X, Vagrant knows that I can run Docker natively, so it takes the first section of <code class="literal">Vagrantfile</code> and launches a Boot2Docker instance. Boot2Docker is the tiny Linux distribution that powers Docker Machine's default driver.</p><p>Once it has downloaded the Boot2Docker Vagrant Box, it launches the virtual machine and maps port <code class="literal">22</code> on the virtual machine to port <code class="literal">2222</code> on our local PC so that we can get SSH access. Also, as defined in <code class="literal">Vagrantfile</code>, port <code class="literal">80</code> from the virtual machine is mapped to port <code class="literal">9999</code> on the local PC.</p><p>Its worth noting that if I were running this on a Linux PC that had Docker installed, then this step would have been skipped and Vagrant would have made use of my local Docker installation.</p><p>Now that Boot2Docker has been started, the second part of the <code class="literal">Vagrantfile</code> can be run. If, like in my case, Vagrant has downloaded and launched the Boot2Docker Vagrant Box, then you will be asked for a password; this is because we have not exchanged keys with the Boot2Docker virtual machine. The password is <code class="literal">tcuser</code>.</p><p>Once you have entered the password, Vagrant will <a id="id339" class="indexterm"/>download the NGINX image from <a class="ulink" href="https://hub.docker.com/r/russmckendrick/nginx/">https://hub.docker.com/r/russmckendrick/nginx/</a> and launch the container, opening port <code class="literal">80</code>.</p><p>Once the container has been launched, you should be able to go to the NGINX welcome page at <code class="literal">http://localhost:9999/</code>.</p><p>If you like, you <a id="id340" class="indexterm"/>can SSH into the Boot2Docker virtual machine, as Vagrant is primarily managing the container and not the Boot2Docker virtual machine. You will have to use the following command:</p><div><pre class="programlisting">
<strong>ssh docker@localhost -p2222</strong>
</pre></div><p>Again, because we have not exchanged keys, you will need to enter the password, <code class="literal">tcuser</code>. You should then see this:</p><div><img src="img/B05468_06_15.jpg" alt="The Vagrant Docker provider"/></div><p>Once SSHed in, you will be able to run Docker commands locally. Finally, to terminate both the container and virtual machine, run the following command from within the same folder as your <code class="literal">Vagrantfile</code> and you will see something as following:</p><div><pre class="programlisting">
<strong>vagrant destroy</strong>
</pre></div><div><img src="img/B05468_06_16.jpg" alt="The Vagrant Docker provider"/></div><p>This will prompt you, asking whether you are sure you would like to remove the container and then the virtual machine; answer yes to both questions.</p><p>You must <a id="id341" class="indexterm"/>have noticed that we didn't cover our WordPress example while walking through the Docker provider. The reason for this is that the Docker provider functionality, in my opinion, is pretty much redundant now, especially as it has quite a few limitations that can all be easily overcome by using the provisioner or other tools.</p><p>One such limitation is that it can only use port mapping; we cannot assign an IP address to the virtual machine. If we did, it would have silently failed and reverted to port mapping from the virtual machine to the host PC.</p><p>Also, the functionality offered when launching containers doesn't feel as up to date and feature aligned to the latest version of Docker as the other tools we have been looking at so far in the chapter.</p><p>Because of this, I would recommend that you look at using the provisioner rather than the provider if you are looking at utilizing Vagrant.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec33"/>Packaging images</h1></div></div></div><p>So far, we have been quite happily downloading prebuilt images from the Docker Hub to test with. Next up, we are going to be looking at creating our own images. Before we dive into creating images<a id="id342" class="indexterm"/> using third-party tools, we should have a quick look at how to go about building them in Docker.</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec55"/>An application</h2></div></div></div><p>Before we start building our own images, we should really have an application to "bake" into it. I suspect <a id="id343" class="indexterm"/>you are probably getting bored of doing the same WordPress installation over and over again. We are going to be looking at something completely different.</p><p>So, we are going to build an image that has Moby Counter installed. Moby counter is an application written by Kai Davenport, who describes it as follows:</p><div><blockquote class="blockquote"><p><em>"A small app to demonstrate keeping state inside a docker-compose application."</em></p></blockquote></div><p>The application runs<a id="id344" class="indexterm"/> in a browser and will add a Docker logo to the page wherever you click, the idea being that it uses a Redis or Postgres backend to store the number of Docker logos and their positions, which demonstrates how data can persist on volumes such as the ones we looked at in <a class="link" href="ch03.html" title="Chapter 3. Volume Plugins">Chapter 3</a>, <em>Volume Plugins</em>. You can find the<a id="id345" class="indexterm"/> GitHub repository for the application at <a class="ulink" href="https://github.com/binocarlos/moby-counter/">https://github.com/binocarlos/moby-counter/</a>.</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec56"/>The Docker way</h2></div></div></div><p>Now that we know a little about the application we are going to be launching, let's take a look at how<a id="id346" class="indexterm"/> the image would be built using Docker itself.</p><p>The code for<a id="id347" class="indexterm"/> this part of the chapter is available from the GitHub repository that accompanies this book; you can find it at <a class="ulink" href="https://github.com/russmckendrick/extending-docker/tree/master/chapter06/images/docker">https://github.com/russmckendrick/extending-docker/tree/master/chapter06/images/docker</a>.</p><p>The <code class="literal">Dockerfile</code> for the basic build is quite simple:</p><div><pre class="programlisting">FROM russmckendrick/nodejs
ADD . /srv/app
WORKDIR /srv/app
RUN npm install
EXPOSE 80
ENTRYPOINT ["node", "index.js"]</pre></div><p>When we run the build, it will download the <code class="literal">russmckendrick/nodejs</code> image from the Docker Hub; this, as you may have guessed, has NodeJS installed.</p><p>Once that image has been downloaded, Docker will launch the container and add the content of the current working directory, which contains the Moby Counter code. It will then change the working directory to where the the code was uploaded to <code class="literal">/srv/app</code>.</p><p>It will then install the prerequisites required to run the application by issuing the <code class="literal">npm install</code> command; as we have set the working directory, all of the commands will be run from that location, meaning that the <code class="literal">package.json</code> file will be used.</p><p>Accompanying the <code class="literal">Dockerfile</code> is a Docker Compose file, this kicks off the build of the Moby Counter image, downloads the official Redis image, and then launches the two containers, linking them together.</p><p>Before we do that, we need to bring up a machine to run the build on; to do this, run the following command to launch a local VirtualBox-based Docker host:</p><div><pre class="programlisting">
<strong>docker-machine create --driver "VirtualBox" chapter06</strong>
</pre></div><p>Now that the Docker host has been launched, run the following to configure your local Docker client to talk directly to it:</p><div><pre class="programlisting">
<strong>eval $(docker-machine env chapter06)</strong>
</pre></div><p>Now that you have the host ready and client configured, run the following to build the image and launch the application:</p><div><pre class="programlisting">
<strong>docker-compose up -d</strong>
</pre></div><p>When you run the <a id="id348" class="indexterm"/>command, you should see something like the <a id="id349" class="indexterm"/>following output in your terminal:</p><div><img src="img/B05468_06_17.jpg" alt="The Docker way"/></div><p>Now that the application has been launched, you should be able to open your browser by running this:</p><div><pre class="programlisting">
<strong>open http://$(docker-machine ip chapter06)/</strong>
</pre></div><p>You will see a page that says Click to add logos, if you were to click around the page, Docker logos would start appearing. If you were to click on refresh, the logos you added would remain as the number of the logos, their position being stored in the Redis database.</p><div><img src="img/B05468_06_18.jpg" alt="The Docker way"/></div><p>To stop the<a id="id350" class="indexterm"/> containers and remove them, run the following <a id="id351" class="indexterm"/>commands:</p><div><pre class="programlisting">
<strong>docker-compose stop</strong>
<strong>docker-compose rm</strong>
</pre></div><p>Before we look into the pros and cons of using the Docker approach to building container images, let's look at a third-party alternative.</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec57"/>Building with Packer</h2></div></div></div><p>Packer is <a id="id352" class="indexterm"/>written by <em>Mitchell Hashimoto</em> from <em>Hashicorp</em>, the same<a id="id353" class="indexterm"/> author as Vagrant's. Because of this, there are quite a lot of similarities in the terms we will be using.</p><p>The Packer website has probably the best description of the tool:</p><div><blockquote class="blockquote"><p><em>"Packer<a id="id354" class="indexterm"/> is an open source tool for creating identical machine images for multiple platforms from a single source configuration. Packer is lightweight, runs on every major operating system, and is highly performant, creating machine images for multiple platforms in parallel. Packer does not replace configuration management like Chef or Puppet. In fact, when building images, Packer is able to use tools like Chef or Puppet to install software onto the image."</em></p></blockquote></div><p>I have been using Packer since its first release to build images for both Vagrant and public clouds.</p><p>You can download<a id="id355" class="indexterm"/> Packer from <a class="ulink" href="https://www.packer.io/downloads.html">https://www.packer.io/downloads.html</a> or, if you installed Homebrew, you can run the following command:</p><div><pre class="programlisting">
<strong>brew install packer</strong>
</pre></div><p>Now that <a id="id356" class="indexterm"/>you have Packer installed, let's take a look at a configuration <a id="id357" class="indexterm"/>file. Packer configuration files are all defined in JSON.</p><div><div><h3 class="title"><a id="note19"/>Note</h3><p>
<strong>JavaScript Object Notation </strong>(<strong>JSON)</strong> is a lightweight data-interchange format. It is <a id="id358" class="indexterm"/>easy for humans to read and write and for machines to parse and generate.</p></div></div><p>The following file does almost exactly what our <code class="literal">Dockerfile</code> did:</p><div><pre class="programlisting">{
  "builders":[{
    "type": "docker",
    "image": "russmckendrick/nodejs",
    "export_path": "mobycounter.tar"
  }],
  "provisioners":[
    {
      "type": "file",
      "source": "app",
      "destination": "/srv"
    }, 
    {
      "type": "file",
      "source": "npmrc",
      "destination": "/etc/npmrc"
    },
    {
      "type": "shell",
      "inline": [
        "cd /srv/app",
        "npm install"
      ]
    }
  ]
}</pre></div><p>Again, all of the files required to build the image, along with the Docker Compose file to run it, are<a id="id359" class="indexterm"/> in the GitHub repository at <a class="ulink" href="https://github.com/russmckendrick/extending-docker/tree/master/chapter06/images/packer">https://github.com/russmckendrick/extending-docker/tree/master/chapter06/images/packer</a>.</p><p>Rather than <a id="id360" class="indexterm"/>using the Docker Compose file to build the<a id="id361" class="indexterm"/> image, we are going to have to run <strong>packer</strong> and then import the image file. To start the build, run the following command:</p><div><pre class="programlisting">
<strong>packer build docker.json</strong>
</pre></div><p>You should see the following in your terminal:</p><div><img src="img/B05468_06_19.jpg" alt="Building with Packer"/></div><p>Once Packer has <a id="id362" class="indexterm"/>built the image, it will save a copy to the folder <a id="id363" class="indexterm"/>you initiated the Packer build command from; in our case, the image file is called <code class="literal">mobycounter.tar</code>.</p><p>To import the image so that we can use it, run the following command:</p><div><pre class="programlisting">
<strong>docker import mobycounter.tar mobycounter</strong>
</pre></div><p>This will import the image and name it <code class="literal">mobycounter</code>; you can check whether the image is available by running this:</p><div><pre class="programlisting">
<strong>docker images</strong>
</pre></div><p>You should see something like this:</p><div><img src="img/B05468_06_20.jpg" alt="Building with Packer"/></div><p>Once you have <a id="id364" class="indexterm"/>confirmed the image has been imported and is <a id="id365" class="indexterm"/>called <code class="literal">mobycounter</code>, you can launch a container by running this:</p><div><pre class="programlisting">
<strong>docker-compose up -d</strong>
</pre></div><p>Again, you will be able to open your browser and start clicking around to place logos by running this:</p><div><pre class="programlisting">
<strong>open http://$(docker-machine ip chapter06)/</strong>
</pre></div><p>While there may not seem to be much difference, let's take a look at what's going on under the hood.</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec58"/>Packer versus Docker Build</h2></div></div></div><p>Before we go<a id="id366" class="indexterm"/> into detail about the difference between the two <a id="id367" class="indexterm"/>methods of building images, let's try running Packer again.</p><p>This time though, let's to try and reduce the image size: rather than using the <code class="literal">russmckendrick/nodejs</code> image, which has nodejs preinstalled, let's use the base image that this was built on, <code class="literal">russmckendrick/base</code>.</p><p>This image just has bash installed; install NodeJS and the application using Packer:</p><div><pre class="programlisting">{
  "builders":[{
    "type": "docker",
    "image": "russmckendrick/base",
    "export_path": "mobycounter-small.tar"
  }],
  "provisioners":[
    {
      "type": "file",
      "source": "app",
      "destination": "/srv"
    }, 
    {
      "type": "file",
      "source": "npmrc",
      "destination": "/etc/npmrc"
    }, 
    {
      "type": "shell",
      "inline": [
        "apk update",
        "apk add --update nodejs",
        "npm -g install npm",
        "cd /srv/app",
        "npm install",
        "rm -rf /var/cache/apk/**/",
        "npm cache clean"
      ]
    }
  ]
}</pre></div><p>As you can see, we have added a few more commands to the shell provisioner; these use Alpine Linux's package manager to perform an update, install nodejs, configure the application, and finally, clean both the apk and npm caches.</p><p>If you like, you can build the image using the following command:</p><div><pre class="programlisting">
<strong>packer build docker-small.json</strong>
</pre></div><p>This will leave us with two image files. I also exported a copy of the container we built using the <code class="literal">Dockerfile</code> using the following command while the container was running:</p><div><pre class="programlisting">
<strong>docker export docker_web_1 &gt; docker_web.tar</strong>
</pre></div><p>I now have<a id="id368" class="indexterm"/> three image files, and all three are running the<a id="id369" class="indexterm"/> same application, with the same software stack installed, using as close to the same commands as possible. As you can see from the following list of file sizes, there is a difference in the image size:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Dockerfile</strong> (using <code class="literal">russmckendrick/nodejs</code>) = 52 MB</li><li class="listitem" style="list-style-type: disc"><strong>Packer</strong> (using <code class="literal">russmckendrick/nodejs</code>) = 47 MB</li><li class="listitem" style="list-style-type: disc"><strong>Packer</strong> (installing the full stack using packer) = 40 MB</li></ul></div><p>12 MB may not seem like a lot, but when you are dealing with an image that is only 52 MB big, that's quite a decent saving.</p><p>So why is there a difference? Let's start by discussing the way in which Docker images work.</p><p>They are essentially made up of layers of changes on top of a base. When we built our first image using the <code class="literal">Dockerfile</code>, you may have noticed that each line of the <code class="literal">Dockerfile</code> generated a different step in the build process.</p><p>Each step is actually Docker starting a new filesystem layer to store the changes for that step of the build. So, for example, when our <code class="literal">Dockerfile</code> ran, we had six filesystem layers:</p><div><pre class="programlisting">FROM russmckendrick/nodejs
ADD . /srv/app
WORKDIR /srv/app
RUN npm install
EXPOSE 80
ENTRYPOINT ["node", "index.js"]</pre></div><p>The first layer contains the base operating system along with the layers on which NodeJS is installed, and the second layer contains the files for the application itself.</p><p>The third layer just contains the metadata for setting the <code class="literal">workdir</code> variable; next up, we have the layer that contains the NodeJS dependencies for the application. The fifth and sixth layers just contain the metadata needed to configure which ports are exposed and what the "entry point" is.</p><p>As each of these layers is effectively a separate archive within the image file, we also have the additional overhead of these archives within our image file.</p><p>A better example of how the layers work is to look at some of the most popular images from the Docker Hub in the <a id="id370" class="indexterm"/>ImageLayers website, which can be found at <a class="ulink" href="https://imagelayers.io/">https://imagelayers.io/</a>.</p><p>This site is a tool provided by <a id="id371" class="indexterm"/>Century Link Labs (<a class="ulink" href="https://labs.ctl.io/">https://labs.ctl.io/</a>) to visualize Docker images that have been built from a <code class="literal">Dockerfile</code>.</p><p>As you<a id="id372" class="indexterm"/> can see from the following screenshot, some of the <a id="id373" class="indexterm"/>official images are quite complex and also quite large:</p><div><img src="img/B05468_06_21.jpg" alt="Packer versus Docker Build"/></div><p>You can view the previous page at the following URL:</p><p>
<a class="ulink" href="https://imagelayers.io/?images=java:latest,golang:latest,node:latest,python:latest,php:latest,ruby:latest">https://imagelayers.io/?images=java:latest,golang:latest,node:latest,python:latest,php:latest,ruby:latest</a>.</p><p>Even while the official images should be getting smaller thanks to Docker hiring the creator of Alpine Linux and moving the official images over to the smaller base operating system (check out the following hacker news post for more information <a class="ulink" href="https://news.ycombinator.com/item?id=11000827">https://news.ycombinator.com/item?id=11000827</a>), it does not change the amount of layers required for each image. It's also worth pointing out that each image can have a maximum of 127 layers.</p><p>So what does<a id="id374" class="indexterm"/> Packer do differently? Rather than creating a<a id="id375" class="indexterm"/> separate filesystem layer for each step, it produces only two: the first layer is the base image you define, and the second one is everything else—this is where our space savings come in.</p><p>The other advantage of using Packer over Dockfiles is that you can reuse your scripts. Imagine you were doing your local development work using Docker but when you launched into production, you for one reason or another had to launch on one of the containerized virtual machines. Using Packer, you can do exactly that knowing that you could actually use the same set of build scripts to bootstrap your virtual machines as you did for your development containers.</p><p>As I have already mentioned, I have been using Packer for a while and it helps to no end to have a single tool that you can use to target different platforms with the same set of build scripts. The consistency this approach brings is well worth the initial effort of learning a tool such as Packer as you will end up saving a lot of time in the long run; it also helps with eliminating the whole "worked in development" meme we discussed at the start of <a class="link" href="ch01.html" title="Chapter 1. Introduction to Extending Docker">Chapter 1</a>, <em>Introduction to Extending Docker</em>.</p><p>There are some downsides to using this approach, which may put some people off.</p><p>The biggest one in my opinion is that while you are able to push the final image automatically to the Docker Hub, you will not be able to add it as an automated build.</p><p>This means that while it may be available for people to download, it might not be considered trusted as people cannot see exactly what has been added to the image.</p><p>Next up is the lack of support for metadata—functions that configure runtime options such as exposing ports and the command executed by default when the container launches are not currently supported.</p><p>While this can be seen as a drawback, it is easily overcome by defining what you would have defined in your <code class="literal">Dockerfile</code> in a Docker Compose file or passing the information directly using the <code class="literal">docker run</code> command.</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec59"/>Image summary</h2></div></div></div><p>So, to <a id="id376" class="indexterm"/>summarize, if you need to build not only container images but also target different platforms, then Packer is exactly the tool you are after. If it's just container images you need to build, then you may be better off sticking with the <code class="literal">Dockerfile</code> build.</p><p>Some of the other tools we have looked at in this chapter, such as Ansible and Puppet, also support building images by issuing a <code class="literal">docker build</code> command against a <code class="literal">Dockerfile</code>, so<a id="id377" class="indexterm"/> there are plenty of ways to build that into your workflow, which leads us to the next tool we are going be looking at: Jenkins.</p><p>Before we move on, let's quickly just double-check that you are not running any Docker hosts. To do this, run the following commands to check for any Docker hosts and then remove them:</p><div><pre class="programlisting">
<strong>docker-machine ls</strong>
<strong>docker-machine rm &lt;name-of-host&gt;</strong>
</pre></div><p>Don't forget to only remove hosts that you are using for following along with this book; don't remove any you are using for you own projects!</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec34"/>Serving up Docker with Jenkins</h1></div></div></div><p>Jenkins is quite a <a id="id378" class="indexterm"/>big topic to cover in a small section of a single chapter, so the <a id="id379" class="indexterm"/>walkthrough is going to be really basic and will only deal with building and launching containers.</p><p>The other thing to note is that I am going to be covering Jenkins 2.0; at the time of writing this, the first beta has just been released, which means that while things may change slightly as themes and such are refined, all of the features and basic functionality are locked in.</p><p>The reason for covering Jenkins 2.0 rather than the Jenkins 1.x branch is that as far as Jenkins is concerned, Docker is now a first-class citizen, meaning that it fully supports and embraces the Docker way of working. A full overview of the current status of Jenkins 2.0<a id="id380" class="indexterm"/> can be found at <a class="ulink" href="https://jenkins.io/2.0/">https://jenkins.io/2.0/</a>.</p><p>So what is Jenkins? Jenkins is an open source continuous integration tool written in Java, and it has a lot of uses.</p><p>Personally, I am really late to the Jenkins party; being from an operations background, I have always just shrugged it off a tool used for running unit tests on code; however, as I have moved more into orchestration and automation, I am finding the need for a tool that can run tasks based on the results of unit tests.</p><p>As I have already mentioned, I am not going to go into much detail about the testing side of Jenkins; there are plenty of resources that cover this functionality, such as the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>Mastering Jenkins</em> by Jonathan McAllister</li><li class="listitem" style="list-style-type: disc"><em>Jenkins </em><a id="id381" class="indexterm"/><em>Continuous Integration Cookbook</em> by Alan Mark Berg</li></ul></div><p>These are both <a id="id382" class="indexterm"/>available from <a class="ulink" href="https://www.packtpub.com/">https://www.packtpub.com/</a>.</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec60"/>Preparing the environment</h2></div></div></div><p>Rather than<a id="id383" class="indexterm"/> running it locally, let's launch a DigitalOcean droplet and install Jenkins there. First off, we need to use Docker Machine to launch the droplet:</p><div><pre class="programlisting">
<strong>docker-machine create \</strong>
<strong>    --driver digitalocean \</strong>
<strong>    --digitalocean-access-token sdnjkjdfgkjb345kjdgljknqwetkjwhgoih314rjkwergoiyu34rjkherglkhrg0 \</strong>
<strong>    --digitalocean-region lon1 \</strong>
<strong>    --digitalocean-size 1gb \</strong>
<strong>    jenkins</strong>
</pre></div><p>Once the droplet has been launched, we don't need to bother configuring our local Docker client to talk on the droplet by running the Docker engine as Jenkins will be handling everything to do with Docker.</p><p>Because we need Jenkins to run Docker, we will need to install it directly on our droplet rather than run it as a container; first of all, we will need to SSH onto the droplet. To do this, run the following command:</p><div><pre class="programlisting">
<strong>docker-machine ssh jenkins</strong>
</pre></div><p>Now, on the droplet, we need to install Docker Compose, Jenkins, and all of its prerequisites. Let's start<a id="id384" class="indexterm"/> by installing Docker Compose. I have written a quick script to do this, which can be executed by running the following command:</p><div><pre class="programlisting">
<strong>curl -fsS https://raw.githubusercontent.com/russmckendrick/docker-install/master/install-compose | bash</strong>
</pre></div><p>Now that we have Docker Compose installed, it's time to install Jenkins. As version 2 is currently in beta, it is not in any of the main repositories yet; however, there is a DEB package for it.</p><p>To install it, we need to download a local copy and run the following commands:</p><div><pre class="programlisting">
<strong>apt-get install gdebi-core</strong>
</pre></div><p>This will install the <code class="literal">gdebi</code> tool, which we will then use to install Jenkins and its dependencies:</p><div><pre class="programlisting">
<strong>wget http://pkg.jenkins-ci.org/debian-rc/binary/jenkins_2.0_all.deb</strong>
<strong>gdebi jenkins_2.0_all.deb</strong>
</pre></div><p>Now that Jenkins is installed, we need to add the Jenkins user to the Docker group so that the user has permissions to interact with Docker:</p><div><pre class="programlisting">
<strong>usermod -aG docker jenkins</strong>
</pre></div><p>Finally, to<a id="id385" class="indexterm"/> ensure that Jenkins picks up that it has been added to the group, we need to restart it using this command:</p><div><pre class="programlisting">
<strong>/etc/init.d/jenkins restart</strong>
</pre></div><p>You can now open your browser to complete the installation:</p><div><pre class="programlisting">
<strong>open http://$(docker-machine ip jenkins):8080/</strong>
</pre></div><p>When your browser opens, you should be greeted with a screen that looks like the following:</p><div><img src="img/B05468_06_23.jpg" alt="Preparing the environment"/></div><p>For security reasons, when the Jenkins container was launched, a random string was generated; before you can proceed with the installation, Jenkins requires you to confirm what this string is. You can find it out by running this command:</p><div><pre class="programlisting">
<strong>less /var/lib/jenkins/secrets/initialAdminPassword</strong>
</pre></div><p>You can quit <code class="literal">less</code> by pressing the <em>Q</em> key.</p><p>This feature is a most welcome one as not securing your Jenkins installation correctly from the start can have quite bad implications, as I found out when a third party hijacked a test Jenkins 1.x installation I had up running and forgotten about—whoops!</p><p>Once you<a id="id386" class="indexterm"/> have entered the initial admin password, click on the <strong>Continue</strong> button.</p><p>The next page you come to will ask you which plugins you would like to install:</p><div><img src="img/B05468_06_24.jpg" alt="Preparing the environment"/></div><p>For our purposes, just click on <strong>Install suggested Plugins</strong>, which is highlighted. The next page will show you the progress of the suggested plugins:</p><div><img src="img/B05468_06_25.jpg" alt="Preparing the environment"/></div><p>It will take a<a id="id387" class="indexterm"/> minute or two to complete. Once it has completed, you will be asked to create a Jenkins user:</p><div><img src="img/B05468_06_26.jpg" alt="Preparing the environment"/></div><p>As I have already mentioned, it's important to secure your Jenkins installation from the start, so I recommend you don't skip this step. Once you have filled in the requested information, click <a id="id388" class="indexterm"/>on the <strong>Save and Finish</strong> button. If all has gone well, you will be presented with the following screen:</p><div><img src="img/B05468_06_27.jpg" alt="Preparing the environment"/></div><p>All you have to do now is click on <strong>Start using Jenkins</strong> and you will be logged in and taken to the start screen, which looks like this:</p><div><img src="img/B05468_06_28.jpg" alt="Preparing the environment"/></div><p>This installation <a id="id389" class="indexterm"/>process is one of the many improvements that Jenkins 2 brings to the table; earlier, you would have had to install Jenkins and then manually work through several wizards and procedures to both secure and configure the software, which as I have already mentioned can have bad consequences if you don't get it right.</p><p>The final step of the setup is to install the CloudBees Docker Pipeline plugin; to do this, click on the <strong>Manage Jenkins</strong> button from the left-hand side menu, and then click on <strong>Manage Plugins</strong> button.</p><p>As this is a new installation, you will probably see a message about plugins being updated at some point. Ignore the request to restart Jenkins; we will be doing this as part of the installation.</p><p>There are four tabs on the main screen; click on <strong>Available</strong> button and you will be presented with a list of all of the Jenkins plugins.</p><p>In the top right-hand portion of the main screen, there is a search box labelled <strong>Filter</strong>. Type in <code class="literal">Docker Pipeline</code> here, and you should receive one result. Tick the install box and then click on the <strong>Download now and install after restart</strong> button.</p><div><img src="img/B05468_06_29.jpg" alt="Preparing the environment"/></div><p>It will take <a id="id390" class="indexterm"/>a minute or two to restart Jenkins; after it has started back up, you will be prompted to log back in using the credentials you provided during the installation.</p><p>Now that you have Jenkins installed and configured, it's time to add our pipeline. To do this, we need an application to add.</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec61"/>Creating an application</h2></div></div></div><p>There is a <a id="id391" class="indexterm"/>sample application based on Moby Counter available at the following GitHub repository: <code class="literal">https://github.com/russmckendrick/jenkins-docker-example/tree/master</code>. The main page looks like this:</p><div><img src="img/B05468_06_30.jpg" alt="Creating an application"/></div><p>Before we<a id="id392" class="indexterm"/> add the application, it is best that you fork the code, as we will be making changes to the codebase later on. To do this, click on the <strong>Fork</strong> button in the top right of the screen. You will be asked where you want to fork the repository. Once you have forked it, make a note of the URL.</p><p>As I own the repository, I was not able to fork it. Because of this, I have created a copy called <code class="literal">jenkins-pipeline</code>, so you will see references to this in the following section.</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec62"/>Creating a pipeline</h2></div></div></div><p>Now that<a id="id393" class="indexterm"/> Jenkins is configured and we have a GitHub repository that contains the application, we would like to deploy. It's time to roll our sleeves up and configure the pipeline within Jenkins.</p><p>To start, click on the <strong>create new jobs</strong> button on the main page, you will be taken to a screen that has several options on it, enter the name of the pipeline in the top box.</p><p>I am calling mine <code class="literal">Docker Pipeline</code>, and then click on <strong>Pipeline</strong> button. You should see a small box that says <strong>OK</strong> button at the bottom of the screen, click on the <strong>OK</strong> button to create the pipeline, which will take you to the configuration screen:</p><div><img src="img/B05468_06_31.jpg" alt="Creating a pipeline"/></div><p>You will now be<a id="id394" class="indexterm"/> on the pipeline configuration screen, as you can see, there are a lot of options. We are going to be keeping things really simple and will be just adding a pipeline script. The script looks similar to the following code:</p><div><pre class="programlisting">node {
  stage 'Checkout'
  git url: 'https://github.com/russmckendrick/jenkins-pipeline.git'

  stage 'build'
  docker.build('mobycounter')

  stage 'deploy'
  sh './deploy.sh'
}</pre></div><p>Before you add the script to the Pipeline section of the configuration page, replace the Git URL with the one of your own repository. Leave all the other options as they are and click on the <strong>Save</strong> button:</p><div><img src="img/B05468_06_32.jpg" alt="Creating a pipeline"/></div><p>That's it, our <a id="id395" class="indexterm"/>pipeline is now configured. We have told Jenkins to perform the following three tasks each time a build is triggered:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Checkout</strong>: This downloads the latest code for our application from your GitHub repository.</li><li class="listitem" style="list-style-type: disc"><strong>Build</strong>: This uses <code class="literal">Dockerfile</code> that is in the GitHub repository to build the <code class="literal">Mobycounter</code> image.</li><li class="listitem" style="list-style-type: disc"><strong>Deploy</strong>: This runs a script that clears down any currently running containers and then uses the included Docker Compose file to relaunch the application. When launching Redis, the Docker Compose file uses the built-in volume driver for <code class="literal">/data</code>, meaning that the position of the Docker logos will persist between the containers being relaunched.</li></ul></div><p>To trigger a build, click on the <strong>Build Now</strong> button option on the left-hand side menu. If everything goes well, you should see something similar to the following screenshot:</p><div><img src="img/B05468_06_33.jpg" alt="Creating a pipeline"/></div><p>As you can <a id="id396" class="indexterm"/>see, all three tasks are executed without error. You should be able to see the application by opening your browser using the following command:</p><div><pre class="programlisting">
<strong>open http://$(docker-machine ip jenkins)/</strong>
</pre></div><p>Place some logos to test that everything is working as expected, and that's it, you have deployed your application using Jenkins:</p><div><img src="img/B05468_06_34.jpg" alt="Creating a pipeline"/></div><p>Hold on a <a id="id397" class="indexterm"/>minute—there is a problem! As you may have already noticed, the page title is wrong.</p><p>Let's go ahead and fix that. To do so, navigate to the following page in your GitHub repository: <code class="literal">your-github-repo</code> | <code class="literal">src</code> | <code class="literal">client</code> | <code class="literal">index.html</code>. From here, click on the <strong>Edit</strong> button. Once in the editing screen, update the title between the <code class="literal">&lt;title&gt;</code> and <code class="literal">&lt;/title&gt;</code> tags, and then click on the <strong>Commit changes</strong> button.</p><div><img src="img/B05468_06_35.jpg" alt="Creating a pipeline"/></div><p>Now that you<a id="id398" class="indexterm"/> have updated your application code, go back to Jenkins and click on <strong>Build Now</strong> again. This will trigger a second build, which will deploy the changes we made in GitHub.</p><div><img src="img/B05468_06_36.jpg" alt="Creating a pipeline"/></div><p>As you can see <a id="id399" class="indexterm"/>from the second browser tag in the previous screenshot, the title of our application has changed and the second build was successful. If you refresh your application window, you should see that your title has been updated and the Docker logos are where you left them.</p><p>A few other things to note are that that the second build confirms that there is one commit difference between our initial build and the current one. Also, the build itself took less time than our original build; this is because Docker didn't have to download the base image for a second time.</p><p>You can view logs for each task by hovering your mouse over the stage you want to see the logs for and clicking on the <strong>Logs</strong> link. This will make a dialog pop up with the logs for the task:</p><div><img src="img/B05468_06_37.jpg" alt="Creating a pipeline"/></div><p>You can also look <a id="id400" class="indexterm"/>at the full console output for each build by clicking on the build number, say <code class="literal">#2</code>, in the left-hand side menu and then clicking on the <strong>Console Output</strong> button:</p><div><img src="img/B05468_06_38.jpg" alt="Creating a pipeline"/></div><p>This is useful if<a id="id401" class="indexterm"/> your build has errors. Try clicking on some of the options, such as <strong>Docker Fingerprints</strong> and <strong>Changes</strong>, to look at the other information that is recorded during each build.</p><p>Going back to the main Jenkins page, you should see a quick summary of your builds. You should also see a sun icon next to your pipeline, meaning that everything is OK.</p><div><img src="img/B05468_06_39.jpg" alt="Creating a pipeline"/></div><p>What if everything wasn't okay with the second build? Consider that we had made a syntax error <a id="id402" class="indexterm"/>within the Dockerfile when we edited the page title, what would have happened?</p><p>Jenkins would have checked the update files from GitHub, started the build of the updated image, detected the error, and then failed. As this stage would have given an error, the deploy stage would not have been executed, meaning that our application would still be running in its current state, wrong title and all.</p><p>This is where Jenkins' strength lies, if you configure enough tests with both your code and deployment pipelines, you can stop any potential service affecting changes being deployed, it also records enough information to be an extremely valuable resource when it comes to tracking down errors.</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec63"/>Summing up Jenkins</h2></div></div></div><p>As you may have noticed, we have only touched the tip of the iceberg when it comes to Jenkins, there is<a id="id403" class="indexterm"/> a lot of functionality we haven't covered as it is out of scope of this book.</p><p>However, from the little we have discussed, I hope you can see the value of using a continuous integration and deployment platform such as Jenkins to help build and deploy your containers and code. Don't be late to the party like I was, if you deploy any type of code, then consider using Jenkins to assist you, don't wait until you have deployed a serious application-breaking bug.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec35"/>Summary</h1></div></div></div><p>A common thread among all the tools we have looked at in this chapter is that they all quickly evolved to offer support for Docker, filling in gaps in functionality, which was missing from the core Docker toolset.</p><p>Over the past 12 months, the rapid development of Docker has meant that some of these tools may not necessarily be required any more.</p><p>However, as they all provide a wide range of functionality outside of Docker, it means that they can still be a valuable part of your day-to-day workflow should Docker only be one of the technologies you are working with.</p><p>There is one thing using that the tools in this chapter does not provide and that's some intelligence around where your containers are launched, you still have to instruct the tools to <em>place container A on Docker host Z</em>.</p><p>In our next chapter, we will be looking at schedulers that make the decision as to where a container should be launched for you, based on host availability, utilization, and other rules such as <em>don't place Container A on the same host as Container B</em>, meaning that you are no longer confined to a fixed infrastructure.</p></div></body></html>