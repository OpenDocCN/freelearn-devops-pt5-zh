<html><head></head><body>
  
    
      <h1>Orchestrating Containers</h1>
    

    
      <p>In the earlier chapters, we laid down a strong foundation on the need for container networking, how to run a service inside a Docker container, and how to expose this service to the outside world by opening up network ports and other prerequisites. However, recently, there are advanced mechanisms being made available and a few third-party orchestration platforms hitting the market for sagaciously establishing dynamic and decisive linkages between distributed and differently-enabled containers in order to compose powerful containers for comprehensively, yet compactly containing process-centric, multi-tiered, and enterprise-class distributed applications. In the extremely diversified yet connected world, the concept of orchestration cannot be kept away from the deserved prominence for long. This chapter is precisely allocated for explaining the nitty-gritty of container orchestration, and its direct role is in picking up discrete containers to systematically compose sophisticated containers that are more directly aligned with the varying business expectations and expediencies.</p>

      <p>In this chapter, we will discuss the following topics in detail:</p>

      <ul>
        <li>Linking containers</li>

        <li>Orchestrating containers</li>

        <li>Orchestrating containers using the <code>docker-compose</code> tool</li>
      </ul>

      <p>As mission-critical applications are overwhelmingly being built through loosely coupled, yet highly cohesive components/services destined to run on geographically-distributed IT infrastructures and platforms, the concept of composition is getting a lot of attention and attraction. For sustaining the well-begun containerization journey, the orchestration of containers is being prescribed as one of the most critical and crucial requirements in the ensuing, instant-on, adaptive, and smart IT era. There are a few proven and promising methods and standards-compliant tools for enabling the enigmatic orchestration goals.</p>
    
  

  
    
      <h2 id="sigil_toc_id_115">Docker inbuilt service discovery</h2>
    

    
      <p>The Docker platform inherently supports the service discovery for the containers that are attached to any user-defined network using an embedded <strong>Domain Name Service</strong> (<strong>DNS</strong>). This functionality has been added to Docker since the version <code>1.10</code>. The embedded DNS feature enables the Docker containers to discover each other using their names or aliases within the user-defined network. In other words, the name resolution request from the container is first sent to the embedded DNS. The user-defined network then uses a special <code>127.0.0.11</code> IP address for the embedded DNS, which is also listed in <code>/etc/resolv.conf</code>.</p>

      <p>The following example will help to gain a better understanding of Docker's built-in service discovery capability:</p>

      <ol>
        <li>Let's begin by creating a user-defined bridge network, <code>mybridge</code>, using the following command:</li>
      </ol>

      <pre>      <strong>$ sudo docker network create mybridge</strong>
</pre>

      <ol start="2">
        <li>Inspect the newly created network to understand the subnet range and gateway IP:</li>
      </ol>

      <pre><strong> $ sudo docker network inspect mybridge</strong><br/><strong> [</strong><br/><strong> {</strong><br/><strong> "Name": "mybridge",</strong><br/><strong> "Id": "36e5e088543895f6d335eb92299ee8e118cd0610e0d023f7c42e6e603b935e17",</strong><br/><strong> "Created": </strong><br/><strong> "2017-02-12T14:56:48.553408611Z",</strong><br/><strong> "Scope": "local",</strong><br/><strong> "Driver": "bridge",</strong><br/><strong> "EnableIPv6": false,</strong><br/><strong> "IPAM": {</strong><br/><strong> "Driver": "default",</strong><br/><strong> "Options": {},</strong><br/><strong> "Config": [</strong><br/><strong> {</strong><br/><strong> "Subnet": "172.18.0.0/16",</strong><br/><strong> "Gateway": "172.18.0.1"</strong><br/><strong> }</strong><br/><strong> ]</strong><br/><strong> },</strong><br/><strong> "Internal": false,</strong><br/><strong> "Attachable": false,</strong><br/><strong> "Containers": {},</strong><br/><strong> "Options": {},</strong><br/><strong> "Labels": {}</strong><br/><strong> }</strong><br/><strong> ]</strong>
</pre>

      <p style="padding-left: 60px">Here, the subnet assigned to the <code>mybridge</code> network is <code>172.18.0.0/16</code> and the gateway is <code>172.18.0.1</code>.</p>

      <ol start="3">
        <li>Now, let's create a container by attaching it to the <code>mybridge</code> network, as shown here:</li>
      </ol>

      <pre>      <strong>$ sudo docker container run \</strong><br/><strong> -itd --net mybridge --name testdns ubuntu</strong>  
</pre>

      <ol start="4">
        <li>Continue to list the IP address assigned to the container, as illustrated here:</li>
      </ol>

      <pre><strong> $ sudo docker container inspect </strong><strong>--format \</strong><br/><strong> '{{.NetworkSettings.Networks.mybridge.IPAddress}}' \</strong><br/><strong> testdns </strong><br/><strong> 172.18.0.2</strong>
</pre>

      <ol start="4"/>

      <p style="padding-left: 60px">Evidently, the <code>testdns</code> container is assigned a <code>172.18.0.2</code> IP address. The <code>172.18.0.2</code> IP address is from the subnet of the <code>mybridge</code> network (that is, <code>172.18.0.0/16</code>).</p>

      <ol start="5">
        <li>Having got the IP address of the container, let's look into the content of the <code>/etc/resolv.conf</code>  file of the container using the <code>docker container exec</code> subcommand, as shown here:</li>
      </ol>

      <pre><strong> $ sudo docker container exec testdns \</strong><br/><strong> cat /etc/resolv.conf </strong><br/><strong> nameserver 127.0.0.11</strong><br/><strong> options ndots:0</strong>
</pre>

      <p style="padding-left: 60px">Here the <code>nameserver</code> is configured as <code>127.0.0.11</code>, which is the IP address of the embedded DNS.</p>

      <ol start="6">
        <li>As a final step, let's ping the <code>testdns</code> container using the <code>busybox</code> image. We picked the <code>busybox</code> image here because the <code>ubuntu</code> image is shipped without the <code>ping</code> command:</li>
      </ol>

      <pre><strong> $ sudo docker container run --rm --net mybridge \ </strong><br/><strong> busybox ping -c 2 testdns</strong><br/><strong> PING testdns (172.18.0.2): 56 data bytes</strong><br/><strong> 64 bytes from 172.18.0.2: seq=0 ttl=64 </strong><br/><strong> time=0.085 ms</strong><br/><strong> 64 bytes from 172.18.0.2: seq=1 ttl=64 </strong><br/><strong> time=0.133 ms</strong><br/><br/><strong> --- testdns ping statistics ---</strong><br/><strong> 2 packets transmitted, 2 packets received, </strong><br/><strong> 0% packet loss</strong><br/><strong> round-trip min/avg/max = 0.085/0.109/0.133 ms</strong>
</pre>

      <p>Awesome, isn't it! The folks behind Docker have made it so simple that with no effort we are able to discover the containers in the same network.</p>
    
  

  
    
      <h2 id="sigil_toc_id_116">Linking containers</h2>
    

    
      <p>Before the introduction of the concept of the user-defined network, container linking was predominantly used for inter-container discovery and communication. That is, cooperating containers can be linked together to offer complex and business-aware services. The linked containers have a kind of source-recipient relationship, wherein the source container gets linked to the recipient container, and the recipient securely receives a variety of information from the source container. However, the source container will know nothing about the recipients to which it is linked. Another noteworthy feature of linking containers in a secured setup is that the linked containers can communicate using secure tunnels without exposing the ports used for the setup to the external world. Though you will find lots of deployments that use container-linking techniques, they are cumbersome and time-consuming to configure. Also, they are error-prone. So the new method of embedded DNS is highly preferred over the traditional container-linking techniques.</p>

      <p>The Docker Engine provides the <code>--link</code> option in the <code>docker run</code> subcommand to link a source container to a recipient container.</p>

      <p>The format of the <code>--link</code> option is as follows:</p>

      <pre><strong>--link &lt;container&gt;:&lt;alias&gt;</strong>
</pre>

      <p>Here, <code>&lt;container&gt;</code> is the name of the source container and <code>&lt;alias&gt;</code> is the name seen by the recipient container. The name of the container must be unique in a Docker host, whereas alias is very specific and local to the recipient container, and hence, the alias need not be unique in the Docker host. This gives a lot of flexibility to implement and incorporate functionalities with a fixed source alias name inside the recipient container.</p>

      <p>When two containers are linked together, the Docker Engine automatically exports a few environment variables to the recipient container. These environment variables have a well-defined naming convention, where the variables are always prefixed with the capitalized form of the alias name. For instance, if <code>src</code> is the alias name given to the source container, then the exported environment variables will begin with <code>SRC_</code>. Docker exports three categories of environment variables, as enumerated here:</p>

      <ul>
        <li><code>NAME</code>: This is the first category of environment variables. These variables take the form of <code>&lt;ALIAS&gt;_NAME</code>, and they carry the recipient container's hierarchical name as their value. For instance, if the source container's alias is <code>src</code> and the recipient container's name is <code>rec</code>, then the environment variable and its value will be <code>SRC_NAME=/rec/src</code>.</li>

        <li><code>ENV</code>: This is the second category of environment variables used to export the environment variables configured in the source container by the <code>-e</code> option of the <code>docker run</code> subcommand or the <code>ENV</code> instruction of the <code>Dockerfile</code>. This type of an environment variable takes the form of <code>&lt;ALIAS&gt;_ENV_&lt;VAR_NAME&gt;</code>. For instance, if the source container's alias is <code>src</code> and the variable name is <code>SAMPLE</code>, then the environment variable will be <code>SRC_ENV_SAMPLE</code>.</li>

        <li><code>PORT</code>: This is the final and third category of environment variables that is used to export the connectivity details of the source container to the recipient. Docker creates a bunch of variables for each port exposed by the source container through the <code>-p</code> option of the <code>docker run</code> subcommand or the <code>EXPOSE</code> instruction of the <code>Dockerfile</code>.</li>
      </ul>

      <p style="padding-left: 60px">These variables take the <code>&lt;ALIAS&gt;_PORT_&lt;port&gt;_&lt;protocol&gt;</code> form. This form is used to share the source's IP address, port, and protocol as a URL. For example, if the source container's alias is <code>src</code>, the exposed port is <code>8080</code>, the protocol is <code>tcp</code>, and the IP address is <code>172.17.0.2</code>, then the environment variable and its value will be <code>SRC_PORT_8080_TCP=tcp://172.17.0.2:8080</code>. This URL further splits into the following three environment variables:</p>

      <div><ul>
          <li><code>&lt;ALIAS&gt;_PORT_&lt;port&gt;_&lt;protocol&gt;_ADDR</code>: This form carries the IP address part of the URL (for example, <code>SRC_PORT_8080_TCP_ADDR= 172.17.0.2</code>)</li>

          <li><code>&lt;ALIAS&gt;_PORT_&lt;port&gt;_&lt;protocol&gt;_PORT</code>: This form carries the port part of the URL (for example, <code>SRC_PORT_8080_TCP_PORT=8080</code>)</li>

          <li><code>&lt;ALIAS&gt;_PORT_&lt;port&gt;_&lt;protocol&gt;_PROTO</code>: This form carries the protocol part of the URL (for example, <code>SRC_PORT_8080_TCP_PROTO=tcp</code>)</li>
        </ul>
      </div>

      <p>In addition to the preceding environment variables, the Docker Engine exports one more variable in this category, that is, of the <code>&lt;ALIAS&gt;_PORT</code> form, and its value will be the URL of the lowest number of all the exposed ports of the source container. For instance, if the source container's alias is <code>src</code>, the exposed port numbers are <code>7070</code>, <code>8080</code>, and <code>80</code>, the protocol is <code>tcp</code>, and the IP address is <code>172.17.0.2</code>, then the environment variable and its value will be <code>SRC_PORT=tcp://172.17.0.2:80</code>.</p>

      <p>Docker exports these autogenerated environment variables in a well-structured format so that they can be easily discovered programmatically. Thus, it becomes very easy for the recipient container to discover the information about the source container. In addition, Docker automatically updates the source IP address and its alias as an entry in the <code>/etc/hosts</code> file of the recipient.</p>

      <p>In this chapter, we will dive deep into the mentioned features provided by the Docker Engine for container linkage through a bevy of pragmatic examples.</p>

      <p>To start with, let's choose a simple container linking example. Here, we will show you how to establish a linkage between two containers, and transfer some basic information from the source container to the recipient container, as illustrated in the following steps:</p>

      <ol>
        <li>We begin with launching an interactive container that can be used as a source container for linking, using the following command:</li>
      </ol>

      <pre>      <strong>$ sudo docker run --rm --name example -it \<br/> busybox:latest</strong>
</pre>

      <p style="padding-left: 60px">The container is named <code>example</code> using the <code>--name</code> option. In addition, the <code>--rm</code> option is used to clean up the container as soon as you exit from the container.</p>

      <ol start="2">
        <li>Display the <code>/etc/hosts</code> entry of the source container using the <code>cat</code> command:</li>
      </ol>

      <pre><strong> / # cat /etc/hosts</strong><br/><strong> 172.17.0.3 a02895551686</strong><br/><strong> 127.0.0.1 localhost</strong><br/><strong> ::1 localhost ip6-localhost ip6-loopback</strong><br/><strong> fe00::0 ip6-localnet</strong><br/><strong> ff00::0 ip6-mcastprefix</strong><br/><strong> ff02::1 ip6-allnodes</strong><br/><strong> ff02::2 ip6-allrouters</strong>
</pre>

      <p style="padding-left: 60px">Here, the first entry in the <code>/etc/hosts</code> file is the source container's IP address (<code>172.17.0.3</code>) and its hostname (<code>a02895551686</code>).</p>

      <ol start="3">
        <li>We will continue to display the environment variables of the source container using the <code>env</code> command:</li>
      </ol>

      <pre><strong> / # env</strong><br/><strong> HOSTNAME=a02895551686</strong><br/><strong> SHLVL=1</strong><br/><strong> HOME=/root</strong><br/><strong> TERM=xterm</strong><br/><strong> PATH=</strong><br/><strong> /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</strong><br/><strong> PWD=/</strong>
</pre>

      <ol start="4">
        <li>We have now launched the source container. From another Terminal of the same Docker host, let's launch the interactive recipient container by linking it to our source container using the <code>--link</code> option of the <code>docker run</code> subcommand, as shown here:</li>
      </ol>

      <pre>      <strong>$ sudo docker run --rm --link example:ex \ <br/> -it busybox:latest</strong> 
</pre>

      <p style="padding-left: 60px">Here, the source container named <code>example</code> is linked to the recipient container with <code>ex</code> as its alias.</p>

      <ol start="5">
        <li>Let's display the content of the <code>/etc/hosts</code> file of the recipient container using the <code>cat</code> command:</li>
      </ol>

      <pre><strong> / # cat /etc/hosts</strong><br/><strong> 172.17.0.4 a17e5578b98e</strong><br/><strong> 127.0.0.1 localhost</strong><br/><strong> ::1 localhost ip6-localhost ip6-loopback</strong><br/><strong> fe00::0 ip6-localnet</strong><br/><strong> ff00::0 ip6-mcastprefix</strong><br/><strong> ff02::1 ip6-allnodes</strong><br/><strong> ff02::2 ip6-allrouters</strong><br/><strong> 72.17.0.3 ex</strong>
</pre>

      <p style="padding-left: 60px">Of course, as always, the first entry in the <code>/etc/hosts</code> file is the IP address of the container and its hostname. However, the noteworthy entry in the <code>/etc/hosts</code> file is the last entry, where the IP address (<code>172.17.0.3</code>) of the source container and its alias (<code>ex</code>) are added automatically.</p>

      <ol start="6">
        <li>We will continue to display the recipient container's environment variable using the <code>env</code> command:</li>
      </ol>

      <pre><strong> / # env</strong><br/><strong> HOSTNAME=a17e5578b98e</strong><br/><strong> SHLVL=1</strong><br/><strong> HOME=/root</strong><br/><strong> EX_NAME=/berserk_mcclintock/ex</strong><br/><strong> TERM=xterm</strong><br/><strong> PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</strong><br/><strong> PWD=/</strong>
</pre>

      <p style="padding-left: 60px">Apparently, a new <code>EX_NAME</code> environment variable is added automatically to <code>/berserk_mcclintock/ex</code>, as its value. Here <code>EX</code> is the capitalized form of the alias <code>ex</code> and <code>berserk_mcclintock</code> is the autogenerated name of the recipient container.</p>

      <ol start="7">
        <li>As a final step, ping the source container using the widely used <code>ping</code> command for two counts and use the alias name as the ping address:</li>
      </ol>

      <pre><strong> / # ping -c 2 ex</strong><br/><strong> PING ex (172.17.0.3): 56 data bytes</strong><br/><strong> 64 bytes from 172.17.0.3: seq=0 ttl=64 </strong><br/><strong> time=0.108 ms</strong><br/><strong> 64 bytes from 172.17.0.3: seq=1 ttl=64 </strong><br/><strong> time=0.079 ms</strong><br/><br/><strong> --- ex ping statistics ---</strong><br/><strong> 2 packets transmitted, 2 packets received, </strong><br/><strong> 0% packet loss</strong><br/><strong> round-trip min/avg/max = 0.079/0.093/0.108 ms</strong>
</pre>

      <p>Evidently, the alias <code>ex</code> of the source container is resolved to the <code>172.17.0.3</code> IP address, and the recipient container is able to successfully reach the source. In the case of secured container communication, pinging between containers is not allowed. We will see more details on the aspect of securing containers in <a href="../Text/Ch11.xhtml">Chapter 11</a>, <em>Securing Docker Containers</em>.</p>

      <p>In the preceding example, we can link two containers together, and also, observe how elegantly networking is enabled between the containers by updating the IP address of the source container in the <code>/etc/hosts</code> file of the recipient container.</p>

      <p>The next example is to demonstrate how container linking exports the environment variables of the source container, which are configured using the <code>-e</code> option of the <code>docker run</code> subcommand or the <code>ENV</code> instruction of <code>Dockerfile</code>, to the recipient container. For this purpose, we are going to craft a file named <code>Dockerfile</code> with the <code>ENV</code> instruction, build an image, launch a source container using this image, and then launch a recipient container by linking it to the source container:</p>

      <ol>
        <li>We begin with composing a <code>Dockerfile</code> with the <code>ENV</code> instruction, as shown here:</li>
      </ol>

      <pre>      FROM busybox:latest <br/>      ENV BOOK="Learning Docker"  \<br/>          CHAPTER="Orchestrating Containers" 
</pre>

      <p style="padding-left: 60px">Here, we are setting up two environment variables, <code>BOOK</code> and <code>CHAPTER</code>.</p>

      <ol start="2">
        <li>Proceed to build a Docker image <code>envex</code> using the <code>docker build</code> subcommand from the preceding <code>Dockerfile</code>:</li>
      </ol>

      <pre>      <strong>$ sudo docker build -t envex .</strong>
</pre>

      <ol start="3">
        <li>Now, let's launch an interactive source container with the <code>example</code> name using the <code>envex</code> image we just built:</li>
      </ol>

      <pre>      <strong>$ sudo docker run -it --rm \</strong><br/><strong> --name example envex</strong>
</pre>

      <ol start="4">
        <li>From the source container prompt, display all the environment variables by invoking the <code>env</code> command:</li>
      </ol>

      <pre><strong> / # env</strong><br/><strong> HOSTNAME=b53bc036725c</strong><br/><strong> SHLVL=1</strong><br/><strong> HOME=/root</strong><br/><strong> TERM=xterm</strong><br/><strong> PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</strong><br/><strong> BOOK=Learning Docker</strong><br/><strong> CHAPTER=Orchestrating Containers</strong><br/><strong> PWD=/</strong>
</pre>

      <p style="padding-left: 60px">In all the preceding environment variables, both the <code>BOOK</code> and the <code>CHAPTER</code> variables are configured with the <code>ENV</code> instruction of the <code>Dockerfile</code>.</p>

      <ol start="5">
        <li>As a final step, to illustrate the <code>ENV</code> category of environment variables, launch the recipient container with the <code>env</code> command, as shown here:</li>
      </ol>

      <pre><strong> $ sudo docker run --rm --link example:ex \</strong><br/><strong> busybox:latest env</strong><br/><strong> PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</strong><br/><strong> HOSTNAME=a5e0c07fd643</strong><br/><strong> TERM=xterm</strong><br/><strong> EX_NAME=/stoic_hawking/ex</strong><br/><strong> EX_ENV_BOOK=Learning Docker</strong><br/><strong> EX_ENV_CHAPTER=Orchestrating Containers</strong><br/><strong> HOME=/root</strong>
</pre>

      <p>This example is also available on GitHub at <a href="https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Env">https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Env</a>.
      </p>

      <p>Strikingly, in the preceding output, the variables that are prefixed with <code>EX_</code> are the outcome of container linking. The environment variables of our interest are <code>EX_ENV_BOOK</code> and <code>EX_ENV_CHAPTER</code>, which were originally set through the <code>Dockerfile</code> as <code>BOOK</code> and <code>CHAPTER</code> but modified to <code>EX_ENV_BOOK</code> and <code>EX_ENV_CHAPTER</code>, as an effect of container linking. Though the environment variable names get translated, the values stored in these environment variables are preserved as is. We already discussed the <code>EX_NAME</code> variable name in the previous example.</p>

      <p>In the preceding example, we experienced how elegantly and effortlessly Docker exports the <code>ENV</code> category variables from the source container to the recipient container. These environment variables are completely decoupled from the source and the recipient, thus a change in the value of these environment variables in one container does not impact the other. To be even more precise, the values the recipient container receives are the values set during the launch of the source container. Any changes made to the value of these environment variables in the source container after its launch have no effect on the recipient container. It does not matter when the recipient container is launched because the values are being read from the JSON file.</p>

      <p>In our final illustration of linking containers, we are going to show you how to take advantage of the Docker feature to share the connectivity details between two containers. In order to share the connectivity details between containers, Docker uses the <code>PORT</code> category of environment variables. The following are the steps used to craft two containers and share the connectivity details between them:</p>

      <ol>
        <li>Craft a <code>Dockerfile</code> to expose port <code>80</code> and <code>8080</code> using the <code>EXPOSE</code> instruction, as shown here:</li>
      </ol>

      <pre>      FROM busybox:latest <br/>      EXPOSE 8080 80 
</pre>

      <ol start="2">
        <li>Proceed to build a <code>portex</code> Docker image using the <code>docker build</code> subcommand from the <code>Dockerfile</code>, we created just now, by running the following command:</li>
      </ol>

      <pre>      <strong>$ sudo docker build -t portex .</strong>
</pre>

      <ol start="3">
        <li>Now, let's launch an interactive source container with the <code>example</code> name using the earlier built <code>portex</code> image:</li>
      </ol>

      <pre>      <strong>$ sudo docker run -it --rm </strong><strong>--name example portex</strong>
</pre>

      <ol start="4">
        <li>Now that we have launched the source container, let's continue to create a recipient container on another Terminal by linking it to the source container, and invoke the <code>env</code> command to display all the environment variables, as shown here:</li>
      </ol>

      <pre><strong> $ sudo docker run --rm --link example:ex \</strong><br/><strong> busybox:latest env</strong><br/><strong> PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</strong><br/><strong> HOSTNAME=c378bb55e69c</strong><br/><strong> TERM=xterm</strong><br/><strong> EX_PORT=tcp://172.17.0.4:80</strong><br/><strong> EX_PORT_80_TCP=tcp://172.17.0.4:80</strong><br/><strong> EX_PORT_80_TCP_ADDR=172.17.0.4</strong><br/><strong> EX_PORT_80_TCP_PORT=80</strong><br/><strong> EX_PORT_80_TCP_PROTO=tcp</strong><br/><strong> EX_PORT_8080_TCP=tcp://172.17.0.4:8080</strong><br/><strong> EX_PORT_8080_TCP_ADDR=172.17.0.4</strong><br/><strong> EX_PORT_8080_TCP_PORT=8080</strong><br/><strong> EX_PORT_8080_TCP_PROTO=tcp</strong><br/><strong> EX_NAME=/prickly_rosalind/ex</strong><br/><strong> HOME=/root</strong>
</pre>

      <p>This example is also available on GitHub at <a href="https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Expose">https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Expose</a>.
      </p>

      <p>From the preceding output of the <code>env</code> command, it is quite evident that the Docker Engine exported a bunch of four <code>PORT</code> category environment variables for each port that was exposed using the <code>EXPOSE</code> instruction in the <code>Dockerfile</code>. In addition, Docker also exported another <code>PORT</code> category variable <code>EX_PORT</code>.</p>
    
  

  
    
      <h2 id="sigil_toc_id_117">Orchestration of containers</h2>
    

    
      <p>The pioneering concept of orchestration in the IT domain has been there for a long time now. For instance, in the <strong>Service Computing</strong> (<strong>SC</strong>) arena, the idea of service orchestration has been thriving in an unprecedented manner in order to produce and sustain highly robust and resilient services. Discrete or atomic services do not serve any substantial purpose unless they are composed together in a particular sequence to derive process-aware composite services. As orchestrated services are more strategically advantageous for businesses in expressing and exposing their unique capabilities in the form of identifiable/discoverable, interoperable, usable, and composable services to the outside world, corporates are showing exemplary interest in having an easily searchable repository of services (atomic as well as composite). This repository, in turn, enables businesses in realizing large-scale data as well as process-intensive applications. It is clear that the multiplicity of services is very pivotal for organizations to grow and glow. This increasingly mandated requirement gets solved using the proven and promising orchestration capabilities cognitively.</p>

      <p>Now, as we are fast tending toward containerized IT environments, application and data containers ought to be smartly composed to realize a host of new generation software services.</p>

      <p>However, for producing highly competent orchestrated containers, both purpose-specific as well as agnostic containers need to be meticulously selected and launched in the right sequence in order to create orchestrated containers. The sequence can come from the process (control as well as data) flow diagrams. Doing this complicated and daunting activity manually evokes a series of cynicisms and criticisms. Fortunately, there are orchestration tools in the Docker space that come in handy to build, run, and manage multiple containers to build enterprise-class services. The Docker firm, which has been in charge of producing and promoting the generation and assembly of Docker-inspired containers, has come out with a standardized and simplified orchestration tool (named as <code>docker-compose</code>) in order to reduce the workloads of developers as well as system administrators.</p>

      <p>The proven composition technique of the SC paradigm is being replicated here in the raging containerization paradigm in order to reap the originally envisaged benefits of containerization, especially in building powerful application-aware containers.</p>

      <p>The <strong>Microservice Architecture</strong> (<strong>MSA</strong>) is an architectural concept that aims to decouple a software solution by decomposing its functionality in a pool of discrete services. This is done by applying an architectural level to many of the principles. The MSA is slowly emerging as a championed way to design and build large-scale IT and business systems. It not only facilitates loose and light coupling and software modularity but it is also a boon to continuous integration and deployment for the agile world. Any changes being made to one part of the application mandates massive changes that are made to the application as a whole. This has been a bane and barrier to the aspect of continuous deployment. Microservices aim to resolve this situation, and hence, the MSA needs light-weight mechanisms, small, independently deployable services, and to ensure scalability and portability. These requirements can be met using Docker-sponsored containers.</p>

      <p>Microservices are being built around business capabilities and can be independently deployed by fully automated deployment machinery. Each microservice can be deployed without interrupting the other microservices, and containers provide an ideal deployment and execution environment for services along with other noteworthy facilities, such as the reduced time to deployment, isolation management, and a simple life cycle. It is easy to quickly deploy new versions of services inside containers. All of these factors led to the explosion of microservices using the features that Docker had to offer.</p>

      <p>As explained, Docker is being positioned as the next-generation containerization technology, which provides a proven and potentially sound mechanism to distribute applications in a highly efficient and distributed fashion. The beauty is that developers can tweak the application pieces within the container while maintaining the overall integrity of the container. This has a bigger impact as the brewing trend is that instead of large monolithic applications distributed on a single physical or virtual server, companies are building smaller, self-defined and contained, easily manageable, and discrete services to be contained inside standardized and automated containers. In short, the raging containerization technology from Docker has come as a boon for the ensuing era of microservices.</p>

      <p>Docker was built and sustained to fulfill the elusive goal of <em>run it once and run it everywhere</em>. Docker containers are generally isolated at the process level, portable across IT environments, and easily repeatable. A single physical host can host multiple containers, and hence, every IT environment is generally stuffed with a variety of Docker containers. The unprecedented growth of containers is to spell out troubles for effective container management. The multiplicity and the associated heterogeneity of containers are used to sharply increase the management complexities of containers. Hence, the technique of orchestration and the flourishing orchestration tools have come as a strategic solace for accelerating the containerization journey in safe waters.</p>

      <p>Orchestrating applications that span multiple containers containing microservices has become a major part of the Docker world, via projects, such as Google's Kubernetes or Flocker. Decking is another option used to facilitate the orchestration of Docker containers. Docker's new offering in this area is a set of three orchestration services designed to cover all aspects of the dynamic life cycle of distributed applications from application development to deployment and maintenance. Helios is another Docker orchestration platform used to deploy and manage containers across an entire fleet. In the beginning, <code>fig</code> was the most preferred tool for container orchestration. However, in the recent past, the company at the forefront of elevating the Docker technology has come out with an advanced container orchestration tool (<code>docker-compose</code>) to make life easier for developers working with Docker containers as they move through the container life cycle.</p>

      <p>Having realized the significance of having the capability of container orchestration for the next generation, business-critical, and containerized workloads, the Docker company purchased the company that originally conceived and concretized the <code>fig</code> tool. Then, the Docker company appropriately renamed the tool as <code>docker-compose</code> and brought in a good number of enhancements to make the tool more tuned to the varying expectations of the containers' developers and operation teams.</p>

      <p>Here is a gist of <code>docker-compose</code>, which is being positioned as a futuristic and flexible tool used for defining and running complex applications with Docker. With <code>docker-compose</code>, you define your application's components (their containers, configuration, links, volumes, and so on) in a single file, and then, you can spin everything up with a single command, which does everything to get it up and running.</p>

      <p>This tool simplifies container management by providing a set of built-in tools to do a number of jobs that are being performed manually at this point in time. In this section, we supplied all the details of using <code>docker-compose</code> to perform orchestration of containers in order to have a stream of next-generation distributed applications.</p>
    
  

  
    
      <h3 id="sigil_toc_id_118">Orchestrating containers using docker-compose</h3>
    

    
      <p>In this section, we will discuss the widely used container orchestration tool <code>docker-compose</code>. The <code>docker-compose</code> tool is a very simple, yet power tool and has been conceived and concretized to facilitate the running of a group of Docker containers. In other words, <code>docker-compose</code> is an orchestration framework that lets you define and control a multi-container service. It enables you to create a fast and isolated development environment as well as orchestrating multiple Docker containers in production. The <code>docker-compose</code> tool internally leverages the Docker Engine for pulling images, building the images, starting the containers in the correct sequence, and making the right connectivity/linking among the containers/services based on the definition given in the <code>docker-compose.yml</code> file.</p>
    
  

  
    
      <h3 id="sigil_toc_id_119">Installing docker-compose</h3>
    

    
      <p>At the time of writing this book, the latest release of <code>docker-compose</code> is 1.11.2, and it is recommended that you use it with the Docker release 1.9.1 or above. You can find the latest official release of <code>docker-compose</code> at the GitHub location (<a href="https://github.com/docker/compose/releases/latest">https://github.com/docker/compose/releases/latest</a>).</p>

      <p>We have automated the installation process of <code>docker-compose</code> and also made it available for public consumption at <a href="http://sjeeva.github.io/getcompose">http://sjeeva.github.io/getcompose</a>. These automated scripts precisely identify the latest version of <code>docker-compose</code>, download it, and install it at <code>/usr/local/bin/docker-compose</code>:</p>

      <ul>
        <li>Use the <code>wget</code> tool like this:</li>
      </ul>

      <pre>      <strong>$ wget -qO- http://sjeeva.github.io/getcompose \<br/> | sudo sh</strong>
</pre>

      <ul>
        <li>Use the <code>curl</code> tool like this:</li>
      </ul>

      <pre>      <strong>$ curl -sSL http://sjeeva.github.io/getcompose \<br/> | sudo sh</strong>
</pre>

      <p>Alternatively, you may choose to install a particular version of <code>docker-compose</code> directly from the GitHub software repository. Here, you can find the ways and means of downloading and installing the <code>docker-compose</code> version <code>1.11.2</code>:</p>

      <p>Use the <code>wget</code> tool like this:</p>

      <pre><strong>sudo sh -c 'wget -qO- \</strong><br/><strong> https://github.com/docker/compose/releases/tag/1.11.2/ \</strong><br/><strong> docker-compose-`uname -s`-`uname -m` &gt; \</strong><br/><strong> /usr/local/bin/docker-compose; \</strong><br/><strong> chmod +x /usr/local/bin/docker-compose'</strong>
</pre>

      <p>Use the <code>curl</code> tool like this:</p>

      <pre><strong>curl -L https://github.com/docker/compose/releases/download/1.11.2/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose</strong><br/><strong>chmod +x /usr/local/bin/docker-compose</strong>
</pre>

      <p>The <code>docker-compose</code> tool is also available as a Python package, which you can install using the <code>pip</code> installer, as shown here:</p>

      <pre><strong>$ sudo pip install -U docker-compose</strong>  
</pre>

      <p>If <code>pip</code> is not installed on the system, install the <code>pip</code> package before the <code>docker-compose</code> installation.
      </p>

      <p>Having successfully installed <code>docker-compose</code>, you can now check the <code>docker-compose</code> version:</p>

      <pre><strong>$ docker-compose --version</strong><br/><strong>docker-compose version 1.11.2, build dfed245</strong>
</pre>
    
  

  
    
      <h3 id="sigil_toc_id_120">The docker-compose file</h3>
    

    
      <p>The <code>docker-compose</code> tool orchestrates containers using <strong>YAML</strong>, which is a <strong>Yet Another Markup Language</strong> called the <code>docker-compose</code> file. YAML is a human-friendly data serialization format. Docker began its journey as a container enablement tool, and it is growing by leaps and bounds as an ecosystem to automate and accelerate most of the tasks such as container provisioning, networking, storage, management, orchestration, security, governance, and persistence. Consequently, the <code>docker-compose</code> file format and its version are revised multiple times to keep up with the Docker platform. At the time of writing this edition, the latest version of the <code>docker-compose</code> file is version 3. The following table lists the <code>docker-compose</code> file and the Docker Engine version compatibility matrix:</p>

      <table class="table">
        <tbody>
          <tr>
            <td>
              <p><strong>Docker Compose file format</strong></p>
            </td>

            <td>
              <p><strong>Docker Engine</strong></p>
            </td>

            <td>
              <p><strong>Remarks</strong></p>
            </td>
          </tr>

          <tr>
            <td>
              <p>3, 3.1</p>
            </td>

            <td>
              <p>1.13.0+</p>
            </td>

            <td>
              <p>Provides support for <code>docker stack deploy</code> and <code>docker secrets</code></p>
            </td>
          </tr>

          <tr>
            <td>
              <p>2.1</p>
            </td>

            <td>
              <p>1.12.0+</p>
            </td>

            <td>
              <p>Introduced a few new parameters</p>
            </td>
          </tr>

          <tr>
            <td>
              <p>2</p>
            </td>

            <td>
              <p>1.10.0+</p>
            </td>

            <td>
              <p>Introduced support for named volumes and networks</p>
            </td>
          </tr>

          <tr>
            <td>
              <p>1</p>
            </td>

            <td>
              <p>1.9.0+</p>
            </td>

            <td>
              <p>Will be deprecated in the future compose releases</p>
            </td>
          </tr>
        </tbody>
      </table>

      <p>The <code>docker-compose</code> tool by default uses a file named as <code>docker-compose.yml</code> or <code>docker-compose.yaml</code> to orchestrate containers. This default file can be modified using the <code>-f</code> option of the <code>docker-compose</code> tool. The following is the format of the <code>docker-compose</code> file:</p>

      <pre>version: "&lt;version&gt;" <br/>services: <br/>  &lt;service&gt;: <br/>    &lt;key&gt;: &lt;value&gt; <br/>    &lt;key&gt;: <br/>       - &lt;value&gt; <br/>       - &lt;value&gt; <br/>networks: <br/>  &lt;network&gt;: <br/>    &lt;key&gt;: &lt;value&gt; <br/><br/>volumes: <br/>  &lt;volume&gt;: <br/>    &lt;key&gt;: &lt;value&gt; 
</pre>

      <p>Here, the options used are as follows:</p>

      <ul>
        <li><code>&lt;version&gt;</code>: This is the version of the <code>docker-compose</code> file. Refer to the preceding version table.</li>

        <li><code>&lt;service&gt;</code>: This is the name of the service. You can have more than one service definition in a single <code>docker-compose</code> file. The service name should be followed by one or more keys. However, all the services must either have an <code>image</code> or a <code>build</code> key, followed by any number of optional keys. Except for the <code>image</code> and <code>build</code> keys, the rest of the keys can be directly mapped to the options in the <code>docker run</code> subcommand. The value can be either a single value or multiple values. All the <code>&lt;service&gt;</code> definitions must be grouped under the top-level <code>services</code> key.</li>

        <li><code>&lt;network&gt;</code>: This is the name of the networks that are used by the services. All the <code>&lt;network&gt;</code> definitions must be grouped under the top-level <code>networks</code> key.</li>

        <li><code>&lt;volume&gt;</code>: This is the name of the volume that is used by the services. All the <code>&lt;volume&gt;</code> definitions must be grouped under the top-level <code>volume</code> key.</li>
      </ul>

      <p>Here, we are listing a few keys supported in the <code>docker-compose</code> file version 3. Refer to <a href="https://docs.docker.com/compose/compose-file">https://docs.docker.com/compose/compose-file</a> for all the keys supported by <code>docker-compose</code>.</p>

      <ul>
        <li><code>image</code>: This is the tag or image ID.</li>

        <li><code>build</code>: This is the path to a directory containing a <code>Dockerfile</code>.</li>

        <li><code>command</code>: This key overrides the default command.</li>

        <li><code>deploy</code>: This key has many subkeys and is used to specify deployment configuration. This is used only in the <code>docker swarm</code> mode.</li>

        <li><code>depends_on</code>: This is used to specify the dependencies between services. It can be further extended to chain services based on their conditions.</li>

        <li><code>cap_add</code>: This adds a capability to the container.</li>

        <li><code>cap_drop</code>: This drops a capability of the container.</li>

        <li><code>dns</code>: This sets custom DNS servers.</li>

        <li><code>dns_search</code>: This sets custom DNS search servers.</li>

        <li><code>entrypoint</code>: This key overrides the default entrypoint.</li>

        <li><code>env_file</code>: This key lets you add environment variables through files.</li>

        <li><code>environment</code>: This adds environment variables and uses either an array or a dictionary.</li>

        <li><code>expose</code>: This key exposes ports without publishing them to the host machine.</li>

        <li><code>extends</code>: This extends another service defined in the same or a different configuration file.</li>

        <li><code>extra_hosts</code>: This enables you to add additional hosts to <code>/etc/hosts</code> inside the container.</li>

        <li><code>healthcheck</code>: This allows us to configure the service health check.</li>

        <li><code>labels</code>: This key lets you add metadata to your container.</li>

        <li><code>links</code>: This key links to containers in another service. Usage of links is strongly discouraged.</li>

        <li><code>logging</code>: This is used to configure the logging for the service.</li>

        <li><code>network</code>: This is used to join the service to the network defined in the top-level <code>networks</code> key.</li>

        <li><code>pid</code>: This enables the PID space sharing between the host and the containers.</li>

        <li><code>ports</code>: This key exposes ports and specifies both the <code>HOST_port:CONTAINER_port</code> ports.</li>

        <li><code>volumes</code>: This key mounts path or named volumes. The named volumes need to be defined in the top-level <code>volumes</code> key.</li>
      </ul>
    
  

  
    
      <h3 id="sigil_toc_id_121">The docker-compose command</h3>
    

    
      <p>The <code>docker-compose</code> tool provides sophisticated orchestration functionality with a handful of commands. In this section, we will list out the <code>docker-compose</code> options and commands:</p>

      <pre><strong>docker-compose [&lt;options&gt;] &lt;command&gt; [&lt;args&gt;...]</strong>  
</pre>

      <p>The <code>docker-compose</code> tool supports the following options:</p>

      <ul>
        <li><code>-f</code>, <code>--file &lt;file&gt;</code>: This specifies an alternate file for <code>docker-compose</code> (default is the <code>docker-compose.yml</code> file)</li>

        <li><code>-p</code>, <code>--project-name &lt;name&gt;</code>: This specifies an alternate project name (default is the directory name)</li>

        <li><code>--verbose</code>: This shows more output</li>

        <li><code>-v</code>, <code>--version</code>: This prints the version and exits</li>

        <li><code>-H</code>, <code>--host &lt;host&gt;</code>: This is to specify the daemon socket to connect to</li>

        <li><code>-tls</code>, <code>--tlscacert</code>, <code>--tlskey</code>, and <code>--skip-hostname-check</code>: The <code>docker-compose</code> tool also supports these flags for <strong>Transport Layer Security</strong> (<strong>TLS</strong>)</li>
      </ul>

      <p>The <code>docker-compose</code> tool supports the following commands:</p>

      <ul>
        <li><code>build</code>: This command builds or rebuilds services.</li>

        <li><code>bundle</code>: This is used to create a Docker bundle from the compose file, this is still an experimental feature on Docker 1.13.</li>

        <li><code>config</code>: This is a command to validate and display the compose file.</li>

        <li><code>create</code>: This creates the services defined in the compose file.</li>

        <li><code>down</code>: This command is used to stop and remove containers and networks.</li>

        <li><code>events</code>: This can be used to view the real-time container life cycle events.</li>

        <li><code>exec</code>: This enables you to run a command in a running container. It is used predominantly for debugging purposes.</li>

        <li><code>kill</code>: This command kills running containers.</li>

        <li><code>logs</code>: This displays the output from the containers.</li>

        <li><code>pause</code>: This command is used to pause services.</li>

        <li><code>port</code>: This prints the public port for a port binding.</li>

        <li><code>ps</code>: This lists the containers.</li>

        <li><code>pull</code>: This command pulls the images from the repository.</li>

        <li><code>push</code>: This command pushes the images to the repository.</li>

        <li><code>restart</code>: This is used to restart the services defined in the compose file.</li>

        <li><code>rm</code>: This removes the stopped containers.</li>

        <li><code>run</code>: This runs a one-off command.</li>

        <li><code>scale</code>: This sets a number of containers for a service.</li>

        <li><code>start</code>: This command starts services defined in the compose file.</li>

        <li><code>stop</code>: This stops services.</li>

        <li><code>unpause</code>: This command is used to unpause services.</li>

        <li><code>up</code>: This creates and starts containers.</li>

        <li><code>version</code>: This prints the version of Docker Compose.</li>
      </ul>
    
  

  
    
      <h3 id="sigil_toc_id_122">Common usage</h3>
    

    
      <p>In this section, we are going to experience the power of the orchestration feature provided by the Docker Compose framework with the help of an example. For this purpose, we are going to build a two-tiered web application that will receive your inputs through a URL and respond with the associated response text. This application is built using the following two services, as enumerated here:</p>

      <ul>
        <li><strong>Redis</strong>: This is a key-value database used to store a key and its associated value</li>

        <li><strong>Node.js</strong>: This is a JavaScript runtime environment used to implement the web server functionality as well the application logic</li>
      </ul>

      <p>Each of these services is packed inside two different containers that are stitched together using the <code>docker-compose</code> tool. The following is the architectural representation of the services:</p>

      <div><img class=" image-border" height="123" src="img/image_08_001.png" width="306"/>
      </div>

      <p>Here, in this example, we begin with implementing the <code>example.js</code> module, a Node.js file to realize the web server, and the key lookup functionality. Further, we will craft the <code>Dockerfile</code> on the same directory as <code>example.js</code> to package the Node.js runtime environment, and then, define the service orchestration using a <code>docker-compose.yml</code> file in the same directory as <code>example.js</code>.</p>

      <p>The following is the <code>example.js</code> file, which is a Node.js implementation of the simple request/response web application. For demonstration, in this sample code, we restrict the request and response for just two <code>docker-compose</code> commands (<code>build</code> and <code>kill</code>). For the code to be self-explanatory, we added comments in the code:</p>

      <pre>// A Simple Request/Response web application <br/><br/>// Load all required libraries <br/>var http = require('http'); <br/>var url = require('url'); <br/>var redis = require('redis'); <br/><br/>// Connect to redis server running <br/>// createClient API is called with <br/>//  -- 6379, a well-known port to which the <br/>//           redis server listens to <br/>//  -- redis, is the name of the service (container) <br/>//            that runs redis server <br/>var client = redis.createClient(6379, 'redis'); <br/><br/>// Set the key value pair in the redis server <br/><br/>// Here all the keys proceeds with "/", because <br/>// URL parser always have "/" as its first character <br/>client.set("/", "Welcome to Docker-Compose helpernEnter the docker-compose command in the URL for helpn", redis.print); <br/>client.set("/build", "Build or rebuild services", redis.print); <br/>client.set("/kill", "Kill containers", redis.print); <br/><br/>var server = http.createServer(function (request, response) { <br/>  var href = url.parse(request.url, true).href; <br/>  response.writeHead(200, {"Content-Type": "text/plain"}); <br/><br/>  // Pull the response (value) string using the URL <br/>  client.get(href, function (err, reply) { <br/>    if ( reply == null ) response.write("Command: " + <br/>    href.slice(1) + " not supportedn"); <br/>    else response.write(reply + "n"); <br/>    response.end(); <br/>  }); <br/>}); <br/><br/>console.log("Listening on port 80"); <br/>server.listen(80); 
</pre>

      <p>This example is also available at <a href="https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose">https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose</a>.
      </p>

      <p>The following text is the content of <code>Dockerfile</code> that packs the Node.js image, the <code>redis</code> driver for Node.js, and the <code>example.js</code> file, as defined earlier:</p>

      <pre>############################################### <br/># Dockerfile to build a sample web application <br/>############################################### <br/><br/># Base image is node.js <br/>FROM node:latest <br/><br/># Author: Dr. Peter <br/>MAINTAINER Dr. Peter &lt;peterindia@gmail.com&gt; <br/><br/># Install redis driver for node.js <br/>RUN npm install redis <br/><br/># Copy the source code to the Docker image <br/>ADD example.js /myapp/example.js 
</pre>

      <p>This code is also available at <a href="https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose">https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose</a>.
      </p>

      <p>The following text is from the <code>docker-compose.yml</code> file that defines the services that the Docker Compose tool orchestrates:</p>

      <pre>version: "3.1" <br/>services: <br/>  web: <br/>    build: . <br/>    command: node /myapp/example.js <br/>    depends_on: <br/>       - redis <br/>    ports: <br/>    - 8080:80 <br/>  redis: <br/>    image: redis:latest 
</pre>

      <p>This example is also available at <a href="https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose">https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose</a>.
      </p>

      <p>We defined two services in this <code>docker-compose.yml</code> file, wherein these services serve the following purposes:</p>

      <ul>
        <li>The service named <code>web</code> is built using the <code>Dockerfile</code> in the current directory. Also, it is instructed that you launch the container by running the <code>node</code> (the Node.js runtime) with <code>/myapp/example.js</code> (web application implementation), as its argument. Since this Node.js application uses the <code>redis</code> database, the <code>web</code> service is forced to start after the <code>redis</code> service using the <code>depends_on</code> instruction. Besides, the <code>80</code> container port is mapped to the <code>8080</code> Docker host's port.</li>

        <li>The service named <code>redis</code> is instructed to launch a container with the <code>redis:latest</code> image. If the image is not present in the Docker host, the Docker Engine will pull it from the central repository or the private repository.</li>
      </ul>

      <p>Now, let's continue with our example by building the Docker images using the <code>docker-compose build</code> command, launch the containers using the <code>docker-compose up</code> command, and connect with a browser to verify the request/response functionality, as explained step by step here:</p>

      <ol>
        <li>The <code>docker-compose</code> commands must be executed from the directory in which the <code>docker-compose.yml</code> file is stored. Besides, <code>docker-compose</code> considers each <code>docker-compose.yml</code> file as a project, and it assumes the project name from the <code>docker-compose.yml</code> file's directory. Of course, this can be overridden using the <code>-p</code> option. So, as a first step, let's change the directory, wherein the <code>docker-compose.yml</code> file is stored:</li>
      </ol>

      <pre>      <strong>$ cd ~/example</strong>
</pre>

      <ol start="2">
        <li>Build the services using the <code>docker-compose build</code> command:</li>
      </ol>

      <pre>      <strong>$ sudo docker-compose build</strong>
</pre>

      <ol start="3">
        <li>Pull the images from the repository using the <code>docker-compose pull</code> command:</li>
      </ol>

      <pre>      <strong>$ sudo docker-compose pull</strong>
</pre>

      <ol start="4">
        <li>Proceed to bring up the services as indicated in the <code>docker-compose.yml</code> file using the <code>docker-compose up</code> command:</li>
      </ol>

      <pre><strong> $ sudo docker-compose up</strong><br/><strong> Creating network "example_default" with the default</strong><br/><strong> driver</strong><br/><strong> Creating example_redis_1</strong><br/><strong> Creating example_web_1</strong><br/><strong> Attaching to example_redis_1, example_web_1</strong><br/><strong> redis_1 | 1:C 03 Feb 18:09:40.743 # Warning: no </strong><br/><strong> config file specified, using the default config. </strong><br/><strong> In order to specify a config file use redis-server </strong><br/><strong> /path/to/redis.conf </strong><br/><strong> . . . TRUNCATED OUTPUT . . .</strong><br/><strong> redis_1 | 1:M 03 Feb 18:03:47.438 * The server </strong><br/><strong> is now ready to accept connections on port 6379</strong><br/><strong> web_1 | Listening on port 80</strong><br/><strong> web_1 | Reply: OK</strong><br/><strong> web_1 | Reply: OK</strong><br/><strong> web_1 | Reply: OK</strong>
</pre>

      <p style="padding-left: 60px">Since the directory name is <code>example</code>, the <code>docker-compose</code> tool has assumed that the project name is <code>example</code>. If you pay attention to the first line of the output, you will notice the <code>example_default</code> network being created. The Docker Compose tool creates this bridge network by default and this network is used by the service for IP address resolution. Thus the services can reach the other services by just using the service names defined in the compose file.</p>

      <ol start="5">
        <li>Having successfully orchestrated the services using the <code>docker-compose</code> tool, let's invoke the <code>docker-compose ps</code> command from a different Terminal to list the containers associated with the example <code>docker-compose</code> project:</li>
      </ol>

      <pre><strong> $ sudo docker-compose ps</strong><br/><strong> Name Command </strong><br/><strong> State Ports</strong><br/><strong> -------------------------------------------------- </strong><br/><strong> -------------------------</strong><br/><strong> example_redis_1 /entrypoint.sh redis-server </strong><br/><strong> Up 6379/tcp</strong><br/><strong> example_web_1 node /myapp/example.js </strong><br/><strong> Up 0.0.0.0:8080-&gt;80/tcp</strong>
</pre>

      <p style="padding-left: 60px">Evidently, the two <code>example_redis_1</code> and <code>example_web_1</code> containers are up and running. The container name is prefixed with <code>example_</code>, which is the <code>docker-compose</code> project name.</p>

      <ol start="6">
        <li>Explore the functionality of our own request/response web application on a different Terminal of the Docker host, as illustrated here:</li>
      </ol>

      <pre><strong> $ curl http://localhost:8080</strong><br/><strong> Welcome to Docker-Compose helper</strong><br/><strong> Enter the docker-compose command in the URL for help</strong><br/><strong> $ curl http://localhost:8080/build</strong><br/><strong> Build or rebuild services</strong><br/><strong> $ curl http://localhost:8080/something</strong><br/><strong> Command: something not supported</strong>
</pre>

      <p>Here, we are directly connecting to the <code>web</code> service using <code>http://localhost:8080</code> because the <code>web</code> service is bound to the Docker host on port <code>8080</code>. You can also access the service externally using the Docker host IP address and port <code>8080</code> (<code>https://&lt;docker host ip&gt;:8080</code>), provided the IP address and the port is reachable from the external system.
      </p>

      <p>Cool, isn't it? With very minimal effort and with the help of the <code>docker-compose.yml</code> file, we are able to compose two different services together and offer a composite service.</p>
    
  

  
    
      <h2 id="sigil_toc_id_123">Summary</h2>
    

    
      <p>This chapter was incorporated into this book in order to provide you with all the probing and prescribing details on seamlessly orchestrating multiple containers. We extensively discussed the need for container orchestration and the enabling tools to simplify and streamline the increasingly complicated process of container orchestration. In order to substantiate how orchestration is handy and helpful in crafting enterprise-class containers and to illustrate the orchestration process, we took the widely followed way of explaining the whole gamut through a simple example. We developed a web application and contained it within a standard container. Similarly, we took a database container, which is a backend for the frontend web application. The database gets executed inside another container. We saw how to make the web application container aware of the database, using different technologies through the container-linkage feature of the Docker Engine. We used an open-source tool (<code>docker-compose</code>) for this purpose.</p>

      <p>In the next chapter, we will discuss how Docker facilitates software testing, especially integration testing with a few pragmatic examples.</p>
    
  
</body></html>