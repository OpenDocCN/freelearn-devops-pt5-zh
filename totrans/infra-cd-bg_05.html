<html><head></head><body>
<div><div><div><h1 id="_idParaDest-75" class="chapter-number"><a id="_idTextAnchor268"/>5</h1>
			<h1 id="_idParaDest-76"><a id="_idTextAnchor269"/>Deploying to Amazon Web Services</h1>
			<p><a id="_idTextAnchor270"/>After deploying our WordPress infrastructure into Microsoft Azure, we are now ready to explore how to <a id="_idIndexMarker238"/>deploy the same infrastructure to <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>). However, while the high-level design of the infrastructure remains the same, there are some key differences between Azure and AWS that will require us to approach the deployment differently.</p>
			<p>In <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to Microsoft Azure</em>, we focused on using Terraform to deploy to Azure. In this chapter, we will be diving deeper into Ansible, another popular infrastructure-as-code tool, to deploy our workload to AWS. Ansible allows us to define the desired state of our infrastructure in a declarative manner and manage the configuration and orchestration of our AWS resources.</p>
			<p>By the end of this chapter, you will have a good understanding of how to use Ansible and Terraform to deploy a WordPress workload on AWS. You will also be familiar with the key differences between Azure and AWS and how to adapt your deployment approach to your infrastructure-as-code deployment.</p>
			<p>We are going to be covering the following topics:<a id="_idTextAnchor271"/></p>
			<ul>
				<li>Introducing Amazon Web Services<a id="_idTextAnchor272"/></li>
				<li>Preparing our cloud environment for deployment<a id="_idTextAnchor273"/><a id="_idTextAnchor274"/></li>
				<li>Producing the low-level design<a id="_idTextAnchor275"/></li>
				<li>Ansible – writing the code and deploying our infrastructure<a id="_idTextAnchor276"/></li>
				<li>Terraform – reviewing the code and deploying our infrastructure</li>
			</ul>
			<h1 id="_idParaDest-77"><a id="_idTextAnchor277"/>Technical requirements</h1>
			<p>Like in the previous chapter, due to the amount of code needed to deploy our project, when it comes to the Terraform and Ansible sections of the chapter, we will only be covering some pieces of code needed to deploy the project. The code repository accompanying this book will contain the complete executable code.</p>
			<h1 id="_idParaDest-78"><a id="_idTextAnchor278"/>Introducing Amazon Web Services</h1>
			<p>AWS is a cloud <a id="_idIndexMarker239"/>infrastructure platform owned and operated by the e-commerce giant Amazon, which you probably already guessed, given the name.</p>
			<p>The company began experimenting with cloud services in 2000, developing and deploying <strong class="bold">application programming interfaces</strong> (<strong class="bold">APIs</strong>) for their internal and external retail <a id="_idIndexMarker240"/>partners to consume. As more and more of the Amazon retail partners consumed more of the software services and grew at an exponential rate, they realized they would need to build a better and more standardized infrastructure platform to not only host the services they had been developing but also ensure that they could quickly scale as well.</p>
			<p>Off the back of this requirement, Amazon enginee<a id="_idTextAnchor279"/>rs Chris Pinkham and Benjamin Black wrote a white paper, which Jeff Bezos personally approved in early 2004. The paper described an infrastructure platform where the compute and storage elements could all be deployed programmatically.</p>
			<p>The first public acknowledgment of AWS’s existence was made in late 2004. Still, at that time, the term was used to describe a collection of tools and APIs that would allow first and third parties to intera<a id="_idTextAnchor280"/>ct with Amazon’s retail product catalog rather than the fully formed public cloud service it is today. It wasn’t until 2006 that a rebranded AWS was launched, due mainly to the service starting to expand beyond offering an API to Amazon’s retail services and instead starting to offer services that allowed users to use the services for their applications.</p>
			<p><strong class="bold">Simple Storage Service</strong> (<strong class="bold">S3</strong>) was the <a id="_idIndexMarker241"/>first of these new services; this was, and still is, albeit a little more feature-rich, a service that allows developers to write and serve individual files using a web API rather than having to write and read from a traditional local filesystem.</p>
			<p>The next service to <a id="_idIndexMarker242"/>launch is also still around, Amazon <strong class="bold">Simple Queue Service</strong> (<strong class="bold">SQS</strong>). It initially formed part of the original AWS collection of API endpoints. It is a distributed message system that again could be controlled and consumed by developers using an API.</p>
			<p>The final service, launched in 2006, was <a id="_idIndexMarker243"/>a beta version of the Amazon <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>) service, which was limited to existing AWS customers – again, you could use the APIs developed by Amazon to launch and manage resources.</p>
			<p>This was the final <a id="_idIndexMarker244"/>piece of the jigsaw for Amazon. They now had the foundations of a public cloud platform, which had initially been envisioned in the whitepaper that Chris Pinkham and Benjamin Black produced a few years earlier. They could not only use this new service for their retail platform but also sell space to other companies and the public, such as you and me. The bonus was that this new service could have a recurring revenue stream not only to pay for the initial development but also so that Amazon could maximize its hardware investment by <em class="italic">renting</em> out its idle compute resources.</p>
			<p>AWS has grown from the 3 services mentioned in 2006 to over 200 in 2023. All these 200+ services are aligned with the core principles laid out in the original white paper. Each service is software-defined, meaning that a developer simply needs to make an API request to launch, configure, sometimes consume, and terminate the service.</p>
			<p>Interacting with the API is also precisely what we will do in this chapter, as many of the principles laid out in that original white paper are also at the core of infrastructure as code.</p>
			<h1 id="_idParaDest-79"><a id="_idTextAnchor281"/>Preparing our cloud environment for deployment</h1>
			<p>As we discussed in <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to Microsoft Azure</em>, we will be running Ansible <a id="_idIndexMarker245"/>and Terraform on our local machine, which means <a id="_idIndexMarker246"/>we can install and configure the AWS <strong class="bold">command-line </strong><strong class="bold">interface</strong> (<strong class="bold">CLI</strong>).</p>
			<p>Ansible and Terraform will use the credentials configured in the AWS CLI to authenticate against the AWS APIs. For <a id="_idIndexMarker247"/>details on how to install the AWS CLI, see <a href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html">https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html</a>.</p>
			<p>Once installed, you need to generate and enter your credentials. This process is documented at <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html">https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html</a>.</p>
			<p>Once configured, you should be able to run the following commands:</p>
			<pre class="source-code">
$ aws --version
$ aws ec2 describe-regions</pre>
			<p>When I run them on my own machine, I get the following o<a id="_idTextAnchor282"/>utput:</p>
			<div><div><img src="img/Figure_5.01_B19537.jpg" alt="Figure 5.1 – The output of running the AWS version command to check the version" width="1650" height="147"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – The output of running the AWS version command to check the version</p>
			<p>For the <a id="_idIndexMarker248"/>second command, there is quite a lot of output, which should look something like the following:</p>
			<div><div><img src="img/Figure_5.02_B19537.jpg" alt="Figure 5.2 – The output of running the AWS version command to describe the regions" width="1650" height="557"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – The output of running the AWS version command to describe the regions</p>
			<p>Now that we have the AWS CLI configured and hooked into our AWS account, we can discuss the services we will be deploying and configuring within AWS.</p>
			<h1 id="_idParaDest-80">Producing the low-leve<a id="_idTextAnchor283"/>l design</h1>
			<p>From an <a id="_idIndexMarker249"/>architecture point of view, the services that are going to be deployed are not too dissimilar from those we covered in <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to </em><em class="italic">Microsoft <a id="_idTextAnchor284"/>Azure</em>:</p>
			<div><div><img src="img/Figure_5.03_B19537.jpg" alt="Figure 5.3 – An overview of the services we will be deploying into AWS" width="1650" height="880"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – An overview of the services we will be deploying into AWS</p>
			<p>The core services we are going to be deploying are as <a id="_idTextAnchor285"/>follows:</p>
			<ul>
				<li>Amazon <strong class="bold">Elastic Load Balancing</strong> (<strong class="bold">ELB</strong>) is the first difference in the services we will <a id="_idIndexMarker250"/>be deploying. Azure Load Balancer only distributed TCP requests between our WordPress instances. However, in AWS, we will launch ELB configured as Application Load Balancer, which will terminate our HTTP requests and distribute them across our WordPress instances.</li>
				<li><strong class="bold">Amazon EC2</strong> is the <a id="_idIndexMarker251"/>compute service. For our WordPress deployment, we will be deploying a single Amazon EC2 instance, which will be used to bootstrap WordPress, and then the rest of the Amazon EC2 instances will be aut<a id="_idTextAnchor286"/>o-scaling.</li>
				<li>We will be <a id="_idIndexMarker252"/>using a combination of Amazon EC2 <strong class="bold">Auto Scaling groups</strong> (<strong class="bold">ASGs</strong>) and launch configurations to manage the deployment of the Amazon EC2 instances, which will host the web instances.</li>
				<li>Amazon <strong class="bold">Elastic File System</strong> (<strong class="bold">EFS</strong>) is the <a id="_idIndexMarker253"/>service that will provide the NFS share hosting of the WordPress installation, which will be shared across all of our instances.</li>
				<li>Amazon <strong class="bold">Relational Database Service</strong> (<strong class="bold">RDS</strong>) will be <a id="_idIndexMarker254"/>used to host the MySQL database we will use for WordPress.</li>
				<li>Amazon <strong class="bold">Virtual Private Cloud</strong> (<strong class="bold">VPC</strong>) is the underlying network service that hosts the <a id="_idIndexMarker255"/>services that will be deployed throughout this chapter. There are a few different services that come under this umbrella, and those will be covered in more detail when we do a deep dive into the Ansible code in the next section.</li>
			</ul>
			<p>Now that we <a id="_idIndexMarker256"/>have an idea of the services we are going to be using and also which part of the WordPress deployment they will be hosting, we can start to look at how we approach the project using Ansible – this time going in into a little more detail than we did in <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to </em><em class="italic">Microsoft Azure</em>.</p>
			<h1 id="_idParaDest-81"><a id="_idTextAnchor287"/>Ansible – writing the code and deploying our infrastructure</h1>
			<p>In <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to Microsoft Azure</em>, we briefly covered the Ansible code to deploy our Azure environment. Let’s take a step back and cover some of the basics we skipped.</p>
			<p>While we <a id="_idIndexMarker257"/>can have one big YAML file containing our playbook code, I tend to split mine into more manageable chunks using roles. Roles can be used for <a id="_idIndexMarker258"/>a few things. In some cases, they can be stand-alone distributable tasks that can be reused across multiple projects; or, in our case, they can be used to manage more complex playbooks.</p>
			<p>A copy of the <code>site.yml</code> file that will be used to deploy our WordPress environment in AWS looks like the following:</p>
			<pre class="source-code">
- name: Deploy and configure the AWS Environment
  hosts: localhost
  connection: local
  gather_facts: true
  vars_files:
    - group_vars/aws.yml
    - group_vars/common.y<a id="_idTextAnchor288"/>ml
  roles:
    - roles/create-randoms
    - roles/aws-network
    - roles/aws-storage
    - roles/aws-database
    - roles/aws-vm-admin
    - roles/aws-asg-web
    - roles/output</pre>
			<p>As you can see, there are several roles, all of which I have grouped in the logical order we need to deploy our resources.</p>
			<p>If you look <a id="_idIndexMarker259"/>in one of the role folders, for example, <code>roles/create-randoms</code>, you will <a id="_idIndexMarker260"/>notice that there are several folders and files:</p>
			<ul>
				<li><code>defaults</code>: This is where the default variables for the role are stored. These can be overridden by any variables with the same name called in the <code>vars</code> folder.</li>
				<li><code>files</code>: This folder contains any static files we wish to copy to the target hosts using the <code>copy</code> module.</li>
				<li><code>handlers</code>: These are tasks that are executed once a playbook has been executed, for example, restarting services on a target host when a configuration file has changed.</li>
				<li><code>meta</code>: This folder contains information about the role itself. This information would be used if it was ever published to Ansible Galaxy.</li>
				<li><code>tasks</code>: This contains the primary set of instructions or actions that will be executed on the target hosts. These instructions are usually defined in YAML files, including installing packages, creating users, and copying files. Tasks can be organized into different files based on their functionality or the specific actions they perform. They can also include variables and conditional statements to make them more dynamic and flexible.</li>
				<li><code>templates</code>: This folder contains the Jinja2 templates used by the <code>template</code> module.</li>
				<li><code>tests</code>: If you are publishing your role to Ansible Galaxy, then it is a good idea to set up some tests. These are stored here.</li>
				<li><code>vars</code>: You can override any of the variables defined in the <code>default</code> folder using the variables defined here. Variables defin<a id="_idTextAnchor289"/>ed here can also be overridden by any variables loaded from the <code>group_vars</code> folder at the top level of the playbook. These, in turn, can be overridden by variables passed in at runtime using the <code>ansible-playbook</code> command.</li>
				<li><code>README.md</code>: This is the file used to create any documentation about the role when the role is checked into a service such as GitHub. This is useful when publishing the role to Ansible Galaxy.</li>
			</ul>
			<p>Now that is <a id="_idIndexMarker261"/>a lot of folders and files to create when you want to <a id="_idIndexMarker262"/>add a role. Luckily, the <code>ansible-galaxy</code> command can bootstrap a role quickly. To do this, simply run the following command in the top level of your <code>playbook</code> folder, making sure to replace <code>role-name</code> with the name you want for your role:</p>
			<pre class="source-code">
$ ansible-galaxy init roles/role-name</pre>
			<p>This will create the folder and file structure we just covered and is an excellent starting point.</p>
			<p>Before we dive into the roles, let’s quickly discuss the variables. At the top of the <code>group_vars/aws.yml</code> file, we have some basic variables defined. These are as f<a id="_idTextAnchor290"/>ollows:</p>
			<pre class="source-code">
app:
  name: "iac-wordpress"
  location: "us-east-1"
  env: "prod"
wordpress:
  wp_title: "IAC WordPress"
  wp_admin_user: "admin"
  wp_admin_email: "test@test.com"</pre>
			<p>As you can see, we are defining a top level and have multiple keys and values attached to them. So, anywhere in our code, or even in other top-level variables, we can simply use something such as <code>{{ app.name }}</code>, which will be replaced by <code>iac-wordpress</code> when our playbook runs.</p>
			<p>This can be seen when defining the resource names, as these are mostly made up of groups of <a id="_idIndexMarker263"/>variables defined elsewhere. Take the following example:</p>
			<pre class="source-code">
vpc_name: "{{ app.name }}-{{ app.env }}-{{ dict.vpc }}"
vpc_subnet_web01_name: "{{ app.name }}-{{ app.env }}-web01-{{ dict.subnet }}"
vpc_subnet_web02_name: "{{ app.name }}-{{ app.env }}-web02-{{ dict.subnet }}"</pre>
			<p>Now, let’s <a id="_idIndexMarker264"/>look at the playbook roles in detail.</p>
			<h2 id="_idParaDest-82"><a id="_idTextAnchor291"/>Ansible playbook roles</h2>
			<p>Let’s dive <a id="_idIndexMarker265"/>straight in and<a id="_idTextAnchor292"/> look at the first role.</p>
			<h3>Creating the Randoms role</h3>
			<p>This role, which <a id="_idIndexMarker266"/>we already covered in detail in <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to Microsoft Azure</em>, does the same tasks as covered in that chapter. The role was copied straight from the Microsoft<a id="_idTextAnchor293"/> Azure deployment folder.</p>
			<h3>The AWS Network role</h3>
			<p>The primary <a id="_idIndexMarker267"/>variable we are defining in <code>group_vars/aws.yml</code> for this role is a lot more simplistic than the one we defined for the Azure <a id="_idIndexMarker268"/>deployment. It contains the CIDR range we want to use for our VPC network and nothing e<a id="_idTextAnchor294"/>lse:</p>
			<pre class="source-code">
vpc:
  address_space: "10.0.0.0/24"</pre>
			<p>The tasks we are running in the role take care of the rest of the information using some of Ansible’s built-in functions. The first task is a relatively straightforwar<a id="_idTextAnchor295"/>d one:</p>
			<pre class="source-code">
- name: Create VPC
  amazon.aws.ec2_vpc_net:
    name: "{{ vpc_name }}"
    region: "{{ region }}"
    cidr_block: "{{ vpc.address_space }}"
    dns_hostnames: true
    dns_support: true
    state: present
  register: vpc</pre>
			<p>As you can see, it uses the <code>amazon.aws.ec2_vpc_net</code> module from the Amazon collection <a id="_idIndexMarker269"/>on Ansible Galaxy to create the VPC – so nothing too special or complicated there. The output of the task is registered as <code>vpc</code>; we will use this output register throughout the remainder of the playbook run.</p>
			<p>The next <a id="_idIndexMarker270"/>task gathers some information on the region in which we are going to be deploying our workload:</p>
			<pre class="source-code">
- name: get some information on the available zones
  amazon.aws.aws_az_info:
    region: "{{ region }}"
  register: zones</pre>
			<p>Now that we have a few outputs registered, we can add the subnets and start doing more exciting things.</p>
			<p>As part of our deployment, we need to add four subnets – two for the web services and two for the database services. Like our Azure deployment, the subnets will be /27s, and we will deploy each subnet in different Availability Zones.</p>
			<p class="callout-heading">Information</p>
			<p class="callout">When we deployed the Azure version of our WordPress workload, we didn’t have to worry about how the subnets were distributed across Availability Zones (which are different data centers within a region), as virtual networks in Azure can span multiple Availability Zones. However, AWS is different; subnets need to be pinned to Availability Zones, meaning you will need to have more than one per server role or service function.</p>
			<p>The task <a id="_idIndexMarker271"/>to add the first subnet <a id="_idIndexMarker272"/>looks like the following:</p>
			<pre class="source-code">
- name: Create Subnet Web01
  amazon.<a id="_idTextAnchor296"/>aws.ec2_vpc_<a id="_idTextAnchor297"/>subnet:
    vpc_id: "{{ vpc.vpc.id }}"
    cidr: "{{ vpc.vpc.cidr_block | ansible.uti<a id="_idTextAnchor298"/>ls.ipsubnet(27, 0) }}"
    az: "{{ zones.availability_zones[0].zone_name }}"
    region: "{{ region }}"
    tags:
      Name: "{{ vpc_subnet_web01_name }}"
      Description: "{{ dict.ansible_warning }}"
      Project: "{{ app.name }}"
      Environment: "{{ app.env }}"
      Deployed_by: "Ansible"
  register: subnet_web01</pre>
			<p>Things start simple enough in that we use the output register from when we created the VPC to get the ID of the VPC to attach the subnet to by using <code>"{{ </code><code>vpc.vpc.id }}"</code>.</p>
			<p>Next, we use the output register again to get the CIDR range from the VPC output register; however, we take that value and use the <code>ansible.utils.ipsubnet</code> function to work out what the first <code>/27</code> in the CIDR range will be.</p>
			<p>As we have passed in <code>10.0.0.0/24</code>, running <code>ansible.utils<a id="_idTextAnchor299"/>.ipsubnet(27, 0)</code> should give us <code>10.0.0.0/27</code>. The keen-eyed among you may have noticed that we passed in <code>0</code> rather than <code>1</code>. Ansible always counts from 0, so if we had used <code>1</code>, then we would have gotten <code>10.0.0.32/27</code>, which is what we need to use for the second subnet.</p>
			<p>The second exciting thing we are doing is taking the output of the <code>zone</code> register, which contains information on the region we are using, including a list of the Availab<a id="_idTextAnchor300"/>ility <a id="_idTextAnchor301"/>Zones. So, when we use <code>{{ zones.availability_zones[0].zone_name }}</code>, it is taking the zone name for the first result, that is, <code>0</code>.</p>
			<p>The advantage of this approach in populating information for the CIDR and Availability Zone for the subnet is that we do not have to hardcode those details as variables. If we change the CIDR range or regions, the information would be programmatically generated to consider those changes.</p>
			<p>When you <a id="_idIndexMarker273"/>write your Ansible playbooks, anything you can do to have your playbook adapt to user input or change dynamically <a id="_idIndexMarker274"/>is considered a best practice as it not only simplifies the information your consumers need to know but also makes the code reusable.</p>
			<p>The rest of the task is populated using mostly static variables, so less interesting than what we have just covered.</p>
			<p>This is then repeated for the second web subnet and the two subnets used with Amazon RDS – all we do is increment the numbers being passed to <code>ansible.utils.ipsubnet</code> and <code>zones.availability_zones</code>.</p>
			<p>Once the subnets have been defined, we create an internet gateway using <code>amazon.aws.ec2_vpc_igw</code>. Following that, we create a route table to take advantage of the gateway using <code>amazon.aws.ec2_vpc_route_table</code>.</p>
			<p>This is attached to the two web subnets and forwards all outgoing traffic to our internet gateway.</p>
			<p>The next batch of tasks creates three security groups using the <code>amazon.aws.ec2_security_group</code> module.</p>
			<p>The first of the three security groups will be assigned to the admin/web EC2 instances and the elastic load balancer. It opens ports <code>80</code> and <code>22</code> to the world, making them publicly accessible.</p>
			<p class="callout-heading">Information</p>
			<p class="callout">For ease of use, I am opening port <code>22</code> to the world. In your production deployments, you should not do this and lock access down to one or more trusted IP addresses.</p>
			<p>The next two security groups will be attached to the Amazon RDS and EFS services.</p>
			<p>However, rather than defining source IP range(s), we are passing in the ID of the first security group we created, which means that ports <code>3306</code> (MySQL) and <code>2049</code> (NFS) will only be access to resources, which in our case is going to be the admin and web EC2 instances. The first security group attached will be able to access those services.</p>
			<p>The final <a id="_idIndexMarker275"/>two tasks configure and launch <a id="_idIndexMarker276"/>the application load balancer. The first of the following two tasks is shown here and creates an empty ELB target group:</p>
			<pre class="source-code">
-<a id="_idTextAnchor302"/> name: Create an ELB target group
  community.aws.elb_target_group:
    name: "{{ alb_target_group_name }}"
    protocol: "HTTP"
    port: "80"
    vpc_id: "{{ vpc.vpc.id }}"
    region: "{{ region }}"
    state: "present"
    modify_targets: false
    tags:
      Name: "{{ alb_target_group_name }}"
      Description: "{{ dict.ansible_warning }}"
      Project: "{{ app.name }}"
      Environment: "{{ app.env }}"
      Deployed_by: "Ansible"
  register: alb_target_group</pre>
			<p>On the face of it, there does not appear to be anything too special about that, so why have I called it out?</p>
			<p>At the time of writing, there is no module for creating an ELB target group using the <code>amazon.aws</code> collection; so instead, we have switched to using the <code>community.aws</code> collection. The developers use this collection as a staging ground for new features, and we will bounce between these two collections throughout the playbook.</p>
			<p class="callout-heading">Information</p>
			<p class="callout">As modules may be promoted from being hosted in the <code>community.aws</code> collection to the <code>amazon.aws</code> collection in the future, please refer to the code in the GitHub repository that accompanies this book for the most recent updates.</p>
			<p>The final <a id="_idIndexMarker277"/>task of the role is to create the <a id="_idIndexMarker278"/>application load balancer. Here, we use the <code>amazon.aws.elb_application_lb</code> module and several output registers we have created so far in the playbook run.</p>
			<p>That concludes all the tasks we need to run to deploy the underlying network and supporting services. Now that we have those resources in place, we can deploy the storage for our WordPress installation.</p>
			<h3>The AWS Storage role</h3>
			<p>This is <a id="_idIndexMarker279"/>a simple role that contains a single <a id="_idIndexMarker280"/>task:</p>
			<pre class="source-code">
- name: Create the EFS resource
  community.aws.efs:
    name: "{{ efs_name }}"
    state: present
    region: "{{ region }}"
    targets:
      - subnet_id: "{{ subnet_web01.subnet.id }}"
        security_groups: ["{{ security_group_efs.group_id }}"]
      - subnet_id: "{{ subnet_web02.subnet.id }}"
        security_groups: ["{{ security_group_efs.group_id }}"]
    tags:
      Name: "{{ efs_name }}"
      Description: "{{ dict.ansible_warning }}"
      Project: "{{ app.name }}"
      Environment: "{{ app.env }}"
      Deployed_by: "Ansible"
  register: efs</pre>
			<p>As you <a id="_idIndexMarker281"/>can see, it uses the <code>community.aws.efs</code> module to create the Amazon EFS share, creating a target endpoint in <a id="_idIndexMarker282"/>our two web subnets. This step is important as EFS has a different DNS endpoint in each availability zone, so without this, we would be unable to connect to the NFS share in both of our web subnets.</p>
			<h3>The AWS Database role</h3>
			<p>Before we <a id="_idIndexMarker283"/>launch our EC2 instances, we need <a id="_idIndexMarker284"/>to have the MySQL Amazon RDS instance ready. This role contains two tasks – the first of which creates an RDS subnet group using the <code>amazon.aws.rds_subnet_group</code> module. Once we have the subnet group, the <code>amazon.aws.rds_instance</code> module is then used to create the RDS instance itself.</p>
			<p>There isn’t much to this role, but we now have an Amazon RDS instance<a id="_idTextAnchor303"/> and can start deploying our EC2 instances.</p>
			<h3>The AWS VM Admin role</h3>
			<p>Like in <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to Microsoft Azure</em>, we will deploy a single instance using a <code>cloud-init</code> script to <a id="_idIndexMarker285"/>bootstrap <a id="_idIndexMarker286"/>our WordPress installation.</p>
			<p>The variables that we are going to be using for both this role and the next, which configures the ASG-managed EC2 instances, are as follows:</p>
			<pre class="source-code">
ec2:
  instance_type: "t2.micro"
  public_ip: true
  asg:
    min_size: 1
    max_size: 3
    desired_capacity: 2
  ami:
    owners: "099720109477"
    filters:
      name: "ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*"
      virtualization_type: "hvm"</pre>
			<p>The fi<a id="_idTextAnchor304"/>rst <a id="_idIndexMarker287"/>task that we will perform is generating <a id="_idIndexMarker288"/>a temporary file:</p>
			<pre class="source-code">
- name: Generate temp admin cloud-init file
  ansible.builtin.tempfile:
  register: tmp_file_create_cloud_init_admin_task</pre>
			<p>We will render the template file in <code>templates/vm-cloud-init-admin.yml.j2</code> and place the rendered contents in the temporary file we just created:</p>
			<pre class="source-code">
- name: Create the admin cloud-init file from a template file
  ansible.builtin.template:
    src: "vm-cloud-init-admin.yml.j2"
    dest: "{{ tmp_file_create_cloud_init_admin_task.path }}"</pre>
			<p>With the <code>cloud-init</code> file prepared, we can move on to the next step: figure out the ID of <a id="_idIndexMarker289"/>the <strong class="bold">Amazon Machine Image</strong> (<strong class="bold">AMI</strong>) we need to use:</p>
			<pre class="source-code">
- name: gather information about AMIs with the specified filters
  amazon.aws.ec2_ami_info:
    region: "{{ region }}"
    owners: "{{ ec2.ami.owners }}"
    filters:
      name: "{{ ec2.ami.filters.name }}<a id="_idTextAnchor305"/>"
      virtualization-type: "{{ ec2.ami.filters.virtualization_type }}"
  re<a id="_idTextAnchor306"/>gister: ubuntu_ami_info</pre>
			<p>As the AMI’s maintainer, <strong class="bold">Canonical</strong>, which also develops Ubuntu, keeps the AMI up to date with <a id="_idIndexMarker290"/>patches and so on, a long list <a id="_idIndexMarker291"/>of AMIs will be returned as there are multiple versions.</p>
			<p>Our next task sorts that list and takes the last item:</p>
			<pre class="source-code">
- name: filter the list of AMIs to find the latest one<a id="_idTextAnchor307"/>
  set_fact:
  <a id="_idTextAnchor308"/>  ami: "{{ ubuntu_ami_info.images | sort(attribute='creation_date') | last }}"</pre>
			<p>As you can see in the preceding code snippet, we are using the <code>sort</code> function to sort the list, which is JSON, by the <code>creation_date</code> attribute and then taking the <code>last</code> result. This leaves us with the details of the most recent AMI that Canonical has published.</p>
			<p>Now we have everything we need to launch our admin EC2 instance:</p>
			<pre class="source-code">
- name: create the admin ec2 instance
  amazon.aws.ec2_instance:
    name: "{{ ec2_instance_name_admin }}"
    region: "{{ region }}"
    vpc_subnet_id: "{{ subnet_web01.subnet.id }}"
    instance_type: "{{ ec2.instance_type }}"
    security_group: "{{ security_group_web.group_name }}"
    network:
      assign_public_ip: "{{ ec2.public_ip }}"
    image_id: "{{ ami.image_id }}"
    user_data: "{{ lookup('file', tmp_file_create_cloud_init_admin_task.path) }}"
    tags:
      Name: "{{ ec2_instance_name_admin }}"
      Description: "{{ dict.ansible_warning }}"
      Project: "{{ app.name }}"
      Environment: "{{ app.env }}"
      Deployed_by: "Ansible"
  register: ec2_instance_admin</pre>
			<p>As you <a id="_idIndexMarker292"/>can see, most all the information <a id="_idIndexMarker293"/>needed to deploy the instance is a variable, either a hardcoded one, such as <code>instance_type</code>, or one that is an output variable, like the one for <code>image_id</code>, which is the one we just gathered the information for.</p>
			<p>For <code>user_data</code>, we are using the <code>lookup</code> function to read the contents of the temporary file we populated with the <code>cloud-init</code> script, which we will talk about in a moment.</p>
			<p>Now that we have an EC2 instance, we need to register it in the ELB target group we created in the Network role, but we can only do this if the instance has a state of <code>running</code>.</p>
			<p>Our Ansible playbook can progress a little too quickly, and the instance may not yet have entered that state, so we need to create a bit of logic that will pause the playbook execution and <a id="_idIndexMarker294"/>wait for the instance to have the correct state before progressing.</p>
			<p>We can <a id="_idIndexMarker295"/>do this with the following task:</p>
			<pre class="source-code">
- name: Get information about the admin EC2 instance to see if its running
  amazon.aws.ec2_instance_info:
    region: "{{ region }}"
    filters:
      instance-id: "{{ ec2_instance_admin.instances[0].<a id="_idTextAnchor309"/>instance_<a id="_idTextAnchor310"/>id }}"
  registe<a id="_idTextAnchor311"/>r: admin_ec2_instance_state
  delay: 5
  retries: 50
  until: admin_ec2_instance_state.instances[0].state.name == "running"</pre>
			<p>The task itself is quite simple; it uses the <code>amazon.aws.ec2_instance_info</code> module to gather information on the EC2 instance we have just launched.</p>
			<p>On its own, this task would be pretty useless as it would gather the information once and then move on. The three lines at the end are bits that add the logic we need.</p>
			<p>Using the <code>until</code> function, we take our output<a id="_idTextAnchor312"/> register, <code>admin_ec2_instance_state</code>, an<a id="_idTextAnchor313"/>d check whether <code>state.name</code> is equal to<a id="_idTextAnchor314"/> <code>running</code>:</p>
			<pre class="source-code">
until: admin_ec2_insta<a id="_idTextAnchor315"/>nce_state.instances[0].state.name == "running"</pre>
			<p>If the <code>state.name</code> variable does not equal <code>running</code>, then retry 50 times every 5 seconds:</p>
			<pre class="source-code">
retries: 50
delay: 5</pre>
			<p>Continue until <code>state.name</code> equals <code>running</code>.</p>
			<p>Once this <a id="_idIndexMarker296"/>condition is met, we know it <a id="_idIndexMarker297"/>will be safe to move on to the next task, and we won’t get any errors because the state of the instance is incorrect:</p>
			<pre class="source-code">
- name: Update the ELB target group
  community.aws.elb_target_group:
    name: "{{ alb_target_group_name }}"
    protocol: "HTTP"
    port: "80"
    vpc_id: "{{ vpc.vpc.id }}"
    region: "{{ region }}"
    state: "present"
    modify_targets: true
    targets:
      - Id: "{{ ec2_instance_admin.instances[0].instance_id }}"
        Port: 80</pre>
			<p>So, we now have our admin EC2 instance running and registered with the ELB target group and the <code>cloud-init</code> script running. Well, sort of – we need to make a few adjustments to the <code>cloud-init</code> script from when we last looked at it in <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to Microsoft Azure</em>. Most of it is as we used it when deploying to Azure, with one additional piece of logic we needed to b<a id="_idTextAnchor316"/>uild in:</p>
			<pre class="source-code">
  # Mount the NFS share and add it to f<a id="_idTextAnchor317"/>stab
<strong class="bold">  - until nc -vzw 2 {{ efs.efs.filesystem_address | regex_replace("[^A-Za-z0-9.-]", "") }} 2049; do sleep 2; done; mount -t nfs4 {{ efs.efs.filesystem_address }} /var/www/html -o vers=4,minorversion=1,sec=sys</strong>
  - echo "{{ efs.efs.filesystem_address }} /var/www/html nfs4 vers=4,minorversion=1,sec=sys" | sudo tee --append /etc/fstab</pre>
			<p>As you can see from the preceding code snippet, there is a change to the line that mounts the NFS share provided by the Amazon EFS service – why have we needed to make this change?</p>
			<p>If you remember, back when we launched the Amazon EFS service, we talked about the unique DNS endpoints being registered automatically in each subnet. To get around having <a id="_idIndexMarker298"/>to build the logic into our deployment <a id="_idIndexMarker299"/>to figure out which availability zone we are running our instances in so we can use the right DNS name for our Amazon EFS endpoint, a generic endpoint, <code>CNAME</code>, is created, which resolves to the appropriate endpoint for the subnet.</p>
			<p>Great, you might be thinking that that saves us the hassle of having to code something to take this into account – and you would be correct, but it can take a while for this DNS alias to propagate.</p>
			<p>As the <code>cloud-init</code> script is running completely independently of our Ansible playbook run, we can’t use a conditional like the one that we just discussed for waiting, for instance, to have the correct state before progressing.</p>
			<p>So, to get<a id="_idTextAnchor318"/> around this, we are adding the following:</p>
			<pre class="source-code">
until nc -vzw 2 somedns.domain.com 2049; do sleep 2;
done;</pre>
			<p>This is the Bash equivalent of the condition w<a id="_idTextAnchor319"/>e added before. It will run the netcat (<code>nc</code>) command to see whether <code>somedns.domain.com</code> is responding on port <code>2049</code>. If it isn’t, it will wait for two seconds using the <code>sleep</code> command and then repeat until we get the correct response.</p>
			<p>You may have also noticed that we are using another Ansible function to get the details on the Amazon EFS endpoint from our output register.</p>
			<p>By default, if we were to just use <code>{{ efs.efs.filesystem_address }}</code>, it would return the fully qualified domain name for our Amazon EFS endpoint with the fi<a id="_idTextAnchor320"/>lesystem path appended to the end of it, which in our case is <code>:/</code>.</p>
			<p>This is not a valid address for the <code>nc</code> command to use, so we need to remove the <code>:/</code> from the address. To do this, we can use Ansible’s <code>regex_replace</code> function, as we want to remove everything that isn’t a regular character, dot, or hyphen. Then, this looks like the following:</p>
			<pre class="source-code">
{{ efs.efs.filesystem_address | regex_replace("[^A-Za-z0-9.-]", "") }}</pre>
			<p>This code should leave us with, for example, <code>somedns.domain.com</code> rather than <code>somedns.domain.com:/</code>.</p>
			<p>The rest <a id="_idIndexMarker300"/>of the script remains intact. We <a id="_idIndexMarker301"/>also must use the same logic as previously for the cut-down version of the <code>cloud-init</code> script being used for the web EC2 instances being deployed using the ASG, which we will look at next.</p>
			<h3>The AWS ASG role</h3>
			<p>This role <a id="_idIndexMarker302"/>follows a similar pattern to the AWS VM <a id="_idIndexMarker303"/>Admin role, starting with generating the <code>cloud-init</code> script:</p>
			<pre class="source-code">
- name: Generate temp web cloud-init file
  ansible.builtin.tempfile:
  register: tmp_file_create_cloud_init_web_task
- name: Create the web cloud-init file from a template file
  ansible.builtin.template:
    src: "vm-cloud-init-web.yml.j2"
    dest: "{{ tmp_file_create_cloud_init_web_task.path }}"</pre>
			<p>We then need to<a id="_idTextAnchor321"/> create a launch configuration:</p>
			<pre class="source-code">
- name: Create launch config
  community.aws.autoscaling_launch_config:
    name: "{{ lauch_configuration_name }}"
    image_id: "{{ ami.image_id }}"
    region: "{{ region }}"
    security_groups: "{{ security_group_web.group_name }}"
    instance_type: "{{ ec2.instance_type }}"
    assign_public_ip: "{{ ec2.public_ip }}"
    user_data: "{{ lookup('file', tmp_file_create_cloud_init_web_task.path) }}"</pre>
			<p>As you can see, this uses the <code>community.aws.autoscaling_launch_config</code> module <a id="_idIndexMarker304"/>as there is currently no official support in the <code>amazon.aws</code> collection <a id="_idIndexMarker305"/>for the creation of launch configurations.</p>
			<p>The final task in the role, and also the final one where we will target AWS directly, is as follows:</p>
			<pre class="source-code">
- name: Create the Auto Scaling Group
  amazon.aws.autoscaling_group:
    name: "{{ asg_name }}"
    region: "{{ region }}"
    target_group_arns:
      - "{{ alb_target_group.target_group_arn }}"
    availability_zones:
      - "{{ zones.availability_zones[0].zone_name }}"
      - "{{ zones.availability_zones[1].zone_name }}"
    launch_config_name: "{{ lauch_configuration_name }}"
    min_size: "{{ ec2.asg.min_size <a id="_idTextAnchor322"/>}}"
    max_size: "{{ ec2.asg.max_size }}"
    desired_capacity: "{{ ec2.asg.desired_capacity }}"
    vpc_zone_identifier:
      - "{{ subnet_web01.subnet.id }}"
      - "{{ subnet_web02.subnet.id }}"
    tags:
      - Name: "{{ asg_name }}"
      - Description: "{{ dict.ansible_warning }}"
      - Project: "{{ app.name }}"
      - Environment: "{{ app.env }}"
      - Deployed_by: "Ansible"</pre>
			<p>This creates <a id="_idIndexMarker306"/>the ASG, which will immediately start <a id="_idIndexMarker307"/>to launch however many instances we have defined in the <code>{{ ec2.asg.desired_capacity }}</code> variable.</p>
			<p>All values are again filled using hardcoded variables like the one we just mentioned or output registers.</p>
			<h3>The Output role</h3>
			<p>All that is left <a id="_idIndexMarker308"/>now is to print some information to the terminal containing <a id="_idIndexMarker309"/>the URL we need to open to visit our WordPress installation and the credentials needed to log in:</p>
			<pre class="source-code">
- name: Output details on the deployment
  ansible.builtin.debug:
    msg:
      - "Wordpress Admin Username: {{ wordpress.wp_admin_user }}"
      - "Wordpress Admin Password: {{ wp_password }}"
      - "Wordpress URL: http://{{ alb.dns_name }}/"</pre>
			<p>That concludes our Ansible p<a id="_idTextAnchor323"/>laybook, so let’s look at executing it.</p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor324"/>Running the Ansible playbook</h2>
			<p>The command <a id="_idIndexMarker310"/>to run the playbook is the same as we used in <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to </em><em class="italic">Microsoft Azure</em>:</p>
			<pre class="source-code">
$ ansible-playbook site.yml</pre>
			<p><a id="_idTextAnchor325"/>Once finished, you should see something like the following output:</p>
			<div><div><img src="img/Figure_5.04_B19537.jpg" alt="Figure 5.4 – The last few lines of the playbook run output" width="1650" height="779"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4 – The last few lines of the playbook run output</p>
			<p>If you were watching the output, you might have noticed where we put in the logic to wait for the admin EC2 instances to enter the <code>run<a id="_idTextAnchor326"/>ning</code> state. Those lines can be found in the following screenshot:</p>
			<div><div><img src="img/Figure_5.05_B19537.jpg" alt="Figure 5.5 – Waiting for the instance to have a state of running" width="1650" height="476"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.5 – Waiting for the instance to have a state of running</p>
			<p>You can now follow the URL in the output and take a look at your WordPress installation. It should look like the Azure installation did in <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to Microsoft Azure</em>, and the AWS resources in the AWS Management Console at <a href="http://console.aws.amazon.com">http://console.aws.amazon.com</a>.</p>
			<p>Once you are finished looking around, you can terminate all of the resources launched by the playbook by running the following command:</p>
			<pre class="source-code">
$ ansible-playbook destory.yml</pre>
			<p>You may <a id="_idIndexMarker311"/>notice that a lot more is happening, as seen in the following output:</p>
			<div><div><img src="img/Figure_5.06_B19537.jpg" alt="Figure 5.6 – Deleting all of the resources" width="1650" height="486"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.6 – Deleting all of the resources</p>
			<p> In fact, there are nearly 20 tasks compared to the small handful when we ran the same playbook in <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to Microsoft Azure</em>; why is that?</p>
			<p>This is another difference between Microsoft Azure and AWS. When we deployed the resources in Microsoft Azure, we deployed them to a single resource group, which acts as a logical container for your workload, collecting all its resources together.</p>
			<p>When we came to terminate our Microsoft Azure deployment, we had to remove the resource group and all the resources contained within it in a single task.</p>
			<p>However, AWS is very different, and we need to build a playbook to terminate the resources in the rev<a id="_idTextAnchor327"/>erse order in which we deployed them.</p>
			<p>Some of the tasks used in the <code>destroy.yml</code> file reuse a little of the logic we used in the roles to deploy the resources, so before we look at using Terraform in AWS, let’s quickly discuss the <code>destroy.yml</code> playbook, starting with the A<a id="_idTextAnchor328"/>uto Scaling group which will remove the instances we have launched.</p>
			<h3>Auto Scaling group</h3>
			<p>There are three tasks that deal with removing the ASG; the first task uses the <code>amazon.aws.autoscaling_group_info</code> module to get information on the ASG.</p>
			<p>The second <a id="_idIndexMarker312"/>task uses the <code>amazon.aws.autoscaling_group</code> module with just enough configuration to allow us to set <code>state</code> to <code>absent</code> – but only when there are more than 0 results returned from the previous task. To do this, we use the following line:</p>
			<pre class="source-code">
when: asgs.results | length &gt; 0</pre>
			<p>This means <a id="_idIndexMarker313"/>that the task will be skipped if the ASG has been removed, but we need to rerun the playbook because of another failed task. We will be using this logic throughout this playbook.</p>
			<p>The final of the three tasks removes the launch configuration using the <code>community.aws.autoscaling_launch_config</code> module.</p>
			<h3>EC2 instance</h3>
			<p>Just the <a id="_idIndexMarker314"/>two tasks are required here, one that uses <code>amazon.aws.ec2_instance_info</code> to get information on our EC2 instances, and the second <a id="_idIndexMarker315"/>that uses <code>amazon.aws.ec2_instance</code> to set <code>state</code> to <code>absent</code> if the first task returns a result.</p>
			<h3>RDS instance</h3>
			<p>There are <a id="_idIndexMarker316"/>three tasks here. The first gets information, the <a id="_idIndexMarker317"/>second terminates the RDS instance, and the third removes the RDS subnet group.</p>
			<h3>EFS instance</h3>
			<p>Just a single <a id="_idIndexMarker318"/>task is required here; it uses <code>community.aws.efs</code> to ensure <a id="_idIndexMarker319"/>that any resources matching <code>{{ efs_name }}</code> in the region defined by <code>{{ region }}</code> are absent.</p>
			<h3>Elastic load balancer</h3>
			<p>Here <a id="_idIndexMarker320"/>we have <a id="_idIndexMarker321"/>two more simple tasks that use <code>amazon.aws.elb_application_lb</code> and <code>community.aws.elb_target_group</code> to set our <code>state</code> resource to <code>absent</code>.</p>
			<h3>Security groups</h3>
			<p>If you remember, when we added the security groups, we used the ID of the Web security group <a id="_idIndexMarker322"/>to allow access to the RDS and EFS resources. Also, as we discussed when launching the EC2 instance, the Ansible playbook can <a id="_idIndexMarker323"/>sometimes be a little ahead of the AWS API when it comes to completing tasks, meaning that Ansible could be trying to move on to the next task before AWS has completed processing<a id="_idTextAnchor329"/> an earlier task.</p>
			<p>Because of this, there is the risk that either the RDS or EFS security group may not be fully removed before the playbook attempts to remove the web security group, which would result in a dependency error.</p>
			<p>To avoid this, we have a little checking built into the task:</p>
			<pre class="source-code">
    - name: Delete the security groups
      amazon.aws.ec2_security_group:
        name: "{{ item }}"
        region: "{{ region }}"
        state: absent
      with_items:
        - "{{ vpc_security_group_name_efs }}"
        - "{{ vpc_security_group_name_rds }}"
        - "{{ vpc_security_group_name_web }}"
      register: delelte_security_groups
      until: "delelte_security_groups is not failed"
      retries: 25
      delay: 10</pre>
			<p>As you can see, we are using <code>with_items</code> to loop through our three security groups and set their <code>state</code> to <code>absent</code>. We also have an <code>until</code> set, which will repeat whichever <a id="_idTextAnchor330"/>part of the loop fails until it has successfully removed the security group:</p>
			<div><div><img src="img/Figure_5.07_B19537.jpg" alt="Figure 5.7 – Setting the state of the security groups to absent" width="1650" height="338"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.7 – Setting the state of the security groups to absent</p>
			<p>It will <a id="_idIndexMarker324"/>allow for 25 failures and will try every 10 seconds. As you <a id="_idIndexMarker325"/>can see from the preceding screenshot, it should only fail once or twice before moving on.</p>
			<h3>Virtual Private Cloud</h3>
			<p>The remaining <a id="_idIndexMarker326"/>tasks all work in the same pattern as we defined <a id="_idIndexMarker327"/>previously, apart from the route table. Like other resources, we use a module, <code>amazon.aws.ec2_vpc_route_table_info</code> in this case, to get information on the route tables. However, the difference here is that it will return the default route table, which was created when we first launched the VPC. This one will error if we try to remove it.</p>
			<p>To get around this, we have to extend the <code>when</code> clause in the task:</p>
			<pre class="source-code">
    - name: Delete the Route Table
      amazon.aws.ec2_vpc_route_table:
        route_table_id: "{{ item.route_table_id }}"
        vpc_id: "{{ the_vpc.vpcs[0].id }}"
        region: "{{ region }}"
        lookup: id
        state: absent
      when: the_vpc.vpcs | length &gt; 0 and item.associations[0].main != true
      with_items: "{{ the_route_tables.route_tables }}"</pre>
			<p>As you can see, this will remove the route table if there are more than zero of them listed and it<a id="_idTextAnchor331"/> is not the <code>main</code> association. This looks something like the following when run:</p>
			<div><div><img src="img/Figure_5.08_B19537.jpg" alt="Figure 5.8 – Removing our custom route table but skipping the main one" width="1650" height="665"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.8 – Removing our custom route table but skipping the main one</p>
			<p>The remaining <a id="_idIndexMarker328"/>tasks follow the same patterns <a id="_idIndexMarker329"/>we used elsewhere in the chapter when we launched the resources.</p>
			<p class="callout-heading">Information</p>
			<p class="callout">Remember to make sure that all the resources have been removed by checking to see whether <a id="_idIndexMarker330"/>they are still listed in the AWS Management Console at <a href="http://console.aws.amazon.com">http://console.aws.amazon.com</a>, as you could incur unexpected costs if the preceding playbook failed for any reason.</p>
			<p>That is the end of the playbook, which removes the resources and concludes our deep dive into running Ansible on AWS.</p>
			<p>Now it is time to move on to Terraform.</p>
			<h1 id="_idParaDest-84"><a id="_idTextAnchor332"/>Terraform – reviewing the code and deploying our infrastructure</h1>
			<p>As we did <a id="_idIndexMarker331"/>a deep dive into Terraform in <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to Microsoft Azure</em>, we aren’t going to dig too deep into the code here, and instead <a id="_idIndexMarker332"/>will just highlight any considerations we need to make when targeting AWS or if there is a function we didn’t use when deploying our workload to Microsoft Azure.</p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor333"/>Walk-through of Terraform files</h2>
			<p>What follows <a id="_idIndexMarker333"/>is a walk-through of each of the Terraform files. Just as we did for Microsoft Azure, I have grouped each logical group of resources in its own <code>.</code><code>tf</code> file.</p>
			<h3>Setup</h3>
			<p>This is not too <a id="_idIndexMarker334"/>dissimilar to the one we defined for Azure. There are a few obvious differences – the biggest of which is that we are using the AWS provider:</p>
			<pre class="source-code">
    aws = {
      source  = "hashicorp/aws"
      version = "~&gt; 4.0"
    }</pre>
			<p>Also, we are hardcoding the region we want to launch our resources in as a provider configuration option:</p>
			<pre class="source-code">
provider "aws" {
  region = "us-east-1"
}</pre>
			<p>There are a few omissions in that we are not loading any helper providers or modules to assist us with resource naming; that is going to be up to us to define as we launch our resources.</p>
			<h3>N<a id="_idTextAnchor334"/><a id="_idTextAnchor335"/>etworking</h3>
			<p>There are <a id="_idIndexMarker335"/>several tasks here:</p>
			<ul>
				<li><code>resource "aws_vpc" "vpc"</code>, which launches the VPC</li>
				<li><code>resource "aws_subnet" "web01<a id="_idTextAnchor336"/>"</code>, which adds the <code>web01</code> subnet</li>
				<li><code>resource "aws_subnet" "web02"</code>, which adds the <code>web02</code> subnet</li>
				<li><code>resource "aws_subnet" "rds01"</code>, which adds the <code>rds01</code> subnet</li>
				<li><code>resource "aws_subnet" "rds02"</code>, which adds the <code>rds02</code> subnet</li>
			</ul>
			<p>The four subnet tasks all look similar:</p>
			<pre class="source-code">
r<a id="_idTextAnchor337"/>esource "aws_subnet" "web01" {
  vpc_id            = aws_vpc.vpc.id
  cidr_block        = cidrsubnet("${aws_vpc.v<a id="_idTextAnchor338"/>pc.cidr_block}", 3, 0)
  availability_zone = var.zones[0]
  tags              = merge(var.default_tags, tomap({ Name = "${var.name}-${var.environment_type}-web01-subnet" }))
}</pre>
			<p>As you can see, there is a slight difference in the way we are defining the CIDR range for each subnet; rather than hardcode it as we did for Microsoft Azure, we are following a similar pattern as we did when using Ansible and are using a Terraform function called <code>cidrsubnet</code> to generate the correct CIDR range for us.</p>
			<p>The only other to note is that we are taking the list of <code>default_tags</code> we are defining in our <code>tfvars</code> file and merging it with a map we are dynamically creating using the <code>tomap</code> function. This map name contains the <code>Name</code> tag. We will be reusing this approach throughout the remainder of the deployment.</p>
			<p>The remaining tasks are very similar to the ones we performed when deploying using Ansible:</p>
			<ul>
				<li><code>resource "aws_internet_gateway" "vpc_igw"</code>, which deploys an internet gateway.</li>
				<li><code>resource "aws_route_table" "vpc_igw_route"</code>, which adds a route table to route all outgoing traff<a id="_idTextAnchor339"/>ic to the internet gateway.</li>
				<li><code>resource "aws_route_table_association" "rta_subnet_public01"</code>, which associates the route table we just created with the <code>web01</code> subnet.</li>
				<li><code>resource "aws_route_table_association" "rta_subnet_public02"</code>, which associates the route table we just created with the <code>web02</code> subnet.</li>
				<li><code>resource "aws_security_group" "sg_vms"</code>, which creates a security group <a id="_idIndexMarker336"/>open<a id="_idTextAnchor340"/>ing ports <code>80</code> and <code>22</code> to everyone, that is, <code>0.0.0.0/0</code>.</li>
				<li><code>resource "aws_security_group" "sg_efs"</code>, which adds the EFS security group opening port <code>2049</code> to any resource with the web security group attached.</li>
				<li><code>resource "aws_security_group" "sg_rds"</code>, which creates the RDS security group opening port <code>3306</code> to any resource with the web security group attached.</li>
				<li><code>resource "aws_lb" "lb"</code>, which creates an elastic load balancer with a type of <code>application</code>.</li>
				<li><code>resource "aws_lb_target_group" "front_end"</code>, which creates the target group we will be registering our EC2 instances with.</li>
				<li><code>resource "aws_lb_listener" "front_end"</code>, which configures the frontend listener for port <code>80</code> on the elastic load balancer. When we launched our workload using Ansible, this was defined in line when creating the ELB resource.</li>
			</ul>
			<p>That is all the network resources we need to launch and configure to support the remaining services for our workload. Now we can start defining the resources themselves.</p>
			<h3>Storage</h3>
			<p>There are <a id="_idIndexMarker337"/>three tasks in this file, which are as follows:</p>
			<ul>
				<li><code>resource "aws_efs_file_system" "ef<a id="_idTextAnchor341"/>s"</code>, which creates the Amazon EFS volume</li>
				<li><code>resource "aws_efs_mount_target" "efs_mount_targets01"</code>, which creates the mount target in the <code>web01</code> subnet</li>
				<li><code>resource "aws_efs_mount_target" "efs_mount_targets02"</code>, which creates the mount target in the <code>web02</code> subnet</li>
			</ul>
			<p>Now that our storage is in place, we can move into the Amazon RDS instance.</p>
			<h3>Database</h3>
			<p>Again, we have <a id="_idIndexMarker338"/>just three tasks defined here to configure and launch our Amazon RDS instance. They are as follows:</p>
			<ul>
				<li><code>resource "aws_db_subnet_group" "database"</code>, which creates the subnet group so that our Amazon RDS instance is accessible from within our VPC</li>
				<li><code>resource "random_password" "database_password"</code>, which randomly generates the password we will be using when launching the Amazon RDS service</li>
				<li><code>resource "aws_db_instance" "database"</code>, which deploys the Amazon RDS instance into the subnet group we defined and configures it per the variables we have defined in the <code>variables</code> file</li>
			</ul>
			<p>As you already know, as we are following the steps we took when launching the workload with Ansible, it is now time to launch the Admin EC2 instance and bootstrap WordPress.</p>
			<h3>Virtual machine (admin)</h3>
			<p>First of all, we need <a id="_idIndexMarker339"/>to find the right AMI to use. This slightly differs from how we achieved this using Ansible, as Terraform ca<a id="_idTextAnchor342"/>n pick the lat<a id="_idTextAnchor343"/>est one for us as part of the task execution:</p>
			<pre class="source-code">
data "aws_ami" "ubuntu_admin" {
  most_recent = var.ami_most_recent
  owners      = [var.ami_owners]
  filter {
    name   = "name"
    values = [var.ami_filter_name]
  }
  filter {
    name   = "virtualization-type"
    values = [var.ami_filter_virtualization_type]
  }
}</pre>
			<p>As you <a id="_idIndexMarker340"/>can see, we are setting the <code>most_recent</code> key to be the value of the <code>var.ami_most_recent</code> variable, which by default is set to <code>true</code>.</p>
			<p>Before we launch the EC2 instance, we have one last bit of housekeeping to do, and that is to create the WordPress admin password:</p>
			<pre class="source-code">
resource "random_password" "wordpress_admin_password" {
  length           = 16
  special          = true
  override_special = "_%@"
}</pre>
			<p>Now we have everything we need to launch our EC2 instance. To start, we define the basics needed to launch the instance:</p>
			<pre class="source-code">
resource "aws_instance" "admin" {
  ami  = data.aws_ami.ubuntu_admin.id
  instance_type = var.instance_type
  subnet_id = aws_subnet.web01.id
  associate_public_ip_address = true
  availability_zone = var.zones[0]
  vpc_security_group_ids = [aws_security_group.sg_vms.id]</pre>
			<p>The ne<a id="_idTextAnchor344"/>xt <a id="_idIndexMarker341"/>part of the task is where the user data is defined. More on that in a second:</p>
			<pre class="source-code">
  user_data = templatefile("vm-cloud-init-admin.yml.tftpl", {
    tmpl_database_username = "${var.database_username}"
    tmpl_database_password = "${random_password.database_password.result}"
    tmpl_database_hostname = "${aws_db_instance.database.address}"
    tmpl_database_name     = "${var.database_name}"
    tmpl_file_share        = "${aws_efs_file_system.efs.dns_name}"
    tmpl_wordpress_url     = "http://${aws_lb.lb.dns_name}/"
    tmpl_wp_title          = "${var.wp_title}"
    tmpl_wp_admin_user     = "${var.wp_admin_user}"
    tmpl_wp_admin_password = "${random_password.wordpress_admin_password.result}"
    tmpl_wp_admin_email    = "${var.wp_admin_email}"
  })</pre>
			<p>Finally, we define the tags, which include the resource name:</p>
			<pre class="source-code">
  tags = merge(var.default_tags, tomap({ Name = "${var.name}-${var.environment_type}-ec2-admin" }))
}</pre>
			<p>As you can see, we are using a similar logic to when we launched the workload in Microsoft Azure when injecting <code>user_data</code> by using the <code>templatefile</code> function. However, we are not having to Base64 encode it this time around.</p>
			<p>The template for the <code>cloud-init</code> file contains the same changes we made when launching <a id="_idIndexMarker342"/>the workload using Ansible, again using <code>nc</code> to check that the DNS endpoint for the NFS share is responding on port <code>2048</code> before mounting the volume. The only other differences are related to the templating functions between the two tools.</p>
			<p>The final task, <a id="_idTextAnchor345"/>l<a id="_idTextAnchor346"/>ike Ansible, is to register the newly launched EC2 instance with our ELB target group:</p>
			<pre class="source-code">
resource "aws_lb_target_group_attachment" "admin" {
  target_group_arn = aws_lb_target_group.front_end.arn
  target_id        = aws_instance.admin.id
  port             = 80
}</pre>
			<p>The final difference between using Terraform and Ansible is that we do not have to build the logic to wait for the EC2 instance to have a state of <code>running</code> in our code, as Terraform continues to poll the state of the EC2 instance until it is as desired – which by default is <code>running</code>.</p>
			<p>Any dependencies on the EC2 task, like our <code>"aws_lb_target_group_attachment" "admin"</code> task, will not error as the Ansible deployment did because the deployment won’t progress until the state is met.</p>
			<h3>Auto Scaling group (web)</h3>
			<p>As with <a id="_idIndexMarker343"/>Ansible, the final set of AWS resources we will launch is the ASG for the web servers.</p>
			<p>Again, we start with a launch configuration:</p>
			<pre class="source-code">
resource "aws_launch_configuration" "web_launch_configuration" {
  name_prefix                 = "${var.name}-${var.environment_type}-alc-web-"
  image_id                    = data.aws_ami.ubuntu_admin.id
  instance_type               = var.instance_type
  associate_public_ip_address = true
  security_groups             = [aws_security_group.sg_vms.id]
  user_data = templatefile("vm-cloud-init-web.yml.tftpl", {
    tmpl_file_share = "${aws_efs_file_system.efs.dns_name}"
  })
}</pre>
			<p>Like when <a id="_idIndexMarker344"/>we deployed in Microsoft Azure, the only variable we needed to pass into the template file was the DNS endpoint for the Amazon EFS endpoint.</p>
			<p>Now that the launch configuration is in place, we can create the ASG, which will immediately launch the number of EC2 instances we have defined in the <code>var.min_number_of_web_servers</code> variable:</p>
			<pre class="source-code">
resource "aws_autoscaling_group" "web_autoscaling_group" {
  name                 = "${var.name}-${var.environment_type}-asg-web"
  min_size             = var.min_number_of_web_servers
  max_size             = var.max_number_of_web_servers
  launch_configuration = aws_launch_configuration.web_launch_configuration.name
  target_group_arns    = [aws_lb_target_group.front_end.arn]
  vpc_zone_identifier  = [aws_subnet.web01.id, aws_subnet.web02.id]
  lifecycle {
    create_before_destroy = true
  }
}</pre>
			<p>With that <a id="_idIndexMarker345"/>task in place, we have everything needed to launch the workload, apart from the output, which tells us how to access WordPress.</p>
			<h3>Output</h3>
			<p>There are <a id="_idIndexMarker346"/>three outputs defined here – one of which is being marked as <code>sensitive</code>:</p>
			<pre class="source-code">
output "wp_user" {
  value     = "Wordpress Admin Username: ${var.wp_admin_user}"
  sensitive = false
}
output "wp_password" {
  value     = "Wordpress Admin Password: ${random_password.wordpress_admin_password.result}"
  sensitive = true
}
output "wp_url" {
  value     = "Wordpress URL: http://${aws_lb.lb.dns_name}/"
  sensitive = false
}</pre>
			<p>This will give you the URL you can use to access your WordPress site, along with the username and password. Now we can run our Terraform script.</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor347"/>Deploying the environment</h2>
			<p>To deploy <a id="_idIndexMarker347"/>the environment, we simply need to run the following commands:</p>
			<pre class="source-code">
$ terraform init
$ terraform apply</pre>
			<p>Answering <code>yes</code> when prompted after running <code>terraform apply</code> will proceed with the deployment, and once complete, you should see something like the following screen:</p>
			<div><div><img src="img/Figure_5.09_B19537.jpg" alt="Figure 5.9 – Deploying the environment using Terraform" width="1650" height="486"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.9 – Deploying the environment using Terraform</p>
			<p>Again, like we did when deploying to Microsoft Azure, running <code>terraform output -json</code> will show the content of the <code>sensitive</code> value, meaning you can browse and log in to WordPress and review the resources in the AWS Management Console.</p>
			<p>When you have finished, you just need to run the following command:</p>
			<pre class="source-code">
$ terraform destroy</pre>
			<p>This will remove all the resources that we created using the <code>terraform apply</code> command. As always, double-check in the AWS Management Console that all of the resources have been removed correctly, as you do not want to incur any unexpected costs.</p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor348"/>Summary</h1>
			<p>In this chapter, we have done a deep dive into using Ansible to deploy our WordPress environment in AWS.</p>
			<p>After discussing what our deployment looks like, we walked through the Ansible playbook and expanded on the quick overview that we had in <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to Microsoft Azure</em>. We discussed Ansible roles and how to bootstrap one using the <code>ansible-galaxy </code><code>init</code> command.</p>
			<p>We discussed some of the built-in functions and utilities, such as <code>ipsubnet</code>, <code>sort</code>, and <code>regex_replace</code>, which we used to manipulate hardcoded and output variables. We also covered a few different approaches for building logic into our playbook tasks using functions such as <code>until</code> to make sure that our playbook does not error both when launching the resources and, just as importantly, when terminating resources. After all, we don’t want stray resources hanging around and costing money.</p>
			<p>We then took a quick look at how we would deploy the same resources using Terraform, as we had already done a deeper dive into Terraform, highlighting some additional approaches we can take when deploying resources.</p>
			<p>Throughout both walk-throughs, we also discussed the differences in the approach we needed to take to deploy our workload in AWS as opposed to Microsoft Azure.</p>
			<p>Feel free to play around with both the Ansible and Terraform code; for example, try and update the number of servers being launched, update the various SKUs, change the network addressing, and so on, and see what effects your changes have on the deployment.</p>
			<p>In the next chapter, we will expand on what we have covered in this chapter and <a href="B19537_04.xhtml#_idTextAnchor151"><em class="italic">Chapter 4</em></a>, <em class="italic">Deploying to Microsoft Azure</em>, by looking further at how the two cloud-agnostic tools we have been looking at work and what considerations we need to make when approaching the cloud providers.</p>
			<p>We will also examine how we can make our Ansible and Terraform code more reusable.</p>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor349"/>Further reading</h1>
			<p>You can find more details on the services and documentation we have mentioned in this chapter at the following URLs:</p>
			<ul>
				<li>Amazon services:<ul><li>Amazon ELB: <a href="https://aws.amazon.com/elasticloadbalancing/">https://aws.amazon.com/elasticloadbalancing/</a></li><li>Amazon EC2: <a href="https://aws.amazon.com/ec2/">https://aws.amazon.com/ec2/</a></li><li>Amazon EFS: <a href="https://aws.amazon.com/efs/">https://aws.amazon.com/efs/</a></li><li>Amazon RDS: https://aws.amazon.com/rds/</li><li>Amazon VPC: <a href="https://aws.amazon.com/vpc/">https://aws.amazon.com/vpc/</a></li><li>Amazon EC2 ASGs: <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html">https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html</a></li></ul></li>
				<li>Ansible collections:<ul><li>Amazon AWS collection: <a href="https://galaxy.ansible.com/amazon/aws">https://galaxy.ansible.com/amazon/aws</a></li><li>Community AWS collection: <a href="https://galaxy.ansible.com/community/aws">https://galaxy.ansible.com/community/aws</a></li></ul></li>
				<li>Terraform provider:<ul><li>HashiCorp AWS: <a href="https://registry.terraform.io/providers/hashicorp/aws/">https://registry.terraform.io/providers/hashicorp/aws/</a></li></ul></li>
			</ul>
		</div>
	</div>
</div>
</body></html>