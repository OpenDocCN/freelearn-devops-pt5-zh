- en: Chapter 7. Looking at Schedulers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at a few different schedulers that are capable
    of launching containers on both your own infrastructures as well as public cloud-based
    infrastructures. To start with, we will look at two different schedulers, both
    of which we will use to launch clusters on Amazon Web Services. The two schedulers
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Kubernetes**: [http://kubernetes.io/](http://kubernetes.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amazon** **ECS**: [https://aws.amazon.com/ecs/](https://aws.amazon.com/ecs/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will then take a look at a tool that offers its own scheduler as well as
    supports others:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rancher**: [http://rancher.com/](http://rancher.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's dive straight in by looking at Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes is an open source tool, originally developed by Google. It is described
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"A tool for automating deployment, operations, and scaling of containerized
    applications. It groups containers that make up an application into logical units
    for easy management and discovery. Kubernetes builds upon a decade and a half
    of experience of running production workloads at Google, combined with best-of-breed
    ideas and practices from the community." [http://www.kubernetes.io](http://www.kubernetes.io)*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'While it is not the exact tool that Google uses to deploy their containers
    internally, it has been built from the ground up to offer the same functionality.
    Google is also slowly transitioning to internally use Kubernetes themselves. It
    is designed around the following three principles:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Planet scale**: Designed on the same principles that allow Google to run
    billions of containers a week, Kubernetes can scale without increasing your ops
    team'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Never outgrow**: Whether testing locally or running a global enterprise,
    Kubernetes'' flexibility grows with you in order to deliver your applications
    consistently and easily no matter how complex your need is'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Run anywhere**: Kubernetes is open source, giving you the freedom to take
    advantage of on-premise, hybrid, or public cloud infrastructure, letting you effortlessly
    move workloads to where it matters to you'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Out of the box, it comes with quite a mature feature set:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Automatic bin packing**: This is the core of the tool, a powerful scheduler
    that makes decisions on where to launch your containers based on the resources
    currently being consumed on your cluster nodes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Horizontal scaling**: This allows you to scale up your application, either
    manually or based on CPU utilization'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Self-healing**: You can configure status checks; if your container fails
    a check, then it will be relaunched where the resource is available'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Load balancing & service discovery**: Kubernetes allows you to attach your
    containers to services, these can expose your container either locally or externally'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage orchestration**: Kubernetes supports a number of backend storage
    modules out of the box, including Google Cloud Platform, AWS, and services such
    as NFS, iSCSI, Gluster, or Flocker to name a few'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secret and configuration management**: This allows you to deploy and update
    secrets such as API keys to your containers, without exposing them or rebuilding
    your container images'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a lot more features that we could talk about; rather than covering
    these features, let's dive right in and install a Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As hinted by the Kubernetes website, there are a lot of ways you can install
    Kubernetes. A lot of the documentation refers to Google's own public cloud; however,
    rather than introducing a third public cloud into the mix, we are going to be
    looking at deploying our Kubernetes cluster onto Amazon Web Services.
  prefs: []
  type: TYPE_NORMAL
- en: Before we start the Kubernetes installation, we need to ensure that you have
    the AWS Command Line Interface installed and configured.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The AWS **Command Line Interface** (**CLI**) is a unified tool to manage your
    AWS services. With just one tool to download and configure, you can control multiple
    AWS services from the command line and automate them through scripts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have already used Homebrew several times during the previous chapters,
    we will use that to install the tools. To do this, simply run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the tools have been installed, you will be able to configure the tools
    by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This will ask for the following four pieces of information:'
  prefs: []
  type: TYPE_NORMAL
- en: AWS Access Key ID
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS Secret Access Key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Default region name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Default output format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You should have your AWS Access and Secret keys from the when we launched a
    Docker Machine in Amazon Web Services in [Chapter 2](ch02.html "Chapter 2. Introducing
    First-party Tools"), *Introducing First-party Tools*. For the `Default region
    name`, I used `eu-west-1` (which is the closest region to me) and I left the `Default
    output format` as `None`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing Kubernetes](img/B05468_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have the AWS Command Line Tools installed and configured, we can
    install the Kubernetes Command Line Tools. This is a binary that will allow you
    to interact with your Kubernetes'' cluster in the same way that the local Docker
    client connects to a remote Docker Engine. This can be installed using Homebrew,
    just run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![Installing Kubernetes](img/B05468_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We don't need to configure the tool once installed as this will be taken care
    of by the main Kubernetes deployment script that we will be running next.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the tools needed to launch and interact with our AWS Kubernetes
    cluster, we can make a start deploying the cluster itself.
  prefs: []
  type: TYPE_NORMAL
- en: Before we kick off the installation, we need to let the installation script
    know a little bit of information about where we want our cluster to launch and
    also how big we would like it, this information is passed on to the installation
    script as environment variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, I would like it launched in Europe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, I would like two nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we need to instruct the installation script that we would like to
    launch the Kubernetes in Amazon Web Services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have told the installer where we would like our Kubernetes cluster
    to be launched, it''s time to actually launch it. To do this, run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This will download the installer and the latest Kubernetes codebase, and then
    launch our cluster. The process itself can take anywhere between eight and fifteen
    minutes, depending on your network connection.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you prefer not to run this installation yourself, you can view a recording
    of a Kubernetes cluster being deployed in Amazon Web Services at the following
    URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://asciinema.org](https://asciinema.org)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing Kubernetes](img/B05468_07_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the installation script has completed, you will be given information on
    where to access your Kubernetes cluster, you should also be able to run the following
    command to get a list of the nodes within your Kubernetes cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This should return something similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing Kubernetes](img/B05468_07_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Also, if you have the AWS Console open, you should see that a new VPC dedicated
    to Kubernetes has been created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing Kubernetes](img/B05468_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You will also see that three EC2 instances have been launched into the Kubernetes
    VPC:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing Kubernetes](img/B05468_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The last thing to make a note of before we start to launch applications into
    our Kubernetes cluster is the username and password credentials for the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may have seen during the installation, these are stored in the Kubernetes
    CLI configuration, as they are right at the bottom of the file, you can get these
    by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![Installing Kubernetes](img/B05468_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now that our Kubernetes cluster has been launched, and we have access to it
    using the command-line tools, we can start launching an application.
  prefs: []
  type: TYPE_NORMAL
- en: Launching our first Kubernetes application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To start off with, we are going to be launching a really basic cluster of NGINX
    containers, each container within the cluster will be serving a simple graphic
    and also print its host name on the page. You can find the image for container
    on the Docker Hub at [https://hub.docker.com/r/russmckendrick/cluster/](https://hub.docker.com/r/russmckendrick/cluster/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Like a lot of the tools we have looked at in the previous chapters, Kubernetes
    uses the YAML format for its definition file. The file we are going to launch
    into our cluster is the following file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s call the file `nginxcluster.yaml`. To launch it, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Once launched, you will be able to see the active pods by running the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You may find that you need to run the `kubectl` `get pods` command a few times
    to ensure that everything is running as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching our first Kubernetes application](img/B05468_07_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that you have your pods up and running, we need to expose them so that
    we can access the cluster using a browser. To do this, we need to create a service.
    To view the current services, type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see just the main Kubernetes service. When we launched our pods,
    we defined a replication controller, this is the process that manages the number
    of pods. To view the replication controllers, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the nginxcluster controller with five pods in the desired and
    current column. Now that we have confirmed that our replication controller is
    active with the expected number of pods registered with it, let''s create the
    service and expose the pods to the outside world by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if you run the `get services` command again, you should see our new service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Your terminal session should look something similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching our first Kubernetes application](img/B05468_07_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Great, you now have your pods exposed to the Internet. However, you may have
    noticed that the cluster IP address is an internal one, so how do you access your
    cluster?
  prefs: []
  type: TYPE_NORMAL
- en: 'As we are running our Kubernetes cluster in Amazon Web Services, when you exposed
    the service, Kubernetes made an API call to AWS and launched an Elastic Load Balancer.
    You can get the URL of the load balancer by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![Launching our first Kubernetes application](img/B05468_07_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, in my case, my load balancer can be accessed at `http:// af92913bcf98a11e5841c0a7f321c3b2-1182773033.eu-west-1.elb.amazonaws.com/`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Opening the load balancer URL in a browser shows our container page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching our first Kubernetes application](img/B05468_07_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, if you open the AWS console, you should be able to see the elastic
    load balancer created by Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching our first Kubernetes application](img/B05468_07_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: An advanced example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's try something more advanced than launching a few of the same instances
    and load balancing them.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the following example, we are going to launch our WordPress stack. This
    time we are going to mount Elastic Block Storage volumes to store both our MySQL
    database and WordPress files on:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Amazon Elastic Block Store (Amazon EBS) provides persistent block level storage
    volumes for use with Amazon EC2 instances in the AWS Cloud.  Each Amazon EBS volume
    is automatically replicated within its Availability Zone to protect you from component
    failure, offering high availability and durability. Amazon EBS volumes offer the
    consistent and low-latency performance needed to run your workloads. With Amazon
    EBS, you can scale your usage up or down within minutes – all while paying a low
    price for only what you provision." - [https://aws.amazon.com/ebs/](https://aws.amazon.com/ebs/)*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Creating the volumes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before we launch our pods and services, we need to create the two EBS volumes
    that we will be attaching to our pods. As we already have the AWS Command Line
    Interface installed and configured, we will be using that to create the volume
    rather than logging into the console and creating it using the GUI.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the two volumes, simply run the following command twice, making sure
    that you update the availability zone to match where your Kubernetes cluster was
    configured to launch:'
  prefs: []
  type: TYPE_NORMAL
- en: '`aws ec2 create-volume --availability-zone eu-west-1c --size 10 --volume-type
    gp2`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each time you run the command, you will get a blob of JSON returned, this will
    contain all of the metadata generated when the volume was created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating the volumes](img/B05468_07_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Make a note of VolumeId for each of the two volumes, you will need to know these
    when we create our MySQL and WordPress pods.
  prefs: []
  type: TYPE_NORMAL
- en: Launching MySQL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we have the volumes created, we are now able to launch our MySQL Pod
    and Service. First of all, let''s start with the Pod definition, make sure that
    you add one of the volumeIDs at the where promoted towards the bottom of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this follows pretty closely to our first Kubernetes application,
    except this time, we are only creating a single Pod rather than one with a Replication
    Controller.
  prefs: []
  type: TYPE_NORMAL
- en: Also, as you can see, I have added my volumeID to the bottom of the file; you
    will need to add your own volumeID when you come to launch the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'I call the file `mysql.yaml`, so to launch it, we need to run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Kubernetes will validate the `mysql.yaml` file before it tries to launch the
    Pod; if you get any errors, please check whether the indentation is correct:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching MySQL](img/B05468_07_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You should now have the Pod launched; however, you should probably check if
    it''s there. Run the following command to view the status of your Pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'If you see that the Pod has a status of `Pending`, like I did, you will probably
    be wondering *what''s going on?* Luckily, you can easily find that out by getting
    more information on the Pod we are trying to launch by using the `describe` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This will print out everything you will ever want know about the Pod, as you
    can see from the following terminal output, we did not have enough capacity within
    our cluster to launch the Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching MySQL](img/B05468_07_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can free up some resources by removing our previous Pods and Services by
    running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you run the commands to remove `nginxcluster`, your mysql Pod should automatically
    launch after a few seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching MySQL](img/B05468_07_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that the Pod has been launched, we need to attach a service so that port
    `3306` is exposed, rather than doing this using the `kubectl` command like we
    did before, we will use a second file called `mysql-service.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'To launch the service, simply run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: So now that we have the MySQL Pod and Service launched, it's time to launch
    the actual WordPress container.
  prefs: []
  type: TYPE_NORMAL
- en: Launching WordPress
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Like the MySQL Pod and Service, we will be launching our WordPress container
    using two files. The first file is for the Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'As an EBS volume cannot be attached to more than one device at a time, remember
    to use the second EBS volume you created here. Call the `wordpress.yaml` file
    and launch it using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then wait for the Pod to launch:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching WordPress](img/B05468_07_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As we have already removed `nginxcluster`, there should be enough resources
    to launch the Pod straightaway, meaning that you should not get any errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although the Pod should be running, it''s best to check whether the container
    launched without any problems. To do this, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This should print out the container logs, you will see something similar to
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching WordPress](img/B05468_07_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that the Pod has launched and WordPress appears to have bootstrapped itself
    as expected, we should launch the service. Like `nginxcluster`, this will create
    an Elastic Load Balancer. The service definition file looks similar to the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'To launch it, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Once launched, check whether the service has been created and get the details
    of the Elastic Load Balancer by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'When I ran the commands, I got the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching WordPress](img/B05468_07_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After a few minutes, you should be able to access the URL for Elastic Load
    Balancer, and as expected, you will be presented with a WordPress installation
    screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching WordPress](img/B05468_07_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As we did in [Chapter 3](ch03.html "Chapter 3. Volume Plugins"), *Volume Plugins*
    when we were looking at storage plugins, complete the installation, log in, and
    attach an image to the `Hello World` post.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have the WordPress site up and running, let''s try removing the
    wordpress Pod and relaunching it, first of let''s make a note of the Container
    ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Then delete the Pod and relaunch it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the Container ID again to make sure that we have a different one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![Launching WordPress](img/B05468_07_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Going to your WordPress site, you should see everything exactly as you left
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching WordPress](img/B05468_07_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If we wanted to, we could perform the same action for the MySQL pod and our
    data would be exactly as we left it, as it is stored in the EBS volume.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s remove the Pod and Service for the WordPress application by running
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This should leave us with a nice clean Kubernetes cluster for the next section
    of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Supporting tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You may be wondering to yourself why we bothered grabbing the username and password
    when we first deployed our Kubernetes cluster as we have not had to use it yet.
    Let's take a look at some of the supporting tools that are deployed as part of
    our Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you first deployed your Kubernetes cluster, there was a list of URLs printed
    on the screen, we will be using these for this section. Don''t worry if you didn''t
    make a note of them as you can get all the URLs for the supporting tools by running
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This will print out a list of URLs for the various parts of your Kubernetes
    cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Supporting tools](img/B05468_07_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You will need the username and password to view some of these tools, again
    if you don''t have these to hand, you can get them by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Kubernetes Dashboard
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'First of all, let''s take a look at the Kubernetes Dashboard. You can get this
    by putting the URL for the Kubernetes-dashboard in your browser. When you enter
    it, depending on your browser, you will get warnings about the certificates, accept
    the warnings and you will be given a login prompt. Enter the username and password
    here. Once logged in, you will see the following screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Kubernetes Dashboard](img/B05468_07_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s deploy the NGINX Cluster application using the UI. To do this, click
    on **Deploy An App** and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**App name** = `nginx-cluster`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Container image** = `russmckendrick/cluster`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of pods** = `5`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port** = Leave blank'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port** = `80`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Target port** = `80`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tick the box for **Expose service externally**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Kubernetes Dashboard](img/B05468_07_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once you click on **Deploy**, you will be taken back to the overview screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Kubernetes Dashboard](img/B05468_07_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'From here, you can click on **nginx-cluster** and be taken to an overview screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Kubernetes Dashboard](img/B05468_07_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, this gives you all the details on both the Pod and Service,
    with details such as the CPU and memory utilization, as well as a link to the
    Elastic Load Balancer. Clicking the link should take you to the default cluster
    page of the image and the container's hostname.
  prefs: []
  type: TYPE_NORMAL
- en: Let's leave nginx-cluster up and running to look at the next tool.
  prefs: []
  type: TYPE_NORMAL
- en: Grafana
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The next URL that we are going to open is Grafana; going to the URL, you should
    see a quite dark and mostly empty page.
  prefs: []
  type: TYPE_NORMAL
- en: 'Grafana is the tool that is recording all the metrics that we saw being displayed
    in the Kubernetes dashboard. Let''s take a look at the cluster stats. To do this,
    click on the **Cluster** dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Grafana](img/B05468_07_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, this gives us a breakdown of all of the metrics that you would
    expect to see from a system-monitoring tool. Scrolling down, you can see:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU Usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory Usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network Usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filesystem Usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Both collectively and per individual node. You can also view details on Pods
    by clicking on the **Pods** dashboard. As Grafana gets its data from the InfluxDB
    pod, which has been running since we first launched our Kubernetes cluster, you
    can view metrics for every Pod that you have launched, even if it is not currently
    running. The following is the Pod metrics for the `mysql` pod we launched when
    installing WordPress:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Grafana](img/B05468_07_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: I would recommend you to look around to view some of the other Pod metrics.
  prefs: []
  type: TYPE_NORMAL
- en: ELK
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The final tool we are going to look at is the ELK stack that has been running
    in the background since we first launch our Kubernetes cluster. An ELK stack is
    a collection of the following three different tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Elasticsearch**: [https://www.elastic.co/products/elasticsearch](https://www.elastic.co/products/elasticsearch)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logstash**: [https://www.elastic.co/products/logstash](https://www.elastic.co/products/logstash)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kibana**: [https://www.elastic.co/products/kibana](https://www.elastic.co/products/kibana)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Together they form a powerful central logging platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we ran the following command earlier in this section of the chapter (please
    note you will not be able to run it again as we removed the WordPress pod):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The logs displayed for our `wordpress` pod the log file entries were actually
    read from the Elasticsearch pod. Elasticsearch comes with its own dashboard called
    Kibana. Let's open the Kibana URL.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you first open Kibana, you will be asked to configure an index pattern.
    To do this, just select Time-field name from the drop-down box and click on **Create**
    button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ELK](img/B05468_07_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the index pattern has been created, click on the **Discover** link in
    the top menu. You will then be taken to an overview of all of the log data that
    has been sent to Elasticsearch by the Logstash installations that are running
    on each of the nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ELK](img/B05468_07_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, there is a lot of data being logged; in fact, when I looked,
    there were 4,918 messages logged within 15 minutes alone. There is a lot of data
    in here, I would recommend clicking around and trying some searches to get an
    idea of what is being logged.
  prefs: []
  type: TYPE_NORMAL
- en: 'To give you an idea of what each log entry looks like, here is one for one
    of my nginx-cluser pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ELK](img/B05468_07_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Remaining cluster tools
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The remaining cluster tools that we are yet to open in the browser are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Kubernetes**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heapster**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**KubeDNS**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**InfluxDB**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These all are API endpoints, so you will not see anything other than an API
    response, they are using by Kubernetes internally to both manage and schedule
    within the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Destroying the cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As the cluster is sat in your Amazon Web Services account on instances that
    are pay-as-you-go, we should look at removing the cluster; to do this, let''s
    re-enter the original configuration that we entered when we first deployed the
    Kubernetes cluster by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, from the same location you first deployed your Kubernetes cluster, run
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: This will connect to the AWS API and start to tear down all of the instances,
    configuration, and any other resources that have been launched with Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process will take several minutes, do not interrupt it or you maybe left
    with resources that incur costs running within your Amazon Web Services account:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Destroying the cluster](img/B05468_07_35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: I would also recommend logging into your Amazon Web Services console and remove
    the unattached EBS volumes that we created for the WordPress installation and
    also any Kubernetes labelled S3 buckets as these will be incurring costs as well.
  prefs: []
  type: TYPE_NORMAL
- en: Recap
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes, like Docker, has matured a lot since its first public release. It
    has become easier to deploy and manage with each release without having a negative
    impact on the feature set.
  prefs: []
  type: TYPE_NORMAL
- en: As a solution that offers scheduling for your containers, it is second to none,
    and as it is not tied to any particular provider, you can easily deploy it to
    providers other than Amazon Web Services, such as Google's own Cloud Platform,
    where it is considered a first class citizen. It is also possible to deploy it
    on premise on your own bare metal of virtual servers, making sure that it keeps
    itself inline with the build once and deploy anywhere philosophy that Docker has.
  prefs: []
  type: TYPE_NORMAL
- en: Also, it adapts to work with the technologies available in every platform you
    deploy it onto; for example, if you need persistent storage, then as already mentioned,
    there are multiple options available to you.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, just like Docker has been over the past 18 months, Kubernetes has quite
    a unifying platform, with multiple vendors such as Google, Microsoft, and Red
    Hat. They all support and use it as part of their products.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon EC2 Container Service (ECS)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next tool that we are going to be looking at is the Elastic Container Service
    from Amazon. The description that Amazon gives is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Amazon EC2 Container Service (ECS) is a highly scalable, high performance
    container management service that supports Docker containers and allows you to
    easily run applications on a managed cluster of Amazon EC2 instances. Amazon ECS
    eliminates the need for you to install, operate, and scale your own cluster management
    infrastructure. With simple API calls, you can launch and stop Docker-enabled
    applications, query the complete state of your cluster, and access many familiar
    features like security groups, Elastic Load Balancing, EBS volumes, and IAM roles.
    You can use Amazon ECS to schedule the placement of containers across your cluster
    based on your resource needs and availability requirements. You can also integrate
    your own scheduler or third-party schedulers to meet business or application specific
    requirements." - [https://aws.amazon.com/ecs/](https://aws.amazon.com/ecs/)*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It wasn't a surprise that Amazon would offer their own container-based service.
    After all, if you are following Amazon's best practices, then you will already
    be treating each of your EC2 instances in the same way you are treating your containers.
  prefs: []
  type: TYPE_NORMAL
- en: When I deploy applications into Amazon Web Services, I always try to ensure
    that I build and deploy production-ready images, along with ensuring that all
    the data written by the application is sent to a shared source as the instances
    could be terminated any time due to scaling events.
  prefs: []
  type: TYPE_NORMAL
- en: 'To help support this approach, Amazon offers a wide range of services such
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Elastic Load Balancing** (**ELB**): This is a highly available and scalable
    load balancer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amazon Elastic Block Store** (**EBS**): This provides persistent block-level
    storage volumes for your compute resources'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Auto Scaling**: This scales EC2 resources up and down, allowing you to manage
    both, peaks in traffic and failures within the application'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amazon Relational Database Service** (**RDS**): This is a highly available
    database as a service supporting MySQL, Postgres, and Microsoft SQL'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these are designed to help you remove all single points of failure within
    your Amazon-hosted application.
  prefs: []
  type: TYPE_NORMAL
- en: Also, as all of Amazon's services are API-driven, it wasn't too much of a jump
    for them to extend support to Docker containers.
  prefs: []
  type: TYPE_NORMAL
- en: Launching ECS in the console
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I am going to be using the the AWS Console to launch my ECS cluster. As my AWS
    account is quite old, a few of the steps may differ. To try and account for this,
    I will be launching my cluster in one of the newer AWS regions.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have logged into the AWS Console at [http://console.aws.amazon.com/](http://console.aws.amazon.com/),
    make sure that you are in the region you would like to launch your ECS cluster
    in, and then click on the **EC2 Container Service** link from the **Services**
    drop-down menu.
  prefs: []
  type: TYPE_NORMAL
- en: As this is your first time launching an ECS cluster, you will be greeted with
    an overview video of the service.
  prefs: []
  type: TYPE_NORMAL
- en: Click on **Get started** to be taken to the Wizard that will help us launch
    our first cluster.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, you will be prompted to create a task definition. This is the
    equivalent of creating a Docker Compose file. Here you will define the container
    image that you would like to run and the resources it is allowed to consume, such
    as RAM and CPU. You will also map the ports from the host to container here.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, we will use the defaults and look at launching our own containers
    once the cluster is up and running. Fill in the details as per the following screenshot
    and click on **Next step**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that the task has been defined, we need to attach it to a service. This
    allows us to create a group of tasks, which initially will be three copies of
    the `console-sample-app-static` task, and register them with an Elastic Load Balancer.
    Fill in the details as per the following screenshot and click on **Next step**
    button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have the service defined, we need a location to launch it. This
    is where EC2 instances come into play, and also where you still to be charged.
    While the Amazon EC2 Container Service is free of charge to set up, you will be
    charged for the resources used to deliver the compute side of the cluster. These
    will be your standard EC2 instance charges. Fill in the details as per the following
    screenshot and click on **Review & launch**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Before anything is launched, you will get the opportunity to double-check everything
    that is configured within your AWS account, this is your last chance to back out
    of launching the ECS cluster. If you are happy with everything, click on **Launch
    instance & run service** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'What you will see now is an overview of what is happening. Typically, it will
    take about 10 minutes to run through these tasks. In the background, it is doing
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating an IAM role that accesses the ECS service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a VPC for your cluster to be launched in
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Launch Configuration to run an Amazon ECS-optimized Amazon Linux
    AMI with the ECS IAM role
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attaching the newly created Launch Configuration to an Auto Scaling Group and
    configuring it with the number of instances you defined
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the ECS Cluster, Task, and Service within the Console
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Waiting for the EC2 instances that have been launched by the Auto Scaling Group
    to launch and register themselves with the ECS service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running the Service on your newly created ECS cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating an Elastic Load Balancer and registering your Service with it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find more information on the Amazon ECS-Optimized Amazon Linux AMI on
    its AWS Marketplace page at [https://aws.amazon.com/marketplace/pp/B00U6QTYI2/ref=srh_res_product_title?ie=UTF8&sr=0-2&qid=1460291696921](https://aws.amazon.com/marketplace/pp/B00U6QTYI2/ref=srh_res_product_title?ie=UTF8&sr=0-2&qid=1460291696921).
    This image is a cut-down version of Amazon Linux that only runs on Docker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once everything is completed, you will be given the option to go to your newly
    created Service. You should see something similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_41.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, we have three running tasks and a load balancer.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's create our own task and service. From the preceding Service view,
    click on **Update** button and change the desired count from three to zero, this
    will stop the tasks and allow us to remove the Service. To do this, click on **default**
    button to go to the cluster view and then remove the Service.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that the `sample-webapp` Service has been removed, click on the **Task
    Definitions** button and then the **Create new task definition** button. On the
    page that opens, click on the **Add container** button and fill in the following
    details:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Container name**: `cluster`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image**: `russmckendrick/cluster`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maximum memory (MB)**: `32`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port mappings**: `80` (**Host port**) `80` (**Container port**) `tcp` (**Protocol**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Everything else can be left at the default values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_42.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once filled in, click on the **Add** button. This will take you back to the
    **Create a Task Definition** screen, fill in the Task Definition Name, let''s
    call it `our-awesome-cluster` and then click on the **Create** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_43.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have our new Task defined, we need to create a Service to attach
    it to. Click on the **Clusters** tab, then click on the **default** cluster, you
    should see something similar to the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the **Create** button in the **Services** tab. From this screen, fill
    in the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Task Definition**: `our-awesome-cluster:1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster**: `default`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service name**: `Our-Awesome-Cluster`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of tasks**: `3`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Minimum healthy percent**: `50`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maximum percent**: `200`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Also, in the **Optional configurations** section, click on **Configure ELB**
    button and use the Elastic Load Balancer that was originally configured for the
    `sample-webapp` service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_45.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once you have filled in the information, click on the **Create Service** button.
    If all goes well, you should see something similar to the following page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_46.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Clicking on **View Service** will give you an overview similar to the one we
    first saw for the `Sample-Webapp` Service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_47.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'All that''s left to do now is to click on **Load Balancer Name** to be taken
    to the ELB overview page; from here, you will be able to get the URL for the ELB,
    putting this into a browser should show you our clustered application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Launching ECS in the console](img/B05468_07_48.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Click refresh a few times and you should see the container's hostname change,
    indicating that we are being load balanced between different containers.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than launching any more instances, let's terminate our cluster. To do
    this, go to the **EC2** service in the **Services** menu at the top of the AWS
    Console.
  prefs: []
  type: TYPE_NORMAL
- en: From here, scroll down to **Auto Scaling Groups** that can be found at the bottom
    of the left-hand side menu. From here, remove the auto scaling group and then
    the launch configuration. This will terminate the three EC2 instances that formed
    our ECS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Once the instances have been terminated, click on **Load Balancer** and terminate
    the Elastic Load Balancer.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, go back to the **EC2 Container Service** and delete the default cluster
    by clicking on the **x**. This will remove the remainder of the resources that
    were created by us launching the ECS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Recap
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you can see, Amazon's EC2 Container Service can be run from the web-based
    AWS Console. There are command tools available, but I won't be covering them here.
    Why, you might ask?
  prefs: []
  type: TYPE_NORMAL
- en: Well, although the service offering Amazon has built is complete, it feels very
    much like a product that is in an early alpha stage. The versions of Docker that
    ship on the Amazon ECS-Optimized Amazon Linux AMI are quite old. The process of
    having to launch instances outside of the default stack feels very clunky. Its
    integration with some of the supporting services provided by Amazon is also a
    very manual process, making it feel incomplete. There is also the feeling that
    you don't have much control.
  prefs: []
  type: TYPE_NORMAL
- en: Personally, I think the service has a lot of potential; however, in the last
    12 months, a lot of alternatives have launched and are being developed at a more
    rapid pace, meaning that Amazon's ECS service is left feeling old and quite outdated
    compared to the other services we are looking at.
  prefs: []
  type: TYPE_NORMAL
- en: Rancher
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rancher is a relatively new player, at the time of writing this book, it has
    only just hit its 1.0 release. Rancher Labs (the developers) describe Rancher
    (the platform) as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"An open source software platform that implements a purpose-built infrastructure
    for running containers in production. Docker containers, as an increasingly popular
    application workload, create new requirements in infrastructure services such
    as networking, storage, load balancer, security, service discovery, and resource
    management.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Rancher takes in raw computing resources from any public or private cloud
    in the form of Linux hosts. Each Linux host can be a virtual machine or a physical
    machine. Rancher does not expect more from each host than CPU, memory, local disk
    storage, and network connectivity. From Rancher''s perspective, a VM instance
    from a cloud provider and a bare metal server hosted at a colo facility are indistinguishable."
    - [http://docs.rancher.com/rancher/](http://docs.rancher.com/rancher/)*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Rancher Labs also provide RancherOS—a tiny Linux distribution that runs the
    entire operating system as Docker containers. We will look at that in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Rancher
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Rancher needs a host to run on, so let''s launch a server in DigitalOcean using
    Docker Machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Rancher runs as a container, so rather than using SSH to connect to the newly
    launched Docker host, let''s configure our local client to connect to the host
    and then we can launch Rancher:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: That's it, Rancher will be up and running shortly. You can watch the logs to
    keep an eye on when Rancher is ready.
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, check what the Rancher container is called by running the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'In my case, it was `jolly_hodgkin`, so now run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '![Installing Rancher](img/B05468_07_49.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You should see a lot of log file entries scroll pass, after a while, logs will
    stop being written. This is a sign that Rancher is ready and you can log in to
    the web interface. To do this, run the following command to open your browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Once open, you should see something similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing Rancher](img/B05468_07_50.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, we have logged in straight. As this is available on a public
    IP address, we have better lock the installation down. This is why the red warning
    icon is next to **Admin** in the top menu is there.
  prefs: []
  type: TYPE_NORMAL
- en: Securing your Rancher installation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As I don't have an Active Directory server configured, I am going to use GitHub
    to authenticate against my Rancher installation. Just like the installation itself,
    Rancher Labs have made this a really easy process. First of all, click on **Admin**
    in the top menu and then **Access Control** in the secondary menu, you will be
    taken to a screen that allows you to know everything you need in order to configure
    Rancher to use GitHub as its authentication backend.
  prefs: []
  type: TYPE_NORMAL
- en: 'For me, this screen looked similar to the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Securing your Rancher installation](img/B05468_07_51.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As I have a standard GitHub account rather than the Enterprise installation,
    all I had to do was click on the link, this took me to a page where I could register
    my Rancher installation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This asked for several pieces of information, all of which are provided on
    the following screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Securing your Rancher installation](img/B05468_07_52.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once I filled in the information, I clicked on **Register application** button.
    Once the application had been registered, I was taken a page that gave me a Client
    ID and Client Secret:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Securing your Rancher installation](img/B05468_07_53.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'I entered these parameters into appropriate boxes on my Rancher page and then
    clicked on **Authenticate with GitHub**. This prompted a pop-up window from GitHub
    asking me to authorize the application. Clicking the **Authorize application**
    button refreshed the Rancher screen and logged me in, as you can see from the
    following screenshot, my application is now secure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Securing your Rancher installation](img/B05468_07_54.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now that we have the authentication configured, you should probably log out
    and log back in just to double-check whether everything is working as expected
    before we move onto the next step. To do this, click on your avatar at the right-hand
    top of the page and click on **Log Out**.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be instantly taken to the following page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Securing your Rancher installation](img/B05468_07_55.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Click on **Authenticate with GitHub** to log back in.
  prefs: []
  type: TYPE_NORMAL
- en: So, why did we log out and then logged back in? Well, next up, we are going
    to be giving our Rancher installation our DigitalOcean API key so that it can
    launch hosts, if we hadn't secured our installation before adding this API key,
    it would mean that anyone could stumble upon our Rancher installation and start
    launching hosts as they see fit. This, as I am sure you could imagine, could get
    very expensive.
  prefs: []
  type: TYPE_NORMAL
- en: Cattle cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rancher supports three different schedulers, we have already looked at two of
    them in both this and the previous chapters. From our Rancher installation, we
    will be able to launch a Docker Swarm Cluster, Kubernetes cluster, and also Rancher
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: For this part of the chapter, we are going to be looking at a Rancher cluster.
    The scheduler that will be used here is called Cattle. It is also the default
    scheduler, so we do not need to configure it, all we need to do is add some hosts.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned in the previous section, we are going to launch our hosts in DigitalOcean;
    to do this, click on **Add Host** in the **Adding your first Host** section of
    the front page.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be taken to a page with several hosting providers listed at the top,
    click on DigitalOcean and then enter the following details:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Quantity**: I wanted to launch three hosts, so I dragged the slider to `3`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Name**: This is how the hosts will appear in my DigitalOcean control panel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Description**: A quick description to be attached to each host.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Access Token**: This is my API token, you should have yours from [Chapter
    2](ch02.html "Chapter 2. Introducing First-party Tools"), *The First-party Tools*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image**: At the moment, only Ubuntu 14.04x64 is supported.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Size**: This is the size of the host you would like to launch. Don''t forget,
    the bigger the host, the more money you will pay while the host is online.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Region**: Which DigitalOcean data center would you like to launch the hosts
    in?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'I left the remainder of the options at their defaults:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Cattle cluster](img/B05468_07_56.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Once I was happy with what I had entered, I clicked on **Create** button. Rancher
    then, using the DigitalOcean API, went ahead and launched my hosts.
  prefs: []
  type: TYPE_NORMAL
- en: To check the status of the hosts, you should click on **Infrastructure** in
    the top menu and then **Hosts** in the secondary menu.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, you should see the hosts you are deploying, along with their status,
    which is updating in real time. You should see messages saying the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The host has been launched
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker is being installed and configured
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Rancher agent is being installed and configured
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, all three of your hosts are shown as active:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Cattle cluster](img/B05468_07_57.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There you have it, your first Cattle cluster. As you can see, so far it has
    been incredibly easy to install, secure, and configure our first cluster in Rancher.
    Next up, we need to deploy our containers.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Cluster application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As per the previous two schedulers, let's look at deploying our basic cluster
    application. To do this, click on the **Applications** tab in the top menu, and
    then click on **Add Service**. There is an option to **Add From Catalog**, we
    will be looking at this option when we have launched our own application.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the **Add Service** page, enter the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scale**: `Always run one instance of this container on every host`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Name**: `MyClusterApp`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Description**: `My really awesome clustered application`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Select Image**: `russmckendrick/cluster`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port map**: Add a port map for port `80` just in the **Private port** box![Deploying
    the Cluster application](img/B05468_07_58.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For now, leave the rest of the forms at their default values and click on the
    **Create** button.
  prefs: []
  type: TYPE_NORMAL
- en: 'After a few minutes, you should see that your service is active, clicking on
    the service name will take you a screen that gives you the details on all of the
    containers running within the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying the Cluster application](img/B05468_07_59.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'So, now that we have our containers running, we really need to be able to access
    them. To configure a load balancer, click on **Stacks** and then on the downward
    arrow on our default service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying the Cluster application](img/B05468_07_60.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Selecting **Add Load Balancer** from the drop-down menu will take you to a screen
    that looks similar to the one where we added our cluster application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fill in the following details:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scale**: `Run 1 container`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Name**: `ClusterLoadBalancer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Description**: `The Load Balancer for my clustered application`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Listening** **Ports**: `Source IP/Port 80 Default Target Post 80`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Target** **Service**: `MyClusterApp`![Deploying the Cluster application](img/B05468_07_61.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Click on the **Save** button and wait for the service to launch. You will be
    taken back to the list of services that you have launched, clicking on the information
    sign next to name of the load balancer will open an information pane at the bottom
    of the screen. From here, click on the IP address listed in the Ports section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying the Cluster application](img/B05468_07_62.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Your browser should open the now-familiar cluster application page.
  prefs: []
  type: TYPE_NORMAL
- en: Clicking on refresh a few times should change the host name of the container
    you are being connected to.
  prefs: []
  type: TYPE_NORMAL
- en: What's going on in the background?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of Rancher's strengths is that there are a lot of tasks, configuration,
    and process running in the background, which are all hidden by an intuitive and
    easy-to-use web interface.
  prefs: []
  type: TYPE_NORMAL
- en: To get an idea of what's going on, let's have a look around the interface. To
    start off with, click on **Infrastructure** in the top menu, and then click on
    **Hosts**.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the running containers are now listed; alongside the containers
    for our Default stack, there is a network agent container running on each host:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What''s going on in the background?](img/B05468_07_64.jpg)'
  prefs: []
  type: TYPE_IMG
- en: These containers form a network between all three of our hosts using iptables,
    allowing cross-host connectivity for our containers.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'iptables is a user-space application program that allows a system administrator
    to configure the tables provided by the Linux kernel firewall (implemented as
    different Netfilter modules) and the chains and rules it stores:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://en.wikipedia.org/wiki/Iptables](https://en.wikipedia.org/wiki/Iptables)'
  prefs: []
  type: TYPE_NORMAL
- en: To confirm this, click on **Containers** button in the secondary menu. You will
    see a list of the currently running containers, this list should include three
    containers running our cluster application.
  prefs: []
  type: TYPE_NORMAL
- en: Make a note of the IP address for **Default_MyClusterApp_2** (in my case, it's
    `10.42.220.91`) and then click on **Default_MyClusterApp_1**.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be taken to a page that gives you real-time information about the
    CPU, memory, network, and storage utilization of the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What''s going on in the background?](img/B05468_07_65.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the container is currently active on my first Rancher host.
    Let's get a little more information about the container by connecting to it. At
    the top right-hand side of the page, where it says **Running**, there is an icon
    with three dots, click on that, and then select **Execute Shell** from the drop-down
    menu.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will open a terminal within your browser to the running container. Try
    entering some commands such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, while we have the shell open, let''s ping our second container that is
    hosted on another one of our hosts (make sure that you replace the IP address
    with the one made a note of):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, although it is on a different host within our cluster, we are
    able to ping it without any problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What''s going on in the background?](img/B05468_07_66.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Another feature that is useful is Health Check. Let's configure Health Check
    for our service and then simulate an error.
  prefs: []
  type: TYPE_NORMAL
- en: Click on **Applications** in the top menu, then on the **+** next to our Default
    stack, this will bring up a list of services that make up the stack. Click on
    the **MyClusterApp** service to be taken to the overview page.
  prefs: []
  type: TYPE_NORMAL
- en: From here, as we did to access the container shell, click on the icon with the
    three dots in the top right-hand side, next to where it says **Active**. From
    the drop-down menu, select **Upgrade**, this will take us to a stripped-down version
    of the page we filled in to create the initial service.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the bottom of this page there are several tabs, click on **Health Check**
    and fill out the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Health Check**: `HTTP Responds 2xx/3xx`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HTTP Request**: `/index.html`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port**: `80`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**When Unhealthy**: `Re-create`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![What''s going on in the background?](img/B05468_07_67.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Leave the rest of the settings as they are and then click on the **Upgrade**
    button. You will be taken back to the list of services that are in the Default
    stack, and next to the **MyClusterApp** service, it will say **Upgrading**.
  prefs: []
  type: TYPE_NORMAL
- en: During the upgrade process, Rancher has relaunched our containers with the new
    configuration. It did this one at a time, meaning that there would have been no
    downtime as far as people browsing our application would have been concerned.
  prefs: []
  type: TYPE_NORMAL
- en: You may also notice that it says there are six containers, and also that the
    stack is degraded; to resolve this, click on the **MyClusterApp** service in order
    to be taken to the list of containers.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, three of them have a state of Stopped. To remove them, click
    on the **Finish Upgrade** button, next to where it says **Degraded**, this will
    remove the stopped containers and return us to a stopped state.
  prefs: []
  type: TYPE_NORMAL
- en: So now that we have a health checking, make sure that each of our containers
    is serving a web page, let's stop NGINX from running and see what happens.
  prefs: []
  type: TYPE_NORMAL
- en: To do this, click on any of our three containers and then open a console by
    selecting **Execute Shell** from the drop-down menu.
  prefs: []
  type: TYPE_NORMAL
- en: 'As our container is running supervised to manage the processes within the container,
    all we need to do is run the following command to stop NGINX:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we need to kill the NGINX processes; to do this, find out the process
    IDs by running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'In my case, the PIDs were 12 and 13, so to kill them, I will run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This will stop NGINX, but keep the container up and running. After a few seconds,
    you will notice that the stats in the background disappear:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What''s going on in the background?](img/B05468_07_68.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Then your console will close, leaving you with something that looks similar
    to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What''s going on in the background?](img/B05468_07_69.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Going back to the list of containers for the MyClusterApp service, you will
    notice that there is a new **Default_MyClusterApp_2** container running under
    a different IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What''s going on in the background?](img/B05468_07_70.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Rancher has done exactly as we instructed it to, if port 80 on any of our containers
    stops responding for more than six seconds, it has to fail three checks that are
    made every 2,000 ms, then remove the container, and replace it with a new one.
  prefs: []
  type: TYPE_NORMAL
- en: The catalog
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I am pretty sure that you would have clicked on the **Catalog** item in the
    top menu, this lists all the pre-built stacks that you can launch within Rancher.
    Let's look at launching WordPress using the catalog item. To do this, click on
    **Catalog** and scroll down to the bottom where you will see an entry for WordPress.
  prefs: []
  type: TYPE_NORMAL
- en: WordPress
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Click on **View Details** to be taken to a screen where you are able to add
    a WordPress stack. All it asks is for you to provide a **Name** and **Description**
    for the stack, fill these in, and click on **Launch**.
  prefs: []
  type: TYPE_NORMAL
- en: This will launch two containers, one running MariaDB and the other running the
    WordPress container. These containers use the same images from the Docker Hub
    that we have been launching throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you click on **Stacks** in the secondary menu and then expand the two stacks.
    Once the WordPress stack is active, you will be able to click on the information
    icon next to where it says **wordpress**. Like before, this will give the IP address
    where you can access your WordPress installation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![WordPress](img/B05468_07_71.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Clicking on it will open a new browser window and you will see a very familiar
    WordPress installation screen.
  prefs: []
  type: TYPE_NORMAL
- en: Again, Rancher did something interesting here. Remember that we have three hosts
    in total. One of these hosts is running a container that is acting as a load balancer
    for our **ClusterApp**, this is bound to port 80 on one of these hosts.
  prefs: []
  type: TYPE_NORMAL
- en: By default, the WordPress catalog stack launches the WordPress container and
    maps port 80 from the host to port 80 on the container. With no prompting from
    us, Rancher realized that one of our hosts already has a service bound to port
    80, so it didn't even attempt to launch the WordPress container here, instead
    it chose the next available host without a service mapped to port 80 and launched
    our WordPress container there.
  prefs: []
  type: TYPE_NORMAL
- en: This is another example of Rancher doing tasks in the background to make the
    best use of the resources you have launched.
  prefs: []
  type: TYPE_NORMAL
- en: Storage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far so good with Rancher, let's take a look at how we can add some shared
    storage to our installation. One of the things that DigitalOcean doesn't provide
    is block storage, because of which we will need to use a clustered filesystem,
    as we do not want to introduce a single point of failure within our application.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Gluster FS is a scalable network filesystem. Using common off-the-shelf hardware,
    you can create large distributed storage solutions for media streaming, data analysis,
    and other data and bandwidth-intensive tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.gluster.org](https://www.gluster.org)'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may have noticed when browsing the catalog, there are several storage
    items in there that we are going to be looking at GlusterFS to provide our distributed
    storage:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Storage](img/B05468_07_72.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Once we have our Gluster cluster up and running, we will then use Convoy to
    expose it to our containers. Before we do this, we need to start GlusterFS. To
    do this, click on **View Details** on the **Gluster FS** catalog item.
  prefs: []
  type: TYPE_NORMAL
- en: You will be taken to a form that details exactly what is going to be configured
    and how. For our purpose, we can leave all the settings as they are and click
    on the **Launch** button at the bottom of the page.
  prefs: []
  type: TYPE_NORMAL
- en: 'It will take a few minutes to launch. When it has completed, you will see that
    a total of 12 containers have been created. Of these, six of them will be running
    and the other six will be marked as started. This is not anything to worry about,
    as they are acting as the volumes for the running containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Storage](img/B05468_07_73.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now that we have our Gluster FS cluster up and running, we need to launch Convoy
    and let it know about the Gluster FS cluster. Go back to the catalog page and
    click on **View Details** next to the **Convoy Gluster FS** entry.
  prefs: []
  type: TYPE_NORMAL
- en: As we kept of the default options and names selected when we launched the Gluster
    FS cluster, we can leave everything at the defaults here, all we have to do is
    select our Gluster FS cluster from the Gluster FS service drop-down menu.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have made the selection and clicked on **Launch**, it won''t take
    long to download and launch the `convoy-gluster` containers. Once completed, you
    should have four containers running. As you may have noticed, a new icon for **System**
    has appeared next to **Stacks** on the secondary menu, this is where you will
    find your `Convoy Gluster` stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Storage](img/B05468_07_74.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So, we now have our distributed storage ready. Before we put it to use, let's
    look at one more catalog item.
  prefs: []
  type: TYPE_NORMAL
- en: Clustered database
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We don't really want to store our database on a shared or distrusted filesystem,
    one of the other items in the catalog launches a MariaDB Galera Cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Galera Cluster for MySQL is a true Multimaster Cluster based on synchronous
    replication. Galera Cluster is an easy-to-use, high-availability solution that
    provides high-system uptime, no data loss, and scalability for future growth:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://galeracluster.com/products/](http://galeracluster.com/products/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The cluster will sit behind a load balancer, meaning that your database requests
    will always be directed to an active master database server. As earlier, click
    on **View Details** on the **Galera Cluster** item and then fill in the database
    credentials you wish the cluster to be configured with. These credentials are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: MySQL Root Password
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MySQL Database Name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MySQL DB User
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MySQL DB Password
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once filled in, click on the **Launch** button. The cluster will take a few
    minutes to launch. Once launched, it will contain 13 containers, these make up
    the cluster and load balancer.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at WordPress again
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we have our clustered filesystem configured, and also our clustered
    database, let's look at launching WordPress again.
  prefs: []
  type: TYPE_NORMAL
- en: To do this, click on **Applications** from the top menu, and then make sure
    that you are on the **Stacks** page, click on **New Stack**.
  prefs: []
  type: TYPE_NORMAL
- en: 'From here, give it the name `WordPress` and then click on **Create**, and now
    click on **Add Service**. You will need to fill in the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scale**: `Run 1 container (we will scale up later)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Name**: `WordPress`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Description**: `My WordPress cluster`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Select Image**: `wordpress`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port Map**: `Leave the public port blank and add 80 in the private port`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service Links**: **Destination Service** should your `galera-lb` and the
    **As Name** `galera-lb`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We then need to enter the following details on the tabbed options along the
    bottom:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Command:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Enviroment Vars: Add the following variables:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variable** = `WORDPRESS_DB_HOST`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Value** = `galera-lb`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variable** = `WORDPRESS_DB_NAME`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Value** = The name of the DB you created when setting up Galera'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variable** = `WORDPRESS_DB_USER`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Value** = The user you created when setting up Galera'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variable** = `WORDPRESS_DB_PASSWORD`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Value** = The password of the user you created when setting up Galera'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Volumes:'
  prefs: []
  type: TYPE_NORMAL
- en: Add a volume as `wpcontent:/var/www/html/wp-content/`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Volume Driver: convoy-gluster'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then click on the **Launch** button. It will take a minute to download and
    start the container, once it has started, you should see the status change to
    Active. Once you have a healthy service, click on the drop-down menu next to Add
    Service and add a Load Balancer:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Name**: `WordPressLB`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Description**: `My WordPress Load Balancer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Source IP/Port**: `80`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Default Target Port**: `80`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Target Service**: `WordPress`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you have added the Load Balancer, click on the information icon next to
    the Load Balancer service to get the IP address, open this in your browser and
    then perform the WordPress installation, and add the featured image as we have
    done in other chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have a WordPress container up and running with a highly available database
    backend, which we can move between hosts maintaining the same IP address and content
    thanks to the load balancer and Gluster FS storage.
  prefs: []
  type: TYPE_NORMAL
- en: DNS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The last catalog item I thought I would cover is one of the DNS managers. What
    these items do is automatically connect with your DNS provider's API and create
    DNS records for each of the stacks and services you launch. As I use Route53 to
    manage my DNS records, I clicked on **View Details** on the **Route53 DNS Stack**
    on the catalog screen.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the *Configuration Options* section, I entered the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AWS access key**: My access key, the user must have permission to access
    Route53'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AWS secret key**: The secret key that accompanies the preceding access key'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AWS region**: The region I want to use'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hosted zone**: The zone I wanted to use was `mckendrick.io`, so I entered
    that here'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TTL**: I left this as the default `299 seconds`, if you want a quicker update
    to your DNS, you should set this to `60 seconds`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then I clicked on the **Launch** button. After a few minutes, I checked the
    hosted zone in the Route53 control panel and the service had connected automatically
    and created the following records for stacks and services I already had running.
  prefs: []
  type: TYPE_NORMAL
- en: 'The DNS entries are formatted in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'So in my case, I had entries for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`clusterloadbalancer.default.default.mckendrick.io`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`myclusterapp.default.default.mckendrick.io`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As `myclusterapp` contained three containers, three IP addresses were added
    to the entry so that round robin DNS would direct traffic to each container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![DNS](img/B05468_07_75.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Another good thing about the DNS catalog items is that they are automatically
    updated, meaning that if we were to move a container to a different host, the
    DNS for the container would automatically be updated to reflect the new IP address.
  prefs: []
  type: TYPE_NORMAL
- en: Docker & Rancher Compose
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another thing that you may have noticed is that when you go to add a stack,
    Rancher gives you two boxes where you can enter the content of a Docker and Rancher
    Compose file.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have been creating services manually using the web interface, for
    each of the stacks we have built up with way you have the option of viewing it
    as a configuration files.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we are looking at the Docker and Rancher compose
    files for our Clustered Application stack. To get this view, click on the icon
    to the left of where it says **Active**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker & Rancher Compose](img/B05468_07_76.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This feature allows you to ship your stacks to other Rancher users. The contents
    of the preceding files are given in the following so that you can try it on your
    own Rachner installation.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Compose
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is a standard version one Docker Compose file, there are Rancher settings
    passed as labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Rancher Compose
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Rancher Compose file wraps the containers defined in the Docker Compose
    file in Rancher services, as you can see where we are defining the health checks
    for both the Load Balancer and Cluster containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Rancher Compose is also the name of the command-line tool that can locally install
    to interact with your Rancher installation. As the command line duplicates the
    functionality, we have already covered, I won't be going into any detail about
    it here; however, if you would like give it a go, complete details about it can
    be found in the official Rancher documentation at [http://docs.rancher.com/rancher/rancher-compose/](http://docs.rancher.com/rancher/rancher-compose/).
  prefs: []
  type: TYPE_NORMAL
- en: Back to where we started
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last task we are going to do using Rancher is to launch a Kubernetes cluster
    in DigitalOcean. As mentioned at the start of the chapter, Rancher not only manages
    its own Cattle clusters, but also Kubernetes and Swarm ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a Kubernetes cluster, click on the drop-down menu where it says **Environment**,
    underneath your avatar and click on **Add Environment**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back to where we started](img/B05468_07_77.jpg)'
  prefs: []
  type: TYPE_IMG
- en: On the page, you will be asked which container-orchestration tool would you
    like to use for the environment, what it should be called, and finally who should
    be able to access it.
  prefs: []
  type: TYPE_NORMAL
- en: Select Kubernetes, fill in the remaining information, and click on the **Create**
    button. Once you have your second environment, you will be able to check between
    them on the **Environment** drop-down menu.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to when we first launched Rancher, we will need to add some hosts that
    will make up our Kubernetes cluster. To do this, click on **Add Host** and then
    enter the details as done earlier, apart from this, time call them Kubernetes
    rather than Rancher.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will then be taken to a screen that looks like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back to where we started](img/B05468_07_78.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It will take about 10 minutes to complete the installation. Once it has completed,
    you will be taken to a familiar-looking Rancher screen; however, you will now
    have **Services**, **RCS**, **Pods**, and **kubectl** listed in the secondary
    menu.
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on **kubectl** will take you to a page that allows you to run kubectl
    commands in your browser and also you will get an option to download a kubectl
    config file so that you can interact with Kubernetes from your local machine as
    well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back to where we started](img/B05468_07_79.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Another thing you will notice is that a different catalog has been loaded,
    this is because Docker and Rancher Compose files won''t work with Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Back to where we started](img/B05468_07_80.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Feel free to launch services like we did in the first part of this chapter or
    use the catalog items to create a service.
  prefs: []
  type: TYPE_NORMAL
- en: Removing the hosts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, you will have around seven instances launched in DigitalOcean.
    As we are coming to the end of this chapter, you should terminate all these machines
    so that you do not get charged for resources you are not using.
  prefs: []
  type: TYPE_NORMAL
- en: I would recommend doing this using the DigitalOcean control panel rather than
    through Rancher, that way you can be 100% sure that the Droplets have been successfully
    powered down and removed, meaning that you do not get billed for them.
  prefs: []
  type: TYPE_NORMAL
- en: Summing up Rancher
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you have seen, Rancher is not only an incredibly powerful piece of open source
    software, it is also extremely user-friendly and well-polished.
  prefs: []
  type: TYPE_NORMAL
- en: We have only touched on some of the features of Rancher here, for example, you
    can split your hosts between providers to create your own regions, there is a
    full API that allows you to interact with Rancher from your own applications and
    also there is a full command-line interface.
  prefs: []
  type: TYPE_NORMAL
- en: For a 1.0 release, it is incredibly feature-rich and stable. I don't think I
    saw it having any problems during my time using it.
  prefs: []
  type: TYPE_NORMAL
- en: If you want a tool that allows you launch your own clusters and then give end
    users, such as developers, access to an intuitive interface, then Rancher is going
    to be a match made in heaven.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The three tools that we have looked are not the only schedulers available,
    there are also tools such as the following to name a few:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Nomad**: [https://www.nomadproject.io/](https://www.nomadproject.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fleet**: [https://coreos.com/using-coreos/clustering/](https://coreos.com/using-coreos/clustering/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Marathon**: [https://mesosphere.github.io/marathon/](https://mesosphere.github.io/marathon/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All these schedulers have their own requirements, complexities, and use cases.
  prefs: []
  type: TYPE_NORMAL
- en: If you had asked me a year ago which of the three schedulers that we have looked
    in this chapter would I recommend, I would have said Amazons EC2 Container Service.
    Kubernetes would have been second and I probably wouldn't have mentioned Rancher.
  prefs: []
  type: TYPE_NORMAL
- en: In the past 12 months, Kubernetes has vastly reduced its complexity when it
    comes to installing the service has removed its biggest barrier to people adopting
    it, and as we have demonstrated, Rancher reduces this complexity even further.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, this has left EC2 Container Service feeling like it is a lot
    more complex to both configure and operate when compared to the other tools, especially
    as both Kubernetes and Rancher support launching hosts in Amazon Web Services
    and can take advantage of the myriad of supporting services offer by Amazon's
    public cloud.
  prefs: []
  type: TYPE_NORMAL
- en: In our next and final chapter, we are going to be reviewing all the tools that
    we have looked at throughout the previous chapters, we will come up with some
    use cases as well, and talk about the security considerations that we will need
    to take when using them.
  prefs: []
  type: TYPE_NORMAL
