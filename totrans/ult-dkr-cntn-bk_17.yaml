- en: '17'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying, Updating, and Securing an Application with Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned about the basics of the container orchestrator
    known as Kubernetes. We got a high-level overview of the architecture of Kubernetes
    and learned a lot about the important objects used by Kubernetes to define and
    manage a containerized application.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to deploy, update, and scale applications
    into a Kubernetes cluster. We will also explain how zero-downtime deployments
    are achieved to enable disruption-free updates and rollbacks of mission-critical
    applications. Finally, we will introduce Kubernetes secrets as a means to configure
    services and protect sensitive data.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Deploying our first application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining liveness and readiness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero-downtime deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes secrets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After working through this chapter, you will be able to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Deploy a multi-service application into a Kubernetes cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define a liveness and readiness probe for your Kubernetes application service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update an application service running in Kubernetes without causing downtime
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define secrets in a Kubernetes cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure an application service to use Kubernetes secrets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’re going to use Docker Desktop on our local computer. Please
    refer to [*Chapter 2*](B19199_02.xhtml#_idTextAnchor027), *Setting Up a Working
    Environment*, for more information on how to install and use Docker Desktop.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this chapter can be found here: `main/sample-solutions/ch17`.'
  prefs: []
  type: TYPE_NORMAL
- en: Please make sure you have cloned this book’s GitHub repository, as described
    in [*Chapter 2*](B19199_02.xhtml#_idTextAnchor027).
  prefs: []
  type: TYPE_NORMAL
- en: 'In your Terminal, navigate to the `~/The-Ultimate-Docker-Container-Book` folder
    and create a subfolder called `ch17` and navigate to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Deploying our first application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will take our pets application, which we first introduced in [*Chapter 11*](B19199_11.xhtml#_idTextAnchor237),
    *Managing Containers with* *Docker Compose*, and deploy it into a Kubernetes cluster.
    Our cluster will be Docker Desktop, which, as you know, is offering us a single
    node Kubernetes cluster. However, from the perspective of deployment, it doesn’t
    matter how big the cluster is and whether the cluster is located in the cloud,
    in your company’s data center, or on your workstation.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the web component
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Just as a reminder, our application consists of two application services: the
    Node-based web component and the backing PostgreSQL database. In the previous
    chapter, we learned that we need to define a Kubernetes Deployment object for
    each application service we want to deploy. We’ll do this for the web component
    first. As always in this book, we will choose the declarative way of defining
    our objects:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use our local Kubernetes single-node cluster provided by Docker Desktop.
    Make sure Kubernetes is turned on for your Docker Desktop installation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 17.1 – Kubernetes on Docker Desktop](img/Figure_17.01_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.1 – Kubernetes on Docker Desktop
  prefs: []
  type: TYPE_NORMAL
- en: 'To your code subfolder (`ch17`), add a file called `web-deployment.yaml` with
    the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 17.2 – Kubernetes deployment definition for the web component](img/Figure_17.02_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.2 – Kubernetes deployment definition for the web component
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding deployment definition can be found in the `web-deployment.yaml`
    file in the `sample-solutions/ch17` subfolder. It contains the instructions necessary
    to deploy the `web` component. The lines of code are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Line 7: We define the name for our `Deployment` object as `web`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Line 9: We declare that we want to have one instance of the `web` component
    running.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lines 11 to 13: Through `Selector`, we define which pods will be part of our
    deployment, namely those that have the `app` and `service` labels with values
    of `pets` and `web`, respectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Line 14: In the template for the pods starting at line 11, we define that each
    pod will have the `app` and `service` labels applied to them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lines 20 onward: We define the single container that will be running in the
    pod. The image for the container is our well-known `fundamentalsofdocker/ch11-web:2.0`
    image and the name of the container will be `web`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lines 23 and 24: It is worth noting that we declare that the container exposes
    port `3000` to incoming traffic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Please make sure that you have set the context of `kubectl` to Docker Desktop.
    See [*Chapter 2*](B19199_02.xhtml#_idTextAnchor027), *Setting Up a Working Environment*,
    for details on how to do that. Use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will receive the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We can deploy this `Deployment` object using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding command outputs the following message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can double-check that the deployment has been created again using our Kubernetes
    CLI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.3 – Listing all the resources running in Kind](img/Figure_17.03_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.3 – Listing all the resources running in Kind
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding output, we can see that Kubernetes created three objects –
    the deployment, a pertaining `ReplicaSet`, and a single pod (remember that we
    specified that we want one replica only). The current state corresponds to the
    desired state for all three objects, so we are fine so far.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, the web service needs to be exposed to the public. For this, we need to
    define a Kubernetes `Service` object of the `NodePort` type. Create a new file
    called `web-service.yaml` and add the following code to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 17.4 – Definition of the Service object for our web component](img/Figure_17.04_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.4 – Definition of the Service object for our web component
  prefs: []
  type: TYPE_NORMAL
- en: Once again, the same file can be found in the `web-service.yaml` file in the
    `sample-solutions/ch17` subfolder.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding lines of code are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Line 7: We set the name of this `Service` object to `web`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Line 9: We define the type of `Service` object we’re using. Since the `web`
    component has to be accessible from outside of the cluster, this cannot be a `Service`
    object of the `ClusterIP` type and must be of the `NodePort` or `LoadBalancer`
    type. We discussed the various types of Kubernetes services in the previous chapter,
    so will not go into further detail about this. In our example, we’re using a `NodePort`
    type of service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lines 10 to 13: We specify that we want to expose port `3000` for access through
    the TCP protocol. Kubernetes will map container port `3000` automatically to a
    free host port in the range of 30,000 to 32,768\. Which port Kubernetes effectively
    chooses can be determined using the `kubectl get service` or `kubectl describe`
    command for the service after it has been created.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lines 14 to 16: We define the filter criteria for the pods that this service
    will be a stable endpoint for. In this case, it is all the pods that have the
    `app` and `service` labels with the `pets` and `web` values, respectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that we have this specification for a `Service` object, we can create it
    using `kubectl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can list all the services to see the result of the preceding command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding command produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.5 – The Service object that was created for the web component](img/Figure_17.05_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.5 – The Service object that was created for the web component
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding output, we can see that a service called `web` has been created.
    A unique `ClusterIP` value of `10.96.195.255` has been assigned to this service,
    and container port `3000` has been published on port `30319` on all cluster nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to test this deployment, we can use `curl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the response is `Pets Demo Application`, which is what we expected.
    The web service is up and running in the Kubernetes cluster. Next, we want to
    deploy the database.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A database is a stateful component and has to be treated differently from stateless
    components, such as our web component. We discussed the difference between stateful
    and stateless components in a distributed application architecture in detail in
    [*Chapter 9*](B19199_09.xhtml#_idTextAnchor194),*Learning about* *Distributed
    Application Architecture*, and [*Chapter 3*](B19199_03.xhtml#_idTextAnchor057),
    *Introducing* *Container Orchestration*.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes has defined a special type of `ReplicaSet` object for stateful components.
    This object is called `StatefulSet`. Let’s use this kind of object to deploy our
    database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new file called `db-stateful-set.yaml` and add the following content
    to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 17.6 – A StatefulSet object for the DB component](img/Figure_17.06_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.6 – A StatefulSet object for the DB component
  prefs: []
  type: TYPE_NORMAL
- en: The definition can also be found in the `sample-solutions/ch17` subfolder.
  prefs: []
  type: TYPE_NORMAL
- en: OK; this looks a bit scary, but it isn’t. It is a bit longer than the definition
    of the deployment for the web component since we also need to define a volume
    where the PostgreSQL database can store the data. The volume claim definition
    is on lines 25 to 33.
  prefs: []
  type: TYPE_NORMAL
- en: We want to create a volume called `pets-data` that has a maximum size equal
    to 100 MB. On lines 22 to 24, we use this volume and mount it into the container
    at `/var/lib/postgresql/data`, where PostgreSQL expects it. On line 21, we also
    declare that PostgreSQL is listening at port `5432`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As always, we use `kubectl` to deploy our `StatefulSet`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, if we list all the resources in the cluster, we will be able to see the
    additional objects that were created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 17.7 – The StatefulSet and its pod](img/Figure_17.07_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.7 – The StatefulSet and its pod
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that `StatefulSet` and a pod have been created. For both, the
    current state corresponds to the desired state and thus the system is healthy,
    but that doesn’t mean that the `web` component can access the database at this
    time. Service discovery won’t work. Remember that the `web` component wants to
    access the `db` service under the name `db`. We hardcoded the `db` hostname in
    the `server.js` file.
  prefs: []
  type: TYPE_NORMAL
- en: To make service discovery work inside the cluster, we have to define a Kubernetes
    `Service` object for the database component too. Since the database should only
    ever be accessible from within the cluster, the type of `Service` object we need
    is `ClusterIP`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a new file called `db-service.yaml` and add the following specification
    to it. It can be found in the `sample-solutions/ch17` subfolder:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.8 – Definition of the Kubernetes Service object for the database](img/Figure_17.08_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.8 – Definition of the Kubernetes Service object for the database
  prefs: []
  type: TYPE_NORMAL
- en: 'The database component will be represented by this `Service` object. It can
    be reached by the name `db`, which is the name of the service, as defined on line
    4\. The database component does not have to be publicly accessible, so we decided
    to use a `Service` object of the `ClusterIP` type. The selector on lines 10 to
    12 defines that this service represents a stable endpoint for all the pods that
    have the necessary labels defined – that is, `app: pets` and `service: db`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s deploy this service with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we should be ready to test the application. We can use the browser this
    time to enjoy the beautiful animal images from the Maasai Mara national park in
    Kenya:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 17.9 – Testing the pets application running in Kubernetes](img/Figure_17.09_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.9 – Testing the pets application running in Kubernetes
  prefs: []
  type: TYPE_NORMAL
- en: In this case, port number `30317` is the number that Kubernetes automatically
    selected for my `web` `Service` object. Replace this number with the port that
    Kubernetes assigned to your service. You can get the number by using the `kubectl
    get` `services` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that, we have successfully deployed the pets application to a single-node
    Kubernetes cluster provided by Docker Desktop. We had to define four artifacts
    to do so, which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Deployment` and `Service` objects for the `web` component'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`StatefulSet` and `Service` objects for the `database` component'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To remove the application from the cluster, we can use the following small
    script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Please note the last line in this script. We are deleting the persistent volume
    claim that Kubernetes automatically created as part of the `db` deployment. When
    we delete the `db` deployment, this claim is not automatically deleted! Persistent
    volume claims are a bit similar (but not the same, mind you) as Docker volumes.
  prefs: []
  type: TYPE_NORMAL
- en: Use the `kubectl get pvc` command to get a list of all claims on your machine.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will optimize the deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Streamlining the deployment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, we have created four artifacts that needed to be deployed to the cluster.
    This is only a very simple application, consisting of two components. Imagine
    having a much more complex application. It would quickly become a maintenance
    nightmare. Luckily, we have several options as to how we can simplify the deployment.
    The method that we are going to discuss here is the possibility of defining all
    the components that make up an application in Kubernetes in a single file.
  prefs: []
  type: TYPE_NORMAL
- en: Other solutions that lie outside the scope of this book include using a package
    manager, such as Helm ([https://helm.sh/](https://helm.sh/)), or Kustomize ([https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/)),
    the native Kubernetes solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we have an application consisting of many Kubernetes objects, such as `Deployment`
    and `Service` objects, then we can keep them all in a single file and separate
    the individual object definitions by three dashes. For example, if we wanted to
    have the `Deployment` and `Service` definitions for the `web` component in a single
    file, this would look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.10 – Deployment and Service for web in a single file](img/Figure_17.10_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.10 – Deployment and Service for web in a single file
  prefs: []
  type: TYPE_NORMAL
- en: You can find this file in `sample-solutions/ch17/install-web.yaml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we collected all four object definitions for the pets application in
    the `sample-solutions/ch17/install-pets.yaml` file, and we can deploy the application
    in one go:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give us this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we created a script called `sample-solutions/ch17/remove-pets.sh`
    to remove all the artifacts of the pets application from the Kubernetes cluster.
    Note that the file was made executable with `chmod +x ./remove-pets.sh` first.
    Now, we can use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in an output like is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This will delete all the resources except the persistent volume claim, which
    you still need to delete by hand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: With this, we have taken the pets application we introduced in [*Chapter 11*](B19199_11.xhtml#_idTextAnchor237)*,*
    *Managing Containers with* *Docker Compose*, and defined all the Kubernetes objects
    that are necessary to deploy this application into a Kubernetes cluster. In each
    step, we made sure that we got the expected result, and once all the artifacts
    existed in the cluster, we showed the running application.
  prefs: []
  type: TYPE_NORMAL
- en: Defining liveness and readiness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Container orchestration systems such as Kubernetes and Docker Swarm make it
    significantly easier to deploy, run, and update highly distributed, mission-critical
    applications. The orchestration engine automates many cumbersome tasks, such as
    scaling up or down, asserting that the desired state is maintained at all times,
    and more.
  prefs: []
  type: TYPE_NORMAL
- en: However, the orchestration engine cannot just do everything automatically. Sometimes,
    we developers need to support the engine with some information that only we can
    know about. So, what do I mean by that?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at a single application service. Let’s assume it is a microservice
    and let’s call it service A. If we run service A containerized on a Kubernetes
    cluster, then Kubernetes can make sure that we have the five instances that we
    require in the service definition running at all times. If one instance crashes,
    Kubernetes can quickly launch a new instance and thus maintain the desired state.
    But what if an instance of the service does not crash, but is unhealthy or just
    not ready yet to serve requests? Kubernetes should know about both situations.
    But it can’t, since good or bad health from an application service perspective
    is outside of the knowledge of the orchestration engine. Only we application developers
    can know when our service is healthy and when it is not.
  prefs: []
  type: TYPE_NORMAL
- en: The application service could, for example, be running, but its internal state
    could have been corrupted due to some bug, it could be in an endless loop, or
    it could be in a deadlock situation.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, only we application developers know whether our service is ready
    to work, or whether it is still initializing. Although it is highly recommended
    to keep the initialization phase of a microservice as short as possible, it often
    cannot be avoided if a significant time span is needed by a particular service
    so that it’s ready to operate. Being in this state of initialization is not the
    same thing as being unhealthy, though. The initialization phase is an expected
    part of the life cycle of a microservice or any other application service.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, Kubernetes should not try to kill our microservice if it is in the initialization
    phase. If our microservice is unhealthy, though, Kubernetes should kill it as
    quickly as possible and replace it with a fresh instance.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes has the concept of probes to provide the seam between the orchestration
    engine and the application developer. Kubernetes uses these probes to find out
    more about the inner state of the application service at hand. Probes are executed
    locally, inside each container. There is a probe for the health – also called
    liveness – of the service, a startup probe, and a probe for the readiness of the
    service. Let’s look at them in turn.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes liveness probes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes uses the liveness probe to decide when a container needs to be killed
    and when another instance should be launched instead. Since Kubernetes operates
    at a pod level, the respective pod is killed if at least one of its containers
    reports as being unhealthy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, we can say it the other way around: only if all the containers
    of a pod report to be healthy is the pod considered to be healthy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can define the liveness probe in the specification for a pod as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The relevant part is in the `livenessProbe` section. First, we define a command
    that Kubernetes will execute as a probe inside the container. In our case, we
    have a `PostreSQL` container and use the `netcat` Linux tool to probe port `5432`
    over TCP. The `nc localhost 5432` command is successful once Postgres listens
    to it.
  prefs: []
  type: TYPE_NORMAL
- en: The other two settings, `initialDelaySeconds` and `periodSeconds`, define how
    long Kubernetes should wait after starting the container until it first executes
    the probe and how frequently the probe should be executed thereafter. In our case,
    Kubernetes waits for 10 seconds before executing the first probe and then executes
    a probe every 5 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is also possible to probe an HTTP endpoint instead of using a command. Let’s
    assume we’re running a microservice from an image, `acme.com/my-api:1.0`, with
    an API that has an endpoint called `/api/health` that returns status `200 (OK)`
    if the microservice is healthy, and `50x (Error)` if it is unhealthy. Here, we
    can define the liveness probe as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding snippet, I defined the liveness probe so that it uses the HTTP
    protocol and executed a `GET` request to the `/api/health` endpoint on port `5000`
    of `localhost`. Remember, the probe is executed inside the container, which means
    I can use localhost.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also directly use the TCP protocol to probe a port on the container.
    But wait a second – didn’t we just do that in our first example, where we used
    the generic liveness probe based on an arbitrary command? Yes, you’re right, we
    did, but we had to rely on the presence of the `netcat` tool in the container
    to do so. We cannot assume that this tool is always there. Thus, it is favorable
    to rely on Kubernetes to do the TCP-based probing for us out of the box. The modified
    pod spec looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This looks very similar. The only change is that the type of probe has been
    changed from `exec` to `tcpSocket` and that, instead of providing a command, we
    provide the port to probe.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we could also use `failureThreshold` here with Kubernetes’ `livenessProbe`.
    The `livenessProbe` failure threshold in Kubernetes is the minimum number of consecutive
    failures that must occur before the container is restarted. The default value
    is `3`. The minimum value is `1`. If the handler returns a failure code, `kubelet`
    kills the container and restarts it. Any code greater than or equal to `200` and
    less than `400` indicates success. Any other code indicates failure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try this out:'
  prefs: []
  type: TYPE_NORMAL
- en: Copy the `probes` subfolder from the `sample-solutions/ch17` folder to your
    `ch17` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Build the Docker image with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `kubectl` to deploy the sample pod that’s defined in `probes-demo.yaml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Describe the pod and specifically analyze the log part of the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'During the first half minute or so, you should get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.11 – Log output of the healthy pod](img/Figure_17.11_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.11 – Log output of the healthy pod
  prefs: []
  type: TYPE_NORMAL
- en: 'Wait at least 30 seconds and then describe the pod again. This time, you should
    see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 17.12 – Log output of the pod after it has changed its state to Unhealthy](img/Figure_17.12_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.12 – Log output of the pod after it has changed its state to Unhealthy
  prefs: []
  type: TYPE_NORMAL
- en: The marked lines indicate the failure of the probe and the fact that the pod
    is going to be restarted.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you get the list of pods, you will see that the pod has been restarted several
    times:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This results in this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'When you’re done with the sample, delete the pod with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we will have a look at the Kubernetes readiness probe.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes readiness probes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes uses a readiness probe to decide when a service instance – that is,
    a container – is ready to accept traffic. Now, we all know that Kubernetes deploys
    and runs pods and not containers, so it only makes sense to talk about the readiness
    of a pod. Only if all containers in a pod report as ready is the pod considered
    to be ready itself. If a pod reports as not ready, then Kubernetes removes it
    from the service load balancers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Readiness probes are defined the same way as liveness probes: just switch the
    `livenessProbe` key in the pod spec to `readinessProbe`. Here is an example using
    our prior pod spec:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Note that, in this example, we don’t need an initial delay for the liveness
    probe anymore since we now have a readiness probe. Thus, I have replaced the initial
    delay entry for the liveness probe with an entry called `failureThreshold`, which
    indicates how many times Kubernetes should repeat probing in case of a failure
    until it assumes that the container is unhealthy.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes startup probes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is often helpful for Kubernetes to know when a service instance has started.
    If we define a startup probe for a container, then Kubernetes does not execute
    the liveness or readiness probes, so long as the container’s startup probe does
    not succeed. Once again, Kubernetes looks at pods and starts executing liveness
    and readiness probes on its containers if the startup probes of all the pod’s
    containers succeed.
  prefs: []
  type: TYPE_NORMAL
- en: When would we use a startup probe, given the fact that we already have the liveness
    and readiness probes? There might be situations where we have to account for exceptionally
    long startup and initialization times, such as when containerizing a legacy application.
    We could technically configure the readiness or liveness probes to account for
    this fact, but that would defeat the purpose of these probes. The latter probes
    are meant to provide quick feedback to Kubernetes on the health and availability
    of the container. If we configure for long initial delays or periods, then this
    would counter the desired outcome.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unsurprisingly, the startup probe is defined the same way as the readiness
    and liveness probes. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Make sure that you define the `failureThreshold * periodSeconds` product so
    that it’s big enough to account for the worst startup time.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, the max startup time should not exceed 150 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Zero-downtime deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a mission-critical environment, the application must be always up and running.
    These days, we cannot afford downtime anymore. Kubernetes gives us various means
    of achieving this. Performing an update on an application in the cluster that
    causes no downtime is called a **zero-downtime deployment**. In this section,
    we will present two ways of achieving this. These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Rolling updates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blue-green deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start by discussing rolling updates.
  prefs: []
  type: TYPE_NORMAL
- en: Rolling updates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, we learned that the Kubernetes `Deployment` object
    distinguishes itself from the `ReplicaSet` object in that it adds rolling updates
    and rollbacks on top of the latter’s functionality. Let’s use our web component
    to demonstrate this. We will have to modify the manifest or description of the
    deployment for the web component.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the same deployment definition as in the previous section, with
    one important difference – we will have `web` component running. The following
    definition can also be found in the `sample-solutions/ch17/web-deployment-rolling-v1.yaml`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.13 – Deployment for the web component with five replicas](img/Figure_17.13_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.13 – Deployment for the web component with five replicas
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can create this deployment as usual and also, at the same time, the
    service that makes our component accessible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have deployed the pods and the service, we can test our web component.
    First, we can get the assigned node port with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we can use the `$PORT` environment variable in our `curl` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This provides the expected output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the application is up and running and returns the expected message,
    `Pets` `Demo Application`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our developers have created a new version, 2.1, of the web component. The code
    of the new version of the web component can be found in the `sample-solutions/ch17/web`
    folder, and the only change is located on line 12 of the `server.js` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.14 – Code change for version 2.0 of the web component](img/Figure_17.14_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.14 – Code change for version 2.0 of the web component
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now build the new image as follows (replace `demo` with your GitHub
    username):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Subsequently, we can push the image to Docker Hub, as follows (replace `demo`
    with your GitHub username):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we want to update the image that’s used by our pods that are part of the
    `web` `Deployment` object. We can do this by using the `set image` command of
    `kubectl`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'If we test the application again, we’ll get a confirmation that the update
    has indeed happened:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The output indicates that we now have version 2 installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, how do we know that there hasn’t been any downtime during this update?
    Did the update happen in a rolling fashion? What does rolling update mean at all?
    Let’s investigate. First, we can get a confirmation from Kubernetes that the deployment
    has indeed happened and was successful by using the `rollout` `status` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The command will respond as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'If we describe the `web` deployment object with `kubectl describe deploy/web`,
    we will get the following list of events at the end of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.15 – List of events found in the output of the deployment description
    of the web component](img/Figure_17.15_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.15 – List of events found in the output of the deployment description
    of the web component
  prefs: []
  type: TYPE_NORMAL
- en: 'The first event tells us that, when we created the deployment, a `ReplicaSet`
    object called `web-769b88f67` with five replicas was created. Then, we executed
    the `update` command. The second event in the list tells us that this meant creating
    a new `ReplicaSet` object called `web-55cdf67cd` with, initially, one replica
    only. Thus, at that particular moment, six pods existed on the system: the five
    initial pods and one pod with the new version. But, since the desired state of
    the `Deployment` object states that we want five replicas only, Kubernetes now
    scales down the old `ReplicaSet` object to four instances, which we can see in
    the third event.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, again, the new `ReplicaSet` object was scaled up to two instances, and,
    subsequently, the old `ReplicaSet` object was scaled down to three instances,
    and so on, until we had five new instances and all the old instances were decommissioned.
    Although we cannot see any precise time (other than 3 minutes) when that happened,
    the order of the events tells us that the whole update happened in a rolling fashion.
  prefs: []
  type: TYPE_NORMAL
- en: During a short period, some of the calls to the web service would have had an
    answer from the old version of the component, and some calls would have received
    an answer from the new version of the component, but at no time would the service
    have been down.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also list the `ReplicaSet` objects in the cluster and get confirmation
    of what I said in the preceding section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.16 – Listing all the ReplicaSet objects in the cluster](img/Figure_17.16_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.16 – Listing all the ReplicaSet objects in the cluster
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the new `ReplicaSet` object has five instances running
    and that the old one has been scaled down to zero instances. The reason that the
    old `ReplicaSet` object is still lingering is that Kubernetes provides us with
    the possibility of rolling back the update and, in that case, will reuse that
    `ReplicaSet`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To roll back the update of the image in case some undetected bug sneaked into
    the new code, we can use the `rollout` `undo` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This outputs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We can test whether the rollback was successful like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, the output shows us that this is the case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'If we list the `ReplicaSet` objects, we will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.17 – Listing the ReplicaSet objects after rolling back](img/Figure_17.17_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.17 – Listing the ReplicaSet objects after rolling back
  prefs: []
  type: TYPE_NORMAL
- en: This confirms that the old `ReplicaSet` (`web-9d66cd994`) object has been reused
    and that the new one has been scaled down to zero instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before continuing, please delete the deployment and the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Sometimes, though, we cannot, or do not want to, tolerate the mixed state of
    an old version coexisting with the new version. We want an all-or-nothing strategy.
    This is where blue-green deployments come into play, which we will discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: Blue-green deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we want to do a blue-green style deployment for our `web` component of the
    pets application, then we can do so by using labels creatively. First, let’s remind
    ourselves how blue-green deployments work. Here is a rough step-by-step guide:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploy the first version of the `web` component as `blue`. We will label the
    pods with a label of `color: blue` to do so.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy the Kubernetes service for these pods with the `color: blue` label in
    the `selector` section.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we can deploy version 2 of the web component, but, this time, the pods
    have a label of `color: green`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can test the green version of the service to check that it works as expected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, we can flip traffic from `blue` to `green` by updating the Kubernetes service
    for the web component. We will modify the selector so that it uses the `color:`
    `green` label.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s define a `Deployment` object for version 1, `blue`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.18 – Specification of the blue deployment for the web component](img/Figure_17.18_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.18 – Specification of the blue deployment for the web component
  prefs: []
  type: TYPE_NORMAL
- en: The preceding definition can be found in the `sample-solutions/ch17/web-deployment-blue.yaml`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please take note of line 8, where we define the name of the deployment as `web-blue`
    to distinguish it from the upcoming deployment, `web-green`. Also, note that we
    have added the `color: blue` label on lines 7, 15, and 21\. Everything else remains
    the same as before.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can define the `Service` object for the web component. It will be the
    same as the one we used before but with a minor change, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.19 – Kubernetes service for the web component supporting blue-green
    deployments](img/Figure_17.19_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.19 – Kubernetes service for the web component supporting blue-green
    deployments
  prefs: []
  type: TYPE_NORMAL
- en: 'The only difference regarding the definition of the service we used earlier
    in this chapter is line 17, which adds the `color: blue` label to the selector.
    We can find the preceding definition in the `sample-solutions/ch17/web-service-blue-green.yaml`
    file.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we can deploy the blue version of the `web` component with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'We can deploy its service with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the service is up and running, we can determine its IP address and port
    number and test it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can access it with the `curl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us what we expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can deploy the green version of the `web` component. The definition
    of its `Deployment` object can be found in the `sample-solutions/ch17/web-deployment-green.yaml`
    file and looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.20 – Specification of the green deployment for the web component](img/Figure_17.20_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.20 – Specification of the green deployment for the web component
  prefs: []
  type: TYPE_NORMAL
- en: 'The interesting lines are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Line 8: Named `web-green` to distinguish it from `web-blue` and allow for parallel
    installation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lines 7, 15, and 21: Have the color green'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Line 24: Now using version 2.1 of the web image we built earlier in this chapter'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not forget to change ‘‘`demo`’’ to your own GitHub username on line 24.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we’re ready to deploy this green version of the service. It should run
    separately from the blue service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'We can make sure that both deployments coexist like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.21 – Displaying the list of Deployment objects running in the cluster](img/Figure_17.21_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.21 – Displaying the list of Deployment objects running in the cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'As expected, we have both blue and green running. We can verify that blue is
    still the active service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'We should still receive the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Now comes the interesting part: we can flip traffic from `blue` to `green`
    by editing the existing service for the web component. To do so, execute the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Change the value of the label color from `blue` to `green`. Then, save and
    quit the editor. The Kubernetes CLI will automatically update the service. Now,
    when we query the web service again, we’ll get this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, we should get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: This confirms that the traffic has indeed switched to the green version of the
    web component (note `v2` at the end of the response to the `curl` command).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If we wanted to stick to the declarative form, it would be better to update
    the `web-service-blue-green.yaml` file and apply the new version so that the desired
    state is still present in a file, avoiding potential mismatch in reality and the
    file. However, for illustration, the presented way is fine.
  prefs: []
  type: TYPE_NORMAL
- en: If we realize that something went wrong with our green deployment and the new
    version has a defect, we can easily switch back to the blue version by editing
    the web service again and replacing the value of the `color` label with blue.
    This rollback is instantaneous and should always work. Then, we can remove the
    buggy green deployment and fix the component. Once we have corrected the problem,
    we can deploy the green version once again.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the green version of the component is running as expected and performing
    well, we can decommission the blue version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: When we’re ready to deploy a new version, 3.0, this one becomes the blue version.
    We must update the `ch17/web-deployment-blue.yaml` file accordingly and deploy
    it. Then, we must flip the web service from `green` to `blue`, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: With that, we have successfully demonstrated, with our `web` component of the
    pets application, how blue-green deployment can be achieved in a Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we are going to learn how to deal with secrets used by applications running
    on Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes secrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, services that we want to run in the Kubernetes cluster have to use
    confidential data such as passwords, secret API keys, or certificates, to name
    just a few. We want to make sure that this sensitive information can only ever
    be seen by the authorized or dedicated service. All other services running in
    the cluster should not have any access to this data.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, Kubernetes secrets were introduced. A secret is a key-value
    pair where the key is the unique name of the secret, and the value is the actual
    sensitive data. Secrets are stored in `etcd`. Kubernetes can be configured so
    that secrets are encrypted at rest – that is, in `etcd` – and in transit – that
    is, when the secrets are going over the wire from a master node to the worker
    nodes that the pods of the service using this secret are running on.
  prefs: []
  type: TYPE_NORMAL
- en: Manually defining secrets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can create a secret declaratively in the same way as we can create any other
    object in Kubernetes. Here is the YAML for such a secret:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: The preceding definition can be found in the `sample-solutions/ch17/pets-secret.yaml`
    file. Now, you might be wondering what the values are. Are these the real (unencrypted)
    values? No, they are not. And they are also not encrypted values, but just `base64`-encoded
    values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, they are not really secure, since base64-encoded values can easily be
    reverted to cleartext values. How did I get these values? That’s easy – follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `base64` tool as follows to encode the values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, try the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the preceding values, we can create the secret:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, the command outputs this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'We can describe the secret with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of the preceding command looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.22 – Creating and describing the Kubernetes secret](img/Figure_17.22_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.22 – Creating and describing the Kubernetes secret
  prefs: []
  type: TYPE_NORMAL
- en: 'In the description of the secret, the values are hidden and only their length
    is given. So, maybe the secrets are safe now. No, not really. We can easily decode
    this secret using the `kubectl` `get` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.23 – Kubernetes secret decoded](img/Figure_17.23_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.23 – Kubernetes secret decoded
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the preceding screenshot, we have our original secret values
    back.
  prefs: []
  type: TYPE_NORMAL
- en: 'Decode the values you got previously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Thus, the consequence is that this method of creating a Kubernetes secret is
    not to be used in any environment other than development, where we deal with non-sensitive
    data. In all other environments, we need a better way to deal with secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Creating secrets with kubectl
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A much safer way to define secrets is to use `kubectl`. First, we must create
    files containing the base64-encoded secret values, similar to what we did in the
    preceding section, but, this time, we must store the values in temporary files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can use `kubectl` to create a secret from those files, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: The secret can then be used the same way as the manually created secret.
  prefs: []
  type: TYPE_NORMAL
- en: Why is this method more secure than the other one, you might ask? Well, first
    of all, no YAML defines a secret, and it is stored in some source code version
    control system, such as GitHub, which many people have access to, so they can
    see and decode the secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Only the admin that is authorized to know the secrets ever sees their values
    and uses them to directly create the secrets in the (production) cluster. The
    cluster itself is protected by role-based access control so that no unauthorized
    persons have access to it, nor can they possibly decode the secrets defined in
    the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s see how we can use the secrets that we have defined.
  prefs: []
  type: TYPE_NORMAL
- en: Using secrets in a pod
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s say we want to create a `Deployment` object where the `web` component
    uses our secret, `pets-secret`, which we introduced in the preceding section.
    We can use the following command to create the secret in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `sample-solutions/ch17/web-deployment-secret.yaml` file, we can find
    the definition of the `Deployment` object. We had to add the part starting from
    line 23 to the original definition of the `Deployment` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.24 – The Deployment object for the web component with a secret](img/Figure_17.24_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.24 – The Deployment object for the web component with a secret
  prefs: []
  type: TYPE_NORMAL
- en: On lines 29 through 32, we define a volume called `secrets` from our secret,
    `pets-secret`. Then, we use this volume in the container, as described on lines
    25 through 28.
  prefs: []
  type: TYPE_NORMAL
- en: We mount the secrets in the container filesystem at `/etc/secrets` and mount
    the volume in read-only mode. Thus, the secret values will be available to the
    container as files in said folder. The names of the files will correspond to the
    key names, and the content of the files will be the values of the corresponding
    keys. The values will be provided in unencrypted form to the application running
    inside the container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply the deployment with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'In our case, since we have the username and password keys in the secret, we
    will find two files, named `username` and `password`, in the `/etc/secrets` folder
    in the container filesystem. The `username` file should contain the `john.doe`
    value and the `password` file should contain the `sEcret-pasSw0rD` value. Let’s
    confirm this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will get the name of the pod:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will give us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.25 – Looking for the name of the pod](img/Figure_17.25_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.25 – Looking for the name of the pod
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the pod’s name, we can execute the commands shown in the following screenshot
    to retrieve the secrets:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 17.26 – Confirming that secrets are available inside the container](img/Figure_17.26_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.26 – Confirming that secrets are available inside the container
  prefs: []
  type: TYPE_NORMAL
- en: On line 1 of the preceding output, we `exec` into the container where the `web`
    component runs. Then, on lines 2 to 5, we list the files in the `/etc/secrets`
    folder, and, finally, on the last 3 lines, we show the content of the two files,
    which, unsurprisingly, shows the secret values in clear text.
  prefs: []
  type: TYPE_NORMAL
- en: Since any application written in any language can read simple files, this mechanism
    of using secrets is very backward-compatible. Even an old Cobol application can
    read clear text files from the filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before leaving, please delete the Kubernetes deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Sometimes, though, applications expect secrets to be available in environment
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at what Kubernetes offers us in this case.
  prefs: []
  type: TYPE_NORMAL
- en: Secret values in environment variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s say our web component expects the username in the `PETS_USERNAME` environment
    variable and the password in the `PETS_PASSWORD` environment variable. If this
    is the case, we can modify our deployment YAML file so that it looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.27 – Deployment mapping secret values to environment variables](img/Figure_17.27_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.27 – Deployment mapping secret values to environment variables
  prefs: []
  type: TYPE_NORMAL
- en: On lines 25 through 35, we define the two environment variables, `PETS_USERNAME`
    and `PETS_PASSWORD`, and map the corresponding key-value pair of `pets-secret`
    to them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply the updated deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we don’t need a volume anymore; instead, we directly map the individual
    keys of `pets-secret` to the corresponding environment variables that are valid
    inside the container. The following sequence of commands shows that the secret
    values are indeed available inside the container in the respective environment
    variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.28 – The secret values have been mapped to environment variables](img/Figure_17.28_B19199.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.28 – The secret values have been mapped to environment variables
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have shown you how to define secrets in a Kubernetes cluster
    and how to use those secrets in containers running as part of the pods of a deployment.
    We have shown two variants of how secrets can be mapped inside a container – using
    files and using environment variables.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to deploy an application into a Kubernetes cluster
    and how to set up application-level routing for this application. Furthermore,
    we learned how to update application services running in a Kubernetes cluster
    without causing any downtime. Finally, we used secrets to provide sensitive information
    to application services running in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to learn about different techniques that are
    used to monitor an individual service or a whole distributed application running
    on a Kubernetes cluster. We will also learn how we can troubleshoot an application
    service that is running in production without altering the cluster or the cluster
    nodes that the service is running on. Stay tuned.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are a few links that provide additional information on the topics that
    were discussed in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Performing a rolling* *update*: [https://bit.ly/2o2okEQ](https://bit.ly/2o2okEQ)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Blue-green* *deployment*: [https://bit.Ly/2r2IxNJ](https://bit.Ly/2r2IxNJ)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Secrets in* *Kubernetes*: [https://bit.ly/2C6hMZF](https://bit.ly/2C6hMZF)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To assess your learning progress, please answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: You have an application consisting of two services, the first one being a web
    API and the second one being a database, such as MongoDB. You want to deploy this
    application into a Kubernetes cluster. In a few short sentences, explain how you
    would proceed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are liveness and readiness probes in the context of a Kubernetes application
    service?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe in your own words what components you need to establish layer 7 (or
    application-level) routing for your application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List the main steps needed to implement a blue-green deployment for a simple
    application service. Avoid going into too much detail.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name three or four types of information that you would provide to an application
    service through Kubernetes secrets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name the sources that Kubernetes accepts when creating a secret.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you configure an application service to use Kubernetes secrets?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are the answers to this chapter’s questions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming we have a Docker image in a registry for the two application services
    – the web API and MongoDB – we need to do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a deployment for MongoDB using a `StatefulSet` object; let’s call this
    deployment `db-deployment`. The `StatefulSet` object should have one replica (replicating
    MongoDB is a bit more involved and is outside the scope of this book).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a Kubernetes service called `db` of the `ClusterIP` type for `db-deployment`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a deployment for the web API; let’s call it `web-deployment`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s scale this service to three instances.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a Kubernetes service called `api` of the `NodePort` type for `web-deployment`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: If we are using secrets, then define those secrets directly in the cluster using
    `kubectl`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the application using `kubectl`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Liveness and readiness probes are health checks provided by Kubernetes for containers.
    A liveness probe checks whether a container is still running, and if not, Kubernetes
    automatically restarts it. A readiness probe checks whether a container is ready
    to serve requests. If a container fails the readiness check, it is not removed,
    but it does not receive incoming requests until it passes the readiness probe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To implement layer 7 routing for an application, we ideally use `IngressController`.
    This is a reverse proxy such as Nginx that has a sidecar listening on the Kubernetes
    Server API for relevant changes and updating the reverse proxy’s configuration
    and restarting it if such a change has been detected. Then, we need to define
    ingress resources in the cluster that define the routing, for example, from a
    context-based route such as `https://example.com/pets` to `<a service name>/<port>`
    or a pair such as `api/32001`. The moment Kubernetes creates or changes this `Ingress`
    object, the sidecar of `IngressController` picks it up and updates the proxy’s
    routing configuration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Assuming this is a cluster internal inventory service, then we do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When deploying version 1.0, we define a deployment called `inventory-deployment-blue`
    and label the pods with a label of `color:blue`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: We deploy the Kubernetes service of the `ClusterIP` type called `inventory`
    for the preceding deployment with the selector containing `color:blue`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: When we’re ready to deploy the new version of the `payments` service, we define
    a deployment for version 2.0 of the service and call it `inventory-deployment-green`.
    We add a label of `color:green` to the pods.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: We can now smoke-test the “green” service and when everything is OK, we can
    update the inventory service so that the selector contains `color:green`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Some forms of information that are confidential and thus should be provided
    to services through Kubernetes secrets include passwords, certificates, API key
    IDs, API key secrets, and tokens.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sources for secret values can be files or base64-encoded values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To configure an application to use a Kubernetes secret, you must create a `Secret`
    object with the sensitive data. Then, you must modify your `Pod` specification
    so that it includes a reference to the `Secret` object. This reference can be
    made as an environment variable in the container specification or as a volume
    mount, allowing the secret data to be used by your application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
