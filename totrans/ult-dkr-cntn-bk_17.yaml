- en: '17'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '17'
- en: Deploying, Updating, and Securing an Application with Kubernetes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 部署、更新和保护应用
- en: In the previous chapter, we learned about the basics of the container orchestrator
    known as Kubernetes. We got a high-level overview of the architecture of Kubernetes
    and learned a lot about the important objects used by Kubernetes to define and
    manage a containerized application.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了关于容器编排器 Kubernetes 的基础知识。我们对 Kubernetes 的架构进行了概览，并了解了 Kubernetes
    用来定义和管理容器化应用的许多重要对象。
- en: In this chapter, we will learn how to deploy, update, and scale applications
    into a Kubernetes cluster. We will also explain how zero-downtime deployments
    are achieved to enable disruption-free updates and rollbacks of mission-critical
    applications. Finally, we will introduce Kubernetes secrets as a means to configure
    services and protect sensitive data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何将应用程序部署、更新和扩展到 Kubernetes 集群中。我们还将解释如何实现零停机部署，以便无干扰地更新和回滚关键任务应用。最后，我们将介绍
    Kubernetes 秘密，作为配置服务和保护敏感数据的一种手段。
- en: 'This chapter covers the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: Deploying our first application
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署我们的第一个应用
- en: Defining liveness and readiness
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义存活性和就绪性
- en: Zero-downtime deployments
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零停机部署
- en: Kubernetes secrets
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 秘密
- en: 'After working through this chapter, you will be able to do the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章后，你将能够完成以下任务：
- en: Deploy a multi-service application into a Kubernetes cluster
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一个多服务应用部署到 Kubernetes 集群中
- en: Define a liveness and readiness probe for your Kubernetes application service
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为你的 Kubernetes 应用服务定义存活探针和就绪探针
- en: Update an application service running in Kubernetes without causing downtime
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新在 Kubernetes 中运行的应用服务，而不会造成停机
- en: Define secrets in a Kubernetes cluster
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 集群中定义秘密
- en: Configure an application service to use Kubernetes secrets
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置应用服务以使用 Kubernetes 秘密
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we’re going to use Docker Desktop on our local computer. Please
    refer to [*Chapter 2*](B19199_02.xhtml#_idTextAnchor027), *Setting Up a Working
    Environment*, for more information on how to install and use Docker Desktop.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用本地计算机上的 Docker Desktop。有关如何安装和使用 Docker Desktop 的更多信息，请参阅 [*第2章*](B19199_02.xhtml#_idTextAnchor027)，*设置工作环境*。
- en: 'The code for this chapter can be found here: `main/sample-solutions/ch17`.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在这里找到：`main/sample-solutions/ch17`。
- en: Please make sure you have cloned this book’s GitHub repository, as described
    in [*Chapter 2*](B19199_02.xhtml#_idTextAnchor027).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保你已经按照 [*第2章*](B19199_02.xhtml#_idTextAnchor027) 中描述的方式克隆了本书的 GitHub 仓库。
- en: 'In your Terminal, navigate to the `~/The-Ultimate-Docker-Container-Book` folder
    and create a subfolder called `ch17` and navigate to it:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的终端中，导航到 `~/The-Ultimate-Docker-Container-Book` 文件夹，并创建一个名为 `ch17` 的子文件夹并进入它：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Deploying our first application
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署我们的第一个应用
- en: We will take our pets application, which we first introduced in [*Chapter 11*](B19199_11.xhtml#_idTextAnchor237),
    *Managing Containers with* *Docker Compose*, and deploy it into a Kubernetes cluster.
    Our cluster will be Docker Desktop, which, as you know, is offering us a single
    node Kubernetes cluster. However, from the perspective of deployment, it doesn’t
    matter how big the cluster is and whether the cluster is located in the cloud,
    in your company’s data center, or on your workstation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把我们的宠物应用——我们在 [*第11章*](B19199_11.xhtml#_idTextAnchor237) 中首次介绍的，*使用 Docker
    Compose 管理容器*——部署到 Kubernetes 集群中。我们的集群将使用 Docker Desktop，它提供了一个单节点的 Kubernetes
    集群。然而，从部署的角度来看，集群的规模和集群位于云端、公司数据中心或你的工作站并不重要。
- en: Deploying the web component
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署 Web 组件
- en: 'Just as a reminder, our application consists of two application services: the
    Node-based web component and the backing PostgreSQL database. In the previous
    chapter, we learned that we need to define a Kubernetes Deployment object for
    each application service we want to deploy. We’ll do this for the web component
    first. As always in this book, we will choose the declarative way of defining
    our objects:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，我们的应用程序由两个应用服务组成：基于 Node 的 Web 组件和后台 PostgreSQL 数据库。在上一章中，我们学习了需要为每个我们想要部署的应用服务定义一个
    Kubernetes 部署对象。我们将首先为 Web 组件执行此操作。和本书中一贯的做法一样，我们将选择声明式方式来定义我们的对象：
- en: 'We will use our local Kubernetes single-node cluster provided by Docker Desktop.
    Make sure Kubernetes is turned on for your Docker Desktop installation:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用由 Docker Desktop 提供的本地 Kubernetes 单节点集群。确保你的 Docker Desktop 安装中已启用 Kubernetes：
- en: '![Figure 17.1 – Kubernetes on Docker Desktop](img/Figure_17.01_B19199.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图17.1 – 在Docker Desktop上运行Kubernetes](img/Figure_17.01_B19199.jpg)'
- en: Figure 17.1 – Kubernetes on Docker Desktop
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.1 – 在Docker Desktop上运行Kubernetes
- en: 'To your code subfolder (`ch17`), add a file called `web-deployment.yaml` with
    the following content:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的代码子文件夹（`ch17`）中，添加一个名为`web-deployment.yaml`的文件，内容如下：
- en: '![Figure 17.2 – Kubernetes deployment definition for the web component](img/Figure_17.02_B19199.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图17.2 – `web`组件的Kubernetes部署定义](img/Figure_17.02_B19199.jpg)'
- en: Figure 17.2 – Kubernetes deployment definition for the web component
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.2 – `web`组件的Kubernetes部署定义
- en: 'The preceding deployment definition can be found in the `web-deployment.yaml`
    file in the `sample-solutions/ch17` subfolder. It contains the instructions necessary
    to deploy the `web` component. The lines of code are as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的部署定义可以在`sample-solutions/ch17`子文件夹中的`web-deployment.yaml`文件中找到。它包含了部署`web`组件所需的指令。代码行如下：
- en: 'Line 7: We define the name for our `Deployment` object as `web`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7行：我们将`Deployment`对象的名称定义为`web`。
- en: 'Line 9: We declare that we want to have one instance of the `web` component
    running.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9行：我们声明希望运行一个`web`组件的实例。
- en: 'Lines 11 to 13: Through `Selector`, we define which pods will be part of our
    deployment, namely those that have the `app` and `service` labels with values
    of `pets` and `web`, respectively.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第11到13行：通过`Selector`，我们定义了哪些Pods将成为我们部署的一部分，即那些具有`app`和`service`标签，且值分别为`pets`和`web`的Pods。
- en: 'Line 14: In the template for the pods starting at line 11, we define that each
    pod will have the `app` and `service` labels applied to them.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第14行：在从第11行开始的Pod模板中，我们定义了每个Pod将应用`app`和`service`标签。
- en: 'Lines 20 onward: We define the single container that will be running in the
    pod. The image for the container is our well-known `fundamentalsofdocker/ch11-web:2.0`
    image and the name of the container will be `web`.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从第20行开始：我们定义了将在Pod中运行的唯一容器。容器的镜像是我们熟悉的`fundamentalsofdocker/ch11-web:2.0`镜像，容器的名称将为`web`。
- en: 'Lines 23 and 24: It is worth noting that we declare that the container exposes
    port `3000` to incoming traffic.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第23行和第24行：值得注意的是，我们声明容器将端口`3000`暴露给传入流量。
- en: 'Please make sure that you have set the context of `kubectl` to Docker Desktop.
    See [*Chapter 2*](B19199_02.xhtml#_idTextAnchor027), *Setting Up a Working Environment*,
    for details on how to do that. Use the following command:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请确保您已将`kubectl`的上下文设置为Docker Desktop。有关如何设置的详细信息，请参见[*第二章*](B19199_02.xhtml#_idTextAnchor027)，《设置工作环境》。使用以下命令：
- en: '[PRE1]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You will receive the following output:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您将收到以下输出：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can deploy this `Deployment` object using the following command:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令部署此`Deployment`对象：
- en: '[PRE3]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The preceding command outputs the following message:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令输出如下信息：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can double-check that the deployment has been created again using our Kubernetes
    CLI:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过Kubernetes CLI再次确认该部署是否已创建：
- en: '[PRE5]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We should see the following output:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该看到以下输出：
- en: '![Figure 17.3 – Listing all the resources running in Kind](img/Figure_17.03_B19199.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图17.3 – 列出所有在Kind中运行的资源](img/Figure_17.03_B19199.jpg)'
- en: Figure 17.3 – Listing all the resources running in Kind
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.3 – 列出所有在Kind中运行的资源
- en: In the preceding output, we can see that Kubernetes created three objects –
    the deployment, a pertaining `ReplicaSet`, and a single pod (remember that we
    specified that we want one replica only). The current state corresponds to the
    desired state for all three objects, so we are fine so far.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们可以看到Kubernetes创建了三个对象——部署（deployment）、相关的`ReplicaSet`，以及一个Pod（记住我们指定了只需要一个副本）。当前状态与这三个对象的期望状态一致，所以到目前为止我们没问题。
- en: 'Now, the web service needs to be exposed to the public. For this, we need to
    define a Kubernetes `Service` object of the `NodePort` type. Create a new file
    called `web-service.yaml` and add the following code to it:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，web服务需要公开给外部访问。为此，我们需要定义一个Kubernetes类型为`NodePort`的`Service`对象。创建一个名为`web-service.yaml`的新文件，并向其中添加以下代码：
- en: '![Figure 17.4 – Definition of the Service object for our web component](img/Figure_17.04_B19199.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图17.4 – 我们的web组件的Service对象定义](img/Figure_17.04_B19199.jpg)'
- en: Figure 17.4 – Definition of the Service object for our web component
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.4 – 我们的web组件的Service对象定义
- en: Once again, the same file can be found in the `web-service.yaml` file in the
    `sample-solutions/ch17` subfolder.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，相同的文件可以在`sample-solutions/ch17`子文件夹中的`web-service.yaml`文件中找到。
- en: 'The preceding lines of code are as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码行如下：
- en: 'Line 7: We set the name of this `Service` object to `web`.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7行：我们将此`Service`对象的名称设置为`web`。
- en: 'Line 9: We define the type of `Service` object we’re using. Since the `web`
    component has to be accessible from outside of the cluster, this cannot be a `Service`
    object of the `ClusterIP` type and must be of the `NodePort` or `LoadBalancer`
    type. We discussed the various types of Kubernetes services in the previous chapter,
    so will not go into further detail about this. In our example, we’re using a `NodePort`
    type of service.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9行：我们定义了使用的`Service`对象类型。由于`web`组件必须能够从集群外部访问，因此不能是`ClusterIP`类型的`Service`对象，必须是`NodePort`或`LoadBalancer`类型。在前一章中我们讨论了Kubernetes服务的各种类型，因此这里不再详细说明。在我们的示例中，我们使用的是`NodePort`类型的服务。
- en: 'Lines 10 to 13: We specify that we want to expose port `3000` for access through
    the TCP protocol. Kubernetes will map container port `3000` automatically to a
    free host port in the range of 30,000 to 32,768\. Which port Kubernetes effectively
    chooses can be determined using the `kubectl get service` or `kubectl describe`
    command for the service after it has been created.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10到13行：我们指定希望通过TCP协议暴露端口`3000`供访问。Kubernetes会自动将容器端口`3000`映射到30,000到32,768范围内的一个空闲主机端口。Kubernetes最终选择的端口可以通过在服务创建后使用`kubectl
    get service`或`kubectl describe`命令来确定。
- en: 'Lines 14 to 16: We define the filter criteria for the pods that this service
    will be a stable endpoint for. In this case, it is all the pods that have the
    `app` and `service` labels with the `pets` and `web` values, respectively.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第14到16行：我们定义了此服务将作为稳定端点的pods的过滤条件。在这种情况下，它是所有具有`app`和`service`标签且值分别为`pets`和`web`的pods。
- en: 'Now that we have this specification for a `Service` object, we can create it
    using `kubectl`:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经有了`Service`对象的规格说明，我们可以使用`kubectl`来创建它：
- en: '[PRE6]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can list all the services to see the result of the preceding command:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以列出所有服务，以查看前面命令的结果：
- en: '[PRE7]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding command produces the following output:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令会产生以下输出：
- en: '![Figure 17.5 – The Service object that was created for the web component](img/Figure_17.05_B19199.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.5 – 为Web组件创建的Service对象](img/Figure_17.05_B19199.jpg)'
- en: Figure 17.5 – The Service object that was created for the web component
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.5 – 为Web组件创建的Service对象
- en: In the preceding output, we can see that a service called `web` has been created.
    A unique `ClusterIP` value of `10.96.195.255` has been assigned to this service,
    and container port `3000` has been published on port `30319` on all cluster nodes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们可以看到一个名为`web`的服务已被创建。该服务被分配了一个唯一的`ClusterIP`值`10.96.195.255`，并且容器端口`3000`已在所有集群节点的端口`30319`上发布。
- en: 'If we want to test this deployment, we can use `curl`:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们想测试这个部署，可以使用`curl`：
- en: '[PRE8]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This will result in the following output:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As we can see, the response is `Pets Demo Application`, which is what we expected.
    The web service is up and running in the Kubernetes cluster. Next, we want to
    deploy the database.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，响应是`Pets Demo Application`，这是我们预期的结果。Web服务已在Kubernetes集群中启动并运行。接下来，我们将部署数据库。
- en: Deploying the database
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署数据库
- en: A database is a stateful component and has to be treated differently from stateless
    components, such as our web component. We discussed the difference between stateful
    and stateless components in a distributed application architecture in detail in
    [*Chapter 9*](B19199_09.xhtml#_idTextAnchor194),*Learning about* *Distributed
    Application Architecture*, and [*Chapter 3*](B19199_03.xhtml#_idTextAnchor057),
    *Introducing* *Container Orchestration*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库是一个有状态组件，必须与无状态组件（如我们的Web组件）不同对待。我们在[*第9章*](B19199_09.xhtml#_idTextAnchor194)《*学习分布式应用架构*》和[*第3章*](B19199_03.xhtml#_idTextAnchor057)《*容器编排介绍*》中详细讨论了分布式应用架构中有状态和无状态组件的区别。
- en: Kubernetes has defined a special type of `ReplicaSet` object for stateful components.
    This object is called `StatefulSet`. Let’s use this kind of object to deploy our
    database.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes为有状态组件定义了一种特殊类型的`ReplicaSet`对象，这种对象叫做`StatefulSet`。我们使用这种类型的对象来部署数据库。
- en: 'Create a new file called `db-stateful-set.yaml` and add the following content
    to it:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`db-stateful-set.yaml`的新文件，并将以下内容添加到该文件中：
- en: '![Figure 17.6 – A StatefulSet object for the DB component](img/Figure_17.06_B19199.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.6 – 用于DB组件的StatefulSet对象](img/Figure_17.06_B19199.jpg)'
- en: Figure 17.6 – A StatefulSet object for the DB component
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.6 – 用于DB组件的StatefulSet对象
- en: The definition can also be found in the `sample-solutions/ch17` subfolder.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 定义也可以在`sample-solutions/ch17`子文件夹中找到。
- en: OK; this looks a bit scary, but it isn’t. It is a bit longer than the definition
    of the deployment for the web component since we also need to define a volume
    where the PostgreSQL database can store the data. The volume claim definition
    is on lines 25 to 33.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，看起来有点吓人，但其实不是。它比 web 组件的部署定义稍长，因为我们还需要定义一个卷，用于 PostgreSQL 数据库存储数据。卷索赔定义在第
    25 至 33 行。
- en: We want to create a volume called `pets-data` that has a maximum size equal
    to 100 MB. On lines 22 to 24, we use this volume and mount it into the container
    at `/var/lib/postgresql/data`, where PostgreSQL expects it. On line 21, we also
    declare that PostgreSQL is listening at port `5432`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要创建一个名为 `pets-data` 的卷，其最大大小为 100 MB。在第 22 至 24 行，我们使用此卷，并将其挂载到容器中的 `/var/lib/postgresql/data`，这是
    PostgreSQL 期望的位置。在第 21 行，我们还声明 PostgreSQL 正在端口 `5432` 上监听。
- en: 'As always, we use `kubectl` to deploy our `StatefulSet`:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像往常一样，我们使用 `kubectl` 部署我们的 `StatefulSet`：
- en: '[PRE10]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, if we list all the resources in the cluster, we will be able to see the
    additional objects that were created:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，如果我们列出集群中的所有资源，我们将能够看到创建的额外对象：
- en: '![Figure 17.7 – The StatefulSet and its pod](img/Figure_17.07_B19199.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.7 – StatefulSet 及其 pod](img/Figure_17.07_B19199.jpg)'
- en: Figure 17.7 – The StatefulSet and its pod
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.7 – StatefulSet 及其 pod
- en: Here, we can see that `StatefulSet` and a pod have been created. For both, the
    current state corresponds to the desired state and thus the system is healthy,
    but that doesn’t mean that the `web` component can access the database at this
    time. Service discovery won’t work. Remember that the `web` component wants to
    access the `db` service under the name `db`. We hardcoded the `db` hostname in
    the `server.js` file.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到已创建了 `StatefulSet` 和一个 pod。对于两者来说，当前状态与期望状态相符，因此系统是健康的，但这并不意味着此时 `web`
    组件可以访问数据库。服务发现不起作用。请记住，`web` 组件希望使用 `db` 服务的名称来访问 `db`。我们在 `server.js` 文件中硬编码了
    `db` 主机名。
- en: To make service discovery work inside the cluster, we have to define a Kubernetes
    `Service` object for the database component too. Since the database should only
    ever be accessible from within the cluster, the type of `Service` object we need
    is `ClusterIP`.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使集群内的服务发现正常工作，我们还必须为数据库组件定义一个 Kubernetes `Service` 对象。由于数据库应仅能从集群内部访问，因此我们需要的
    `Service` 对象类型是 `ClusterIP`。
- en: 'Create a new file called `db-service.yaml` and add the following specification
    to it. It can be found in the `sample-solutions/ch17` subfolder:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为 `db-service.yaml` 的新文件，并将以下规范添加到其中。它可以在 `sample-solutions/ch17` 子文件夹中找到：
- en: '![Figure 17.8 – Definition of the Kubernetes Service object for the database](img/Figure_17.08_B19199.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.8 – 为数据库定义的 Kubernetes Service 对象](img/Figure_17.08_B19199.jpg)'
- en: Figure 17.8 – Definition of the Kubernetes Service object for the database
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.8 – 为数据库定义的 Kubernetes Service 对象
- en: 'The database component will be represented by this `Service` object. It can
    be reached by the name `db`, which is the name of the service, as defined on line
    4\. The database component does not have to be publicly accessible, so we decided
    to use a `Service` object of the `ClusterIP` type. The selector on lines 10 to
    12 defines that this service represents a stable endpoint for all the pods that
    have the necessary labels defined – that is, `app: pets` and `service: db`.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '数据库组件将由此 `Service` 对象表示。它可以通过名称 `db` 进行访问，这是服务的名称，如第 4 行所定义。数据库组件不必公开访问，因此我们决定使用
    `ClusterIP` 类型的 `Service` 对象。第 10 至 12 行的选择器定义了该服务代表具有必要标签的所有 pod 的稳定端点 – 即 `app:
    pets` 和 `service: db`。'
- en: 'Let’s deploy this service with the following command:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用以下命令部署此服务：
- en: '[PRE11]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, we should be ready to test the application. We can use the browser this
    time to enjoy the beautiful animal images from the Maasai Mara national park in
    Kenya:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们应该准备好测试该应用程序了。这次我们可以使用浏览器，欣赏肯尼亚马赛马拉国家公园美丽的动物图像：
- en: '![Figure 17.9 – Testing the pets application running in Kubernetes](img/Figure_17.09_B19199.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.9 – 在 Kubernetes 中运行 pets 应用程序的测试](img/Figure_17.09_B19199.jpg)'
- en: Figure 17.9 – Testing the pets application running in Kubernetes
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.9 – 在 Kubernetes 中运行 pets 应用程序的测试
- en: In this case, port number `30317` is the number that Kubernetes automatically
    selected for my `web` `Service` object. Replace this number with the port that
    Kubernetes assigned to your service. You can get the number by using the `kubectl
    get` `services` command.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，端口号 `30317` 是 Kubernetes 自动为我的 `web` `Service` 对象选择的端口号。请将此数字替换为 Kubernetes
    分配给您的服务的端口号。您可以使用 `kubectl get services` 命令获取该数字。
- en: 'With that, we have successfully deployed the pets application to a single-node
    Kubernetes cluster provided by Docker Desktop. We had to define four artifacts
    to do so, which are as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就成功将宠物应用程序部署到了 Docker Desktop 提供的单节点 Kubernetes 集群中。我们需要定义四个构件才能完成这一操作，它们如下所示：
- en: '`Deployment` and `Service` objects for the `web` component'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Deployment` 和 `Service` 对象用于 `web` 组件'
- en: '`StatefulSet` and `Service` objects for the `database` component'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StatefulSet` 和 `Service` 对象用于 `database` 组件'
- en: 'To remove the application from the cluster, we can use the following small
    script:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要从集群中移除应用程序，我们可以使用以下小脚本：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Please note the last line in this script. We are deleting the persistent volume
    claim that Kubernetes automatically created as part of the `db` deployment. When
    we delete the `db` deployment, this claim is not automatically deleted! Persistent
    volume claims are a bit similar (but not the same, mind you) as Docker volumes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意该脚本的最后一行。我们正在删除 Kubernetes 自动为 `db` 部署创建的持久卷声明。当我们删除 `db` 部署时，这个声明不会被自动删除！持久卷声明与
    Docker 卷有点相似（但请注意，它们并不相同）。
- en: Use the `kubectl get pvc` command to get a list of all claims on your machine.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `kubectl get pvc` 命令查看机器上所有声明的列表。
- en: Next, we will optimize the deployment.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将优化部署。
- en: Streamlining the deployment
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 精简部署过程
- en: So far, we have created four artifacts that needed to be deployed to the cluster.
    This is only a very simple application, consisting of two components. Imagine
    having a much more complex application. It would quickly become a maintenance
    nightmare. Luckily, we have several options as to how we can simplify the deployment.
    The method that we are going to discuss here is the possibility of defining all
    the components that make up an application in Kubernetes in a single file.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经创建了四个需要部署到集群中的构件。这只是一个非常简单的应用程序，由两个组件组成。试想如果是一个更加复杂的应用程序，它会迅速变成一场维护噩梦。幸运的是，我们有几个方法可以简化部署。我们将在这里讨论的方法是，将组成
    Kubernetes 应用程序的所有组件定义在一个文件中。
- en: Other solutions that lie outside the scope of this book include using a package
    manager, such as Helm ([https://helm.sh/](https://helm.sh/)), or Kustomize ([https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/)),
    the native Kubernetes solution.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 本书未涉及的其他解决方案包括使用包管理器，例如 Helm（[https://helm.sh/](https://helm.sh/)）或 Kustomize（[https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/)），这是
    Kubernetes 的原生解决方案。
- en: 'If we have an application consisting of many Kubernetes objects, such as `Deployment`
    and `Service` objects, then we can keep them all in a single file and separate
    the individual object definitions by three dashes. For example, if we wanted to
    have the `Deployment` and `Service` definitions for the `web` component in a single
    file, this would look as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的应用程序包含多个 Kubernetes 对象，例如 `Deployment` 和 `Service` 对象，那么我们可以将它们都保存在一个文件中，并通过三个破折号分隔各个对象定义。例如，如果我们想在一个文件中包含
    `web` 组件的 `Deployment` 和 `Service` 定义，文件内容将如下所示：
- en: '![Figure 17.10 – Deployment and Service for web in a single file](img/Figure_17.10_B19199.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.10 – 单个文件中的 web 组件部署和服务](img/Figure_17.10_B19199.jpg)'
- en: Figure 17.10 – Deployment and Service for web in a single file
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.10 – 单个文件中的 web 组件部署和服务
- en: You can find this file in `sample-solutions/ch17/install-web.yaml`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 `sample-solutions/ch17/install-web.yaml` 文件中找到此文件。
- en: 'Next, we collected all four object definitions for the pets application in
    the `sample-solutions/ch17/install-pets.yaml` file, and we can deploy the application
    in one go:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将所有四个对象定义收集到 `sample-solutions/ch17/install-pets.yaml` 文件中，并可以一次性部署该应用程序：
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This will give us this output:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给出如下输出：
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Similarly, we created a script called `sample-solutions/ch17/remove-pets.sh`
    to remove all the artifacts of the pets application from the Kubernetes cluster.
    Note that the file was made executable with `chmod +x ./remove-pets.sh` first.
    Now, we can use the following command:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们创建了一个名为 `sample-solutions/ch17/remove-pets.sh` 的脚本，用于从 Kubernetes 集群中删除所有宠物应用程序的构件。请注意，该文件在使用之前已通过
    `chmod +x ./remove-pets.sh` 命令设置为可执行文件。现在，我们可以使用以下命令：
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This will result in an output like is:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下输出：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Alternatively, you can use the following command:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以使用以下命令：
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This will delete all the resources except the persistent volume claim, which
    you still need to delete by hand:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这将删除除持久卷声明外的所有资源，而持久卷声明需要手动删除：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: With this, we have taken the pets application we introduced in [*Chapter 11*](B19199_11.xhtml#_idTextAnchor237)*,*
    *Managing Containers with* *Docker Compose*, and defined all the Kubernetes objects
    that are necessary to deploy this application into a Kubernetes cluster. In each
    step, we made sure that we got the expected result, and once all the artifacts
    existed in the cluster, we showed the running application.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们已经使用在[*第11章*](B19199_11.xhtml#_idTextAnchor237)《使用 Docker Compose 管理容器》中介绍的宠物应用程序，定义了将此应用程序部署到
    Kubernetes 集群中所需的所有 Kubernetes 对象。在每个步骤中，我们确保得到了预期的结果，并且一旦所有的工件存在于集群中，我们展示了运行中的应用程序。
- en: Defining liveness and readiness
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义存活性和就绪性
- en: Container orchestration systems such as Kubernetes and Docker Swarm make it
    significantly easier to deploy, run, and update highly distributed, mission-critical
    applications. The orchestration engine automates many cumbersome tasks, such as
    scaling up or down, asserting that the desired state is maintained at all times,
    and more.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 像 Kubernetes 和 Docker Swarm 这样的容器编排系统大大简化了部署、运行和更新高度分布式、关键任务应用程序的过程。编排引擎自动化了许多繁琐的任务，例如上下扩展、确保所需状态始终得到维护等。
- en: However, the orchestration engine cannot just do everything automatically. Sometimes,
    we developers need to support the engine with some information that only we can
    know about. So, what do I mean by that?
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，编排引擎不能自动完成所有事情。有时，我们开发人员需要提供一些只有我们才能了解的信息来支持引擎。那么，我说的是什么意思呢？
- en: Let’s look at a single application service. Let’s assume it is a microservice
    and let’s call it service A. If we run service A containerized on a Kubernetes
    cluster, then Kubernetes can make sure that we have the five instances that we
    require in the service definition running at all times. If one instance crashes,
    Kubernetes can quickly launch a new instance and thus maintain the desired state.
    But what if an instance of the service does not crash, but is unhealthy or just
    not ready yet to serve requests? Kubernetes should know about both situations.
    But it can’t, since good or bad health from an application service perspective
    is outside of the knowledge of the orchestration engine. Only we application developers
    can know when our service is healthy and when it is not.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一个单一的应用服务。假设它是一个微服务，我们称之为服务 A。如果我们将服务 A 容器化并运行在 Kubernetes 集群上，那么 Kubernetes
    可以确保我们在服务定义中要求的五个实例始终运行。如果一个实例崩溃，Kubernetes 可以快速启动一个新实例，从而保持所需状态。但是，如果一个服务实例没有崩溃，而是不健康或还没有准备好处理请求呢？Kubernetes
    应该知道这两种情况。但它不能，因为从应用服务的角度来看，健康与否超出了编排引擎的知识范畴。只有我们应用程序的开发人员知道我们的服务何时健康，何时不健康。
- en: The application service could, for example, be running, but its internal state
    could have been corrupted due to some bug, it could be in an endless loop, or
    it could be in a deadlock situation.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，应用服务可能正在运行，但由于某些 bug 其内部状态可能已经损坏，可能处于无限循环中，或者可能处于死锁状态。
- en: Similarly, only we application developers know whether our service is ready
    to work, or whether it is still initializing. Although it is highly recommended
    to keep the initialization phase of a microservice as short as possible, it often
    cannot be avoided if a significant time span is needed by a particular service
    so that it’s ready to operate. Being in this state of initialization is not the
    same thing as being unhealthy, though. The initialization phase is an expected
    part of the life cycle of a microservice or any other application service.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，只有我们这些应用程序开发人员才知道我们的服务是否准备好工作，或者它是否还在初始化中。虽然强烈建议将微服务的初始化阶段尽可能缩短，但如果某些服务需要较长的时间才能准备好工作，通常也无法避免。在初始化状态下并不意味着不健康。初始化阶段是微服务或任何其他应用服务生命周期中的预期部分。
- en: Thus, Kubernetes should not try to kill our microservice if it is in the initialization
    phase. If our microservice is unhealthy, though, Kubernetes should kill it as
    quickly as possible and replace it with a fresh instance.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们的微服务处于初始化阶段，Kubernetes 不应尝试杀死它。但是，如果我们的微服务不健康，Kubernetes 应该尽快将其杀死并替换为一个新的实例。
- en: Kubernetes has the concept of probes to provide the seam between the orchestration
    engine and the application developer. Kubernetes uses these probes to find out
    more about the inner state of the application service at hand. Probes are executed
    locally, inside each container. There is a probe for the health – also called
    liveness – of the service, a startup probe, and a probe for the readiness of the
    service. Let’s look at them in turn.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 有探针的概念，提供了协调引擎和应用开发者之间的连接。Kubernetes 使用这些探针来获取有关当前应用服务内部状态的更多信息。探针在每个容器内本地执行。服务的健康状况探针（也叫存活探针）、启动探针和服务的就绪探针都有对应的定义。我们逐一来看它们。
- en: Kubernetes liveness probes
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 存活探针
- en: Kubernetes uses the liveness probe to decide when a container needs to be killed
    and when another instance should be launched instead. Since Kubernetes operates
    at a pod level, the respective pod is killed if at least one of its containers
    reports as being unhealthy.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 使用存活探针来决定何时杀死一个容器，以及何时启动另一个实例来替代它。由于 Kubernetes 在 Pod 层面上操作，如果至少有一个容器报告为不健康，则相应的
    Pod 会被杀死。
- en: 'Alternatively, we can say it the other way around: only if all the containers
    of a pod report to be healthy is the pod considered to be healthy.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以换个角度来说：只有当一个 Pod 中的所有容器都报告健康时，Pod 才会被视为健康。
- en: 'We can define the liveness probe in the specification for a pod as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 Pod 的规格说明中定义存活探针，如下所示：
- en: '[PRE19]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The relevant part is in the `livenessProbe` section. First, we define a command
    that Kubernetes will execute as a probe inside the container. In our case, we
    have a `PostreSQL` container and use the `netcat` Linux tool to probe port `5432`
    over TCP. The `nc localhost 5432` command is successful once Postgres listens
    to it.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 相关部分在 `livenessProbe` 部分。首先，我们定义一个 Kubernetes 会在容器内执行的命令作为探针。在我们的例子中，我们有一个 `PostreSQL`
    容器，使用 `netcat` Linux 工具来探测 `5432` 端口的 TCP。命令 `nc localhost 5432` 成功时，表示 Postgres
    已经开始监听此端口。
- en: The other two settings, `initialDelaySeconds` and `periodSeconds`, define how
    long Kubernetes should wait after starting the container until it first executes
    the probe and how frequently the probe should be executed thereafter. In our case,
    Kubernetes waits for 10 seconds before executing the first probe and then executes
    a probe every 5 seconds.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 另外两个设置项，`initialDelaySeconds` 和 `periodSeconds`，定义了 Kubernetes 在启动容器后应该等待多长时间才执行第一次探针，以及之后探针应该以多频繁的间隔执行。在我们的例子中，Kubernetes
    等待 10 秒钟后执行第一次探针，然后每隔 5 秒执行一次探针。
- en: 'It is also possible to probe an HTTP endpoint instead of using a command. Let’s
    assume we’re running a microservice from an image, `acme.com/my-api:1.0`, with
    an API that has an endpoint called `/api/health` that returns status `200 (OK)`
    if the microservice is healthy, and `50x (Error)` if it is unhealthy. Here, we
    can define the liveness probe as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以使用 HTTP 端点来替代命令进行探测。假设我们运行一个来自镜像 `acme.com/my-api:1.0` 的微服务，且该 API 的端点 `/api/health`
    返回状态 `200 (OK)` 表示微服务健康，返回 `50x (Error)` 表示微服务不健康。在这种情况下，我们可以这样定义存活探针：
- en: '[PRE20]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In the preceding snippet, I defined the liveness probe so that it uses the HTTP
    protocol and executed a `GET` request to the `/api/health` endpoint on port `5000`
    of `localhost`. Remember, the probe is executed inside the container, which means
    I can use localhost.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码片段中，我定义了存活探针，使其使用 HTTP 协议，并对 `localhost` 的 `5000` 端口上的 `/api/health` 端点执行
    `GET` 请求。记住，探针是在容器内执行的，这意味着我可以使用 localhost。
- en: 'We can also directly use the TCP protocol to probe a port on the container.
    But wait a second – didn’t we just do that in our first example, where we used
    the generic liveness probe based on an arbitrary command? Yes, you’re right, we
    did, but we had to rely on the presence of the `netcat` tool in the container
    to do so. We cannot assume that this tool is always there. Thus, it is favorable
    to rely on Kubernetes to do the TCP-based probing for us out of the box. The modified
    pod spec looks like this:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以直接使用 TCP 协议来探测容器上的端口。但稍等一下——我们不就是在第一个例子中使用了基于命令的通用存活探针吗？没错，我们确实使用了，但是我们依赖的是容器中是否存在
    `netcat` 工具。我们不能假设这个工具总是存在。因此，依赖 Kubernetes 本身来为我们执行基于 TCP 的探测会更好。修改后的 Pod 规格如下：
- en: '[PRE21]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This looks very similar. The only change is that the type of probe has been
    changed from `exec` to `tcpSocket` and that, instead of providing a command, we
    provide the port to probe.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这个看起来非常相似。唯一的变化是，探针的类型从 `exec` 更改为 `tcpSocket`，并且我们不再提供命令，而是提供要探测的端口。
- en: Note that we could also use `failureThreshold` here with Kubernetes’ `livenessProbe`.
    The `livenessProbe` failure threshold in Kubernetes is the minimum number of consecutive
    failures that must occur before the container is restarted. The default value
    is `3`. The minimum value is `1`. If the handler returns a failure code, `kubelet`
    kills the container and restarts it. Any code greater than or equal to `200` and
    less than `400` indicates success. Any other code indicates failure.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们也可以在这里使用 Kubernetes 的 `livenessProbe` 配置项中的 `failureThreshold`。在 Kubernetes
    中，`livenessProbe` 的失败阈值是指容器重启前必须连续发生的最小失败次数。默认值是 `3`。最小值是 `1`。如果处理程序返回失败代码，`kubelet`
    会杀死容器并重新启动它。任何大于或等于 `200` 且小于 `400` 的代码表示成功，其他任何代码表示失败。
- en: 'Let’s try this out:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试这个：
- en: Copy the `probes` subfolder from the `sample-solutions/ch17` folder to your
    `ch17` folder.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `sample-solutions/ch17` 文件夹中的 `probes` 子文件夹复制到你的 `ch17` 文件夹中。
- en: 'Build the Docker image with the following command:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令构建 Docker 镜像：
- en: '[PRE22]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Use `kubectl` to deploy the sample pod that’s defined in `probes-demo.yaml`:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `kubectl` 部署在 `probes-demo.yaml` 中定义的示例 pod：
- en: '[PRE23]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Describe the pod and specifically analyze the log part of the output:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述 pod，并具体分析输出中的日志部分：
- en: '[PRE24]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'During the first half minute or so, you should get the following output:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在大约前半分钟内，你应该看到以下输出：
- en: '![Figure 17.11 – Log output of the healthy pod](img/Figure_17.11_B19199.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.11 – 健康 pod 的日志输出](img/Figure_17.11_B19199.jpg)'
- en: Figure 17.11 – Log output of the healthy pod
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.11 – 健康 pod 的日志输出
- en: 'Wait at least 30 seconds and then describe the pod again. This time, you should
    see the following output:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待至少 30 秒，然后再次描述 pod。这时，你应该看到以下输出：
- en: '![Figure 17.12 – Log output of the pod after it has changed its state to Unhealthy](img/Figure_17.12_B19199.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.12 – pod 状态变为不健康后的日志输出](img/Figure_17.12_B19199.jpg)'
- en: Figure 17.12 – Log output of the pod after it has changed its state to Unhealthy
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.12 – pod 状态变为不健康后的日志输出
- en: The marked lines indicate the failure of the probe and the fact that the pod
    is going to be restarted.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 标记的行表示探针失败，并且 pod 即将被重启。
- en: 'If you get the list of pods, you will see that the pod has been restarted several
    times:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你获取 pod 列表，你会看到 pod 已经重启了多次：
- en: '[PRE25]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This results in this output:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '[PRE26]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'When you’re done with the sample, delete the pod with the following command:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成示例后，使用以下命令删除 pod：
- en: '[PRE27]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Next, we will have a look at the Kubernetes readiness probe.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看 Kubernetes 的就绪探针（readiness probe）。
- en: Kubernetes readiness probes
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 就绪探针（readiness probes）
- en: Kubernetes uses a readiness probe to decide when a service instance – that is,
    a container – is ready to accept traffic. Now, we all know that Kubernetes deploys
    and runs pods and not containers, so it only makes sense to talk about the readiness
    of a pod. Only if all containers in a pod report as ready is the pod considered
    to be ready itself. If a pod reports as not ready, then Kubernetes removes it
    from the service load balancers.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 使用就绪探针来决定服务实例——即容器——何时准备好接收流量。现在，我们都知道 Kubernetes 部署和运行的是 pod 而非容器，因此讨论
    pod 的就绪状态是有意义的。只有当 pod 中的所有容器都报告为“就绪”时，pod 才会被认为是“就绪”的。如果 pod 报告为“未就绪”，Kubernetes
    将会把它从服务负载均衡器中移除。
- en: 'Readiness probes are defined the same way as liveness probes: just switch the
    `livenessProbe` key in the pod spec to `readinessProbe`. Here is an example using
    our prior pod spec:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪探针的定义与存活探针相同：只需将 pod 配置中的 `livenessProbe` 键切换为 `readinessProbe`。以下是使用我们之前的
    pod 配置的示例：
- en: '[PRE28]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note that, in this example, we don’t need an initial delay for the liveness
    probe anymore since we now have a readiness probe. Thus, I have replaced the initial
    delay entry for the liveness probe with an entry called `failureThreshold`, which
    indicates how many times Kubernetes should repeat probing in case of a failure
    until it assumes that the container is unhealthy.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这个例子中，由于我们现在有了就绪探针（readiness probe），我们不再需要为存活探针设置初始延迟。因此，我已将存活探针的初始延迟条目替换为一个名为
    `failureThreshold` 的条目，表示在发生故障时 Kubernetes 应该重复探测多少次，直到它认为容器不健康。
- en: Kubernetes startup probes
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 启动探针（startup probes）
- en: It is often helpful for Kubernetes to know when a service instance has started.
    If we define a startup probe for a container, then Kubernetes does not execute
    the liveness or readiness probes, so long as the container’s startup probe does
    not succeed. Once again, Kubernetes looks at pods and starts executing liveness
    and readiness probes on its containers if the startup probes of all the pod’s
    containers succeed.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 对Kubernetes来说，知道一个服务实例何时启动通常是很有帮助的。如果我们为容器定义了启动探针，那么只要容器的启动探针未成功，Kubernetes就不会执行存活探针或就绪探针。一旦所有Pod容器的启动探针成功，Kubernetes就会开始执行容器的存活探针和就绪探针。
- en: When would we use a startup probe, given the fact that we already have the liveness
    and readiness probes? There might be situations where we have to account for exceptionally
    long startup and initialization times, such as when containerizing a legacy application.
    We could technically configure the readiness or liveness probes to account for
    this fact, but that would defeat the purpose of these probes. The latter probes
    are meant to provide quick feedback to Kubernetes on the health and availability
    of the container. If we configure for long initial delays or periods, then this
    would counter the desired outcome.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们已经有了存活探针和就绪探针，什么时候我们需要使用启动探针？可能有一些情况需要考虑异常长的启动和初始化时间，例如在将传统应用程序容器化时。我们本可以通过配置就绪探针或存活探针来解决这个问题，但那样做会违背这些探针的目的。后者的探针旨在快速反馈容器的健康状况和可用性。如果我们配置了长时间的初始延迟或持续时间，反而会影响预期效果。
- en: 'Unsurprisingly, the startup probe is defined the same way as the readiness
    and liveness probes. Here is an example:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，启动探针的定义与就绪探针和存活探针相同。以下是一个示例：
- en: '[PRE29]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Make sure that you define the `failureThreshold * periodSeconds` product so
    that it’s big enough to account for the worst startup time.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你定义了`failureThreshold * periodSeconds`的乘积，以便它足够大，能够应对最差的启动时间。
- en: In our example, the max startup time should not exceed 150 seconds.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，最大启动时间不应超过150秒。
- en: Zero-downtime deployments
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 零停机部署
- en: 'In a mission-critical environment, the application must be always up and running.
    These days, we cannot afford downtime anymore. Kubernetes gives us various means
    of achieving this. Performing an update on an application in the cluster that
    causes no downtime is called a **zero-downtime deployment**. In this section,
    we will present two ways of achieving this. These are as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在关键任务环境中，应用程序必须始终保持运行。这些天，我们已经无法容忍停机了。Kubernetes为我们提供了多种实现这一目标的方法。对集群中的应用程序进行更新而不导致停机被称为**零停机部署**。在本节中，我们将介绍实现这一目标的两种方法，具体如下：
- en: Rolling updates
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滚动更新
- en: Blue-green deployments
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝绿部署
- en: Let’s start by discussing rolling updates.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从讨论滚动更新开始。
- en: Rolling updates
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 滚动更新
- en: In the previous chapter, we learned that the Kubernetes `Deployment` object
    distinguishes itself from the `ReplicaSet` object in that it adds rolling updates
    and rollbacks on top of the latter’s functionality. Let’s use our web component
    to demonstrate this. We will have to modify the manifest or description of the
    deployment for the web component.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解到Kubernetes的`Deployment`对象与`ReplicaSet`对象的区别在于，它在后者的功能基础上增加了滚动更新和回滚功能。让我们使用我们的Web组件来演示这一点。我们将需要修改Web组件的部署清单或描述。
- en: 'We will use the same deployment definition as in the previous section, with
    one important difference – we will have `web` component running. The following
    definition can also be found in the `sample-solutions/ch17/web-deployment-rolling-v1.yaml`
    file:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与上一节相同的部署定义，唯一的区别是——我们将运行`web`组件。以下定义也可以在`sample-solutions/ch17/web-deployment-rolling-v1.yaml`文件中找到：
- en: '![Figure 17.13 – Deployment for the web component with five replicas](img/Figure_17.13_B19199.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图17.13 – 带有五个副本的Web组件部署](img/Figure_17.13_B19199.jpg)'
- en: Figure 17.13 – Deployment for the web component with five replicas
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.13 – 带有五个副本的Web组件部署
- en: 'Now, we can create this deployment as usual and also, at the same time, the
    service that makes our component accessible:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以像往常一样创建这个部署，同时也创建使我们的组件可访问的服务：
- en: '[PRE30]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Once we have deployed the pods and the service, we can test our web component.
    First, we can get the assigned node port with this command:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们部署了Pod和服务，就可以测试我们的Web组件。首先，我们可以使用以下命令获取分配的节点端口：
- en: '[PRE31]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Next, we can use the `$PORT` environment variable in our `curl` statement:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以在`curl`语句中使用`$PORT`环境变量：
- en: '[PRE32]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This provides the expected output:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这将提供预期的输出：
- en: '[PRE33]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: As we can see, the application is up and running and returns the expected message,
    `Pets` `Demo Application`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，应用程序已经启动并运行，返回了预期的消息，`Pets` `Demo Application`。
- en: 'Our developers have created a new version, 2.1, of the web component. The code
    of the new version of the web component can be found in the `sample-solutions/ch17/web`
    folder, and the only change is located on line 12 of the `server.js` file:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的开发人员已经创建了Web组件的新版本2.1。新版本的代码可以在`sample-solutions/ch17/web`文件夹中找到，唯一的变化位于`server.js`文件的第12行：
- en: '![Figure 17.14 – Code change for version 2.0 of the web component](img/Figure_17.14_B19199.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.14 – Web组件版本2.0的代码更改](img/Figure_17.14_B19199.jpg)'
- en: Figure 17.14 – Code change for version 2.0 of the web component
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.14 – Web组件版本2.0的代码更改
- en: 'We can now build the new image as follows (replace `demo` with your GitHub
    username):'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以按如下方式构建新的镜像（将`demo`替换为你的GitHub用户名）：
- en: '[PRE34]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Subsequently, we can push the image to Docker Hub, as follows (replace `demo`
    with your GitHub username):'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，我们可以将镜像推送到Docker Hub，步骤如下（将`demo`替换为你的GitHub用户名）：
- en: '[PRE35]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, we want to update the image that’s used by our pods that are part of the
    `web` `Deployment` object. We can do this by using the `set image` command of
    `kubectl`:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们希望更新由属于`web` `Deployment`对象的pod使用的镜像。我们可以通过使用`kubectl`的`set image`命令来实现：
- en: '[PRE36]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If we test the application again, we’ll get a confirmation that the update
    has indeed happened:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再次测试该应用程序，我们将得到一个确认，证明更新确实已发生：
- en: '[PRE37]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output indicates that we now have version 2 installed:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示现在已经安装了版本2：
- en: '[PRE38]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, how do we know that there hasn’t been any downtime during this update?
    Did the update happen in a rolling fashion? What does rolling update mean at all?
    Let’s investigate. First, we can get a confirmation from Kubernetes that the deployment
    has indeed happened and was successful by using the `rollout` `status` command:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们怎么知道在这次更新过程中没有任何停机时间呢？更新是以滚动方式进行的吗？滚动更新到底是什么意思呢？让我们来探讨一下。首先，我们可以通过使用`rollout`
    `status`命令，从Kubernetes获取确认，确保部署确实已成功完成：
- en: '[PRE39]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The command will respond as follows:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 命令将返回以下响应：
- en: '[PRE40]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'If we describe the `web` deployment object with `kubectl describe deploy/web`,
    we will get the following list of events at the end of the output:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用`kubectl describe deploy/web`描述`web`部署对象，在输出的末尾，我们将看到以下事件列表：
- en: '![Figure 17.15 – List of events found in the output of the deployment description
    of the web component](img/Figure_17.15_B19199.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.15 – 在Web组件部署描述输出中找到的事件列表](img/Figure_17.15_B19199.jpg)'
- en: Figure 17.15 – List of events found in the output of the deployment description
    of the web component
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.15 – 在Web组件部署描述输出中找到的事件列表
- en: 'The first event tells us that, when we created the deployment, a `ReplicaSet`
    object called `web-769b88f67` with five replicas was created. Then, we executed
    the `update` command. The second event in the list tells us that this meant creating
    a new `ReplicaSet` object called `web-55cdf67cd` with, initially, one replica
    only. Thus, at that particular moment, six pods existed on the system: the five
    initial pods and one pod with the new version. But, since the desired state of
    the `Deployment` object states that we want five replicas only, Kubernetes now
    scales down the old `ReplicaSet` object to four instances, which we can see in
    the third event.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个事件告诉我们，在创建部署时，创建了一个名为`web-769b88f67`的`ReplicaSet`对象，包含五个副本。然后，我们执行了`update`命令。事件列表中的第二个事件告诉我们，这意味着创建了一个新的`ReplicaSet`对象，名为`web-55cdf67cd`，最初只有一个副本。因此，在那个特定时刻，系统上存在六个pod：五个初始pod和一个新的版本的pod。但是，由于`Deployment`对象的期望状态要求只有五个副本，Kubernetes现在将旧的`ReplicaSet`对象缩减为四个实例，这一点可以从第三个事件中看到。
- en: Then, again, the new `ReplicaSet` object was scaled up to two instances, and,
    subsequently, the old `ReplicaSet` object was scaled down to three instances,
    and so on, until we had five new instances and all the old instances were decommissioned.
    Although we cannot see any precise time (other than 3 minutes) when that happened,
    the order of the events tells us that the whole update happened in a rolling fashion.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，新的`ReplicaSet`对象被扩展到两个实例，随后，旧的`ReplicaSet`对象被缩减到三个实例，依此类推，直到我们得到了五个新的实例，并且所有旧的实例都被淘汰。尽管我们无法看到发生这些变化的具体时间（除了3分钟），但事件的顺序告诉我们，整个更新过程是以滚动方式进行的。
- en: During a short period, some of the calls to the web service would have had an
    answer from the old version of the component, and some calls would have received
    an answer from the new version of the component, but at no time would the service
    have been down.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在短时间内，一些 web 服务的调用会从旧版本的组件中得到响应，而另一些调用则会从新版本的组件中得到响应，但服务在任何时候都不会中断。
- en: 'We can also list the `ReplicaSet` objects in the cluster and get confirmation
    of what I said in the preceding section:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以列出集群中的 `ReplicaSet` 对象，以确认我在前面提到的内容：
- en: '![Figure 17.16 – Listing all the ReplicaSet objects in the cluster](img/Figure_17.16_B19199.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.16 – 列出集群中的所有 ReplicaSet 对象](img/Figure_17.16_B19199.jpg)'
- en: Figure 17.16 – Listing all the ReplicaSet objects in the cluster
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.16 – 列出集群中的所有 ReplicaSet 对象
- en: Here, we can see that the new `ReplicaSet` object has five instances running
    and that the old one has been scaled down to zero instances. The reason that the
    old `ReplicaSet` object is still lingering is that Kubernetes provides us with
    the possibility of rolling back the update and, in that case, will reuse that
    `ReplicaSet`.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到新的 `ReplicaSet` 对象有五个实例正在运行，而旧的 `ReplicaSet` 对象已缩减为零实例。旧的 `ReplicaSet`
    对象仍然存在的原因是 Kubernetes 允许我们回滚更新，在这种情况下，它会重用该 `ReplicaSet`。
- en: 'To roll back the update of the image in case some undetected bug sneaked into
    the new code, we can use the `rollout` `undo` command:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在更新镜像时出现一些未检测到的 bug 渗入新代码，我们可以使用 `rollout` `undo` 命令回滚更新：
- en: '[PRE41]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This outputs the following:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出以下内容：
- en: '[PRE42]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We can test whether the rollback was successful like so:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像这样测试回滚是否成功：
- en: '[PRE43]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'As we can see, the output shows us that this is the case:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，输出显示了这一点：
- en: '[PRE44]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'If we list the `ReplicaSet` objects, we will see the following output:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们列出 `ReplicaSet` 对象，我们将看到以下输出：
- en: '![Figure 17.17 – Listing the ReplicaSet objects after rolling back](img/Figure_17.17_B19199.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.17 – 回滚后列出 ReplicaSet 对象](img/Figure_17.17_B19199.jpg)'
- en: Figure 17.17 – Listing the ReplicaSet objects after rolling back
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.17 – 回滚后列出 ReplicaSet 对象
- en: This confirms that the old `ReplicaSet` (`web-9d66cd994`) object has been reused
    and that the new one has been scaled down to zero instances.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这确认了旧的 `ReplicaSet`（`web-9d66cd994`）对象已被重用，而新的 `ReplicaSet` 对象已缩减为零实例。
- en: 'Before continuing, please delete the deployment and the service:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，请删除部署和服务：
- en: '[PRE45]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Sometimes, though, we cannot, or do not want to, tolerate the mixed state of
    an old version coexisting with the new version. We want an all-or-nothing strategy.
    This is where blue-green deployments come into play, which we will discuss next.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，有时我们无法或不想容忍旧版本与新版本共存的混合状态。我们希望采取全有或全无的策略。这时，蓝绿部署就派上用场了，我们将在接下来的内容中讨论。
- en: Blue-green deployment
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 蓝绿部署
- en: 'If we want to do a blue-green style deployment for our `web` component of the
    pets application, then we can do so by using labels creatively. First, let’s remind
    ourselves how blue-green deployments work. Here is a rough step-by-step guide:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想为宠物应用程序的 `web` 组件进行蓝绿式部署，可以通过巧妙地使用标签来实现。首先，让我们回顾一下蓝绿部署是如何工作的。以下是一个大致的步骤指南：
- en: 'Deploy the first version of the `web` component as `blue`. We will label the
    pods with a label of `color: blue` to do so.'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '将 `web` 组件的第一个版本作为 `blue` 部署。我们将为 pods 添加 `color: blue` 的标签来实现这一点。'
- en: 'Deploy the Kubernetes service for these pods with the `color: blue` label in
    the `selector` section.'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '为这些带有 `color: blue` 标签的 pods 在 `selector` 部分部署 Kubernetes 服务。'
- en: 'Now, we can deploy version 2 of the web component, but, this time, the pods
    have a label of `color: green`.'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '现在，我们可以部署版本 2 的 web 组件，但这次，pods 会有一个 `color: green` 的标签。'
- en: We can test the green version of the service to check that it works as expected.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以测试服务的绿色版本，以检查它是否按预期工作。
- en: Now, we can flip traffic from `blue` to `green` by updating the Kubernetes service
    for the web component. We will modify the selector so that it uses the `color:`
    `green` label.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以通过更新 Kubernetes 服务来将流量从 `blue` 切换到 `green`，我们将修改选择器，使其使用 `color:` `green`
    标签。
- en: 'Let’s define a `Deployment` object for version 1, `blue`:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为版本 1 定义一个 `Deployment` 对象，标记为 `blue`：
- en: '![Figure 17.18 – Specification of the blue deployment for the web component](img/Figure_17.18_B19199.jpg)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.18 – 为 web 组件指定蓝色部署](img/Figure_17.18_B19199.jpg)'
- en: Figure 17.18 – Specification of the blue deployment for the web component
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.18 – 为 web 组件指定蓝色部署
- en: The preceding definition can be found in the `sample-solutions/ch17/web-deployment-blue.yaml`
    file.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 上述定义可以在`sample-solutions/ch17/web-deployment-blue.yaml`文件中找到。
- en: 'Please take note of line 8, where we define the name of the deployment as `web-blue`
    to distinguish it from the upcoming deployment, `web-green`. Also, note that we
    have added the `color: blue` label on lines 7, 15, and 21\. Everything else remains
    the same as before.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '请注意第8行，在那里我们将部署的名称定义为`web-blue`，以便与即将到来的`web-green`部署区分开来。另外，请注意我们在第7、15和21行添加了`color:
    blue`标签。其他内容与之前相同。'
- en: 'Now, we can define the `Service` object for the web component. It will be the
    same as the one we used before but with a minor change, as shown in the following
    screenshot:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以为网页组件定义`Service`对象。它将与我们之前使用的相同，但有一个小的改动，如下图所示：
- en: '![Figure 17.19 – Kubernetes service for the web component supporting blue-green
    deployments](img/Figure_17.19_B19199.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.19 – 支持蓝绿部署的网页组件 Kubernetes 服务](img/Figure_17.19_B19199.jpg)'
- en: Figure 17.19 – Kubernetes service for the web component supporting blue-green
    deployments
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.19 – 支持蓝绿部署的网页组件 Kubernetes 服务
- en: 'The only difference regarding the definition of the service we used earlier
    in this chapter is line 17, which adds the `color: blue` label to the selector.
    We can find the preceding definition in the `sample-solutions/ch17/web-service-blue-green.yaml`
    file.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '关于本章早些时候使用的服务定义，唯一的区别是第17行，它将`color: blue`标签添加到了选择器中。我们可以在`sample-solutions/ch17/web-service-blue-green.yaml`文件中找到上述定义。'
- en: 'Then, we can deploy the blue version of the `web` component with the following
    command:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用以下命令部署蓝色版本的`web`组件：
- en: '[PRE46]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We can deploy its service with this command:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用此命令部署其服务：
- en: '[PRE47]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Once the service is up and running, we can determine its IP address and port
    number and test it:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦服务启动并运行，我们可以确定其IP地址和端口号并进行测试：
- en: '[PRE48]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Then, we can access it with the `curl` command:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用`curl`命令访问它：
- en: '[PRE49]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'This gives us what we expect:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们预期的结果：
- en: '[PRE50]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now, we can deploy the green version of the `web` component. The definition
    of its `Deployment` object can be found in the `sample-solutions/ch17/web-deployment-green.yaml`
    file and looks as follows:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以部署`web`组件的绿色版本。其`Deployment`对象的定义可以在`sample-solutions/ch17/web-deployment-green.yaml`文件中找到，内容如下：
- en: '![Figure 17.20 – Specification of the green deployment for the web component](img/Figure_17.20_B19199.jpg)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.20 – 网页组件绿色部署规范](img/Figure_17.20_B19199.jpg)'
- en: Figure 17.20 – Specification of the green deployment for the web component
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.20 – 网页组件绿色部署规范
- en: 'The interesting lines are as follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的行如下：
- en: 'Line 8: Named `web-green` to distinguish it from `web-blue` and allow for parallel
    installation'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第8行：命名为`web-green`，以便与`web-blue`区分，并支持并行安装
- en: 'Lines 7, 15, and 21: Have the color green'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7、15和21行：颜色为绿色
- en: 'Line 24: Now using version 2.1 of the web image we built earlier in this chapter'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第24行：现在使用的是本章前面构建的网页镜像版本 2.1
- en: Do not forget to change ‘‘`demo`’’ to your own GitHub username on line 24.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 请不要忘记在第24行将`‘’demo‘’`改为你自己的GitHub用户名。
- en: 'Now, we’re ready to deploy this green version of the service. It should run
    separately from the blue service:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备部署这个绿色版本的服务。它应与蓝色服务分开运行：
- en: '[PRE51]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We can make sure that both deployments coexist like so:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以确保两个部署并存，如下所示：
- en: '![Figure 17.21 – Displaying the list of Deployment objects running in the cluster](img/Figure_17.21_B19199.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.21 – 显示集群中运行的部署对象列表](img/Figure_17.21_B19199.jpg)'
- en: Figure 17.21 – Displaying the list of Deployment objects running in the cluster
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.21 – 显示集群中运行的部署对象列表
- en: 'As expected, we have both blue and green running. We can verify that blue is
    still the active service:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，我们有蓝色和绿色两个版本在运行。我们可以验证蓝色仍然是活跃的服务：
- en: '[PRE52]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We should still receive the following output:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该仍然收到以下输出：
- en: '[PRE53]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Now comes the interesting part: we can flip traffic from `blue` to `green`
    by editing the existing service for the web component. To do so, execute the following
    command:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是有趣的部分：我们可以通过编辑现有的网页组件服务，将流量从`blue`切换到`green`。为此，请执行以下命令：
- en: '[PRE54]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Change the value of the label color from `blue` to `green`. Then, save and
    quit the editor. The Kubernetes CLI will automatically update the service. Now,
    when we query the web service again, we’ll get this:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 将标签的颜色值从`blue`更改为`green`。然后，保存并退出编辑器。Kubernetes CLI将自动更新服务。现在，当我们再次查询网页服务时，将得到如下内容：
- en: '[PRE55]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'This time, we should get the following output:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这时，我们应该得到以下输出：
- en: '[PRE56]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: This confirms that the traffic has indeed switched to the green version of the
    web component (note `v2` at the end of the response to the `curl` command).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这证明了流量确实已经切换到`web`组件的绿色版本（注意`curl`命令响应末尾的`v2`）。
- en: Note
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If we wanted to stick to the declarative form, it would be better to update
    the `web-service-blue-green.yaml` file and apply the new version so that the desired
    state is still present in a file, avoiding potential mismatch in reality and the
    file. However, for illustration, the presented way is fine.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望坚持声明式的形式，那么最好更新`web-service-blue-green.yaml`文件并应用新版本，这样所需的状态仍然保存在文件中，避免现实与文件之间可能的不匹配。然而，为了说明，展示的方式是可以接受的。
- en: If we realize that something went wrong with our green deployment and the new
    version has a defect, we can easily switch back to the blue version by editing
    the web service again and replacing the value of the `color` label with blue.
    This rollback is instantaneous and should always work. Then, we can remove the
    buggy green deployment and fix the component. Once we have corrected the problem,
    we can deploy the green version once again.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们意识到绿色部署出现了问题，新版本有缺陷，我们可以通过再次编辑web服务并将`color`标签的值替换为蓝色来轻松切换回蓝色版本。这个回滚是瞬时的，并且应该总是有效。然后，我们可以删除有缺陷的绿色部署并修复组件。一旦我们修复了问题，就可以再次部署绿色版本。
- en: 'Once the green version of the component is running as expected and performing
    well, we can decommission the blue version:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦组件的绿色版本按照预期运行并且性能良好，我们可以停用蓝色版本：
- en: '[PRE57]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: When we’re ready to deploy a new version, 3.0, this one becomes the blue version.
    We must update the `ch17/web-deployment-blue.yaml` file accordingly and deploy
    it. Then, we must flip the web service from `green` to `blue`, and so on.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们准备部署新版本3.0时，这个版本将成为蓝色版本。我们必须相应地更新`ch17/web-deployment-blue.yaml`文件并部署它。然后，我们必须将web服务从`green`切换到`blue`，依此类推。
- en: With that, we have successfully demonstrated, with our `web` component of the
    pets application, how blue-green deployment can be achieved in a Kubernetes cluster.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这一点，我们成功地展示了如何在Kubernetes集群中实现蓝绿部署，使用的是我们宠物应用程序的`web`组件。
- en: Next, we are going to learn how to deal with secrets used by applications running
    on Kubernetes.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习如何处理Kubernetes中应用程序使用的秘密。
- en: Kubernetes secrets
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes秘密
- en: Sometimes, services that we want to run in the Kubernetes cluster have to use
    confidential data such as passwords, secret API keys, or certificates, to name
    just a few. We want to make sure that this sensitive information can only ever
    be seen by the authorized or dedicated service. All other services running in
    the cluster should not have any access to this data.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们希望在Kubernetes集群中运行的服务必须使用机密数据，比如密码、API密钥或证书，仅举几例。我们希望确保只有授权或专用服务能够查看这些敏感信息。集群中的所有其他服务不应访问这些数据。
- en: For this reason, Kubernetes secrets were introduced. A secret is a key-value
    pair where the key is the unique name of the secret, and the value is the actual
    sensitive data. Secrets are stored in `etcd`. Kubernetes can be configured so
    that secrets are encrypted at rest – that is, in `etcd` – and in transit – that
    is, when the secrets are going over the wire from a master node to the worker
    nodes that the pods of the service using this secret are running on.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 出于这个原因，Kubernetes引入了秘密管理。一个秘密是一个键值对，其中键是秘密的唯一名称，值是实际的敏感数据。秘密存储在`etcd`中。Kubernetes可以配置为在静态存储时加密秘密——也就是在`etcd`中——以及在传输时加密秘密——也就是当秘密从主节点传输到工作节点，这些节点上运行着使用此秘密的服务的pod时。
- en: Manually defining secrets
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动定义秘密
- en: 'We can create a secret declaratively in the same way as we can create any other
    object in Kubernetes. Here is the YAML for such a secret:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像创建Kubernetes中的任何其他对象一样声明式地创建一个秘密。以下是这样一个秘密的YAML配置：
- en: '[PRE58]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The preceding definition can be found in the `sample-solutions/ch17/pets-secret.yaml`
    file. Now, you might be wondering what the values are. Are these the real (unencrypted)
    values? No, they are not. And they are also not encrypted values, but just `base64`-encoded
    values.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的定义可以在`sample-solutions/ch17/pets-secret.yaml`文件中找到。现在，你可能会想知道这些值是什么。这些是实际的（未加密的）值吗？不是的。它们也不是加密值，而只是`base64`编码的值。
- en: 'Thus, they are not really secure, since base64-encoded values can easily be
    reverted to cleartext values. How did I get these values? That’s easy – follow
    these steps:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，它们并不完全安全，因为`base64`编码的值可以轻松还原为明文值。我是如何获得这些值的？这很简单——只需按照以下步骤操作：
- en: 'Use the `base64` tool as follows to encode the values:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `base64` 工具按如下方式编码值：
- en: '[PRE59]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'This will result in the following output:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '[PRE60]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Also, try the following:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，尝试以下操作：
- en: '[PRE61]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'This will give us the following output:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们带来以下输出：
- en: '[PRE62]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Using the preceding values, we can create the secret:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前面的值，我们可以创建密钥：
- en: '[PRE63]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Here, the command outputs this:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，命令输出如下：
- en: '[PRE64]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'We can describe the secret with the following command:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令描述密钥：
- en: '[PRE65]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The output of the preceding command looks like this:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令输出如下：
- en: '![Figure 17.22 – Creating and describing the Kubernetes secret](img/Figure_17.22_B19199.jpg)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.22 – 创建和描述 Kubernetes 密钥](img/Figure_17.22_B19199.jpg)'
- en: Figure 17.22 – Creating and describing the Kubernetes secret
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.22 – 创建和描述 Kubernetes 密钥
- en: 'In the description of the secret, the values are hidden and only their length
    is given. So, maybe the secrets are safe now. No, not really. We can easily decode
    this secret using the `kubectl` `get` command:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在密钥描述中，值被隐藏，只有它们的长度会显示。所以，也许密钥现在是安全的了。其实不然。我们可以通过 `kubectl` 的 `get` 命令轻松解码这个密钥：
- en: '[PRE66]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The output looks like this:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 17.23 – Kubernetes secret decoded](img/Figure_17.23_B19199.jpg)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.23 – 解码 Kubernetes 密钥](img/Figure_17.23_B19199.jpg)'
- en: Figure 17.23 – Kubernetes secret decoded
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.23 – 解码 Kubernetes 密钥
- en: As we can see in the preceding screenshot, we have our original secret values
    back.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的截图所示，我们已经恢复了原始的密钥值。
- en: 'Decode the values you got previously:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码你之前得到的值：
- en: '[PRE67]'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'This will result in the following output:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '[PRE68]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Thus, the consequence is that this method of creating a Kubernetes secret is
    not to be used in any environment other than development, where we deal with non-sensitive
    data. In all other environments, we need a better way to deal with secrets.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，结果是这种创建 Kubernetes 密钥的方法只适用于开发环境，在那里我们处理的是非敏感数据。在所有其他环境中，我们需要一种更好的方式来处理密钥。
- en: Creating secrets with kubectl
  id: totrans-339
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 kubectl 创建密钥
- en: 'A much safer way to define secrets is to use `kubectl`. First, we must create
    files containing the base64-encoded secret values, similar to what we did in the
    preceding section, but, this time, we must store the values in temporary files:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 定义密钥的更安全方式是使用 `kubectl`。首先，我们必须创建包含 base64 编码密钥值的文件，类似于前一节所做的，但这次，我们必须将值存储在临时文件中：
- en: '[PRE69]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Now, we can use `kubectl` to create a secret from those files, as follows:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 `kubectl` 从这些文件创建密钥，如下所示：
- en: '[PRE70]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'This will result in this output:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '[PRE71]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: The secret can then be used the same way as the manually created secret.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，密钥可以像手动创建的密钥一样使用。
- en: Why is this method more secure than the other one, you might ask? Well, first
    of all, no YAML defines a secret, and it is stored in some source code version
    control system, such as GitHub, which many people have access to, so they can
    see and decode the secrets.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，为什么这种方法比另一种更安全？首先，没有 YAML 文件定义密钥，并且它存储在某些源代码版本控制系统中，例如 GitHub，很多人都可以访问这些系统，因此他们可以看到并解码这些密钥。
- en: Only the admin that is authorized to know the secrets ever sees their values
    and uses them to directly create the secrets in the (production) cluster. The
    cluster itself is protected by role-based access control so that no unauthorized
    persons have access to it, nor can they possibly decode the secrets defined in
    the cluster.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 只有授权了解密钥的管理员才能看到密钥的值，并使用它们直接在（生产）集群中创建密钥。集群本身受到基于角色的访问控制保护，因此没有授权的人无法访问它，也无法解码集群中定义的密钥。
- en: Now, let’s see how we can use the secrets that we have defined.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何使用我们定义的密钥。
- en: Using secrets in a pod
  id: totrans-350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 pod 中使用密钥
- en: 'Let’s say we want to create a `Deployment` object where the `web` component
    uses our secret, `pets-secret`, which we introduced in the preceding section.
    We can use the following command to create the secret in the cluster:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们要创建一个 `Deployment` 对象，其中 `web` 组件使用我们在前一节中介绍的密钥 `pets-secret`。我们可以使用以下命令在集群中创建密钥：
- en: '[PRE72]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'In the `sample-solutions/ch17/web-deployment-secret.yaml` file, we can find
    the definition of the `Deployment` object. We had to add the part starting from
    line 23 to the original definition of the `Deployment` object:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `sample-solutions/ch17/web-deployment-secret.yaml` 文件中，我们可以找到 `Deployment`
    对象的定义。我们需要将从第 23 行开始的部分添加到原始的 `Deployment` 对象定义中：
- en: '![Figure 17.24 – The Deployment object for the web component with a secret](img/Figure_17.24_B19199.jpg)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.24 – 带有密钥的 web 组件的 Deployment 对象](img/Figure_17.24_B19199.jpg)'
- en: Figure 17.24 – The Deployment object for the web component with a secret
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.24 – 带有密钥的Web组件的部署对象
- en: On lines 29 through 32, we define a volume called `secrets` from our secret,
    `pets-secret`. Then, we use this volume in the container, as described on lines
    25 through 28.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 在第29到32行，我们定义了一个名为`secrets`的卷，该卷来自我们的密钥`pets-secret`。然后，我们按照第25到28行的描述，在容器中使用该卷。
- en: We mount the secrets in the container filesystem at `/etc/secrets` and mount
    the volume in read-only mode. Thus, the secret values will be available to the
    container as files in said folder. The names of the files will correspond to the
    key names, and the content of the files will be the values of the corresponding
    keys. The values will be provided in unencrypted form to the application running
    inside the container.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将密钥挂载到容器文件系统的`/etc/secrets`路径，并以只读模式挂载该卷。因此，密钥值将作为文件提供给容器，并存放在该文件夹中。文件名将对应于键名，文件内容将是对应键的值。密钥值将以未加密的形式提供给运行在容器内的应用程序。
- en: 'Apply the deployment with the following command:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令应用部署：
- en: '[PRE73]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'In our case, since we have the username and password keys in the secret, we
    will find two files, named `username` and `password`, in the `/etc/secrets` folder
    in the container filesystem. The `username` file should contain the `john.doe`
    value and the `password` file should contain the `sEcret-pasSw0rD` value. Let’s
    confirm this:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，由于密钥中有用户名和密码的键，我们将在容器文件系统的`/etc/secrets`文件夹中找到两个文件，分别名为`username`和`password`。`username`文件应该包含`john.doe`值，`password`文件应该包含`sEcret-pasSw0rD`值。让我们确认一下：
- en: 'First, we will get the name of the pod:'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们将获取Pod的名称：
- en: '[PRE74]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'This will give us the following output:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们以下输出：
- en: '![Figure 17.25 – Looking for the name of the pod](img/Figure_17.25_B19199.jpg)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![图17.25 – 查找Pod的名称](img/Figure_17.25_B19199.jpg)'
- en: Figure 17.25 – Looking for the name of the pod
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.25 – 查找Pod的名称
- en: 'Using the pod’s name, we can execute the commands shown in the following screenshot
    to retrieve the secrets:'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Pod的名称，我们可以执行以下屏幕截图中显示的命令来获取密钥：
- en: '![Figure 17.26 – Confirming that secrets are available inside the container](img/Figure_17.26_B19199.jpg)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![图17.26 – 确认容器内可以访问密钥](img/Figure_17.26_B19199.jpg)'
- en: Figure 17.26 – Confirming that secrets are available inside the container
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.26 – 确认容器内可以访问密钥
- en: On line 1 of the preceding output, we `exec` into the container where the `web`
    component runs. Then, on lines 2 to 5, we list the files in the `/etc/secrets`
    folder, and, finally, on the last 3 lines, we show the content of the two files,
    which, unsurprisingly, shows the secret values in clear text.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出的第1行，我们`exec`进入运行`web`组件的容器。然后，在第2到5行，我们列出了`/etc/secrets`文件夹中的文件，最后，在最后3行，我们展示了两个文件的内容，毫无意外地，显示了明文的密钥值。
- en: Since any application written in any language can read simple files, this mechanism
    of using secrets is very backward-compatible. Even an old Cobol application can
    read clear text files from the filesystem.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 由于任何语言编写的应用程序都可以读取简单的文件，因此使用密钥的这种机制非常向后兼容。即使是一个旧的Cobol应用程序也能从文件系统中读取明文文件。
- en: 'Before leaving, please delete the Kubernetes deployment:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 离开之前，请删除Kubernetes部署：
- en: '[PRE75]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Sometimes, though, applications expect secrets to be available in environment
    variables.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时应用程序期望密钥在环境变量中可用。
- en: Let’s look at what Kubernetes offers us in this case.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看Kubernetes在这种情况下为我们提供了什么。
- en: Secret values in environment variables
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 环境变量中的密钥值
- en: 'Let’s say our web component expects the username in the `PETS_USERNAME` environment
    variable and the password in the `PETS_PASSWORD` environment variable. If this
    is the case, we can modify our deployment YAML file so that it looks as follows:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的Web组件期望`PETS_USERNAME`环境变量中有用户名，`PETS_PASSWORD`环境变量中有密码。如果是这样，我们可以修改部署的YAML文件，使其如下所示：
- en: '![Figure 17.27 – Deployment mapping secret values to environment variables](img/Figure_17.27_B19199.jpg)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![图17.27 – 部署映射密钥值到环境变量](img/Figure_17.27_B19199.jpg)'
- en: Figure 17.27 – Deployment mapping secret values to environment variables
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.27 – 部署映射密钥值到环境变量
- en: On lines 25 through 35, we define the two environment variables, `PETS_USERNAME`
    and `PETS_PASSWORD`, and map the corresponding key-value pair of `pets-secret`
    to them.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在第25到35行，我们定义了两个环境变量`PETS_USERNAME`和`PETS_PASSWORD`，并将`pets-secret`中的相应键值对映射到它们。
- en: 'Apply the updated deployment:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 应用更新后的部署：
- en: '[PRE76]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Note that we don’t need a volume anymore; instead, we directly map the individual
    keys of `pets-secret` to the corresponding environment variables that are valid
    inside the container. The following sequence of commands shows that the secret
    values are indeed available inside the container in the respective environment
    variables:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们不再需要使用卷；相反，我们直接将 `pets-secret` 的各个密钥映射到容器内有效的环境变量。以下命令序列显示了秘密值确实可用，并且已经映射到相应的环境变量中：
- en: '![Figure 17.28 – The secret values have been mapped to environment variables](img/Figure_17.28_B19199.jpg)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.28 – 秘密值已经映射到环境变量](img/Figure_17.28_B19199.jpg)'
- en: Figure 17.28 – The secret values have been mapped to environment variables
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.28 – 秘密值已经映射到环境变量
- en: In this section, we have shown you how to define secrets in a Kubernetes cluster
    and how to use those secrets in containers running as part of the pods of a deployment.
    We have shown two variants of how secrets can be mapped inside a container – using
    files and using environment variables.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了如何在 Kubernetes 集群中定义秘密，以及如何在作为部署的一部分运行的容器中使用这些秘密。我们展示了秘密如何在容器内部映射的两种变体——使用文件和使用环境变量。
- en: Summary
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned how to deploy an application into a Kubernetes cluster
    and how to set up application-level routing for this application. Furthermore,
    we learned how to update application services running in a Kubernetes cluster
    without causing any downtime. Finally, we used secrets to provide sensitive information
    to application services running in the cluster.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何将应用程序部署到 Kubernetes 集群，并为该应用程序设置应用层路由。此外，我们还学习了如何在不引起任何停机的情况下更新
    Kubernetes 集群中运行的应用服务。最后，我们使用秘密为集群中运行的应用服务提供敏感信息。
- en: In the next chapter, we are going to learn about different techniques that are
    used to monitor an individual service or a whole distributed application running
    on a Kubernetes cluster. We will also learn how we can troubleshoot an application
    service that is running in production without altering the cluster or the cluster
    nodes that the service is running on. Stay tuned.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习不同的技术，这些技术用于监控在 Kubernetes 集群中运行的单个服务或整个分布式应用程序。我们还将学习如何在不更改集群或服务所在集群节点的情况下，排查生产环境中运行的应用服务问题。敬请期待。
- en: Further reading
  id: totrans-389
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Here are a few links that provide additional information on the topics that
    were discussed in this chapter:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些链接，提供了本章讨论主题的更多信息：
- en: '*Performing a rolling* *update*: [https://bit.ly/2o2okEQ](https://bit.ly/2o2okEQ)'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*执行滚动* *更新*：[https://bit.ly/2o2okEQ](https://bit.ly/2o2okEQ)'
- en: '*Blue-green* *deployment*: [https://bit.Ly/2r2IxNJ](https://bit.Ly/2r2IxNJ)'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*蓝绿* *部署*：[https://bit.Ly/2r2IxNJ](https://bit.Ly/2r2IxNJ)'
- en: '*Secrets in* *Kubernetes*: [https://bit.ly/2C6hMZF](https://bit.ly/2C6hMZF)'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kubernetes中的秘密*：[https://bit.ly/2C6hMZF](https://bit.ly/2C6hMZF)'
- en: Questions
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'To assess your learning progress, please answer the following questions:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估你的学习进度，请回答以下问题：
- en: You have an application consisting of two services, the first one being a web
    API and the second one being a database, such as MongoDB. You want to deploy this
    application into a Kubernetes cluster. In a few short sentences, explain how you
    would proceed.
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你有一个由两个服务组成的应用程序，第一个是 Web API，第二个是数据库，如 MongoDB。你想将这个应用程序部署到 Kubernetes 集群中。用简短的几句话解释你会如何进行。
- en: What are liveness and readiness probes in the context of a Kubernetes application
    service?
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 应用服务的上下文中，liveness 和 readiness 探针是什么？
- en: Describe in your own words what components you need to establish layer 7 (or
    application-level) routing for your application.
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请用自己的话描述你需要哪些组件来为你的应用程序建立第七层（或应用层）路由。
- en: List the main steps needed to implement a blue-green deployment for a simple
    application service. Avoid going into too much detail.
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 简要列出实施蓝绿部署所需的主要步骤。避免过多细节。
- en: Name three or four types of information that you would provide to an application
    service through Kubernetes secrets.
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列举三到四种你会通过 Kubernetes 秘密提供给应用服务的信息类型。
- en: Name the sources that Kubernetes accepts when creating a secret.
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出 Kubernetes 在创建秘密时接受的来源。
- en: How do you configure an application service to use Kubernetes secrets?
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何配置应用服务以使用 Kubernetes 秘密？
- en: Answers
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 答案
- en: 'Here are the answers to this chapter’s questions:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是本章问题的答案：
- en: 'Assuming we have a Docker image in a registry for the two application services
    – the web API and MongoDB – we need to do the following:'
  id: totrans-405
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设我们在注册表中有一个用于两个应用服务的Docker镜像——网页API和MongoDB——我们需要做如下操作：
- en: Define a deployment for MongoDB using a `StatefulSet` object; let’s call this
    deployment `db-deployment`. The `StatefulSet` object should have one replica (replicating
    MongoDB is a bit more involved and is outside the scope of this book).
  id: totrans-406
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`StatefulSet`对象定义MongoDB的部署；我们将这个部署命名为`db-deployment`。`StatefulSet`对象应该有一个副本（复制MongoDB稍微复杂一些，超出了本书的范围）。
- en: Define a Kubernetes service called `db` of the `ClusterIP` type for `db-deployment`.
  id: totrans-407
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个名为`db`的Kubernetes服务，类型为`ClusterIP`，用于`db-deployment`。
- en: Define a deployment for the web API; let’s call it `web-deployment`.
  id: totrans-408
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个网页API的部署，命名为`web-deployment`。
- en: Let’s scale this service to three instances.
  id: totrans-409
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将这个服务扩展为三个实例。
- en: Define a Kubernetes service called `api` of the `NodePort` type for `web-deployment`.
  id: totrans-410
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个名为`api`的Kubernetes服务，类型为`NodePort`，用于`web-deployment`。
- en: If we are using secrets, then define those secrets directly in the cluster using
    `kubectl`.
  id: totrans-411
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们使用密钥，那么直接在集群中通过`kubectl`定义这些密钥。
- en: Deploy the application using `kubectl`.
  id: totrans-412
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl`部署应用。
- en: Liveness and readiness probes are health checks provided by Kubernetes for containers.
    A liveness probe checks whether a container is still running, and if not, Kubernetes
    automatically restarts it. A readiness probe checks whether a container is ready
    to serve requests. If a container fails the readiness check, it is not removed,
    but it does not receive incoming requests until it passes the readiness probe.
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存活探针和就绪探针是Kubernetes为容器提供的健康检查。存活探针检查容器是否仍在运行，如果没有，Kubernetes会自动重启它。就绪探针检查容器是否准备好接受请求。如果容器未通过就绪检查，它不会被移除，但在通过就绪探针之前，不会接收任何传入请求。
- en: To implement layer 7 routing for an application, we ideally use `IngressController`.
    This is a reverse proxy such as Nginx that has a sidecar listening on the Kubernetes
    Server API for relevant changes and updating the reverse proxy’s configuration
    and restarting it if such a change has been detected. Then, we need to define
    ingress resources in the cluster that define the routing, for example, from a
    context-based route such as `https://example.com/pets` to `<a service name>/<port>`
    or a pair such as `api/32001`. The moment Kubernetes creates or changes this `Ingress`
    object, the sidecar of `IngressController` picks it up and updates the proxy’s
    routing configuration.
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了实现应用的第7层路由，我们理想情况下使用`IngressController`。这是一种反向代理，如Nginx，它有一个侧车容器监听Kubernetes服务器API的相关变化，并在检测到变化时更新反向代理的配置并重启它。然后，我们需要在集群中定义Ingress资源，定义路由，例如从基于上下文的路由如`https://example.com/pets`到`<服务名称>/<端口>`或类似`api/32001`的配对。当Kubernetes创建或更改此`Ingress`对象时，`IngressController`的侧车容器会捕捉并更新代理的路由配置。
- en: 'Assuming this is a cluster internal inventory service, then we do the following:'
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设这是一个集群内部的库存服务，那么我们做如下操作：
- en: When deploying version 1.0, we define a deployment called `inventory-deployment-blue`
    and label the pods with a label of `color:blue`.
  id: totrans-416
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署1.0版本时，我们定义一个名为`inventory-deployment-blue`的部署，并将Pods标记为`color:blue`。
- en: We deploy the Kubernetes service of the `ClusterIP` type called `inventory`
    for the preceding deployment with the selector containing `color:blue`.
  id: totrans-417
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为前述部署部署一个类型为`ClusterIP`的Kubernetes服务，名为`inventory`，并且选择器包含`color:blue`。
- en: When we’re ready to deploy the new version of the `payments` service, we define
    a deployment for version 2.0 of the service and call it `inventory-deployment-green`.
    We add a label of `color:green` to the pods.
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们准备部署新版本的`payments`服务时，我们定义一个该服务的2.0版本的部署，并将其命名为`inventory-deployment-green`。我们给Pods添加一个`color:green`标签。
- en: We can now smoke-test the “green” service and when everything is OK, we can
    update the inventory service so that the selector contains `color:green`.
  id: totrans-419
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以对“绿色”服务进行冒烟测试，当一切正常时，我们可以更新库存服务，使选择器包含`color:green`。
- en: Some forms of information that are confidential and thus should be provided
    to services through Kubernetes secrets include passwords, certificates, API key
    IDs, API key secrets, and tokens.
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些形式的信息是机密的，因此应该通过Kubernetes密钥提供给服务，包括密码、证书、API密钥ID、API密钥秘密和令牌。
- en: Sources for secret values can be files or base64-encoded values.
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 密钥值的来源可以是文件或base64编码的值。
- en: To configure an application to use a Kubernetes secret, you must create a `Secret`
    object with the sensitive data. Then, you must modify your `Pod` specification
    so that it includes a reference to the `Secret` object. This reference can be
    made as an environment variable in the container specification or as a volume
    mount, allowing the secret data to be used by your application.
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要配置应用程序使用 Kubernetes 密钥，必须创建一个包含敏感数据的`Secret`对象。然后，必须修改你的`Pod`规格，使其包含对`Secret`对象的引用。此引用可以作为容器规格中的环境变量，或者作为卷挂载，这样你的应用程序就可以使用这些密钥数据。
