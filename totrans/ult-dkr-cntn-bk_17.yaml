- en: '17'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '17'
- en: Deploying, Updating, and Securing an Application with Kubernetes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 部署、更新和保护应用
- en: In the previous chapter, we learned about the basics of the container orchestrator
    known as Kubernetes. We got a high-level overview of the architecture of Kubernetes
    and learned a lot about the important objects used by Kubernetes to define and
    manage a containerized application.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了关于容器编排器 Kubernetes 的基础知识。我们对 Kubernetes 的架构进行了概览，并了解了 Kubernetes
    用来定义和管理容器化应用的许多重要对象。
- en: In this chapter, we will learn how to deploy, update, and scale applications
    into a Kubernetes cluster. We will also explain how zero-downtime deployments
    are achieved to enable disruption-free updates and rollbacks of mission-critical
    applications. Finally, we will introduce Kubernetes secrets as a means to configure
    services and protect sensitive data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何将应用程序部署、更新和扩展到 Kubernetes 集群中。我们还将解释如何实现零停机部署，以便无干扰地更新和回滚关键任务应用。最后，我们将介绍
    Kubernetes 秘密，作为配置服务和保护敏感数据的一种手段。
- en: 'This chapter covers the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: Deploying our first application
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署我们的第一个应用
- en: Defining liveness and readiness
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义存活性和就绪性
- en: Zero-downtime deployments
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零停机部署
- en: Kubernetes secrets
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 秘密
- en: 'After working through this chapter, you will be able to do the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章后，你将能够完成以下任务：
- en: Deploy a multi-service application into a Kubernetes cluster
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一个多服务应用部署到 Kubernetes 集群中
- en: Define a liveness and readiness probe for your Kubernetes application service
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为你的 Kubernetes 应用服务定义存活探针和就绪探针
- en: Update an application service running in Kubernetes without causing downtime
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新在 Kubernetes 中运行的应用服务，而不会造成停机
- en: Define secrets in a Kubernetes cluster
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 集群中定义秘密
- en: Configure an application service to use Kubernetes secrets
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置应用服务以使用 Kubernetes 秘密
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we’re going to use Docker Desktop on our local computer. Please
    refer to [*Chapter 2*](B19199_02.xhtml#_idTextAnchor027), *Setting Up a Working
    Environment*, for more information on how to install and use Docker Desktop.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用本地计算机上的 Docker Desktop。有关如何安装和使用 Docker Desktop 的更多信息，请参阅 [*第2章*](B19199_02.xhtml#_idTextAnchor027)，*设置工作环境*。
- en: 'The code for this chapter can be found here: `main/sample-solutions/ch17`.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在这里找到：`main/sample-solutions/ch17`。
- en: Please make sure you have cloned this book’s GitHub repository, as described
    in [*Chapter 2*](B19199_02.xhtml#_idTextAnchor027).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保你已经按照 [*第2章*](B19199_02.xhtml#_idTextAnchor027) 中描述的方式克隆了本书的 GitHub 仓库。
- en: 'In your Terminal, navigate to the `~/The-Ultimate-Docker-Container-Book` folder
    and create a subfolder called `ch17` and navigate to it:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的终端中，导航到 `~/The-Ultimate-Docker-Container-Book` 文件夹，并创建一个名为 `ch17` 的子文件夹并进入它：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Deploying our first application
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署我们的第一个应用
- en: We will take our pets application, which we first introduced in [*Chapter 11*](B19199_11.xhtml#_idTextAnchor237),
    *Managing Containers with* *Docker Compose*, and deploy it into a Kubernetes cluster.
    Our cluster will be Docker Desktop, which, as you know, is offering us a single
    node Kubernetes cluster. However, from the perspective of deployment, it doesn’t
    matter how big the cluster is and whether the cluster is located in the cloud,
    in your company’s data center, or on your workstation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把我们的宠物应用——我们在 [*第11章*](B19199_11.xhtml#_idTextAnchor237) 中首次介绍的，*使用 Docker
    Compose 管理容器*——部署到 Kubernetes 集群中。我们的集群将使用 Docker Desktop，它提供了一个单节点的 Kubernetes
    集群。然而，从部署的角度来看，集群的规模和集群位于云端、公司数据中心或你的工作站并不重要。
- en: Deploying the web component
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署 Web 组件
- en: 'Just as a reminder, our application consists of two application services: the
    Node-based web component and the backing PostgreSQL database. In the previous
    chapter, we learned that we need to define a Kubernetes Deployment object for
    each application service we want to deploy. We’ll do this for the web component
    first. As always in this book, we will choose the declarative way of defining
    our objects:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，我们的应用程序由两个应用服务组成：基于 Node 的 Web 组件和后台 PostgreSQL 数据库。在上一章中，我们学习了需要为每个我们想要部署的应用服务定义一个
    Kubernetes 部署对象。我们将首先为 Web 组件执行此操作。和本书中一贯的做法一样，我们将选择声明式方式来定义我们的对象：
- en: 'We will use our local Kubernetes single-node cluster provided by Docker Desktop.
    Make sure Kubernetes is turned on for your Docker Desktop installation:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用由 Docker Desktop 提供的本地 Kubernetes 单节点集群。确保你的 Docker Desktop 安装中已启用 Kubernetes：
- en: '![Figure 17.1 – Kubernetes on Docker Desktop](img/Figure_17.01_B19199.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图17.1 – 在Docker Desktop上运行Kubernetes](img/Figure_17.01_B19199.jpg)'
- en: Figure 17.1 – Kubernetes on Docker Desktop
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.1 – 在Docker Desktop上运行Kubernetes
- en: 'To your code subfolder (`ch17`), add a file called `web-deployment.yaml` with
    the following content:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的代码子文件夹（`ch17`）中，添加一个名为`web-deployment.yaml`的文件，内容如下：
- en: '![Figure 17.2 – Kubernetes deployment definition for the web component](img/Figure_17.02_B19199.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图17.2 – `web`组件的Kubernetes部署定义](img/Figure_17.02_B19199.jpg)'
- en: Figure 17.2 – Kubernetes deployment definition for the web component
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.2 – `web`组件的Kubernetes部署定义
- en: 'The preceding deployment definition can be found in the `web-deployment.yaml`
    file in the `sample-solutions/ch17` subfolder. It contains the instructions necessary
    to deploy the `web` component. The lines of code are as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的部署定义可以在`sample-solutions/ch17`子文件夹中的`web-deployment.yaml`文件中找到。它包含了部署`web`组件所需的指令。代码行如下：
- en: 'Line 7: We define the name for our `Deployment` object as `web`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7行：我们将`Deployment`对象的名称定义为`web`。
- en: 'Line 9: We declare that we want to have one instance of the `web` component
    running.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9行：我们声明希望运行一个`web`组件的实例。
- en: 'Lines 11 to 13: Through `Selector`, we define which pods will be part of our
    deployment, namely those that have the `app` and `service` labels with values
    of `pets` and `web`, respectively.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第11到13行：通过`Selector`，我们定义了哪些Pods将成为我们部署的一部分，即那些具有`app`和`service`标签，且值分别为`pets`和`web`的Pods。
- en: 'Line 14: In the template for the pods starting at line 11, we define that each
    pod will have the `app` and `service` labels applied to them.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第14行：在从第11行开始的Pod模板中，我们定义了每个Pod将应用`app`和`service`标签。
- en: 'Lines 20 onward: We define the single container that will be running in the
    pod. The image for the container is our well-known `fundamentalsofdocker/ch11-web:2.0`
    image and the name of the container will be `web`.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从第20行开始：我们定义了将在Pod中运行的唯一容器。容器的镜像是我们熟悉的`fundamentalsofdocker/ch11-web:2.0`镜像，容器的名称将为`web`。
- en: 'Lines 23 and 24: It is worth noting that we declare that the container exposes
    port `3000` to incoming traffic.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第23行和第24行：值得注意的是，我们声明容器将端口`3000`暴露给传入流量。
- en: 'Please make sure that you have set the context of `kubectl` to Docker Desktop.
    See [*Chapter 2*](B19199_02.xhtml#_idTextAnchor027), *Setting Up a Working Environment*,
    for details on how to do that. Use the following command:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请确保您已将`kubectl`的上下文设置为Docker Desktop。有关如何设置的详细信息，请参见[*第二章*](B19199_02.xhtml#_idTextAnchor027)，《设置工作环境》。使用以下命令：
- en: '[PRE1]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You will receive the following output:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您将收到以下输出：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can deploy this `Deployment` object using the following command:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令部署此`Deployment`对象：
- en: '[PRE3]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The preceding command outputs the following message:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令输出如下信息：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can double-check that the deployment has been created again using our Kubernetes
    CLI:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过Kubernetes CLI再次确认该部署是否已创建：
- en: '[PRE5]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We should see the following output:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该看到以下输出：
- en: '![Figure 17.3 – Listing all the resources running in Kind](img/Figure_17.03_B19199.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图17.3 – 列出所有在Kind中运行的资源](img/Figure_17.03_B19199.jpg)'
- en: Figure 17.3 – Listing all the resources running in Kind
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.3 – 列出所有在Kind中运行的资源
- en: In the preceding output, we can see that Kubernetes created three objects –
    the deployment, a pertaining `ReplicaSet`, and a single pod (remember that we
    specified that we want one replica only). The current state corresponds to the
    desired state for all three objects, so we are fine so far.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们可以看到Kubernetes创建了三个对象——部署（deployment）、相关的`ReplicaSet`，以及一个Pod（记住我们指定了只需要一个副本）。当前状态与这三个对象的期望状态一致，所以到目前为止我们没问题。
- en: 'Now, the web service needs to be exposed to the public. For this, we need to
    define a Kubernetes `Service` object of the `NodePort` type. Create a new file
    called `web-service.yaml` and add the following code to it:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，web服务需要公开给外部访问。为此，我们需要定义一个Kubernetes类型为`NodePort`的`Service`对象。创建一个名为`web-service.yaml`的新文件，并向其中添加以下代码：
- en: '![Figure 17.4 – Definition of the Service object for our web component](img/Figure_17.04_B19199.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图17.4 – 我们的web组件的Service对象定义](img/Figure_17.04_B19199.jpg)'
- en: Figure 17.4 – Definition of the Service object for our web component
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.4 – 我们的web组件的Service对象定义
- en: Once again, the same file can be found in the `web-service.yaml` file in the
    `sample-solutions/ch17` subfolder.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，相同的文件可以在`sample-solutions/ch17`子文件夹中的`web-service.yaml`文件中找到。
- en: 'The preceding lines of code are as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码行如下：
- en: 'Line 7: We set the name of this `Service` object to `web`.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7行：我们将此`Service`对象的名称设置为`web`。
- en: 'Line 9: We define the type of `Service` object we’re using. Since the `web`
    component has to be accessible from outside of the cluster, this cannot be a `Service`
    object of the `ClusterIP` type and must be of the `NodePort` or `LoadBalancer`
    type. We discussed the various types of Kubernetes services in the previous chapter,
    so will not go into further detail about this. In our example, we’re using a `NodePort`
    type of service.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9行：我们定义了使用的`Service`对象类型。由于`web`组件必须能够从集群外部访问，因此不能是`ClusterIP`类型的`Service`对象，必须是`NodePort`或`LoadBalancer`类型。在前一章中我们讨论了Kubernetes服务的各种类型，因此这里不再详细说明。在我们的示例中，我们使用的是`NodePort`类型的服务。
- en: 'Lines 10 to 13: We specify that we want to expose port `3000` for access through
    the TCP protocol. Kubernetes will map container port `3000` automatically to a
    free host port in the range of 30,000 to 32,768\. Which port Kubernetes effectively
    chooses can be determined using the `kubectl get service` or `kubectl describe`
    command for the service after it has been created.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10到13行：我们指定希望通过TCP协议暴露端口`3000`供访问。Kubernetes会自动将容器端口`3000`映射到30,000到32,768范围内的一个空闲主机端口。Kubernetes最终选择的端口可以通过在服务创建后使用`kubectl
    get service`或`kubectl describe`命令来确定。
- en: 'Lines 14 to 16: We define the filter criteria for the pods that this service
    will be a stable endpoint for. In this case, it is all the pods that have the
    `app` and `service` labels with the `pets` and `web` values, respectively.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第14到16行：我们定义了此服务将作为稳定端点的pods的过滤条件。在这种情况下，它是所有具有`app`和`service`标签且值分别为`pets`和`web`的pods。
- en: 'Now that we have this specification for a `Service` object, we can create it
    using `kubectl`:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经有了`Service`对象的规格说明，我们可以使用`kubectl`来创建它：
- en: '[PRE6]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can list all the services to see the result of the preceding command:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以列出所有服务，以查看前面命令的结果：
- en: '[PRE7]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding command produces the following output:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令会产生以下输出：
- en: '![Figure 17.5 – The Service object that was created for the web component](img/Figure_17.05_B19199.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.5 – 为Web组件创建的Service对象](img/Figure_17.05_B19199.jpg)'
- en: Figure 17.5 – The Service object that was created for the web component
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.5 – 为Web组件创建的Service对象
- en: In the preceding output, we can see that a service called `web` has been created.
    A unique `ClusterIP` value of `10.96.195.255` has been assigned to this service,
    and container port `3000` has been published on port `30319` on all cluster nodes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们可以看到一个名为`web`的服务已被创建。该服务被分配了一个唯一的`ClusterIP`值`10.96.195.255`，并且容器端口`3000`已在所有集群节点的端口`30319`上发布。
- en: 'If we want to test this deployment, we can use `curl`:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们想测试这个部署，可以使用`curl`：
- en: '[PRE8]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This will result in the following output:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As we can see, the response is `Pets Demo Application`, which is what we expected.
    The web service is up and running in the Kubernetes cluster. Next, we want to
    deploy the database.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，响应是`Pets Demo Application`，这是我们预期的结果。Web服务已在Kubernetes集群中启动并运行。接下来，我们将部署数据库。
- en: Deploying the database
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署数据库
- en: A database is a stateful component and has to be treated differently from stateless
    components, such as our web component. We discussed the difference between stateful
    and stateless components in a distributed application architecture in detail in
    [*Chapter 9*](B19199_09.xhtml#_idTextAnchor194),*Learning about* *Distributed
    Application Architecture*, and [*Chapter 3*](B19199_03.xhtml#_idTextAnchor057),
    *Introducing* *Container Orchestration*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库是一个有状态组件，必须与无状态组件（如我们的Web组件）不同对待。我们在[*第9章*](B19199_09.xhtml#_idTextAnchor194)《*学习分布式应用架构*》和[*第3章*](B19199_03.xhtml#_idTextAnchor057)《*容器编排介绍*》中详细讨论了分布式应用架构中有状态和无状态组件的区别。
- en: Kubernetes has defined a special type of `ReplicaSet` object for stateful components.
    This object is called `StatefulSet`. Let’s use this kind of object to deploy our
    database.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes为有状态组件定义了一种特殊类型的`ReplicaSet`对象，这种对象叫做`StatefulSet`。我们使用这种类型的对象来部署数据库。
- en: 'Create a new file called `db-stateful-set.yaml` and add the following content
    to it:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`db-stateful-set.yaml`的新文件，并将以下内容添加到该文件中：
- en: '![Figure 17.6 – A StatefulSet object for the DB component](img/Figure_17.06_B19199.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.6 – 用于DB组件的StatefulSet对象](img/Figure_17.06_B19199.jpg)'
- en: Figure 17.6 – A StatefulSet object for the DB component
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.6 – 用于DB组件的StatefulSet对象
- en: The definition can also be found in the `sample-solutions/ch17` subfolder.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 定义也可以在`sample-solutions/ch17`子文件夹中找到。
- en: OK; this looks a bit scary, but it isn’t. It is a bit longer than the definition
    of the deployment for the web component since we also need to define a volume
    where the PostgreSQL database can store the data. The volume claim definition
    is on lines 25 to 33.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，看起来有点吓人，但其实不是。它比 web 组件的部署定义稍长，因为我们还需要定义一个卷，用于 PostgreSQL 数据库存储数据。卷索赔定义在第
    25 至 33 行。
- en: We want to create a volume called `pets-data` that has a maximum size equal
    to 100 MB. On lines 22 to 24, we use this volume and mount it into the container
    at `/var/lib/postgresql/data`, where PostgreSQL expects it. On line 21, we also
    declare that PostgreSQL is listening at port `5432`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要创建一个名为 `pets-data` 的卷，其最大大小为 100 MB。在第 22 至 24 行，我们使用此卷，并将其挂载到容器中的 `/var/lib/postgresql/data`，这是
    PostgreSQL 期望的位置。在第 21 行，我们还声明 PostgreSQL 正在端口 `5432` 上监听。
- en: 'As always, we use `kubectl` to deploy our `StatefulSet`:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像往常一样，我们使用 `kubectl` 部署我们的 `StatefulSet`：
- en: '[PRE10]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, if we list all the resources in the cluster, we will be able to see the
    additional objects that were created:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，如果我们列出集群中的所有资源，我们将能够看到创建的额外对象：
- en: '![Figure 17.7 – The StatefulSet and its pod](img/Figure_17.07_B19199.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.7 – StatefulSet 及其 pod](img/Figure_17.07_B19199.jpg)'
- en: Figure 17.7 – The StatefulSet and its pod
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.7 – StatefulSet 及其 pod
- en: Here, we can see that `StatefulSet` and a pod have been created. For both, the
    current state corresponds to the desired state and thus the system is healthy,
    but that doesn’t mean that the `web` component can access the database at this
    time. Service discovery won’t work. Remember that the `web` component wants to
    access the `db` service under the name `db`. We hardcoded the `db` hostname in
    the `server.js` file.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到已创建了 `StatefulSet` 和一个 pod。对于两者来说，当前状态与期望状态相符，因此系统是健康的，但这并不意味着此时 `web`
    组件可以访问数据库。服务发现不起作用。请记住，`web` 组件希望使用 `db` 服务的名称来访问 `db`。我们在 `server.js` 文件中硬编码了
    `db` 主机名。
- en: To make service discovery work inside the cluster, we have to define a Kubernetes
    `Service` object for the database component too. Since the database should only
    ever be accessible from within the cluster, the type of `Service` object we need
    is `ClusterIP`.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使集群内的服务发现正常工作，我们还必须为数据库组件定义一个 Kubernetes `Service` 对象。由于数据库应仅能从集群内部访问，因此我们需要的
    `Service` 对象类型是 `ClusterIP`。
- en: 'Create a new file called `db-service.yaml` and add the following specification
    to it. It can be found in the `sample-solutions/ch17` subfolder:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为 `db-service.yaml` 的新文件，并将以下规范添加到其中。它可以在 `sample-solutions/ch17` 子文件夹中找到：
- en: '![Figure 17.8 – Definition of the Kubernetes Service object for the database](img/Figure_17.08_B19199.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.8 – 为数据库定义的 Kubernetes Service 对象](img/Figure_17.08_B19199.jpg)'
- en: Figure 17.8 – Definition of the Kubernetes Service object for the database
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.8 – 为数据库定义的 Kubernetes Service 对象
- en: 'The database component will be represented by this `Service` object. It can
    be reached by the name `db`, which is the name of the service, as defined on line
    4\. The database component does not have to be publicly accessible, so we decided
    to use a `Service` object of the `ClusterIP` type. The selector on lines 10 to
    12 defines that this service represents a stable endpoint for all the pods that
    have the necessary labels defined – that is, `app: pets` and `service: db`.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '数据库组件将由此 `Service` 对象表示。它可以通过名称 `db` 进行访问，这是服务的名称，如第 4 行所定义。数据库组件不必公开访问，因此我们决定使用
    `ClusterIP` 类型的 `Service` 对象。第 10 至 12 行的选择器定义了该服务代表具有必要标签的所有 pod 的稳定端点 – 即 `app:
    pets` 和 `service: db`。'
- en: 'Let’s deploy this service with the following command:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用以下命令部署此服务：
- en: '[PRE11]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, we should be ready to test the application. We can use the browser this
    time to enjoy the beautiful animal images from the Maasai Mara national park in
    Kenya:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们应该准备好测试该应用程序了。这次我们可以使用浏览器，欣赏肯尼亚马赛马拉国家公园美丽的动物图像：
- en: '![Figure 17.9 – Testing the pets application running in Kubernetes](img/Figure_17.09_B19199.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.9 – 在 Kubernetes 中运行 pets 应用程序的测试](img/Figure_17.09_B19199.jpg)'
- en: Figure 17.9 – Testing the pets application running in Kubernetes
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.9 – 在 Kubernetes 中运行 pets 应用程序的测试
- en: In this case, port number `30317` is the number that Kubernetes automatically
    selected for my `web` `Service` object. Replace this number with the port that
    Kubernetes assigned to your service. You can get the number by using the `kubectl
    get` `services` command.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，端口号 `30317` 是 Kubernetes 自动为我的 `web` `Service` 对象选择的端口号。请将此数字替换为 Kubernetes
    分配给您的服务的端口号。您可以使用 `kubectl get services` 命令获取该数字。
- en: 'With that, we have successfully deployed the pets application to a single-node
    Kubernetes cluster provided by Docker Desktop. We had to define four artifacts
    to do so, which are as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就成功将宠物应用程序部署到了 Docker Desktop 提供的单节点 Kubernetes 集群中。我们需要定义四个构件才能完成这一操作，它们如下所示：
- en: '`Deployment` and `Service` objects for the `web` component'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Deployment` 和 `Service` 对象用于 `web` 组件'
- en: '`StatefulSet` and `Service` objects for the `database` component'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StatefulSet` 和 `Service` 对象用于 `database` 组件'
- en: 'To remove the application from the cluster, we can use the following small
    script:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要从集群中移除应用程序，我们可以使用以下小脚本：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Please note the last line in this script. We are deleting the persistent volume
    claim that Kubernetes automatically created as part of the `db` deployment. When
    we delete the `db` deployment, this claim is not automatically deleted! Persistent
    volume claims are a bit similar (but not the same, mind you) as Docker volumes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意该脚本的最后一行。我们正在删除 Kubernetes 自动为 `db` 部署创建的持久卷声明。当我们删除 `db` 部署时，这个声明不会被自动删除！持久卷声明与
    Docker 卷有点相似（但请注意，它们并不相同）。
- en: Use the `kubectl get pvc` command to get a list of all claims on your machine.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `kubectl get pvc` 命令查看机器上所有声明的列表。
- en: Next, we will optimize the deployment.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将优化部署。
- en: Streamlining the deployment
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 精简部署过程
- en: So far, we have created four artifacts that needed to be deployed to the cluster.
    This is only a very simple application, consisting of two components. Imagine
    having a much more complex application. It would quickly become a maintenance
    nightmare. Luckily, we have several options as to how we can simplify the deployment.
    The method that we are going to discuss here is the possibility of defining all
    the components that make up an application in Kubernetes in a single file.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经创建了四个需要部署到集群中的构件。这只是一个非常简单的应用程序，由两个组件组成。试想如果是一个更加复杂的应用程序，它会迅速变成一场维护噩梦。幸运的是，我们有几个方法可以简化部署。我们将在这里讨论的方法是，将组成
    Kubernetes 应用程序的所有组件定义在一个文件中。
- en: Other solutions that lie outside the scope of this book include using a package
    manager, such as Helm ([https://helm.sh/](https://helm.sh/)), or Kustomize ([https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/)),
    the native Kubernetes solution.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 本书未涉及的其他解决方案包括使用包管理器，例如 Helm（[https://helm.sh/](https://helm.sh/)）或 Kustomize（[https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/)），这是
    Kubernetes 的原生解决方案。
- en: 'If we have an application consisting of many Kubernetes objects, such as `Deployment`
    and `Service` objects, then we can keep them all in a single file and separate
    the individual object definitions by three dashes. For example, if we wanted to
    have the `Deployment` and `Service` definitions for the `web` component in a single
    file, this would look as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的应用程序包含多个 Kubernetes 对象，例如 `Deployment` 和 `Service` 对象，那么我们可以将它们都保存在一个文件中，并通过三个破折号分隔各个对象定义。例如，如果我们想在一个文件中包含
    `web` 组件的 `Deployment` 和 `Service` 定义，文件内容将如下所示：
- en: '![Figure 17.10 – Deployment and Service for web in a single file](img/Figure_17.10_B19199.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.10 – 单个文件中的 web 组件部署和服务](img/Figure_17.10_B19199.jpg)'
- en: Figure 17.10 – Deployment and Service for web in a single file
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.10 – 单个文件中的 web 组件部署和服务
- en: You can find this file in `sample-solutions/ch17/install-web.yaml`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 `sample-solutions/ch17/install-web.yaml` 文件中找到此文件。
- en: 'Next, we collected all four object definitions for the pets application in
    the `sample-solutions/ch17/install-pets.yaml` file, and we can deploy the application
    in one go:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将所有四个对象定义收集到 `sample-solutions/ch17/install-pets.yaml` 文件中，并可以一次性部署该应用程序：
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This will give us this output:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给出如下输出：
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Similarly, we created a script called `sample-solutions/ch17/remove-pets.sh`
    to remove all the artifacts of the pets application from the Kubernetes cluster.
    Note that the file was made executable with `chmod +x ./remove-pets.sh` first.
    Now, we can use the following command:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们创建了一个名为 `sample-solutions/ch17/remove-pets.sh` 的脚本，用于从 Kubernetes 集群中删除所有宠物应用程序的构件。请注意，该文件在使用之前已通过
    `chmod +x ./remove-pets.sh` 命令设置为可执行文件。现在，我们可以使用以下命令：
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This will result in an output like is:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下输出：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Alternatively, you can use the following command:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以使用以下命令：
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This will delete all the resources except the persistent volume claim, which
    you still need to delete by hand:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这将删除除持久卷声明外的所有资源，而持久卷声明需要手动删除：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: With this, we have taken the pets application we introduced in [*Chapter 11*](B19199_11.xhtml#_idTextAnchor237)*,*
    *Managing Containers with* *Docker Compose*, and defined all the Kubernetes objects
    that are necessary to deploy this application into a Kubernetes cluster. In each
    step, we made sure that we got the expected result, and once all the artifacts
    existed in the cluster, we showed the running application.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们已经使用在[*第11章*](B19199_11.xhtml#_idTextAnchor237)《使用 Docker Compose 管理容器》中介绍的宠物应用程序，定义了将此应用程序部署到
    Kubernetes 集群中所需的所有 Kubernetes 对象。在每个步骤中，我们确保得到了预期的结果，并且一旦所有的工件存在于集群中，我们展示了运行中的应用程序。
- en: Defining liveness and readiness
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义存活性和就绪性
- en: Container orchestration systems such as Kubernetes and Docker Swarm make it
    significantly easier to deploy, run, and update highly distributed, mission-critical
    applications. The orchestration engine automates many cumbersome tasks, such as
    scaling up or down, asserting that the desired state is maintained at all times,
    and more.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 像 Kubernetes 和 Docker Swarm 这样的容器编排系统大大简化了部署、运行和更新高度分布式、关键任务应用程序的过程。编排引擎自动化了许多繁琐的任务，例如上下扩展、确保所需状态始终得到维护等。
- en: However, the orchestration engine cannot just do everything automatically. Sometimes,
    we developers need to support the engine with some information that only we can
    know about. So, what do I mean by that?
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，编排引擎不能自动完成所有事情。有时，我们开发人员需要提供一些只有我们才能了解的信息来支持引擎。那么，我说的是什么意思呢？
- en: Let’s look at a single application service. Let’s assume it is a microservice
    and let’s call it service A. If we run service A containerized on a Kubernetes
    cluster, then Kubernetes can make sure that we have the five instances that we
    require in the service definition running at all times. If one instance crashes,
    Kubernetes can quickly launch a new instance and thus maintain the desired state.
    But what if an instance of the service does not crash, but is unhealthy or just
    not ready yet to serve requests? Kubernetes should know about both situations.
    But it can’t, since good or bad health from an application service perspective
    is outside of the knowledge of the orchestration engine. Only we application developers
    can know when our service is healthy and when it is not.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一个单一的应用服务。假设它是一个微服务，我们称之为服务 A。如果我们将服务 A 容器化并运行在 Kubernetes 集群上，那么 Kubernetes
    可以确保我们在服务定义中要求的五个实例始终运行。如果一个实例崩溃，Kubernetes 可以快速启动一个新实例，从而保持所需状态。但是，如果一个服务实例没有崩溃，而是不健康或还没有准备好处理请求呢？Kubernetes
    应该知道这两种情况。但它不能，因为从应用服务的角度来看，健康与否超出了编排引擎的知识范畴。只有我们应用程序的开发人员知道我们的服务何时健康，何时不健康。
- en: The application service could, for example, be running, but its internal state
    could have been corrupted due to some bug, it could be in an endless loop, or
    it could be in a deadlock situation.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，应用服务可能正在运行，但由于某些 bug 其内部状态可能已经损坏，可能处于无限循环中，或者可能处于死锁状态。
- en: Similarly, only we application developers know whether our service is ready
    to work, or whether it is still initializing. Although it is highly recommended
    to keep the initialization phase of a microservice as short as possible, it often
    cannot be avoided if a significant time span is needed by a particular service
    so that it’s ready to operate. Being in this state of initialization is not the
    same thing as being unhealthy, though. The initialization phase is an expected
    part of the life cycle of a microservice or any other application service.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，只有我们这些应用程序开发人员才知道我们的服务是否准备好工作，或者它是否还在初始化中。虽然强烈建议将微服务的初始化阶段尽可能缩短，但如果某些服务需要较长的时间才能准备好工作，通常也无法避免。在初始化状态下并不意味着不健康。初始化阶段是微服务或任何其他应用服务生命周期中的预期部分。
- en: Thus, Kubernetes should not try to kill our microservice if it is in the initialization
    phase. If our microservice is unhealthy, though, Kubernetes should kill it as
    quickly as possible and replace it with a fresh instance.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们的微服务处于初始化阶段，Kubernetes 不应尝试杀死它。但是，如果我们的微服务不健康，Kubernetes 应该尽快将其杀死并替换为一个新的实例。
- en: Kubernetes has the concept of probes to provide the seam between the orchestration
    engine and the application developer. Kubernetes uses these probes to find out
    more about the inner state of the application service at hand. Probes are executed
    locally, inside each container. There is a probe for the health – also called
    liveness – of the service, a startup probe, and a probe for the readiness of the
    service. Let’s look at them in turn.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 有探针的概念，提供了协调引擎和应用开发者之间的连接。Kubernetes 使用这些探针来获取有关当前应用服务内部状态的更多信息。探针在每个容器内本地执行。服务的健康状况探针（也叫存活探针）、启动探针和服务的就绪探针都有对应的定义。我们逐一来看它们。
- en: Kubernetes liveness probes
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 存活探针
- en: Kubernetes uses the liveness probe to decide when a container needs to be killed
    and when another instance should be launched instead. Since Kubernetes operates
    at a pod level, the respective pod is killed if at least one of its containers
    reports as being unhealthy.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 使用存活探针来决定何时杀死一个容器，以及何时启动另一个实例来替代它。由于 Kubernetes 在 Pod 层面上操作，如果至少有一个容器报告为不健康，则相应的
    Pod 会被杀死。
- en: 'Alternatively, we can say it the other way around: only if all the containers
    of a pod report to be healthy is the pod considered to be healthy.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以换个角度来说：只有当一个 Pod 中的所有容器都报告健康时，Pod 才会被视为健康。
- en: 'We can define the liveness probe in the specification for a pod as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 Pod 的规格说明中定义存活探针，如下所示：
- en: '[PRE19]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The relevant part is in the `livenessProbe` section. First, we define a command
    that Kubernetes will execute as a probe inside the container. In our case, we
    have a `PostreSQL` container and use the `netcat` Linux tool to probe port `5432`
    over TCP. The `nc localhost 5432` command is successful once Postgres listens
    to it.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 相关部分在 `livenessProbe` 部分。首先，我们定义一个 Kubernetes 会在容器内执行的命令作为探针。在我们的例子中，我们有一个 `PostreSQL`
    容器，使用 `netcat` Linux 工具来探测 `5432` 端口的 TCP。命令 `nc localhost 5432` 成功时，表示 Postgres
    已经开始监听此端口。
- en: The other two settings, `initialDelaySeconds` and `periodSeconds`, define how
    long Kubernetes should wait after starting the container until it first executes
    the probe and how frequently the probe should be executed thereafter. In our case,
    Kubernetes waits for 10 seconds before executing the first probe and then executes
    a probe every 5 seconds.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 另外两个设置项，`initialDelaySeconds` 和 `periodSeconds`，定义了 Kubernetes 在启动容器后应该等待多长时间才执行第一次探针，以及之后探针应该以多频繁的间隔执行。在我们的例子中，Kubernetes
    等待 10 秒钟后执行第一次探针，然后每隔 5 秒执行一次探针。
- en: 'It is also possible to probe an HTTP endpoint instead of using a command. Let’s
    assume we’re running a microservice from an image, `acme.com/my-api:1.0`, with
    an API that has an endpoint called `/api/health` that returns status `200 (OK)`
    if the microservice is healthy, and `50x (Error)` if it is unhealthy. Here, we
    can define the liveness probe as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以使用 HTTP 端点来替代命令进行探测。假设我们运行一个来自镜像 `acme.com/my-api:1.0` 的微服务，且该 API 的端点 `/api/health`
    返回状态 `200 (OK)` 表示微服务健康，返回 `50x (Error)` 表示微服务不健康。在这种情况下，我们可以这样定义存活探针：
- en: '[PRE20]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In the preceding snippet, I defined the liveness probe so that it uses the HTTP
    protocol and executed a `GET` request to the `/api/health` endpoint on port `5000`
    of `localhost`. Remember, the probe is executed inside the container, which means
    I can use localhost.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码片段中，我定义了存活探针，使其使用 HTTP 协议，并对 `localhost` 的 `5000` 端口上的 `/api/health` 端点执行
    `GET` 请求。记住，探针是在容器内执行的，这意味着我可以使用 localhost。
- en: 'We can also directly use the TCP protocol to probe a port on the container.
    But wait a second – didn’t we just do that in our first example, where we used
    the generic liveness probe based on an arbitrary command? Yes, you’re right, we
    did, but we had to rely on the presence of the `netcat` tool in the container
    to do so. We cannot assume that this tool is always there. Thus, it is favorable
    to rely on Kubernetes to do the TCP-based probing for us out of the box. The modified
    pod spec looks like this:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以直接使用 TCP 协议来探测容器上的端口。但稍等一下——我们不就是在第一个例子中使用了基于命令的通用存活探针吗？没错，我们确实使用了，但是我们依赖的是容器中是否存在
    `netcat` 工具。我们不能假设这个工具总是存在。因此，依赖 Kubernetes 本身来为我们执行基于 TCP 的探测会更好。修改后的 Pod 规格如下：
- en: '[PRE21]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This looks very similar. The only change is that the type of probe has been
    changed from `exec` to `tcpSocket` and that, instead of providing a command, we
    provide the port to probe.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这个看起来非常相似。唯一的变化是，探针的类型从 `exec` 更改为 `tcpSocket`，并且我们不再提供命令，而是提供要探测的端口。
- en: Note that we could also use `failureThreshold` here with Kubernetes’ `livenessProbe`.
    The `livenessProbe` failure threshold in Kubernetes is the minimum number of consecutive
    failures that must occur before the container is restarted. The default value
    is `3`. The minimum value is `1`. If the handler returns a failure code, `kubelet`
    kills the container and restarts it. Any code greater than or equal to `200` and
    less than `400` indicates success. Any other code indicates failure.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们也可以在这里使用 Kubernetes 的 `livenessProbe` 配置项中的 `failureThreshold`。在 Kubernetes
    中，`livenessProbe` 的失败阈值是指容器重启前必须连续发生的最小失败次数。默认值是 `3`。最小值是 `1`。如果处理程序返回失败代码，`kubelet`
    会杀死容器并重新启动它。任何大于或等于 `200` 且小于 `400` 的代码表示成功，其他任何代码表示失败。
- en: 'Let’s try this out:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试这个：
- en: Copy the `probes` subfolder from the `sample-solutions/ch17` folder to your
    `ch17` folder.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `sample-solutions/ch17` 文件夹中的 `probes` 子文件夹复制到你的 `ch17` 文件夹中。
- en: 'Build the Docker image with the following command:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令构建 Docker 镜像：
- en: '[PRE22]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Use `kubectl` to deploy the sample pod that’s defined in `probes-demo.yaml`:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `kubectl` 部署在 `probes-demo.yaml` 中定义的示例 pod：
- en: '[PRE23]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Describe the pod and specifically analyze the log part of the output:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述 pod，并具体分析输出中的日志部分：
- en: '[PRE24]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'During the first half minute or so, you should get the following output:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在大约前半分钟内，你应该看到以下输出：
- en: '![Figure 17.11 – Log output of the healthy pod](img/Figure_17.11_B19199.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.11 – 健康 pod 的日志输出](img/Figure_17.11_B19199.jpg)'
- en: Figure 17.11 – Log output of the healthy pod
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.11 – 健康 pod 的日志输出
- en: 'Wait at least 30 seconds and then describe the pod again. This time, you should
    see the following output:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待至少 30 秒，然后再次描述 pod。这时，你应该看到以下输出：
- en: '![Figure 17.12 – Log output of the pod after it has changed its state to Unhealthy](img/Figure_17.12_B19199.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.12 – pod 状态变为不健康后的日志输出](img/Figure_17.12_B19199.jpg)'
- en: Figure 17.12 – Log output of the pod after it has changed its state to Unhealthy
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.12 – pod 状态变为不健康后的日志输出
- en: The marked lines indicate the failure of the probe and the fact that the pod
    is going to be restarted.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 标记的行表示探针失败，并且 pod 即将被重启。
- en: 'If you get the list of pods, you will see that the pod has been restarted several
    times:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你获取 pod 列表，你会看到 pod 已经重启了多次：
- en: '[PRE25]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This results in this output:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '[PRE26]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'When you’re done with the sample, delete the pod with the following command:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成示例后，使用以下命令删除 pod：
- en: '[PRE27]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Next, we will have a look at the Kubernetes readiness probe.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看 Kubernetes 的就绪探针（readiness probe）。
- en: Kubernetes readiness probes
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 就绪探针（readiness probes）
- en: Kubernetes uses a readiness probe to decide when a service instance – that is,
    a container – is ready to accept traffic. Now, we all know that Kubernetes deploys
    and runs pods and not containers, so it only makes sense to talk about the readiness
    of a pod. Only if all containers in a pod report as ready is the pod considered
    to be ready itself. If a pod reports as not ready, then Kubernetes removes it
    from the service load balancers.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 使用就绪探针来决定服务实例——即容器——何时准备好接收流量。现在，我们都知道 Kubernetes 部署和运行的是 pod 而非容器，因此讨论
    pod 的就绪状态是有意义的。只有当 pod 中的所有容器都报告为“就绪”时，pod 才会被认为是“就绪”的。如果 pod 报告为“未就绪”，Kubernetes
    将会把它从服务负载均衡器中移除。
- en: 'Readiness probes are defined the same way as liveness probes: just switch the
    `livenessProbe` key in the pod spec to `readinessProbe`. Here is an example using
    our prior pod spec:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪探针的定义与存活探针相同：只需将 pod 配置中的 `livenessProbe` 键切换为 `readinessProbe`。以下是使用我们之前的
    pod 配置的示例：
- en: '[PRE28]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note that, in this example, we don’t need an initial delay for the liveness
    probe anymore since we now have a readiness probe. Thus, I have replaced the initial
    delay entry for the liveness probe with an entry called `failureThreshold`, which
    indicates how many times Kubernetes should repeat probing in case of a failure
    until it assumes that the container is unhealthy.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这个例子中，由于我们现在有了就绪探针（readiness probe），我们不再需要为存活探针设置初始延迟。因此，我已将存活探针的初始延迟条目替换为一个名为
    `failureThreshold` 的条目，表示在发生故障时 Kubernetes 应该重复探测多少次，直到它认为容器不健康。
- en: Kubernetes startup probes
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 启动探针（startup probes）
- en: It is often helpful for Kubernetes to know when a service instance has started.
    If we define a startup probe for a container, then Kubernetes does not execute
    the liveness or readiness probes, so long as the container’s startup probe does
    not succeed. Once again, Kubernetes looks at pods and starts executing liveness
    and readiness probes on its containers if the startup probes of all the pod’s
    containers succeed.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: When would we use a startup probe, given the fact that we already have the liveness
    and readiness probes? There might be situations where we have to account for exceptionally
    long startup and initialization times, such as when containerizing a legacy application.
    We could technically configure the readiness or liveness probes to account for
    this fact, but that would defeat the purpose of these probes. The latter probes
    are meant to provide quick feedback to Kubernetes on the health and availability
    of the container. If we configure for long initial delays or periods, then this
    would counter the desired outcome.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'Unsurprisingly, the startup probe is defined the same way as the readiness
    and liveness probes. Here is an example:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Make sure that you define the `failureThreshold * periodSeconds` product so
    that it’s big enough to account for the worst startup time.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: In our example, the max startup time should not exceed 150 seconds.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Zero-downtime deployments
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a mission-critical environment, the application must be always up and running.
    These days, we cannot afford downtime anymore. Kubernetes gives us various means
    of achieving this. Performing an update on an application in the cluster that
    causes no downtime is called a **zero-downtime deployment**. In this section,
    we will present two ways of achieving this. These are as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Rolling updates
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blue-green deployments
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start by discussing rolling updates.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Rolling updates
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, we learned that the Kubernetes `Deployment` object
    distinguishes itself from the `ReplicaSet` object in that it adds rolling updates
    and rollbacks on top of the latter’s functionality. Let’s use our web component
    to demonstrate this. We will have to modify the manifest or description of the
    deployment for the web component.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the same deployment definition as in the previous section, with
    one important difference – we will have `web` component running. The following
    definition can also be found in the `sample-solutions/ch17/web-deployment-rolling-v1.yaml`
    file:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.13 – Deployment for the web component with five replicas](img/Figure_17.13_B19199.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
- en: Figure 17.13 – Deployment for the web component with five replicas
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can create this deployment as usual and also, at the same time, the
    service that makes our component accessible:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Once we have deployed the pods and the service, we can test our web component.
    First, we can get the assigned node port with this command:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Next, we can use the `$PORT` environment variable in our `curl` statement:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This provides the expected output:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: As we can see, the application is up and running and returns the expected message,
    `Pets` `Demo Application`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'Our developers have created a new version, 2.1, of the web component. The code
    of the new version of the web component can be found in the `sample-solutions/ch17/web`
    folder, and the only change is located on line 12 of the `server.js` file:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.14 – Code change for version 2.0 of the web component](img/Figure_17.14_B19199.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: Figure 17.14 – Code change for version 2.0 of the web component
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now build the new image as follows (replace `demo` with your GitHub
    username):'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Subsequently, we can push the image to Docker Hub, as follows (replace `demo`
    with your GitHub username):'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, we want to update the image that’s used by our pods that are part of the
    `web` `Deployment` object. We can do this by using the `set image` command of
    `kubectl`:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If we test the application again, we’ll get a confirmation that the update
    has indeed happened:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output indicates that we now have version 2 installed:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, how do we know that there hasn’t been any downtime during this update?
    Did the update happen in a rolling fashion? What does rolling update mean at all?
    Let’s investigate. First, we can get a confirmation from Kubernetes that the deployment
    has indeed happened and was successful by using the `rollout` `status` command:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The command will respond as follows:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'If we describe the `web` deployment object with `kubectl describe deploy/web`,
    we will get the following list of events at the end of the output:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.15 – List of events found in the output of the deployment description
    of the web component](img/Figure_17.15_B19199.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
- en: Figure 17.15 – List of events found in the output of the deployment description
    of the web component
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: 'The first event tells us that, when we created the deployment, a `ReplicaSet`
    object called `web-769b88f67` with five replicas was created. Then, we executed
    the `update` command. The second event in the list tells us that this meant creating
    a new `ReplicaSet` object called `web-55cdf67cd` with, initially, one replica
    only. Thus, at that particular moment, six pods existed on the system: the five
    initial pods and one pod with the new version. But, since the desired state of
    the `Deployment` object states that we want five replicas only, Kubernetes now
    scales down the old `ReplicaSet` object to four instances, which we can see in
    the third event.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Then, again, the new `ReplicaSet` object was scaled up to two instances, and,
    subsequently, the old `ReplicaSet` object was scaled down to three instances,
    and so on, until we had five new instances and all the old instances were decommissioned.
    Although we cannot see any precise time (other than 3 minutes) when that happened,
    the order of the events tells us that the whole update happened in a rolling fashion.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: During a short period, some of the calls to the web service would have had an
    answer from the old version of the component, and some calls would have received
    an answer from the new version of the component, but at no time would the service
    have been down.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also list the `ReplicaSet` objects in the cluster and get confirmation
    of what I said in the preceding section:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.16 – Listing all the ReplicaSet objects in the cluster](img/Figure_17.16_B19199.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
- en: Figure 17.16 – Listing all the ReplicaSet objects in the cluster
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the new `ReplicaSet` object has five instances running
    and that the old one has been scaled down to zero instances. The reason that the
    old `ReplicaSet` object is still lingering is that Kubernetes provides us with
    the possibility of rolling back the update and, in that case, will reuse that
    `ReplicaSet`.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'To roll back the update of the image in case some undetected bug sneaked into
    the new code, we can use the `rollout` `undo` command:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This outputs the following:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We can test whether the rollback was successful like so:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'As we can see, the output shows us that this is the case:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'If we list the `ReplicaSet` objects, we will see the following output:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.17 – Listing the ReplicaSet objects after rolling back](img/Figure_17.17_B19199.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
- en: Figure 17.17 – Listing the ReplicaSet objects after rolling back
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: This confirms that the old `ReplicaSet` (`web-9d66cd994`) object has been reused
    and that the new one has been scaled down to zero instances.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'Before continuing, please delete the deployment and the service:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Sometimes, though, we cannot, or do not want to, tolerate the mixed state of
    an old version coexisting with the new version. We want an all-or-nothing strategy.
    This is where blue-green deployments come into play, which we will discuss next.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Blue-green deployment
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we want to do a blue-green style deployment for our `web` component of the
    pets application, then we can do so by using labels creatively. First, let’s remind
    ourselves how blue-green deployments work. Here is a rough step-by-step guide:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploy the first version of the `web` component as `blue`. We will label the
    pods with a label of `color: blue` to do so.'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy the Kubernetes service for these pods with the `color: blue` label in
    the `selector` section.'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we can deploy version 2 of the web component, but, this time, the pods
    have a label of `color: green`.'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can test the green version of the service to check that it works as expected.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, we can flip traffic from `blue` to `green` by updating the Kubernetes service
    for the web component. We will modify the selector so that it uses the `color:`
    `green` label.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s define a `Deployment` object for version 1, `blue`:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.18 – Specification of the blue deployment for the web component](img/Figure_17.18_B19199.jpg)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
- en: Figure 17.18 – Specification of the blue deployment for the web component
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: The preceding definition can be found in the `sample-solutions/ch17/web-deployment-blue.yaml`
    file.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 上述定义可以在`sample-solutions/ch17/web-deployment-blue.yaml`文件中找到。
- en: 'Please take note of line 8, where we define the name of the deployment as `web-blue`
    to distinguish it from the upcoming deployment, `web-green`. Also, note that we
    have added the `color: blue` label on lines 7, 15, and 21\. Everything else remains
    the same as before.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '请注意第8行，在那里我们将部署的名称定义为`web-blue`，以便与即将到来的`web-green`部署区分开来。另外，请注意我们在第7、15和21行添加了`color:
    blue`标签。其他内容与之前相同。'
- en: 'Now, we can define the `Service` object for the web component. It will be the
    same as the one we used before but with a minor change, as shown in the following
    screenshot:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以为网页组件定义`Service`对象。它将与我们之前使用的相同，但有一个小的改动，如下图所示：
- en: '![Figure 17.19 – Kubernetes service for the web component supporting blue-green
    deployments](img/Figure_17.19_B19199.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.19 – 支持蓝绿部署的网页组件 Kubernetes 服务](img/Figure_17.19_B19199.jpg)'
- en: Figure 17.19 – Kubernetes service for the web component supporting blue-green
    deployments
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.19 – 支持蓝绿部署的网页组件 Kubernetes 服务
- en: 'The only difference regarding the definition of the service we used earlier
    in this chapter is line 17, which adds the `color: blue` label to the selector.
    We can find the preceding definition in the `sample-solutions/ch17/web-service-blue-green.yaml`
    file.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '关于本章早些时候使用的服务定义，唯一的区别是第17行，它将`color: blue`标签添加到了选择器中。我们可以在`sample-solutions/ch17/web-service-blue-green.yaml`文件中找到上述定义。'
- en: 'Then, we can deploy the blue version of the `web` component with the following
    command:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用以下命令部署蓝色版本的`web`组件：
- en: '[PRE46]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We can deploy its service with this command:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用此命令部署其服务：
- en: '[PRE47]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Once the service is up and running, we can determine its IP address and port
    number and test it:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦服务启动并运行，我们可以确定其IP地址和端口号并进行测试：
- en: '[PRE48]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Then, we can access it with the `curl` command:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用`curl`命令访问它：
- en: '[PRE49]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'This gives us what we expect:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们预期的结果：
- en: '[PRE50]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now, we can deploy the green version of the `web` component. The definition
    of its `Deployment` object can be found in the `sample-solutions/ch17/web-deployment-green.yaml`
    file and looks as follows:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以部署`web`组件的绿色版本。其`Deployment`对象的定义可以在`sample-solutions/ch17/web-deployment-green.yaml`文件中找到，内容如下：
- en: '![Figure 17.20 – Specification of the green deployment for the web component](img/Figure_17.20_B19199.jpg)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.20 – 网页组件绿色部署规范](img/Figure_17.20_B19199.jpg)'
- en: Figure 17.20 – Specification of the green deployment for the web component
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.20 – 网页组件绿色部署规范
- en: 'The interesting lines are as follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的行如下：
- en: 'Line 8: Named `web-green` to distinguish it from `web-blue` and allow for parallel
    installation'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第8行：命名为`web-green`，以便与`web-blue`区分，并支持并行安装
- en: 'Lines 7, 15, and 21: Have the color green'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7、15和21行：颜色为绿色
- en: 'Line 24: Now using version 2.1 of the web image we built earlier in this chapter'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第24行：现在使用的是本章前面构建的网页镜像版本 2.1
- en: Do not forget to change ‘‘`demo`’’ to your own GitHub username on line 24.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 请不要忘记在第24行将`‘’demo‘’`改为你自己的GitHub用户名。
- en: 'Now, we’re ready to deploy this green version of the service. It should run
    separately from the blue service:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备部署这个绿色版本的服务。它应与蓝色服务分开运行：
- en: '[PRE51]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We can make sure that both deployments coexist like so:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以确保两个部署并存，如下所示：
- en: '![Figure 17.21 – Displaying the list of Deployment objects running in the cluster](img/Figure_17.21_B19199.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.21 – 显示集群中运行的部署对象列表](img/Figure_17.21_B19199.jpg)'
- en: Figure 17.21 – Displaying the list of Deployment objects running in the cluster
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.21 – 显示集群中运行的部署对象列表
- en: 'As expected, we have both blue and green running. We can verify that blue is
    still the active service:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，我们有蓝色和绿色两个版本在运行。我们可以验证蓝色仍然是活跃的服务：
- en: '[PRE52]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We should still receive the following output:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该仍然收到以下输出：
- en: '[PRE53]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Now comes the interesting part: we can flip traffic from `blue` to `green`
    by editing the existing service for the web component. To do so, execute the following
    command:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是有趣的部分：我们可以通过编辑现有的网页组件服务，将流量从`blue`切换到`green`。为此，请执行以下命令：
- en: '[PRE54]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Change the value of the label color from `blue` to `green`. Then, save and
    quit the editor. The Kubernetes CLI will automatically update the service. Now,
    when we query the web service again, we’ll get this:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 将标签的颜色值从`blue`更改为`green`。然后，保存并退出编辑器。Kubernetes CLI将自动更新服务。现在，当我们再次查询网页服务时，将得到如下内容：
- en: '[PRE55]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'This time, we should get the following output:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这时，我们应该得到以下输出：
- en: '[PRE56]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: This confirms that the traffic has indeed switched to the green version of the
    web component (note `v2` at the end of the response to the `curl` command).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: If we wanted to stick to the declarative form, it would be better to update
    the `web-service-blue-green.yaml` file and apply the new version so that the desired
    state is still present in a file, avoiding potential mismatch in reality and the
    file. However, for illustration, the presented way is fine.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: If we realize that something went wrong with our green deployment and the new
    version has a defect, we can easily switch back to the blue version by editing
    the web service again and replacing the value of the `color` label with blue.
    This rollback is instantaneous and should always work. Then, we can remove the
    buggy green deployment and fix the component. Once we have corrected the problem,
    we can deploy the green version once again.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the green version of the component is running as expected and performing
    well, we can decommission the blue version:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: When we’re ready to deploy a new version, 3.0, this one becomes the blue version.
    We must update the `ch17/web-deployment-blue.yaml` file accordingly and deploy
    it. Then, we must flip the web service from `green` to `blue`, and so on.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: With that, we have successfully demonstrated, with our `web` component of the
    pets application, how blue-green deployment can be achieved in a Kubernetes cluster.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Next, we are going to learn how to deal with secrets used by applications running
    on Kubernetes.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes secrets
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, services that we want to run in the Kubernetes cluster have to use
    confidential data such as passwords, secret API keys, or certificates, to name
    just a few. We want to make sure that this sensitive information can only ever
    be seen by the authorized or dedicated service. All other services running in
    the cluster should not have any access to this data.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, Kubernetes secrets were introduced. A secret is a key-value
    pair where the key is the unique name of the secret, and the value is the actual
    sensitive data. Secrets are stored in `etcd`. Kubernetes can be configured so
    that secrets are encrypted at rest – that is, in `etcd` – and in transit – that
    is, when the secrets are going over the wire from a master node to the worker
    nodes that the pods of the service using this secret are running on.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: Manually defining secrets
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can create a secret declaratively in the same way as we can create any other
    object in Kubernetes. Here is the YAML for such a secret:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The preceding definition can be found in the `sample-solutions/ch17/pets-secret.yaml`
    file. Now, you might be wondering what the values are. Are these the real (unencrypted)
    values? No, they are not. And they are also not encrypted values, but just `base64`-encoded
    values.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, they are not really secure, since base64-encoded values can easily be
    reverted to cleartext values. How did I get these values? That’s easy – follow
    these steps:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `base64` tool as follows to encode the values:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'This will result in the following output:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Also, try the following:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'This will give us the following output:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Using the preceding values, we can create the secret:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Here, the command outputs this:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'We can describe the secret with the following command:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The output of the preceding command looks like this:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.22 – Creating and describing the Kubernetes secret](img/Figure_17.22_B19199.jpg)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
- en: Figure 17.22 – Creating and describing the Kubernetes secret
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: 'In the description of the secret, the values are hidden and only their length
    is given. So, maybe the secrets are safe now. No, not really. We can easily decode
    this secret using the `kubectl` `get` command:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The output looks like this:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.23 – Kubernetes secret decoded](img/Figure_17.23_B19199.jpg)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
- en: Figure 17.23 – Kubernetes secret decoded
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the preceding screenshot, we have our original secret values
    back.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: 'Decode the values you got previously:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'This will result in the following output:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Thus, the consequence is that this method of creating a Kubernetes secret is
    not to be used in any environment other than development, where we deal with non-sensitive
    data. In all other environments, we need a better way to deal with secrets.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: Creating secrets with kubectl
  id: totrans-339
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A much safer way to define secrets is to use `kubectl`. First, we must create
    files containing the base64-encoded secret values, similar to what we did in the
    preceding section, but, this time, we must store the values in temporary files:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Now, we can use `kubectl` to create a secret from those files, as follows:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'This will result in this output:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: The secret can then be used the same way as the manually created secret.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: Why is this method more secure than the other one, you might ask? Well, first
    of all, no YAML defines a secret, and it is stored in some source code version
    control system, such as GitHub, which many people have access to, so they can
    see and decode the secrets.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: Only the admin that is authorized to know the secrets ever sees their values
    and uses them to directly create the secrets in the (production) cluster. The
    cluster itself is protected by role-based access control so that no unauthorized
    persons have access to it, nor can they possibly decode the secrets defined in
    the cluster.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s see how we can use the secrets that we have defined.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Using secrets in a pod
  id: totrans-350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s say we want to create a `Deployment` object where the `web` component
    uses our secret, `pets-secret`, which we introduced in the preceding section.
    We can use the following command to create the secret in the cluster:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'In the `sample-solutions/ch17/web-deployment-secret.yaml` file, we can find
    the definition of the `Deployment` object. We had to add the part starting from
    line 23 to the original definition of the `Deployment` object:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.24 – The Deployment object for the web component with a secret](img/Figure_17.24_B19199.jpg)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
- en: Figure 17.24 – The Deployment object for the web component with a secret
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: On lines 29 through 32, we define a volume called `secrets` from our secret,
    `pets-secret`. Then, we use this volume in the container, as described on lines
    25 through 28.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: We mount the secrets in the container filesystem at `/etc/secrets` and mount
    the volume in read-only mode. Thus, the secret values will be available to the
    container as files in said folder. The names of the files will correspond to the
    key names, and the content of the files will be the values of the corresponding
    keys. The values will be provided in unencrypted form to the application running
    inside the container.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply the deployment with the following command:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'In our case, since we have the username and password keys in the secret, we
    will find two files, named `username` and `password`, in the `/etc/secrets` folder
    in the container filesystem. The `username` file should contain the `john.doe`
    value and the `password` file should contain the `sEcret-pasSw0rD` value. Let’s
    confirm this:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will get the name of the pod:'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE74]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'This will give us the following output:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.25 – Looking for the name of the pod](img/Figure_17.25_B19199.jpg)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
- en: Figure 17.25 – Looking for the name of the pod
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the pod’s name, we can execute the commands shown in the following screenshot
    to retrieve the secrets:'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 17.26 – Confirming that secrets are available inside the container](img/Figure_17.26_B19199.jpg)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
- en: Figure 17.26 – Confirming that secrets are available inside the container
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: On line 1 of the preceding output, we `exec` into the container where the `web`
    component runs. Then, on lines 2 to 5, we list the files in the `/etc/secrets`
    folder, and, finally, on the last 3 lines, we show the content of the two files,
    which, unsurprisingly, shows the secret values in clear text.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: Since any application written in any language can read simple files, this mechanism
    of using secrets is very backward-compatible. Even an old Cobol application can
    read clear text files from the filesystem.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: 'Before leaving, please delete the Kubernetes deployment:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Sometimes, though, applications expect secrets to be available in environment
    variables.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at what Kubernetes offers us in this case.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: Secret values in environment variables
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s say our web component expects the username in the `PETS_USERNAME` environment
    variable and the password in the `PETS_PASSWORD` environment variable. If this
    is the case, we can modify our deployment YAML file so that it looks as follows:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.27 – Deployment mapping secret values to environment variables](img/Figure_17.27_B19199.jpg)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
- en: Figure 17.27 – Deployment mapping secret values to environment variables
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: On lines 25 through 35, we define the two environment variables, `PETS_USERNAME`
    and `PETS_PASSWORD`, and map the corresponding key-value pair of `pets-secret`
    to them.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply the updated deployment:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Note that we don’t need a volume anymore; instead, we directly map the individual
    keys of `pets-secret` to the corresponding environment variables that are valid
    inside the container. The following sequence of commands shows that the secret
    values are indeed available inside the container in the respective environment
    variables:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.28 – The secret values have been mapped to environment variables](img/Figure_17.28_B19199.jpg)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
- en: Figure 17.28 – The secret values have been mapped to environment variables
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have shown you how to define secrets in a Kubernetes cluster
    and how to use those secrets in containers running as part of the pods of a deployment.
    We have shown two variants of how secrets can be mapped inside a container – using
    files and using environment variables.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to deploy an application into a Kubernetes cluster
    and how to set up application-level routing for this application. Furthermore,
    we learned how to update application services running in a Kubernetes cluster
    without causing any downtime. Finally, we used secrets to provide sensitive information
    to application services running in the cluster.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to learn about different techniques that are
    used to monitor an individual service or a whole distributed application running
    on a Kubernetes cluster. We will also learn how we can troubleshoot an application
    service that is running in production without altering the cluster or the cluster
    nodes that the service is running on. Stay tuned.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-389
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are a few links that provide additional information on the topics that
    were discussed in this chapter:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: '*Performing a rolling* *update*: [https://bit.ly/2o2okEQ](https://bit.ly/2o2okEQ)'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Blue-green* *deployment*: [https://bit.Ly/2r2IxNJ](https://bit.Ly/2r2IxNJ)'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Secrets in* *Kubernetes*: [https://bit.ly/2C6hMZF](https://bit.ly/2C6hMZF)'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Questions
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To assess your learning progress, please answer the following questions:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: You have an application consisting of two services, the first one being a web
    API and the second one being a database, such as MongoDB. You want to deploy this
    application into a Kubernetes cluster. In a few short sentences, explain how you
    would proceed.
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are liveness and readiness probes in the context of a Kubernetes application
    service?
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe in your own words what components you need to establish layer 7 (or
    application-level) routing for your application.
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List the main steps needed to implement a blue-green deployment for a simple
    application service. Avoid going into too much detail.
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name three or four types of information that you would provide to an application
    service through Kubernetes secrets.
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name the sources that Kubernetes accepts when creating a secret.
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you configure an application service to use Kubernetes secrets?
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are the answers to this chapter’s questions:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming we have a Docker image in a registry for the two application services
    – the web API and MongoDB – we need to do the following:'
  id: totrans-405
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a deployment for MongoDB using a `StatefulSet` object; let’s call this
    deployment `db-deployment`. The `StatefulSet` object should have one replica (replicating
    MongoDB is a bit more involved and is outside the scope of this book).
  id: totrans-406
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a Kubernetes service called `db` of the `ClusterIP` type for `db-deployment`.
  id: totrans-407
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a deployment for the web API; let’s call it `web-deployment`.
  id: totrans-408
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s scale this service to three instances.
  id: totrans-409
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a Kubernetes service called `api` of the `NodePort` type for `web-deployment`.
  id: totrans-410
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: If we are using secrets, then define those secrets directly in the cluster using
    `kubectl`.
  id: totrans-411
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the application using `kubectl`.
  id: totrans-412
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Liveness and readiness probes are health checks provided by Kubernetes for containers.
    A liveness probe checks whether a container is still running, and if not, Kubernetes
    automatically restarts it. A readiness probe checks whether a container is ready
    to serve requests. If a container fails the readiness check, it is not removed,
    but it does not receive incoming requests until it passes the readiness probe.
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To implement layer 7 routing for an application, we ideally use `IngressController`.
    This is a reverse proxy such as Nginx that has a sidecar listening on the Kubernetes
    Server API for relevant changes and updating the reverse proxy’s configuration
    and restarting it if such a change has been detected. Then, we need to define
    ingress resources in the cluster that define the routing, for example, from a
    context-based route such as `https://example.com/pets` to `<a service name>/<port>`
    or a pair such as `api/32001`. The moment Kubernetes creates or changes this `Ingress`
    object, the sidecar of `IngressController` picks it up and updates the proxy’s
    routing configuration.
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Assuming this is a cluster internal inventory service, then we do the following:'
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When deploying version 1.0, we define a deployment called `inventory-deployment-blue`
    and label the pods with a label of `color:blue`.
  id: totrans-416
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: We deploy the Kubernetes service of the `ClusterIP` type called `inventory`
    for the preceding deployment with the selector containing `color:blue`.
  id: totrans-417
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: When we’re ready to deploy the new version of the `payments` service, we define
    a deployment for version 2.0 of the service and call it `inventory-deployment-green`.
    We add a label of `color:green` to the pods.
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: We can now smoke-test the “green” service and when everything is OK, we can
    update the inventory service so that the selector contains `color:green`.
  id: totrans-419
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Some forms of information that are confidential and thus should be provided
    to services through Kubernetes secrets include passwords, certificates, API key
    IDs, API key secrets, and tokens.
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sources for secret values can be files or base64-encoded values.
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To configure an application to use a Kubernetes secret, you must create a `Secret`
    object with the sensitive data. Then, you must modify your `Pod` specification
    so that it includes a reference to the `Secret` object. This reference can be
    made as an environment variable in the container specification or as a volume
    mount, allowing the secret data to be used by your application.
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
