<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-164"><a id="_idTextAnchor501"/>11</h1>
<h1 id="_idParaDest-165"><a id="_idTextAnchor502"/>Highly Available Cloud Deployments</h1>
<p>Continuing with our AWS deployment, we will start to deploy services into the network we created in the previous chapter, and by the end of the chapter, we will be left with a highly available WordPress installation.</p>
<p>Building on top of the roles we created in the previous chapter, we will be doing the following:</p>
<ul>
<li>Launching and configuring an Application Load Balancer</li>
<li>Launching and configuring Amazon <strong class="bold">Relational Database Service</strong> (<strong class="bold">RDS</strong>) (database)</li>
<li>Launching and configuring Amazon <strong class="bold">Elastic File System</strong> (<strong class="bold">EFS</strong>) (shared storage)</li>
<li>Launching an <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>) instance and creating an <strong class="bold">Amazon Machine Image</strong> (<strong class="bold">AMI</strong>) from it (deploying the WordPress code)</li>
<li>Launching and configuring a launch template to use the newly created AMI and autoscaling group (high availability)</li>
</ul>
<p>The chapter covers the following topics:</p>
<ul>
<li>Planning the deployment</li>
<li>The Playbook</li>
<li>Running the Playbook</li>
<li>Terminating all the resources</li>
</ul>
<h1 id="_idParaDest-166"><a id="_idTextAnchor503"/>Technical requirements</h1>
<p>As in the previous chapter, we will be using AWS; you will need the access key and secret key we created in the previous chapter to launch the resources needed for our highly available WordPress installation. Please note that we will be launching resources that incur charges. Again, you can find the complete playbook in the <code>Chapter11</code> folder of the accompanying GitHub repository at <a href="https://github.com/PacktPublishing/Learn-Ansible-Second-Edition/tree/main/Chapter11/">https://github.com/PacktPublishing/Learn-Ansible-Second-Edition/tree/main/Chapter11/</a>.</p>
<h1 id="_idParaDest-167"><a id="_idTextAnchor504"/>Planning the deployment</h1>
<p>Before diving into the playbooks, we should<a id="_idIndexMarker589"/> get an idea of what we are trying to achieve. As mentioned, we<a id="_idIndexMarker590"/> will build on our AWS <strong class="bold">Virtual Private Cloud</strong> (<strong class="bold">VPC</strong>) role by adding instances and storage; our final deployment will look like the following diagram:</p>
<div><div><img alt="Figure 11.1 – An overview of what we shall be launching" src="img/B21620_11_01.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1 – An overview of what we shall be launching</p>
<p>In the diagram, we have<a id="_idIndexMarker591"/> the following:</p>
<ul>
<li>2 x EC2 instances (t2.micro), deployed across different availability zones</li>
<li>1 x RDS instances (t2.micro)</li>
<li>1 x EFS storage across three availability zones</li>
</ul>
<p>Before we talk about the deployment itself, based on the diagram and specifications here, how much is this deployment going to cost us to run?</p>
<h2 id="_idParaDest-168"><a id="_idTextAnchor505"/>Costing the deployment</h2>
<p>The cost of running<a id="_idIndexMarker592"/> this deployment in the EU-West-1 region is as follows:</p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold">Instance Type</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"># </strong><strong class="bold">Number</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Instance cost</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Total </strong><strong class="bold">Monthly Cost</strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>EC2 instances (t2.micro)</p>
</td>
<td class="No-Table-Style">
<p>x2</p>
</td>
<td class="No-Table-Style">
<p>$9.20</p>
</td>
<td class="No-Table-Style">
<p>$18.40</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>RDS instance (t2.micro)</p>
</td>
<td class="No-Table-Style">
<p>x1</p>
</td>
<td class="No-Table-Style">
<p>$13.14</p>
</td>
<td class="No-Table-Style">
<p>$13.14</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Application Load Balancer</p>
</td>
<td class="No-Table-Style">
<p>x1</p>
</td>
<td class="No-Table-Style">
<p>$24.24</p>
</td>
<td class="No-Table-Style">
<p>$24.24</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>EFS</p>
</td>
<td class="No-Table-Style">
<p>5GB</p>
</td>
<td class="No-Table-Style">
<p>$0.88</p>
</td>
<td class="No-Table-Style">
<p>$4.40</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold">Total</strong></p>
</td>
<td class="No-Table-Style"/>
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p>$61.83</p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 11.1 – Cost of running the deployment</p>
<p>There will be a few other minor costs, such as bandwidth and storing the AMI that contains our software stack. We could also consider increasing these costs by adding additional redundancy, such as updating our RDS instance to a multi-AZ RDS primary and stand-by instance deployment and increasing the number of EC2 instances.</p>
<p>However, this introduces additional complexity to our deployment, as we are about to spend the rest of the chapter covering the playbook, which will be deploying the resources. I want to keep this playbook as simple as possible for now.</p>
<h2 id="_idParaDest-169"><a id="_idTextAnchor506"/>WordPress considerations and high availability</h2>
<p>So far, we have been launching<a id="_idIndexMarker593"/> WordPress on a single server, which is fine. Still, as we are trying to remove as many of the single points of failure within our deployment as possible, we must put a little thought into how we initially configure and launch our deployment.</p>
<p>First, let’s discuss the order we need to launch our deployment. The primary order in which we will need to tackle<a id="_idIndexMarker594"/> the elements is as follows:</p>
<ul>
<li><strong class="bold">VPC, subnets, internet gateway, routing, and security groups</strong>: These are all needed to launch our deployment.</li>
<li><strong class="bold">The Application Elastic Load Balancer</strong>: We will be using the public hostname of the Elastic Load Balancer for our installation, so this needs to be launched before we start our installation.</li>
<li><strong class="bold">The RDS database instance</strong>: Our database instance must be available before we launch our installation, as we need to create the WordPress database and bootstrap the installation.</li>
<li><strong class="bold">The EFS storage</strong>: We need some storage to share between the EC2 instances we will be launching next.</li>
</ul>
<p>So far, so good; however, this is where we have to start taking WordPress into account.</p>
<p>As some of you may know<a id="_idIndexMarker595"/> from experience, the current version<a id="_idIndexMarker596"/> of WordPress is not designed to be spread across multiple servers. We can apply plenty of hacks and workarounds to make WordPress play nicely in this sort of deployment; however, this chapter is about something other than the finer points of deploying WordPress. Instead, it is about using Ansible to deploy a multi-tiered web application.</p>
<p>Because of this, we will be going for the most basic of the multi-instance WordPress options by deploying our code and content on the EFS volume. This means that all we must do is install our LEMP stack. It should be noted that this option could be more performant at a large scale, but it will serve our needs.</p>
<p>Now, back to the list of tasks. When it comes<a id="_idIndexMarker597"/> to launching our instances, we need to do the following:</p>
<ol>
<li>Launch a temporary EC2 instance running Ubuntu to reuse parts of existing playbooks.</li>
<li>Update the operating system and install the software stack, supporting tools, and configuration needed for us to install and run our WordPress installation.</li>
<li>Mount the EFS volume, set the correct permissions, and configure it to mount when the instance boots.</li>
<li>Bootstrap WordPress itself.</li>
<li>Create an AMI from<a id="_idTextAnchor507"/> our temporary instance and then terminate the temporary instance as it will not be needed now.</li>
<li>Create a launch template that uses the AMI we just created.</li>
<li>Create an autoscaling group<a id="_idIndexMarker598"/> and attach the launch configuration; it should also register our WordPress instances with the Elastic Load Balancer.</li>
</ol>
<p>Further playbook runs, which will update the operating system and non-WordPress configuration, should repeat the process with the existing instances up and running, and then, once the AMI is built, it should<a id="_idIndexMarker599"/> be deployed alongside the current<a id="_idIndexMarker600"/> instances, which will then be terminated once the new instances are registered with the Elastic Load Balancer and receiving traffic.</p>
<p>This will allow us to update our operating system packages and configurations without downtime if everything goes as planned!</p>
<p>Now that we have an idea of what we are trying to achieve, let’s make a start on our playbook.</p>
<h1 id="_idParaDest-170"><a id="_idTextAnchor508"/>The Playbook</h1>
<p>We will use the Playbook<a id="_idIndexMarker601"/> we looked at in <a href="B21620_10.xhtml#_idTextAnchor458"><em class="italic">Chapter 10</em></a>, <em class="italic">Building Out a Cloud Network</em>, as a starting point, as all the roles are relevant to our deployment, and it already has the structure we need for our playbook.</p>
<p>We will also be using the roles to deploy and configure WordPress and the supporting software stack we used in <a href="B21620_09.xhtml#_idTextAnchor411"><em class="italic">Chapter 9</em></a>, <em class="italic">Moving to the Cloud</em>, with a few tweaks, which are needed as we are targeting AWS and not Microsoft Azure; I will let you know when we get to them.</p>
<p>Unlike previous chapters, we will first look at the <code>site.yml</code> file to get an idea of the order in which we will run the roles.</p>
<p>There are three stages in the file, starting<a id="_idIndexMarker602"/> with the stage that deploys and configures our underlying AWS resources:</p>
<pre class="source-code">
- name: "Deploy and configure the AWS Environment"
  hosts: localhost
  connection: local
  gather_facts: true
  vars:
    state: "present"
  vars_files:
    - group_vars/common.yml
  roles:
    - vpc
    - subnets
    - gateway
    - securitygroups
    - elb
    - efs
    - rds
    - ec2tmp
    - endpoints</pre> <p>As you can see, this is the same as the <code>site.yml</code> file from <a href="B21620_10.xhtml#_idTextAnchor458"><em class="italic">Chapter 10</em></a>, <em class="italic">Building Out a Cloud Network</em>, with additional roles added to the list from the <code>securitygroups</code> role downwards.</p>
<p>By the time our Playbook<a id="_idIndexMarker603"/> run gets to the second stage:</p>
<pre class="source-code">
- name: "Install and configure Wordpress"
  hosts: vmgroup
  gather_facts: true
  become: true
  become_method: "ansible.builtin.sudo"
  vars_files:
    - group_vars/common.yml
    - group_vars/generated_aws_endpoints.yml
  roles:
    - stack_install
    - stack_config
    - wordpress</pre> <p>A file called <code>group_vars/generated_aws_endpoints.yml</code> will have been generated, and there s<a id="_idTextAnchor509"/>hould be a temporary virtual machine instance up and running, meaning SSH should be accessible to the host running the Playbook.</p>
<p>Once this stage has been completed, our temporary virtual machine instance should have our software stack installed. WordPress will be freshly installed if this is the first time the playbook has been run, or if the playbook has detected an existing WordPress installation and left it alone unless there have been any changes to the plugin configuration from within the playbook.</p>
<p>The final stage is then run:</p>
<pre class="source-code">
- name: "Create AMI and update the Auto Scaling Group"
  hosts: localhost
  connection: local
  gather_facts: true
  vars:
    state: "present"
  vars_files:
    - group_vars/common.yml
  roles:
    - ec2ami
    - autoscaling</pre> <p>This stage creates an AMI from the temporary virtual machine instance, terminates the temporary instance as we no longer need it, creates a new version of our launch template, and then creates/updates the Auto Scaling Group<a id="_idIndexMarker604"/> to deploy the new version on the EC2 instances.</p>
<p>Sounds simple? Well, let’s find out.</p>
<h2 id="_idParaDest-171"><a id="_idTextAnchor510"/>The variables</h2>
<p>Out of the box, there<a id="_idIndexMarker605"/> is a single variables<a id="_idTextAnchor511"/><a id="_idIndexMarker606"/> file called <code>group_vars/common.yml</code> that contains all the static variables needed to deploy our environment.</p>
<p>Some additional files will be created in the <code>group_vars</code> folder throughout the Playbook run; they will contain some dynamically generated resources, such as passwords, resource names/endpoints, and other information.</p>
<p>We will discuss these files in more detail when we look at the tasks that create and interact with them; for now, we will look at the static variables defined within <code>group_vars/common.yml</code>, starting with the base application configuration.</p>
<h3>Application and resource configuration</h3>
<p>We start the configuration<a id="_idIndexMarker607"/> with the option<a id="_idIndexMarker608"/> to enable/disable debug when running the Playbook. By default, it is set to <code>false</code>; however, when running the Playbook, I recommend switching it to <code>true</code> and reviewing the output:</p>
<pre class="source-code">
debug_output: false</pre> <p>Next, we have the application name, region, and environment reference:</p>
<pre class="source-code">
app:
  name: "learnansible"
  region: "eu-west-1"
  env: "prod"</pre> <p>The next block of variables defines details for the WordPress database; as we will be using the Amazon RDS service, we are just using the variables that are defined later in the file, so we only have to update the information in one place:</p>
<pre class="source-code">
wp_database:
  name: "{{ rds.db_name }}"
  username: "{{ rds.db_username }}"
  password: "{{ rds.db_password }}"</pre> <p>The next block is the various variables used to configure WordPress itself:</p>
<pre class="source-code">
wordpress:
  dom<a id="_idTextAnchor512"/>ain: "http://{{ aws_endpoints.elb }}/"
  title: "WordPress installed by Ansible on {{ os_family }}"
  username: "ansible"
  password: "{{ rds.db_password }}"
  email: "test@test.com"
  plugins:
    - "jetpack"
    - "wp-super-cache"
    - "wordpress-seo"
    - "wordfence"
    - "nginx-helper"</pre> <p>There are no significant changes to when we last defined these in <a href="B21620_09.xhtml#_idTextAnchor411"><em class="italic">Chapter 9</em></a><em class="italic">, Moving to the Cloud</em>, apart from using the <code>aws_endpoints.lb</code> variable, which won’t be known until the Elastic Load <a id="_idIndexMarker609"/>Balancer has been launched. Also, for ease of use, we are reusing<a id="_idIndexMarker610"/> the password, which will be dynamically generated later in the file, as the WordPress admin password.</p>
<h3>Stack configuration</h3>
<p>The next section overrides<a id="_idIndexMarker611"/> the defaults in the <code>roles/stack_install</code> role:</p>
<pre class="source-code">
stack_packages<a id="_idTextAnchor513"/>:
  - "nginx"
  - "mariadb-client"
  - "php-cli"
  - "php-curl"
  - "php-fpm"
  - "php-gd"
  - "php-intl"
  - "php-mbstring"
  - "php-mysql"
  - "php-soap"
  - "php-xml"
  - "php-xmlrpc"
  - "php-zip"
  - "nfs-common" # Added for AWS
  - "nfs4-acl-tools" # Added for AWS
  - "autofs"  # Added for <a id="_idTextAnchor514"/>AWS
  - "rpcbind"  # Added for AWS</pre> <p>We have removed <code>mariadb-server</code> from the list of packages as we no longer need to install or configure a local database server, and we have added four packages at the end (all labeled <code># Added for AWS</code>). These packages install the software required to mount the EFS filesystem using the NFS protocol, which leads us nicely in<a id="_idTextAnchor515"/>to the next block:</p>
<pre class="source-code">
n<a id="_idTextAnchor516"/>fs:
  mount_point: "/var/www/"
  mount_options: "nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2"
  state: "mounted"
  fstype: "nfs4"</pre> <p>As you can see, this defines some basic<a id="_idIndexMarker612"/> information on where the EFS filesystem should be mounted, with what options and the type of filesystem it is.</p>
<h3>Resource names</h3>
<p>This next section builds up the names<a id="_idIndexMarker613"/> of the resources we are going to be deploying; there is nothing too special happening here – it is just defined like this, so we don’t have to update repeated information in several places manually:</p>
<pre class="source-code">
vpc_name: "{{ app.name }}-{{ app.env }}-{{ playbook_dict.vpc }}"
internet_gateway_name: "{{ app.name }}-{{ app.env }}-{{ playbook_dict.internet_gateway }}"
internet_gateway_route_name: "{{ internet_gateway_name }}-{{ playbook_dict.route }}"
elb_target_group_name: "{{ app.name }}-{{ app.env }}-{{ playbook_dict.elb_target_group }}"
elb_name: "{{ app.name }}-{{ app.env }}-{{ playbook_dict.elb }}"
efs_name: "{{ app.name }}-{{ app.env }}-{{ playbook_dict.efs }}"
rds_name: "{{ app.name }}-{{ app.env }}-{{ playbook_dict.rds }}"
ec2_tmp_name: "{{ app.name }}-tmp-{{ playbook_dict.ec2 }}"
ami_name: "{{ app.name }}-{{ app.env }}-{{ playbook_dict.ami }}"
ec2_name: "{{ app.name }}-{{ app.env }}-{{ playbook_dict.ec2 }}"
launch_template_name: "{{ app.name }}-{{ app.env }}-{{ playbook_dict.lt }}"
asg_name: "{{ app.name<a id="_idTextAnchor517"/> }}-{{ app.env }}-{{ playbook_dict.asg }}"</pre> <p>We will not be covering the full <code>playbook_dict</code> block here as there is not much to see, although as a reminder, this is what the start of it looks like:</p>
<pre class="source-code">
playbook_dict:
  deployedBy: "Ansible"
  ansible_warning: "Resource managed by Ansible"
  vpc: "vpc"</pre> <p>It just continues defining<a id="_idIndexMarker614"/> service names. The following section is where we start to define the variables used for the AWS resource deployment.</p>
<h2 id="_idParaDest-172"><a id="_idTextAnchor518"/>EC2 configuration</h2>
<p>The <code>ec2</code> variable is split<a id="_idIndexMarker615"/> into a few<a id="_idIndexMarker616"/> different layers. Layers for the auto-scaling group, the AMI, and the SSH keypair follow some general settings:</p>
<pre class="source-code">
ec2:
  instance_type: "t2.micro"
  public_ip: true
  ssh_port: "22"</pre> <p>The variables are used across instances apart from the <code>public_ip</code> reference, which is only used when launching the temporary virtual machine instance to bootstrap WordPress.</p>
<p>The next layer defines some details about the auto-scaling group and launch template when used; they help define how many instances are launched, how updated instances are rolled out, and also, how the load balancer will check to see if they are healthy:</p>
<pre class="source-code">
  asg:
    min_size: 1
    max_size: 3
    desired_capacity: 2
    health_check_type: "EC2"
    replace_batch_size: 1
    health_check_period: 300
    replace_all_instances: true
    wait_for_instances: true
    wait_timeout: 900
    disable_api_termination: true</pre> <p>Next, we define the details about the base AMI we will use; as you can see, we are using Ubuntu 22.0<a id="_idTextAnchor519"/>4, which is supplied by Canonical, the publisher and maintainer of Ubuntu:</p>
<pre class="source-code">
  ami:
    owners: "099720109477"
    filters:
      name: "ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*"
      virtualization_type: "hvm"</pre> <p>Finally, we have some details on the keypair<a id="_idIndexMarker617"/> to upload to AWS and use when launching our Virtual Machine instances:</p>
<pre class="source-code">
  keypair:
    name: "ssh_keypair"
    key_material: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"</pre> <p>Next up are the variables<a id="_idIndexMarker618"/> used when launching the RDS service.</p>
<h3>RDS configuration</h3>
<p>These are all<a id="_idIndexMarker619"/> standard, apart from the <code>rds.db_password</code> variable:</p>
<pre class="source-code">
rds:
  db_username: "{{ app.name }}"
  db_passwo<a id="_idTextAnchor520"/>rd: "{{ lookup('password', 'group_vars/generated_rds_passwordfile chars=ascii_letters,digits length=30') }}"
  db_name: "{{ app.name }}"
  instance_type: "db.t2.micro"
  engine: "mysql"
  engine_version: "8.0"
  allocated_storage: "5"</pre> <p>As you can see, we are using a lookup module to add a random password to the <code>group_vars/generated_rds_passwordfile</code> file; we are instructing the module to generate a 30-character random<a id="_idIndexMarker620"/> password comprising letters and numbers only.</p>
<h3>EFS configuration</h3>
<p>Here, we define the variables<a id="_idIndexMarker621"/> used to tell Ansible to wait and how long when creating the EFS resource:</p>
<pre class="source-code">
efs:
  wait: "yes"
  wait_time: "1200"</pre> <h3><a id="_idTextAnchor521"/>VPC and subnet configuration</h3>
<p><a id="_idTextAnchor522"/>This block remains<a id="_idIndexMarker622"/> unchanged from <a href="B21620_10.xhtml#_idTextAnchor458"><em class="italic">Chapter 10</em></a>, <em class="italic">Building Out a </em><em class="italic">Cloud Network</em>.</p>
<h3>Security group configuration</h3>
<p>Most of this block<a id="_idIndexMarker623"/> is unchanged from <a href="B21620_10.xhtml#_idTextAnchor458"><em class="italic">Chapter 10</em></a>, <em class="italic">Building Out a Cloud Network</em>, as we now define the SSH port as <code>ec2.ssh_port</code>. I have updated the EC2 group to use this reference rather than hardcoding port 22 into the block. The only other addition is the following:</p>
<pre class="source-code">
elb_seach_string: "elb"
ec2_seach_string: "ec2"
rds_seach_string: "rds"
efs_seach_string: "efs"</pre> <p>These will be used throughout the playbook when we query the AWS API for information on our security groups.</p>
<h3>The final block</h3>
<p>As per <a href="B21620_10.xhtml#_idTextAnchor458"><em class="italic">Chapter 10</em></a>, <em class="italic">Building Out a Cloud Network</em>, this contains <a id="_idIndexMarker624"/>the following:</p>
<pre class="source-code">
region: "{{ app.region }}"</pre> <p>That concludes our whistle-stop tour of the <code>group_vars/common.yml</code> file; as you can see, structure- and content-wise, we are following the same patterns as the last few chapters, where we group variables into logical blocks and trying to reuse references as much as possible throughout<a id="_idIndexMarker625"/> so that we don’t have to repeat information repeatedly.</p>
<h2 id="_idParaDest-173"><a id="_idTextAnchor523"/>The Playbook roles</h2>
<p>Now that we have covered<a id="_idIndexMarker626"/> the variables, we can work through the roles in the order they appear in the <code>site.yml</code> file.</p>
<h3>The VPC, subnets, gateway, and security groups roles</h3>
<p>There are no changes<a id="_idIndexMarker627"/> to these<a id="_idIndexMarker628"/> roles from <a href="B21620_10.xhtml#_idTextAnchor458"><em class="italic">Chapter 10</em></a>, <em class="italic">Building Out a Cloud Network</em>; they are just<a id="_idIndexMarker629"/> dropped in place<a id="_idIndexMarker630"/> and work as expected. The remaining roles in this section of the Playbook will reference the output of these roles when referring to subnets, security groups, and the VPC.</p>
<h3>The Application Elastic Load Balancer (ELB) role</h3>
<p>In this role, we will deploy<a id="_idIndexMarker631"/> two resources, the first <a id="_idIndexMarker632"/>of which is a target group. This will be used when we launch our auto-scaling virtual machine instances – we attach our instances to the target group. Then, the target group is attached to the Application Elastic Load Balancer, which we will also launch in this role.</p>
<p>The task itself is pretty static, as you can see from the code for the following task:</p>
<pre class="source-code">
- name: "Provision the target group"
  community.aws.elb_target_group:
    name: "{{ elb_target_group_name }}"
    region: "{{ region }}"
    state: "{{ state }}"
    protocol: "http"
    port: "80"
    deregistration_delay_timeout: "15"
    vpc_id: "{{ vpc_output.vpc.id }}"
    modify_targets: "false"
    tags:
      "Name": "{{ elb_target_group_name }}"
      "projectName": "{{ app.name }}"
      "environment": "{{ app.env }}"
      "deployedBy": "{{ playbook_dict.deployedBy }}"
      "description": "{{ playbook_dict.ansible_warning }}"
      "role": "target-group"
  register: elb_target_group_output</pre> <p>We are just referencing variables, with the only dynamic content being the ID of the VPC, which is referenced from the <code>vpc_output</code> variable we registered when launching the VPC in the VPC role.</p>
<p>As we are registering some<a id="_idIndexMarker633"/> output in this role, we will continue<a id="_idIndexMarker634"/> by adding a debug task straight after; in this case, the task looks like the following:</p>
<pre class="source-code">
- name: "Debug: ELB Target Group Output"
  ansible.builtin.debug:
    var: "elb_target_group_output"
  when: debug_output</pre> <p>As we have already covered in <a href="B21620_10.xhtml#_idTextAnchor458"><em class="italic">Chapter 10</em></a>, <em class="italic">Building Out a Cloud Network</em>, we will not be repeating these tasks in our overview of the Playbook unless we are doing something different – so, from now on, if we are registering an output, please assume that a debug task immediately follows.</p>
<p>There is one more bit of information we need before we create the ELB, and that’s the ID of the security group.</p>
<p>To get this, we can loop through the <code>security_groups_with_rules_output</code> variable and use <code>set_fact</code> to set the <code>group_id</code> when the <code>group_name</code> contains the contents of the <code>elb_seach_string</code> variable:</p>
<pre class="source-code">
- name: Extract ELB Group ID
  ansible.builtin.set_fact:
    elb_group_id: "{{ item.group_id }}"
  loop: "{{ security_groups_with_rules_output.results }}"
  when: item.group_name is search(elb_seach_string)</pre> <p>Whenever we need the ID of a security group, we will use this same pattern but update the name of the fact that is being set and the corresponding search steering variable.</p>
<p>The following task provisions<a id="_idIndexMarker635"/> the Application Elastic<a id="_idIndexMarker636"/> Load Balancer, which will be used to distribute HTTP requests across our auto-scaling managed virtual machine instances to serve our WordPress site:</p>
<pre class="source-code">
- name: "Provision an application elastic load balancer"
  amazon.aws.elb_application_lb:
    region: "{{ region }}"
    name: "{{ elb_name }}"
    state: "{{ state }}"
    security_groups: "{{ elb_group_id }}"
    subnets: "{{ subnet_public_ids }}"
    listeners:
      - Protocol: "HTTP"
        Port: "80"
        DefaultActions:
          - Type: "forward"
            TargetGroupArn: "{{ elb_target_group_output.target_group_arn }}"
    tags:
      "Name": "{{ elb_name }}"
      "projectName": "{{ app.name }}"
      "environment": "{{ app.env }}"
      "deployedBy": "{{ playbook_dict.deployedBy }}"
      "description": "{{ playbook_dict.ansible_warning }}"
      "role": "load-balancer"
  register: loadbalancer_output</pre> <p>As you can see, we are attaching the Application Elastic Load Balancer to the subnets defined listed in the <code>subnet_public_ids</code>, and we are attaching the security group with the ID defined in the <code>elb_group_id</code> fact that registered in the previous task.</p>
<p>We are then configuring a listener<a id="_idIndexMarker637"/> on port <code>80</code> to accept HTTP traffic and forward it to the Target Group we launched<a id="_idIndexMarker638"/> at the start of the role – which concludes the Application Elastic Load balancer role.</p>
<h3>The Elastic File System (EFS) role</h3>
<p>The role starts with<a id="_idIndexMarker639"/> the task<a id="_idIndexMarker640"/> which sets the <code>efs_group_id</code> using the <code>efs_seach_string</code> variable. Once we know the ID of the security group we are applying to the EFS service, we can move on to the next task.</p>
<p>This task generates a file using a template and places it in the <code>group_vars</code> folder:</p>
<pre class="source-code">
- name: "Generate the efs targets vars file"
  ansible.builtin.template:
    src: "targets.j2"
    dest: "group_vars/generated_efs_targets.yml"
    mode: "0644"</pre> <p>The template file used to populate the file at <code>group_vars/gene<a id="_idTextAnchor524"/>rated_efs_targets.yml</code> looks <a id="_idTextAnchor525"/>like the following:</p>
<pre class="source-code">
efs_targets:
{% for item in subnet_storage_ids %}
      - subnet_id: "{{ item }}"
        security_groups: [ "{{ efs_group_id }}" ]
{% endfor %}</pre> <p>Here, we are using a Jinja2 <code>for</code> loop<a id="_idIndexMarker641"/> to loop through the contents<a id="_idIndexMarker642"/> of <code>subnet_storage_ids</code>, which will creat<a id="_idTextAnchor526"/>e a file that looks something like the following:</p>
<pre class="source-code">
efs_targets:
      - subnet_id: "subnet0<a id="_idTextAnchor527"/>1_id"
        security_groups: [ "efs_group_id" ]
      - subnet_id: "subnet02_id"
        security_groups: [ "efs_group_id" ]
      - subnet_id: "subnet03_id"
        security_groups: [ "efs_group_id" ]</pre> <p>This means that when we create the EFS file system, it will be available across all the availability zones in our chosen region.</p>
<p>Well, it will be once we load in the contents of the file we have just loaded, which we do in the next task, as you can see here:</p>
<pre class="source-code">
- name: "Include the efs targets vars file"
  ansible.builtin.include_vars: "group_vars/generated_efs_targets.yml"</pre> <p>We now have everything in place to create the EFS file system, which is done using this task:</p>
<pre class="source-code">
- name: "Create the EFS File System"
  community.aws.efs:
    name: "{{ efs_name }}"
    region: "{{ region }}"
    state: "{{ state }}"
    tags:
      "Name": "{{ efs_name }}"
      "projectName": "{{ app.name }}"
      "environment": "{{ app.env }}"
      "deployedBy": "{{ playbook_dict.deployedBy }}"
      "description": "{{ playbook_dict.ansible_warning }}"
      "role": "efs"
    targets: "{{ efs_targets }}"
    wait: "{{ efs.wait }}"
    wait_timeout: "{{ efs.wait_time }}"
  register: efs_output</pre> <p>It can take a few minutes to create the file system, and we must wait until this task has succeeded before we continue, which is why we are using the wait flag. If we don’t wait, we increase the risk that the file system will not be ready by the time our virtual machine is launched and unable to mount it, which will cause the Playbook execution to fail.</p>
<p>Speaking of tasks that take a while, the next role<a id="_idIndexMarker643"/> deals with launching the Amazon RDS instance, which we will use as the database<a id="_idIndexMarker644"/> for our WordPress site. This task can take up to 10 minutes to complete.</p>
<h3>The Amazon RDS role</h3>
<p>There are two main parts to the role; the first<a id="_idIndexMarker645"/> does a similar task to the one we had to do in the previous role when we created the targets for the EFS to be attached to.</p>
<p>The RDS service differs in that rather than passing in the subnets manually when we deploy the service, we can create a group natively on the AWS side and then reference it when we launch the RDS instance.</p>
<p>The task to create the RDS subnet group looks like the following:</p>
<pre class="source-code">
- name: "Add RDS subnet group"
  amazon.aws.rds_subnet_group:
    name: "{{ rds_name }}"
    region: "{{ region }}"
    state: "{{ state }}"
    description: "{{ dict.ansible_warning }}"
    subnets: "{{ subnet_database_ids }}"
    tags:
      "Name": "{{ rds_name }}"
      "projectName": "{{ app.name }}"
      "environment": "{{ app.env }}"
      "deployedBy": "{{ playbook_dict.deployedBy }}"
      "description": "{{ playbook_dict.ansible_warning }}"
      "role": "rds"
  register: rds_subnet_group_output</pre> <p>Once we have created the subnet group, we need to find the security group ID using the <code>rds_seach_string</code> variable and set a fact called <code>rds_group_id</code>.</p>
<p>Now we have all the information we need to launch the RDS instance, the task for which looks like the following:</p>
<pre class="source-code">
- name: "Create the RDS instance"
  amazon.aws.rds_instance:
    id: "{{ rds_name }}"
    region: "{{ region }}"
    state: "{{ state }}"
    db_instance_class: "{{ rds.instance_type }}"
    engine: "{{ rds.engine }}"
    engine_version: "{{ rds.engine_version }}"
    allocated_storage: "{{ rds.allocated_storage }}"
    username: "{{ rds.db_username }}"
    password: "{{ rds.db_password }}"
    db_name: "{{ rds.db_name }}"
    db_subnet_group_name: "{{ rds_subnet_group_output.subnet_group.name }}"
    vpc_security_group_ids: ["{{ rds_group_id }}"]
    tags:
      "Name": "{{ rds_name }}"
      "projectName": "{{ app.name }}"
      "environment": "{{ app.env }}"
      "deployedBy": "{{ playbook_dict.deployedBy }}"
      "description": "{{ playbook_dict.ansible_warning }}"
      "role": "rds"
  register: rds_instance_output</pre> <p>As mentioned at the end of the previous task, this can take quite a while to deploy, typically <a id="_idIndexMarker646"/>just over 10 minutes, so when we run the Playbook, this task will appear to have stalled.</p>
<p>So please do not worry – it is busy working away in the background.</p>
<p>Once this role has finished<a id="_idIndexMarker647"/> running, we will have all the core AWS resources we need to launch an EC2 instance, perform <a id="_idTextAnchor528"/>the software configuration, and install WordPress.</p>
<h3>The temporary EC2 instance role</h3>
<p>Before we work through the tasks<a id="_idIndexMarker648"/> that launch the temporary instance, let’s go into a little more detail on why we need a temporary EC2 instance in the first place.</p>
<p>As we mentioned in the introduction, this instance will be running Ubuntu, and we will be targeting it with slightly modified copies of the <code>stack_install</code>, <code>stack_config</code>, and <code>wordpress</code> roles that we first ran locally in <a href="B21620_05.xhtml#_idTextAnchor253"><em class="italic">Chapter 5</em></a>, <em class="italic">Deploying WordPress</em>, and against a single cloud instance in <a href="B21620_09.xhtml#_idTextAnchor411"><em class="italic">Chapter 9</em></a>, <em class="italic">Moving to </em><em class="italic">the Cloud</em>.</p>
<p>One of the modifications we will be making to the roles is installing the software needed to mount our EFS, which we will then use to store the WordPress code and supporting files for our WordPress installation, meaning that we have everything we need file-wise for WordPress on a shared file system we can then mount on multiple virtual machine instances.</p>
<p>The second change is that rather than installing a database server on our local instance, we will be using the Amazon RDS database service for WordPress, meaning that we can have multiple instances of WordPress, all being able to connect to a single remote database.</p>
<p>Great, you may be thinking to yourself, but that doesn’t explain why this is a temporary instance.</p>
<p>Well, once everything has been installed, mounted, configured, and WordPress<a id="_idIndexMarker649"/> bootstrapped, we will be making our own <strong class="bold">Amazon Machine Image</strong> (<strong class="bold">AMI</strong>) and terminating the temporary EC2 instance. Once it’s been terminated, we will take the AMI and configure our Auto Scaling Group to use the newly created image, which will either trigger the deployment of new hosts if it is our first time running the Playbook or it will launch more instances and terminate the old ones if we have already had virtual machine instances running our WordPress installation.</p>
<p>When these virtual machine instances boot up using our custom AMI, they will already have NGINX and PHP installed and configured, ready to serve WordPress, and the EFS containing our WordPress files will be mounted, meaning that our servers will be good to go as soon as they are deployed.</p>
<p>All of this means our WordPress installation should be sound to scale up if we have an influx of traffic hitting the site for whatever reason, and all instances of our virtual machines will be running a known good configuration; in fact, it will be the same configuration as the other hosts serving our WordPress site.</p>
<p>Just as important, as we are not relying on anything on the local virtual machine instances filesystem, we are just as good at automatically scaling down by terminating hosts automatically when the influx of traffic has subsided without the risk of data loss or availability.</p>
<p>If this approach is planned right – in theory, we don’t even need SSH access to the hosts launched by the Auto Scaling Group as we should never need to manage them manually, and we can treat them as short-lived instances where we don’t have to care if they are running or terminated – just that we have the desired of instances delivering our application.</p>
<p>So, now that we know<a id="_idIndexMarker650"/> why we are taking this approach, let’s return to the Playbook and look at the tasks needed to get this temporary EC2 instance up and running to the point where we can SSH to it and install our software and WordPress.</p>
<p>The first task is to get a list of all the Ubuntu AMIs using the variables we covered earlier in the chapter:</p>
<pre class="source-code">
- name: "Gather information about AMIs with the specified filters"
  amazon.aws.ec2_ami_info:
    region: "{{ region }}"
    owners: "{{ ec2.ami.owners }}"
    filters:
      name: "{{ ec2.ami.filters.name }}"
      virtualization-type: "{{ ec2.ami.filters.virtualization_type }}"
  register: ubuntu_ami_info</pre> <p>The list of AMIs returned will contain all of the various AMI versions for our chosen Ubuntu version; we only need to know the ID of the latest version published by Canonical (the publisher and maintainer of Ubuntu) so we know we are using the most up-to-date image that contains the latest patches and any bug fixes.</p>
<p>Luckily, each AMI returned in the list has a key called <code>creation_date</code>, the value of which, as you may have guessed, is the date and time the AMI was published. This means we can run the following task to get the ID of the latest version of the AMI:</p>
<pre class="source-code">
- name: "Filter the list of AMIs to find the latest one"
  ansible.builtin.set_fact:
    ami: "{{ ubuntu_ami_info.images | sort(attribute='creation_date') | last }}"</pre> <p>As you can see, this takes the content of the list, which is defined as <code>ubuntu_ami_info.images</code>, sorts the list by <code>creation_date</code>, and then takes the ID of the <code>last</code> AMI in the list as, by default, they are sorted in ascending order.</p>
<p>Now that we know the ID of the most up-to-date Ubuntu AMI, we can progress with more preparation work before launching our EC2 instance.</p>
<p>We now need to create an SSH key pair<a id="_idIndexMarker651"/> on the AWS side. This will contain the public portion of the SSH key we will use to access the EC2 instance when it is launched – the task to configure this looks like the following and uses the variables we covered earlier in the chapter to get the contents of the public portion of our SSH key:</p>
<pre class="source-code">
- name: "Create a SSH Key Pair"
  amazon.aws.ec2_key:
    region: "{{ region }}"
    state: "{{ state }}"
    name: "{{ ec2.keypair.name }}"
    key_material: "{{ ec2.keypair.key_material }}"
    tags:
      "Name": "{{ ec2.keypair.name }}"
      "projectName": "{{ app.name }}"
      "environment": "{{ app.env }}"
      "deployedBy": "{{ playbook_dict.deployedBy }}"
      "description": "{{ playbook_dict.ansible_warning }}"
      "role": "ssh_keypair"
  register: keypair_output</pre> <p>Finally, before we launch our EC2 instance, we<a id="_idIndexMarker652"/> need the ID of the security group, which allows the public IP address of our host running Ansible SSH access to the EC2 instance. To do this, we set a fact called <code>ec2_group_id</code> using the <code>ec2_seach_string</code> variable to find the correct group ID.</p>
<p>Now, we have everything in place to launch the EC2 instance using the following task:</p>
<pre class="source-code">
- name: "Create the temporary ec2 instance"
  amazon.aws.ec2_instance:
    name: "{{ ec2_tmp_name }}"
    region: "{{ region }}"
    state: "{{ state }}"
    vpc_subnet_id: "{{ subnet_compute_ids[0] }}"
    instance_type: "{{ ec2.instance_type }}"
    security_group: "{{ ec2_group_id }}"
    key_name: "{{ ec2.keypair.name }}"
    network:
      assign_public_ip: "{{ ec2.public_ip }}"
    image_id: "{{ ami.image_id }}"
    tags:
      Name: "{{ ec2_tmp_name }}"
      Description: "{{ dict.ansible_warning }}"
      Project: "{{ app.name }}"
      Environment: "{{ app.env }}"
      Deployed_by: "Ansible"
      Role: "tmp"
  register: ec2_tmp_instance_output</pre> <p>The only thing pointed out in the preceding task is that when we add the value for the <code>vpc_subnet_id</code> we can only pass in a single ID. As we don’t need this virtual machine instance to be highly available, that is not a problem, so we are using the first ID in the list of subnet IDs by using the <code>{{ </code><code>subnet_compute_ids[0] }}</code>.</p>
<p>When launching an EC2 instance in AWS, it goes through a few stages and, by default, the <code>amazon.aws.ec2_instance</code> module creates the instance and doesn’t wait for the status to change from <em class="italic">creating</em> to <em class="italic">running</em>.</p>
<p>Our next task polls the AWS API<a id="_idIndexMarker653"/> waiting for the status of our EC2 instance to be <em class="italic">running</em>:</p>
<pre class="source-code">
- name: "Get information about the temporary EC2 instance to see if it is running"
  amazon.aws.ec2_instance_info:
    region: "{{ region }}"
    filters:
      instance-id: "{{ ec2_tmp_instance_output.instances[0].instance_id }}"
  register: ec2_tmp_instance_state
  delay: 5
  retries: 50
  until: ec2_tmp_instance_state.instances[0].state.name == "running"</pre> <p>As you can see, the previous task takes the ID of our newly created EC2 instance and polls the AWS API every <code>5</code> seconds, a maximum of <code>50</code> times, until the value of <code>ec2_tmp_instance_state.instances[0].state.name</code> is equal to <code>running</code>.</p>
<p>You might think to yourself<a id="_idIndexMarker654"/> that it seems a bit overkill to do that, and 99% of the time, you would be correct – it usually takes no more than a few checks for the status to change. Still, there is the odd occasion that AWS might be on a “go-slow,” and during testing, I have seen it take up to 15 checks, or just over a minute, for the status to change, so we need to take this delay into account in our Playbook as it could break the Playbook execution if we don’t.</p>
<p>The next task takes the details, the DNS name and IP address, of our now-running EC2 instance and adds them to the host group called <code>vmgroup</code>:</p>
<pre class="source-code">
- name: "Add the temporary EC2 instance to the vmgroup"
  ansible.builtin.add_host:
    name: "{{ ec2_tmp_instance_output.instances[0].public_dns_name }}"
    ansible_ssh_host: "{{ ec2_tmp_instance_output.instances[0].public_ip_address }}"
    groups: "vmgroup"</pre> <p>Before we hand off to the next role, we should perform one more check.</p>
<p>Sometimes, the Ansible Playbook works through the tasks so quickly that it is possible that even though our EC2 instance has a status of <em class="italic">running</em>, it does not mean that the host has finished booting, and SSH is started and is accessible:</p>
<pre class="source-code">
- name: "Wait for the temporary EC2 instance to be ready to accept SSH connections"
  ansible.builtin.wait_for:
    host: "{{ ec2_tmp_instance_output.instances[0].public_ip_address }}"
    port: "{{ ec2.ssh_port }}"
    delay: 10
    timeout: 300</pre> <p>Now that we have confirmation<a id="_idIndexMarker655"/> that our EC2 host is accessible to our machine running Ansible using SSH, we can proceed to the final role in this section of the <code>site.yml</code> file.</p>
<h3>The endpoints role</h3>
<p>This role has a single<a id="_idIndexMarker656"/> task, which creates a file at <code>generated_aws_endpoints.yml</code> containing the name of the AWS endpoints for the EFS, RDS, and ELB resources we have created:</p>
<pre class="source-code">
- name: "Generate the aws endpoints file"
  ansible.builtin.template:
    src: "endponts.j2"
    dest: "group_vars/generated_aws_endpoints.yml"
    mode: "0644"</pre> <p>The <code>endponts.j2</code> template file<a id="_idTextAnchor529"/> loo<a id="_idTextAnchor530"/>ks like the following:</p>
<pre class="source-code">
aws_endpoints:
  efs: "{{ efs_output.efs.filesystem_address.split(':')[0] }}"
  rds: "{{ rds_instance_output.endpoint.address }}"
  elb: "{{ loadbalancer_output.dns_name }}"</pre> <p>Both the RDS and ELB endpoints are straightforward enough; for the EFS, you might notice something at the end – what is that for?</p>
<p>None of the output that is registered under the <code>efs_output.efs</code> variable contains just the address of the EFS endpoint. The one we are using, <code>filesystem_address</code>, has information on the file system mount, which is represented by appending <code>:/</code> to the end of the DNS address we need.</p>
<p>To get around this, we are using the <code>split</code> function, passing <code>:</code> as the delimiter and then taking the first section, which is defined as <code>0</code>, meaning that we end up with everything before the <code>:</code>, which is the DNS name we are after.</p>
<p>Now that we have a populated <code>group_vars/generated_aws_endpoints.yml</code> file, we can load it into the second section of the <code>site.yml</code> file as a variable file, saving us from having to interact with the AWS from our EC2 instance.</p>
<p>So, now that we have our EC2 instance up and running, let’s get our software stack installed, configured, and WordPress bootstrapped.</p>
<h3>The stack install role</h3>
<p>The tasks in this role<a id="_idIndexMarker657"/> remain unchanged from the previous times we have executed the Playbook because all the changes we have made are in the <code>stack_packages</code> variable we are passing in.</p>
<p>As a reminder, this role does the following:</p>
<ul>
<li>Updates the APT cache and ensures that the installed packages are running the latest available versions – which shouldn’t be too many as we are using the newest AMI</li>
<li>Imports the APT keys for the additional repositories we will be ena<a id="_idTextAnchor531"/>bling</li>
<li>Installs the packages containing details of the additional r<a id="_idTextAnchor532"/>epositories and enables them</li>
<li>Installs<a id="_idTextAnchor533"/> the packages listed in the <code>system_packages</code>, <code>extra_packages</code>, and <code>stack_packages</code> variables – <code>system_packages</code> and <code>extra_packages</code> contain the default values we have been using throughout, and because we are passing the updated <code>stack_packages</code> variable via the <code>group_vars/common.yml</code> file, this overrides the default values from previous chapters which are still defined in the <code>roles/stack_install/defaults/main.yml</code> file</li>
</ul>
<p>This leaves us with all the base software we need to install on the EC2 instance.</p>
<h3>The stack configuration role</h3>
<p>Unlike the previous role, there are some<a id="_idIndexMarker658"/> amendments to this role, starting with additional tasks out of the gate.</p>
<p>Three tasks are added to the top of <code>roles/stack_config/tasks/main.yml</code>, the first of which is a continuation of the checks we did towards the en<a id="_idTextAnchor534"/>d of the roles in the last section of the <code>site.yml</code> file:</p>
<pre class="source-code">
- name: "Check that t<a id="_idTextAnchor535"/>he EFS volume is ready"
  ansible.builtin.wait_for:
    host: "{{ aws_endpoints.efs }}"
    port: "2049"
    delay: 10
    timeout: 300</pre> <p>As you can see, this checks that port <code>2049</code> is accessible at the endpoint defined in <code>aws_endpoints.efs</code>; the reason why this is there is that while the EFS service is ready, it may take a little while for the DNS records for the endpoint to be updated and accessible within the VPC. As we will soon attempt to mount the EFS filesystem, we must ensure it is accessible before proceeding.</p>
<p>The next task is to ensure that<a id="_idIndexMarker659"/> the RPC Bind service is up and running; we will need to mount the EFS file system:</p>
<pre class="source-code">
- name: "ensure rpcbind service is running"
  ansible.builtin.service:
    name: "rpcbind"
    state: "started"
    enabled: true</pre> <p>The final additional task mounts the EFS and ensures that it is added to the file system configuration to ensure that from now on, the EFS is mounted when the EC2 instance boots:</p>
<pre class="source-code">
- name: "mount the EFS volume"
  ansible.posix.mount:
    src: "{{ aws_endpoints.efs }}:/"
    path: "{{ nfs.mount_point }}"
    opts: "{{ nfs.mount_options }}"
    state: "{{ nfs.state }}"
    fstype: "{{ nfs.fstype }}"</pre> <p>As you will have already seen from when we covered the variables at the start of the chapter, we are mounting the EFS at <code>/var/www/</code>; we are making sure to do this before the following two tasks to ensure that our WordPress <code>users</code> home directory is created on the share.</p>
<p>These two tasks remain unchanged from the last time we installed WordPress, as does the value of <code>wordpress_system.home</code>, which is <code>/var/www/wordpress</code>.</p>
<p>So, now that we have created our WordPress user and group, we can proceed with the rest of the tasks:</p>
<ul>
<li>Update <code>/etc/nginx/nginx.conf</code> with some sensible defaults</li>
<li>Create the configuration for our default host at <code>/etc/nginx/conf.d/default.conf</code></li>
<li>Create the <code>/etc/nginx/global</code> directory and copy the <code>restrictions.conf</code> and <code>wordpress_shared.conf</code> files there</li>
</ul>
<p>The next task is more of a quality-of-life improvement to do with the way our Playbook deals with PHP, as this Playbook is designed to keep our WordPress installation up to date by taking the base Ubuntu image and bootstrapping from scratch each time rather than managing the configuration in place. It is possible that the version of PHP could change at some point during the life of our WordPress installation.</p>
<p>So far, whenever the <code>stack_config</code> role has been executed, it has been using the following variables:</p>
<pre class="source-code">
php_fpm_path: "/etc/php/8.1/fpm/pool.d/www.conf"
php_ini_path: "/etc/php/8.1/fpm/php.ini"
php_service_name: "php8.1-fpm"</pre> <p>As you can see, <code>8.1</code> is a hardcoded <a id="_idIndexMarker660"/>value. While we can overwrite these variables at the variable level elsewhere in our configuration, it would be better to work out which version of PHP is installed at runtime and reference that.</p>
<p>To do this<a id="_idTextAnchor536"/>, we can update these values as follows:</p>
<pre class="source-code">
php_fpm_p<a id="_idTextAnchor537"/>ath: "/etc/php/{{ php_version }}/fpm/pool.d/www.conf"
php_ini_path: "/etc/php/{{ php_version }}/fpm/php.ini"
php_service_name: "php{{ php_version }}-fpm"</pre> <p>This means we now must find a way to populate the <code>php_version</code> variable with the relevant version of PHP.</p>
<p>To do this, we can run the <code>php -v</code> command, which returns<a id="_idIndexMarker661"/> a lot of information on the version of PHP installed. We then use the <code>head</code> and a few <code>cut</code> commands on the Linux command line using the <code>ansible.builtin.shell</code> <a id="_idTextAnchor538"/>and not a built-in Ansible functi<a id="_idTextAnchor539"/>on:</p>
<pre class="source-code">
- name: "Get the PHP version"
  ansible.builtin.shell:
    <a id="_idTextAnchor540"/>cmd: "php -v | head -n 1 | cut -d ' ' -f 2 | cut -c 1-3"
  register: php_version_output</pre> <p>Here is a detailed breakdown of the command we are getting Ansible to run:</p>
<ul>
<li><code>php -v</code>: This command, when run, outputs the version information of the PHP installed on the host the command is being executed on; this output is typically a multi-line text that includes the PHP version along with additional information on how the version of the PHP was compiled.</li>
<li><code>|</code>: This symbol is known as a pipe. It takes<a id="_idIndexMarker662"/> the command output on its left (in this case, <code>php -v</code>) and uses it as the input for the command on its right. It’s a way of passing data between programs.</li>
<li><code>head -n 1</code>: This command processes the input received from the previous command; the head command outputs the first part of the files or data it receives. <code>-n 1</code> is an option that tells <code>head</code> to output only the first line. So, in our case, <code>head -n 1</code> takes the multiple lines of output from <code>php -v</code> and returns just the very first line.</li>
<li><code>|</code>: Another pipe, which again passes the command output on its left, <code>head -n 1</code>, to the command on its right.</li>
<li><code>cut -d ' ' -f 2</code>: This command is used for cutting out sections of each input line. <code>-d ' '</code> is an option where <code>-d</code> stands for the delimiter, and <code>' '</code> (a space) is the delimiter being used. This tells cut to divide each line into sections based on spaces. <code>-f 2</code> means <em class="italic">field 2</em>. This option tells the <code>cut</code> command to select the second field of the line in the standard format of the PHP version output; this field should be the version number.</li>
<li><code>|</code>: Again, we have another pipe, passing the output, now just the version number, to the following command.</li>
<li><code>cut -c 1-3</code>: This further processes the version number. <code>-c 1-3</code> tells <code>cut</code> to return only the characters in positions <code>1</code> through <code>3</code> of the string it receives. For a typical PHP version such as <code>8.2.1</code>, this would result in <code>8.2</code>, which is precisely what we need to proceed with the rest of our tasks.</li>
</ul>
<p>We can then take the output and register it as <code>php_version_output</code>, and set the <code>php_version</code> variable as a fact:</p>
<pre class="source-code">
- name: "Set the PHP version"
  ansible.builtin.set_fact:
    php_version: "{{ php_version_output.stdout }}"</pre> <p>Now that we have the PHP version, we can proceed with the remainder of the PHP tasks, which copy the <code>www.conf</code> file to <code>/etc/php/{{ php_version }}/fpm/pool.d/www.conf</code> and also update the <code>PHP.ini</code> file at <code>/etc/php/{{ </code><code>php_version }}/fpm/php.ini</code>.</p>
<p>With those files in place, we start the PHP-FPM and NGINX services, ensuring that they are set to start on boot.</p>
<p>The final task in the role is to create the <code>~/.my.cnf</code> file and populate it with the information of our Amazon RDS instance. All of the other MariaDB tasks, which are there to start and configure our local MariaDB<a id="_idIndexMarker663"/> server, are commented out as we no longer install a local database server, so we don’t need to run the tasks to configure it.</p>
<h3>The WordPress role</h3>
<p>There are just two tasks commented<a id="_idIndexMarker664"/> out in this role. The tasks that create the database and the database user are not needed because when the Amazon RDS instance started, the database and user were made for us, meaning these two tasks are redundant.</p>
<p>All other tasks remain; for more details, see <a href="B21620_05.xhtml#_idTextAnchor253"><em class="italic">Chapter 5</em></a>, <em class="italic">Deploying WordPress</em>.</p>
<h3>The EC2 AMI role</h3>
<p>Now that our software<a id="_idIndexMarker665"/> stack is installed and configured and WordPress is sorted, it is time to create the AMI from our temporary instance.</p>
<p>The first thing we need to do is get the details on our temporary EC2 instance; as our host group contains the DNS name of the instance, we can use this:</p>
<pre class="source-code">
- name: "Find out some facts about the instance we have been using"
  amazon.aws.ec2_instance_info:
    region: "{{ region }}"
    filters:
      dns-name: "{{ groups['vmgroup'] }}"
  register: our_instance</pre> <p>Now that we have the information on the instance we would like to create the AMI from registered as <code>our_instance</code>, we can proceed with the AMI creation:</p>
<pre class="source-code">
- name: "Create the AMI"
  amazon.aws.ec2_ami:
    region: "{{ region }}"
    state: "{{ state }}"
    instance_id: "{{ our_instance.instances[0].instance_id }}"
    wait: "yes"
    name: "{{ ami_name }}-{{ ansible_date_time.date }}_{{ ansible_date_time.hour }}{{ ansible_date_time.minute }}"
    tags:
      "Name": "{{ ami_name }}-{{ ansible_date_time.date }}_{{ ansible_date_time.hour }}{{ ansible_date_time.minute }}"
      "buildDate": "{{ ansible_date_time.date }} {{ ansible_date_time.time }}"
      "projectName": "{{ app.name }}"
      "environment": "{{ app.env }}"
      "deployedBy": "{{ playbook_dict.deployedBy }}"
      "description": "{{ playbook_dict.ansible_warning }}"
      "role": "{{ playbook_dict.ami }}"
  register: ami_output</pre> <p>There are just a few things to point out here. As you can see, we are using <code>ansible_date_time</code> to generate the <code>date</code> and get the current time as an <code>hour</code> and <code>minute</code>. We are using this both to give a unique name for the AMI and add a tag called <code>buildDate</code>.</p>
<p>The reason why we are using both<a id="_idIndexMarker666"/> the date and time is that it could be possible that we will need to create multiple AMIs on a single day, so it is important that we can <a id="_idTextAnchor541"/>easily identify them by name.</p>
<p>Once the AMI is created, we do not need the temporary instance, so we can terminate it:</p>
<pre class="source-code">
- name: "Remove any temporary  instances which are running"
  amazon.aws.ec2_instance:
    region: "{{ region }}"
    state: "absent"
    name: "{{ ec2_tmp_name }}"
    filters:
      instance-state-name: "running"
      "tag:Name": "{{ ec2_tmp_name }}"
      "tag:Role": "tmp"
      "tag:Project": "{{ app.name }}"</pre> <p>Once the EC2 instance has been terminated, there is one more task in the role:</p>
<pre class="source-code">
- name: "Wait for 2 minutes before continuing"
  ansible.builtin.pause:
    minutes: 2</pre> <p>This does exactly what it says: it pauses the Playbook execution for 2 minutes.</p>
<p>I have included this because there was the odd occasion where the AMI was created and shown as available. Still, for some reason, it takes a short while for it to appear in the results when we query<a id="_idIndexMarker667"/> the Amazon API to find our AMIs, so rather than introduce a potential error when the next role starts, I have found it best to wait a minute or two.</p>
<h3>The auto-scaling role</h3>
<p>We have arrived at the final role<a id="_idIndexMarker668"/> of the Playbook; in this role, we will create all the resources needed to deploy EC2 instances using our newly created AMI and register them with the ELB to access our WordPress site.</p>
<p>The first thing we need to do is grab a list of all our AMIs from the API:</p>
<pre class="source-code">
- name: "Search for all of our AMIs"
  amazon.aws.ec2_ami_info:
    region: "{{ region }}"
    filters:
      name: "{{ ami_name }}-*"
  register: ami_find</pre> <p>Now that we have a list of AMIs, we need to filter out the most recent one. To do this, we use the same logic that we used when launching the temporary EC2 instance:</p>
<pre class="source-code">
- name: "Find the last one we built"
  ansible.builtin.set_fact:
    ami_sort_filter: "{{ ami_find.images | sort(attribute='creation_date') | last }}"</pre> <p>Now that we have filtered our list of AMIs down to the latest one, we need to set two facts, one for the name of the AMI and the other containing the ID of the AMI:</p>
<pre class="source-code">
- name: "Grab AMI ID and name of the most recent result"
  ansible.builtin.set_fact:
    our_ami_id: "{{ ami_sort_filter.image_id }}"
    our_ami_name: "{{ ami_sort_filter.name }}"</pre> <p>The final bit of information we need before we start creating/updating resources is the ID of the security group we are using for the EC2 instances.</p>
<p>As before, we use the <code>ec2_seach_string</code> variable to find the correct group ID and set a fact called <code>ec2_group_id</code>.</p>
<p>Next up, we need to create<a id="_idIndexMarker669"/> or update a launch template if one already exists.</p>
<p>A launch template contains the basic configuration for the instances we will be launching in the auto-scaling group:</p>
<pre class="source-code">
- name: "Create the launch template"
  community.aws.ec2_launch_template:
    region: "{{ region }}"
    state: "{{ state }}"
    name: "{{ launch_template_name }}"
    version_description: "{{ our_ami_name }}"
    image_id: "{{ our_ami_id }}"
    security_group_ids: ["{{ ec2_group_id.security_groups[0].group_id }}"]
    instance_type: "{{ ec2.instance_type }}"
    disable_api_termination: "{{ ec2.asg.disable_api_termination }}"
    tags:
      "Name": "{{ ec2_name }}"
      "projectName": "{{ app.name }}"
      "environment": "{{ app.env }}"
      "deployedBy": "{{ playbook_dict.deployedBy }}"
      "description": "{{ playbook_dict.ansible_warning }}"
      "role": "launchTemplate"</pre> <p>With this task, we create the launch template and then publish a version called after the name of our AMI so that we can quickly identify it; we then attach the corresponding AMI ID and security group ID and set the spec of the instances we want to launch.</p>
<p>With the launch template<a id="_idIndexMarker670"/> in place, we need to gather a few more bits of information from the AWS API before creating the auto-scaling group.</p>
<p>First, we need the ID of the target group that we created in the ELB role:</p>
<pre class="source-code">
- name: "Find out the target group ARN"
  community.aws.elb_target_group_info:
    region: "{{ region }}"
    names:
      - "{{ elb_target_group_name }}"
  register: elb_target_group_output</pre> <p>We then need the IDs of the subnets where we are going to be deploying the EC2 instances launched as part of auto-scaling group, the following task gathers information on the subnets:</p>
<pre class="source-code">
- name: "Get information on the ec2 subnets"
  amazon.aws.ec2_vpc_subnet_info:
    region: "{{ region }}"
    filters:
      tag:role: "*{{ subnet_role_compute }}*"
  register: ec2_subnet_output</pre> <p>Now that we have the information on the subnets, we need to extract just the IDs of each of the subnets and create a list:</p>
<pre class="source-code">
- name: "Create a list of subnet IDs"
  ansible.builtin.set_fact:
    subnet_ec2_ids: "{{ subnet_ec2_ids | default([]) + [item.subnet_id] }}"
  loop: "{{ ec2_subnet_output.subnets }}"</pre> <p>This is the final bit of information<a id="_idIndexMarker671"/> we need, and we can now proceed with creating or updating the auto-scaling group:</p>
<pre class="source-code">
- name: "Create/update the auto-scaling group using the launch template we just created"
  amazon.aws.autoscaling_group:
    region: "{{ region }}"
    state: "{{ state }}"
    name: "{{ asg_name }}"
    target_group_arns: ["{{ elb_target_group_output.target_groups[0].target_group_arn }}"]
    launch_template:
      launch_template_name: "{{ launch_template_name }}"
    min_size: "{{ ec2.asg.min_size }}"
    max_size: "{{ ec2.asg.max_size }}"
    desired_capacity: "{{ ec2.asg.desired_capacity }}"
    health_check_period: "{{ ec2.asg.health_check_period }}"
    health_check_type: "{{ ec2.asg.health_check_type }}"
    replace_all_instances: "{{ ec2.asg.replace_all_instances }}"
    replace_batch_size: "{{ ec2.asg.replace_batch_size }}"
    vpc_zone_identifier: "{{ subnet_ec2_ids }}"
    wait_for_instances: "{{ ec2.asg.wait_for_instances }}"
    wait_timeout: "{{ ec2.asg.wait_timeout }}"
    tags:
      - key: "Name"
        value: "{{ ec2_name }}"
        propagate_at_launch: true
      - key: "Project"
        value: "{{ app.name }}"
        propagate_at_launch: true
      - key: "Environment"
        value: "{{ app.env }}"
        propagate_at_launch: true
      - key: "Deployed_by"
        value: "Ansible"
        propagate_at_launch: true
  register: ec2_asg_output</pre> <p>There is quite a lot happening in this, the final resource we will be launching, so let’s go into more detail.</p>
<p>First, we have the basic configuration<a id="_idIndexMarker672"/> standard across most of the AWS-related modules we have called throughout this Playbook; here, we are setting the name, region, and state of the resource, which will be <code>present</code> for this playbook.</p>
<p>Next up, we<a id="_idIndexMarker673"/> must provide the Target Group <code>target_group_arns</code> key specifies the ARNs of the target groups for the load balancer, which we set to the first target group ARN from <code>elb_target_group_output</code> and then the <code>launch_template</code> key references the launch template by its name, set to the value of <code>launch_template_name</code>.</p>
<p>Now we have the size and capacity settings; the <code>min_size</code>, <code>max_size</code>, and <code>desired_capacity</code> keys are set using <code>ec2.asg.min_size</code>, <code>ec2.asg.max_size</code>, and <code>ec2.asg.desired_capacity</code> variables, which define the auto-scaling group’s minimum, maximum, and desired number of instances.</p>
<p>We then have the health check configuration, setting the <code>health_check_period</code> and <code>health_check_type</code> keys to control how the health<a id="_idIndexMarker674"/> of the instances in the <strong class="bold">auto scaling group</strong> (<strong class="bold">ASG</strong>) is checked.</p>
<p>Now we have the Instance Replacement Settings. The <code>replace_all_instances</code> and <code>replace_batch_size</code> keys instruct whether all instances should be replaced and provide the batch size for replacing instances, respectively.</p>
<p>Then, we have the Network Configuration, setting <code>vpc_zone_identifier</code> to use the list of subnet IDs stored in <code>subnet_ec2_ids</code> to distribute the instances in the ASG across those subnets and availability zones.</p>
<p>Next up are the Wait Settings, which control whether the task should wait for the instances to have a status of <code>running</code> and the maximum time to wait for that condition to be met.</p>
<p>Finally, you will have noticed that we are tagging in a pretty different way than we have been doing throughout the rest of the Playbook; the task defines several tags (<code>Name</code>, <code>Project</code>, <code>Environment</code>, and <code>Deployed_by</code>) with respective values, all marked to propagate at launch, which means that the EC2 instances launched by the auto-scaling group will each inherit these tags when they are launched.</p>
<p>This concludes our walk-through<a id="_idIndexMarker675"/> of the Playbook. As you will have seen, we extended our original AWS networking Playbook from <a href="B21620_10.xhtml#_idTextAnchor458"><em class="italic">Chapter 10</em></a>, <em class="italic">Building Out a Cloud Network</em>, to encompass more services as well as integrating our WordPress roles from the Playbook we covered in <a href="B21620_05.xhtml#_idTextAnchor253"><em class="italic">Chapter 5</em></a>, <em class="italic">Deploying WordPress</em> – all that is left now is run the playbook.</p>
<h1 id="_idParaDest-174"><a id="_idTextAnchor542"/>Running the Playbook</h1>
<p>Now that we have all the roles<a id="_idIndexMarker676"/> needed to deploy our resources into AWS, we can run the playbook. To start with, we need to let Ansible know our access key and secret by running the foll<a id="_idTextAnchor543"/>owing commands with your own credentials to se<a id="_idTextAnchor544"/>t the environment variables:</p>
<pre class="console">
$ export AWS_ACCESS_KEY=AKIAI5KECPOTNTTVM3EDA
$ export AWS_SECRET_KEY=Y4B7FFiSWl0Am3VIFc07lgnc/TAtK5+RpxzIGTr</pre> <p>With environment variables set, you kick off the Ansible run by using the following command:</p>
<pre class="console">
$ ansible-playbook -i hosts site.yml</pre> <p>Unlike previous chapters, where we just looked at the end of the playbook run, here we will look at some highlights of what happens when we deploy our resources.</p>
<h2 id="_idParaDest-175"><a id="_idTextAnchor545"/>Playbook run highlights</h2>
<p>This is not the complete<a id="_idIndexMarker677"/> playbook output, and when running the playbook, I have not enabled debug, so all those tasks will be skipped.</p>
<p>We start with the VPC:</p>
<pre class="source-code">
PLAY [Deploy and configure the AWS Environment] ***********
TASK [Gathering Facts] ************************************
ok: [localhost]
TASK [roles/vpc : Create VPC] *****************************
changed: [localhost]</pre> <p>We now have somewhere to put the subnets once we have gathered some information on the availability zones in our chosen region:</p>
<pre class="source-code">
TASK [roles/subnets : Get some information on the available zones] *************
ok: [localhost]</pre> <p>Once we have that information, it will loop through and include the <code>create_subnet.yml</code> tasks:</p>
<pre class="source-code">
TASK [roles/subnets : Create all subnets] *****************
included: create_subnet.yml for localhost =&gt; (item={'name': 'ec2', 'role': 'compute'})
included: create_subnet.yml for localhost =&gt; (item={'name': 'rds', 'role': 'database'})
included: create_subnet.yml for localhost =&gt; (item={'name': 'efs', 'role': 'storage'})
included: create_subnet.yml for localhost =&gt; (item={'name': 'dmz', 'role': 'public'})</pre> <p>We then get the results of each<a id="_idIndexMarker678"/> of the four included task runs, the first of which looks like the following:</p>
<pre class="source-code">
TASK [roles/subnets : Create subnet in the availability zone] *****************************************************
changed: [localhost] =&gt; (item={'state': 'available', 'opt_in_status': 'opt-in-not-required', 'messages': [], 'region_name': 'eu-west-1', 'zone_name': 'eu-west-1a', 'zone_id': 'euw1-az1', 'group_name': 'eu-west-1', 'network_border_group': 'eu-west-1', 'zone_type': 'availability-zone'})
changed: [localhost] =&gt; (item={'state': 'available', 'opt_in_status': 'opt-in-not-required', 'messages': [], 'region_name': 'eu-west-1', 'zone_name': 'eu-west-1b', 'zone_id': 'euw1-az2', 'group_name': 'eu-west-1', 'network_border_group': 'eu-west-1', 'zone_type': 'availability-zone'})
changed: [localhost] =&gt; (item={'state': 'available', 'opt_in_status': 'opt-in-not-required', 'messages': [], 'region_name': 'eu-west-1', 'zone_name': 'eu-west-1c', 'zone_id': 'euw1-az3', 'group_name': 'eu-west-1', 'network_border_group': 'eu-west-1', 'zone_type': 'availability-zone'})</pre> <p>As you can see, a subnet is created for each of the zones in the <code>eu-west-1</code> region – this is then repeated three more times. Once the subnets have all been added, we grab more information on what has been created.</p>
<p>Next, the Internet Gateway role is run:</p>
<pre class="source-code">
TASK [roles/gateway : Create an Internet Gateway] *********
changed: [localhost]
TASK [roles/gateway : Create a route table so the internet gateway can be used by the public subnets] ****************
changed: [localhost]</pre> <p>As you may have remembered, there isn’t much happening<a id="_idIndexMarker679"/> in that role, unlike the next one, which adds the network security groups, where we start by getting your current public IP address:</p>
<pre class="source-code">
TASK [roles/securitygroups : Find out your current public IP address using https://ipify.org/] **********************
ok: [localhost]
TASK [roles/securitygroups : Set your public ip as a fact]*
ok: [localhost]</pre> <p>As you may recall, we create the two groups in two parts – first, we create the base groups:</p>
<pre class="source-code">
TASK [roles/securitygroups : Create the base security groups] ***************************************************
changed: [localhost] =&gt; (item={'name': 'learnansible-elb-security-group', 'description': 'opens port 80 and 443 to the world', 'id_var_name': 'elb_group_id', 'rules': [{'proto': 'tcp', 'from_port': '80', 'to_port': '80', 'cidr_ip': '0.0.0.0/0', 'rule_desc': 'allow all on port 80'}, {'proto': 'tcp', 'from_port': '443', 'to_port': '443', 'cidr_ip': '0.0.0.0/0', 'rule_desc': 'allow all on port 443'}]})
changed: [localhost] =&gt; (item={'name': 'learnansible-ec2-security-group', 'description': 'opens port 22 to a trusted IP and port 80 to the elb group', 'id_var_name': 'ec2_group_id', 'rules': [{'proto': 'tcp', 'from_port': '22', 'to_port': '22', 'cidr_ip': '86.177.22.88/32', 'rule_desc': 'allow 86.177.22.88/32 access to port 22'}, {'proto': 'tcp', 'from_port': '80', 'to_port': '80', 'group_id': '', 'rule_desc': 'allow access to port 80 from ELB'}]})
changed: [localhost] =&gt; (item={'name': 'learnansible-rds-security-group', 'description': 'opens port 3306 to the ec2 instances', 'id_var_name': 'rds_group_id', 'rules': [{'proto': 'tcp', 'from_port': '3306', 'to_port': '3306', 'group_id': '', 'rule_desc': 'allow  access to port 3306'}]})
changed: [localhost] =&gt; (item={'name': 'learnansible-efs-security-group', 'description': 'opens port 2049 to the ec2 instances', 'id_var_name': 'efs_group_id', 'rules': [{'proto': 'tcp', 'from_port': '2049', 'to_port': '2049', 'group_id': '', 'rule_desc': 'allow  access to port 2049'}]})</pre> <p>Then we get information<a id="_idIndexMarker680"/> on the bases we have just launched and set them as facts:</p>
<pre class="source-code">
TASK [roles/securitygroups : Set the fact for the security group ids] ************************************************
ok: [localhost] =&gt; (item={'name': 'learnansible-elb-security-group', 'description': 'opens port 80 and 443 to the world', 'id_var_name': 'elb_group_id', 'rules': [{'proto': 'tcp', 'from_port': '80', 'to_port': '80', 'cidr_ip': '0.0.0.0/0', 'rule_desc': 'allow all on port 80'}, {'proto': 'tcp', 'from_port': '443', 'to_port': '443', 'cidr_ip': '0.0.0.0/0', 'rule_desc': 'allow all on port 443'}]})
ok: [localhost] =&gt; (item={'name': 'learnansible-ec2-security-group', 'description': 'opens port 22 to a trusted IP and port 80 to the elb group', 'id_var_name': 'ec2_group_id', 'rules': [{'proto': 'tcp', 'from_port': '22', 'to_port': '22', 'cidr_ip': '86.177.22.88/32', 'rule_desc': 'allow 86.177.22.88/32 access to port 22'}, {'proto': 'tcp', 'from_port': '80', 'to_port': '80', 'group_id': '', 'rule_desc': 'allow access to port 80 from ELB'}]})
ok: [localhost] =&gt; (item={'name': 'learnansible-rds-security-group', 'description': 'opens port 3306 to the ec2 instances', 'id_var_name': 'rds_group_id', 'rules': [{'proto': 'tcp', 'from_port': '3306', 'to_port': '3306', 'group_id': '', 'rule_desc': 'allow  access to port 3306'}]})
ok: [localhost] =&gt; (item={'name': 'learnansible-efs-security-group', 'description': 'opens port 2049 to the ec2 instances', 'id_var_name': 'efs_group_id', 'rules': [{'proto': 'tcp', 'from_port': '2049', 'to_port': '2049', 'group_id': '', 'rule_desc': 'allow  access to port 2049'}]})</pre> <p>Lastly, we then add the rules; you will notice<a id="_idIndexMarker681"/> from the output that we are passing in the IDs of the groups we have created so that we can use them as part of the rules:</p>
<pre class="source-code">
TASK [roles/securitygroups : Provision security group rules] ****************************************************
changed: [localhost] =&gt; (item={'name': 'learnansible-elb-security-group', 'description': 'opens port 80 and 443 to the world', 'id_var_name': 'elb_group_id', 'rules': [{'proto': 'tcp', 'from_port': '80', 'to_port': '80', 'cidr_ip': '0.0.0.0/0', 'rule_desc': 'allow all on port 80'}, {'proto': 'tcp', 'from_port': '443', 'to_port': '443', 'cidr_ip': '0.0.0.0/0', 'rule_desc': 'allow all on port 443'}]})
changed: [localhost] =&gt; (item={'name': 'learnansible-ec2-security-group', 'description': 'opens port 22 to a trusted IP and port 80 to the elb group', 'id_var_name': 'ec2_group_id', 'rules': [{'proto': 'tcp', 'from_port': '22', 'to_port': '22', 'cidr_ip': '86.177.22.88/32', 'rule_desc': 'allow 86.177.22.88/32 access to port 22'}, {'proto': 'tcp', 'from_port': '80', 'to_port': '80', 'group_id': 'sg-04f31e782e30e1f0a', 'rule_desc': 'allow access to port 80 from ELB'}]})
changed: [localhost] =&gt; (item={'name': 'learnansible-rds-security-group', 'description': 'opens port 3306 to the ec2 instances', 'id_var_name': 'rds_group_id', 'rules': [{'proto': 'tcp', 'from_port': '3306', 'to_port': '3306', 'group_id': 'sg-05bffd3eb96602519', 'rule_desc': 'allow sg-05bffd3eb96602519 access to port 3306'}]})
changed: [localhost] =&gt; (item={'name': 'learnansible-efs-security-group', 'description': 'opens port 2049 to the ec2 instances', 'id_var_name': 'efs_group_id', 'rules': [{'proto': 'tcp', 'from_port': '2049', 'to_port': '2049', 'group_id': 'sg-05bffd3eb96602519', 'rule_desc': 'allow sg-05bffd3eb96602519 access to port 2049'}]})</pre> <p>Now, with the rules configured, we can start deploying<a id="_idIndexMarker682"/> some resources that use them, starting with the Target Group and ELB:</p>
<pre class="source-code">
TASK [roles/elb : Provision the target group] *************
changed: [localhost]
TASK [roles/elb : Provision an application elastic load balancer] *************************************************
changed: [localhost]</pre> <p>Then EFS:</p>
<pre class="source-code">
TASK [roles/efs : Generate the efs targets vars file] *****
changed: [localhost]
TASK [roles/efs : Include the efs targets vars file] ******
ok: [localhost]
TASK [roles/efs : Create the EFS File System] *************
changed: [localhost]</pre> <p>Now RDS:</p>
<pre class="source-code">
TASK [roles/rds : Add RDS subnet group] *******************
changed: [localhost]
TASK [roles/rds : Create the RDS instance] ****************
changed: [localhost]</pre> <p>Now it is time to create the temporary EC2 instance. First, we find the AMI to use:</p>
<pre class="source-code">
TASK [roles/ec2tmp : Gather information about AMIs with the specified filters] ****************************************
ok: [localhost]
TASK [roles/ec2tmp : filter the list of AMIs to find the latest one] ***********************************************
ok: [localhost]</pre> <p>Then, we create the SSH<a id="_idIndexMarker683"/> key pair:</p>
<pre class="source-code">
TASK [roles/ec2tmp : Create an SSH Key Pair] **************
changed: [localhost]</pre> <p>Then, we create the EC2 instance itself:</p>
<pre class="source-code">
TASK [roles/ec2tmp : Create the temporary ec2 instance] ***
changed: [localhost]</pre> <p>With the instance configured, we need to wait for it to have a status of <strong class="bold">running</strong>:</p>
<pre class="source-code">
TASK [roles/ec2tmp : Get information about the temporary EC2 instance to see if it is running] ***
FAILED - RETRYING: [localhost]: Get information about the temporary EC2 instance to see if it is running (50 retries left).
. . . .
FAILED - RETRYING: [localhost]: Get information about the temporary EC2 instance to see if it is running (46 retries left).
ok: [localhost]</pre> <p>Now that the instance is running, we add the newly launching EC2 instance to our host group:</p>
<pre class="source-code">
TASK [roles/ec2tmp : Add the temporary EC2 instance to the vmgroup] **************************************************
changed: [localhost]
TASK [roles/ec2tmp : Wait for the temporary EC2 instance to be ready to accept SSH connections] ***********************
ok: [localhost]</pre> <p>Before we move on to connecting to the EC2 host to install and configure the software stack and WordPress, we generate the endpoints variables file:</p>
<pre class="source-code">
TASK [roles/endpoints : Generate the aws endpoints file] **
changed: [localhost]</pre> <p>That concludes the first section<a id="_idIndexMarker684"/> of the <code>site.yml</code> file, and we can now SSH into the temporary EC2 host and install everything:</p>
<pre class="source-code">
PLAY [Install and configure Wordpress] ********************
TASK [Gathering Facts] ************************************
ok: [ec2-18-203-221-2.eu-west-1.compute.amazonaws.com]</pre> <p>We then progress with the installation, which, as we have already discussed, is pretty much the same set of tasks that we covered <em class="italic">in </em><a href="B21620_05.xhtml#_idTextAnchor253"><em class="italic">Chapter 5</em></a>, <em class="italic">Deploying WordPress</em>, and <a href="B21620_09.xhtml#_idTextAnchor411"><em class="italic">Chapter 9</em></a>, <em class="italic">Moving to the Cloud</em> – except for these tasks, which mount the EFS file system:</p>
<pre class="source-code">
TASK [roles/stack_config : Check that the EFS volume is ready] ****************************************************
ok: [ec2-18-203-221-2.eu-west-1.compute.amazonaws.com]
TASK [roles/stack_config : ensure rpcbind service is running] **************************************************
ok: [ec2-18-203-221-2.eu-west-1.compute.amazonaws.com]
TASK [roles/stack_config : mount the EFS volume] **********
changed: [ec2-18-203-221-2.eu-west-1.compute.amazonaws.com]</pre> <p>These tasks get the PHP version and set it as a fact:</p>
<pre class="source-code">
TASK [roles/stack_config : Get the PHP version] ***********
changed: [ec2-18-203-221-2.eu-west-1.compute.amazonaws.com]
TASK [roles/stack_config : Set the PHP version] ***********
ok: [ec2-18-203-221-2.eu-west-1.compute.amazonaws.com]</pre> <p>Once that is complete, NGINX and PHP-FPM are restarted:</p>
<pre class="source-code">
RUNNING HANDLER [roles/stack_config : restart nginx] ******
changed: [ec2-18-203-221-2.eu-west-1.compute.amazonaws.com]
RUNNING HANDLER [roles/stack_config : restart php-fpm] ****
changed: [ec<a id="_idTextAnchor546"/>2-18-203-221-2.eu-west-1.compute.amazonaws.com]</pre> <p>This concludes the tasks<a id="_idIndexMarker685"/> that bootstrap our temporary EC2 instance. We can now move back to our local machine and run the final section of the <code>sites.yml</code> file.</p>
<p>First, we create the AMI and terminate the temporary EC2 instance:</p>
<pre class="source-code">
TASK [roles/ec2ami : find out some facts about the instance we have been using] ***************************************
ok: [localhost]
TASK [roles/ec2ami : create the AMI] **********************
changed: [localhost]
TASK [roles/ec2ami : remove any temporary instances which are running] **********************************************
changed: [localhost]</pre> <p>Then, we wait for two minutes:</p>
<pre class="source-code">
TASK [roles/ec2ami : wait for 2 minutes before continuing]
Pausing for 120 seconds
(ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
ok: [localhost]</pre> <p>Now, we grab the details of the AMI we just created:</p>
<pre class="source-code">
TASK [roles/autoscaling : Search for all of our AMIs] *****
ok: [localhost]
TASK [roles/autoscaling : Find the last one we built] *****
ok: [localhost]
TASK [roles/autoscaling : Grab AMI ID and name of the most recent result] ********************************************
ok: [localhost]</pre> <p>Once we have those details, we create (or if we have already run the playbook, update) the Launch Template:</p>
<pre class="source-code">
TASK [roles/autoscaling : Create the launch template] <a id="_idTextAnchor547"/>*****
changed: [localhost]</pre> <p>Now, we gather the information needed for us to create/update the Auto Scaling Group:</p>
<pre class="source-code">
TASK [roles/autoscaling : find out the target group ARN] **
ok: [localhost]
TASK [roles/autoscaling : get information on the ec2 subnets] **************************************************
ok: [localhost]</pre> <p>Then we create the list of subnets<a id="_idIndexMarker686"/> the Auto Scaling Group will use:</p>
<pre class="source-code">
TASK [roles/autoscaling : create a list of subnet IDs] ****
ok: [localhost] =&gt; (item={'availability_zone': 'eu-west-1c', 'availability_zone_id': 'euw1-az3', 'available_ip_address_count': 27, 'cidr_block': '10.0.0.64/27', 'default_for_az': False, 'map_public_ip_on_launch': False, 'map_customer_owned_ip_on_launch': False, 'state': 'available', 'subnet_id': 'subnet-091ea1834c5fc8e48', 'vpc_id': 'vpc-008808ff628883751', 'owner_id': '687011238589', 'assign_ipv6_address_on_creation': False, 'ipv6_cidr_block_association_set': [], 'tags': {'role': 'compute', 'deployedBy': 'Ansible', 'Name': 'ec2-subnet-euw1-az3', 'environment': 'prod', 'description': 'Resource managed by Ansible', 'projectName': 'learnansible'}, 'subnet_arn': 'arn:aws:ec2:eu-west-1:687011238589:subnet/subnet-091ea1834c5fc8e48', 'enable_dns64': False, 'ipv6_native': False, 'private_dns_name_options_on_launch': {'hostname_type': 'ip-name', 'enable_resource_name_dns_a_record': False, 'enable_resource_name_dns_aaaa_record': False}, 'id': 'subnet-091ea1834c5fc8e48'})</pre> <p>The preceding output<a id="_idIndexMarker687"/> is repeated twice for the other two subnets we will be using; then, we finally create/update the Auto Scaling Group:</p>
<pre class="source-code">
TASK [roles/autoscaling : Create/update the auto-scaling group using the launch template we just created] **********
changed: [localhost]</pre> <p>Now, we have come to the end of our Playbook run, and we get the recap:</p>
<pre class="source-code">
PLAY RECAP ************************************************
ec2-18-203-221-2.eu-west-1.compute.amazonaws.com :
ok=37   changed=28   unreachable=0    failed=0    skipped=1    rescued=0    ignored=2
localhost :
ok=56   changed=23   unreachable=0    failed=0    skipped=30   rescued=0    ignored=0</pre> <p>When I ran the playbook, it took just over 20 minutes to complete the first time, with subsequent runs taking around 10 minutes to finish.</p>
<p>So, from a single command<a id="_idIndexMarker688"/> and in 20ish minutes, we have a highly available vanilla WordPress installation. If you find out the public URL of your Elastic Load Balancer from the AWS console or by checking the value of the <code>elb</code> key in the <code>group_vars/generated_aws_endpoints.yml</code> file, you should be able to see your site.</p>
<h1 id="_idParaDest-176"><a id="_idTextAnchor548"/>Terminating all the resources</h1>
<p>Before we complete<a id="_idIndexMarker689"/> this chapter, we need to look at terminating the resources; to do this, you can run the following:</p>
<pre class="console">
$ ansible-playbook -i hosts destroy.yml</pre> <p>This removes everything in the reverse order that we launched it, starting with the Auto Scaling Group:</p>
<pre class="source-code">
PLAY [Destroy the AWS Environment created by the site.yml playbook] ************
TASK [Gathering Facts] ************************************
ok: [localhost]
TASK [Delete the Auto Scaling Group] **********************
changed: [localhost]
TASK [Delete the Launch Template] *************************
changed: [localhost]</pre> <p>As there can be more than one AMI, we gather some facts and then loop through removing everything that is returned:</p>
<pre class="source-code">
TASK [Get information about the AMIs] *********************
ok: [localhost]
TASK [Delete the AMI(s)] **********************************
changed: [localhost] =&gt; (item={'architecture': 'x86_64', 'creation_date': '2024-01-12T09:44:07.000Z', 'image_id': 'ami-0ddfeb5a1fb64c23a', 'image_location': '687011238589/learnansible-prod-ami-2024-01-12_0944', 'image_type': 'machine', 'public': False, 'tags': {'Name': 'learnansible-prod-ami-2024-01-12_0944', 'deployedBy': 'Ansible', 'environment': 'prod', 'buildDate': '2024-01-12 09:44:06', 'description': 'Resource managed by Ansible', 'projectName': 'learnansible', 'role': 'ami'}, 'virtualization_type': 'hvm', 'source_instance_id': 'i-050689909fa289998'})</pre> <p>We then remove more<a id="_idIndexMarker690"/> one-off resources:</p>
<pre class="source-code">
TASK [Create a SSH Key Pair] ******************************
changed: [localhost]
TASK [Delete the group_vars/generated_aws_endpoints.yml file] *****************************************************
changed: [localhost]
TASK [Delete the RDS database] ****************************
changed: [localhost]
TASK [Delete RDS subnet group] ****************************
changed: [localhost]
TASK [Delete the group_vars/generated_rds_passwordfile file] *****************************************************
changed: [localhost]
TASK [Delete the EFS File System] *************************
changed: [localhost]
TASK [Delete the group_vars/generated_efs_targets.yml file]
changed: [localhost]
TASK [Delete the application elastic load balancer]********
changed: [localhost]
TASK [Delete the target group] *********************************************************************
changed: [localhost]</pre> <p>As the security groups<a id="_idIndexMarker691"/> reference each other, we need to create a list of them in reverse order so we can attempt to delete a group that is referenced by the next one we are going to delete:</p>
<pre class="source-code">
TASK [Create a reversed list of the security group names] *
ok: [localhost]
TASK [Delete the security groups] *************************
changed: [localhost] =&gt; (item=learnansible-efs-security-group)
changed: [localhost] =&gt; (item=learnansible-rds-security-group)
changed: [localhost] =&gt; (item=learnansible-ec2-security-group)
FAILED - RETRYING: [localhost]: Delete the security groups (50 retries left).
. . . . .
FAILED - RETRYING: [localhost]: Delete the security groups (46 retries left).
changed: [localhost] =&gt; (item=learnansible-elb-security-group)</pre> <p>You may have noticed <a id="_idIndexMarker692"/>that it failed towards the end; that is because the AWS API is having a little trouble keeping up, and the playbook is running a little ahead of the results it is returning.</p>
<p>We check a few more tasks:</p>
<pre class="source-code">
TASK [Get information about the VPC] **********************
ok: [localhost]
TASK [Get information about the Route Table] **************
ok: [localhost]
TASK [Delete the Route Table] *****************************
changed: [localhost] =&gt; (item={'associations': [{'main': False, 'route_table_association_id': 'rtbassoc-0738bb9e5aaf44848', 'route_table_id': 'rtb-04bc7177949ad2c92', 'subnet_id': 'subnet-07c28d376283741f6', 'association_state'
TASK [Delete the Internet Gateway]*************************
changed: [localhost]</pre> <p>Next, we have<a id="_idIndexMarker693"/> the subnets:</p>
<pre class="source-code">
TASK [Get information on the subnets] **************************************************************
ok: [localhost]
TASK [Delete the subnets] *********************************
changed: [localhost] =&gt; (item={'availability_zone': 'eu-west-1c', 'availability_zone_id': 'euw1-az3', 'available_ip_address_count': 27, 'cidr_block': '10.0.0.64/27', 'default_for_az': False, 'map_public_ip_on_launch': False, 'map_customer_owned_ip_on_launch': False, 'state': 'available', 'subnet_id': 'subnet-091ea1834c5fc8e48', 'vpc_id': 'vpc-008808ff628883751', 'id': 'subnet-091ea1834c5fc8e48'})
. . . . .
changed: [localhost] =&gt; (item={'availability_zone': 'eu-west-1b', 'availability_zone_id': 'euw1-az2', 'available_ip_address_count': 27, 'cidr_block': '10.0.0.128/27', 'default_for_az': False, 'map_public_ip_on_launch': False, 'map_customer_owned_ip_on_launch': False, 'state': 'available', 'subnet_id': 'subnet-0fd4610392872d442', 'vpc_id': 'vpc-008808ff628883751', 'id': 'subnet-0fd4610392872d442'})</pre> <p>Finally, we get to the VPC and recap:</p>
<pre class="source-code">
TASK [Delete the VPC] *************************************
changed: [localhost]
PLAY RECAP ************************************************
localhost :
ok=23   changed=17   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0</pre> <p>Once the playbook has finished running, I recommend<a id="_idIndexMarker694"/> you log in to the AWS console and double-check that everything has been correctly removed, as you don’t want to incur any unexpected costs.</p>
<h1 id="_idParaDest-177"><a id="_idTextAnchor549"/>Summary</h1>
<p>In this chapter, we have taken our AWS deployment to the next level by creating and launching a highly available WordPress installation. By leveraging the various services offered by AWS, we engineered out any single points of failure regarding the availability of instances and our use of availability zones.</p>
<p>We also built logic into our playbook to use the same command to launch a new deployment or update the operating system on an existing one with a rolling deployment of new instance AMIs that contain our updated packages, leading to zero downtime during deployment.</p>
<p>While the WordPress deployment is as simple as possible, deploying the production-ready images would remain similar when using a more complicated application.</p>
<p>In our next chapter, we will look at moving from the public to the private cloud and how Ansible interacts with VMware.</p>
</div>
</body></html>