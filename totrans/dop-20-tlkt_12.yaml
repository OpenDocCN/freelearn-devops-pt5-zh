- en: Chapter 12. Continuous Integration, Delivery and Deployment Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have most of the process already automated with Ansible. Until now, we used
    playbooks to automate two types of tasks; server provisioning and configuration
    and the deployment process. While Ansible shines as a tool intended to provision
    and configure our servers, deployment (at least in our context) is not its strongest
    side. We used it mostly as a substitute for bash scripts. Most of the deployment
    tasks we have right now are using the Ansible `shell` module. We could have used
    shell scripts instead, and the result would be, more or less, the same. Ansible
    is designed to use promises as a way to ensure that the system is in the correct
    state. It does not work very well with deployments when conditionals, try/catch
    statements and other types of logic are needed. The main reason for using Ansible
    to deploy containers was avoidance to split the process into multiple commands
    (provision with ansible, run a script, provision more, run more scripts, and so
    on). The second, and more important, reason was that we did not cover CI/CD tools,
    so we used what we had. That will change very soon.
  prefs: []
  type: TYPE_NORMAL
- en: What are we missing in our deployment pipeline? We are using Ansible to configure
    and provision servers, and that works great. We are still looking for a better
    way to deploy software (calling Ansible `shell` module is a bit cumbersome). We
    are also missing a way to monitor the repository so that new deployments can be
    executed whenever there is a change in the code. When part of the process fails,
    we do not have a mechanism to send notifications. We are also missing visual representation
    of all our builds and deployments. The list can go on and on. What all those missing
    features have in common is that they can be easily solved with CI/CD tools. Therefore,
    we should start looking at the CI/CD platform we could use and adopt one of them.
  prefs: []
  type: TYPE_NORMAL
- en: CI/CD Tools Compared
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One way to divide CI/CD tools is to put them into cloud services and self-hosted
    solutions groups. There are a plethora of cloud services both for free and paid.
    Most of them are great for the more simplified process than the one we're trying
    to accomplish. If you have a small application consisting out of few services
    and residing on no more than a few servers, cloud solutions are excellent. I used
    many of them for my pet projects. Travis, Shippable, CircleCI and Drone.io are
    only a few of them. They will run your scripts, build your applications and services
    and pack them into containers. Most of them are neither designed nor capable of
    handling a cluster of servers especially when it is private or self-hosted. That
    is not to say that there are no cloud solutions that would fit this scenario.
    There are, but they tend to be too expensive on a large scale. With that in mind,
    we should look for self-hosted solutions.
  prefs: []
  type: TYPE_NORMAL
- en: There's a hell of a lot of self-hosted CI/CD tools, ranging from free offerings
    all the way to very expensive ones. Some of the commonly used self-hosted CI/CD
    tools like Jenkins, Bamboo, GoCD, Team City and Electric Cloud are only a few
    among many others. All of them have their strengths and weaknesses. However, Jenkins
    sticks out from the crowd thanks to its community. No other tool has such a big
    number of people contributing on a daily basis. It has an excellent support and,
    through its plugins, it can be extended to do almost anything we might need. You
    will hardly find yourself in a need of something that is not already covered with
    one or more plugins. Even if you find a use case that is not covered, writing
    your own plugin (and hopefully making it public for others to use) is a very easy
    thing to do. Community and plugins are its greatest strength that makes it more
    widely adopted than any other tool.
  prefs: []
  type: TYPE_NORMAL
- en: The chances are that you already used Jenkins, or, at least, heard of it. One
    of the main reasons companies are choosing some other tool (especially Bamboo
    and Team City) are their enterprise offerings. When an organization becomes big,
    it needs support and reliability that comes with it. It needs those extra features
    and know-how that enterprise offerings provide. Cloud Bees is one such company
    formed recently. They offer Jenkins Enterprise version and have an excellent support
    capable of handling almost any scenario related to continuous integration, delivery
    or deployment. They have the community version of Jenkins that can be obtained
    for free but also offer paid enterprise features and support. That is another
    reason one should choose Jenkins. No other tool (at least among those previously
    mentioned) has fully free tool and, at the same time, offers paid support and
    additional features. Team City can be downloaded for free but has a limited number
    of agents. GoCD is free but it doesn't provide any support. Bamboo is similar
    to Team City regarding limitations imposed on the free version. By choosing Jenkins,
    we are choosing battle tested and most widely used tool supported by a vast community
    that has, if such a need arises, paid support and features through CloudBees.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While writing this book, I chose to join the CloudBees team (the company behind
    Enterprise Jenkins). The decision to promote Jenkins throughout this book was
    not based on my employment in CloudBees. It's the other way around. I chose to
    join them because I believe that Jenkins is the best CI/CD tool in the market.
  prefs: []
  type: TYPE_NORMAL
- en: The Short History of CI/CD Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Jenkins (forked from Hudson after a dispute with Oracle) has been around for
    a long time and established itself as the leading platform for the creation of
    **continuous integration** (**CI**) and **continuous delivery/deployment** (**CD**)
    pipelines. The idea behind it is that we should create jobs that perform operations
    like building, testing, deploying, and so on. Those jobs should be chained together
    to create a CI/CD pipeline. The success was so big that other products followed
    its lead and we got Bamboo, Team City, and others. They all used a similar logic
    of having jobs and chaining them together. Operations, maintenance, monitoring,
    and the creation of jobs is mostly done through their UIs. However, none of the
    other products managed to suppress Jenkins due to its strong community support.
    There are over one thousand plugins, and one would have a hard time imagining
    a task that is not supported by, at least, one of them. The support, flexibility,
    and extensibility featured by Jenkins allowed it to maintain its reign as the
    most popular and widely used CI/CD tool throughout all this time. The approach
    based on heavy usage of UIs can be considered the first generation of CI/CD tools
    (even though there were others before).
  prefs: []
  type: TYPE_NORMAL
- en: With time, new products come into being and, with them, new approaches were
    born. Travis, CircleCI, and the like, moved the process to the cloud and based
    themselves on auto-discovery and, mostly YML, configurations that reside in the
    same repository as the code that should be moved through the pipeline. The idea
    was good and provided quite a refreshment. Instead of defining your jobs in a
    centralized location, those tools would inspect your code and act depending on
    the type of the project. If, for example, they find `build.gradle` file, they
    would assume that your project should be tested and built using Gradle. As the
    result, they would run `gradle check` to test your code and, if tests passed,
    follow it by `gradle assemble` to produce the artifacts. We can consider those
    products to be the second generation of CI/CD tools.
  prefs: []
  type: TYPE_NORMAL
- en: The first and the second generation of tools suffer from different problems.
    Jenkins and the like feature power and flexibility that allow us to create custom
    tailored pipelines that can handle almost any level of complexity. This power
    comes with a price. When you have tens of jobs, their maintenance is quite easy.
    However, when that number increases to hundreds, managing them can become quite
    tedious and time demanding.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say that an average pipeline has five jobs (building, pre-deployment testing,
    deployment to a staging environment, post-deployment testing, and deployment to
    production). In reality, there are often more than five jobs but let's keep it
    an optimistic estimate. If we multiply those jobs with, let's say, twenty pipelines
    belonging to twenty different projects, the total number reaches one hundred.
    Now, imagine that we need to change all those jobs from, let's say, Maven to Gradle.
    We can choose to start modifying them through the Jenkins UI or be brave and apply
    changes directly in Jenkins XML files that represent those jobs. Either way, this,
    seemingly simple, change would require quite some dedication. Moreover, due to
    its nature, everything is centralized in one location making it hard for teams
    to manage jobs belonging to their projects. Besides, project specific configurations
    and code belong to the same repository where the rest of application code resides
    and not in some central location. And Jenkins is not alone with this problem.
    Most of the other self-hosted tools have it as well. It comes from the era when
    heavy centralization and horizontal division of tasks was thought to be a good
    idea. At approximately the same time, we felt that UIs should solve most of the
    problems. Today, we know that many of the types of tasks are easier to define
    and maintain as code, than through some UI.
  prefs: []
  type: TYPE_NORMAL
- en: I remember the days when Dreamweaver was big. That was around the end of the
    nineties and the beginning of year two thousand (bear in mind that at that time
    Dreamweaver was quite different than today). It looked like a dream come true
    (hence the name?). I could create a whole web page with my mouse. Drag and drop
    a widget, select few options, write a label, repeat. We could create things very
    fast. What was not so obvious at that time was that the result was a loan that
    would need to be paid with interests. The code Dreamweaver created for us was
    anything but maintainable. As a matter a fact, sometimes it was easier to start
    over than modify pages created with it. That was especially true when we had to
    do something not included in one of its widgets. It was a nightmare. Today, almost
    no one writes HTML and JavaScript by using drag & drop tools. We write the code
    ourselves instead of relying on other tools to write it for us. There are plenty
    of other examples. For example, Oracle ESB, at least in its infancy, was similarly
    wrong. Drag & drop was not a thing to rely on (but good for sales). That does
    not mean that GUIs are not used any more. They are, but for very specific purposes.
    A web designer might rely on drag & drop before passing the result to a coder.
  prefs: []
  type: TYPE_NORMAL
- en: What I'm trying to say is that different approaches belong to different contexts
    and types of tasks. Jenkins and similar tools benefit greatly from their UIs for
    monitoring and visual representations of statuses. The part it fails with is the
    creation and maintenance of jobs. That type of tasks would be much better done
    through code. With Jenkins, we had the power but needed to pay the price for it
    in the form of maintenance effort.
  prefs: []
  type: TYPE_NORMAL
- en: The second generation of CI/CD tools (Travis, CircleCI, and the like) reduced
    that maintenance problem to an almost negligible effort. In many cases, there
    is nothing to be done since they will discover the type of the project and do
    the right thing. In some other cases, we have to write a `travis.yml`, a `circle.yml`,
    or a similar file, to give the tool additional instructions. Even in such a case,
    that file tends to have only a few lines of specifications and resides together
    with the code thus making it easy for the project team to manage it. However,
    these tools do not replace the first generation since they tend to work well only
    on small projects with a very simple pipeline. The real continuous delivery/deployment
    pipeline is much more complex than what those tools are capable of. In other words,
    we gained low maintenance but lost the power and, in many cases, flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: Today, old-timers like Jenkins, Bamboo, and Team City, continue dominating the
    market and are recommended tools to use for anything but small projects. At the
    same time, cloud tools like Travis and CircleCI dominate smaller settings. The
    team maintaining Jenkins codebase recognized the need to introduce a few significant
    improvements that will bring it to the next level by combining the best of both
    generations, and some more. I'll call that change the third generation of CI/CD
    tools. They introduced Jenkins Workflow and *Jenkinsfile*. Together, they bring
    some very useful and powerful features. With Jenkins Workflow, we can write a
    whole pipeline using Groovy-based DSL. The process can be written as a single
    script that utilizes most of the existing Jenkins features. The result is an enormous
    reduction in code (Workflow scripts are much smaller than traditional Jenkins
    job definitions in XML) and reduction in jobs (one Workflow job can substitute
    many traditional Jenkins jobs). That results in much easier management and maintenance.
    On the other hand, newly introduced Jenkinsfile allows us to define the Workflow
    script inside the repository together with the code. That means that developers
    in charge of the project can be in control of the CI/CD pipeline as well. That
    way, responsibilities are much better divided. Overall Jenkins management is centralized
    while individual CI/CD pipelines are placed where they belong (together with the
    code that should be moved through it). Moreover, if we combine all that with the
    *Multibranch Workflow* job type, we can even fine tune the pipeline depending
    on the branch. For example, we might have the full process defined in the Jenkinsfile
    residing in the `master` branch and shorter flows in each feature branch. What
    is put into each Jenkinsfile is up to those maintaining each repository/branch.
    With the *Multibranch Workflow* job, Jenkins will create jobs whenever a new branch
    is created and run whatever is defined in the file. Similarly, it will remove
    jobs when branches are removed. Finally, *Docker Workflow* has been introduced
    as well, making Docker the first class citizen in Jenkins.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Jenkins has a long history that led it to the Pipeline plugin. There was the
    Build Pipeline plugin that provided visualizations for connected jobs, then came
    the Build Flow plugin that introduced the concept of Groovy DSL as a way to define
    Jenkins jobs. The latter hit many obstacles that led its authors to start over
    and create the Workflow plugin, only to rename it, later on, into the Pipeline
    plugin.
  prefs: []
  type: TYPE_NORMAL
- en: All those improvements brought Jenkins to a whole new level confirming its supremacy
    among CI/CD platforms.
  prefs: []
  type: TYPE_NORMAL
- en: If even more is needed, there is the CloudBees Jenkins Platform - Enterprise
    Edition that provides fantastic features, especially when we need to run Jenkins
    at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Workflow authors decided to rename the plugin into Pipeline. However, at this
    moment, not all the source code has been renamed and there are references to both
    pipeline and workflow. For consistency, and to avoid possible failures, I chose
    to stick with the old name and use the word Workflow throughout the book. The
    change is only semantic and does not introduce any functional changes.
  prefs: []
  type: TYPE_NORMAL
- en: Jenkins
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Jenkins shines with its plugins. There are so many of them that it would be
    hard to find something we'd like to accomplish that is not already covered with
    at least one plugin. Want to connect to a code repository? There is a plugin.
    Want to send notifications to Slack? There is a plugin. Want to parse logs using
    your formulas? There is a plugin.
  prefs: []
  type: TYPE_NORMAL
- en: Being able to choose from so many plugins is a double edged sword. People tend
    to abuse it and install plugins for many more things than its needed. One example
    would be the Ansible plugin.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can select it as a build step and fill in the fields like **Playbook path**,
    **Inventory**, **Tags to skip**, **Additional parameters** and so on. The screen
    could look like the one presented in the figure 12-01:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Jenkins](img/B05848_12_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-01 – Ansible plugin used inside a Jenkins job
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternative to the Ansible plugin would be just to use the **Execute Shell**
    build step (part of the Jenkins core) and put the command we''d like to run. We
    wrote the automation ourselves and are familiar with commands that should be run.
    By using those same commands there are fewer fields to be filled or ignored, we
    know what will be run and can use those same commands as a reference if the same
    process should be repeated outside of Jenkins:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Jenkins](img/B05848_12_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-02 – Running Ansible playbook as a shell command
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, automation should be something done outside Jenkins (or any other
    CI/CD tool). From there on, all we have to do is tell Jenkins which script to
    run. That script can be in the repository together with the code of the service
    we are deploying (for example `deploy.sh`) or, as in our case, be generalized
    through few naming conventions and used for all services. No matter the way automation
    scripts are organized, in most cases the best and the easiest way to use them
    inside Jenkins is to just run the command associated with those scripts. That
    held true until recently. Now, with the addition of Jenkinsfile, we can follow
    the same logic of creating project specific scripts and keeping them in the project
    repository. The additional benefit it brings is that we can utilize Jenkins specific
    features inside the Workflow script residing in the Jenkinsfile. If you need to
    run something on a particular node, there is a module for it. If you need to use
    authentication stored in Jenkins, there is a module for it. The list goes on and
    on, but the gist is that with Jenkinsfile and the Workflow we can continue relying
    on scripts residing inside the code repository and, at the same time, utilize
    advanced Jenkins features.
  prefs: []
  type: TYPE_NORMAL
- en: The time has come to get our hands dirty and set up Jenkins.
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up Jenkins
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As always, we''ll start by creating virtual machines that we''ll use for our
    exploration of Jenkins. We''ll create the `cd` node that will host our Jenkins
    server as well as Ansible playbooks that we''ll run through it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once both servers are up and running, we can proceed and provision the `prod`
    node in the same way as we did before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we are ready to bring up Jenkins. Setting up the basic installation is
    very easy with Docker. All we have to do is run a container with a few arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Docker detected that there is no local copy of the Jenkins container and started
    pulling it from the Docker Hub. Once pulling is done, we'll have a running instance
    that exposes the port 8080 and shares a few volumes. The `/var/jenkins_home` directory
    contains all Jenkins configuration. It is handy to have it shared for the sake
    of configuration management that we'll explore soon. We gave full permissions
    (0777) to that directory in the host since the container processes run as the
    `jenkins` user that does not exist in our system. It's not a good solution security-wise,
    but it should do for now. The second shared directory is `/machines` that is mapped
    to the host's directory `/vagrant/.vagrant/machines`. That's the location where
    Vagrant keeps all SSH keys that we'll need to set up Jenkins nodes on which the
    actual jobs will be run. Please note that, if you'd run this on production servers,
    you should generate keys with `ssh-copy-id` and share them instead of those generated
    by Vagrant.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the Jenkins container is going, we can open `http:/` `/10.100.198.200:8080`
    and explore the GUI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Jenkins](img/B05848_12_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-03 – Jenkins home screen after the standard installation
  prefs: []
  type: TYPE_NORMAL
- en: If this is the first time you are in front of Jenkins, please take a break from
    this book and spend some time getting familiar with it. Its GUI is very intuitive,
    and there are a lot of online sources that will help you get a basic understanding
    of how it works. We are about to dive into automation of Jenkins administration.
    Even though we won't use the GUI for that, understanding how it works visually
    will help you understand better the tasks we are about to perform. Take your time
    with it and, once you feel comfortable, return here for more.
  prefs: []
  type: TYPE_NORMAL
- en: Most people I know use Jenkins exclusively through its GUI. Some might use its
    API to run jobs or automate some basic operations. And that's fine, for a while.
    You start by installing a few plugins, create a few jobs and feel great for accomplishing
    a lot very quickly. With time, the number of jobs increases and with them the
    maintenance effort. It is not uncommon to have tens, hundreds or even thousands
    of jobs defined and running periodically or being triggered by some events (for
    example code commit). Administrating all those jobs through the GUI is hard and
    time demanding. Imagine, for instance, that you want to add Slack notifications
    to all jobs. Modifying jobs one by one is not a good option when there's a significant
    number of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different ways we can tackle the problem of Jenkins automation that
    is, primarily, focused on creation and maintenance of its jobs. One approach would
    be to use some of the Jenkins plugins that could help us out. A few of those are
    Job DSL and Job Generator plugins. We''ll take a different approach. All Jenkins
    settings are stored as XML files located in the `/var/jenkins_home directory`
    (we exposed it as a Docker volume). We can simply add new files or modify existing
    ones when we need to change some Jenkins behavior. Since we are already familiar
    with Ansible, we can continue using it as a tool to not only install but also
    maintain Jenkins. In that spirit, we''ll remove the current Jenkins installation
    and start over with Ansible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We removed the Jenkins container and deleted the directory we exposed as a volume.
    Now we can install it and configure it through Ansible.
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up Jenkins with Ansible
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Setting up Jenkins with Ansible is easy even though the role we''ll use has
    few complications we haven''t encountered previously. Since it will take a few
    minutes for the playbook to finish executing, let''s run it first and discuss
    its definition while waiting for it to finish:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'First we set up Jenkins nodes that we''ll use later on. It should not take
    long to execute the first playbook since all it has to do is make sure that JDK
    is installed (required by Jenkins, to be able to connect to a node) and that the
    single directory `/data/jenkins_slaves`. Jenkins will use that directory to store
    files when executing processes on those nodes. The `jenkins` role is in the `jenkins.yml`
    playbook is a bit longer and will be worthwhile spending some time with. Let''s
    explore it in more details. The `jenkins.yml` playbook is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: It installs Consul Template that we're already familiar with so we'll move straight
    to the `roles/jenkins` role. The tasks are defined in the `roles` `/jenkins/tasks/main.yml`
    file and we'll go through them one by one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first task creates directories that we''ll need. As before, variables are
    defined in the `roles/jenkins/defaults/main.yml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'With directories created, we can run the jenkins container. Even though it
    takes no time for the container to start running, Jenkins itself requires a bit
    of patience until it is fully operational. Later on, we''ll be issuing some commands
    to Jenkins API, so we''ll have to pause the playbook, for, let''s say, half a
    minute, to be sure that Jenkins is operational. At the same time, this gives us
    the opportunity to see `pause` module in action (even though it should be rarely
    used). Please notice that we are registering the variable `container_result` and,
    later on, pausing so that Jenkins application inside the container is fully operational
    before proceeding with the rest of tasks. This pause is performed if the state
    of the Jenkins container changed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we should copy a few configuration files. We''ll start with `roles/jenkins/files/credentials.xml`,
    followed by few nodes (`roles/jen` `ki` `ns/files/cd_config.xml`, `roles/jenki`
    `ns/files/prod_config.xml`, and so on) and a several other less important configurations.
    Feel free to see contents of those files. At the moment, it is only important
    to understand that we need those configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Next, we should make sure that several plugins are installed. Since our code
    is in GitHub, we'll need the `Git Plugin`. Another useful plugin that we'll use
    is the `Log Parser`. Since Ansible logs are quite big, we'll use this plugin to
    break them into more manageable pieces. Few other plugins will be installed as
    well, and we'll discuss each of them when the time comes to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Most people tend just to download plugins they need. Even the official Jenkins
    container that we are using has a way to specify which plugins to download. However,
    that approach is very dangerous since we'd need to define not only plugins we
    need but also their dependencies, dependencies of those dependencies and so on.
    It would be easy to forget one of them or specify a wrong dependency. If such
    a thing happens, at best, the plugin we wanted to use would not work. In some
    cases, even the whole Jenkins server could stop functioning. We'll take a different
    approach. Plugins can be installed by sending an HTTP request to `/pluginManager/installNecessaryPlugins`
    with XML in the body. Jenkins, upon receiving the request will download both the
    plugin we specify and its dependencies. Since we don't want to send the request
    if the plugin is already installed, we'll use the `creates` instruction specifying
    the path to the plugin. If the plugin exists, the task will not be run.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most plugins require a restart of the application, so we''ll restart the container
    if any of the plugins was added. Since the request to install a plugin is asynchronous,
    first we''ll have to wait until plugin directory is created (Jenkins unpacks plugins
    into directories with the same name). Once it is confirmed that all plugins are
    installed, we''ll restart Jenkins and wait (again) for some time before it is
    fully operational. In other words, we send requests to Jenkins to install plugins
    and, if they are not already installed, wait until Jenkins is finished with installations,
    restart the container so that new plugins are used and wait for a while until
    the restart is finished:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we are ready to create jobs. Since all of them will work in (more or less)
    the same way, we can use a single template that will serve for all our jobs related
    with service deployments. We need to create a separate directory for each job,
    apply the template, copy the result to the destination server and, finally, if
    any of the jobs changed, reload Jenkins. Unlike plugins that require a full restart,
    Jenkins will start using new jobs after the reload which is a very fast (almost
    instantaneous) action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In the future, if we'd like to add more jobs, all we'd need to do is add more
    entries to the `jobs` variable. With a system like that, we can easily create
    as many Jenkins jobs as there are services with almost no effort. Not only that
    but, if jobs need to be updated, all we'd need to do is change the template and
    re-run the playbook, and the changes would be propagated to all the jobs in charge
    of building, testing and deploying our services.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `jo` `bs` variable defined in the `role` `s/jenkins/defaults/main.yml`
    file is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `name` and `service_name` values should be easy to understand. They represent
    the name of the job and the name of the service. The third value is the source
    template we''ll use to create the job configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let's take a look at the `roles/jenkins/templates` `/service-ansible-config.xml`
    template.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'It is a relatively big XML definition of a Jenkins job. I created it manually
    through the GUI, copied the file and replaced values with variables. One of the
    key entries is the one that tells Jenkins the location of the code repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we are, again, using naming conventions. The name of the repository
    is the same as the name of the service and will be replaced with the value of
    the variable we saw earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second entry is the one that executes the command that runs Ansible playbook
    and builds, packages, tests and deploys the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we're running the same Ansible playbook that we created in the
    previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the last task in the `jenkins` role is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: It copies scripts to the `/data` directory. We'll explore those scripts later
    on.
  prefs: []
  type: TYPE_NORMAL
- en: The Ansible role `jenkins` is a good example of a more complicated use case.
    Until this chapter, most of the provisioning and configurations we did with Ansible
    were much simpler. In most instances we would update APT repository, install a
    package and, maybe, copy some configuration file. In some other cases, we would
    only run a Docker container. There were many other cases but, in the essence,
    they were all very simple since none of the other tools required much configuration.
    Jenkins was quite different. Besides running a container, we had to create quite
    a quite a few configuration files, install several plugins, create some jobs,
    and so on. As an alternative, we could (and probably should) have created our
    container that would have everything but jobs inside it. That would simplify the
    setup and, at the same time, provide a more reliable solution. However, I wanted
    to show you a bit more complicated Ansible process.
  prefs: []
  type: TYPE_NORMAL
- en: I'll leave the creation of a custom Jenkins image as an exercise. The image
    should contain everything but jobs inside it. Create a Dockerfile, build and push
    the image to Docker Hub and modify Ansible role `jenkins` so that the new container
    is used. It should share volumes with SSH keys and jobs so that they can be updated
    from outside a container.
  prefs: []
  type: TYPE_NORMAL
- en: Running Jenkins Jobs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By now, the Ansible playbook we run earlier should have finished the execution.
    Not only that Jenkins is up and running, but the `books-ms` job is created and
    waiting for us to use it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the Jenkins GUI. Please open `http://10.100.198.200:8080`.
    You''ll see the home page with a few jobs. The one we''ll be exploring first is
    the `book-ms-ansible` job. In a different situation, our code repository would
    trigger a request to Jenkins to execute the build. However, since we''re using
    public GitHub repo and this Jenkins instance is (probably) running on your laptop
    and is not accessible from a public network, we''ll have to execute the job manually.
    Let''s click the **Schedule a build for books-ms-ansible** button (icon with a
    clock and play arrow). You''ll see that the first build of the `books-ms-ansible`
    job is running on the `cd` node located in the left-hand side of the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Running Jenkins Jobs](img/B05848_12_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-04 – Jenkins home screen with a few jobs
  prefs: []
  type: TYPE_NORMAL
- en: Let's click the `books-ms-ansible` job, then click `#1` link inside the `Build
    History` and, finally, the `Console Output`. The same can be accomplished by opening
    the `http://10.100.198.200:8080/job/book` `s-ms-ansible/lastBuild/console` URL.
    You will be presented with the output of the last build of that job. As you probably
    noticed, the log is a bit big and it would be hard to find information about a
    particular task. Luckily, we installed the `Log Parser` plugin that can help us
    drill through logs easier. But, first things first, we need to wait until the
    build is finished. We'll use that time wisely and explore the job configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Please go back to the `books-ms-ansible` job main screen and click the `Configure`
    link located in the left-hand menu (or open the link `http://10.100.198.200:8080/`
    `job/books-ms-ansible/configure`).
  prefs: []
  type: TYPE_NORMAL
- en: The `books-ms-ansible` is a very simple job and yet, in most cases, we won't
    need anything more complicated if our automation scripts are done correctly (with
    or without Ansible). You'll see that the job is restricted to the `cd` node meaning
    that it can run only on servers named or labeled `cd`. That way we can control
    which jobs are run on which servers. Part of the Jenkins setup was to create one
    node called `cd`.
  prefs: []
  type: TYPE_NORMAL
- en: The *Source Code Management* section has the reference to the GitHub repository.
    Please note that we are missing a trigger that will run this job whenever there
    is a new commit. That can be accomplished in a variety of ways. We could set `Build
    Trigger` to `Poll SCM` and schedule it to run periodically (let's say every 10
    seconds). Please note that the scheduling format uses the `cron` syntax. In such
    a case, Jenkins would regularly check the repository and, if anything changed
    (if there was a commit), it would run the job. A better way would be to create
    a `webhook` directly in the repository. That hook would invoke a Jenkins build
    on every commit. In such a case, the build would start running almost instantaneously
    after the commit. At the same time, there would be no overhead created by jobs
    periodically checking the repository. However, this approach would require Jenkins
    being accessible from the repository (in this case GitHub) and we are currently
    running Jenkins inside a private network. We choose neither since it is very unlikely
    that there will be a commit to the `books-ms` repository while you are reading
    this book. It is up to you to investigate different ways to trigger this job.
    We'll simulate the same process by running builds manually. No matter the way
    the job is run, the first thing it will do is clone the repository using information
    provided in the *Source Code Management* section.
  prefs: []
  type: TYPE_NORMAL
- en: Now we reached the main part of the job; the **Build** section. I already mentioned
    that we could have used the **Ansible** plugin to help us run the playbook. However,
    the command we should run is so simple that using a plugin would only introduce
    additional complications. Inside the **Build** section, we have the `Execute shell`
    step that runs the `service.yml` playbook is the same way as we run it manually.
    We are using Jenkins only as a tool to detect changes to the code repository and
    run the same commands we would run without it.
  prefs: []
  type: TYPE_NORMAL
- en: '![Running Jenkins Jobs](img/B05848_12_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-05 – Jenkins books-ms-ansible job configuration screen
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we have the `Console output (build log) parsing` set as the `Post-build
    actions` step. It parses (in this case) Ansible logs so that they are displayed
    in a more user-friendly fashion. By this time, the execution of the build probably
    finished, and we can take a look at the parsed log.
  prefs: []
  type: TYPE_NORMAL
- en: Go back to the build `#1` of the `books-ms` job and click the `Parsed Console
    Output` link in the left-hand menu or open the URL `http://10.100.198.200:8080/job/books-ms-a`
    `nsible/lastBuild/parsed_console/`. Under the section `Info`, you'll see each
    Ansible task separated and can click any of them to jump to the part of the output
    related to that task. If there were some problems during the execution, they would
    appear under the link `Error`. We won't go into details how the `Log Parser` plugin
    works. I included it into this job mostly as a demonstration of the power Jenkins
    provides through its plugins. There's over a thousand of them available and new
    ones coming. Plugins are probably the main advantage Jenkins has over other CI/CD
    tools. There is such a big community behind them that you can rest assured that
    almost any need you have is (probably) covered. Even better, just by exploring
    available plugins, you will get new ideas.
  prefs: []
  type: TYPE_NORMAL
- en: Even though this job fulfills all the essential purposes required to deploy
    the service (checkout the code and run the Ansible playbook), there are a few
    additional tasks we could add to the job. Probably the most interesting thing
    we could do is add notifications in case of a job failure. That can be an email
    message, Slack notification or (almost) any other type of notification we're used
    to. I'll leave that part to you as an exercise. Spend some time checking out plugins
    that would help to send notifications, select one and install it. The **Manage
    Plugins** screen can be accessed by clicking the `Manage Jenkins` located in the
    left-hand menu on the home screen. As an alternative, the same screen can be accessed
    by opening the URL `http://10.100.198.200:8080/pluginManager/`. Once inside, follow
    plugin instructions and add it to the `books-ms-ansible` job. Once you're comfortable
    with it, try to do the same through Ansible. Add the new plugin to the `plugins`
    variable and put the required entries to the `service-ansible-config.xml` template.
    The easiest way to do that is to apply the changes through the UI, and then check
    the changes Jenkins did to the `/data/jenkins/jobs/books-ms-ansible/conf` `ig.xml`
    file in the `cd` node.
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up Jenkins Workflow Jobs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Is there a better way to structure a job that will deploy the `books-ms` service?
    What we have right now is a job consisting of multiple steps. One step checks
    out the code while the another runs the Ansible script. We specified that it should
    run on the `cd` node and did few more minor steps. Notifications are missing at
    the moment (unless you implemented them yourself) and they would be another step
    in the job. Each step is a separate plugin. Some of them are distributed with
    Jenkins core while others were added by us. With time, the number of steps might
    increase considerably. At the same time, while Ansible is great for provisioning
    and configuring servers when used as a tool to build, test and deploy services,
    it proved to be a bit cumbersome and lacking some of the features that could be
    done easier with a simple bash script.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, bash scripts lack some of the characteristics Ansible has.
    For example, Ansible is much better at running commands in remote locations. The
    third option would be to move the deployment process to traditional Jenkins jobs.
    That would also not be a great solution. We'd end up with quite a few jobs that
    would probably run bash scripts as well. One job would do pre-deployment tasks
    on the `cd` node, another would be in charge of deployment in the `prod` node,
    and we'd need a third one that would execute post-deployment steps in the `cd`
    node. As a minimum, we would have three chained jobs. More likely, there would
    be more. Maintaining many jobs is time-demanding and complicated at best.
  prefs: []
  type: TYPE_NORMAL
- en: We can utilize Jenkins' `Workflow Plugin` to write a script that does all the
    steps for us. We can use it as an alternative to deployment we're currently doing
    with Ansible. We already discussed that Ansible shines at servers provisioning
    and configuration, but the deployment part could be improved. The Workflow plugin
    allows us to script the whole job. This feature in itself is a great way to continue
    relying heavily on automation. That is especially true since Jenkins XML is very
    cumbersome and hard to write and read. It is enough to take a look at the `service-ansible-config.xml`
    that we used to define a simple job that deploys our services. Jenkins XML is
    cryptic and with a lot of boilerplate definitions, Ansible is not designed to
    be used with conditionals nor it has a decent substitute for try/catch statements
    and bash scripts are just an extra layer of complexity. It is true that, at this
    point, our process is complicated, and we should strive to keep things as simple
    as possible without sacrificing the goals we set in front of us.
  prefs: []
  type: TYPE_NORMAL
- en: Let's give Workflow plugin a go and see whether it can help. We'll combine it
    with the `CloudBees Docker Workflow Plugin`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll begin by taking a look at the configuration of the `books-ms` job. We
    can navigate through the Jenkins UI all the way to the job settings screen or
    simply open the `http://10.100.1` `98.200:8080/job/books-ms/configure` URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Jenkins Workflow Jobs](img/B05848_12_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-06 – Configuration screen of the books-ms Jenkins workflow job
  prefs: []
  type: TYPE_NORMAL
- en: 'Once inside the `books-ms` configuration, you''ll notice that the whole job
    consists only of a few parameters and the workflow script. Unlike regular jobs,
    workflow allows us to script (almost) everything. That, in turn, makes managing
    Jenkins jobs much easier. The `roles/je` `nkins/templates/service-flow.groovy`
    script we''re using is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The script starts with the node definition telling Jenkins that all the instructions
    should be run on the `cd` node.
  prefs: []
  type: TYPE_NORMAL
- en: The first instruction inside the node is to check out the code from the Git
    repository. The `git` module is one of the examples of the DSL created for the
    Jenkins Workflow. This instruction uses the `serviceName` parameter defined in
    the Jenkins job.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we're using the `load` instruction that will include all the utility functions
    defined in the `workflow-util.groovy` script. That way we won't repeat ourselves
    when we create jobs with different goals and processes. We'll explore the `workflow-util.groovy`
    script very soon. The result of the load is assigned to the `flow` variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'From this point on, the rest of the script should be self-explanatory. We''re
    calling the `provision` function passing it `prod2.yml` as variable. Then we''re
    calling the `buildTest` function and passing it `serviceName` and `registryIpPort`
    job parameters as variables. And so on, and so forth. The functions we are invoking
    are performing the same actions like those we implemented through Ansible, and
    represent the deployment pipeline. With this separation between utility functions
    loaded as a separate file and the workflow script itself, we can properly divide
    responsibilities. The utility script provides functions multiple workflow scripts
    can use and benefits greatly from being centralized so that improvements are done
    once. On the other hand, one workflow might not be the same as the other so, in
    this case, it mostly contains invocations of utility functions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a closer look at the functions inside the `workflow-util.groovy`
    script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `provision` function is in charge of provisioning our servers before deployment.
    It defines `stage` that helps us better identify the set of tasks this function
    is in charge of. That is followed by the declaration of the `PYTHONUNBUFFERED`
    environment variable that tells Ansible to skip buffering logs and display the
    output as soon as possible. Finally, we are invoking the Ansible playbook using
    the workflow module `sh` that runs any shell script. Since we might run different
    playbooks depending on the type of the Jenkins job, we are passing the playbook
    name as the function variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next function we''ll explore is in charge of building tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This time, we are using the `docker` module to declare the Docker image and
    assigning the result to the `tests` variable. From there on, we are pulling the
    image, running a Shell script that builds a new one in case something changed
    and, finally, pushing the result to the registry. Please note that image pulling
    is inside a `try/catch` statement. The workflow is run for the first time, there
    will be no image to pull, and, without a `try/catch` statement, the script would
    fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next in line are functions for running tests and building the service image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Those two functions use the same instructions as those we already discussed
    so we'll jump over them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function for deploying the service might need further explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The new instruction is the `withEnv`. We're using it to create the environment
    variable that has a limited scope. It will exist only for instructions declared
    inside curly braces. In this case, environment variable `DOCKER_HOST` is used
    only to pull and run the `app` container on a remote host.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last function updates the proxy service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The new instructions are `stash` and `unstash`. Since we are updating the proxy
    on a different node (defined as the `proxyNode` variable), we had to stash few
    files from the `cd` server and unstash them in the proxy node. In other words,
    stash/unstash combination is equivalent to copying the files from one server or
    directory to another.
  prefs: []
  type: TYPE_NORMAL
- en: All in all, the approach with Jenkins Workflow and Groovy DSL removes the need
    for deployment defined in Ansible. We'll keep using Ansible playbooks for provisioning
    and configuration since those are the areas it truly shines. On the other hand,
    Jenkins Workflow and Groovy DSL provide much more power, flexibility, and freedom
    when defining the deployment process. The main difference is that Groovy is a
    scripting language and, therefore, provides a better syntax for this type of tasks.
    At the same time, its integration with Jenkins allows us to utilize some powerful
    features. For example, we could define five nodes with a label `tests`. Later
    on, if we specify that some Workflow instructions should be run on a `tests` node,
    Jenkins would make sure that the least utilized of those five nodes is used (or
    there might be a different logic depending on the way we set it up).
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, by using Jenkins Workflow, we're avoiding complicated and
    not easy to understand XML definitions required by traditional Jenkins jobs and
    reducing the overall number of jobs. There are many other advantages Workflow
    provides and we'll discuss them later. The result is a single script, much shorter
    than Ansible deployment tasks we had before, and, at the same time, something
    easier to understand and update. We embraced Jenkins for tasks it is good at while
    keeping Ansible for servers provisioning and configuration. The result is the
    combination that uses the best of both worlds.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take another look at the configuration of the `books-ms` job. Please open
    the `books-ms configuration` screen in your favorite browser. You'll see that
    the job contains only two set of specifications. It starts with parameters and
    ends with the Workflow script we discussed earlier. The script itself can be very
    generic since differences are declared through parameters. We could multiply this
    job for all our services, and the only differences would be Jenkins parameters.
    That way, management of those jobs can be handled through a single Ansible template
    defined in the `roles/jenkin` `s/templates/service-workflow-config.xml` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s build the job and see how it fares. Please open the `books-ms build`
    screen. You''ll see that the parameters are already pre-defined with reasonable
    values. The name of the service is the `books-ms` parameter, the IP of the production
    server is the `prodIp` parameter, the IP of the proxy server is the `proxyIp`
    parameter and, finally, the IP and the port of the Docker registry is defined
    as the `registryIpPort` parameter. Once you click the **Build** button, the deployment
    will be initiated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Jenkins Workflow Jobs](img/B05848_12_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-07 – Build screen of the books-ms Jenkins workflow job
  prefs: []
  type: TYPE_NORMAL
- en: 'We can monitor the execution of the job by opening the `books-ms` Console screen
    of the last build:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Jenkins Workflow Jobs](img/B05848_12_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-08 – Console screen of the books-ms Jenkins workflow job
  prefs: []
  type: TYPE_NORMAL
- en: 'As you already know, many things are done as part of our deployment process
    and the logs can be too big for us to find something fast. Luckily, Jenkins workflow
    jobs have the `Workflow Steps` feature that can help. When the execution is finished,
    please click the Workflow Steps link after navigating to the last `books-ms build`.
    You''ll see that each stage and step is presented with a link (icon representing
    a terminal screen) that allow us to investigate only logs belonging to the step
    in question:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Jenkins Workflow Jobs](img/B05848_12_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-09 – Workflow Steps screen of the books-ms Jenkins workflow job
  prefs: []
  type: TYPE_NORMAL
- en: There's much more to Jenkins workflow than what we presented here. Please spend
    some time with the online tutorial to get more familiar with it. As an exercise,
    add, for example, email notifications to the script. While exploring Jenkins Workflow,
    make sure to select the **Snippet Generator** checkbox located below the script
    in the books-ms configuration screen. It is a very useful way to discover what
    each snippet does and how it can be used.
  prefs: []
  type: TYPE_NORMAL
- en: Even though Workflow provided a lot of benefits over deployment defined through
    the playbook, managing the script through Ansible is still the sub-optimum solution.
    A better way would be to set the deployment pipeline as a script inside the code
    repository together with the rest of the service code. That way, the team maintaining
    the service would be in full control of deployment. Besides the need to have the
    workflow script inside the code repository, it would be highly beneficial if a
    Jenkins job would be capable not only of handling the main branch but all of them
    or those we select to be worth the trouble. Luckily, both of those improvements
    can be accomplished with the `Multibranch` `Workflow` plugin and `Jenkinsfile`.
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up Jenkins Multibranch Workflow and Jenkinsfile
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `Jenkins Multibranch Workflow` plugin adds a new job type that allows us
    to keep the Workflow script inside a code repository. Such a job would create
    a subproject for each branch it finds in the repository and expects to find `Jenkinsfile`
    in each of them. That allows us to keep the Workflow script inside the repository
    instead having it centralized inside Jenkins. That, in turn, enables developers
    in charge of a project full freedom to define the deployment pipeline. Since each
    branch creates a separate Jenkins project with a different Jenkinsfile, we can
    fine-tune the process depending on the type of branch. For example, we might decide
    to define a full pipeline in the Jenkinsfile residing in the master branch and
    choose to have only building and testing tasks defined for feature branches. There's
    more. Not only that Jenkins will detect all branches and keep that list updated,
    but it will also remove a subproject if a corresponding branch is removed.
  prefs: []
  type: TYPE_NORMAL
- en: Let's give Multibranch Workflow and Jenkinsfile a spin. We'll start by opening
    the `books-ms-multibranch job`. You'll see the message stating that this project
    scans branches in your SCM and generate a job for each of them, but you have no
    branches configured. Please click the `Branch Indexing` and, then, `Run Now` links
    from the left-hand menu. Jenkins will index all branches that match the filter
    we specified in the configuration. Once branches are indexed, it will create subprojects
    for each and initiate building. Let's explore the configuration of the job while
    building is in progress.
  prefs: []
  type: TYPE_NORMAL
- en: Please open the `books-ms-multibranch configuration` screen. The only important
    part of the job configuration is `Branch Sources`. We used it to define the code
    repository. Please note the **Advanced** button. When clicked, you'll see that
    only branches that contain `workflow` in their names are included. This setting
    is configured for two reasons. The first one is to demonstrate the option to filter
    which branches will be included and, the other, to save you from building too
    many branches inside the VM with such a limited capacity (the `cd` node has only
    1 CPU and 1 GB of RAM).
  prefs: []
  type: TYPE_NORMAL
- en: 'By this time, branch indexing is probably finished. If you go back to the books-ms-multibranch
    job screen, you''ll see that two subject projects matched the filter, `jenkins-workflow`
    and `jenkins-workflow-simple`, and that Jenkins initiated builds of both. Since
    the `cd` node is configured to have only one executor, the second build will wait
    until the first is finished.     Let''s take a look at the `Jenkinsfile` in those branches.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Jenkinsfile in the jenkins-workflow branch is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The script is almost the same as the one we defined earlier when we worked
    with Jenkins Workflow embedded in the Jenkins job `books-ms`. The only difference
    is that, this time, variables are defined inside the script instead of using Jenkins
    properties. Since the project team is now in full charge of the process, there
    is no need to externalize those variables. We accomplished the same result as
    before but this time we moved the script to the code repository.The `Jenkinsfile`
    in the `jenkins-workflow-simple` branch is a bit simpler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: By inspecting the script, we can conclude that the developer who made that branch
    wants to benefit from tests being run through Jenkins every time he pushes a commit.
    He removed deployment and post-deployment tests from it since the code is probably
    not ready to be deployed to production or the policy is that only the code in
    the master or other selected branches is deployed. Once he merges his code, a
    different script will be run and his changes will be deployed to production assuming
    that he didn't introduce any bugs, and the process was successful.
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of `Multibranch Workflow` and `Jenkinsfile` improved our deployment
    pipeline quite a lot. We have a utility script located in the `cd` node so that
    others can reuse common functions. From there on, we allowed every team to host
    their script inside the `Jenkinsfile` located in their repository. Moreover, we
    gave them freedom not only to decide what is the proper way to build, test, and
    deploy their services but also the flexibility to fine-tune the process based
    on each branch.
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: That was a very brief introduction to CI/CD tools and Jenkins in particular.
    Apart from the need to have a CI/CD tool, Jenkins will be one of the cornerstones
    of the next chapter. We'll use it as part of the *blue-green deployment* toolset.
    If you are new to Jenkins, I suggest you take a break from this book. Spend some
    time with it, read few tutorials and play around with different plugins. Time
    invested in Jenkins is indeed a valuable investment that will be paid off quickly.
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of Jenkins Workflow together with Docker and Multibranch plugins
    proved to be invaluable additions to our toolbelt. We are using all the power
    Jenkins UI can offer while still maintaining the flexibility that scripting provides
    for the deployment pipeline. Workflow DLS and Groovy combine the best of both
    worlds. Through Workflow domain specific language (DSL), we have syntax and functionality
    specifically tailored to serve deployment purposes. On the other hand, Groovy
    itself provides everything we might need when DSL cuts short. At the same time,
    we can access almost any functionality Jenkins offers. Docker addition to the
    Workflow provided few helpful shortcuts and Multibranch together with Jenkinsfile
    allowed us to have the pipeline (or part of it) applied to all branches (or those
    we select). All in all, we combined high level with low-level tools into one powerful
    and easy to use combination.
  prefs: []
  type: TYPE_NORMAL
- en: The way we created Jenkins jobs through Ansible was far from great. We could
    have used one of the Jenkins plugins like `Template Project Plugin` to create
    templates. However, none of them are truly great and they all suffer from some
    deficiencies. `Jenkins Enterprise Edition` from `CloudBees` does have tools that
    solve templating and many other problems. However, all the examples we used by
    now were based on open source software, and we'll continue in the same fashion
    throughout the rest of the book. That does not mean that paid solutions are not
    worth the investment. They often are and should be evaluated. If you choose to
    use Jenkins and the size of your project or organization warrants the investment,
    I recommend you evaluate `Jenkins Enterprise Edition`. It brings a lot of improvements
    over the open source version.
  prefs: []
  type: TYPE_NORMAL
- en: Given the tools we have at our disposal and the relatively uniform way to run
    our deployment steps, the current solution is probably the best we could do, and
    it is time for us to move to the next subject and explore the benefits we can
    obtain from `blue-green deployment`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we move on, let''s destroy the VMs we used in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
