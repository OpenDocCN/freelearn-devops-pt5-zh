- en: Chapter 12. Continuous Integration, Delivery and Deployment Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章。持续集成、交付和部署工具
- en: We have most of the process already automated with Ansible. Until now, we used
    playbooks to automate two types of tasks; server provisioning and configuration
    and the deployment process. While Ansible shines as a tool intended to provision
    and configure our servers, deployment (at least in our context) is not its strongest
    side. We used it mostly as a substitute for bash scripts. Most of the deployment
    tasks we have right now are using the Ansible `shell` module. We could have used
    shell scripts instead, and the result would be, more or less, the same. Ansible
    is designed to use promises as a way to ensure that the system is in the correct
    state. It does not work very well with deployments when conditionals, try/catch
    statements and other types of logic are needed. The main reason for using Ansible
    to deploy containers was avoidance to split the process into multiple commands
    (provision with ansible, run a script, provision more, run more scripts, and so
    on). The second, and more important, reason was that we did not cover CI/CD tools,
    so we used what we had. That will change very soon.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们大多数的流程已经通过Ansible自动化。直到现在，我们使用playbook来自动化两种任务：服务器的配置和准备以及部署流程。虽然Ansible作为一个工具在准备和配置服务器方面表现出色，但在部署（至少在我们的场景中）并不是它的强项。我们主要把它当作bash脚本的替代品来使用。我们现在大部分的部署任务都是使用Ansible的`shell`模块。我们本可以使用shell脚本，结果也差不多。Ansible设计时是为了使用承诺（promises）来确保系统处于正确的状态。当需要条件判断、try/catch语句或其他类型的逻辑时，它在部署时表现得并不好。我们使用Ansible来部署容器的主要原因是避免将流程拆分为多个命令（用ansible进行准备、运行脚本、再准备更多、再运行更多脚本，依此类推）。第二个也是更重要的原因是我们当时没有覆盖CI/CD工具，所以使用了现有的工具。这种情况很快就会发生变化。
- en: What are we missing in our deployment pipeline? We are using Ansible to configure
    and provision servers, and that works great. We are still looking for a better
    way to deploy software (calling Ansible `shell` module is a bit cumbersome). We
    are also missing a way to monitor the repository so that new deployments can be
    executed whenever there is a change in the code. When part of the process fails,
    we do not have a mechanism to send notifications. We are also missing visual representation
    of all our builds and deployments. The list can go on and on. What all those missing
    features have in common is that they can be easily solved with CI/CD tools. Therefore,
    we should start looking at the CI/CD platform we could use and adopt one of them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在部署流水线中缺少了什么？我们正在使用Ansible来配置和准备服务器，这部分运行得很好。我们仍在寻找一种更好的方式来部署软件（调用Ansible的`shell`模块有点繁琐）。我们也缺少一种方式来监控代码仓库，以便在代码发生变化时可以自动执行新的部署。当流程的某一部分失败时，我们没有机制发送通知。我们也缺少对所有构建和部署的可视化表示。这些问题还有很多可以继续列举。所有这些缺失的功能有一个共同点，那就是它们都可以通过CI/CD工具轻松解决。因此，我们应该开始寻找我们可以使用的CI/CD平台，并采纳其中一种。
- en: CI/CD Tools Compared
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CI/CD工具比较
- en: One way to divide CI/CD tools is to put them into cloud services and self-hosted
    solutions groups. There are a plethora of cloud services both for free and paid.
    Most of them are great for the more simplified process than the one we're trying
    to accomplish. If you have a small application consisting out of few services
    and residing on no more than a few servers, cloud solutions are excellent. I used
    many of them for my pet projects. Travis, Shippable, CircleCI and Drone.io are
    only a few of them. They will run your scripts, build your applications and services
    and pack them into containers. Most of them are neither designed nor capable of
    handling a cluster of servers especially when it is private or self-hosted. That
    is not to say that there are no cloud solutions that would fit this scenario.
    There are, but they tend to be too expensive on a large scale. With that in mind,
    we should look for self-hosted solutions.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 划分CI/CD工具的一种方式是将它们分为云服务和自托管解决方案两大类。云服务有很多，既有免费的也有付费的。它们中的大多数非常适合处理比我们当前尝试实现的更简单的流程。如果你有一个由少数服务组成的小型应用，并且它们运行在不超过几台服务器上，云解决方案非常优秀。我曾在我的个人项目中使用过许多此类服务。Travis、Shippable、CircleCI和Drone.io只是其中的几个。它们会运行你的脚本、构建你的应用和服务，并将它们打包成容器。它们大多数都没有设计或能力来处理一组服务器，特别是在私有或自托管环境下。并不是说没有适合这种场景的云解决方案，确实有，但它们在大规模使用时通常成本过高。考虑到这一点，我们应该寻找自托管解决方案。
- en: There's a hell of a lot of self-hosted CI/CD tools, ranging from free offerings
    all the way to very expensive ones. Some of the commonly used self-hosted CI/CD
    tools like Jenkins, Bamboo, GoCD, Team City and Electric Cloud are only a few
    among many others. All of them have their strengths and weaknesses. However, Jenkins
    sticks out from the crowd thanks to its community. No other tool has such a big
    number of people contributing on a daily basis. It has an excellent support and,
    through its plugins, it can be extended to do almost anything we might need. You
    will hardly find yourself in a need of something that is not already covered with
    one or more plugins. Even if you find a use case that is not covered, writing
    your own plugin (and hopefully making it public for others to use) is a very easy
    thing to do. Community and plugins are its greatest strength that makes it more
    widely adopted than any other tool.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: The chances are that you already used Jenkins, or, at least, heard of it. One
    of the main reasons companies are choosing some other tool (especially Bamboo
    and Team City) are their enterprise offerings. When an organization becomes big,
    it needs support and reliability that comes with it. It needs those extra features
    and know-how that enterprise offerings provide. Cloud Bees is one such company
    formed recently. They offer Jenkins Enterprise version and have an excellent support
    capable of handling almost any scenario related to continuous integration, delivery
    or deployment. They have the community version of Jenkins that can be obtained
    for free but also offer paid enterprise features and support. That is another
    reason one should choose Jenkins. No other tool (at least among those previously
    mentioned) has fully free tool and, at the same time, offers paid support and
    additional features. Team City can be downloaded for free but has a limited number
    of agents. GoCD is free but it doesn't provide any support. Bamboo is similar
    to Team City regarding limitations imposed on the free version. By choosing Jenkins,
    we are choosing battle tested and most widely used tool supported by a vast community
    that has, if such a need arises, paid support and features through CloudBees.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While writing this book, I chose to join the CloudBees team (the company behind
    Enterprise Jenkins). The decision to promote Jenkins throughout this book was
    not based on my employment in CloudBees. It's the other way around. I chose to
    join them because I believe that Jenkins is the best CI/CD tool in the market.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: The Short History of CI/CD Tools
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Jenkins (forked from Hudson after a dispute with Oracle) has been around for
    a long time and established itself as the leading platform for the creation of
    **continuous integration** (**CI**) and **continuous delivery/deployment** (**CD**)
    pipelines. The idea behind it is that we should create jobs that perform operations
    like building, testing, deploying, and so on. Those jobs should be chained together
    to create a CI/CD pipeline. The success was so big that other products followed
    its lead and we got Bamboo, Team City, and others. They all used a similar logic
    of having jobs and chaining them together. Operations, maintenance, monitoring,
    and the creation of jobs is mostly done through their UIs. However, none of the
    other products managed to suppress Jenkins due to its strong community support.
    There are over one thousand plugins, and one would have a hard time imagining
    a task that is not supported by, at least, one of them. The support, flexibility,
    and extensibility featured by Jenkins allowed it to maintain its reign as the
    most popular and widely used CI/CD tool throughout all this time. The approach
    based on heavy usage of UIs can be considered the first generation of CI/CD tools
    (even though there were others before).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Jenkins（在与甲骨文的争执后从 Hudson 分叉出来）已经存在很长时间，并且确立了自己作为创建**持续集成**（**CI**）和**持续交付/部署**（**CD**）管道的领先平台。其背后的理念是我们应该创建执行诸如构建、测试、部署等操作的工作任务。这些任务应当相互连接，以创建一个
    CI/CD 管道。它的成功如此巨大，以至于其他产品纷纷效仿，产生了 Bamboo、Team City 等。它们都采用了类似的逻辑，即拥有任务并将它们连接起来。操作、维护、监控和创建任务主要通过它们的用户界面（UI）来完成。然而，其他产品并未能够压倒
    Jenkins，主要是由于其强大的社区支持。Jenkins 拥有超过一千个插件，可以说很难想象有哪项任务不被至少一个插件支持。Jenkins 所具备的支持、灵活性和可扩展性使得它能够保持作为最受欢迎且广泛使用的
    CI/CD 工具的地位。基于大量使用用户界面的方式可以被认为是第一代 CI/CD 工具（尽管在此之前也有其他工具）。
- en: With time, new products come into being and, with them, new approaches were
    born. Travis, CircleCI, and the like, moved the process to the cloud and based
    themselves on auto-discovery and, mostly YML, configurations that reside in the
    same repository as the code that should be moved through the pipeline. The idea
    was good and provided quite a refreshment. Instead of defining your jobs in a
    centralized location, those tools would inspect your code and act depending on
    the type of the project. If, for example, they find `build.gradle` file, they
    would assume that your project should be tested and built using Gradle. As the
    result, they would run `gradle check` to test your code and, if tests passed,
    follow it by `gradle assemble` to produce the artifacts. We can consider those
    products to be the second generation of CI/CD tools.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，新的产品应运而生，并且随着它们也诞生了新的方法。Travis、CircleCI 等工具将过程迁移到云端，并且依赖于自动发现以及主要基于
    YML 的配置，这些配置与需要在管道中移动的代码存储在同一个代码库中。这一理念非常不错，也带来了很大的清新感。与其在集中位置定义你的任务，这些工具会检查你的代码并根据项目的类型采取相应的行动。例如，如果它们发现
    `build.gradle` 文件，它们会假设你的项目应该使用 Gradle 进行测试和构建。作为结果，它们会运行 `gradle check` 来测试代码，如果测试通过，接着运行
    `gradle assemble` 来生成构件。我们可以认为这些产品是 CI/CD 工具的第二代。
- en: The first and the second generation of tools suffer from different problems.
    Jenkins and the like feature power and flexibility that allow us to create custom
    tailored pipelines that can handle almost any level of complexity. This power
    comes with a price. When you have tens of jobs, their maintenance is quite easy.
    However, when that number increases to hundreds, managing them can become quite
    tedious and time demanding.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 第一代和第二代工具各自存在不同的问题。像 Jenkins 这样的工具具有强大的功能和灵活性，使得我们能够创建量身定制的管道，处理几乎任何复杂度的任务。这种强大带来了代价。当你有几十个任务时，维护起来相对简单。然而，当数量增加到数百个时，管理它们可能变得相当繁琐且耗时。
- en: Let's say that an average pipeline has five jobs (building, pre-deployment testing,
    deployment to a staging environment, post-deployment testing, and deployment to
    production). In reality, there are often more than five jobs but let's keep it
    an optimistic estimate. If we multiply those jobs with, let's say, twenty pipelines
    belonging to twenty different projects, the total number reaches one hundred.
    Now, imagine that we need to change all those jobs from, let's say, Maven to Gradle.
    We can choose to start modifying them through the Jenkins UI or be brave and apply
    changes directly in Jenkins XML files that represent those jobs. Either way, this,
    seemingly simple, change would require quite some dedication. Moreover, due to
    its nature, everything is centralized in one location making it hard for teams
    to manage jobs belonging to their projects. Besides, project specific configurations
    and code belong to the same repository where the rest of application code resides
    and not in some central location. And Jenkins is not alone with this problem.
    Most of the other self-hosted tools have it as well. It comes from the era when
    heavy centralization and horizontal division of tasks was thought to be a good
    idea. At approximately the same time, we felt that UIs should solve most of the
    problems. Today, we know that many of the types of tasks are easier to define
    and maintain as code, than through some UI.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: I remember the days when Dreamweaver was big. That was around the end of the
    nineties and the beginning of year two thousand (bear in mind that at that time
    Dreamweaver was quite different than today). It looked like a dream come true
    (hence the name?). I could create a whole web page with my mouse. Drag and drop
    a widget, select few options, write a label, repeat. We could create things very
    fast. What was not so obvious at that time was that the result was a loan that
    would need to be paid with interests. The code Dreamweaver created for us was
    anything but maintainable. As a matter a fact, sometimes it was easier to start
    over than modify pages created with it. That was especially true when we had to
    do something not included in one of its widgets. It was a nightmare. Today, almost
    no one writes HTML and JavaScript by using drag & drop tools. We write the code
    ourselves instead of relying on other tools to write it for us. There are plenty
    of other examples. For example, Oracle ESB, at least in its infancy, was similarly
    wrong. Drag & drop was not a thing to rely on (but good for sales). That does
    not mean that GUIs are not used any more. They are, but for very specific purposes.
    A web designer might rely on drag & drop before passing the result to a coder.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: What I'm trying to say is that different approaches belong to different contexts
    and types of tasks. Jenkins and similar tools benefit greatly from their UIs for
    monitoring and visual representations of statuses. The part it fails with is the
    creation and maintenance of jobs. That type of tasks would be much better done
    through code. With Jenkins, we had the power but needed to pay the price for it
    in the form of maintenance effort.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是，不同的方法适用于不同的情境和任务类型。Jenkins及类似工具通过其用户界面（UI）在监控和状态可视化方面提供了极大的便利。它的不足之处在于作业的创建和维护。这类任务通过代码来完成会更为高效。使用Jenkins时，我们拥有强大的功能，但也必须为此付出维护的代价。
- en: The second generation of CI/CD tools (Travis, CircleCI, and the like) reduced
    that maintenance problem to an almost negligible effort. In many cases, there
    is nothing to be done since they will discover the type of the project and do
    the right thing. In some other cases, we have to write a `travis.yml`, a `circle.yml`,
    or a similar file, to give the tool additional instructions. Even in such a case,
    that file tends to have only a few lines of specifications and resides together
    with the code thus making it easy for the project team to manage it. However,
    these tools do not replace the first generation since they tend to work well only
    on small projects with a very simple pipeline. The real continuous delivery/deployment
    pipeline is much more complex than what those tools are capable of. In other words,
    we gained low maintenance but lost the power and, in many cases, flexibility.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 第二代CI/CD工具（如Travis、CircleCI等）将维护问题降到了几乎可以忽略不计的程度。在许多情况下，几乎无需做任何事情，因为它们会自动识别项目类型并执行正确的操作。在其他一些情况下，我们需要编写一个`travis.yml`、`circle.yml`或类似的文件，为工具提供额外的指令。即便是这种情况，该文件通常也只有几行配置，并且与代码一起存放，便于项目团队进行管理。然而，这些工具并没有取代第一代工具，因为它们通常只在小型项目和非常简单的管道上表现良好。真正的持续交付/部署管道远比这些工具所能处理的要复杂。换句话说，我们获得了低维护，但失去了力量，而且在许多情况下，灵活性也受到了影响。
- en: Today, old-timers like Jenkins, Bamboo, and Team City, continue dominating the
    market and are recommended tools to use for anything but small projects. At the
    same time, cloud tools like Travis and CircleCI dominate smaller settings. The
    team maintaining Jenkins codebase recognized the need to introduce a few significant
    improvements that will bring it to the next level by combining the best of both
    generations, and some more. I'll call that change the third generation of CI/CD
    tools. They introduced Jenkins Workflow and *Jenkinsfile*. Together, they bring
    some very useful and powerful features. With Jenkins Workflow, we can write a
    whole pipeline using Groovy-based DSL. The process can be written as a single
    script that utilizes most of the existing Jenkins features. The result is an enormous
    reduction in code (Workflow scripts are much smaller than traditional Jenkins
    job definitions in XML) and reduction in jobs (one Workflow job can substitute
    many traditional Jenkins jobs). That results in much easier management and maintenance.
    On the other hand, newly introduced Jenkinsfile allows us to define the Workflow
    script inside the repository together with the code. That means that developers
    in charge of the project can be in control of the CI/CD pipeline as well. That
    way, responsibilities are much better divided. Overall Jenkins management is centralized
    while individual CI/CD pipelines are placed where they belong (together with the
    code that should be moved through it). Moreover, if we combine all that with the
    *Multibranch Workflow* job type, we can even fine tune the pipeline depending
    on the branch. For example, we might have the full process defined in the Jenkinsfile
    residing in the `master` branch and shorter flows in each feature branch. What
    is put into each Jenkinsfile is up to those maintaining each repository/branch.
    With the *Multibranch Workflow* job, Jenkins will create jobs whenever a new branch
    is created and run whatever is defined in the file. Similarly, it will remove
    jobs when branches are removed. Finally, *Docker Workflow* has been introduced
    as well, making Docker the first class citizen in Jenkins.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Jenkins has a long history that led it to the Pipeline plugin. There was the
    Build Pipeline plugin that provided visualizations for connected jobs, then came
    the Build Flow plugin that introduced the concept of Groovy DSL as a way to define
    Jenkins jobs. The latter hit many obstacles that led its authors to start over
    and create the Workflow plugin, only to rename it, later on, into the Pipeline
    plugin.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: All those improvements brought Jenkins to a whole new level confirming its supremacy
    among CI/CD platforms.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: If even more is needed, there is the CloudBees Jenkins Platform - Enterprise
    Edition that provides fantastic features, especially when we need to run Jenkins
    at scale.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Workflow authors decided to rename the plugin into Pipeline. However, at this
    moment, not all the source code has been renamed and there are references to both
    pipeline and workflow. For consistency, and to avoid possible failures, I chose
    to stick with the old name and use the word Workflow throughout the book. The
    change is only semantic and does not introduce any functional changes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流作者决定将插件重命名为 Pipeline。然而，目前并非所有源代码都已被重命名，并且同时存在对 pipeline 和 workflow 的引用。为了保持一致性，并避免可能的失败，我选择坚持使用旧名称，并在整本书中使用
    Workflow 一词。这个变化只是语义上的，并没有引入任何功能上的变化。
- en: Jenkins
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Jenkins
- en: Jenkins shines with its plugins. There are so many of them that it would be
    hard to find something we'd like to accomplish that is not already covered with
    at least one plugin. Want to connect to a code repository? There is a plugin.
    Want to send notifications to Slack? There is a plugin. Want to parse logs using
    your formulas? There is a plugin.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Jenkins 通过其插件表现出色。它的插件种类繁多，以至于很难找到任何我们想要实现的功能，而这些功能没有被至少一个插件覆盖。想连接到代码仓库？有插件。想向
    Slack 发送通知？有插件。想用自己的公式解析日志？有插件。
- en: Being able to choose from so many plugins is a double edged sword. People tend
    to abuse it and install plugins for many more things than its needed. One example
    would be the Ansible plugin.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 能够从如此多的插件中进行选择是把双刃剑。人们往往滥用它，安装比实际需要更多的插件。一个例子就是 Ansible 插件。
- en: 'We can select it as a build step and fill in the fields like **Playbook path**,
    **Inventory**, **Tags to skip**, **Additional parameters** and so on. The screen
    could look like the one presented in the figure 12-01:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其选择为构建步骤，并填写如 **Playbook 路径**、**库存**、**跳过的标签**、**附加参数** 等字段。屏幕可能会显示如图 12-01
    所示的界面：
- en: '![Jenkins](img/B05848_12_01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![Jenkins](img/B05848_12_01.jpg)'
- en: Figure 12-01 – Ansible plugin used inside a Jenkins job
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12-01 – 在 Jenkins 作业中使用的 Ansible 插件
- en: 'Alternative to the Ansible plugin would be just to use the **Execute Shell**
    build step (part of the Jenkins core) and put the command we''d like to run. We
    wrote the automation ourselves and are familiar with commands that should be run.
    By using those same commands there are fewer fields to be filled or ignored, we
    know what will be run and can use those same commands as a reference if the same
    process should be repeated outside of Jenkins:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Ansible 插件的替代方案是直接使用 **执行 Shell** 构建步骤（Jenkins 核心的一部分），并放入我们想要执行的命令。我们自己编写了自动化脚本，并熟悉应该执行的命令。通过使用相同的命令，字段需要填写或忽略的部分更少，我们知道将要执行的内容，并且可以将这些命令作为参考，如果同样的过程需要在
    Jenkins 之外重复执行：
- en: '![Jenkins](img/B05848_12_02.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![Jenkins](img/B05848_12_02.jpg)'
- en: Figure 12-02 – Running Ansible playbook as a shell command
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12-02 – 将 Ansible playbook 作为 Shell 命令运行
- en: In many cases, automation should be something done outside Jenkins (or any other
    CI/CD tool). From there on, all we have to do is tell Jenkins which script to
    run. That script can be in the repository together with the code of the service
    we are deploying (for example `deploy.sh`) or, as in our case, be generalized
    through few naming conventions and used for all services. No matter the way automation
    scripts are organized, in most cases the best and the easiest way to use them
    inside Jenkins is to just run the command associated with those scripts. That
    held true until recently. Now, with the addition of Jenkinsfile, we can follow
    the same logic of creating project specific scripts and keeping them in the project
    repository. The additional benefit it brings is that we can utilize Jenkins specific
    features inside the Workflow script residing in the Jenkinsfile. If you need to
    run something on a particular node, there is a module for it. If you need to use
    authentication stored in Jenkins, there is a module for it. The list goes on and
    on, but the gist is that with Jenkinsfile and the Workflow we can continue relying
    on scripts residing inside the code repository and, at the same time, utilize
    advanced Jenkins features.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，自动化应该在 Jenkins（或任何其他 CI/CD 工具）之外完成。从那时起，我们要做的就是告诉 Jenkins 运行哪个脚本。这个脚本可以与我们要部署的服务代码一起存储在代码库中（例如
    `deploy.sh`），或者像我们这次做的那样，通过一些命名约定进行通用化，并供所有服务使用。无论自动化脚本如何组织，通常在 Jenkins 中使用它们的最好、最简单的方法，就是直接运行与这些脚本相关的命令。这个方法一直适用，直到最近。现在，随着
    Jenkinsfile 的加入，我们可以继续按照相同的逻辑创建项目特定的脚本并将其保存在项目库中。它带来的附加好处是，我们可以在 Jenkinsfile 中的
    Workflow 脚本内使用 Jenkins 特有的功能。如果你需要在某个特定节点上运行某些操作，有一个模块可以使用。如果你需要使用存储在 Jenkins
    中的认证信息，也有相应的模块。功能的清单一长串，但核心要点是，通过 Jenkinsfile 和 Workflow，我们可以继续依赖存放在代码库中的脚本，同时利用
    Jenkins 的高级功能。
- en: The time has come to get our hands dirty and set up Jenkins.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候亲自动手设置 Jenkins 了。
- en: Setting Up Jenkins
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置 Jenkins
- en: 'As always, we''ll start by creating virtual machines that we''ll use for our
    exploration of Jenkins. We''ll create the `cd` node that will host our Jenkins
    server as well as Ansible playbooks that we''ll run through it:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我们将首先创建虚拟机，用于探索 Jenkins。我们将创建 `cd` 节点，作为承载 Jenkins 服务器以及我们将通过其运行的 Ansible
    playbook 的平台：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once both servers are up and running, we can proceed and provision the `prod`
    node in the same way as we did before:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦两台服务器都启动并运行，我们就可以继续像之前一样配置 `prod` 节点：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now we are ready to bring up Jenkins. Setting up the basic installation is
    very easy with Docker. All we have to do is run a container with a few arguments:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好启动 Jenkins。通过 Docker 设置基础安装非常简单。我们只需要运行一个带有几个参数的容器：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Docker detected that there is no local copy of the Jenkins container and started
    pulling it from the Docker Hub. Once pulling is done, we'll have a running instance
    that exposes the port 8080 and shares a few volumes. The `/var/jenkins_home` directory
    contains all Jenkins configuration. It is handy to have it shared for the sake
    of configuration management that we'll explore soon. We gave full permissions
    (0777) to that directory in the host since the container processes run as the
    `jenkins` user that does not exist in our system. It's not a good solution security-wise,
    but it should do for now. The second shared directory is `/machines` that is mapped
    to the host's directory `/vagrant/.vagrant/machines`. That's the location where
    Vagrant keeps all SSH keys that we'll need to set up Jenkins nodes on which the
    actual jobs will be run. Please note that, if you'd run this on production servers,
    you should generate keys with `ssh-copy-id` and share them instead of those generated
    by Vagrant.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 检测到本地没有 Jenkins 容器的副本，并开始从 Docker Hub 拉取它。拉取完成后，我们将拥有一个正在运行的实例，它会暴露 8080
    端口并共享几个卷。`/var/jenkins_home` 目录包含所有 Jenkins 配置。为了配置管理的方便，我们将它共享出来，稍后会详细讲解。由于容器中的进程作为
    `jenkins` 用户运行，而这个用户在我们的系统中不存在，我们为主机上的该目录赋予了完全权限（0777）。从安全角度来看，这不是一个好解决方案，但目前应该足够用了。第二个共享目录是
    `/machines`，它映射到主机的 `/vagrant/.vagrant/machines` 目录。这里是 Vagrant 存储所有 SSH 密钥的位置，稍后我们将需要这些密钥来配置
    Jenkins 节点，在这些节点上将执行实际的作业。请注意，如果你在生产服务器上运行这个操作，你应该使用 `ssh-copy-id` 生成密钥并共享，而不是使用
    Vagrant 生成的密钥。
- en: 'Once the Jenkins container is going, we can open `http:/` `/10.100.198.200:8080`
    and explore the GUI:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 Jenkins 容器启动，我们可以打开 `http:/` `/10.100.198.200:8080` 并浏览图形界面：
- en: '![Setting Up Jenkins](img/B05848_12_03.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![设置 Jenkins](img/B05848_12_03.jpg)'
- en: Figure 12-03 – Jenkins home screen after the standard installation
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: If this is the first time you are in front of Jenkins, please take a break from
    this book and spend some time getting familiar with it. Its GUI is very intuitive,
    and there are a lot of online sources that will help you get a basic understanding
    of how it works. We are about to dive into automation of Jenkins administration.
    Even though we won't use the GUI for that, understanding how it works visually
    will help you understand better the tasks we are about to perform. Take your time
    with it and, once you feel comfortable, return here for more.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Most people I know use Jenkins exclusively through its GUI. Some might use its
    API to run jobs or automate some basic operations. And that's fine, for a while.
    You start by installing a few plugins, create a few jobs and feel great for accomplishing
    a lot very quickly. With time, the number of jobs increases and with them the
    maintenance effort. It is not uncommon to have tens, hundreds or even thousands
    of jobs defined and running periodically or being triggered by some events (for
    example code commit). Administrating all those jobs through the GUI is hard and
    time demanding. Imagine, for instance, that you want to add Slack notifications
    to all jobs. Modifying jobs one by one is not a good option when there's a significant
    number of them.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different ways we can tackle the problem of Jenkins automation that
    is, primarily, focused on creation and maintenance of its jobs. One approach would
    be to use some of the Jenkins plugins that could help us out. A few of those are
    Job DSL and Job Generator plugins. We''ll take a different approach. All Jenkins
    settings are stored as XML files located in the `/var/jenkins_home directory`
    (we exposed it as a Docker volume). We can simply add new files or modify existing
    ones when we need to change some Jenkins behavior. Since we are already familiar
    with Ansible, we can continue using it as a tool to not only install but also
    maintain Jenkins. In that spirit, we''ll remove the current Jenkins installation
    and start over with Ansible:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We removed the Jenkins container and deleted the directory we exposed as a volume.
    Now we can install it and configure it through Ansible.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up Jenkins with Ansible
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Setting up Jenkins with Ansible is easy even though the role we''ll use has
    few complications we haven''t encountered previously. Since it will take a few
    minutes for the playbook to finish executing, let''s run it first and discuss
    its definition while waiting for it to finish:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'First we set up Jenkins nodes that we''ll use later on. It should not take
    long to execute the first playbook since all it has to do is make sure that JDK
    is installed (required by Jenkins, to be able to connect to a node) and that the
    single directory `/data/jenkins_slaves`. Jenkins will use that directory to store
    files when executing processes on those nodes. The `jenkins` role is in the `jenkins.yml`
    playbook is a bit longer and will be worthwhile spending some time with. Let''s
    explore it in more details. The `jenkins.yml` playbook is as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: It installs Consul Template that we're already familiar with so we'll move straight
    to the `roles/jenkins` role. The tasks are defined in the `roles` `/jenkins/tasks/main.yml`
    file and we'll go through them one by one.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: 'The first task creates directories that we''ll need. As before, variables are
    defined in the `roles/jenkins/defaults/main.yml`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'With directories created, we can run the jenkins container. Even though it
    takes no time for the container to start running, Jenkins itself requires a bit
    of patience until it is fully operational. Later on, we''ll be issuing some commands
    to Jenkins API, so we''ll have to pause the playbook, for, let''s say, half a
    minute, to be sure that Jenkins is operational. At the same time, this gives us
    the opportunity to see `pause` module in action (even though it should be rarely
    used). Please notice that we are registering the variable `container_result` and,
    later on, pausing so that Jenkins application inside the container is fully operational
    before proceeding with the rest of tasks. This pause is performed if the state
    of the Jenkins container changed:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next we should copy a few configuration files. We''ll start with `roles/jenkins/files/credentials.xml`,
    followed by few nodes (`roles/jen` `ki` `ns/files/cd_config.xml`, `roles/jenki`
    `ns/files/prod_config.xml`, and so on) and a several other less important configurations.
    Feel free to see contents of those files. At the moment, it is only important
    to understand that we need those configurations:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Next, we should make sure that several plugins are installed. Since our code
    is in GitHub, we'll need the `Git Plugin`. Another useful plugin that we'll use
    is the `Log Parser`. Since Ansible logs are quite big, we'll use this plugin to
    break them into more manageable pieces. Few other plugins will be installed as
    well, and we'll discuss each of them when the time comes to use them.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Most people tend just to download plugins they need. Even the official Jenkins
    container that we are using has a way to specify which plugins to download. However,
    that approach is very dangerous since we'd need to define not only plugins we
    need but also their dependencies, dependencies of those dependencies and so on.
    It would be easy to forget one of them or specify a wrong dependency. If such
    a thing happens, at best, the plugin we wanted to use would not work. In some
    cases, even the whole Jenkins server could stop functioning. We'll take a different
    approach. Plugins can be installed by sending an HTTP request to `/pluginManager/installNecessaryPlugins`
    with XML in the body. Jenkins, upon receiving the request will download both the
    plugin we specify and its dependencies. Since we don't want to send the request
    if the plugin is already installed, we'll use the `creates` instruction specifying
    the path to the plugin. If the plugin exists, the task will not be run.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 'Most plugins require a restart of the application, so we''ll restart the container
    if any of the plugins was added. Since the request to install a plugin is asynchronous,
    first we''ll have to wait until plugin directory is created (Jenkins unpacks plugins
    into directories with the same name). Once it is confirmed that all plugins are
    installed, we''ll restart Jenkins and wait (again) for some time before it is
    fully operational. In other words, we send requests to Jenkins to install plugins
    and, if they are not already installed, wait until Jenkins is finished with installations,
    restart the container so that new plugins are used and wait for a while until
    the restart is finished:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now we are ready to create jobs. Since all of them will work in (more or less)
    the same way, we can use a single template that will serve for all our jobs related
    with service deployments. We need to create a separate directory for each job,
    apply the template, copy the result to the destination server and, finally, if
    any of the jobs changed, reload Jenkins. Unlike plugins that require a full restart,
    Jenkins will start using new jobs after the reload which is a very fast (almost
    instantaneous) action:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the future, if we'd like to add more jobs, all we'd need to do is add more
    entries to the `jobs` variable. With a system like that, we can easily create
    as many Jenkins jobs as there are services with almost no effort. Not only that
    but, if jobs need to be updated, all we'd need to do is change the template and
    re-run the playbook, and the changes would be propagated to all the jobs in charge
    of building, testing and deploying our services.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: 'The `jo` `bs` variable defined in the `role` `s/jenkins/defaults/main.yml`
    file is as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The `name` and `service_name` values should be easy to understand. They represent
    the name of the job and the name of the service. The third value is the source
    template we''ll use to create the job configuration:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let's take a look at the `roles/jenkins/templates` `/service-ansible-config.xml`
    template.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'It is a relatively big XML definition of a Jenkins job. I created it manually
    through the GUI, copied the file and replaced values with variables. One of the
    key entries is the one that tells Jenkins the location of the code repository:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As you can see, we are, again, using naming conventions. The name of the repository
    is the same as the name of the service and will be replaced with the value of
    the variable we saw earlier.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'The second entry is the one that executes the command that runs Ansible playbook
    and builds, packages, tests and deploys the service:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see, we're running the same Ansible playbook that we created in the
    previous chapter.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the last task in the `jenkins` role is as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: It copies scripts to the `/data` directory. We'll explore those scripts later
    on.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: The Ansible role `jenkins` is a good example of a more complicated use case.
    Until this chapter, most of the provisioning and configurations we did with Ansible
    were much simpler. In most instances we would update APT repository, install a
    package and, maybe, copy some configuration file. In some other cases, we would
    only run a Docker container. There were many other cases but, in the essence,
    they were all very simple since none of the other tools required much configuration.
    Jenkins was quite different. Besides running a container, we had to create quite
    a quite a few configuration files, install several plugins, create some jobs,
    and so on. As an alternative, we could (and probably should) have created our
    container that would have everything but jobs inside it. That would simplify the
    setup and, at the same time, provide a more reliable solution. However, I wanted
    to show you a bit more complicated Ansible process.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: I'll leave the creation of a custom Jenkins image as an exercise. The image
    should contain everything but jobs inside it. Create a Dockerfile, build and push
    the image to Docker Hub and modify Ansible role `jenkins` so that the new container
    is used. It should share volumes with SSH keys and jobs so that they can be updated
    from outside a container.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Running Jenkins Jobs
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By now, the Ansible playbook we run earlier should have finished the execution.
    Not only that Jenkins is up and running, but the `books-ms` job is created and
    waiting for us to use it.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the Jenkins GUI. Please open `http://10.100.198.200:8080`.
    You''ll see the home page with a few jobs. The one we''ll be exploring first is
    the `book-ms-ansible` job. In a different situation, our code repository would
    trigger a request to Jenkins to execute the build. However, since we''re using
    public GitHub repo and this Jenkins instance is (probably) running on your laptop
    and is not accessible from a public network, we''ll have to execute the job manually.
    Let''s click the **Schedule a build for books-ms-ansible** button (icon with a
    clock and play arrow). You''ll see that the first build of the `books-ms-ansible`
    job is running on the `cd` node located in the left-hand side of the screen:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '![Running Jenkins Jobs](img/B05848_12_04.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
- en: Figure 12-04 – Jenkins home screen with a few jobs
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Let's click the `books-ms-ansible` job, then click `#1` link inside the `Build
    History` and, finally, the `Console Output`. The same can be accomplished by opening
    the `http://10.100.198.200:8080/job/book` `s-ms-ansible/lastBuild/console` URL.
    You will be presented with the output of the last build of that job. As you probably
    noticed, the log is a bit big and it would be hard to find information about a
    particular task. Luckily, we installed the `Log Parser` plugin that can help us
    drill through logs easier. But, first things first, we need to wait until the
    build is finished. We'll use that time wisely and explore the job configuration.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Please go back to the `books-ms-ansible` job main screen and click the `Configure`
    link located in the left-hand menu (or open the link `http://10.100.198.200:8080/`
    `job/books-ms-ansible/configure`).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: The `books-ms-ansible` is a very simple job and yet, in most cases, we won't
    need anything more complicated if our automation scripts are done correctly (with
    or without Ansible). You'll see that the job is restricted to the `cd` node meaning
    that it can run only on servers named or labeled `cd`. That way we can control
    which jobs are run on which servers. Part of the Jenkins setup was to create one
    node called `cd`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: The *Source Code Management* section has the reference to the GitHub repository.
    Please note that we are missing a trigger that will run this job whenever there
    is a new commit. That can be accomplished in a variety of ways. We could set `Build
    Trigger` to `Poll SCM` and schedule it to run periodically (let's say every 10
    seconds). Please note that the scheduling format uses the `cron` syntax. In such
    a case, Jenkins would regularly check the repository and, if anything changed
    (if there was a commit), it would run the job. A better way would be to create
    a `webhook` directly in the repository. That hook would invoke a Jenkins build
    on every commit. In such a case, the build would start running almost instantaneously
    after the commit. At the same time, there would be no overhead created by jobs
    periodically checking the repository. However, this approach would require Jenkins
    being accessible from the repository (in this case GitHub) and we are currently
    running Jenkins inside a private network. We choose neither since it is very unlikely
    that there will be a commit to the `books-ms` repository while you are reading
    this book. It is up to you to investigate different ways to trigger this job.
    We'll simulate the same process by running builds manually. No matter the way
    the job is run, the first thing it will do is clone the repository using information
    provided in the *Source Code Management* section.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Now we reached the main part of the job; the **Build** section. I already mentioned
    that we could have used the **Ansible** plugin to help us run the playbook. However,
    the command we should run is so simple that using a plugin would only introduce
    additional complications. Inside the **Build** section, we have the `Execute shell`
    step that runs the `service.yml` playbook is the same way as we run it manually.
    We are using Jenkins only as a tool to detect changes to the code repository and
    run the same commands we would run without it.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '![Running Jenkins Jobs](img/B05848_12_05.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
- en: Figure 12-05 – Jenkins books-ms-ansible job configuration screen
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we have the `Console output (build log) parsing` set as the `Post-build
    actions` step. It parses (in this case) Ansible logs so that they are displayed
    in a more user-friendly fashion. By this time, the execution of the build probably
    finished, and we can take a look at the parsed log.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Go back to the build `#1` of the `books-ms` job and click the `Parsed Console
    Output` link in the left-hand menu or open the URL `http://10.100.198.200:8080/job/books-ms-a`
    `nsible/lastBuild/parsed_console/`. Under the section `Info`, you'll see each
    Ansible task separated and can click any of them to jump to the part of the output
    related to that task. If there were some problems during the execution, they would
    appear under the link `Error`. We won't go into details how the `Log Parser` plugin
    works. I included it into this job mostly as a demonstration of the power Jenkins
    provides through its plugins. There's over a thousand of them available and new
    ones coming. Plugins are probably the main advantage Jenkins has over other CI/CD
    tools. There is such a big community behind them that you can rest assured that
    almost any need you have is (probably) covered. Even better, just by exploring
    available plugins, you will get new ideas.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Even though this job fulfills all the essential purposes required to deploy
    the service (checkout the code and run the Ansible playbook), there are a few
    additional tasks we could add to the job. Probably the most interesting thing
    we could do is add notifications in case of a job failure. That can be an email
    message, Slack notification or (almost) any other type of notification we're used
    to. I'll leave that part to you as an exercise. Spend some time checking out plugins
    that would help to send notifications, select one and install it. The **Manage
    Plugins** screen can be accessed by clicking the `Manage Jenkins` located in the
    left-hand menu on the home screen. As an alternative, the same screen can be accessed
    by opening the URL `http://10.100.198.200:8080/pluginManager/`. Once inside, follow
    plugin instructions and add it to the `books-ms-ansible` job. Once you're comfortable
    with it, try to do the same through Ansible. Add the new plugin to the `plugins`
    variable and put the required entries to the `service-ansible-config.xml` template.
    The easiest way to do that is to apply the changes through the UI, and then check
    the changes Jenkins did to the `/data/jenkins/jobs/books-ms-ansible/conf` `ig.xml`
    file in the `cd` node.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up Jenkins Workflow Jobs
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Is there a better way to structure a job that will deploy the `books-ms` service?
    What we have right now is a job consisting of multiple steps. One step checks
    out the code while the another runs the Ansible script. We specified that it should
    run on the `cd` node and did few more minor steps. Notifications are missing at
    the moment (unless you implemented them yourself) and they would be another step
    in the job. Each step is a separate plugin. Some of them are distributed with
    Jenkins core while others were added by us. With time, the number of steps might
    increase considerably. At the same time, while Ansible is great for provisioning
    and configuring servers when used as a tool to build, test and deploy services,
    it proved to be a bit cumbersome and lacking some of the features that could be
    done easier with a simple bash script.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, bash scripts lack some of the characteristics Ansible has.
    For example, Ansible is much better at running commands in remote locations. The
    third option would be to move the deployment process to traditional Jenkins jobs.
    That would also not be a great solution. We'd end up with quite a few jobs that
    would probably run bash scripts as well. One job would do pre-deployment tasks
    on the `cd` node, another would be in charge of deployment in the `prod` node,
    and we'd need a third one that would execute post-deployment steps in the `cd`
    node. As a minimum, we would have three chained jobs. More likely, there would
    be more. Maintaining many jobs is time-demanding and complicated at best.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: We can utilize Jenkins' `Workflow Plugin` to write a script that does all the
    steps for us. We can use it as an alternative to deployment we're currently doing
    with Ansible. We already discussed that Ansible shines at servers provisioning
    and configuration, but the deployment part could be improved. The Workflow plugin
    allows us to script the whole job. This feature in itself is a great way to continue
    relying heavily on automation. That is especially true since Jenkins XML is very
    cumbersome and hard to write and read. It is enough to take a look at the `service-ansible-config.xml`
    that we used to define a simple job that deploys our services. Jenkins XML is
    cryptic and with a lot of boilerplate definitions, Ansible is not designed to
    be used with conditionals nor it has a decent substitute for try/catch statements
    and bash scripts are just an extra layer of complexity. It is true that, at this
    point, our process is complicated, and we should strive to keep things as simple
    as possible without sacrificing the goals we set in front of us.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Let's give Workflow plugin a go and see whether it can help. We'll combine it
    with the `CloudBees Docker Workflow Plugin`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll begin by taking a look at the configuration of the `books-ms` job. We
    can navigate through the Jenkins UI all the way to the job settings screen or
    simply open the `http://10.100.1` `98.200:8080/job/books-ms/configure` URL:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Jenkins Workflow Jobs](img/B05848_12_06.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
- en: Figure 12-06 – Configuration screen of the books-ms Jenkins workflow job
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: 'Once inside the `books-ms` configuration, you''ll notice that the whole job
    consists only of a few parameters and the workflow script. Unlike regular jobs,
    workflow allows us to script (almost) everything. That, in turn, makes managing
    Jenkins jobs much easier. The `roles/je` `nkins/templates/service-flow.groovy`
    script we''re using is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The script starts with the node definition telling Jenkins that all the instructions
    should be run on the `cd` node.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: The first instruction inside the node is to check out the code from the Git
    repository. The `git` module is one of the examples of the DSL created for the
    Jenkins Workflow. This instruction uses the `serviceName` parameter defined in
    the Jenkins job.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Next, we're using the `load` instruction that will include all the utility functions
    defined in the `workflow-util.groovy` script. That way we won't repeat ourselves
    when we create jobs with different goals and processes. We'll explore the `workflow-util.groovy`
    script very soon. The result of the load is assigned to the `flow` variable.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'From this point on, the rest of the script should be self-explanatory. We''re
    calling the `provision` function passing it `prod2.yml` as variable. Then we''re
    calling the `buildTest` function and passing it `serviceName` and `registryIpPort`
    job parameters as variables. And so on, and so forth. The functions we are invoking
    are performing the same actions like those we implemented through Ansible, and
    represent the deployment pipeline. With this separation between utility functions
    loaded as a separate file and the workflow script itself, we can properly divide
    responsibilities. The utility script provides functions multiple workflow scripts
    can use and benefits greatly from being centralized so that improvements are done
    once. On the other hand, one workflow might not be the same as the other so, in
    this case, it mostly contains invocations of utility functions:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a closer look at the functions inside the `workflow-util.groovy`
    script:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `provision` function is in charge of provisioning our servers before deployment.
    It defines `stage` that helps us better identify the set of tasks this function
    is in charge of. That is followed by the declaration of the `PYTHONUNBUFFERED`
    environment variable that tells Ansible to skip buffering logs and display the
    output as soon as possible. Finally, we are invoking the Ansible playbook using
    the workflow module `sh` that runs any shell script. Since we might run different
    playbooks depending on the type of the Jenkins job, we are passing the playbook
    name as the function variable.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'The next function we''ll explore is in charge of building tests:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This time, we are using the `docker` module to declare the Docker image and
    assigning the result to the `tests` variable. From there on, we are pulling the
    image, running a Shell script that builds a new one in case something changed
    and, finally, pushing the result to the registry. Please note that image pulling
    is inside a `try/catch` statement. The workflow is run for the first time, there
    will be no image to pull, and, without a `try/catch` statement, the script would
    fail.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'Next in line are functions for running tests and building the service image:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Those two functions use the same instructions as those we already discussed
    so we'll jump over them.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'The function for deploying the service might need further explanation:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The new instruction is the `withEnv`. We're using it to create the environment
    variable that has a limited scope. It will exist only for instructions declared
    inside curly braces. In this case, environment variable `DOCKER_HOST` is used
    only to pull and run the `app` container on a remote host.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'The last function updates the proxy service:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The new instructions are `stash` and `unstash`. Since we are updating the proxy
    on a different node (defined as the `proxyNode` variable), we had to stash few
    files from the `cd` server and unstash them in the proxy node. In other words,
    stash/unstash combination is equivalent to copying the files from one server or
    directory to another.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: All in all, the approach with Jenkins Workflow and Groovy DSL removes the need
    for deployment defined in Ansible. We'll keep using Ansible playbooks for provisioning
    and configuration since those are the areas it truly shines. On the other hand,
    Jenkins Workflow and Groovy DSL provide much more power, flexibility, and freedom
    when defining the deployment process. The main difference is that Groovy is a
    scripting language and, therefore, provides a better syntax for this type of tasks.
    At the same time, its integration with Jenkins allows us to utilize some powerful
    features. For example, we could define five nodes with a label `tests`. Later
    on, if we specify that some Workflow instructions should be run on a `tests` node,
    Jenkins would make sure that the least utilized of those five nodes is used (or
    there might be a different logic depending on the way we set it up).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, by using Jenkins Workflow, we're avoiding complicated and
    not easy to understand XML definitions required by traditional Jenkins jobs and
    reducing the overall number of jobs. There are many other advantages Workflow
    provides and we'll discuss them later. The result is a single script, much shorter
    than Ansible deployment tasks we had before, and, at the same time, something
    easier to understand and update. We embraced Jenkins for tasks it is good at while
    keeping Ansible for servers provisioning and configuration. The result is the
    combination that uses the best of both worlds.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Let's take another look at the configuration of the `books-ms` job. Please open
    the `books-ms configuration` screen in your favorite browser. You'll see that
    the job contains only two set of specifications. It starts with parameters and
    ends with the Workflow script we discussed earlier. The script itself can be very
    generic since differences are declared through parameters. We could multiply this
    job for all our services, and the only differences would be Jenkins parameters.
    That way, management of those jobs can be handled through a single Ansible template
    defined in the `roles/jenkin` `s/templates/service-workflow-config.xml` file.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s build the job and see how it fares. Please open the `books-ms build`
    screen. You''ll see that the parameters are already pre-defined with reasonable
    values. The name of the service is the `books-ms` parameter, the IP of the production
    server is the `prodIp` parameter, the IP of the proxy server is the `proxyIp`
    parameter and, finally, the IP and the port of the Docker registry is defined
    as the `registryIpPort` parameter. Once you click the **Build** button, the deployment
    will be initiated:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Jenkins Workflow Jobs](img/B05848_12_07.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
- en: Figure 12-07 – Build screen of the books-ms Jenkins workflow job
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'We can monitor the execution of the job by opening the `books-ms` Console screen
    of the last build:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Jenkins Workflow Jobs](img/B05848_12_08.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: Figure 12-08 – Console screen of the books-ms Jenkins workflow job
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'As you already know, many things are done as part of our deployment process
    and the logs can be too big for us to find something fast. Luckily, Jenkins workflow
    jobs have the `Workflow Steps` feature that can help. When the execution is finished,
    please click the Workflow Steps link after navigating to the last `books-ms build`.
    You''ll see that each stage and step is presented with a link (icon representing
    a terminal screen) that allow us to investigate only logs belonging to the step
    in question:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting Up Jenkins Workflow Jobs](img/B05848_12_09.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
- en: Figure 12-09 – Workflow Steps screen of the books-ms Jenkins workflow job
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: There's much more to Jenkins workflow than what we presented here. Please spend
    some time with the online tutorial to get more familiar with it. As an exercise,
    add, for example, email notifications to the script. While exploring Jenkins Workflow,
    make sure to select the **Snippet Generator** checkbox located below the script
    in the books-ms configuration screen. It is a very useful way to discover what
    each snippet does and how it can be used.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Even though Workflow provided a lot of benefits over deployment defined through
    the playbook, managing the script through Ansible is still the sub-optimum solution.
    A better way would be to set the deployment pipeline as a script inside the code
    repository together with the rest of the service code. That way, the team maintaining
    the service would be in full control of deployment. Besides the need to have the
    workflow script inside the code repository, it would be highly beneficial if a
    Jenkins job would be capable not only of handling the main branch but all of them
    or those we select to be worth the trouble. Luckily, both of those improvements
    can be accomplished with the `Multibranch` `Workflow` plugin and `Jenkinsfile`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up Jenkins Multibranch Workflow and Jenkinsfile
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `Jenkins Multibranch Workflow` plugin adds a new job type that allows us
    to keep the Workflow script inside a code repository. Such a job would create
    a subproject for each branch it finds in the repository and expects to find `Jenkinsfile`
    in each of them. That allows us to keep the Workflow script inside the repository
    instead having it centralized inside Jenkins. That, in turn, enables developers
    in charge of a project full freedom to define the deployment pipeline. Since each
    branch creates a separate Jenkins project with a different Jenkinsfile, we can
    fine-tune the process depending on the type of branch. For example, we might decide
    to define a full pipeline in the Jenkinsfile residing in the master branch and
    choose to have only building and testing tasks defined for feature branches. There's
    more. Not only that Jenkins will detect all branches and keep that list updated,
    but it will also remove a subproject if a corresponding branch is removed.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Let's give Multibranch Workflow and Jenkinsfile a spin. We'll start by opening
    the `books-ms-multibranch job`. You'll see the message stating that this project
    scans branches in your SCM and generate a job for each of them, but you have no
    branches configured. Please click the `Branch Indexing` and, then, `Run Now` links
    from the left-hand menu. Jenkins will index all branches that match the filter
    we specified in the configuration. Once branches are indexed, it will create subprojects
    for each and initiate building. Let's explore the configuration of the job while
    building is in progress.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Please open the `books-ms-multibranch configuration` screen. The only important
    part of the job configuration is `Branch Sources`. We used it to define the code
    repository. Please note the **Advanced** button. When clicked, you'll see that
    only branches that contain `workflow` in their names are included. This setting
    is configured for two reasons. The first one is to demonstrate the option to filter
    which branches will be included and, the other, to save you from building too
    many branches inside the VM with such a limited capacity (the `cd` node has only
    1 CPU and 1 GB of RAM).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'By this time, branch indexing is probably finished. If you go back to the books-ms-multibranch
    job screen, you''ll see that two subject projects matched the filter, `jenkins-workflow`
    and `jenkins-workflow-simple`, and that Jenkins initiated builds of both. Since
    the `cd` node is configured to have only one executor, the second build will wait
    until the first is finished.     Let''s take a look at the `Jenkinsfile` in those branches.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'The Jenkinsfile in the jenkins-workflow branch is as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The script is almost the same as the one we defined earlier when we worked
    with Jenkins Workflow embedded in the Jenkins job `books-ms`. The only difference
    is that, this time, variables are defined inside the script instead of using Jenkins
    properties. Since the project team is now in full charge of the process, there
    is no need to externalize those variables. We accomplished the same result as
    before but this time we moved the script to the code repository.The `Jenkinsfile`
    in the `jenkins-workflow-simple` branch is a bit simpler:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: By inspecting the script, we can conclude that the developer who made that branch
    wants to benefit from tests being run through Jenkins every time he pushes a commit.
    He removed deployment and post-deployment tests from it since the code is probably
    not ready to be deployed to production or the policy is that only the code in
    the master or other selected branches is deployed. Once he merges his code, a
    different script will be run and his changes will be deployed to production assuming
    that he didn't introduce any bugs, and the process was successful.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of `Multibranch Workflow` and `Jenkinsfile` improved our deployment
    pipeline quite a lot. We have a utility script located in the `cd` node so that
    others can reuse common functions. From there on, we allowed every team to host
    their script inside the `Jenkinsfile` located in their repository. Moreover, we
    gave them freedom not only to decide what is the proper way to build, test, and
    deploy their services but also the flexibility to fine-tune the process based
    on each branch.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: That was a very brief introduction to CI/CD tools and Jenkins in particular.
    Apart from the need to have a CI/CD tool, Jenkins will be one of the cornerstones
    of the next chapter. We'll use it as part of the *blue-green deployment* toolset.
    If you are new to Jenkins, I suggest you take a break from this book. Spend some
    time with it, read few tutorials and play around with different plugins. Time
    invested in Jenkins is indeed a valuable investment that will be paid off quickly.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of Jenkins Workflow together with Docker and Multibranch plugins
    proved to be invaluable additions to our toolbelt. We are using all the power
    Jenkins UI can offer while still maintaining the flexibility that scripting provides
    for the deployment pipeline. Workflow DLS and Groovy combine the best of both
    worlds. Through Workflow domain specific language (DSL), we have syntax and functionality
    specifically tailored to serve deployment purposes. On the other hand, Groovy
    itself provides everything we might need when DSL cuts short. At the same time,
    we can access almost any functionality Jenkins offers. Docker addition to the
    Workflow provided few helpful shortcuts and Multibranch together with Jenkinsfile
    allowed us to have the pipeline (or part of it) applied to all branches (or those
    we select). All in all, we combined high level with low-level tools into one powerful
    and easy to use combination.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: The way we created Jenkins jobs through Ansible was far from great. We could
    have used one of the Jenkins plugins like `Template Project Plugin` to create
    templates. However, none of them are truly great and they all suffer from some
    deficiencies. `Jenkins Enterprise Edition` from `CloudBees` does have tools that
    solve templating and many other problems. However, all the examples we used by
    now were based on open source software, and we'll continue in the same fashion
    throughout the rest of the book. That does not mean that paid solutions are not
    worth the investment. They often are and should be evaluated. If you choose to
    use Jenkins and the size of your project or organization warrants the investment,
    I recommend you evaluate `Jenkins Enterprise Edition`. It brings a lot of improvements
    over the open source version.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Given the tools we have at our disposal and the relatively uniform way to run
    our deployment steps, the current solution is probably the best we could do, and
    it is time for us to move to the next subject and explore the benefits we can
    obtain from `blue-green deployment`.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we move on, let''s destroy the VMs we used in this chapter:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
