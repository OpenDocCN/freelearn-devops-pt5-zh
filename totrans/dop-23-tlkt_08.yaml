- en: Using Volumes to Access Host&#x27;s File System
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用卷访问主机的文件系统
- en: Having a system without a state is impossible. Even though there is a tendency
    to develop stateless applications, we still need to deal with the state. There
    are databases and other stateful third-party applications. No matter what we do,
    we need to make sure that the state is preserved no matter what happens to containers,
    Pods, or even whole nodes.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 没有状态的系统是无法存在的。尽管目前有将应用程序开发为无状态的趋势，但我们仍然需要处理状态问题。有数据库和其他有状态的第三方应用程序。无论我们做什么，都需要确保无论容器、Pod，甚至整个节点发生什么情况，状态都能够保持。
- en: Most of the time, stateful applications store their state on disk. That leaves
    us with a problem. If a container crashes, `kubelet` will restart it. The problem
    is that it will create a new container based on the same image. All data accumulated
    inside a container that crashed will be lost.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，有状态的应用程序会将其状态存储在磁盘上。这给我们带来了一个问题。如果容器崩溃，`kubelet` 会重启它。问题在于，它会基于相同的镜像创建一个新的容器。崩溃容器内积累的所有数据将会丢失。
- en: Kubernetes volumes solve the need to preserve the state across container crashes.
    In essence, volumes are references to files and directories made accessible to
    containers that form a Pod. The significant difference between different types
    of Kubernetes volumes is in the way these files and directories are created.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 卷解决了容器崩溃时保持状态的需求。从本质上讲，卷是指向文件和目录的引用，这些文件和目录对构成 Pod 的容器可访问。不同类型的 Kubernetes
    卷之间的主要区别在于这些文件和目录是如何创建的。
- en: While the primary use-case for volumes is the preservation of state, there are
    quite a few others. For example, we might use volumes to access Docker's socket
    running on a host. Or we might use them to access configuration residing in a
    file on the host file system.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然卷的主要用途是保持状态，但其实还有很多其他用途。例如，我们可以使用卷来访问主机上运行的 Docker 套接字，或者我们可以使用它们来访问存储在主机文件系统中的配置文件。
- en: We can describe Volumes as a way to access a file system that might be running
    on the same host or somewhere else. No matter where that file system is, it is
    external to the containers that mount volumes. There can be many reasons why someone
    might mount a Volume, with state preservation being only one of them.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将卷描述为一种访问文件系统的方式，该文件系统可能运行在同一主机或其他地方。无论该文件系统在哪里，它都是容器挂载卷时外部的。有人挂载卷的原因有很多，其中状态保持只是其中之一。
- en: There are over twenty-five volume types supported by Kubernetes. It would take
    us too much time to go through all of them. Besides, even if we'd like to do that,
    many volume types are specific to a hosting vendor. For example, `awsElasticBlockStore`
    works only with AWS, `azureDisk` and `azureFile` work only with Azure, and so
    on and so forth. We'll limit our exploration to volume types that can be used
    within Minikube. You should be able to extrapolate that knowledge to volume types
    applicable to your hosting vendor of choice.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 支持超过二十五种卷类型。要逐一讲解它们需要花费大量时间。此外，即使我们愿意这么做，很多卷类型都是特定于某个托管商的。例如，`awsElasticBlockStore`
    仅与 AWS 配合使用，`azureDisk` 和 `azureFile` 仅与 Azure 配合使用，依此类推。我们将把探索范围限制在 Minikube
    中可以使用的卷类型。你应该能够将这些知识推断到适用于你所选择的托管商的卷类型。
- en: Let's get down to it.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Creating a cluster
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建集群
- en: This time, we'll have an additional action we'll execute in preparation to create
    a Minikube cluster.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，在准备创建 Minikube 集群时，我们将执行一个额外的操作。
- en: All the commands from this chapter are available in the [`08-volume.sh`](https://gist.github.com/5acafb64c0124a1965f6d371dd0dedd1)
    ([https://gist.github.com/vfarcic/5acafb64c0124a1965f6d371dd0dedd1](https://gist.github.com/vfarcic/5acafb64c0124a1965f6d371dd0dedd1))
    Gist.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有命令都可以在 [`08-volume.sh`](https://gist.github.com/5acafb64c0124a1965f6d371dd0dedd1)
    ([https://gist.github.com/vfarcic/5acafb64c0124a1965f6d371dd0dedd1](https://gist.github.com/vfarcic/5acafb64c0124a1965f6d371dd0dedd1))
    Gist 中找到。
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We'll need the file inside the soon-to-be-created Minikube VM. When it starts,
    it will copy all the files from `~/.minikube/files` on your host, into the `/files`
    directory in the VM.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要 Minikube 虚拟机内的文件。它启动时，会将主机上 `~/.minikube/files` 目录中的所有文件复制到虚拟机中的 `/files`
    目录。
- en: Depending on your operating system, the `~/.minikube/files` directory might
    be somewhere else. If that's the case, please adapt the preceding command.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的操作系统，`~/.minikube/files` 目录可能在其他地方。如果是这种情况，请调整前面的命令。
- en: Now that the files are copied to the shared directory, we can repeat the same
    process we did quite a few times before. Please note that we've added the step
    from the last chapter that enables the ingress addon.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在文件已复制到共享目录，我们可以重复之前做过的相同过程。请注意，我们已经添加了上一章节的步骤，以启用ingress插件。
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now that the Minikube cluster is up-and-running, we can explore the first volume
    type.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在Minikube集群已启动，我们可以探索第一种卷类型。
- en: Accessing host's resources through hostPath volumes
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过hostPath卷访问主机的资源
- en: Sooner or later, we'll have to build our images. A simple solution would be
    to execute the `docker image build` command directly from a server. However, that
    might cause problems. Building images on a single host means that there is an
    uneven resource utilization and that there is a single point of failure. Wouldn't
    it be better if we could build images anywhere inside a Kubernetes cluster?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，最终我们都需要构建镜像。一种简单的解决方案是直接在服务器上执行`docker image build`命令。然而，这可能会导致问题。在单个主机上构建镜像意味着资源利用不均衡，并且存在单点故障。如果我们能够在Kubernetes集群内的任何地方构建镜像，岂不是更好吗？
- en: Instead of executing the `docker image build` command, we could create a Pod
    based on the `docker` image. Kubernetes will make sure that the Pod is scheduled
    somewhere inside the cluster, thus distributing resource usage much better.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以基于`docker`镜像创建一个Pod，而不是执行`docker image build`命令。Kubernetes会确保Pod被调度到集群中的某个位置，从而更好地分配资源使用。
- en: Let's start with an elementary example. If we can list the images, we'll prove
    that running docker commands inside containers works. Since, from Kubernetes'
    point of view, Pods are the smallest entity, that's what we'll run.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个基础的例子开始。如果我们能够列出镜像，我们就能证明在容器内运行docker命令是可行的。因为从Kubernetes的角度来看，Pod是最小的实体，所以我们将运行Pod。
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We created a Pod named `docker` and based it on the official `docker` image.
    Since we want to execute a one-shot command, we specified that it should `Never`
    restart. Finally, the container command is `docker image ls`. The second command
    lists all the Pods in the cluster (including failed ones).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个名为`docker`的Pod，并基于官方的`docker`镜像。由于我们想执行一个一次性的命令，因此指定它应该`Never`重启。最后，容器命令是`docker
    image ls`。第二个命令列出了集群中所有的Pod（包括失败的Pod）。
- en: 'The output of the latter command is as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 后者命令的输出如下：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The output should show that the status is `Error`, thus indicating that there
    is a problem with the container we're running. If, in your case, the status is
    not yet `Error`, Kubernetes is probably still pulling the image. In that case,
    please wait a few moments, and re-execute the `kubectl get pods` command.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该显示状态为`Error`，这表示我们运行的容器存在问题。如果你的状态还不是`Error`，可能是Kubernetes仍在拉取镜像。在这种情况下，请稍等片刻，然后重新执行`kubectl
    get pods`命令。
- en: 'Let''s take a look at the logs of the container:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下容器的日志：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output is as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Docker consists of two main pieces. There is a client, and there is a server.
    When we executed `docker image ls`, we invoked the client who tried to communicate
    with the server through its API. The problem is that Docker server is not running
    in that container. What we should do is tell the client (inside a container) to
    use Docker server that is already running on the host (Minikube VM).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Docker由两个主要部分组成。一个是客户端，一个是服务器。当我们执行`docker image ls`时，我们调用了客户端，它通过API与服务器进行通信。问题在于，Docker服务器并没有在容器中运行。我们应该做的是告诉客户端（在容器内）使用已经在主机（Minikube
    VM）上运行的Docker服务器。
- en: By default, the client sends instructions to the server through the socket located
    in `/var/run/docker.sock`. We can accomplish our goal if we mount that file from
    the host into a container.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，客户端通过位于`/var/run/docker.sock`的套接字向服务器发送指令。如果我们将该文件从主机挂载到容器内，就可以实现我们的目标。
- en: 'Before we try to enable communication between a Docker client in a container
    and Docker server on a host, we''ll delete the Pod we created a few moments ago:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试启用容器内的Docker客户端与主机上的Docker服务器之间的通信之前，我们将删除几分钟前创建的Pod：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s take a look at the Pod definition stored in `volume/docker.yml`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下存储在`volume/docker.yml`中的Pod定义：
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Part of the definition closely mimics the `kubectl run` command we executed
    earlier. The only significant difference is in the `volumeMounts` and `volumes`
    sections.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 部分定义与我们之前执行的`kubectl run`命令非常相似。唯一显著的区别是在`volumeMounts`和`volumes`部分。
- en: The `volumeMounts` field is relatively straightforward and is the same no matter
    which type of volume we're using. In this section, we're specifying the `mountPath`
    and the name of the volume. The former is the path we expect to mount inside this
    container. You'll notice that we are not specifying the type of the volume nor
    any other specifics inside the `VolumeMounts` section. Instead, we simply have
    a reference to a volume called `docker-socket`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`volumeMounts` 字段相对简单，不论我们使用哪种类型的卷，都是相同的。在这一部分，我们指定了 `mountPath` 和卷的名称。前者是我们期望在容器内挂载的路径。你会注意到，我们并没有在
    `VolumeMounts` 部分指定卷的类型或其他任何细节。相反，我们仅仅引用了一个名为 `docker-socket` 的卷。'
- en: The volume configuration specific to each type is defined in the `volumes` section.
    In this case, we're using the `hostPath` volume type.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 每种类型的卷配置在 `volumes` 部分中定义。在本例中，我们使用的是 `hostPath` 卷类型。
- en: '`hostPath` allows us to mount a file or a directory from a host to Pods and,
    through them, to containers. Before we discuss the usefulness of this type, we''ll
    have a short discussion about use-cases when this is not a good choice.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`hostPath` 允许我们将主机上的文件或目录挂载到 Pod，并通过这些 Pod 挂载到容器。在讨论此类型的实用性之前，我们先简单讨论一下在什么情况下它并不是一个好的选择。'
- en: Do not use `hostPath` to store a state of an application. Since it mounts a
    file or a directory from a host into a Pod, it is not fault-tolerant. If the server
    fails, Kubernetes will schedule the Pod to a healthy node, and the state will
    be lost.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 不要使用 `hostPath` 来存储应用的状态。由于它将文件或目录从主机挂载到 Pod，因此它不是容错的。如果服务器失败，Kubernetes 会将
    Pod 调度到健康的节点，而状态将会丢失。
- en: For our use case, `hostPath` works just fine. We're not using it to preserve
    state, but to gain access to Docker server running on the same host as the Pod.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的使用场景，`hostPath` 非常合适。我们不是用它来保存应用的状态，而是为了访问与 Pod 运行在同一主机上的 Docker 服务。
- en: The `hostPath` type has only two fields. The `path` represents the file or a
    directory we want to mount from the host. Since we want to mount a socket, we
    set the `type` accordingly. There are other types we could use.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`hostPath` 类型只有两个字段。`path` 表示我们希望从主机挂载的文件或目录。由于我们想挂载一个套接字，因此相应地设置了 `type`。当然，也可以使用其他类型。'
- en: The `Directory` type will mount a directory from the host. It must exist on
    the given path. If it doesn't, we might switch to `DirectoryOrCreate` type which
    serves the same purpose. The difference is that `DirectoryOrCreate` will create
    the directory if it does not exist on the host.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`Directory` 类型将挂载主机上的目录。该目录必须存在于给定的路径上。如果不存在，我们可以改用 `DirectoryOrCreate` 类型，后者具有相同的目的。区别在于，`DirectoryOrCreate`
    会在主机上不存在目录时自动创建该目录。'
- en: The `File` and `FileOrCreate` are similar to their `Directory` equivalents.
    The only difference is that this time we'd mount a file, instead of a directory.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`File` 和 `FileOrCreate` 与其 `Directory` 对应类型类似。唯一的区别是这次我们会挂载文件，而不是目录。'
- en: The other supported types are `Socket`, `CharDevice`, and `BlockDevice`. They
    should be self-explanatory. If you don't know what character or block devices
    are, you probably don't need those types.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其他支持的类型包括 `Socket`、`CharDevice` 和 `BlockDevice`。它们应该是自解释的。如果你不知道字符设备或块设备是什么，那么你可能不需要这些类型。
- en: Last, but not least, we changed the command and the arguments to `sleep 100000`.
    That will give us more freedom since we'll be able to create the Pod, enter inside
    its only container, and experiment with different commands.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，我们修改了命令和参数为 `sleep 100000`。这将给我们更多自由，因为我们可以创建 Pod，进入它唯一的容器，并尝试不同的命令。
- en: 'Let''s create the Pod and check whether, this time, we can execute Docker commands
    from inside the container it''ll create:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建 Pod，并检查这次是否可以从容器内部执行 Docker 命令：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Since the image is already pulled, starting the Pod should be almost instant.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 由于镜像已经拉取，启动 Pod 应该几乎是瞬时的。
- en: 'Let''s see whether we can retrieve the list of Docker images:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看是否能检索到 Docker 镜像列表：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We executed `docker image ls` command and shortened the output by limiting
    its formatting only to `Repository`. The output is as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行了 `docker image ls` 命令，并通过将输出格式限制为 `Repository` 来缩短结果。输出如下：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Even though we executed the `docker` command inside a container, the output
    clearly shows the images from the host. We proved that mounting the Docker socket
    (`/var/run/docker.sock`) as a volume allows communication between Docker client
    inside the container, and Docker server running on the host.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们在容器内执行了 `docker` 命令，输出仍清楚地显示了来自主机的镜像。我们证明了将 Docker 套接字（`/var/run/docker.sock`）作为卷挂载可以实现容器内的
    Docker 客户端与主机上运行的 Docker 服务器之间的通信。
- en: '![](img/0aebfc58-7258-4d6c-8549-dc9d52ccbda9.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0aebfc58-7258-4d6c-8549-dc9d52ccbda9.png)'
- en: 'Figure 8-1: HostPath mounted inside a container'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8-1：HostPath 挂载在容器内
- en: Let's enter the container and see whether we can build a Docker image.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入容器，看看能否构建 Docker 镜像。
- en: '[PRE12]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'To build an image, we need a `Dockerfile` as well as an application''s source
    code. We''ll continue using `go-demo-2` as the example, so our first action will
    be to clone the repository:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建镜像，我们需要一个 `Dockerfile` 和应用程序的源代码。我们将继续使用 `go-demo-2` 作为示例，因此我们的第一步是克隆仓库：
- en: '[PRE13]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We used `apk add` to install `git`. `docker` and many other images use `alpine`
    as the base. If you're not familiar with `alpine`, it is a very slim and efficient
    base image, and I strongly recommend that you use it when building your own. Images
    like `debian`, `centos`, `ubuntu`, `redhat`, and similar base images are often
    a terrible choice made because of a misunderstanding of how containers work.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `apk add` 安装了 `git`。`docker` 和许多其他镜像使用 `alpine` 作为基础镜像。如果你不熟悉 `alpine`，它是一个非常精简且高效的基础镜像，我强烈建议在构建自己的镜像时使用它。像
    `debian`、`centos`、`ubuntu`、`redhat` 和类似的基础镜像，常常因为误解容器工作原理而成为糟糕的选择。
- en: '`alpine` uses `apk` package management, so we invoked it to install `git`.
    Next, we cloned the `vfarcic/go-demo-2` repository, and, finally, we entered into
    the `go-demo-2` directory:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`alpine` 使用 `apk` 包管理器，因此我们调用它安装了 `git`。接下来，我们克隆了 `vfarcic/go-demo-2` 仓库，最后进入了
    `go-demo-2` 目录：'
- en: 'Let''s take a quick look at the `Dockerfile`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速看一下 `Dockerfile`：
- en: '[PRE14]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output is as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE15]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Since this book is dedicated to Kubernetes, we won't go into details behind
    this Dockerfile, but only comment that it uses Docker's multi-stage builds. The
    first stage downloads the dependencies, it runs unit tests, and it builds the
    binary. The second stage starts over. It builds a fresh image with the `go-demo`
    binary copied from the previous stage.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书专注于 Kubernetes，我们不会详细探讨这个 Dockerfile 的内容，只评论它使用了 Docker 的多阶段构建。第一阶段下载依赖，运行单元测试，并构建二进制文件。第二阶段重新开始，构建一个新镜像，并将之前阶段构建的
    `go-demo` 二进制文件复制过来。
- en: I sincerely hope you're proficient with Docker and there's no need to explain
    image building further. If that's not the case, you might want to explore the
    official documentation or one of my previous books. This one is focused only on
    Kubernetes.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我真心希望你对 Docker 已经非常熟练，因此无需进一步解释镜像构建。如果情况并非如此，你可能需要查阅官方文档或我之前的书籍之一。本书专注于 Kubernetes。
- en: Let's test whether building an image indeed works.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试构建镜像是否确实可行。
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We executed the `docker image build` command, followed by `docker image ls`.
    The output of the latter command is as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行了 `docker image build` 命令，然后运行了 `docker image ls`。后者的输出如下：
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: If we compare this with the previous `docker image ls` output, we'll notice
    that, this time, a few new images are listed. The `golang` and `alpine` images
    are used as a basis for each of the build stages. The `vfarcic/go-demo-2` is the
    result of our build. Finally, `<none>` is only a left-over of the process and
    it can be safely removed.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们与之前的 `docker image ls` 输出进行对比，会发现这一次列出了几个新镜像。`golang` 和 `alpine` 镜像作为每个构建阶段的基础。而
    `vfarcic/go-demo-2` 则是我们构建的结果。最后，`<none>` 只是构建过程中的残余，可以安全移除。
- en: '[PRE18]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `docker system prune` command removes all unused resources. At least, all
    those created and unused by Docker. We confirmed that by executing `docker image
    ls` again. This time, we can see the `<none>` image is gone.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker system prune` 命令会移除所有未使用的资源。至少是那些由 Docker 创建但未使用的资源。我们通过再次执行 `docker
    image ls` 来验证这一点。这一次，我们可以看到 `<none>` 镜像已经消失。'
- en: 'We''ll destroy the `docker` Pod and explore other usages of the `hostPath`
    volume type:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将销毁 `docker` Pod，并探索 `hostPath` 卷类型的其他用法：
- en: '[PRE19]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '`hostPath` is a great solution for accessing host resources like `/var/run/docker.sock`,
    `/dev/cgroups`, and others. That is, as long as the resource we''re trying to
    reach is on the same node as the Pod.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`hostPath` 是访问主机资源（如 `/var/run/docker.sock`、`/dev/cgroups` 等）的好方法。前提是我们要访问的资源和
    Pod 在同一节点上。'
- en: Let's see whether we can find other use-cases for `hostPath`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看是否能找到 `hostPath` 的其他用例。
- en: Using hostPath volume type to inject configuration files
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用hostPath卷类型注入配置文件
- en: We are about to deploy Prometheus ([https://prometheus.io/](https://prometheus.io/))
    for the first time (in this book). We won't go into details behind the application
    except to say that it's fantastic and that you should consider it for your monitoring
    and alerting needs. At the risk of disappointing you, I will have to say that
    Prometheus is not in the scope of this chapter, and probably not even the book.
    We're using it only to demonstrate a few Kubernetes concepts. We're not trying
    to learn how to operate it.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将首次部署Prometheus（[https://prometheus.io/](https://prometheus.io/)）(在本书中)。我们不会深入讨论该应用，除了说它非常棒，并且你应该考虑将其用于监控和告警需求。为了避免让你失望，我必须告诉你，Prometheus并不在本章的范围内，可能也不在本书的范围内。我们仅仅是用它来演示一些Kubernetes概念。我们并不打算学习如何操作它。
- en: 'Let''s take a look the application''s definition:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看应用的定义：
- en: '[PRE20]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output is as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE21]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: There's nothing genuinely new in that YAML file. It defines an Ingress, a deployment,
    and a service. There is, however, one thing we might need to change. Prometheus
    needs a full `external-url` if we want to change the base path. At the moment,
    it's set to the IP of my Minikube VM. In your case, that IP might be different.
    We'll fix that by adding a bit of sed "magic" that will make sure the IP matches
    that of your Minikube VM.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 那个YAML文件并没有什么真正的新内容。它定义了一个Ingress、一个部署和一个服务。不过，我们可能需要修改一件事。如果我们想更改基础路径，Prometheus需要一个完整的`external-url`。目前，它被设置为我Minikube虚拟机的IP。在你的情况下，那个IP可能不同。我们将通过添加一些`sed`“魔法”来修复它，确保IP与您的Minikube虚拟机的IP匹配。
- en: '[PRE22]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We output the contents of the `volume/prometheus.yml` file, we used `sed` to
    replace the hard-coded IP with the actual value of your Minikube instance, and
    we passed the result to `kubectl create`. Please note that, this time, the `create`
    command has dash (`-`) instead of the path to the file. That's an indication that
    `stdin` should be used instead.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们输出了`volume/prometheus.yml`文件的内容，使用`sed`命令将硬编码的IP替换为实际的Minikube实例的值，然后将结果传递给`kubectl
    create`。请注意，这次的`create`命令使用了破折号（`-`）而不是文件路径。这表明应该使用`stdin`。
- en: Once we created the application, we used the `kubectl rollout status` command
    to confirm that the deployment finished.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建应用后，我们使用`kubectl rollout status`命令确认部署已完成。
- en: Now we can open Prometheus in a browser.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在浏览器中打开Prometheus了。
- en: '[PRE23]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'At first glance, the application seems to be running correctly. However, since
    the targets are the crucial part of the application, we should check them as well.
    For those not familiar with Prometheus, it pulls data from targets (external data
    sources) and, by default, comes with only one target pre-configured: Prometheus
    itself. Prometheus will always pull data from this target unless we configure
    it otherwise.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一开始，应用似乎运行正常。然而，由于目标是应用的关键部分，我们应该检查它们。对于不熟悉Prometheus的人来说，它从目标（外部数据源）拉取数据，默认情况下，只配置了一个目标：Prometheus本身。Prometheus会始终从这个目标拉取数据，除非我们另行配置。
- en: Let's take a look at its targets.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它的目标。
- en: '[PRE24]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: There's something wrong. The default target is not reachable. Before we start
    panicking, we should take a closer look at its configuration.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 出现了一些问题。默认的目标无法访问。在我们开始惊慌之前，我们应该仔细查看其配置。
- en: '[PRE25]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The problem is with the `metrics_path` field. By default, it is set to `/metrics`.
    However, since we changed the base path to `/prometheus`, the field should have
    `/prometheus/metrics` as the value.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 问题出在`metrics_path`字段上。默认情况下，它被设置为`/metrics`。然而，由于我们已经将基础路径更改为`/prometheus`，该字段的值应该为`/prometheus/metrics`。
- en: Long story short, we must change Prometheus configuration.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 长话短说，我们必须更改Prometheus的配置。
- en: We could, for example, enter the container, update the configuration file, and
    send the reload request to Prometheus. That would be a terrible solution since
    it would last only until the next time we update the application, or until the
    container fails, and Kubernetes decides to reschedule it.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以进入容器，更新配置文件，并发送重新加载请求给Prometheus。这个解决方案非常糟糕，因为它只会持续到下次更新应用，或者直到容器崩溃，Kubernetes决定重新调度它为止。
- en: Let's explore alternative solutions. We could, for example, use `hostPath` volume
    for this as well. If we can guarantee that the correct configuration file is inside
    the VM, the Pod could attach it to the `prometheus` container. Let's try it out.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一下替代方案。例如，我们也可以使用`hostPath`卷来实现这一点。如果我们能确保正确的配置文件在虚拟机中，Pod就可以将其挂载到`prometheus`容器。让我们试试看。
- en: '[PRE26]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output, limited to relevant parts, is as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 输出（仅显示相关部分）如下：
- en: '[PRE27]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The only significant difference, when compared with the previous definition,
    is in the added `volumeMounts` and `volumes` fields. We're using the same schema
    as before, except that, this time, the `type` is set to `File`. Once we apply
    this Deployment, the file `/files/prometheus-conf.yml` on the host will be available
    as `/etc/prometheus/prometheus.yml` inside the container.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的定义相比，唯一显著的区别在于增加了 `volumeMounts` 和 `volumes` 字段。我们使用的是与之前相同的模式，只不过这次 `type`
    设置为 `File`。一旦我们应用了这个 Deployment，主机上的 `/files/prometheus-conf.yml` 文件将在容器内作为 `/etc/prometheus/prometheus.yml`
    可用。
- en: If you recall, we copied one file to the `~/.minikube/files` directory, and
    Minikube copied it to the `/files` directory inside the VM.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得，我们将一个文件复制到 `~/.minikube/files` 目录，并且 Minikube 将其复制到虚拟机中的 `/files` 目录。
- en: In some cases, files might end up being copied to the VM's root (`/`), instead
    of to `/files`. If this has happened to you, please enter the VM (`minikube ssh`),
    and move the files to `/files`, by executing the commands that follow (only if
    the `/files` directory does not exist or is empty).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，文件可能最终被复制到虚拟机的根目录（`/`），而不是 `/files`。如果发生了这种情况，请进入虚拟机（`minikube ssh`），并通过执行以下命令将文件移到
    `/files`（前提是 `/files` 目录不存在或为空）。
- en: '[PRE28]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The time has come to take a look at the content of the file.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候查看文件的内容了。
- en: '[PRE29]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We changed the permissions of the file and displayed its content.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们更改了文件的权限并显示了其内容。
- en: 'The output is as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE30]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This configuration is almost identical to what Prometheus uses by default. The
    only difference is in the `metrics_path`, which is now pointing to `/prometheus/metrics`.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配置几乎与 Prometheus 默认使用的配置相同。唯一的区别是在 `metrics_path`，它现在指向 `/prometheus/metrics`。
- en: 'Let''s see whether Prometheus with the new configuration works as expected:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看使用新配置的 Prometheus 是否按预期工作：
- en: '[PRE31]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We applied the new definition (after the `sed` "magic"), we waited until the
    `rollout` finished, and we then opened the Prometheus targets in a browser. This
    time, with the updated configuration, Prometheus is successfully pulling data
    from the only target currently configured:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用了新的定义（在执行了 `sed` 的“魔法”之后），等待 `rollout` 完成，然后在浏览器中打开 Prometheus 目标。这次，使用更新的配置，Prometheus
    成功地从当前配置的唯一目标拉取数据：
- en: '![](img/68682aff-9d59-427a-bbbb-d42877a9cd8a.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/68682aff-9d59-427a-bbbb-d42877a9cd8a.png)'
- en: 'Figure 8-2: Prometheus targets screen'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8-2：Prometheus 目标界面
- en: The next logical step would be to configure Prometheus with additional targets.
    Specifically, you may want to configure it to fetch metrics that are already made
    available through the Kubernetes API. We, however, will *NOT* be doing this. First
    of all, this chapter is not about monitoring and alerting. The second, and the
    more important reason, is that using the `hostPath` volume type to provide configuration
    is *NOT* a good idea.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的逻辑步骤是为 Prometheus 配置额外的目标。具体来说，你可能想配置它以获取已经通过 Kubernetes API 提供的指标。不过，我们*不会*这么做。首先，本章并不是关于监控和告警的。第二，也是更重要的原因是，使用
    `hostPath` 卷类型来提供配置*不是*一个好主意。
- en: A `hostPath` volume maps a directory from a host to where the Pod is running.
    Using it to "inject" configuration files into containers would mean that we'd
    have to make sure that the file is present on every node of the cluster.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`hostPath` 卷将主机上的一个目录映射到 Pod 运行的地方。使用它来“注入”配置文件到容器中，意味着我们必须确保该文件在集群的每个节点上都存在。'
- en: Working with Minikube can be potentially misleading. The fact that we're running
    a single-node cluster means that every Pod we run will be scheduled on one node.
    Copying a configuration file to that single node, as we did in our example, ensures
    that it can be mounted in any Pod. However, the moment we add more nodes to the
    cluster, we'd experience side effects. We'd need to make sure that each node in
    our cluster has the same file we wish to mount, as we would not be able to predict
    where individual Pods would be scheduled. This would introduce far too much unnecessary
    work and added complexity.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Minikube 可能会产生误导。由于我们运行的是单节点集群，意味着我们运行的每个 Pod 都会调度到一个节点上。将配置文件复制到这个单节点，如我们在示例中所做的，确保它可以在任何
    Pod 中挂载。然而，一旦我们向集群中添加更多节点，就会出现副作用。我们需要确保集群中的每个节点都有我们想要挂载的相同文件，因为我们无法预测单个 Pod 会被调度到哪里。这会带来过多不必要的工作和额外的复杂性。
- en: An alternative solution would be to mount an NFS drive to all the nodes and
    store the file there. That would provide the guarantee that the file will be available
    on all the nodes, as long as we do *NOT* forget to mount NFS on each.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种解决方案是将NFS驱动器挂载到所有节点，并在那里存储文件。这可以确保文件在所有节点上可用，只要我们*不*忘记在每个节点上挂载NFS。
- en: Another solution could be to create a custom Prometheus image. It could be based
    on the official image, with a single `COPY` instruction that would add the configuration.
    The advantage of that solution is that the image would be entirely immutable.
    Its state would not be polluted with unnecessary volume mounts. Anyone could run
    that image and expect the same result. That is my preferred solution. However,
    in some cases, you might want to deploy the same application with a slightly different
    configuration. Should we, in those cases, fall back to mounting an NFS drive on
    each node and continue using `hostPath`?
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种解决方案可能是创建一个自定义的Prometheus镜像。它可以基于官方镜像，并且只需一个`COPY`指令来添加配置。这个解决方案的优势在于镜像将是完全不可变的。它的状态不会被不必要的卷挂载污染。任何人都可以运行该镜像并期待相同的结果。这是我更倾向的解决方案。然而，在某些情况下，你可能希望使用稍微不同的配置部署相同的应用程序。在这些情况下，我们是否应该回退到在每个节点上挂载一个NFS驱动器并继续使用`hostPath`？
- en: Even though mounting an NFS drive would solve some of the problems, it is still
    not a great solution. In order to mount a file from NFS, we need to use the [`nfs`](https://kubernetes.io/docs/concepts/storage/volumes/#nfs)
    ([https://kubernetes.io/docs/concepts/storage/volumes/#nfs](https://kubernetes.io/docs/concepts/storage/volumes/#nfs))
    volume type instead of `hostPath`. Even then it would be a sub-optimal solution.
    A much better approach would be to use `configMap`. We'll explore it in the next
    chapter.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 即使挂载NFS驱动器可以解决一些问题，它仍然不是一个很好的解决方案。为了从NFS挂载文件，我们需要使用[`nfs`](https://kubernetes.io/docs/concepts/storage/volumes/#nfs)（[https://kubernetes.io/docs/concepts/storage/volumes/#nfs](https://kubernetes.io/docs/concepts/storage/volumes/#nfs)）卷类型，而不是`hostPath`。即使如此，它仍然是一个次优解决方案。一个更好的方法是使用`configMap`。我们将在下一章中探讨这个问题。
- en: Do use `hostPath` to mount host resources like `/var/run/docker.sock` and `/dev/cgroups`.
    Do not use it to inject configuration files or store the state of an application.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 确实要使用`hostPath`来挂载主机资源，如`/var/run/docker.sock`和`/dev/cgroups`。不要使用它来注入配置文件或存储应用程序的状态。
- en: 'We''ll move onto a more exotic volume type. But, before that, we''ll remove
    the Pod we''re currently running:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续讨论一种更为特殊的卷类型。但在此之前，我们将删除当前运行的Pod：
- en: '[PRE32]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Using gitRepo to mount a Git repository
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用gitRepo挂载Git仓库
- en: The `gitRepo` volume type is probably not going to be on your list of top three
    volume types. Or, maybe it will. It all depends on your use cases. I like it since
    it demonstrates how a concept of a volume can be extended to a new and innovative
    solution.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`gitRepo`卷类型可能不会出现在你列出的前三大卷类型中。或者，也可能会。它完全取决于你的使用场景。我喜欢它，因为它展示了如何将卷的概念扩展到新的创新解决方案。'
- en: 'Let''s see it in action through the `volume/github.yml` definition:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过`volume/github.yml`定义来查看其实际效果：
- en: '[PRE33]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output is as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE34]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This Pod definition is very similar to `volume/docker.yml`. The only significant
    difference is that we added the second `volumeMount`. It will mount the directory
    `/src` inside the container, and will use the volume named `github`. The volume
    definition is straightforward. The `gitRepo` type defines the Git `repository`
    and the `directory`. If we skipped the latter, we'd get the repository mounted
    as `/src/go-demo-2`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Pod 定义与`volume/docker.yml`非常相似。唯一显著的区别是我们添加了第二个`volumeMount`。它将在容器内部挂载`/src`目录，并使用名为`github`的卷。卷的定义非常简单。`gitRepo`类型定义了Git`repository`和`directory`。如果我们省略后者，仓库将作为`/src/go-demo-2`挂载。
- en: The `gitRepo` volume type allows a third field which we haven't used. We could
    have set a specific `revision` of the repository. But, for demo purposes, the
    `HEAD` should do.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`gitRepo`卷类型允许使用第三个字段，但我们没有使用它。我们本可以设置仓库的特定`revision`。不过，出于演示目的，`HEAD`应该足够了。'
- en: Let's create the Pod.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建Pod。
- en: '[PRE35]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now that we created the Pod, we''ll enter its only container, and check whether
    `gitRepo` indeed works as expected:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了Pod，我们将进入其唯一的容器，并检查`gitRepo`是否如预期工作：
- en: '[PRE36]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We entered into the container of the Pod, switched to the `/src` directory,
    and listed all the files and directories inside it. That proved that `gitRepo`
    mounted a volume with the contents of the `vfarcic/go-demo-2` GitHub repository.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进入Pod的容器，切换到`/src`目录，并列出了其中的所有文件和目录。这证明了`gitRepo`将`vfarcic/go-demo-2`GitHub仓库的内容挂载为一个卷。
- en: '![](img/edf5c060-dfc3-4ff6-9a70-ae0bdcddfff9.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/edf5c060-dfc3-4ff6-9a70-ae0bdcddfff9.png)'
- en: 'Figure 8-3: GitHub repository mounted inside a container'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8-3：GitHub 仓库挂载在容器内
- en: 'Since the Pod container is based on the `docker` image, and the socket is mounted
    as well, we should be able to build the image using the source code provided by
    the `gitRepo` volume:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Pod 容器基于`docker`镜像，并且插座也已挂载，我们应该能够使用由`gitRepo`卷提供的源代码来构建镜像：
- en: '[PRE37]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This time, the build should be very fast since we already have the same image
    on the host, and the source code did not change in the meantime. You should see
    a `Using cache` notification for each layer of the image we're building.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，构建应该非常快速，因为我们已经在主机上有了相同的镜像，而且在此期间源代码没有发生变化。你应该能看到每个构建层都有一个`Using cache`的通知。
- en: 'Since we now proved the point, let''s get out of the container and remove the
    Pod:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经证明了这一点，接下来让我们退出容器并移除 Pod：
- en: '[PRE38]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '`gitRepo` is a nifty little addition to the volume types. It does not save
    us a lot of work, nor does it provide something truly exceptional. We could accomplish
    the same result by using an image with `git` and execute a simple `git clone`
    command. Still, the volume type might come in handy on a few occasions. The more
    we have defined in YAML files, the less we depend on ad-hoc commands. That way,
    we can aim towards fully documented processes.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`gitRepo`是一个小巧的新增功能，它并没有为我们节省大量工作，也没有提供什么真正特别的功能。我们可以通过使用带有`git`的镜像并执行简单的`git
    clone`命令来达到相同的效果。不过，这种卷类型在某些情况下可能会派上用场。我们在 YAML 文件中定义的内容越多，就越不依赖临时命令。这样，我们就能朝着完全文档化的流程迈进。'
- en: The `gitRepo` volume type helps us move `git` commands (for example, `git clone`)
    into the YAML definition. It also removes the need for the `git` binary inside
    containers. While `gitRepo` might not always be the best option, it is indeed
    something worth considering.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`gitRepo`卷类型帮助我们将`git`命令（例如`git clone`）移到 YAML 定义中。它还消除了容器中需要`git`二进制文件的需求。虽然`gitRepo`可能并不总是最佳选择，但它确实是值得考虑的一个选项。'
- en: Persisting state through the emptyDir volume type
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过 emptyDir 卷类型持久化状态
- en: This time we'll deploy Jenkins and see what challenges we will face.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，我们将部署 Jenkins，看看会遇到什么挑战。
- en: 'Let''s take a look at the `volume/jenkins.yml` definition:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看看`volume/jenkins.yml`的定义：
- en: '[PRE39]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output is as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE40]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: There's nothing special in that YAML file. It defines an Ingress with `/jenkins`
    path, a Deployment, and a Service. We won't waste time with it. Instead, we'll
    move on and create the objects.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 YAML 文件没有什么特别的。它定义了一个路径为`/jenkins`的 Ingress，一个 Deployment 和一个 Service。我们不会浪费时间在这些上，而是继续前进并创建这些对象。
- en: '[PRE41]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We created the objects and waited until the processes finished. Now we can
    open Jenkins in our browser of choice:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了对象并等待进程完成。现在，我们可以在我们选择的浏览器中打开 Jenkins：
- en: '[PRE42]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Jenkins UI opened, thus confirming that the application is deployed correctly.
    Jenkins'' primary function is to execute jobs, so it''s only fair to create one:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Jenkins UI 已经打开，确认应用程序已正确部署。Jenkins 的主要功能是执行作业，因此理应创建一个作业：
- en: '[PRE43]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Please type `test` in the item name field, select `Pipeline` as the type, and
    click the OK button.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 请在项目名称字段中输入`test`，选择`Pipeline`作为类型，然后点击“OK”按钮。
- en: There's no need to make the Pipeline do any specific set of tasks. For now,
    you should be fine if you just Save the job.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 不需要让 Pipeline 执行任何特定的任务。现在，只要你保存作业，就应该没有问题。
- en: 'Let''s explore what happens if the main process inside the Jenkins container
    dies:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一下如果 Jenkins 容器中的主进程终止会发生什么：
- en: '[PRE44]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We retrieved the name of the Pod, and we used it to execute `kill 1` inside
    its only container. The result is a simulation of a failure. Soon afterward, Kubernetes
    detected the failure and recreated the container. Let's double-check all that.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检索到了 Pod 的名称，并使用它在唯一的容器中执行了`kill 1`命令。结果是模拟了一个失败。很快，Kubernetes 检测到这个失败并重新创建了容器。让我们再检查一遍。
- en: '[PRE45]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The output is as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE46]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We can see that a container is running. Since we killed the main process and,
    with it, the first container, the number of restarts was increased to one.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到有一个容器正在运行。由于我们杀掉了主进程，并且因此杀死了第一个容器，重启次数增加到了 1。
- en: Let's go back to Jenkins UI and check what happened to the job. I'm sure you
    already know the answer, but we'll double check it anyways.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到 Jenkins UI，检查一下作业发生了什么。我相信你已经知道答案了，但我们还是再确认一遍。
- en: '[PRE47]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'As expected, the job we created is gone. When Kubernetes recreated the failed
    container, it created a new one from the same image. Everything we generated inside
    the running container is no more. We reset to the initial state:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，我们创建的任务消失了。当 Kubernetes 重新创建失败的容器时，它是从相同的镜像创建了一个新的容器。在运行中的容器内生成的所有内容都不复存在。我们恢复到了初始状态：
- en: 'Let''s take a look at a slightly updated YAML definition:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看稍作更新的 YAML 定义：
- en: '[PRE48]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The output, limited to the relevant parts, is as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 输出内容（只包括相关部分）如下：
- en: '[PRE49]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We added a mount that references the `jenkins-home` volume. The volume type
    is, this time, `emptyDir`. We''ll discuss the new volume type soon. But, before
    we dive into explanations, we''ll try to experience its effects:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了一个引用 `jenkins-home` 卷的挂载。此时，卷类型是 `emptyDir`。我们很快会讨论这种新的卷类型。但是，在我们深入解释之前，我们先体验一下它的效果：
- en: '[PRE50]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: We applied the new definition and waited until the rollout finished.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用了新的定义，并等待部署完成。
- en: 'Now we can open the New Job Jenkins screen and repeat the same process we followed
    before:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以打开新的 Jenkins 任务屏幕，重复之前的操作：
- en: '[PRE51]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Please type `test` in the item name field, select `Pipeline` as the type, click
    the OK button, and finish by clicking the Save button.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 请在项目名称字段中输入 `test`，选择 `Pipeline` 作为类型，点击确定按钮，然后点击保存按钮完成操作。
- en: 'Now we''ll kill the container and see what happens:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将停止容器并观察会发生什么：
- en: '[PRE52]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: The output should show that there is a container running or, in other words,
    that Kubernetes detected the failure and created a new container.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该显示有一个正在运行的容器，换句话说，Kubernetes 已检测到故障并创建了一个新的容器。
- en: 'Finally, let''s open Jenkins'' Home screen one more time:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们再一次打开 Jenkins 的主页：
- en: '[PRE53]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'This time, the `test` job is there. The state of the application was preserved
    even when the container failed, and Kubernetes created a new one:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，`test` 任务仍然存在。即使容器失败，应用程序的状态也得以保留，并且 Kubernetes 创建了一个新的容器：
- en: '![](img/4a0c9a7f-e811-421a-86bb-60a6de474730.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4a0c9a7f-e811-421a-86bb-60a6de474730.png)'
- en: 'Figure 8-4: Jenkins with preserved state'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8-4：带有持久化状态的 Jenkins
- en: Now let's talk about the `emptyDir` volume. It is considerably different from
    those we explored thus far.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来讨论一下 `emptyDir` 卷。它与我们到目前为止探索的那些卷有显著不同。
- en: An emptyDir Volume is created when a Pod is assigned to a node. It will exist
    for as long as the Pod continues running on that server.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Pod 被分配到一个节点时，会创建一个 `emptyDir` 卷。只要 Pod 继续在该服务器上运行，该卷就会一直存在。
- en: What that means is that `emptyDir` can survive container failures. When a container
    crashes, a Pod is not removed from the node. Instead, Kubernetes will recreate
    the failed container inside the same Pod and, thus, preserve the `emptyDir` Volume.
    All in all, this volume type is only partially fault-tolerant.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着 `emptyDir` 可以在容器失败时继续存活。当容器崩溃时，Pod 不会从节点中移除。相反，Kubernetes 会在同一个 Pod 内重新创建失败的容器，从而保留
    `emptyDir` 卷。总的来说，这种卷类型只具有部分容错能力。
- en: If `emptyDir` is not entirely fault-tolerant, you might be wondering why we
    are discussing it in the first place.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `emptyDir` 并不完全具有容错性，你可能会想知道为什么我们一开始要讨论它。
- en: The `emptyDir` volume type is closest we can get to fault-tolerant volumes without
    using a network drive. Since we do not have any, we had to resort to `emptyDir`
    as the-closest-we-can-get-to-fault-tolerant-persistence type of Volume.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`emptyDir` 卷类型是我们在不使用网络驱动器的情况下能接近容错卷的最接近类型。由于我们没有网络驱动器，所以我们不得不使用 `emptyDir`
    作为最接近容错持久化的卷类型。'
- en: As you start deploying third-party applications, you'll discover that many of
    them come with the recommended YAML definition. If you pay closer attention, you'll
    notice that many are using `emptyDir` volume type. It's not that `emptyDir` is
    the best choice, but that it all depends on your needs, your hosting provider,
    your infrastructure, and quite a few other things. There is no one-size-fits-all
    type of persistent and fault-tolerant volume type. On the other hand, `emptyDir`
    always works. Since it has no external dependencies, it is safe to put it as an
    example, with the assumption that people will change to whichever type fits them
    better.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始部署第三方应用程序时，你会发现许多应用程序都附带了推荐的 YAML 定义。如果你仔细观察，会注意到很多使用了 `emptyDir` 卷类型。并不是说
    `emptyDir` 是最好的选择，而是它完全取决于你的需求、托管服务商、基础设施以及其他许多因素。没有一种“通用适用”的持久性和容错性卷类型。另一方面，`emptyDir`
    总是能工作。由于它没有外部依赖，因此可以将其作为示例，假设人们会根据需要更改为更适合自己的卷类型。
- en: There is an unwritten assumption that `emptyDir` is used for testing purposes,
    and will be changed to something else before it reaches production.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个不成文的假设，即`emptyDir`是用于测试目的的，并将在正式进入生产环境之前更换为其他方案。
- en: As long as we're using Minikube to create a Kubernetes cluster, we'll use `emptyDir`
    as a solution for persistent volumes. Do not despair. Later on, once we move into
    a "more serious" cluster setup, we'll explore better options for persisting state.
    For now, you have a taste. The full (and persistent) meal is coming later.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 只要我们使用Minikube来创建Kubernetes集群，就会使用`emptyDir`作为持久卷的解决方案。不要灰心。稍后，一旦我们转向更“正式”的集群配置，我们将探索更好的持久化状态的方案。目前，你已经初步体验过。真正的（且持久的）内容将在之后呈现。
- en: What now?
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现在怎么办？
- en: With the exception of `emptyDir`, our choice of volume type demonstrated in
    this chapter was not simply based on the ability to use them in a Minikube cluster.
    Each of these three volume types will be an essential piece in the chapters that
    follow. We'll use `hostPath` to access Docker server from inside containers. The
    `gitRepo` volume type will be very significant once we start designing a continuous
    deployment pipeline. The `emptyDir` type will be required as long as we're using
    Minikube. Until we have a better solution for creating a Kubernetes cluster, `emptyDir`
    will continue to be used in our Minikube examples.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`emptyDir`，我们在本章中展示的卷类型选择并不仅仅是基于它们在Minikube集群中使用的能力。这三种卷类型中的每一种都将在接下来的章节中成为关键部分。我们将使用`hostPath`从容器内部访问Docker服务器。`gitRepo`卷类型在我们开始设计持续部署管道时将变得非常重要。只要我们使用Minikube，`emptyDir`类型就会是必需的。在我们找到更好的Kubernetes集群创建方案之前，`emptyDir`将继续在我们的Minikube示例中使用。
- en: We have only scratched the surface with volumes. There are at least two more
    that we should explore inside Minikube, and one (or more) when we change to a
    different solution for creating a cluster. The volumes that we'll explore throughout
    the rest of the book are long enough subjects to deserve a separate chapter or,
    as we already mentioned, require that we get rid of Minikube. For now, we'll just
    destroy the cluster and take a break.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们才刚刚触及卷的表面。至少还有两种卷类型我们应该在Minikube中进一步探索，另外一种（或更多）则是当我们转向其他集群创建方案时需要探索的内容。整个书籍中将要探索的卷是一个足够庞大的主题，值得单独成章，或者，正如我们已经提到的，需要我们摆脱Minikube。现在，我们将销毁集群并休息一下。
- en: '[PRE54]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: If you'd like to know more about Volumes, please explore Volume v1 core ([https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#volume-v1-core](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#volume-v1-core))
    API documentation.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于卷的信息，请参考卷v1核心的API文档（[https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#volume-v1-core](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#volume-v1-core)）。
- en: The next chapter is dedicated to the `configMap` volume type. It will, hopefully,
    solve a few problems and provide better solutions to some use-cases than those
    we employed in this chapter. ConfigMaps deserve a full chapter, so they're getting
    one.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将专注于`configMap`卷类型。希望它能够解决一些问题，并提供比本章中使用的方案更好的解决方案。ConfigMap值得单独成章，所以它将有一章内容。
- en: '![](img/b1ad4db4-979a-48a2-9166-a07d83085772.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1ad4db4-979a-48a2-9166-a07d83085772.png)'
- en: 'Figure 8-5: The components explored so far'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图8-5：迄今为止探索的组件
