- en: Chapter 6. Configuration Management in the Docker World
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Anyone managing more than a few servers can confirm that doing such a task manually
    is a waste of time and risky. **Configuration management** (**CM**) exists for
    a long time, and there is no single reason I can think of why one would not use
    one of the tools. The question is not whether to adopt one of them but which one
    to choose. Those that already embraced one or the other and invested a lot of
    time and money will probably argue that the best tool is the one they chose. As
    things usually go, the choices change over time and the reasons for one over the
    other might not be the same today as they were yesterday. In most cases, decisions
    are not based on available options but by the architecture of the legacy system,
    we are sworn to maintain. If such systems are to be ignored, or someone with enough
    courage and deep pockets would be willing to modernize them, today's reality would
    be dominated by containers and microservices. In such a situation, the choices
    we made yesterday are different from choices we could make today.
  prefs: []
  type: TYPE_NORMAL
- en: CFEngine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CFEngine can be considered the father of configuration management. It was created
    in 1993 and revolutionized the way we approach server setups and configurations.
    It started as an open source project and become commercialized in 2008 when the
    first enterprise version was released.
  prefs: []
  type: TYPE_NORMAL
- en: CFEngine is written in C, has only a few dependencies and is lightning fast.
    Actually, as to my knowledge, no other tool managed to overcome CFEngine's speed.
    That was, and still is its main strength. However, it had its weaknesses, with
    the requirement for coding skills being probably the main one. In many cases,
    an average operator was not able to utilize CFEngine. It requires a C developer
    to manage it. That did not prevent it from becoming widely adopted in some of
    the biggest enterprises. However, as youth usually wins over age, new tools were
    created, and today rarely anyone chooses CFEngine without being forced to do so
    due to the investment the company made into it.
  prefs: []
  type: TYPE_NORMAL
- en: Puppet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Later on, Puppet came into being. It also started as an open source project
    followed by the enterprise version. It was considered more "operations friendly"
    thanks to its model-driven approach and small learning curve when compared to
    CFEngine. Finally, there was a configuration management tool that operations department
    could leverage. Unlike C utilized by CFEngine, Ruby proved to be easier to reason
    with and more accepted by ops. CFEngine's learning curve was probably the main
    reason Puppet got its footing into the configuration management market and slowly
    sent CFEngine into history. That does not mean that CFEngine is not used any more.
    It is, and it doesn't seem it will disappear anytime soon in the same way as Cobol
    is still present in many banks and other finance related businesses. However,
    it lost its reputation for being the weapon of choice.
  prefs: []
  type: TYPE_NORMAL
- en: Chef
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Then came Chef promising to solve some of the nuances of Puppet. And it did,
    for a while. Later, as the popularity of both Puppet and Chef continued increasing,
    they entered the zero sum game. As soon as one of them came up with something
    new or some improvement, the other one adopted it. Both feature an ever increasing
    number of tools that tend to increase their learning curves and complexity. Chef
    is a bit more "developer friendly" while Puppet could be considered more oriented
    towards operations and sysadmin type of tasks. Neither has a clear enough advantage
    over the other, and the choice is often based on personal experience than anything
    else. Both Puppet and Chef are mature, widely adopted (especially in enterprise
    environments) and have an enormous number of open source contributions. The only
    problem is that they are too complicated for what we are trying to accomplish.
    Neither of them was designed with containers in mind. Neither of them could know
    that the game would change with Docker since it didn't exist at the time they
    were designed.
  prefs: []
  type: TYPE_NORMAL
- en: All of the configuration management tools we mentioned thus far are trying to
    solve problems that we should not have the moment we adopt containers and immutable
    deployments. The server mess that we had before is no more. Instead of hundreds
    or even thousands of packages, configuration files, users, logs, and so on, we
    are now trying to deal with a lot of containers and very limited amount of anything
    else. That does not mean that we do not need configuration management. We do!
    However, the scope of what the tool of choice should do is much smaller. In most
    cases, we need a user or two, Docker service up and running and a few more things.
    All the rest are containers. Deployment is becoming a subject of a different set
    of tools and redefining the scope of what CM should do. Docker Compose, Mesos,
    Kubernetes, and Docker Swarm, are only a few of a rapidly increasing number of
    deployment tools we might use today. In such a setting, our configuration management
    choice should value simplicity and immutability over other things. Syntax should
    be simple and easy to read even to those who never used the tool. Immutability
    can be accomplished by enforcing a push model that does not require anything to
    be installed on the destination server.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ansible tries to solve the same problems as other configuration management tools
    but in a very different way. One significant difference is that it performs all
    its operations over SSH. CFEngine and Puppet require clients to be installed on
    all servers they are supposed to manage. While Chef claims that it doesn't, its
    support for agent-less running has limited features. That in itself is a huge
    difference when compared to Ansible that does not require servers to have anything
    special since SSH is (almost) always present. It leverages well defined and widely
    used protocol to run whatever commands need to be run to make sure that the destination
    servers comply with our specifications. The only requirement is Python that is
    already pre-installed on most Linux distributions. In other words, unlike competitors
    that are trying to force you to setup servers in a certain way, Ansible leverages
    existing realities and does not require anything. Due to its architecture, all
    you need is a single instance running on a Linux or OS X computer. We can, for
    example, manage all our servers from a laptop. While that is not advisable and
    Ansible should probably run on a real server (preferably the same one where other
    continuous integration and deployment tools are installed), laptop example illustrates
    its simplicity. In my experience, push-based systems like Ansible are much easier
    to reason with than pull based tools we discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Learning Ansible takes a fraction of the time when compared to all the intricacies
    required to master the other tools. Its syntax is based on YAML and with a single
    glimpse over a playbook, even a person who never used the tool would understand
    what's going on. Unlike Chef, Puppet and, especially CFEngine that are written
    by developers for developers, Ansible is written by developers for people who
    have better things to do than learn yet another language and/or DSL.
  prefs: []
  type: TYPE_NORMAL
- en: Some would point out that the major downside is Ansible's limited support for
    Windows. The client does not even run on Windows, and the number of modules that
    can be used in playbooks and run on it is very limited. This downside, assuming
    that we are using containers is, in my opinion, an advantage. Ansible developers
    did not waste time trying to create an all around tool and concentrated on what
    works best (commands over SSH on Linux). In any case, Docker is not yet ready
    to run containers in Windows. It might be in the future but at this moment (or,
    at least, the moment I was writing this text), this is on the roadmap. Even if
    we ignore containers and their questionable future on Windows, other tools are
    also performing much worse on Windows than Linux. Simply put, Windows architecture
    is not as friendly to the CM objectives as Linux is.
  prefs: []
  type: TYPE_NORMAL
- en: I probably went too far and should not be too harsh on Windows and question
    your choices. If you do prefer Windows servers over some Linux distribution, all
    my praise of Ansible is in vain. You should choose Chef or Puppet and, unless
    you already use it, ignore CFEngine.
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If someone asked me few years ago which tool should we use I would have a hard
    time answering. Today, if one has the option to switch to containers (be it Docker
    or some other type) and immutable deployments, the choice is clear (at least among
    tools I mentioned). Ansible (when combined with Docker and Docker deployment tools)
    wins any time of the day. We might even argue whether CM tools are needed at all.
    There are examples when people fully rely upon, let's say, CoreOS, containers,
    and deployment tools like Docker Swarm or Kubernetes. I do not have such a radical
    opinion (yet) and think that CM continues being a valuable tool in the arsenal.
    Due to the scope of the tasks CM tools needs to perform, Ansible is just the tool
    we need. Anything more complicated or harder to learn would be overkill. I am
    yet to find a person who had trouble maintaining Ansible playbooks. As a result,
    configuration management can quickly become the responsibility of the whole team.
    I'm not trying to say that infrastructure should be taken lightly (it definitely
    shouldn't). However, having contributions from the entire team working on a project
    is a significant advantage for any type of tasks and CM should not be an exception.
    CFEngine, Chef, and Puppet are an overkill with their complex architecture and
    their steep learning curve, at least, when compared with Ansible.
  prefs: []
  type: TYPE_NORMAL
- en: The four tools we briefly went through are by no means the only ones we can
    choose from. You might easily argue that neither of those is the best and vote
    for something else. Fair enough. It all depends on preferences and objectives
    we are trying to archive. However, unlike the others, Ansible can hardly be a
    waste of time. It is so easy to learn that, even if you choose not to adopt it,
    you won't be able to say that a lot of valuable time was wasted. Besides, everything
    we learn brings something new and makes us better professionals.
  prefs: []
  type: TYPE_NORMAL
- en: You probably guessed by now that Ansible will be the tool we'll use for configuration
    management.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the Production Environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let us see Ansible in action and then discuss how it is configured. We'll need
    two VMs up and running; the `cd` will be used as a server from which we'll set
    up the prod node.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The important thing about Ansible (and configuration management in general)
    is that we are in most cases specifying the desired state of something instead
    commands we want to run. Ansible, in turn, will do its best to make sure that
    the servers are in that state. From the output above we can see that statuses
    of all tasks are *changed* or *skipping*. For example, we specified that we want
    Docker service. Ansible noticed that we do not have it on the destination server
    (*prod*) and installed it.
  prefs: []
  type: TYPE_NORMAL
- en: What happens if we run the playbook again?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You''ll notice that the status of all the tasks is `ok`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Ansible went to the server and checked the status of all tasks, one at the time.
    Since this is the second run and we haven't modified anything in the server, Ansible
    concluded that there is nothing to do. The current state is as expected.
  prefs: []
  type: TYPE_NORMAL
- en: The command we just run (`ansible-playbook prod.yml -i hosts/prod`) is simple.
    The first argument is the path to the playbook and the second argument's value
    represents the path to the inventory file that contains the list of servers where
    this playbook should run.
  prefs: []
  type: TYPE_NORMAL
- en: That was a very simple example. We had to setup the production environment and,
    at this moment, all we needed is Docker, Docker Compose, and a few configuration
    files. Later on, we'll see more complicated examples.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've seen Ansible in action let us go through the configuration of
    the *playbook* we just run (twice).
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up the Ansible Playbook
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The content of the `prod.yml` Ansible playbook is as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Just by reading the playbook one should be able to understand what's it about.
    It is running on hosts called *prod* as the user *vagrant* and executes commands
    as `sudo`. At the bottom is the list of roles that, in our case, consists of only
    two; `common` and `docker`. Role is a set of tasks that we usually organize around
    one functionality, product, type of operations, and so on. The Ansible playbook
    organization is based on tasks that are grouped into roles that can be combined
    into playbooks.
  prefs: []
  type: TYPE_NORMAL
- en: Before we take a look at it, let us discuss what are the objectives of the *docker*
    role. We want to make sure that the Docker Debian repository is present and that
    the latest *docker-engine* package is installed. Later on, we'll need the `docker-py`
    (Python API client for Docker) that can be installed with `pip` so we're making
    sure that both are present in our system. Next, we need the standard Docker configuration
    to be replaced with our file located in the *files* directory. Docker configurations
    require Docker service to be restarted, so we have to do just that every time
    there is a change to the `files/docker` file. Finally, we're making sure that
    the user *vagrant* is added to the group *docker* and, therefore, able to run
    Docker commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us take a look at the `roles/docker` directory that defines the role we''re
    using. It consists of two sub-directories, `files`, and `tasks`. Tasks are the
    heart of any role and, by default, requires them to be defined in the `main.yml`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Since we'll be running Docker on both Debian (Ubuntu) and CentOS or Red Hat,
    roles are split into `debian.yml` and `centos.yml` files. Right now, we'll be
    using Ubuntu so let's take a look at the `roles/docker/tasks/debian.yml` role.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If this would be a different framework or a tool, I would pass through each
    of the tasks and explain them one by one, and you would be very grateful for acquiring
    more pieces of wisdom. However, I do not think there is a reason to do that. Ansible
    is very straightforward. Assuming that you have a basic Linux knowledge, I bet
    you can understand each of the tasks without any further explanation. In case
    I was wrong, and you do need an explanation, please look for the module in question
    in the [http://docs.ansible.com/ansible/list_of_all_modules.html](http://docs.ansible.com/ansible/list_of_all_modules.html)
    of the Ansible documentation. For example, if you''d like to know what the second
    task does, you''d open the apt module. The only important thing to know for now
    is how the indentation works. YAML is based on `key: value`, `parent/child` structure.
    For example, the last task has `name` and `state` keys that are children of the
    `service` that, in turn, is one of the Ansible modules.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one more thing we used with our `prod.yml` playbook. The command we
    executed had the `-i hosts/prod` argument that we used to specify the inventory
    file with the list of hosts the playbook should run on. The `hosts/prod` inventory
    is quite big since it is used throughout the whole book. At the moment, we are
    interested only in the `prod` section since that is the value of the `hosts` argument
    we specified in the playbook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: If we'd like to apply the same configuration to more than one server all we'd
    have to do is add another IP.
  prefs: []
  type: TYPE_NORMAL
- en: We'll see more complex examples later on. I intentionally said more complex
    since nothing is truly complicated in Ansible but, depending on some tasks and
    their interdependency, some roles can be more or less complex. I hope that the
    playbook we just run gave you an approximation of the type of the tool Ansible
    is and I hope you liked it. We'll rely on it for all the configuration management
    tasks and more.
  prefs: []
  type: TYPE_NORMAL
- en: You might have noticed that we never entered the `prod` environment but run
    everything remotely from the `cd` server. The same practice will continue throughout
    the book. With Ansible and few other tools we'll get introduced to, later on,
    there is no need to ssh into servers and do manual tasks. In my opinion, our knowledge
    and creativity should be used for coding and everything else should be automatic;
    testing, building, deployment, scaling, logging, monitoring, and so on. That is
    one of the takeaways of this book. The key to success is massive automation that
    frees us to do exciting and more productive tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, we''ll end this chapter by destroying all the VMs. The next chapter
    will create those we need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: With the first production server up and running (at the moment only with Ubuntu
    OS, Docker, and Docker Compose) we can continue working on the basic implementation
    of the deployment pipeline.
  prefs: []
  type: TYPE_NORMAL
