<html><head></head><body>
        

                            
                    Deploying Multi-Container Applications
                
            
            
                
<p>In this chapter, we will learn about the Docker Compose tool, a key component of any Docker environment. Using Docker Compose, we can manage multi-container applications, and all the actions and functionalities we usually use to manage a container-based application will be made available in multi-container environments by Docker Compose. We are able to build all the required images for a project at once. There is no need to build, pull/push, and execute containers one by one. We can declare all the pieces, along with their interconnections, storage, environments, and so on, in a single file. We are also able to debug multi-container applications from a single endpoint, which is vital when you have many separate elements running on production environments.</p>
<p>But this is not just a tool. Docker Compose declares a new type of file, <kbd>docker-compose.yaml</kbd>. This file provides all the requirements for multi-container applications and can be used with other Docker tools. The introduction of this kind of file is very important because it was the basis for Swarm-orchestrated deployments and the newest CNAB-based applications. We will not cover <strong>Cloud-Native Application Bundles</strong> (<strong>CNABs</strong>) in this book, but if you are interested, take a look at <a href="https://cnab.io.">https://cnab.io.</a> Docker has its own CNAB implementation, but it is in the experimental stage at the time of writing this book and is not part of the DCA exam.</p>
<p>In this chapter, we will review Docker Compose. We will learn how to install this tool with different methods, along with its keys and how we should use them. We will discover some of the actions provided by the tool and their use cases. We will finish with some tips that will help us to use <kbd>docker-compose</kbd> with variables. This allows us to provision dynamic content for different environments using the same deployment files.</p>
<p>We will cover the following topics in this chapter:</p>
<ul>
<li>Installing and using Docker Compose</li>
<li>Understanding the docker-compose.yaml file</li>
<li>Using docker-compose</li>
<li>Customizing images with docker-compose</li>
<li>Automating your desktop and CI/CD with docker-compose</li>
</ul>
<p>Let's get started!</p>
<h1 id="uuid-eadc1867-9035-4eaf-9656-4e171b8fdf7c">Technical requirements</h1>
<p>In this chapter, we will learn about Dockerized multi-container applications. We'll provide some labs at the end of this chapter that will help you understand and learn the concepts covered. These labs can be run on your laptop or PC using the provided Vagrant standalone environment or any already deployed Docker host of your own. Check the additional information in this book's GitHub code repository at <a href="https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git">https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git</a>.</p>
<p>Check out the following video to see the Code in Action:</p>
<p>"<a href="https://bit.ly/3hz0IB0" target="_blank">https://bit.ly/3hz0IB0</a>"</p>
<h1 id="uuid-5d5b21b7-88d6-4db4-8cd6-b410766bee03">Installing and using Docker Compose</h1>
<p>Before deep-diving into the Docker Compose tool, let's learn about the differences between multi-container applications and multi-service applications:</p>
<ul>
<li>Multi-container applications are applications based on multiple containers. These containers will run together on the same host. Therefore, we can deploy multi-container applications on our laptop or on any other Docker daemon. All application components will run together on a host. As a result, possible network performance issues will be mitigated because all the pieces will run together. Take into account that this deployment will not provide high availability if the host goes down. We will be able to configure the automatic restart of all components, but that is not enough for production.</li>
<li>Multi-service applications are applications based on multiple services. These applications will run using Swarm orchestration and containers will run distributed on different hosts. We will learn about Docker Swarm orchestration in <a href="78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml">Chapter 8</a>, <em>Orchestrating with Docker Swarm</em>. But you should understand that services are the smallest unit of scheduling on Docker Swarm environments. We will not schedule containers; we will schedule a service, based on the execution of a number of tasks. Those tasks are associated with containers; in fact, one container per task. Therefore, a service is represented by a number of tasks (known as replicas) that run containers. We schedule a service in Docker Swarm, setting the number of replicas required to be healthy. Docker Swarm will take care of the container's status. As we mentioned previously, services will run distributed on different hosts. Multi-service application components will usually run distributed cluster-wide. Components' interconnections will rely on internal and external networking, while Swarm provides out-of-the-box high availability based on resilience for all services' tasks. Keep these features in mind. We will learn about the great features behind Swarm and Kubernetes orchestrations in the <em>Container orchestration</em> section.</li>
</ul>
<p>In summary, we deploy multi-container applications on one node while multi-service applications run distributed in different nodes.</p>
<div><kbd>docker-compose</kbd> does not come with Docker packages when you install it. It is a different product. On Docker Desktop for macOS and Windows, Docker Compose is included and ready to use.</div>
<p>The first thing we have to learn about Docker Compose is that it is a Python-based application. Therefore, we can install it as we would any other Python module or download it as a binary file. We can also run <kbd>docker-compose</kbd> within a container. We can find easy instructions at <a href="https://docs.docker.com/compose/install">https://docs.docker.com/compose/install</a>. Notice that at the time of writing, the latest <kbd>docker-compose</kbd> release was 1.24.1. We will use this version for all of the following installation methods.</p>
<h2 id="uuid-a936e077-5058-440a-b360-9d0e6f7948ce">Installing docker-compose as a Python module</h2>
<p>Installation using <kbd>pip</kbd> (the Python module installer) is easy on Linux systems. We will review this method and we will also download the Docker Compose binary. First, we need to have <kbd>pip</kbd> installed on our system. It is a package that's available on almost all Linux systems and, consequently, whether it's already installed or not will depend on the Linux flavor used (the package name can be <kbd>py-pip</kbd>, <kbd>python3-pip</kbd>, or <kbd>pip-python</kbd>; it really depends on your operating system and the Python version used).</p>
<p>We will not cover this package installation and will assume you have <kbd>pip</kbd> installed on your system. We will install the <kbd>docker-compose</kbd> module as the root user to allow all host users to use it.</p>
<p>There is a version of <kbd>pip</kbd> for Python 2.x and another for Python 3.x. Remember that Python 2.x is obsolete nowadays, so it might be time to move to Python 3.x. We will cover Python 3 installation only, for this reason.</p>
<p>We use <kbd>sudo</kbd> as root with <kbd>-H</kbd> to use our logged-in user's home path:</p>
<pre><strong>$ sudo -sH pip install -q docker-compose</strong></pre>
<p>After execution, we will have <kbd>docker-compose</kbd> installed at <kbd>/usr/local/bin/docker-compose</kbd>.</p>
<h2 id="uuid-42629a97-0940-460f-b117-f3cbeeb5808f">Installing docker-compose using downloaded binaries</h2>
<p>Here, we just need <kbd>curl</kbd> or <kbd>wget</kbd> to download the defined version binaries from this project's GitHub page (<a href="https://github.com/docker/compose/releases">https://github.com/docker/compose/releases</a>). Make sure to choose the right binary and version for your architecture processor and system. We will review the installation for the CentOS 7 Linux system, which is used for all our labs:</p>
<pre><strong>$ curl -sL "https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)" -o /tmp/docker-compose</strong><br/><br/><strong>$ sudo chmod +x /tmp/docker-compose</strong><br/><br/><strong>$ sudo mv /tmp/docker-compose /usr/local/bin/docker-compose</strong></pre>
<p>We can also use a container to execute <kbd>docker-compose</kbd>, as we will learn in the next section.</p>
<h2 id="uuid-d2d3bd49-aa4a-4d05-a0c9-29fe1d5f66c0">Executing docker-compose using a container</h2>
<p>This is quite interesting because, as we have learned, executing applications as containers just requires a Docker daemon running on our system. It is a great way to execute applications! In this case, <kbd>run.sh</kbd> is a script that will prepare all the required volumes and parameters (<kbd>curl -L</kbd> will follow redirections and the <kbd>-o</kbd> argument will allow us to choose the destination filename):</p>
<pre><strong>$ sudo curl -L --fail https://github.com/docker/compose/releases/download/1.24.1/run.sh -o /usr/local/bin/docker-compose</strong><br/><br/><strong>$ sudo chmod +x /usr/local/bin/docker-compose</strong></pre>
<p>Docker Compose can also be installed on Windows nodes, as we will learn in the next section.</p>
<h2 id="uuid-1f50cdd5-f1f3-423f-b24f-0e79eaeeae70">Installing docker-compose on Windows servers</h2>
<p>On Windows servers, we will use an elevated PowerShell (that is, run it as administrator).</p>
<div><p class="mce-root">Since GitHub now requires TLS1.2, it is required to run the following on our administrator PowerShell before executing the installation:</p>
<p class="mce-root"><kbd>[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12</kbd></p>
</div>
<p class="mce-root">Once in the administrator's PowerShell, we need to run the following command:</p>
<pre class="mce-root"><strong>Invoke-WebRequest "https://github.com/docker/compose/releases/download/1.24.1/docker-compose-Windows-x86_64.exe" -UseBasicParsing -OutFile $Env:ProgramFiles\Docker\docker-compose.exe</strong></pre>
<p>In the next section, we will learn about Docker Compose files.</p>
<h1 id="uuid-79984e15-0f35-4512-ba11-7255dcc377c1">Understanding the docker-compose.yaml file</h1>
<p>Docker Compose introduces the concept of multi-container applications using an all-in-one application components' definition file. This file is known as <kbd>docker-compose.yaml</kbd>. Usually, we will manage a <kbd>docker-compose.yaml</kbd> file. Notice that this is a YAML file; therefore, indentation is fundamental. The file will contain all of the application components and their properties.</p>
<p>This is how a simple <kbd>docker-compose.yaml</kbd> file looks (we can use either the <kbd>.yaml</kbd> or <kbd>.yml</kbd> extension for YAML files):</p>
<pre>version: "3.7"<br/>services:<br/>  lb:<br/>    build: simplestlb<br/>    image: myregistry/simplest-lab:simplestlb<br/>    environment:<br/>      - APPLICATION_ALIAS=simplestapp<br/>      - APPLICATION_PORT=3000<br/>    networks:<br/>      simplestlab:<br/>          aliases:<br/>          - simplestlb<br/>    ports:<br/>      - "8080:80"<br/>  db:<br/>    build: simplestdb<br/>    image: myregistry/simplest-lab:simplestdb<br/>    environment:<br/>        - "POSTGRES_PASSWORD=changeme"<br/>    networks:<br/>       simplestlab:<br/>        aliases:<br/>          - simplestdb<br/>    volumes:<br/>      - pgdata:/var/lib/postgresql/data<br/>  app:<br/>    build: simplestapp<br/>    image: myregistry/simplest-lab:simplestapp<br/>    environment:<br/>      - dbhost=simplestdb<br/>      - dbname=demo<br/>      - dbuser=demo<br/>      - dbpasswd=d3m0<br/>    networks:<br/>       simplestlab:<br/>        aliases:<br/>          - simplestapp<br/>    depends_on:<br/>      - lb<br/>      - db<br/>volumes:<br/>  pgdata:<br/>networks:<br/>  simplestlab:<br/>    ipam:<br/>      driver: default<br/>      config:<br/>        - subnet: 172.16.0.0/16</pre>
<p>The <kbd>docker-compose.yaml</kbd> file will contain definitions for all Docker-based application components (services, networks, and volumes). In this file, we first declare the file definition version. This definition manages how Docker Compose should interpret some of the directives written. We will use version 3.x for our file definition because it is the most up to date and is recommended at the time of writing. There are a few differences between versions, although <kbd>docker-compose</kbd> provides backward compatibility, so you should check the Docker documentation for more information. It is important to know that keys and definition structures may vary between versions, and you should use specific versions with older Docker engines. We will use version 3.7 (the current version at the time of writing).</p>
<p>Let's learn a bit about the file contents.</p>
<p>We are using environment variables to provide credentials and access to some services. This is just for demo purposes – never use environment variables for your passwords, credentials, or connection strings. In Docker Swarm, we use secrets and configuration objects. In Docker Compose, we do not have this kind of object, so it's preferred to use external configuration tools or secure key-value stores to manage these values.</p>
<p>We have a section for <kbd>services</kbd> and another one for <kbd>networks</kbd>. We can also have a <kbd>volumes</kbd> section. The <kbd>volumes</kbd> and <kbd>networks</kbd> sections will define their properties for the application. In these sections, we will declare special features and the drivers used for them. In the example file, we have declared a special subnet to use on the <kbd>simplestlab</kbd> network with the default bridge driver. This is the network that will be created and used for all the components, as we can see in all of our service definitions.</p>
<p>In Docker Swarm, we can also define <kbd>Configs</kbd> and <kbd>Secrets</kbd>, which are cluster objects. We will declare objects in one section of the file and then we will use these objects inside each service definition.</p>
<p>Each service represents one component. Let's take a closer look at the definitions of the <kbd>app</kbd> service, for example.</p>
<p>Each service definition has some key configurations to explain how this application component will run. In the <kbd>app</kbd> service, we have a <kbd>build</kbd> definition, which indicates how this component will be created. The value of the <kbd>build</kbd> key indicates the context path for building an image for these components (the <kbd>simplestapp</kbd> directory). Therefore, we can build this component with this <kbd>docker-compose.yaml</kbd> file and the <kbd>simplestapp</kbd> directory content. We've learned that to build an image, we need a Dockerfile; consequently, a Dockerfile is mandatory inside the <kbd>simplestapp</kbd> directory. All the files required to compile the <kbd>myregistry/simplest-lab:simplestapp</kbd> image should be in this directory.</p>
<p>When we talk about multi-container applications with Docker Compose, services definitions are different from Swarm Services, which are managed by Swarm orchestration. In non-Swam environments, we refer to services as application components.</p>
<p>The next line, which contains the <kbd>image</kbd> key, defines the name of the image. If the image does not exist in your host, it will be built with this name. If we do not have a <kbd>build</kbd> definition, the Docker daemon will try to download the defined image from the registry.</p>
<p>The next key defines a list of variables and their values to be used as environment variables during container execution. We can override the image-defined <kbd>ENVIRONMENT</kbd>, <kbd>CMD</kbd>, <kbd>ENTRYPOINT</kbd>, and <kbd>VOLUME</kbd> values, among others, as we usually do within containers. We will take a look at the Docker Compose definitions later, but keep in mind that almost every option we use on the <kbd>docker container run</kbd> or <kbd>docker container create</kbd> actions is available as a key on <kbd>docker-compose.yaml</kbd>.</p>
<p>Then, we define the networks to be used in this component.  We also defined an alias name to use in this network. This component will be known as <kbd>app</kbd>, which is its service name, and also by its defined alias, which is <kbd>simplestapp</kbd>.</p>
<p>It is important to note that Docker Compose allows us to define an order of execution, as we can see in the last few lines. We used the <kbd>depends_on</kbd> key to wait until all the components in the list were available (that is, all the containers were marked as healthy).</p>
<p>With that, we have reviewed the <kbd>services</kbd> section of the preceding code file. In this example, we also have <kbd>volumes</kbd> and <kbd>networks</kbd> sections.</p>
<p>In the <kbd>volumes</kbd> section, we have the simplest definition. It is empty and just defines a volume with the default parameters (the local driver). In the <kbd>services</kbd> section, we define where and how these volumes should be attached.</p>
<p>Now that we know the basics, we can take a look at some of the most used key definitions:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr style="height: 32px">
<td style="width: 26.7714%" class="CDPAlignCenter CDPAlign">
<p><strong>Key</strong></p>
</td>
<td style="width: 72.805%;height: 32px">
<p class="mce-root CDPAlignCenter CDPAlign"><strong>Definitions</strong></p>
</td>
</tr>
<tr style="height: 32px">
<td style="width: 26.7714%">
<p><kbd>build</kbd></p>
</td>
<td style="width: 72.805%;height: 32px">
<p class="mce-root">This key will define the options used to build the application images. These are some of the most used options:</p>
<ul>
<li>
<p><kbd>context</kbd>: This option defines the path to the build context, the directory that contains the Dockerfile, and all the other files required for the image.</p>
</li>
<li>
<p><kbd>dockerfile</kbd>: This defines an alternative Dockerfile name.</p>
</li>
<li>
<p><kbd>args</kbd>: We can set Dockerfile arguments here.</p>
</li>
<li>
<p><kbd>labels</kbd>: This option allows us to set image labels.</p>
</li>
</ul>
</td>
</tr>
<tr style="height: 32px">
<td style="width: 26.7714%">
<p><kbd>image</kbd></p>
</td>
<td style="width: 72.805%;height: 32px">
<p>This is the name of the image to be used. If the image does not exist, it will be pulled from the registry. If the image must be built, it will use this value for its name.</p>
</td>
</tr>
<tr style="height: 32px">
<td style="width: 26.7714%">
<p><kbd>environment</kbd></p>
</td>
<td style="width: 72.805%;height: 32px">
<p>We are able to set environment variables within containers. This will overwrite any image-defined values. We can also use <kbd>env_file</kbd> to define a file with many values.</p>
</td>
</tr>
<tr style="height: 32px">
<td style="width: 26.7714%">
<p><kbd>command</kbd></p>
</td>
<td style="width: 72.805%;height: 32px">
<p>This will set or overwrite the image's <kbd>command</kbd> definition.</p>
</td>
</tr>
<tr style="height: 32px">
<td style="width: 26.7714%">
<p><kbd>entrypoint</kbd></p>
</td>
<td style="width: 72.805%;height: 32px">
<p>This will set or overwrite the image's <kbd>entrypoint</kbd> definition.</p>
</td>
</tr>
<tr style="height: 32px">
<td style="width: 26.7714%">
<p><kbd>ports</kbd></p>
</td>
<td style="width: 72.805%;height: 32px">
<p>These are the ports to be exposed by the services to be reachable at the host level.</p>
</td>
</tr>
<tr style="height: 32px">
<td style="width: 26.7714%">
<p><kbd>expose</kbd></p>
</td>
<td style="width: 72.805%;height: 32px">
<p>This option defines which service ports will be available for other services.</p>
</td>
</tr>
<tr style="height: 32px">
<td style="width: 26.7714%">
<p class="mce-root"><kbd>privileged</kbd></p>
<p><kbd>cap_add/cap_drop</kbd></p>
<p><kbd>read_only</kbd></p>
</td>
<td style="width: 72.805%;height: 32px">
<p>These options will set the same features we learned about when we talked about container execution in <a href="c2dd78c4-066f-40b4-94e7-a7e2904d7ec2.xhtml">Chapter 3</a>, <em>Running Docker Containers</em>.</p>
</td>
</tr>
<tr style="height: 32px">
<td style="width: 26.7714%">
<p><kbd>user</kbd></p>
</td>
<td style="width: 72.805%;height: 32px">
<p>This will set or overwrite the image's <kbd>user</kbd> definition.</p>
</td>
</tr>
<tr style="height: 32px">
<td style="width: 26.7714%">
<p><kbd>labels</kbd></p>
</td>
<td style="width: 72.805%;height: 32px">
<p>This will set or overwrite image labels.</p>
</td>
</tr>
<tr style="height: 10px">
<td style="width: 26.7714%">
<p><kbd>restart</kbd></p>
</td>
<td style="width: 72.805%;height: 10px">
<p>With <kbd>restart</kbd>, we can set how associated containers should be managed. If they die, should Docker restart them or leave them stopped? Remember the options defined for our containers – we will use the same values here.</p>
</td>
</tr>
<tr style="height: 10px">
<td style="width: 26.7714%">
<p><kbd>container_name</kbd></p>
</td>
<td style="width: 72.805%;height: 10px">
<p>We are able to set the container name using this variable. If not defined, the container name will be generated using the service project name as a prefix, followed by the service name and the instance number, starting from <kbd>1</kbd>. Take care with this parameter; as you've already learned, there can only be one container with a defined name per host.</p>
</td>
</tr>
<tr style="height: 10px">
<td style="width: 26.7714%">
<p class="mce-root"><kbd>hostname</kbd></p>
<p class="mce-root"><kbd>domainname</kbd></p>
</td>
<td style="width: 72.805%;height: 10px">
<p>These options will allow us to change the container hostname and its domain name. Under the <kbd>network</kbd> definition, we are able to add as many DNS aliases as required.</p>
</td>
</tr>
<tr style="height: 10px">
<td style="width: 26.7714%">
<p><kbd>extra_hosts</kbd></p>
</td>
<td style="width: 72.805%;height: 10px">
<p>With this option, we can add external hosts to be discovered via internal DNS. This will help us reach external services as if they were running within containers.</p>
</td>
</tr>
<tr style="height: 10px">
<td style="width: 26.7714%">
<p><kbd>depends_on</kbd></p>
</td>
<td style="width: 72.805%;height: 10px">
<p>This key allows us to set components' dependencies. It is deprecated now in version <kbd>3</kbd> but is included here to explain to you that it did not provide real dependency. This option will just control the boot order.</p>
</td>
</tr>
<tr style="height: 10px">
<td style="width: 26.7714%">
<p><kbd>networks</kbd></p>
</td>
<td style="width: 72.805%;height: 10px">
<p class="mce-root">We can set which network drivers to use, their options and subnet ranges, and how they will be accessible (internal and/or attachable). Let's review a simple example:</p>
<pre>networks:<br/>  mynet:<br/>    driver: bridge<br/>    ipam:<br/>      driver: default<br/>      config:<br/>       - subnet: 172.28.0.0/16</pre>
<p>In the preceding code, we have defined <kbd>mynet</kbd> as a bridge network with a defined subnet for all our containers. We can use this defined network on each service section:</p>
<pre>  myservice:<br/> build:<br/> context: .<br/> dockerfile: ./src/myapp/Dockerfile<br/> networks:<br/> - mynet</pre></td>
</tr>
<tr style="height: 10px">
<td style="width: 26.7714%">
<p><kbd>volumes</kbd></p>
</td>
<td style="width: 72.805%;height: 10px">
<p class="mce-root">Volumes are defined in the <kbd>volumes</kbd> section. We will be able to set their drivers and special options. The following is an example of a simple local definition that we can use in the <kbd>services</kbd> section:</p>
<pre>...<br/>...<br/>  myservice:<br/>    image: myregistry/myimage:tag<br/>    volumes:<br/>     - data:/appdata/<br/>...<br/>...<br/>volumes:<br/>  config-data:<br/>    driver: local</pre></td>
</tr>
<tr style="height: 10px">
<td style="width: 26.7714%">
<p><kbd>tmpfs</kbd></p>
</td>
<td style="width: 72.805%;height: 10px">
<p class="mce-root">We can use an in-memory filesystem with <kbd>tmpfs</kbd>. This option is very useful for bypassing the overlay filesystem to improve I/O performance or for security reasons. The in-memory filesystem will disappear when the container dies:</p>
<pre> - type: tmpfs<br/>     target: /app<br/>     tmpfs:<br/>       size: 1000</pre></td>
</tr>
<tr style="height: 10px">
<td style="width: 26.7714%">
<p><kbd>healthcheck</kbd></p>
</td>
<td style="width: 72.805%;height: 10px">
<p>This will set or overwrite the image's <kbd>healthcheck</kbd> definitions.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>These keys are the most commonly used ones. Consult the Docker Compose documentation for more information, which is available on the Docker website at <a href="https://docs.docker.com/compose/compose-file/">https://docs.docker.com/compose/compose-file/</a>.</p>
<p>There are many keys that are only allowed on Docker Swarm environments. We didn't include them in the preceding information table because the Swarm options will be shown in <a href="78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml">Chapter 8</a>, <em>Orchestration Using Docker Swarm</em>. Defining container resource limits in <kbd>docker-compose.yaml</kbd> files is only allowed either using Docker Swarm mode or using Docker Compose version 2.</p>
<p>Once we have created our <kbd>docker-compose.yaml</kbd> file, we will be able to use the Docker Compose command-line definitions written in this file.</p>
<h1 id="uuid-99d33408-47ef-4c86-893a-88b0f6d2e988">Using the Docker Compose command-line interface</h1>
<p>We installed the <kbd>docker-compose</kbd> binary in the previous section, which means we can now review the actions available to us. <kbd>docker-compose</kbd> will provide most of the actions available for Docker because we will execute them on multiple containers at once. Let's review the available <kbd>docker-compose</kbd> actions in the following table:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Command</strong></p>
</td>
<td style="width: 81.766%" class="CDPAlignCenter CDPAlign">
<p><strong>Definition</strong></p>
</td>
</tr>
<tr>
<td>
<p><kbd>build</kbd></p>
</td>
<td style="width: 81.766%">
<p>As expected, this action will build or rebuild all <kbd>docker-compose.yaml</kbd> file components, or just the selected ones. This action will look for any <kbd>build</kbd> keys in our <kbd>docker-compose.yaml</kbd> file and launch a build or rebuild. If we set a project name using <kbd>--project</kbd>, all images will be created as <kbd>&lt;project_name&gt;_&lt;service_name&gt;</kbd> if no image name is defined. If so, this is the name that will be used if we push them to a registry.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>pull</kbd>/<kbd>push</kbd></p>
</td>
<td style="width: 81.766%">
<p>We will be able to push or pull all images at once because we manage all the application components with <kbd>docker-compose</kbd>.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>images</kbd></p>
</td>
<td style="width: 81.766%">
<p>This action will list all application images.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>create</kbd></p>
</td>
<td style="width: 81.766%">
<p>Remember that we can create containers. In this case, we will create all containers required by the application, but they will not be launched until a <kbd>start</kbd> action is executed.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>rm</kbd></p>
</td>
<td style="width: 81.766%">
<p>This action will remove all stopped containers. Remember to use the project name, or leave it empty to use the current directory as the application name.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>up</kbd> (<kbd>-d</kbd> or <kbd>--detach</kbd>)</p>
</td>
<td style="width: 81.766%">
<p>We will create and start all components with this simple action. All the components will run at once. We will use <kbd>--detach</kbd> to run the application in the background, as we learned with containers.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>down</kbd></p>
</td>
<td style="width: 81.766%">
<p>To remove all application components, we will use the <kbd>down</kbd> action. This will end all application containers or just the specified ones. Take care as externally defined resources will not be deleted and must be removed manually.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>start/stop/restart</kbd></p>
</td>
<td style="width: 81.766%">
<p>These options will allow us to manage components, applying either to all components at once or only those specified.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>run</kbd></p>
</td>
<td style="width: 81.766%">
<p>With this option, we can execute one component to run a specified command, such as to initialize a database or create a required file.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>pause</kbd>/<kbd>unpause</kbd></p>
</td>
<td style="width: 81.766%">
<p>As we learned with containers, we can pause and unpause application components.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>ps</kbd></p>
</td>
<td style="width: 81.766%">
<p><kbd>docker-compose</kbd> will show all application containers (processes) and their ports.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>top</kbd></p>
</td>
<td style="width: 81.766%">
<p>This option will show the processes running on each container deployed for the application.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>exec</kbd></p>
</td>
<td style="width: 81.766%">
<p>We will be able to run a process within any application container namespace. Remember what we learned in <a href="c2dd78c4-066f-40b4-94e7-a7e2904d7ec2.xhtml"/><a href="c2dd78c4-066f-40b4-94e7-a7e2904d7ec2.xhtml">Chapter 3</a>, <em>Running Docker Containers</em>.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>logs</kbd></p>
</td>
<td style="width: 81.766%">
<p>It is very useful to be able to retrieve all application container' logs using a single command. We can use the <kbd>logs</kbd> action to retrieve all application logs at once. Logs will appear together, along with their service names, to help us identify each component.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>config</kbd></p>
</td>
<td style="width: 81.766%">
<p>We can verify a Docker Compose definition using the <kbd>config</kbd> action. We can also list the defined services using <kbd>services</kbd> as the argument.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>With this information, we can quickly see how the usual container workflow can be achieved in multi-container environments with Docker Compose, which gives us a new command-line interface to build, share, and run all our application components at once.</p>
<p>We can define external resources such as <kbd>volume</kbd> or <kbd>networks</kbd>. We will use the <kbd>external: true</kbd> option in these cases and you'll have to create these resources manually.</p>
<p>Each application that's deployed using <kbd>docker-compose</kbd> will have its own project definition. Each project will run in isolation alongside others in the same host. By default, <kbd>docker-compose</kbd> will use the current directory name as the project's name. We can override this behavior using <kbd>--project-name</kbd> or <kbd>-p</kbd> to set a more descriptive name.</p>
<p>In <a href="c5ecd7bc-b7ed-4303-89a8-e487c6a220ed.xhtml">Chapter 1</a>, <em>Modern Infrastructures and Applications with Docker</em>, we learned that object names are unique (we can have objects with many names, but each is unique, and we cannot have repeated names); therefore, <kbd>docker-compose</kbd> adds the project's name as a prefix to each created object. This way, we identify all application components and ensure that they have unique names. Of course, we can use the same <kbd>docker-compose</kbd> file to deploy the same application twice, but we should choose a different project name each time.</p>
<p>We can use the <kbd>docker-compose.yaml</kbd> file to launch the same application multiple times, but we cannot share unique resources such as ports, volumes, and IP addresses between volumes. Sharing a volume between components depends on application behavior, but IP addresses or ports will be unique to a given Docker host.</p>
<p>Let's review the complete application deployment workflow with the previous <kbd>docker-compose.yaml</kbd> file (seen in the <em>Understanding the docker-compose file</em> section).</p>
<p>First, we need to build the application images. You can download all the application code from this book's GitHub repository at <a href="https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git.">https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git.</a></p>
<p>Let's clone the repository to get all the source code directories and configuration files. Your output may vary from the following:</p>
<pre><strong>$ git clone https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git</strong><br/><strong>Cloning into 'dca-book-code'...</strong><br/><strong>remote: Enumerating objects: 26, done.</strong><br/><strong>remote: Counting objects: 100% (26/26), done.</strong><br/><strong>remote: Compressing objects: 100% (22/22), done.</strong><br/><strong>remote: Total 26 (delta 0), reused 26 (delta 0), pack-reused 0</strong><br/><strong>Unpacking objects: 100% (26/26), done.</strong></pre>
<p>We will have a directory for the <kbd>simplest-lab</kbd> project with a <kbd>docker-compose.yaml</kbd> file and different directories for each application component:</p>
<pre><strong>$ cd chapter5/simplest-lab/</strong><br/><br/><strong>$ ls -lRt</strong><br/><strong>.:</strong><br/><strong>total 4</strong><br/><strong>-rw-rw-r-- 1 zero zero 982 nov 24 11:06 docker-compose.yaml</strong><br/><strong>drwxrwxr-x 2 zero zero 146 nov 24 11:06 simplestapp</strong><br/><strong>drwxrwxr-x 3 zero zero 112 nov 24 11:06 simplestdb</strong><br/><strong>drwxrwxr-x 2 zero zero 80 nov 24 11:06 simplestlb</strong><br/><strong>./simplestapp:</strong><br/><strong>total 32</strong><br/><strong>-rw-rw-r-- 1 zero zero 91 nov 24 11:06 dbconfig.json</strong><br/><strong>-rw-rw-r-- 1 zero zero 466 nov 24 11:06 Dockerfile</strong><br/><strong>-rw-rw-r-- 1 zero zero 354 nov 24 11:06 package.json</strong><br/><strong>-rw-rw-r-- 1 zero zero 191 nov 24 11:06 README.md</strong><br/><strong>-rw-rw-r-- 1 zero zero 1244 nov 24 11:06 reset.html</strong><br/><strong>-rw-rw-r-- 1 zero zero 3837 nov 24 11:06 simplestapp.html</strong><br/><strong>-rw-rw-r-- 1 zero zero 6556 nov 24 11:06 simplestapp.js</strong><br/><strong>./simplestdb:</strong><br/><strong>total 12</strong><br/><strong>drwxrwxr-x 2 zero zero 26 nov 24 11:06 docker-entrypoint-initdb.d </strong><br/><strong>-rwxrwxr-x 1 zero zero 2587 nov 24 11:06 docker-entrypoint.sh </strong><br/><strong>-rw-rw-r-- 1 zero zero 152 nov 24 11:06 Dockerfile </strong><br/><strong>-rw-rw-r-- 1 zero zero 2568 nov 24 11:06 Dockerfile.scratch</strong><br/><strong>./simplestdb/docker-entrypoint-initdb.d:</strong><br/><strong>total 4</strong><br/><strong>-rw-rw-r-- 1 zero zero 484 nov 24 11:06 init-demo.sh</strong><br/><strong>./simplestlb:</strong><br/><strong>total 16</strong><br/><strong>-rw-rw-r-- 1 zero zero 467 nov 24 11:06 Dockerfile</strong><br/><strong>-rwxrwxr-x 1 zero zero 213 nov 24 11:06 entrypoint.sh</strong><br/><strong>-rw-rw-r-- 1 zero zero 837 nov 24 11:06 nginx.conf</strong><br/><strong>-rw-rw-r-- 1 zero zero 24 nov 24 11:06 README.md</strong></pre>
<p>In each project directory, there is a Dockerfile we can use to build that specific component. So, let's build all the components at once.</p>
<p>We have the same options for removing the intermediate containers (used for building and disallowing image caching) as we had with the <kbd>docker image build</kbd> command. We will use <kbd>--force-rm</kbd> and <kbd>--no-cache</kbd>, respectively.</p>
<p>To ensure that the defined <kbd>docker-compose.yaml</kbd> file is valid, we can use <kbd>docker-compose config --quiet</kbd>. If there is an issue, it will be reported. We can also list the names of the services or volumes that have been defined:</p>
<pre><strong>$ docker-compose config --services</strong><br/><strong>db</strong><br/><strong>lb</strong><br/><strong>app<br/></strong><br/><strong>$ docker-compose config --volumes</strong><br/><strong>pgdata</strong></pre>
<p>We will use these service name definitions later on in this section.</p>
<p>We will execute <kbd>docker-compose build</kbd> to build all the component images defined in our <kbd>docker-compose.yaml</kbd> file. This command will take some time because we are not just building an image, but all the images required. The following output is truncated:</p>
<pre><strong>$ docker-compose build </strong><br/><strong>Building db</strong><br/><strong>Step 1/2 : FROM postgres:alpine</strong><br/><strong>alpine: Pulling from library/postgres</strong><br/><strong>....</strong><br/><strong>Successfully built 336fb84e7fbf</strong><br/><strong>Successfully tagged myregistry/simplest-lab:simplestdb</strong><br/><strong>Building lb</strong><br/><strong>Step 1/10 : FROM alpine:latest</strong><br/><strong>latest: Pulling from library/alpine</strong><br/><strong>....</strong><br/><strong>Successfully built 4a5308d90123</strong><br/><strong>Successfully tagged myregistry/simplest-lab:simplestlb</strong><br/><strong>Building app</strong><br/><strong>Step 1/15 : FROM alpine</strong><br/><strong> ---&gt; 965ea09ff2eb</strong><br/><strong>Step 2/15 : RUN apk --update --no-progress --no-cache add nodejs npm</strong><br/><strong>....</strong><br/><strong>Successfully built ffa49ee4228e</strong><br/><strong>Successfully tagged myregistry/simplest-lab:simplestapp</strong></pre>
<p>After a few minutes (or seconds, depending on your internet connection and processor speed), all three images will be created. As we have not set a project name, <kbd>docker-compose</kbd> has created one for you. As we mentioned previously, by default, all the components will be created with the directory name prefixed. In this case, we have an image key on our <kbd>docker-compose.yaml</kbd> file, so that image naming syntax will be used instead of a local directory reference.</p>
<p>Notice that we have used a dummy registry name (<kbd>myregistry</kbd>). This means that we cannot push images to this dummy registry, but it is important to understand the logic behind image names. If we list current images on our Docker daemon, we should have all the images created for this project:</p>
<pre><strong>$ docker images --filter=reference='myregistry/*:*'</strong><br/><strong>REPOSITORY TAG IMAGE ID CREATED SIZE</strong><br/><strong>myregistry/simplest-lab simplestapp ffa49ee4228e About an hour ago 56.5MB</strong><br/><strong>myregistry/simplest-lab simplestlb 4a5308d90123 About an hour ago 7MB</strong><br/><strong>myregistry/simplest-lab simplestdb 336fb84e7fbf About an hour ago 72.8MB</strong></pre>
<p>Now that we have our images, we can share them. We can now execute the <kbd>docker-compose push</kbd> command to push them to <kbd>myregistry</kbd> (in our example file). This will upload the images one by one with defined tags.</p>
<p class="mce-root">We are ready to run all the application components together using <kbd>docker-compose up</kbd>. To launch it in the background, we will use the <kbd>--detach</kbd> option. If we do not use this option, we will be attached to all our container's standard and error outputs. We learned how to attach to container output in <a href="c2dd78c4-066f-40b4-94e7-a7e2904d7ec2.xhtml">Chapter 3</a>, <em>Running Docker Containers</em>. Remember that this behavior is expected on <kbd>docker container run</kbd> without the <kbd>--detach</kbd> or <kbd>-d</kbd> option:</p>
<pre class="mce-root"><strong>$ docker-compose up --detach</strong><br/><strong>Creating network "simplest-lab_simplestlab" with the default driver</strong><br/><strong>Creating simplest-lab_db_1 ... done</strong><br/><strong>Creating simplest-lab_lb_1 ... done</strong><br/><strong>Creating simplest-lab_app_1 ... done</strong></pre>
<p>With this line, we have just started our application. It is important to understand that <kbd>docker-compose up</kbd> does more than merely execute all the components. In this case, we built our components first, but the <kbd>docker-compose up</kbd> instruction will verify that component images are present on the Docker host. If not, it will build or pull them. If the images are not present, they should be downloaded, and that is what the Docker daemon will do.</p>
<p>The application should be running. Let's verify the execution of all components. We will use <kbd>docker-compose ps</kbd> to obtain the application component status:</p>
<pre><strong>$ docker-compose ps</strong><br/><strong> Name Command State Ports </strong><br/><strong>----------------------------------------------------------------------------------</strong><br/><strong>simplest-lab_app_1 node simplestapp.js 3000 Up 3000/tcp </strong><br/><strong>simplest-lab_db_1 docker-entrypoint.sh postgres Up 5432/tcp </strong><br/><strong>simplest-lab_lb_1 /entrypoint.sh /bin/sh -c ... Up 0.0.0.0:8080-&gt;80/tcp</strong></pre>
<p>Take a look at the application component names. They are all created with the <kbd>simplest-lab</kbd> prefix, followed by <kbd>_</kbd> and the name used in the service definition. This is what we expected because we have not defined a project name. The directory name was used as the project name by default.</p>
<p>We can also see that component names end with <kbd>_</kbd>, followed by a number (in this case, <kbd>1</kbd>). This indicates the number of replicas we have for this component. We use more than one replica for some application components. Keep in mind that Docker Compose does not know anything about our application logic. Therefore, it is up to us to code this component to make it scalable. In our example, we have a three-layer application with three components: a simple load balancer, <kbd>lb</kbd>, an application's backend, <kbd>app</kbd>, and a database component, <kbd>db</kbd>. We will not be able to scale up our database component because this will corrupt the database data. No more than one <kbd>postgres</kbd> process can use a specific set of data files, and this applies to our case. On the other hand, our <kbd>app</kbd> sample application component is prepared to run multiple times.</p>
<p>Let's take a look at our application environment. By reviewing the output of <kbd>docker-compose ps</kbd>, we can see that only one component is exposing its service. We have only published the <kbd>lb</kbd><em><strong> </strong></em>component. This is our application frontend (in fact, it is a load balancer component that will route traffic to different <kbd>app</kbd> component backends). If we open a web browser on <kbd>http://0.0.0.0:8080</kbd>, we will have a web application similar to the one shown in the following screenshot:</p>
<div><img src="img/6dade774-d569-4a90-ace9-8413d2c3bd7a.jpg" style=""/></div>
<p>At this point, the application is already deployed. We can review the component logs using the service name with the <kbd>docker-compose logs</kbd> action. If we do not add a service name, we will be reviewing the logs of all the containers deployed with this <kbd>docker-compose.yaml</kbd> file. This is very useful because we will be able to review all their outputs from a single endpoint. Each component's log will appear in a different color to help us distinguish between them.</p>
<p>For example, to review the database component log, we will use the following command:</p>
<pre><strong>$ docker-compose logs db</strong><br/><strong>Attaching to simplest-lab_db_1</strong><br/><strong>db_1 | </strong><br/><strong>db_1 | PostgreSQL Database directory appears to contain a database; Skipping initialization</strong><br/><strong>db_1 | </strong><br/><strong>db_1 | 2019-11-24 11:57:14.011 UTC [1] LOG: starting PostgreSQL 12.1 on x86_64-pc-linux-musl, compiled by gcc (Alpine 8.3.0) 8.3.0, 64-bit</strong><br/><strong>db_1 | 2019-11-24 11:57:14.011 UTC [1] LOG: listening on IPv4 address "0.0.0.0", port 5432</strong><br/><strong>db_1 | 2019-11-24 11:57:14.011 UTC [1] LOG: listening on IPv6 address "::", port 5432</strong><br/><strong>db_1 | 2019-11-24 11:57:14.025 UTC [1] LOG: listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"</strong></pre>
<p>It is important to notice that the service name is the name defined in our <kbd>docker-compose.yaml</kbd> file. It is not the name of the service running.</p>
<p>All <kbd>docker-compose</kbd> commands need a <kbd>docker-compose.yaml</kbd> file (or any other filename using the <kbd>--file</kbd> or <kbd>-f</kbd> options) and a project name (defined using the <kbd>--project</kbd> or <kbd>-p</kbd> options, or the current directory by default). These two parameters define the instances where all the <kbd>docker-compose</kbd> commands will be applied.</p>
<p>As we did with containers in <a href="c2dd78c4-066f-40b4-94e7-a7e2904d7ec2.xhtml">Chapter 3</a>, <em>Running Docker Containers</em>, we can run a new process within the container's process namespaces using <kbd>docker-compose exec</kbd>:</p>
<pre><strong>$ docker-compose exec app sh</strong><br/><strong>/APP $ ls -lart</strong><br/><strong>total 344</strong><br/><strong>-rwxr-xr-x 1 root root 314658 May 24 2017 Chart.js</strong><br/><strong>-rw-rw-r-- 1 root root 6556 Nov 24 10:06 simplestapp.js</strong><br/><strong>-rw-rw-r-- 1 root root 1244 Nov 24 10:06 reset.html</strong><br/><strong>-rw-rw-r-- 1 root root 354 Nov 24 10:06 package.json</strong><br/><strong>-rw-rw-r-- 1 root root 91 Nov 24 10:06 dbconfig.json</strong><br/><strong>-rw-rw-r-- 1 root root 3826 Nov 24 14:38 simplestapp.html</strong><br/><strong>-rw-r--r-- 1 root root 7654 Nov 24 14:38 package-lock.json</strong><br/><strong>drwxr-xr-x 31 root root 4096 Nov 24 14:38 node_modules</strong><br/><strong>drwxr-xr-x 1 root root 22 Nov 24 14:38 .</strong><br/><strong>drwxr-xr-x 1 root root 6 Nov 24 14:38 ..</strong></pre>
<p>Notice that it allocates a Terminal by default. Therefore, it is not necessary to use the <kbd>-t</kbd> and <kbd>-i</kbd> options.</p>
<p>Using <kbd>docker-compose top</kbd>, we will obtain the consumption of each process on each container:</p>
<pre><strong>$ docker-compose top</strong><br/><strong>simplest-lab_app_1</strong><br/><strong>UID PID PPID C STIME TTY TIME CMD </strong><br/><strong>--------------------------------------------------------------------------</strong><br/><strong>zero 9594 9564 0 15:38 ? 00:00:05 node simplestapp.js 3000</strong><br/><br/><strong>simplest-lab_db_1</strong><br/><strong>UID PID PPID C STIME TTY TIME CMD </strong><br/><strong>-------------------------------------------------------------------------------------------</strong><br/><strong>70 9374 9304 0 15:38 ? 00:00:00 postgres </strong><br/><strong>70 9558 9374 0 15:38 ? 00:00:00 postgres: checkpointer </strong><br/><strong>70 9559 9374 0 15:38 ? 00:00:00 postgres: background writer </strong><br/><strong>70 9560 9374 0 15:38 ? 00:00:00 postgres: walwriter </strong><br/><strong>70 9561 9374 0 15:38 ? 00:00:00 postgres: autovacuum launcher </strong><br/><strong>70 9562 9374 0 15:38 ? 00:00:00 postgres: stats collector </strong><br/><strong>70 9563 9374 0 15:38 ? 00:00:00 postgres: logical replication launcher </strong><br/><strong>70 9702 9374 0 15:38 ? 00:00:00 postgres: demo demo 172.16.0.4(37134) idle</strong><br/><br/><strong>simplest-lab_lb_1</strong><br/><strong> UID PID PPID C STIME TTY TIME CMD </strong><br/><strong>--------------------------------------------------------------------------------------------------------------------</strong><br/><strong>root 9360 9295 0 15:38 ? 00:00:00 nginx: master process nginx -g pid /run/nginx.pid; daemon off;</strong><br/><strong>systemd+ 9467 9360 0 15:38 ? 00:00:01 nginx: worker process </strong><br/><strong>systemd+ 9468 9360 0 15:38 ? 00:00:00 nginx: worker process</strong></pre>
<p>Let's review some of the objects created by this multi-container deployment. We have a new network, with the name defined following the format we learned about previously; that is, <kbd>&lt;project or directory name&gt;_ &lt;defined_network_name&gt;</kbd>. We have not specified a special network type, so, by default, it is a bridge network, as expected. The output may vary in your environment, but the name for the newly deployed network will exist:</p>
<pre><strong>$ docker network ls</strong><br/>NETWORK ID NAME DRIVER SCOPE<br/>0950a6281629 bridge bridge local<br/>82faac964567 host host local<br/>2fb14f721dc3 none null local<br/><strong>a913507af228 simplest-lab_simplestlab bridge local</strong></pre>
<p>Remember that all custom bridge networks manage their own internal DNS resolution. As a result, all services (application components) deployed on the same network can be reached using their service names.</p>
<p>The same occurs with our defined volumes. If we list our local volume, we will get a new volume following the same naming convention. The output may vary in your environment, but the name for the newly deployed volume will exist:</p>
<pre><strong>$ docker volume ls</strong><br/>DRIVER VOLUME NAME<br/>local 3f93b55b105f64dd03a9088405484909d2f8cad83dacc5fb5a53ea27af1f33e6<br/>local mydbdata<br/><strong>local simplest-lab_pgdata</strong><br/>vieux/sshfs:latest sshvolume</pre>
<p>We can stop and start (or restart) any service defined in the <kbd>docker-compose.yaml</kbd> file using their names. The following action will restart all the instances of a defined service:</p>
<pre><strong>$ docker-compose restart lb</strong><br/><strong>Restarting simplest-lab_lb_1 ... done</strong></pre>
<p>Let's go back to the concept of instances. We can have more than one instance of a defined process for a service. This is the reason we have numbered all our instances. As we mentioned previously, the ability of a process to be scaled up or down is not defined in Docker. It is related to your application logic. In this example, we can scale up the number of instances of the <kbd>app</kbd> component. We can use <kbd>docker-compose scale</kbd> to change the number of instances (containers) for a defined application component:</p>
<pre><strong>$ docker-compose scale app=5</strong><br/><strong>WARNING: The scale command is deprecated. Use the up command with the --scale flag instead.</strong><br/><strong>Starting simplest-lab_app_1 ... done</strong><br/><strong>Creating simplest-lab_app_2 ... done</strong><br/><strong>Creating simplest-lab_app_3 ... done</strong><br/><strong>Creating simplest-lab_app_4 ... done</strong><br/><strong>Creating simplest-lab_app_5 ... done</strong></pre>
<p>Note that the <kbd>scale</kbd> action is deprecated, so nowadays, we should use <kbd>docker-compose up --scale &lt;service=number_of_instances&gt;</kbd>.</p>
<p>As a result, we now have five instances of the <kbd>app</kbd> application component. All the instances' IP addresses are added to the internal DNS resolution. Therefore, we can resolve the service name to all the instances' IP addresses in a round-robin sequence:</p>
<pre><strong>$ docker-compose ps</strong><br/><strong> Name Command State Ports </strong><br/><strong>----------------------------------------------------------------------------------</strong><br/><strong>simplest-lab_app_1 node simplestapp.js 3000 Up 3000/tcp </strong><br/><strong>simplest-lab_app_2 node simplestapp.js 3000 Up 3000/tcp </strong><br/><strong>simplest-lab_app_3 node simplestapp.js 3000 Up 3000/tcp </strong><br/><strong>simplest-lab_app_4 node simplestapp.js 3000 Up 3000/tcp </strong><br/><strong>simplest-lab_app_5 node simplestapp.js 3000 Up 3000/tcp </strong><br/><strong>simplest-lab_db_1 docker-entrypoint.sh postgres Up 5432/tcp </strong><br/><strong>simplest-lab_lb_1 /entrypoint.sh /bin/sh -c ... Up 0.0.0.0:8080-&gt;80/tcp</strong></pre>
<p>If we go back to the application GUI at <kbd>http://localhost:8080/</kbd>, we'll notice that the chart has changed because the requests are now distributed across five different backends:</p>
<div><img src="img/d6b7f950-71fd-4472-94ee-529dc36377d4.jpg"/></div>
<p>In this chart, we can see that we now have five different IP addresses and that requests are distributed between them. Because we have been running the application for a long time (and automated requests are executed during this period), we have more requests for the first IP address (the first instance launched).</p>
<p>We can remove previous data from the database using the Reset App Data<em><strong> </strong></em>button. Let's click this button and review the requests count. You can either wait for more requests (a new request is made every 5 seconds) or simply click the Make Request<em><strong> </strong></em>button a few times. You should now have something similar to the following chart:</p>
<div><img src="img/d394fc35-5994-4d32-ba6c-128d21250caf.jpg" style=""/></div>
<p>This chart shows the request distribution of the five defined instances of the <kbd>app</kbd> component. Now, let's scale down to three instances, as follows:</p>
<pre><strong>$ docker-compose up -d --scale app=3</strong><br/><strong>simplest-lab_db_1 is up-to-date</strong><br/><strong>simplest-lab_lb_1 is up-to-date</strong><br/><strong>Stopping and removing simplest-lab_app_4 ... done</strong><br/><strong>Stopping and removing simplest-lab_app_5 ... done</strong><br/><strong>Starting simplest-lab_app_1 ... done</strong><br/><strong>Starting simplest-lab_app_2 ... done</strong><br/><strong>Starting simplest-lab_app_3 ... done</strong></pre>
<p>Now, we can review the <kbd>app</kbd> instances:</p>
<pre><strong>$ docker-compose ps app</strong><br/><strong> Name Command State Ports </strong><br/><strong>----------------------------------------------------------------</strong><br/><strong>simplest-lab_app_1 node simplestapp.js 3000 Up 3000/tcp</strong><br/><strong>simplest-lab_app_2 node simplestapp.js 3000 Up 3000/tcp</strong><br/><strong>simplest-lab_app_3 node simplestapp.js 3000 Up 3000/tcp</strong></pre>
<p>The chart will change again and only three backends will receive requests (there are only three running). Once again, we will use the Reset App Data<em><strong> </strong></em>button and get a chart similar to the following one:</p>
<div><img src="img/9554c1c5-b383-4c91-946f-69df30db4cb9.jpg" style=""/></div>
<p>Take a quick look at the running containers associated with the deployed <kbd>docker-compose.yaml</kbd> application file. In this case, we are using a filter to obtain all the containers with names starting with the <kbd>simplest</kbd> pattern. We formatted the result to obtain only their names and labels:</p>
<div><img src="img/98848394-2b35-45ff-a65a-605e71af5009.png" style=""/></div>
<p>Notice that <kbd>docker-compose</kbd> has added labels for each application component, indicating the name of the project, the container name, and the associated service name.</p>
<p>We can easily stop or kill a single component or all of them at once. We can also remove all the components using the <kbd>down</kbd> or <kbd>rm</kbd> options. Usually, we use <kbd>docker-compose down</kbd> because it is easier to remember. We can also define a timeout for components to stop using <kbd>stop_grace_period</kbd>, which defaults to 10 seconds (review the <kbd>docker-compose</kbd> file reference for available options at <a href="https://docs.docker.com/compose/compose-file/">https://docs.docker.com/compose/compose-file/</a>). Using <kbd>docker-compose down</kbd>, components will be removed once they are stopped:</p>
<pre><strong>$ docker-compose down </strong><br/><strong>Stopping simplest-lab_app_3 ... done</strong><br/><strong>Stopping simplest-lab_app_2 ... done</strong><br/><strong>Stopping simplest-lab_app_1 ... done</strong><br/><strong>Stopping simplest-lab_lb_1 ... done</strong><br/><strong>Stopping simplest-lab_db_1 ... done</strong><br/><strong>Removing simplest-lab_app_3 ... done</strong><br/><strong>Removing simplest-lab_app_2 ... done</strong><br/><strong>Removing simplest-lab_app_1 ... done</strong><br/><strong>Removing simplest-lab_lb_1 ... done</strong><br/><strong>Removing simplest-lab_db_1 ... done</strong><br/><strong>Removing network simplest-lab_simplestlab</strong></pre>
<p>Let's take a look at all the application-related objects. Here, we can see that <kbd>network</kbd> was removed but <kbd>volume</kbd> persists. This is because Docker does not know what to do with the volume. Are we going to use it later? Consequently, it is preferred not to delete the volume unless we use the <kbd>docker-compose down --volumes</kbd> (or <kbd>-v</kbd>) option to remove all the volumes associated with the application:</p>
<pre><strong>$ docker volume ls</strong><br/>DRIVER VOLUME NAME<br/>local 3f93b55b105f64dd03a9088405484909d2f8cad83dacc5fb5a53ea27af1f33e6<br/>local mydbdata<br/><strong>local simplest-lab_pgdata</strong><br/>vieux/sshfs:latest sshvolume<br/><br/><strong>$ docker network ls</strong><br/>NETWORK ID NAME DRIVER SCOPE<br/>0950a6281629 bridge bridge local<br/>82faac964567 host host local<br/>2fb14f721dc3 none null local</pre>
<p>In this section, we have learned about all of the main <kbd>docker-compose</kbd> actions associated with the usual Docker workflow. In the next section, we will review some specific options for building images.</p>
<h1 id="uuid-f14ede0b-0cb4-4d87-85ec-9344c7df467e">Customizing images with docker-compose</h1>
<p>Building applications using <kbd>docker-compose</kbd> is very useful because we can use it for creating all the images in Docker Swarm or Kubernetes environments. We just need a <kbd>docker-compose</kbd> file definition and the application components' code.</p>
<p>We have been using a static <kbd>docker-compose</kbd> file definition, but in many cases, we will use some variables to fulfill their values for specific needs. In fact, we could use variables in Dockerfiles as well, to complete the dynamic configurations at all levels.</p>
<p>Let's introduce some variables to our application's <kbd>docker-compose.yaml</kbd> file (we do this to allow different behaviors):</p>
<pre>version: "3.7"<br/><br/>services:<br/>  lb:<br/><strong>    build:</strong><br/><strong>      context: ./simplestlb</strong><br/><strong>      args:</strong><br/><strong>        alpineversion: "latest"</strong><br/><strong>      dockerfile: Dockerfile.custom</strong><br/><strong>      labels:</strong><br/><strong>        org.codegazers.dscription: "Test image"</strong><br/><strong>    image: ${dockerhubid}/simplest-lab:simplestlb</strong><br/>    environment:<br/>      - APPLICATION_ALIAS=simplestapp<br/>      - APPLICATION_PORT=3000<br/>    networks:<br/>      simplestlab:<br/>          aliases:<br/>          - simplestlb<br/>    ports:<br/>      - "${LB_PORT}:80"<br/><br/>...<br/>...</pre>
<p>You will find this file in <a href="https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git">https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git</a> as <kbd>docker-compose.dev.yaml</kbd>, along with all the other code files that were used in the previous section.</p>
<p>First, we'll review the definition configuration using the <kbd>docker-compose config</kbd> action:</p>
<pre><strong>$ docker-compose --file docker-compose.dev.yaml config</strong><br/><strong>WARNING: The dockerhubid variable is not set. Defaulting to a blank string.</strong><br/><strong>WARNING: The LB_PORT variable is not set. Defaulting to a blank string.</strong><br/><strong>ERROR: The Compose file './docker-compose.dev.yaml' is invalid because:</strong><br/><strong>services.lb.ports contains an invalid type, it should be a number, or an object</strong></pre>
<p>These warnings and errors indicate that the following variables must be set:</p>
<ul>
<li><kbd>dockerhubid</kbd>: By default, this will be empty.</li>
<li><kbd>LB_PORT</kbd>: This must be set to a port number because it is the one we will publish to consume the application.</li>
</ul>
<p>We need to have values for these variables. We can also use variables on Dockerfiles to add even more granularity. However, this is not the point here and we will not deep dive into Dockerfile variable usage again. For the Docker Certified Associate exam, it is important to know how to use variables to provide values to <kbd>docker-compose</kbd> deployments. We can use dynamic configurations with variables to deploy different projects using just one <kbd>docker-compose.yaml</kbd> file. This is very useful for building debugging images with developer tools, for example.</p>
<p>Let's set the <kbd>LB_PORT</kbd> and <kbd>dockerhubid</kbd> variables and review our project configuration once more:</p>
<pre>$ <strong>LB_PORT=8081 docker-compose --file docker-compose.dev.yaml config</strong><br/>WARNING: The dockerhubid variable is not set. Defaulting to a blank string.<br/>networks:<br/>  simplestlab:<br/>    ipam:<br/>      config:<br/>      - subnet: 172.16.0.0/16<br/>      driver: default<br/>services:<br/>  app:<br/>    build:<br/>      context: &lt;..&gt;/Docker-Certified-Associate-DCA-Exam-Guide/simplest-lab/simplestapp<br/>    depends_on:<br/>    - db<br/>    - lb<br/>    environment:<br/>      dbhost: simplestdb<br/>      dbname: demo<br/>      dbpasswd: d3m0<br/>      dbuser: demo<br/>    image: myregistry/simplest-lab:simplestapp<br/>    networks:<br/>      simplestlab:<br/>        aliases:<br/>        - simplestapp<br/>  db:<br/>    build:<br/>      context: &lt;..&gt;/Docker-Certified-Associate-DCA-Exam-Guide/simplest-lab/simplestdb<br/>    environment:<br/>      POSTGRES_PASSWORD: changeme<br/>    image: myregistry/simplest-lab:simplestdb<br/>    networks:<br/>      simplestlab:<br/>        aliases:<br/>        - simplestdb<br/>    volumes:<br/>    - pgdata:/var/lib/postgresql/data:rw<br/>  lb:<br/>    build:<br/>      args:<br/>        alpineversion: latest<br/>      context: &lt;..&gt;/Docker-Certified-Associate-DCA-Exam-Guide/simplest-lab/simplestlb<br/>      dockerfile: Dockerfile.custom<br/>      labels:<br/>        org.codegazers.description: Test image<br/>    environment:<br/>      APPLICATION_ALIAS: simplestapp<br/>      APPLICATION_PORT: '3000'<br/>    image: /simplest-lab:simplestlb<br/>    networks:<br/>      simplestlab:<br/>        aliases:<br/>        - simplestlb<br/>    ports:<br/>    - published: 8081<br/>      target: 80<br/>version: '3.7'<br/>volumes:<br/>  pgdata: {}</pre>
<p>The other variables have been left empty. We defined different configurations to provide some features for production, for example, using specific credentials:</p>
<pre><strong>$ LB_PORT=8081 dockerhubid=frjaraur docker-compose --project-name test --file docker-compose.dev.yaml build --build-arg alpineversion="3.6" </strong><br/><strong>Building db</strong><br/><strong>Step 1/2 : FROM postgres:alpine</strong><br/><strong>...</strong><br/><strong>...</strong><br/><strong>[Warning] One or more build-args [alpineversion] were not consumed</strong><br/><strong>Successfully built 336fb84e7fbf</strong><br/><strong>Successfully tagged myregistry/simplest-lab:simplestdb</strong><br/><strong>Building lb</strong><br/><strong>Step 1/12 : ARG alpineversion=latest</strong><br/><strong>...</strong><br/><strong>...</strong><br/><strong>Step 12/12 : LABEL org.codegazers.dscription=Test image</strong><br/><strong> ---&gt; Using cache</strong><br/><strong> ---&gt; ea4739af8eb5</strong><br/><strong>Successfully built ea4739af8eb5</strong><br/><strong>Successfully tagged frjaraur/simplest-lab:simplestlb</strong><br/><strong>Building app</strong><br/><strong>Step 1/15 : FROM alpine</strong><br/><strong>...</strong><br/><strong>...</strong><br/><strong>[Warning] One or more build-args [alpineversion] were not consumed</strong><br/><strong>Successfully built ff419f0998ae</strong><br/><strong>Successfully tagged myregistry/simplest-lab:simplestapp</strong></pre>
<p>If we review the new build image, we will notice that it now has a new label and was created using <kbd>alpine:3.6</kbd> instead of the latest version:</p>
<pre>"Labels": {<br/> "org.codegazers.dscription": "Test image"<br/> }</pre>
<p>With that, we have learned how we can prepare different environments using variables. With variables, we can use one <kbd>docker-compose.yaml</kbd> file for any stage in our environment. We have learned how to prepare a deployment for the following:</p>
<ul>
<li>Development, using images with compilers or debugging utilities</li>
<li>Tests, thereby adding tools to verify connectivity with third-party applications, for example</li>
<li>Pre-production or integration, with libraries to execute load and performance tests before passing the application to production</li>
<li>The production stage, with only well-tested application components within images being tagged as <kbd>release</kbd>, for example</li>
</ul>
<p>Docker Compose allows us to keep track of all configurations required for each stage with a YAML file. This file will be stored in our infrastructure as a code repository. Versioning will help us keep control of deployed applications in production.</p>
<h1 id="uuid-f5fc778c-44d3-424e-b8a3-f9e063e02644">Automating your desktop and CI/CD with Docker Compose</h1>
<p>Docker Compose allows us to easily develop on our own laptops. DevOps teams will provide complete application stack files, <kbd>docker-compose.yaml</kbd> files, along with all the required components and configurations. Developers do not have to learn how all the components work. They can focus on the component they are developing because the rest of the components will run automatically thanks to <kbd>docker-compose</kbd>.</p>
<p>We can use Docker Compose on a <strong>Continuous Integration</strong>/<strong>C</strong><strong>ontinuous Deployment</strong> (<strong>CI</strong>/<strong>CD</strong>) pipeline, building all the components at once.</p>
<p>Docker Compose helps us build all the application components at the development stage, but we can also use this tool to run all the components together. CI/CD orchestrators will execute <kbd>docker-compose</kbd> files at different stages.</p>
<p>With the described steps and variables, it is easy to imagine how to implement a pipeline starting at the development stages and ending with the application in production. We would use different image tags in production, which are created by applying different variable values between environments.</p>
<p>It is very important to understand that <kbd>docker-compose.yaml</kbd> files are key in <strong>Infrastructure-as-Code</strong> (<strong>IaC</strong>) environments. We need to store them and use version control systems. These files describe what application components will run and what resources they will use. We can add variables for an application's published ports, for example, to avoid port conflicts if we deploy a couple of applications using the same <kbd>docker-compose</kbd> files in the same host. We can also use the same <kbd>docker-compose</kbd> file for development and testing, as well as deploying applications to these environments. To avoid environment conflicts, we can use variables to define an application's component endpoints, such as databases or any connection chain that should be different between environments.</p>
<p>Developers will use these files to launch the required application components on their laptops while they are developing new features or fixing code errors. They can focus on coding because they do not need to create complex infrastructures to test what they are coding. In fact, they do not need development infrastructures at all, as they can use their own computers.</p>
<p>We will continue this chapter by reviewing some labs to help us understand and build on the concepts we've learned so far.</p>
<h1 id="uuid-ca132df2-6b5c-4f6a-b26f-85a13dd3f7df">Chapter labs</h1>
<p>We will deploy a simple lab to review the different steps described during this chapter. First, we will build the images required and will continue executing and scaling up components. We will use a CentOS Linux host with Docker Engine installed.</p>
<p>Deploy <kbd>environments/standalone-environment</kbd><em> </em>from this book's GitHub repository (<a href="https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git">https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git</a>) if you have not done so yet. You can use your own CentOS 7 server. Use <kbd>vagrant up</kbd> from the <kbd>environments/standalone-environment</kbd><em> </em>folder to start your virtual environment.</p>
<p>If you are using <kbd>standalone-environment</kbd>, wait until it is running. We can check the node's status using <kbd>vagrant status</kbd>. Connect to your lab node using <kbd>vagrant ssh standalone</kbd>. Now, <kbd>standalone</kbd> is the name of your node. You will be using the <kbd>vagrant</kbd> user with root privileges using <kbd>sudo</kbd>. You should get the following output:</p>
<pre><strong>Docker-Certified-Associate-DCA-Exam-Guide/environments/standalone$ vagrant up</strong><br/><strong>Bringing machine 'standalone' up with 'virtualbox' provider...</strong><br/><strong>...</strong><br/><strong>Docker-Certified-Associate-DCA-Exam-Guide/environments/standalone$ vagrant status</strong><br/><strong>Current machine states:</strong><br/><strong>standalone running (virtualbox)</strong><br/><strong>...</strong><br/><strong>Docker-Certified-Associate-DCA-Exam-Guide/environments/standalone$</strong></pre>
<p class="mce-root">We can now connect to the <kbd>standalone</kbd> node using <kbd>vagrant ssh standalone</kbd>. This process may vary if you deployed the <kbd>standalone</kbd> virtual node previously and you started it using <kbd>vagrant up</kbd>:</p>
<pre><strong>Docker-Certified-Associate-DCA-Exam-Guide/environments/standalone$ vagrant ssh standalone</strong><br/><strong>[vagrant@standalone ~]$</strong> </pre>
<p>If you are reusing your <kbd>standalone-environment</kbd> instance, this means that Docker Engine is already installed. If you started a new instance, please execute the <kbd>/vagrant/install_requirements.sh</kbd> script to get access to all the required tools (Docker Engine and <kbd>docker-compose</kbd>):</p>
<pre><strong>[vagrant@standalone ~]$ /vagrant/install_requirements.sh</strong> </pre>
<p>Now, you are ready to start the labs.</p>
<h2 id="uuid-493563d8-aa68-46ca-94a1-bde53bea077f">Colors application lab</h2>
<p>We will start these labs by deploying a simple application that will run a small Python process. This process is a web server that was developed using Flask that will show a colored page (a random color, by default) with some information about the container name, its IP address, and the application version.</p>
<p>All the files required for this lab can be found in the <kbd>Docker-Certified-Associate-DCA-Exam-Guide/chapter5</kbd> folder in this book's GitHub repository at <a href="https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git">https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git</a>. Let's get started:</p>
<ol>
<li>Let's begin by cloning our repository, navigating to our folder, and listing the files present inside the folder:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone ~]$ git clone https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git<br/></strong><strong>[vagrant@standalone ~]$ cd Docker-Certified-Associate-DCA-Exam-Guide/chapter5</strong><br/><strong>[vagrant@standalone chapter5]$ ls -1</strong><br/><strong>app</strong><br/><strong>docker-compose.loadbalancer.yaml</strong><br/><strong>docker-compose.multicolor.yaml</strong><br/><strong>docker-compose.random.yaml</strong><br/><strong>docker-compose.red.yaml</strong><br/><strong>lb</strong><br/><strong>Readme.md</strong></pre>
<ol start="2">
<li>Let's quickly review the <kbd>docker-compose.random.yaml</kbd><em><strong> </strong></em>file's content:</li>
</ol>
<pre style="padding-left: 60px">version: "3.7"<br/>services:<br/>    red:<br/>        build: app<br/>        environment:<br/>            COLOR: "red"<br/>        labels:<br/>            role: backend<br/>        ports:<br/>        - 3000<br/>        networks:<br/>        - lab<br/>networks:<br/>    lab:</pre>
<p style="padding-left: 60px">It is very simple. We defined a <kbd>random</kbd><em><strong> </strong></em>service using the code contained in the <kbd>app</kbd> directory. We will expose container port <kbd>3000</kbd> to a random host one.</p>
<ol start="3">
<li>We will now build images using <kbd>lab1</kbd><em><strong> </strong></em>as the project name. Notice that we defined the <kbd>lab</kbd> network. The Docker daemon will create a <kbd>lab1_random</kbd><em><strong> </strong></em>image and the <kbd>lab1_lab</kbd><strong><em> </em></strong>network:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone chapter5]$ docker-compose -p lab1 -f docker-compose.random.yaml build</strong><br/><strong>Building random</strong><br/><strong>Step 1/9 : FROM node:alpine</strong><br/><strong>alpine: Pulling from library/node</strong><br/><strong>89d9c30c1d48: Already exists</strong><br/><strong>5320ee7fe9ff: Pull complete</strong><br/><strong>...</strong><br/><strong>...</strong><br/><strong>Step 9/9 : EXPOSE 3000</strong><br/><strong> ---&gt; Running in 51379c5e7630</strong><br/><strong>Removing intermediate container 51379c5e7630</strong><br/><strong> ---&gt; c0dce423a972</strong><br/><br/><strong>Successfully built c0dce423a972</strong><br/><strong>Successfully tagged lab1_random:latest</strong></pre>
<ol start="4">
<li>Now, we execute our multi-container application (in this case, we just have one service definition):</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone chapter5]$ docker-compose -p lab1 -f docker-compose.random.yaml up -d</strong><br/><strong>Creating network "lab1_lab" with the default driver</strong><br/><strong>Creating lab1_random_1 ... done</strong></pre>
<p style="padding-left: 60px">Let's review the <kbd>docker-compose</kbd> project's <kbd>lab1</kbd><strong><em> </em></strong>execution:</p>
<pre style="padding-left: 60px"><strong>[vagrant@standalone chapter5]$ docker-compose -p lab1 -f docker-compose.random.yaml ps</strong><br/><strong>    Name Command State Ports </strong><br/><strong>-------------------------------------------------------------------------</strong><br/><strong>lab1_random_1 docker-entrypoint.sh node ... Up 0.0.0.0:32780-&gt;3000/tcp</strong></pre>
<p style="padding-left: 60px">Notice that the application's port, <kbd>3000</kbd>, is linked to the Docker host port <kbd>32780</kbd> (using NAT).</p>
<ol start="5">
<li>We can access the application via that random port; that is, <kbd>32780</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone chapter5]$ curl 0.0.0.0:32780/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: blue</strong><br/><strong>CONTAINER_NAME: 17bc24f60799</strong><br/><strong>CONTAINER_IP: 172.27.0.2</strong><br/><strong>CLIENT_IP: ::ffff:172.27.0.1</strong><br/><strong>CONTAINER_ARCH: linux</strong></pre>
<p style="padding-left: 60px">We can use a web browser to access the running application. We can also use <kbd>curl</kbd> because the application is prepared to show a text response using the <kbd>/text</kbd><em><strong> </strong></em>URI:</p>
<div><img src="img/570ea77a-ec62-4eda-9555-03b83433f418.jpg" style=""/></div>
<p style="padding-left: 60px">A random color will be used. In this case, we get a blue page. It may vary in your environment because a random color will be chosen if the <kbd>COLOR</kbd> variable is not set.</p>
<p>If you deployed the <kbd>random color</kbd> application using the provided <kbd>vagrant</kbd> standalone environment, you should use <kbd>192.168.56.11:&lt;PUBLISHED_PORT&gt;</kbd> in your browser because you are using a virtual machine. However, we prepared a host-to-virtual node interface (the <kbd>192.168.56.11</kbd> IP address).</p>
<ol start="6">
<li>We can now remove the application and continue to the next lab using <kbd>docker-compose down</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>[vagrant@standalone chapter5]$ docker-compose -p lab1 -f docker-compose.random.yaml down</strong><br/><strong>Stopping lab1_random_1 ... done</strong><br/><strong>Removing lab1_random_1 ... done</strong><br/><strong>Removing network lab1_lab</strong></pre>
<p>Now, we will create a <kbd>red</kbd> application, defining a simple variable to change the application's behavior.</p>
<h2 id="uuid-67ce663b-b705-4dd4-bed2-bdcae7d219de">Executing a red application</h2>
<p>In this lab, we will change the application's behavior by setting the <kbd>COLOR</kbd> environment variable. In this case, we will execute our <kbd>red</kbd> application. This new application can be deployed with just a few changes, which will help us integrate more components in the following labs.</p>
<p>Now, let's execute a <kbd>red</kbd><em><strong> </strong></em>application. In this case, we just change the service name and add an environment variable to define the backend color (a <kbd>COLOR</kbd> key and a <kbd>red</kbd> value). The following is the content of the <kbd>docker-compose.red.yaml</kbd> file:</p>
<pre>version: "3.7"<br/><br/>services:<br/>  red:<br/>    build: app<br/>    environment:<br/>      COLOR: "red" <br/>    labels:<br/>      role: backend<br/>    ports:<br/>    - 3000<br/>    networks:<br/>    - lab<br/><br/>networks:<br/>  lab:</pre>
<p>We can reuse the <kbd>lab1</kbd> project name or create a new one. If we use <kbd>lab2</kbd> as the new project name, new tags will be added. Building it will not create new layers because we haven't changed any code. We will simply use <kbd>docker-compose up -d</kbd>, as follows:</p>
<pre><strong>[vagrant@standalone ~]$ docker-compose -p lab2 -f docker-compose.red.yaml up -d </strong><br/><strong>Creating network "lab2_lab" with the default driver</strong><br/><strong>Building red</strong><br/><strong>Step 1/9 : FROM node:alpine</strong><br/><strong> ---&gt; fac3d6a8e034</strong><br/><strong>Step 2/9 : ENV APPDIR /APP</strong><br/><strong> ---&gt; Using cache</strong><br/><strong> ---&gt; 61bbe191216e</strong><br/><strong>Step 3/9 : WORKDIR ${APPDIR}</strong><br/><strong> ---&gt; Using cache</strong><br/><strong>...</strong><br/><strong>...</strong><br/><strong> ---&gt; Using cache</strong><br/><strong> ---&gt; df0f6838dfca</strong><br/><strong>Step 9/9 : EXPOSE 3000</strong><br/><strong> ---&gt; Using cache</strong><br/><strong> ---&gt; 24ae28db3e15</strong><br/><br/><strong>Successfully built 24ae28db3e15</strong><br/><strong>Successfully tagged lab2_red:latest</strong><br/><strong>WARNING: Image for service red was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.</strong><br/><strong>Creating lab2_red_1 ... done</strong></pre>
<p>We can review the deployment status using <kbd>docker-compose ps</kbd>:</p>
<pre><strong>[vagrant@standalone ~]$ docker-compose -p lab2 -f docker-compose.red.yaml ps</strong><br/><strong>   Name Command State Ports </strong><br/><strong>-----------------------------------------------------------------------------</strong><br/><strong>lab2_red_1 docker-entrypoint.sh node ... Up 0.0.0.0:32781-&gt;3000/tcp</strong></pre>
<p>We can easily access <kbd>0.0.0.0:32781</kbd> to access the <kbd>red</kbd><strong><em> </em></strong>application using <kbd>curl</kbd>:</p>
<pre><strong>[vagrant@standalone ~]$ curl 0.0.0.0:32781/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: red</strong><br/><strong>CONTAINER_NAME: fc05e400d02a</strong><br/><strong>CONTAINER_IP: 172.29.0.2</strong><br/><strong>CLIENT_IP: ::ffff:172.29.0.1</strong><br/><strong>CONTAINER_ARCH: linux</strong></pre>
<p>Now, let's try to scale up the number of application instances.</p>
<h2 id="uuid-e3e4f54d-49ec-4b68-a53e-bb72774d089f">Scaling the red application's backends</h2>
<p>In this lab, we will increase the number of application backends by scaling one of its components up using <kbd>docker-compose</kbd>.</p>
<p>Let's set the new number of instances required for the application using <kbd>docker-compose scale</kbd>:</p>
<pre><strong>[vagrant@standalone ~]$ docker-compose -p lab2 -f docker-compose.red.yaml scale red=5</strong><br/><strong>WARNING: The scale command is deprecated. Use the up command with the --scale flag instead.</strong><br/><strong>Starting lab2_red_1 ... done</strong><br/><strong>Creating lab2_red_2 ... done</strong><br/><strong>Creating lab2_red_3 ... done</strong><br/><strong>Creating lab2_red_4 ... done</strong><br/><strong>Creating lab2_red_5 ... done</strong></pre>
<p>Notice that in this case, we are deploying a stateless application, without any persistence. There is something else to take note of in this case – we left the host-linked port unset. Therefore, a random one is always used for each container instance. Let's review the new instance port number with <kbd>docker-compose ps</kbd>:</p>
<pre><strong>[vagrant@standalone ~]$ docker-compose -p lab2 -f docker-compose.red.yaml ps</strong><br/><strong>   Name Command State Ports </strong><br/><strong>-----------------------------------------------------------------------------</strong><br/><strong>lab2_red_1 docker-entrypoint.sh node ... Up 0.0.0.0:32781-&gt;3000/tcp</strong><br/><strong>lab2_red_2 docker-entrypoint.sh node ... Up 0.0.0.0:32784-&gt;3000/tcp</strong><br/><strong>lab2_red_3 docker-entrypoint.sh node ... Up 0.0.0.0:32785-&gt;3000/tcp</strong><br/><strong>lab2_red_4 docker-entrypoint.sh node ... Up 0.0.0.0:32783-&gt;3000/tcp</strong><br/><strong>lab2_red_5 docker-entrypoint.sh node ... Up 0.0.0.0:32782-&gt;3000/tcp</strong></pre>
<p>Now, we can access all the instances. Each one is using its own NAT port, all of which are available in the Docker host. We can check this again using <kbd>curl</kbd>:</p>
<pre><strong>[vagrant@standalone ~]$ curl 0.0.0.0:32781/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: red</strong><br/><strong>CONTAINER_NAME: fc05e400d02a</strong><br/><strong>CONTAINER_IP: 172.29.0.2</strong><br/><strong>CLIENT_IP: ::ffff:172.29.0.1</strong><br/><strong>CONTAINER_ARCH: linux</strong><br/><br/><strong>[vagrant@standalone ~]$ curl 0.0.0.0:32782/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: red</strong><br/><strong>CONTAINER_NAME: f5de33465357</strong><br/><strong>CONTAINER_IP: 172.29.0.3</strong><br/><strong>CLIENT_IP: ::ffff:172.29.0.1</strong><br/><strong>CONTAINER_ARCH: linux</strong><br/><br/><strong>[vagrant@standalone ~]$ curl 0.0.0.0:32783/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: red</strong><br/><strong>CONTAINER_NAME: 5be016aadadb</strong><br/><strong>CONTAINER_IP: 172.29.0.4</strong><br/><strong>CLIENT_IP: ::ffff:172.29.0.1</strong><br/><strong>CONTAINER_ARCH: linux</strong><br/><br/><strong>[vagrant@standalone ~]$ curl 0.0.0.0:32784/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: red</strong><br/><strong>CONTAINER_NAME: 413c9d605bd5</strong><br/><strong>CONTAINER_IP: 172.29.0.5</strong><br/><strong>CLIENT_IP: ::ffff:172.29.0.1</strong><br/><strong>CONTAINER_ARCH: linux</strong><br/><br/><strong>[vagrant@standalone ~]$ curl 0.0.0.0:32785/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: red</strong><br/><strong>CONTAINER_NAME: fe879a59c3aa</strong><br/><strong>CONTAINER_IP: 172.29.0.6</strong><br/><strong>CLIENT_IP: ::ffff:172.29.0.1</strong><br/><strong>CONTAINER_ARCH: linux</strong></pre>
<p>All the IP addresses are different because we are accessing different containers. However, all of them are <kbd>red</kbd>, as expected.</p>
<p>Let's remove all the application instances:</p>
<pre><strong>[vagrant@standalone ~]$ docker-compose -p lab2 -f docker-compose.red.yaml down</strong><br/><strong>Stopping lab2_red_2 ... done</strong><br/><strong>Stopping lab2_red_3 ... done</strong><br/><strong>Stopping lab2_red_4 ... done</strong><br/><strong>Stopping lab2_red_5 ... done</strong><br/><strong>Stopping lab2_red_1 ... done</strong><br/><strong>Removing lab2_red_2 ... done</strong><br/><strong>Removing lab2_red_3 ... done</strong><br/><strong>Removing lab2_red_4 ... done</strong><br/><strong>Removing lab2_red_5 ... done</strong><br/><strong>Removing lab2_red_1 ... done</strong><br/><strong>Removing network lab2_lab</strong></pre>
<p>In the next lab, we will add more colors using a single file.</p>
<h2 id="uuid-da84a5af-2ac2-4db6-96e9-edc8b25a6585">Adding more colors</h2>
<p>We will now increase our application's components by adding more colors.</p>
<p>Let's add more color applications. In the <kbd>docker-compose.multicolor.yaml</kbd> file, we'll add a couple of services, along with their own <kbd>COLOR</kbd> variables:</p>
<pre>version: "3.7"<br/><br/>services:<br/>  red:<br/>    build: app<br/>    environment:<br/>      COLOR: "red" <br/>    labels:<br/>      role: backend<br/>    ports:<br/>    - 3000<br/>    networks:<br/>    - lab<br/>  green:<br/>    build: app<br/>    environment:<br/>      COLOR: "green" <br/>    labels:<br/>      role: backend<br/>    ports:<br/>    - 3000<br/>    networks:<br/>    - lab<br/>  white:<br/>    build: app<br/>    environment:<br/>      COLOR: "white" <br/>    labels:<br/>      role: backend<br/>    ports:<br/>    - 3000<br/>    networks:<br/>    - lab<br/><br/>networks:<br/>  lab:</pre>
<p>We will launch our <kbd>red</kbd>, <kbd>green</kbd>, and <kbd>white</kbd> applications using <kbd>docker-compose up</kbd>:</p>
<pre class="mce-root"><strong>[vagrant@standalone ~]$ docker-compose -p lab3 -f docker-compose.multicolor.yaml up -d </strong><br/><strong>Creating network "lab3_lab" with the default driver</strong><br/><strong>Building white</strong><br/><strong>Step 1/9 : FROM node:alpine</strong><br/><strong> ---&gt; fac3d6a8e034</strong><br/><strong>...</strong><br/><strong>Successfully built 24ae28db3e15</strong><br/><strong>Successfully tagged lab3_white:latest</strong><br/><strong>...</strong><br/><strong>Building green</strong><br/><strong>...</strong><br/><strong>Successfully tagged lab3_green:latest</strong><br/><strong>...</strong><br/><strong>Building red</strong><br/><strong>...</strong><br/><strong>Successfully tagged lab3_red:latest</strong><br/><strong>WARNING: Image for service red was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.</strong><br/><strong>Creating lab3_green_1 ... done</strong><br/><strong>Creating lab3_white_1 ... done</strong><br/><strong>Creating lab3_red_1 ... done</strong></pre>
<p>We will be able to access different applications. Let's review their processes and ports using <kbd>docker-compose ps</kbd> and then access each instance using <kbd>curl</kbd>:</p>
<pre><strong>[vagrant@standalone ~]$ docker-compose -p lab3 -f docker-compose.multicolor.yaml ps</strong><br/><strong> Name Command State Ports </strong><br/><strong>-------------------------------------------------------------------------------</strong><br/><strong>lab3_green_1 docker-entrypoint.sh node ... Up 0.0.0.0:32789-&gt;3000/tcp</strong><br/><strong>lab3_red_1 docker-entrypoint.sh node ... Up 0.0.0.0:32791-&gt;3000/tcp</strong><br/><strong>lab3_white_1 docker-entrypoint.sh node ... Up 0.0.0.0:32790-&gt;3000/tcp</strong><br/><br/><strong>$ curl 0.0.0.0:32789/text </strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: green</strong><br/><strong>CONTAINER_NAME: a25a4cc36232</strong><br/><strong>CONTAINER_IP: 172.31.0.2</strong><br/><strong>CLIENT_IP: ::ffff:172.31.0.1</strong><br/><strong>CONTAINER_ARCH: linux</strong><br/><br/><strong>$ curl 0.0.0.0:32791/text </strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: red</strong><br/><strong>CONTAINER_NAME: 5e12b0de196c</strong><br/><strong>CONTAINER_IP: 172.31.0.4</strong><br/><strong>CLIENT_IP: ::ffff:172.31.0.1</strong><br/><strong>CONTAINER_ARCH: linux</strong><br/><br/><strong>$ curl 0.0.0.0:32790/text </strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: white</strong><br/><strong>CONTAINER_NAME: b67b09c8c836</strong><br/><strong>CONTAINER_IP: 172.31.0.3</strong><br/><strong>CLIENT_IP: ::ffff:172.31.0.1</strong><br/><strong>CONTAINER_ARCH: linux</strong></pre>
<p>In this situation, all application components are accessible using random published ports. We can use fixed ports to route users' requests to external load balancers, for example. We would not use random ports in production.</p>
<p>Note that the backend ports are dynamically associated with random ports. This allows us to run this application more than once without any <kbd>docker-compose</kbd> file changes. We will just need to use another project name to ensure the created objects' uniqueness.</p>
<p>Now, let's add a simple load balancer to see some other deployment features. We will publish this load balancer, and other services will only be accessible through this component.</p>
<h2 id="uuid-bc42d022-559f-4aca-83ed-ad7b2e18fd79">Adding a simple load balancer</h2>
<p class="mce-root">In this lab, we will add a simple <kbd>nginx</kbd> load balancer to route traffic to different color backends.</p>
<p>Let's take a look at the new deployment file:</p>
<pre>version: "3.7"<br/><br/>services:<br/>  loadbalancer:<br/>    build: lb<br/>    environment:<br/>      APPLICATION_PORT: 3000<br/>    ports:<br/>    - 8080:80<br/>    networks:<br/>    - lab<br/>  red:<br/>    build: app<br/>    environment:<br/>      COLOR: "red"<br/>    labels:<br/>      role: backend<br/>    networks:<br/>    - lab<br/>  green:<br/>    build: app<br/>    environment:<br/>      COLOR: "green"<br/>    labels:<br/>      role: backend<br/>    networks:<br/>    - lab<br/>  white:<br/>    build: app<br/>    environment:<br/>      COLOR: "white"<br/>    labels:<br/>      role: backend<br/>    networks:<br/>    - lab<br/><br/>networks:<br/>  lab:</pre>
<p>Notice that we have removed all the color's service backends' ports. Now, we are just exposing port <kbd>8080</kbd>, which is linked to the internal <kbd>nginx</kbd> component's port; that is, port <kbd>80</kbd>.</p>
<p>Let's launch the application deployment and review the results using <kbd>docker-compose up -d</kbd>:</p>
<pre><strong>[vagrant@standalone ~]$ docker-compose -p lab5 -f docker-compose.loadbalancer.yaml up -d</strong><br/><strong>Creating network "lab5_lab" with the default driver</strong><br/><strong>Building white</strong><br/><strong>...</strong><br/><strong>Successfully tagged lab5_white:latest</strong><br/><strong>WARNING: Image for service white was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.</strong><br/><strong>Building green</strong><br/><strong>...</strong><br/><strong>Successfully tagged lab5_green:latest</strong><br/><strong>WARNING: Image for service green was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.</strong><br/><strong>Building red</strong><br/><strong>...</strong><br/><strong>Successfully tagged lab5_red:latest</strong><br/><strong>WARNING: Image for service red was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.</strong><br/><strong>Building loadbalancer</strong><br/><strong>...Successfully tagged lab5_loadbalancer:latest</strong><br/><strong>WARNING: Image for service loadbalancer was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.</strong><br/><strong>Creating lab5_loadbalancer_1 ... done</strong><br/><strong>Creating lab5_white_1 ... done</strong><br/><strong>Creating lab5_red_1 ... done</strong><br/><strong>Creating lab5_green_1 ... done</strong></pre>
<p>Once all our components are ready, we can test all the color backends using different host headers to reach each backend. We prepared a simple <kbd>nginx</kbd> load balancing configuration for this (we've provided a quick review of the load balancer configuration file in <kbd>lb/nginx.conf</kbd>). Every time we ask for a specific host header using each color, we will be routed to the right backend:</p>
<pre><strong>[vagrant@standalone ~]$ cat lb/nginx.conf </strong><br/><strong>...</strong><br/><strong>...</strong><br/><strong> server {</strong><br/><strong> listen 80;</strong><br/><strong> set $port "__APPLICATION_PORT__";</strong><br/><strong>...</strong><br/><strong>...</strong><br/><strong> location / {</strong><br/><strong> proxy_pass http://$host:$port;</strong><br/><strong> }</strong><br/><strong>...</strong><br/><strong>...</strong></pre>
<p>Using <kbd>curl</kbd>, we can test all the backends:</p>
<pre><strong>[vagrant@standalone ~]$ curl -H "Host: white" 0.0.0.0:8080/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: white</strong><br/><strong>CONTAINER_NAME: 86871cba5a71</strong><br/><strong>CONTAINER_IP: 192.168.208.5</strong><br/><strong>CLIENT_IP: ::ffff:192.168.208.4</strong><br/><strong>CONTAINER_ARCH: linux</strong><br/><br/><strong>[vagrant@standalone ~]$ curl -H "Host: green" 0.0.0.0:8080/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: green</strong><br/><strong>CONTAINER_NAME: f7d90dc89255</strong><br/><strong>CONTAINER_IP: 192.168.208.2</strong><br/><strong>CLIENT_IP: ::ffff:192.168.208.4</strong><br/><strong>CONTAINER_ARCH: linux</strong><br/><br/><strong>[vagrant@standalone ~]$ curl -H "Host: red" 0.0.0.0:8080/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: red</strong><br/><strong>CONTAINER_NAME: 25bb1b66bab8</strong><br/><strong>CONTAINER_IP: 192.168.208.3</strong><br/><strong>CLIENT_IP: ::ffff:192.168.208.4</strong><br/><strong>CONTAINER_ARCH: linux</strong></pre>
<p>Remember, none of the services are accessible except <kbd>loadbalancer</kbd>. Let's review the published ports using <kbd>docker-compose ps</kbd>:</p>
<pre><strong>[vagrant@standalone ~]$ docker-compose -p lab5 -f docker-compose.loadbalancer.yaml ps</strong><br/><strong>       Name Command State Ports </strong><br/><strong>-----------------------------------------------------------------------------------</strong><br/><strong>lab5_green_1 docker-entrypoint.sh node ... Up 3000/tcp </strong><br/><strong>lab5_loadbalancer_1 /entrypoint.sh /bin/sh -c ... Up 0.0.0.0:8080-&gt;80/tcp</strong><br/><strong>lab5_red_1 docker-entrypoint.sh node ... Up 3000/tcp </strong><br/><strong>lab5_white_1 docker-entrypoint.sh node ... Up 3000/tcp</strong> </pre>
<p>What will happen if we scale up the <kbd>green</kbd> service to four instances? We expect to reach all the instances because the service instances will be added to the internal DNS. Let's scale up this service using <kbd>docker-compose up -d</kbd>:</p>
<pre><strong>[vagrant@standalone ~]$ docker-compose -p lab5 -f docker-compose.loadbalancer.yaml up -d --scale green=4 </strong><br/><strong>Starting lab5_green_1 ... </strong><br/><strong>lab5_white_1 is up-to-date</strong><br/><strong>lab5_red_1 is up-to-date</strong><br/><strong>Starting lab5_green_1 ... done</strong><br/><strong>Creating lab5_green_2 ... done</strong><br/><strong>Creating lab5_green_3 ... done</strong><br/><strong>Creating lab5_green_4 ... done</strong></pre>
<p>Let's ask for the <kbd>green</kbd> service again using <kbd>curl</kbd>:</p>
<pre><strong>[vagrant@standalone ~]$ curl -H "Host: green" 0.0.0.0:8080/text </strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: green</strong><br/><strong>CONTAINER_NAME: ba90c57914f9</strong><br/><strong>CONTAINER_IP: 192.168.208.7</strong><br/><strong>CLIENT_IP: ::ffff:192.168.208.4</strong><br/><strong>CONTAINER_ARCH: linux</strong><br/><br/><strong>[vagrant@standalone ~]$ curl -H "Host: green" 0.0.0.0:8080/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: green</strong><br/><strong>CONTAINER_NAME: c1a9ebcf82ac</strong><br/><strong>CONTAINER_IP: 192.168.208.6</strong><br/><strong>CLIENT_IP: ::ffff:192.168.208.4</strong><br/><strong>CONTAINER_ARCH: linux</strong><br/><br/><strong>[vagrant@standalone ~]$ curl -H "Host: green" 0.0.0.0:8080/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: green</strong><br/><strong>CONTAINER_NAME: d5436822ca8f</strong><br/><strong>CONTAINER_IP: 192.168.208.8</strong><br/><strong>CLIENT_IP: ::ffff:192.168.208.4</strong><br/><strong>CONTAINER_ARCH: linux</strong><br/><br/><strong>[vagrant@standalone ~]$ curl -H "Host: green" 0.0.0.0:8080/text</strong><br/><strong>APP_VERSION: 1.0</strong><br/><strong>COLOR: green</strong><br/><strong>CONTAINER_NAME: f7d90dc89255</strong><br/><strong>CONTAINER_IP: 192.168.208.2</strong><br/><strong>CLIENT_IP: ::ffff:192.168.208.4</strong><br/><strong>CONTAINER_ARCH: linux</strong></pre>
<p>As we expected, we get different backends on each request because the DNS gave the load balancer a different backend IP address.</p>
<p>To finish this lab, let's install the <kbd>bind-tools</kbd><em><strong> </strong></em>package on the <kbd>loadbalancer</kbd> container to query the internal DNS using the <kbd>host</kbd> tool. We will query the <kbd>red</kbd> and <kbd>green</kbd> services to verify the internal DNS resolution. This is key in application deployment when using components' names. We will use <kbd>docker-compose exec</kbd> to install the <kbd>bind-tools</kbd><em><strong> </strong></em>package in the <kbd>loadbalancer</kbd> container. Once the package is installed, we will use <kbd>docker-compose exec</kbd> again with the <kbd>host</kbd> command to query the DNS:</p>
<pre><strong>[vagrant@standalone ~]$ docker-compose -p lab5 \<br/>-f docker-compose.loadbalancer.yaml exec loadbalancer apk add -q --update bind-tools</strong><br/><br/><strong>[vagrant@standalone ~]$ docker-compose -p lab5 -f docker-compose.loadbalancer.yaml \<br/>exec loadbalancer host red</strong><br/><strong>red has address 192.168.208.3</strong><br/><br/><strong>[vagrant@standalone ~]$ docker-compose -p lab5 \<br/>-f docker-compose.loadbalancer.yaml exec loadbalancer host green</strong><br/><strong>green has address 192.168.208.8</strong><br/><strong>green has address 192.168.208.2</strong><br/><strong>green has address 192.168.208.7</strong><br/><strong>green has address 192.168.208.6</strong></pre>
<p>The internal DNS gave us all the IP addresses associated with the <kbd>green</kbd><em><strong> </strong></em>and <kbd>red</kbd> services. Those are the associated containers' IP addresses. Therefore, our defined <kbd>green</kbd><em><strong> </strong></em>service is load-balanced to all running <kbd>green</kbd><em><strong> </strong></em>backends.</p>
<p>Remove all the labs using <kbd>docker-compose down</kbd> with the appropriate <kbd>docker-compose</kbd> file and project name.</p>
<h1 id="uuid-53f193b6-84dc-4e0e-96d1-7ed2c1a206ef" class="mce-root">Summary</h1>
<p class="mce-root">This chapter covered how to deploy multi-container applications on Docker hosts. We learned that the <kbd>docker-compose</kbd> command does not just deploy applications, but allows us to build and share all application components. Reviewing all the components' statuses is also easier because <kbd>docker-compose</kbd> provides a command-line interface for retrieving all the application container's standard and error outputs. We can start and stop all the components at once. But we can go even further than this: we are also able to scale the number of instances of each component up and down. This feature depends on our application logic because the Docker daemon does not know anything about our application processes.</p>
<p>All application components are defined in a YAML-formatted file that can be customized using variables. We learned about the most important keys and their default values in this instance. The <kbd>docker-compose</kbd> file is key as it describes all the application components and its resources, as well as their interactions. Each component has its own version because we use images with their tags and arguments. We can also code versioning systems to be able to track <kbd>docker-compose</kbd> changes because this provides IaC information. We need to know exactly what application components are running in production, and Docker Compose allows us to apply release numbers to the files used for application deployments. This will ensure that the right application components are running. Introducing variables in these files allows us to use them at different development and deployment stages with only minor changes.</p>
<p>In the following section, there are some questions that you can have a go at to consolidate your understanding of the topics that we've learned about in this chapter. The next chapter will teach us how to manage image ownership and content using Docker Content Trust.</p>
<h1 id="uuid-29ae09e7-aae6-44fe-8f5d-d59c42357c83" class="mce-root">Questions</h1>
<ol>
<li>Which of these statements is not true?</li>
</ol>
<p style="padding-left: 90px">a) Docker Compose can run multi-service applications distributed on different services.<br/>
b) Docker Compose can run multi-container applications on a Docker host.<br/>
c) Docker Compose is a software application that is not installed with standard Docker packages.<br/>
d) All of the above are true.</p>
<ol start="2">
<li>What can we do with <kbd>docker-compose</kbd>?</li>
</ol>
<p style="padding-left: 90px">a) We can build all application images.<br/>
b) We can pull and push application component images.<br/>
c) We can run all application components at once.<br/>
d) All of the above.</p>
<ol start="3">
<li>What will happen if we execute <kbd>docker-compose up</kbd> with a <kbd>docker-compose</kbd> file in which we have defined the frontend, backend, and database services? (Choose all of the correct statements out of the following options.)</li>
</ol>
<p style="padding-left: 90px">a) Docker Compose will look for all the services' defined images and will pull them if they are not present in the current host.<br/>
b) Docker Compose will execute only images with the <kbd>start</kbd> key defined.<br/>
c) Docker Compose will run all containers at once and your terminal will be attached to their standard and error outputs.<br/>
d) All of the above are false.</p>
<ol start="4">
<li>How can we use a <kbd>docker-compose</kbd> file to launch application services more than once?</li>
</ol>
<p style="padding-left: 90px">a) In actual fact, we cannot do that, but we can launch service process instances using the <kbd>scale</kbd> action. This service name will resolve to all replica IP addresses.<br/>
b) Docker Compose will only execute images with the <kbd>start</kbd> key defined.<br/>
c) Docker Compose will run all the containers at once, without any precedence.<br/>
d) All of the above are false.</p>
<ol start="5">
<li>What does the execution of <kbd>docker-compose down</kbd> do?</li>
</ol>
<p style="padding-left: 90px">a) It will stop all running containers associated with an application.<br/>
b) It will try to stop all running containers associated with an application.<br/>
c) It will try to stop all running containers associated with an application. Once they're all stopped, it will remove them.<br/>
d) It will try to stop all running containers associated with an application. Once they're all stopped, it will remove them, along with all of their associated resources, unless they were defined externally.</p>
<h1 id="uuid-5d1cdd35-5390-4e4b-bb49-060ce7d99777">Further reading</h1>
<p>You can refer to the following links for more information regarding the topics that were covered in this chapter:</p>
<ul>
<li>The Docker Compose file reference: <a href="https://docs.docker.com/compose/compose-file/">https://docs.docker.com/compose/compose-file/</a></li>
<li>Docker Compose's GitHub repository: <a href="https://github.com/docker/compose.git">https://github.com/docker/compose.git</a></li>
<li>Docker Compose with Visual Studio Code: <a href="https://code.visualstudio.com/docs/containers/docker-compose">https://code.visualstudio.com/docs/containers/docker-compose</a></li>
<li>Docker Compose samples: <a href="https://github.com/dockersamples/example-voting-app">https://github.com/dockersamples/example-voting-app</a></li>
<li>Docker Compose releases: <a href="https://github.com/docker/compose/releases">https://github.com/docker/compose/releases</a></li>
</ul>


            

            
        
    </body></html>