- en: Chapter 7. Metrics, Log Collection, and Monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第七章：指标、日志收集和监控
- en: '![Metrics, Log Collection, and Monitoring](img/image_07_001.jpg)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![Metrics, Log Collection, and Monitoring](img/image_07_001.jpg)'
- en: That's it. This chapter could well have ended here but I shall carry on for
    the benefit of those amongst us who would prefer things in more detail.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。本章本来可以在这里结束，但为了那些希望更详细了解的朋友们，我将继续进行下去。
- en: A great deal of the DevOps practice(s) evolve around the idea of being able
    to review and react to the state of your infrastructure at any given time – should
    you need to.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 许多DevOps实践围绕着能够随时回顾和应对基础设施状态的理念——如果您需要的话。
- en: That is not to say, setup e-mail notifications for every time the date changes
    on your host, but a stream of sensible, usable amount of event data which would
    allow an operator to make a reasonably informed decision under stress and/or uncertainy.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是说每当主机上的日期发生变化时都设置电子邮件通知，而是提供一系列合理、可用的事件数据流，使得操作员能够在压力和/或不确定的情况下做出合理的决策。
- en: If you have been paying attention in life so far, you would have noticed many
    a wise man talking about *balance, the golden middle*.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您一直在关注生活，您会注意到许多智者提到过*平衡，黄金中庸*。
- en: You should aim to configure your monitoring system in a way that you are notified
    of events of potential interest and in a timely manner. The notifications should
    arrive in a format that is hard to overlook, and should provide enough detail
    for an operator to be able to make an informed guess at what is going on.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该目标是以一种方式配置您的监控系统，以便能够及时接收到潜在重要事件的通知。这些通知应该以一种难以忽视的格式到达，并且提供足够的细节，让操作员能够做出合理的判断，了解发生了什么。
- en: 'At the same time, the said monitoring system must cause the least amount of
    alert fatigue (as outlined in this concise Datadog article: [https://www.datadoghq.com/blog/monitoring-101-alerting](https://www.datadoghq.com/blog/monitoring-101-alerting)).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，所述监控系统必须尽量减少告警疲劳（如这篇简洁的Datadog文章所概述：[https://www.datadoghq.com/blog/monitoring-101-alerting](https://www.datadoghq.com/blog/monitoring-101-alerting)）。
- en: Unfortunately for our friendship, finding that middle ground which suits your
    case (your infrastructure and the people looking after it) is an adventure which
    you will have to go on alone. We could however spend some quality time together,
    discussing a few of the tools that could make it even more enjoyable!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，找到适合您情况（您的基础设施以及负责维护它的人们）的中间地带是一个冒险，您必须独自去完成。然而，我们可以一起花一些时间讨论一些工具，这些工具可以使这一过程更加愉快！
- en: 'Checklists are sophisticated, so here is one:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 检查清单很复杂，所以这是其中之一：
- en: '**Centralized logging**:'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集中日志记录**：'
- en: Ingesting and storing logs with **Logstash** and **Elasticsearch**
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Logstash**和**Elasticsearch**进行日志的摄取和存储
- en: Collecting logs with Elasticsearch **Filebeat**
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Elasticsearch的**Filebeat**收集日志
- en: Visualizing logs with **Kibana**
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Kibana**可视化日志
- en: '**Metrics**:'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指标**：'
- en: Ingesting and storing metrics with **Prometheus**
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Prometheus**摄取和存储指标
- en: Gathering OS and application metrics with **Telegraf**
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Telegraf**收集操作系统和应用程序的指标
- en: Visualizing metrics with **Grafana**
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Grafana**可视化指标
- en: '**Monitoring**:'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控**：'
- en: Alerting with **Prometheus**
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Prometheus**进行告警
- en: Self-remediation with **Prometheus** and **Jenkins**
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Prometheus**和**Jenkins**进行自我修复
- en: 'Naturally, we would require a few hosts to form our playground for all of the
    preceding checklist. There has been sufficient practice in deploying VPC EC2 instances
    on AWS in previous chapters, thus I hereby exercise the great power of delegation
    and assume the existence of:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 自然，我们需要一些主机来作为前面所有检查清单的“游乐场”。在之前的章节中，我们已经充分练习了在AWS上部署VPC EC2实例，因此我在此行使委托权，并假设以下内容的存在：
- en: A VPC with an IGW, NAT gateway, 2x private and 2x public subnets
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个带有IGW、NAT网关、2个私有子网和2个公共子网的VPC
- en: 2x standalone, vanilla Amazon Linux EC2 instances (say `t2.small`) within the
    public subnets
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2个独立的、原生的Amazon Linux EC2实例（比如`t2.small`），位于公共子网内
- en: 1x Auto Scale Group (`t2.nano`) within the private subnets
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1个自动伸缩组（`t2.nano`）位于私有子网内
- en: 1x Internet-facing ELB passing HTTP traffic to the Auto Scale Group
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1个面向互联网的ELB，将HTTP流量传递到自动伸缩组
- en: Centralized logging
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集中日志记录
- en: Since the olden days, mankind has strived to use its limited attention span
    only on what really matters in life, and without having to look for it too hard
    – if possible. So we started with copying log files around, evolution brought
    us centralized (r)syslog and today (we learn from our mistakes) we have Logstash
    and Elasticsearch.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 自古以来，人类就努力将有限的注意力集中在生活中真正重要的事情上，并尽量不费力地找到它——如果可能的话。因此，我们从复制日志文件开始，进化到了集中式 (r)syslog，今天（我们从错误中学习）我们拥有了
    Logstash 和 Elasticsearch。
- en: '|   | *Elasticsearch is a distributed, open source search and analytics engine,
    designed for horizontal scalability, reliability, and easy management. It combines
    the speed of search with the power of analytics via a sophisticated, developer-friendly
    query language covering structured, unstructured, and time-series data.**Logstash
    is a flexible, open source data collection, enrichment, and transportation pipeline.
    With connectors to common infrastructure for easy integration, Logstash is designed
    to efficiently process a growing list of log, event, and unstructured data sources
    for distribution into a variety of outputs, including Elasticsearch.* |   |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|   | *Elasticsearch 是一个分布式的开源搜索和分析引擎，旨在实现水平扩展性、可靠性和易于管理。它通过一个复杂的、开发者友好的查询语言结合了搜索速度和分析能力，涵盖了结构化、非结构化和时间序列数据。**Logstash
    是一个灵活的开源数据收集、增强和传输管道。Logstash 提供了与常见基础设施的连接器，便于集成，旨在高效处理越来越多的日志、事件和非结构化数据源，并将其分发到包括
    Elasticsearch 在内的多种输出中。* |   |'
- en: '|   | --[https://www.elastic.co/products](https://www.elastic.co/products)
    |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '|   | --[https://www.elastic.co/products](https://www.elastic.co/products)
    |'
- en: Ingesting and storing logs with Logstash and Elasticsearch
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Logstash 和 Elasticsearch 获取和存储日志
- en: We will be using Logstash to receive, process and then store log events into
    Elasticsearch.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Logstash 接收、处理并将日志事件存储到 Elasticsearch 中。
- en: For the purposes of the demos in this chapter, we'll be installing and configuring
    services manually, directly on the hosts. When done experimenting, you should,
    of course, use configuration management instead (wink).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的演示目的，我们将在主机上手动安装和配置服务。实验完成后，当然应该使用配置管理工具来代替（眨眼）。
- en: 'Let us start by installing the two services on one of the standalone EC2 instances
    (we shall call it ELK):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在一台独立的 EC2 实例上安装这两个服务（我们将其称为 ELK）：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Edit `/etc/elasticsearch/elasticsearch.yml`:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑 `/etc/elasticsearch/elasticsearch.yml`：
- en: Note
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/elasticsearch/elasticsearch.yml](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/elasticsearch/elasticsearch.yml)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考：[https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/elasticsearch/elasticsearch.yml](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/elasticsearch/elasticsearch.yml)
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It is important to select a unique name for the Elasticsearch cluster, so that
    the node does not join somebody else's inadvertently, should there be any on your
    LAN. For development, we only ask for a single shard and no replicas. Impatience
    dictates a five second refresh rate on any ES indices.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为 Elasticsearch 集群选择一个唯一的名称非常重要，以确保节点不会意外地加入其他人的集群（如果您的局域网上有的话）。对于开发环境，我们只需要一个分片且没有副本。为了提高效率，我们设置
    Elasticsearch 索引的刷新率为 5 秒。
- en: 'Create a Logstash `patterns` folder:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个 Logstash `patterns` 文件夹：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create a sample NGINX pattern `/opt/logstash/patterns/nginx` (ref: [https://www.digitalocean.com/community/tutorials/adding-logstash-filters-to-improve-centralized-logging](https://www.digitalocean.com/community/tutorials/adding-logstash-filters-to-improve-centralized-logging)):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个示例 NGINX 模式 `/opt/logstash/patterns/nginx`（参考：[https://www.digitalocean.com/community/tutorials/adding-logstash-filters-to-improve-centralized-logging](https://www.digitalocean.com/community/tutorials/adding-logstash-filters-to-improve-centralized-logging)）：
- en: Note
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/opt/logstash/patterns/nginx](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/opt/logstash/patterns/nginx)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考：[https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/opt/logstash/patterns/nginx](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/opt/logstash/patterns/nginx)
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create `/etc/logstash/conf.d/main.conf`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 `/etc/logstash/conf.d/main.conf`：
- en: Note
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/logstash/conf.d/main.conf](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/logstash/conf.d/main.conf)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考：[https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/logstash/conf.d/main.conf](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/logstash/conf.d/main.conf)
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Logstash allows us to configure one or more listeners (inputs) in order to receive
    data, filters to help us process it and outputs specifying where that data should
    be forwarded once processed.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash 允许我们配置一个或多个监听器（输入），以接收数据，配置过滤器帮助我们处理数据，并设置输出，指定处理后数据应转发到哪里。
- en: 'We expect logs to be delivered by Elasticsearch Filebeat on `TCP: 5044`. If
    the log event happens to be of type `nginx-access`, we have it modified according
    to the `NGINXACCESS` pattern then shipped to Elasticsearch on localhost `TCP:
    9200` for storage.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '我们期望 Elasticsearch Filebeat 通过 `TCP: 5044` 传送日志。如果日志事件的类型是 `nginx-access`，我们会根据
    `NGINXACCESS` 模式对其进行修改，然后将其通过 `TCP: 9200` 发送到本地主机的 Elasticsearch 进行存储。'
- en: 'Finally, let us start the services:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们启动服务：
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Collecting logs with Elasticsearch Filebeat
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Elasticsearch Filebeat 收集日志
- en: We have the systems in place; let us push somes from the ELK node that we are
    on.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经搭建好系统；接下来让我们推送一些来自 ELK 节点的数据。
- en: 'We will use Filebeat to collect local logs of interest and forward those to
    Logstash (incidentally also local in this case):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Filebeat 收集本地感兴趣的日志，并将其转发到 Logstash（顺便说一下，这也是本地的）：
- en: '|   | *Filebeat is a log data shipper. Installed as an agent on your servers,
    Filebeat monitors the log directories or specific log files, tails the files,
    and forwards them either to Elasticsearch or Logstash for indexing.* |   |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|   | *Filebeat 是一个日志数据传输工具。它作为代理安装在服务器上，监控日志目录或特定日志文件，跟踪文件并将其转发到 Elasticsearch
    或 Logstash 进行索引。* |   |'
- en: '|   | --*https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-overview.html*
    |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '|   | --*https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-overview.html*
    |'
- en: 'Installation:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 安装：
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'While functionality is provided to ship directly to ES, we are planning to
    use Logstash so we need to disable the Elasticsearch output and enable the logstash
    one in `/etc/filebeat/filebeat.yml`:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然提供了直接发送到 Elasticsearch 的功能，但我们计划使用 Logstash，因此我们需要在`/etc/filebeat/filebeat.yml`中禁用
    Elasticsearch 输出，并启用 Logstash 输出。
- en: Note
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/filebeat/filebeat.yml](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/filebeat/filebeat.yml)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考：[https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/filebeat/filebeat.yml](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/elk/etc/filebeat/filebeat.yml)
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We could also list a few more log files to collect:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以列出更多要收集的日志文件：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then start the service:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然后启动服务：
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Fun, but let us launch a few other EC2 instances for even more of it!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 很有趣，但让我们再启动一些 EC2 实例，享受更多乐趣！
- en: We shall use the Auto Scale Group we mentioned earlier. We will install Filebeat
    on each instance and configure it to forward selected logs to our Logstash node.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用之前提到的自动扩展组。我们将在每个实例上安装 Filebeat，并配置它将选定的日志转发到我们的 Logstash 节点。
- en: 'First, ensure that the security group of the Logstash instance allows inbound
    connections from the Auto Scale Group (`TCP: 5044`).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，确保 Logstash 实例的安全组允许来自自动扩展组的入站连接（`TCP: 5044`）。'
- en: 'Next, we use an EC2 User Data script to bootstrap the Filebeat binary and configuration
    onto each of the EC2 instances in our Auto Scale Group (we will call them webservers):'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用 EC2 用户数据脚本将 Filebeat 二进制文件和配置引导到自动扩展组中的每个 EC2 实例上（我们将其称为 Web 服务器）：
- en: Note
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/webserver/user_data.sh](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/webserver/user_data.sh)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考：[https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/webserver/user_data.sh](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/webserver/user_data.sh)
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: With that in place, go ahead and scale the group up. The new web server instances,
    should start streaming logs promptly.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 配置好后，继续扩展该组。新的 Web 服务器实例应立即开始流式传输日志。
- en: Visualizing logs with Kibana
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Kibana 可视化日志
- en: We have our logs collected by Filebeat and stored in Elasticsearch, how about
    browsing them?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将日志收集到 Filebeat，并存储在 Elasticsearch 中，那我们来浏览这些日志吧？
- en: 'Kibana, right on time:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana，准时到达：
- en: '|   | *Kibana is an open source analytics and visualization platform designed
    to work with Elasticsearch. You use Kibana to search, view, and interact with
    data stored in Elasticsearch indices. You can easily perform advanced data analysis
    and visualize your data in a variety of charts, tables, and maps.* |   |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|   | *Kibana 是一个开源的分析和可视化平台，旨在与 Elasticsearch 配合使用。你可以使用 Kibana 搜索、查看和交互 Elasticsearch
    索引中的数据。你可以轻松地执行高级数据分析，并在各种图表、表格和地图中可视化数据。* |   |'
- en: '|   | --*https://www.elastic.co/guide/en/kibana/current/introduction.html*
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '|   | --*https://www.elastic.co/guide/en/kibana/current/introduction.html*
    |'
- en: 'Install the package:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 安装包：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Start the service:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 启动服务：
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The default port is `TCP:5601`, if allowed in the relevant security group,
    you should be able to see the Kibana dashboard:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 默认端口是 `TCP:5601`，如果在相关的安全组中允许，你应该能够看到 Kibana 仪表板：
- en: '![Visualizing logs with Kibana](img/image_07_002.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Kibana 可视化日志](img/image_07_002.jpg)'
- en: Set the **index pattern** to **filebeat-*** and click **Create**.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 将 **索引模式** 设置为 **filebeat-*** 然后点击 **创建**。
- en: 'Kibana is now ready to display our Filebeat data. Switch to the **Discover**
    tab to see the list of recent events:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana 现在已经准备好显示我们的 Filebeat 数据。切换到 **发现** 标签页查看最近的事件列表：
- en: '![Visualizing logs with Kibana](img/image_07_003.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Kibana 可视化日志](img/image_07_003.jpg)'
- en: 'In addition to the standard **Syslog** messages, you will also notice some
    **NGINX access-log** entries, with various fields populated as per the filter
    we specified earlier:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标准的 **Syslog** 消息外，你还会注意到一些 **NGINX 访问日志** 条目，字段根据我们之前指定的过滤条件进行了填充：
- en: '![Visualizing logs with Kibana](img/image_07_004.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Kibana 可视化日志](img/image_07_004.jpg)'
- en: 'Logs: done. Now, how about some metrics?'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 日志：完成。那么，关于一些度量呢？
- en: Metrics
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 度量
- en: 'For ingesting, storing and alerting on our metrics, we shall explore another,
    quite popular open-source project called Prometheus:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取、存储和警报我们的度量，我们将探索另一个非常流行的开源项目，名为 Prometheus：
- en: '|   | *Prometheus is an open-source systems monitoring and alerting toolkit
    originally built at SoundCloud.**Prometheus''s main features are:**-a multi-dimensional
    data model (time series identified by metric name and key/value pairs)**- a flexible
    query language to leverage this dimensionality**- no reliance on distributed storage;
    single server nodes are autonomous**- time series collection happens via a pull
    model over HTTP**- pushing time series is supported via an intermediary gateway**-
    targets are discovered via service discovery or static configuration**- multiple
    modes of graphing and dashboarding support* |   |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|   | *Prometheus 是一个开源的系统监控和警报工具包，最初在 SoundCloud 开发。**Prometheus 的主要特点包括：**-
    多维数据模型（通过指标名称和键/值对标识时间序列）**- 一个灵活的查询语言来利用这种维度**- 无需分布式存储；单个服务器节点是自治的**- 通过 HTTP
    拉取模型进行时间序列采集**- 通过中间网关支持推送时间序列**- 通过服务发现或静态配置发现目标**- 支持多种图形和仪表板模式* |   |'
- en: '|   | --*https://prometheus.io/docs/introduction/overview/emphasis>* |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|   | --*https://prometheus.io/docs/introduction/overview/emphasis>* |'
- en: 'Even though it is the kind of system that takes care of pretty much everything,
    the project still follows the popular UNIX philosophy of modular development.
    Prometheus is composed of multiple components, each providing a specific function:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它是一个几乎涵盖所有功能的系统，但该项目仍然遵循流行的 UNIX 模块化开发哲学。Prometheus 由多个组件组成，每个组件提供特定功能：
- en: '|   | *- the main Prometheus server which scrapes and stores time series data**-
    client libraries for instrumenting application code**- a push gateway for supporting
    short-lived jobs**- a GUI-based dashboard builder based on Rails/SQL**- special-purpose
    exporters (for HAProxy, StatsD, Ganglia, etc.)**- an (experimental) alertmanager**-
    a command-line querying tool* |   |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '|   | *- 主要的 Prometheus 服务器，用于抓取和存储时间序列数据**- 用于仪表化应用代码的客户端库**- 支持短生命周期作业的推送网关**-
    基于 Rails/SQL 的 GUI 仪表板构建器**- 特殊用途的导出器（如 HAProxy、StatsD、Ganglia 等）**- 一个（实验性的）告警管理器**-
    命令行查询工具* |   |'
- en: '|   | --*https://prometheus.io/docs/introduction/overview/* |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '|   | --*https://prometheus.io/docs/introduction/overview/* |'
- en: Ingesting and storing metrics with Prometheus
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Prometheus 获取和存储度量
- en: Our second EC2 instance is going to host the Prometheus service alongside Jenkins
    (we will come to that shortly), thus a rather appropriate name would be promjenkins.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二个 EC2 实例将会托管 Prometheus 服务和 Jenkins（稍后会介绍），因此一个合适的名称可以是 promjenkins。
- en: 'As a start, download and extract Prometheus and Alertmanager in `/opt/prometheus/server`
    and `/opt/prometheus/alertmanager` respectively (ref: [https://prometheus.io/download](https://prometheus.io/download)).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，下载并解压 Prometheus 和 Alertmanager 到 `/opt/prometheus/server` 和 `/opt/prometheus/alertmanager`（参考：[https://prometheus.io/download](https://prometheus.io/download)）。
- en: 'We create a basic configuration file for the Alertmanager in `/opt/prometheus/alertmanager/alertmanager.yml`
    (replace e-mail addresses as needed):'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为 Alertmanager 创建一个基本的配置文件，存放在 `/opt/prometheus/alertmanager/alertmanager.yml`（根据需要替换电子邮件地址）：
- en: Note
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/alertmanager/alertmanager.yml](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/alertmanager/alertmanager.yml)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考：[https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/alertmanager/alertmanager.yml](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/alertmanager/alertmanager.yml)
- en: '[PRE13]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This will simply e-mail out alert notifications.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这将简单地通过电子邮件发送警报通知。
- en: 'Start the service:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 启动服务：
- en: '[PRE14]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Ensure the default `TCP:9093` is allowed, then you should be able to get to
    the dashboard at `http://$public_IP_of_promjenkins_node:9093/#/status`:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 确保默认的 `TCP:9093` 已被允许，然后你应该能够访问 `http://$public_IP_of_promjenkins_node:9093/#/status`
    仪表盘：
- en: '![Ingesting and storing metrics with Prometheus](img/image_07_005.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Prometheus 进行度量数据的摄取与存储](img/image_07_005.jpg)'
- en: 'Back to the Prometheus server, the default `/opt/prometheus/server/prometheus.yml`
    will suffice for now. We can start the service:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 返回到 Prometheus 服务器，默认的 `/opt/prometheus/server/prometheus.yml` 目前就足够了。我们可以启动该服务：
- en: '[PRE15]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Open up `TCP:9090`, then try `http://$public_IP_of_promjenkins_node:9090/status`:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 `TCP:9090`，然后尝试 `http://$public_IP_of_promjenkins_node:9090/status`：
- en: '![Ingesting and storing metrics with Prometheus](img/image_07_006.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Prometheus 进行度量数据的摄取与存储](img/image_07_006.jpg)'
- en: We are ready to start adding hosts to be monitored. That is to say targets for
    Prometheus to scrape.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好开始添加要监控的主机。也就是说，添加 Prometheus 要拉取的目标。
- en: 'Prometheus offers various ways in which targets can be defined. The one most
    suitable for our case is called `ec2_sd_config` (ref: [https://prometheus.io/docs/operating/configuration/#<ec2_sd_config>](https://prometheus.io/docs/operating/configuration/#<ec2_sd_config>)).
    All we need to do is provide a set of API keys with read-only EC2 access (**AmazonEC2ReadOnlyAccess**
    IAM policy) and Prometheus will do the host discovery for us (ref: [https://www.robustperception.io/automatically-monitoring-ec2-instances](https://www.robustperception.io/automatically-monitoring-ec2-instances)).'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 提供了多种定义目标的方式。最适合我们案例的是 `ec2_sd_config`（参考：[https://prometheus.io/docs/operating/configuration/#<ec2_sd_config>](https://prometheus.io/docs/operating/configuration/#<ec2_sd_config>)）。我们所需要做的就是提供一组具有只读
    EC2 访问权限的 API 密钥（**AmazonEC2ReadOnlyAccess** IAM 策略），然后 Prometheus 将为我们执行主机发现（参考：[https://www.robustperception.io/automatically-monitoring-ec2-instances](https://www.robustperception.io/automatically-monitoring-ec2-instances)）。
- en: 'We append the `ec2_sd_config` settings to: `/opt/prometheus/server/prometheus.yml`:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 `ec2_sd_config` 配置追加到：`/opt/prometheus/server/prometheus.yml`：
- en: Note
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/prometheus.yml](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/prometheus.yml)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考：[https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/prometheus.yml](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/prometheus.yml)
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We are interested only in any instances in the `us-east-1` region with a name
    matching the `^webserver` regex expression.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只关注位于 `us-east-1` 区域，并且名称符合 `^webserver` 正则表达式的实例。
- en: Now let us bring some of those online.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将其中一些实例上线。
- en: Gathering OS and application metrics with Telegraf
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Telegraf 收集操作系统和应用程序的度量数据
- en: We will be using the pull method of metric collection in Prometheus. This means
    that our clients (targets) will expose their metrics for Prometheus to scrape.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 Prometheus 中使用拉取方式进行度量数据收集。这意味着我们的客户端（目标）将暴露它们的度量数据，供 Prometheus 拉取。
- en: 'To expose OS metrics, we shall deploy InfluxData''s Telegraf (ref: [https://github.com/influxdata/telegraf](https://github.com/influxdata/telegraf)).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了暴露操作系统度量数据，我们将部署 InfluxData 的 Telegraf（参考：[https://github.com/influxdata/telegraf](https://github.com/influxdata/telegraf)）。
- en: It comes with a rich set of plugins, which will provide for a good deal of metrics.
    Should you need more, you have the option to write your own (in Go) or use the
    `exec` plugin which will essentially attempt to launch any type of script you
    point it at.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 它提供了一套丰富的插件，能够提供大量度量。如果你需要更多的度量，可以选择自己编写插件（使用 Go）或使用 `exec` 插件，它本质上会尝试启动你指定的任何类型的脚本。
- en: 'As for application metrics, we have two options (at least):'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 至于应用程序度量，我们有两个（至少）选择：
- en: Build a metrics API endpoint in the application itself
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在应用程序中构建一个度量 API 端点
- en: Have the application submit metrics data to an external daemon (StatsD as an
    example)
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让应用程序将度量数据提交给外部守护进程（以 StatsD 为例）
- en: Incidentally, Telegraf comes with a built-in StatsD listener, so if your applications
    already happen to have StatsD instrumentation, you should be able to simply point
    them at it.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，Telegraf 内置了一个 StatsD 监听器，因此如果你的应用程序已经有 StatsD 插桩，你应该能够直接将其指向 Telegraf。
- en: Following on from the ELK example, we will extend the EC2 user data script to
    get Telegraf on our the Auto Scale Group instances.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 继 ELK 示例之后，我们将扩展 EC2 用户数据脚本，以便在自动扩展组实例上安装 Telegraf。
- en: Note
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/webserver/user_data.sh](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/webserver/user_data.sh)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考：[https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/webserver/user_data.sh](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/webserver/user_data.sh)
- en: 'We append:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们附加：
- en: '[PRE17]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The important one here is `outputs.prometheus_client` with which we turn Telegraf
    into a Prometheus scrape target. By all means check the default configuration
    file if you''d like to enable more metrics during this test (ref: [https://github.com/influxdata/telegraf/blob/master/etc/telegraf.conf](https://github.com/influxdata/telegraf/blob/master/etc/telegraf.conf))'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这里最重要的是 `outputs.prometheus_client`，它将 Telegraf 转换为 Prometheus 抓取目标。如果你希望在此测试中启用更多度量，请务必检查默认配置文件（参考：[https://github.com/influxdata/telegraf/blob/master/etc/telegraf.conf](https://github.com/influxdata/telegraf/blob/master/etc/telegraf.conf)）
- en: 'Next, check that TCP: `9126` is allowed into the Auto Scale Group security
    group, then launch a couple of nodes. In a few moments, you should see any matching
    instances listed in the targets dashboard (ref: `http://$ public_IP_of_promjenkins_node:9090/targets`):'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '接下来，检查 TCP: `9126` 是否被允许进入自动扩展组安全组，然后启动几个节点。几秒钟后，你应该能在目标仪表板中看到任何匹配的实例（参考：`http://$
    public_IP_of_promjenkins_node:9090/targets`）：'
- en: '![Gathering OS and application metrics with Telegraf](img/image_07_007.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Telegraf 收集操作系统和应用程序度量](img/image_07_007.jpg)'
- en: We see the new hosts under the **ec2** scrape job which we configured earlier.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在先前配置的**ec2**抓取任务下看到了新主机。
- en: Visualizing metrics with Grafana
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Grafana 可视化度量
- en: 'It is true that Prometheus is perfectly capable of visualizing the data we
    are now collecting from our targets, as seen here:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，Prometheus 完全能够可视化我们现在从目标收集的数据，如下所示：
- en: '![Visualizing metrics with Grafana](img/image_07_008.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Grafana 可视化度量](img/image_07_008.jpg)'
- en: In fact, this is the recommended approach for any ad-hoc queries you might want
    to run.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，这就是推荐的做法，适用于你可能想要执行的任何临时查询。
- en: 'Should you have an appetite for dashboards however, you would most certainly
    appreciate *Grafana - The 8th Wonder* (ref: [http://grafana.org](http://grafana.org))'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对仪表板有兴趣的话，你一定会非常欣赏 *Grafana - 第八大奇迹*（参考：[http://grafana.org](http://grafana.org)）
- en: 'Check this out to get a feel for the thing: http://play.grafana.org'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 查看这个网址以了解这个工具的使用感受：http://play.grafana.org
- en: I mean, how many other projects do you know of with a *play* URL?!
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是，你知道多少个项目有 *play* URL 吗？！
- en: 'So, yes, Grafana, let us install the service on the promjenkins node:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所以，是的，Grafana，让我们在 promjenkins 节点上安装该服务：
- en: '[PRE18]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The default Grafana port is TCP:`3000`, auth `admin:admin`. After updating
    the relevant security group, we should be able to see the screen at: `http://$
    public_IP_of_promjenkins_node:3000`:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 默认的 Grafana 端口是 TCP:`3000`，认证为 `admin:admin`。更新相关安全组后，我们应该能看到以下页面：`http://$
    public_IP_of_promjenkins_node:3000`：
- en: '![Visualizing metrics with Grafana](img/image_07_009.jpg)'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用 Grafana 可视化度量](img/image_07_009.jpg)'
- en: After logging in, first we need to create a **Data Sources** for our **Dashboards**:![Visualizing
    metrics with Grafana](img/image_07_010.jpg)
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录后，首先我们需要为我们的**仪表板**创建一个**数据源**：![使用 Grafana 可视化度量](img/image_07_010.jpg)
- en: Back at the home screen, choose to create a new dashboard, then use the green
    button on the left to **Add Panel** then a **Graph**:![Visualizing metrics with
    Grafana](img/image_07_011.jpg)
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在首页，选择创建一个新仪表板，然后使用左侧的绿色按钮 **添加面板**，接着选择 **图表**：![使用 Grafana 可视化指标](img/image_07_011.jpg)
- en: Then, adding a basic CPU usage plot looks like this:![Visualizing metrics with
    Grafana](img/image_07_012.jpg)
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，添加一个基本的 CPU 使用率图表如下所示：![使用 Grafana 可视化指标](img/image_07_012.jpg)
- en: At this point I encourage you to browse [http://docs.grafana.org](http://docs.grafana.org)
    to find out more about templating, dynamic dashboards, access control, tagging,
    scripting, playlist, and so on.
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此时，我鼓励你浏览 [http://docs.grafana.org](http://docs.grafana.org) 以了解更多有关模板、动态仪表板、访问控制、标签、脚本、播放列表等方面的信息。
- en: Monitoring
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控
- en: We have our metrics flowing into Prometheus. We also have a way of exploring
    and visualizing them. The next step should probably be to configure some sort
    of alerts, so that we show other people we are doing real work.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的指标已经流入 Prometheus。我们也有了一种探索和可视化它们的方法。下一步可能是配置某种告警，这样我们就能向其他人展示我们正在进行实际工作。
- en: Alerting with Prometheus
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Prometheus 进行告警
- en: '|   | *ALERTING OVERVIEW**Alerting with Prometheus is separated into two parts.
    Alerting rules in Prometheus servers send alerts to an Alertmanager. The Alertmanager
    then manages those alerts, including silencing, inhibition, aggregation and sending
    out notifications via methods such as e-mail, PagerDuty and HipChat.**The main
    steps to setting up alerting and notifications are:**- Setup and configure the
    Alertmanager**- Configure Prometheus to talk to the Alertmanager with the-alertmanager.url
    flag**- Create alerting rules in Prometheus* |   |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '|   | *告警概述**Prometheus 的告警功能分为两个部分。Prometheus 服务器中的告警规则将告警发送到 Alertmanager。Alertmanager
    然后管理这些告警，包括静默、抑制、聚合和通过电子邮件、PagerDuty 和 HipChat 等方式发送通知。**设置告警和通知的主要步骤是：**- 设置并配置
    Alertmanager**- 配置 Prometheus 以通过 --alertmanager.url 标志与 Alertmanager 通信**- 在
    Prometheus 中创建告警规则* |   |'
- en: '|   | --*https://prometheus.io/docs/alerting/overview/* |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|   | --*https://prometheus.io/docs/alerting/overview/* |'
- en: Let us break this down.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将其分解：
- en: We already have Alertmanager running with some minimal configuration in `/opt/prometheus/alertmanager/alertmanager.yml`.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在 `/opt/prometheus/alertmanager/alertmanager.yml` 中以一些最小配置运行了 Alertmanager。
- en: Our Prometheus instance is aware of it as we passed the `-alertmanager.url=http://localhost:9093`
    flag.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们传递了 `-alertmanager.url=http://localhost:9093` 标志，我们的 Prometheus 实例已经意识到了这一点。
- en: 'What is left is to create alerting rules. We''ll store these in a `rules/`
    folder:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的就是创建告警规则。我们将这些存储在 `rules/` 文件夹中：
- en: '[PRE19]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We need to tell Prometheus about this location, so we add a `rule_files` section
    to `prometheus.yml`:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要告诉 Prometheus 这个位置，因此我们需要在 `prometheus.yml` 中添加一个 `rule_files` 部分：
- en: Note
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/prometheus.yml](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/prometheus.yml)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考：[https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/prometheus.yml](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/prometheus.yml)
- en: '[PRE20]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This way we can store separate rule files, perhaps based on the type of rules
    they contain?
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这样我们可以存储单独的规则文件，也许可以根据它们包含的规则类型来区分？
- en: 'As an example, let us have a keepalive and a disk usage alert:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，让我们设置一个保活和磁盘使用告警：
- en: Note
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/rules](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/rules)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考：[https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/rules](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_07_CodeFiles/promjenkins/opt/prometheus/server/rules)
- en: '`/opt/prometheus/server/rules/keepalive.rules`:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '`/opt/prometheus/server/rules/keepalive.rules`：'
- en: '[PRE21]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '`/opt/prometheus/server/rules/disk.rules`:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '`/opt/prometheus/server/rules/disk.rules`：'
- en: '[PRE22]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you'll notice, we are being impatient with the `FOR 1m` and `>20`, meaning
    notifications will fire after just 60 seconds of alert detection and the alert
    threshold is only 20% of space used.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所注意到的，我们在 `FOR 1m` 和 `>20` 上显得不耐烦，这意味着在检测到告警后仅经过 60 秒，且告警阈值只有 20% 的空间使用。
- en: 'In a more realistic scenario, we should wait a bit longer to filter any transient
    issues and use severities to distinguish between critical alerts and warnings
    (ref: [https://github.com/prometheus/alertmanager](https://github.com/prometheus/alertmanager)).'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在更实际的场景中，我们应等待更长时间，以过滤掉任何瞬态问题，并使用严重性来区分关键警报和警告（参考：[https://github.com/prometheus/alertmanager](https://github.com/prometheus/alertmanager)）。
- en: 'Reload Prometheus with the new rules in place. Now let us suppose that one
    of the web server nodes goes down:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 重新加载Prometheus并应用新规则。现在，假设其中一个Web服务器节点出现故障：
- en: '![Alerting with Prometheus](img/image_07_013.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![Prometheus告警](img/image_07_013.jpg)'
- en: 'Switching to the **Alerts** tab we see:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 切换到**警报**标签页，我们看到：
- en: '![Alerting with Prometheus](img/image_07_014.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![Prometheus告警](img/image_07_014.jpg)'
- en: 'In the Alertmanager respectively: (`http://$ public_IP_of_promjenkins_node:9093/#/alerts`):'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在Alertmanager中，分别为：(`http://$ public_IP_of_promjenkins_node:9093/#/alerts`)：
- en: '![Alerting with Prometheus](img/image_07_015.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![Prometheus告警](img/image_07_015.jpg)'
- en: At this point an e-mail notification should have gone out as well.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，应该已经发送了电子邮件通知。
- en: Self-remediation with Prometheus and Jenkins
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Prometheus和Jenkins的自我修复
- en: The dream of every operator is an ecosystem that looks after itself.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 每个运维人员的梦想是一个能够自我照看的生态系统。
- en: Imagine for a moment an environment in which, instead of receiving alerts prompting
    for action, we received mere notifications or reports of actions taken on our
    behalf.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果我们生活在一个环境中，不是接收到要求采取行动的警报，而是接收到仅仅是通知或我们已采取的行动的报告，会是怎样的？
- en: 'For example, no more "CRITICAL: Service X is not responding. Please check."
    but "INFO: Service X was unresponsive at nn:nn:nn and was restarted after N seconds
    at nn:nn:nn" instead.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '例如，不再是“CRITICAL: 服务X未响应，请检查。”，而是“INFO: 服务X在nn:nn:nn时未响应，并在nn:nn:nn时经过N秒后重启。”'
- en: Well, technically, this should not be too difficult to achieve if we were to
    provide enough context to the tools we use today. It is not uncommon to find alerts
    which tend to get resolved in the same manner under the same conditions and those
    are to be considered prime candidates for automation.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，如果我们为今天使用的工具提供足够的上下文，那么实现这一点应该不会太困难。在相同条件下，解决方案通常以相同方式解决警报，这些警报应被视为自动化的主要候选项。
- en: To demonstrate, let us assume we inherited this old, no longer supported application.
    A cool app overall, but it does not have the habit of tidying up after itself,
    so would occasionally fill up its `tmp` directory.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示，我们假设我们继承了这个旧的、不再支持的应用程序。总体来说是个不错的应用，但它没有整理自己的习惯，因此偶尔会填满其`tmp`目录。
- en: Let us also assume that while we are not particularly excited about having to
    connect to this app's server to delete `tmp` files at random times of the day,
    our friend, Mr. Jenkins - does not mind at all.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一下，虽然我们并不特别喜欢每天在随机的时间连接到这个应用的服务器去删除`tmp`文件，但我们的朋友——Jenkins先生，完全不介意。
- en: Conveniently, Jenkins allows jobs to be triggered via a relevant `JOB_URL` and
    at the same time Prometheus supports webhook calls as a method of alert notification.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 方便的是，Jenkins允许通过相关的`JOB_URL`触发任务，同时Prometheus支持Webhook调用作为警报通知的方法。
- en: 'Here is the plan:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 计划如下：
- en: Prometheus will make a webhook call to Jenkins whenever a `disk_space` alert
    is fired with the alert details passed as parameters.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每当触发`disk_space`警报时，Prometheus将调用Webhook并传递警报详细信息作为参数给Jenkins。
- en: Jenkins will use the parameters to determine which host to connect to and clean
    up the application's `tmp` directory.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Jenkins将使用这些参数来决定连接哪个主机，并清理应用程序的`tmp`目录。
- en: 'We would need to:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要：
- en: Create a parameterized Jenkins job which can be triggered remotely.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个参数化的Jenkins任务，可以通过远程触发。
- en: Allow Jenkins to `ssh` into the application's host.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 允许Jenkins通过`ssh`连接到应用程序的主机。
- en: Setup a webhook receiver in Prometheus which calls the Jenkins job when a certain
    alert is fired.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Prometheus中设置一个Webhook接收器，当某个警报触发时调用Jenkins任务。
- en: 'First a quick Jenkins installation onto our `promjenkins` node:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 首先在`promjenkins`节点上快速安装Jenkins：
- en: '[PRE23]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '`TCP: 8080` needs to be open, then you should be able to reach the Jenkins
    service at `http://$public_IP_of_promjenkins_node:8080`.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '`TCP: 8080`需要开放，然后你应该能够通过`http://$public_IP_of_promjenkins_node:8080`访问Jenkins服务。'
- en: 'Under **Manage Jenkins** | **Manage Users** create an account for Prometheus:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在**管理Jenkins** | **管理用户**中为Prometheus创建一个账户：
- en: '![Self-remediation with Prometheus and Jenkins](img/image_07_016.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![Prometheus和Jenkins自我修复](img/image_07_016.jpg)'
- en: Then, under **Manage Jenkins** | **Configure Global Security**, select Jenkins'
    own user database and **Matrix-based Security**, then add both accounts.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Untick **Prevent Cross Site Request Forgery exploits** if you find that it causes
    issues when making `curl` request to Jenkins.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'Grant yourself **Overall Administer rights** and **Prometheus Overall Read**
    plus **Job Build/Read**:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '![Self-remediation with Prometheus and Jenkins](img/image_07_017.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
- en: 'To be able to ssh into the app (web server) nodes we need a key for the Jenkins
    user:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'While we are here, let us create an ssh config file for the Jenkins user (`~/.ssh/config`)
    containing:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This is to allow our non-interactive jobs to ssh to instances for the first
    time.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to take the generated public key and add it to the Auto Scale
    Group user data , so that it gets onto our web server instances. We will be using
    the standard (Amzn-Linux) ec2-user account to connect:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/webserver/user_data.sh](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/webserver/user_data.sh)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now let us create the Jenkins job (freestyle project) with a few parameters:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '![Self-remediation with Prometheus and Jenkins](img/image_07_018.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
- en: We will discuss those four parameters (`alertname`, `alertcount`, `instance`,
    `labels`) later. In the **Build** section, select **Execute shell** and enter
    `exit 0` as a placeholder until we are ready to configure the job further. **Save**
    and let's get back to Prometheus.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: 'As we mentioned earlier, we will be using the webhook receiver to trigger the
    Jenkins job. While the receiver allows us to set a URL to call, it does not seem
    to allow for any parameters to be included. To accomplish this, we will use a
    small helper application called **prometheus-am-executor** (ref: [https://github.com/imgix/prometheus-am-executor](https://github.com/imgix/prometheus-am-executor)).'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: The executor sits between the Alertmanager and an arbitrary executable. It receives
    the webhook call from the Alertmanager and runs the executable, passing a list
    of alert variables to it. In our case, we will be executing a shell script which
    processes those variables and constructs a `curl` call in the format that Jenkins
    expects.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us install the helper app alongside Prometheus and the Alertmanager:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'On success, you should have a binary in `/opt/prometheus/executor/bin`. Now
    the script (executable) that we mentioned:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/executor/executor.sh](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/executor/executor.sh)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'In essence we are constructing an HTTP call to our Jenkins job URL at `http://localhost:8080/job/prometheus_webhook/build`
    passing the `alertcount`, `alertname`, `instance` and `labels` parameters. All
    values come from the AMX environment variables which the prometheus-am-executor
    exposes (ref: [https://github.com/imgix/prometheus-am-executor](https://github.com/imgix/prometheus-am-executor)).'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we need to reconfigure the Alertmanager to use webhooks:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Please refer to: [https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/alertmanager/alertmanager.yml](https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_07_CodeFiles/promjenkins/opt/prometheus/alertmanager/alertmanager.yml)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'So, we have added a new sub-route which would match on `alertname`: `High_disk_space_usage`
    and use the `jenkins-webhook` receiver.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: 'Reload Alertmanager and let us start the executor. Assuming that the `executor.sh`
    has been placed in `/opt/prometheus/executor`:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We have the executor running (port `8888`) and ready to accept requests from
    the Alertmanager.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'Before triggering any test alerts, let''s go back to our Jenkins job. You are
    now familiar with the parameters it expects and the ones that we pass via the
    `webhook` | `executor` | `jenkins` setup that we have, so we can replace the contents
    of the placeholder **Build** step with this shell script:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'To test all of this, we need to ssh into one of the ASG (web server) instances
    which Prometheus is monitoring and setup a pretend App temporary folder like so:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This should give us a small filesystem to play with. Next, we fill it up:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This is way over the 20% we have set in the `High_disk_space_usage` and should
    trigger it. In turn the executor should call Jenkins and run our job:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '![Self-remediation with Prometheus and Jenkins](img/image_07_019.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
- en: We can see Jenkins connecting to the affected instance over SSH, then clearing
    our fake application `tmp` directory.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that while we allow ourselves root access for the purpose
    of this example, in any other circumstances you would either ensure that Jenkins
    could handle the given `tmp` directory as a non-privileged user, or if you would
    absolutely have to use `sudo` and then limit the commands and command line arguments
    that can be used.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we looked at a way of centralizing our logs with Logstash and
    Elasticsearch then browsing them in Kibana. We configured a metrics collection
    and visualization with the help of Prometheus, Telegraf and Grafana. Finally,
    we added monitoring via Prometheus and self-remediation using Jenkins.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter takes us into the area of optimization. We shall discuss cost
    considerations and approaches to demand-based scaling.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
