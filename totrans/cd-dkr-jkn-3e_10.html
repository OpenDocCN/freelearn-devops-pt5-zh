<html><head></head><body>
		<div><h1 id="_idParaDest-186"><em class="italic"><a id="_idTextAnchor185"/>Chapter 7</em>: Configuration Management with Ansible</h1>
			<p>We have already covered the two most crucial phases of the continuous delivery process: the commit phase and automated acceptance testing. We also explained how to cluster your environments for both your application and Jenkins agents. In this chapter, we will focus on configuration management, which connects the virtual containerized environment to the real server infrastructure.</p>
			<p>This chapter will cover the following points:</p>
			<ul>
				<li>Introducing configuration management</li>
				<li>Installing Ansible</li>
				<li>Using Ansible</li>
				<li>Deployment with Ansible</li>
				<li>Ansible with Docker and Kubernetes</li>
				<li>Introducing infrastructure as code</li>
				<li>Introducing Terraform</li>
			</ul>
			<h1 id="_idParaDest-187"><a id="_idTextAnchor186"/>Technical requirements</h1>
			<p>To follow along with the instructions in this chapter, you'll need the following hardware/software:</p>
			<ul>
				<li>Java 8+</li>
				<li>Python</li>
				<li>Remote machines with the Ubuntu operating system and SSH server installed</li>
				<li>An AWS account</li>
			</ul>
			<p>All the examples and solutions to the exercises can be found on GitHub at <a href="https://github.com/PacktPublishing/Continuous-Delivery-With-Docker-and-Jenkins-3rd-Edition/tree/main/Chapter07">https://github.com/PacktPublishing/Continuous-Delivery-With-Docker-and-Jenkins-3rd-Edition/tree/main/Chapter07</a>.</p>
			<p>Code in Action videos for this chapter can be viewed at <a href="https://bit.ly/3JkcGLE">https://bit.ly/3JkcGLE</a>.</p>
			<h1 id="_idParaDest-188"><a id="_idTextAnchor187"/>Introducing configuration management</h1>
			<p>Configuration management<a id="_idIndexMarker737"/> is the process of controlling configuration changes in such a way that the system maintains integrity over time. Even though the term did not originate in the IT industry, currently, it is broadly used to refer to software and hardware. In this context, it concerns the following aspects:</p>
			<ul>
				<li><strong class="bold">Application configuration</strong>: This<a id="_idIndexMarker738"/> involves software properties that decide how the system works, which are usually expressed in the form of flags or properties files passed to the application, for example, the database address, the maximum chunk size for file processing, or the logging level. They can be applied during different development phases: build, package, deploy, or run.</li>
				<li><strong class="bold">Server configuration</strong>: This <a id="_idIndexMarker739"/>defines what dependencies should be installed on each server and specifies the way applications are orchestrated (which application is run on which server, and in how many instances).</li>
				<li><strong class="bold">Infrastructure configuration</strong>: This <a id="_idIndexMarker740"/>involves server infrastructure and environment configuration. If you use on-premises servers, then this part is related to the manual hardware and network installation; if you use cloud solutions, then this part can be automated with the <strong class="bold">infrastructure as code </strong>(<strong class="bold">IaC</strong>)e approach. </li>
			</ul>
			<p>As an example, we can <a id="_idIndexMarker741"/>think of the calculator web service, which uses the Hazelcast server. Let's look at the following diagram, which presents how configuration management works:</p>
			<div><div><img src="img/B18223_07_01.jpg" alt="Figure 7.1 – Sample configuration management&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.1 – Sample configuration management</p>
			<p>The configuration<a id="_idIndexMarker742"/> management tool reads the configuration file and prepares the environment. It installs dependent tools and libraries and deploys the applications to multiple instances. Additionally, in the case of cloud deployment, it can provide the necessary infrastructure.</p>
			<p>In the preceding example, <strong class="bold">Infrastructure Configuration</strong> specifies the required servers and S<strong class="bold">erver Configuration</strong> defines that the <strong class="bold">Calculator</strong> service should be deployed in two instances, on <strong class="bold">Server 1</strong> and <strong class="bold">Server 2</strong>, and that the Hazelcast service should be installed on <strong class="bold">Server 3</strong>. <strong class="bold">Calculator Application Configuration</strong> specifies the port and the address of the Hazelcast server so that the services can communicate.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">The configuration can differ, depending on the type of the environment (QA, staging, or production); for example, server addresses can be different.</p>
			<p>There are many approaches to configuration management, but before we look into concrete solutions, let's comment on what characteristics a good configuration management tool should have.</p>
			<h2 id="_idParaDest-189"><a id="_idTextAnchor188"/>Traits of good configuration management</h2>
			<p>What should a modern configuration management solution look like? Let's walk through the most important factors:</p>
			<ul>
				<li><strong class="bold">Automation</strong>: Each <a id="_idIndexMarker743"/>environment should be automatically reproducible, including the operating system, the network configuration, the software installed, and the applications deployed. In such an approach, fixing production issues means nothing more than an automatic rebuild of the environment. What's more, it simplifies server replications and ensures that the staging and production environments are exactly the same.</li>
				<li><strong class="bold">Version control</strong>: Every change in the configuration should be tracked, so that we know who made it, why, and when. Usually, that means keeping the configuration in the source code repository, either with the code or in a separate place. The former solution is recommended because configuration properties have a different life cycle than the application itself. Version control also helps with fixing production issues; the configuration can always be rolled back to the previous version, and the environment automatically rebuilt. The only exception to the version control-based solution is storing credentials and other sensitive information; these should never be checked in.</li>
				<li><strong class="bold">Incremental changes</strong>: Applying a change in the configuration should not require rebuilding the whole environment. On the contrary, a small change in the configuration should only change the related part of the infrastructure.</li>
				<li><strong class="bold">Server provisioning</strong>: Thanks to automation, adding a new server should be as quick as adding its address to the configuration (and executing one command).</li>
				<li><strong class="bold">Security</strong>: The access to both the configuration management tool and the machines under its control should be well secured. When using the SSH protocol for communication, the access to the keys or credentials needs to be well protected.</li>
				<li><strong class="bold">Simplicity</strong>: Every <a id="_idIndexMarker744"/>member of the team should be able to read the configuration, make a change, and apply it to the environment. The properties themselves should also be kept as simple as possible, and the ones that are not subject to change are better off kept hardcoded.</li>
			</ul>
			<p>It is important to keep these points in mind while creating the configuration, and even beforehand while choosing the right configuration management tool.</p>
			<h2 id="_idParaDest-190"><a id="_idTextAnchor189"/>Overview of configuration management tools</h2>
			<p>In the classic sense, before<a id="_idIndexMarker745"/> the cloud era, configuration management referred to the process that started when all the servers were already in place. So, the starting point was a set of IP addresses with machines accessible via SSH. For that purpose, the most popular configuration management tools are Ansible, Puppet, and Chef. Each of them is a good choice; they are all open source products with free basic versions and paid enterprise editions. The most important differences between them are as follows:</p>
			<ul>
				<li><strong class="bold">Configuration language</strong>: Chef uses Ruby, Puppet uses its own DSL (based on Ruby), and Ansible uses YAML.</li>
				<li><strong class="bold">Agent-based</strong>: Puppet and Chef use agents for communication, which means that each managed server needs to have a special tool installed. Ansible, on the other hand, is agentless and uses the standard SSH protocol for communication.</li>
			</ul>
			<p>The agentless feature is a significant advantage because it implies no need to install anything on servers. What's more, Ansible is quickly trending upward, which is why it was chosen for this book. Nevertheless, other tools can also be used successfully for the continuous delivery process.</p>
			<p>Together with cloud transformation, the meaning of configuration management widened and started to include what is<a id="_idIndexMarker746"/> called <strong class="bold">IaC</strong>. As the input, you no longer need a set of IP addresses, but it's enough to provide the credentials to your favorite cloud provider. Then, IaC tools can provision servers for you. What's more, each cloud provider offers a portfolio of services, so in many cases, you don't even need to provision bare-metal servers, but directly use cloud services. While you can still use Ansible, Puppet, or Chef for that purpose, there is a tool called Terraform that is dedicated to the IaC use case.</p>
			<p>Let's first describe the classic approach to configuration management with Ansible, and then walk through the IaC solution using Terraform.</p>
			<h1 id="_idParaDest-191"><a id="_idTextAnchor190"/>Installing Ansible</h1>
			<p>Ansible is an <a id="_idIndexMarker747"/>open source, agentless automation engine for software provisioning, configuration management, and application deployment. Its first release was in 2012, and its basic version is free for both personal and commercial use. The enterprise version is <a id="_idIndexMarker748"/>called <strong class="bold">Ansible Tower</strong>, which provides GUI management and dashboards, the REST API, role-based access control, and some more features.</p>
			<p>We will present the installation process and a description of how Ansible can be used separately, as well as in conjunction with Docker.</p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor191"/>Ansible server requirements</h2>
			<p>Ansible uses the<a id="_idIndexMarker749"/> SSH protocol for communication and has no special requirements regarding the machine it manages. There is also no central master server, so it's enough to install the Ansible client tool anywhere; we can then use it to manage the whole infrastructure.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">The only requirement for the machines being managed is to have the Python tool (and obviously, the SSH server) installed. These tools are, however, almost always available on any server by default.</p>
			<h2 id="_idParaDest-193"><a id="_idTextAnchor192"/>Ansible installation</h2>
			<p>The installation <a id="_idIndexMarker750"/>instructions will differ depending on the operating system. In the case of Ubuntu, it's enough to run the following commands:</p>
			<pre>$ sudo apt-get install software-properties-common
$ sudo apt-add-repository ppa:ansible/ansible
$ sudo apt-get update
$ sudo apt-get install ansible</pre>
			<p class="callout-heading">Information </p>
			<p class="callout">You can find the installation guides<a id="_idIndexMarker751"/> for all the operating systems on the official Ansible page, at <a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html">https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html</a>.</p>
			<p>After the<a id="_idIndexMarker752"/> installation process is complete, we can execute the <code>ansible</code> command to check that everything was installed successfully:</p>
			<pre>$ ansible –version
ansible [core 2.12.2]
  config file = /etc/ansible/ansible.cfg
...</pre>
			<h1 id="_idParaDest-194"><a id="_idTextAnchor193"/>Using Ansible</h1>
			<p>In order to use <a id="_idIndexMarker753"/>Ansible, we first need to define the inventory, which represents the available resources. Then, we will be able to either execute a single command or define a set of tasks using the Ansible playbook.</p>
			<h2 id="_idParaDest-195"><a id="_idTextAnchor194"/>Creating an inventory</h2>
			<p>An <a id="_idIndexMarker754"/>inventory is<a id="_idIndexMarker755"/> a list of all the servers that are managed by Ansible. Each server requires nothing more than the Python interpreter and the SSH server installed. By default, Ansible assumes that SSH keys are used for authentication; however, it is also possible to use a username and password by adding the <code>--ask-pass</code> option to the Ansible commands.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">SSH keys can be generated with the <code>ssh-keygen</code> tool, and they are usually stored in the <code>~/.ssh</code> directory.</p>
			<p>The inventory is<a id="_idIndexMarker756"/> defined by default in the <code>/etc/ansible/hosts</code> file (but its location can be defined with the <code>–i</code> parameter), and it has the following structure:</p>
			<pre>[group_name]
&lt;server1_address&gt;
&lt;server2_address&gt;
...</pre>
			<p class="callout-heading">Tip </p>
			<p class="callout">The inventory syntax also accepts ranges of servers, for example, <code>www[01-22].company.com</code>. The SSH port should also be specified if it's anything other than <code>22</code> (the default).</p>
			<p>There can be many groups in the inventory file. As an example, let's define two machines in one group of servers:</p>
			<pre>[webservers]
192.168.64.12
192.168.64.13</pre>
			<p>We can also create the configuration with server aliases and specify the remote user:</p>
			<pre>[webservers]
web1 ansible_host=192.168.64.12 ansible_user=ubuntu
web2 ansible_host=192.168.64.13 ansible_user=ubuntu</pre>
			<p>The preceding file defines a group called <code>webservers</code>, which consists of two servers. The Ansible client will log into both of them as the user <code>ubuntu</code>. When we have the inventory created, let's discover how we can use it to execute the same command on many servers.</p>
			<p class="callout-heading">Information</p>
			<p class="callout">Ansible offers the possibility to dynamically pull the inventory from a cloud provider (for example, Amazon EC2/Eucalyptus), LDAP, or <a id="_idIndexMarker757"/>Cobbler. Read more about dynamic inventories at <a href="https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html">https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html</a>.</p>
			<h2 id="_idParaDest-196"><a id="_idTextAnchor195"/>Ad hoc commands</h2>
			<p>The simplest <a id="_idIndexMarker758"/>command we can run is a ping on all servers. Assuming that we have two remote machines (<code>192.168.64.12</code> and <code>192.168.64.13</code>) with SSH servers configured and the inventory file (as defined in the last section), let's execute the <code>ping</code> command:</p>
			<pre>$ ansible all -m ping
web1 | SUCCESS =&gt; {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
    },
    "changed": false,
    "ping": "pong"
}
web2 | SUCCESS =&gt; {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
    },
    "changed": false,
    "ping": "pong"
}</pre>
			<p>We used the <code>-m &lt;module_name&gt;</code> option, which allows for specifying the module that should be executed on the remote hosts. The result is successful, which means that the servers are reachable, and the authentication is configured correctly.</p>
			<p>Note that we used <code>all</code>, so that all<a id="_idIndexMarker759"/> servers would be addressed, but we could also call them by the <code>webservers</code> group name, or by the single host alias. As a second example, let's execute a shell command on only one of the servers:</p>
			<pre>$ ansible web1 -a "/bin/echo hello"
web1 | CHANGED | rc=0 &gt;&gt;
hello</pre>
			<p>The <code>-a &lt;arguments&gt;</code> option specifies the arguments that are passed to the Ansible module. In this case, we didn't specify the module, so the arguments are executed as a shell Unix command. The result was successful, and <code>hello</code> was printed.</p>
			<p class="callout-heading">Tip </p>
			<p class="callout">If the <code>ansible</code> command is connecting to the server for the first time (or if the server is reinstalled), then we are prompted with the key confirmation message (the SSH message, when the host is not present in <code>known_hosts</code>). Since it may interrupt an automated script, we can disable the prompt message by uncommenting <code>host_key_checking = False</code> in the <code>/etc/ansible/ansible.cfg</code> file, or by setting the environment variable, <code>ANSIBLE_HOST_KEY_CHECKING=False</code>.</p>
			<p>In its simplistic form, the Ansible ad hoc command syntax looks as follows:</p>
			<pre>$ ansible &lt;target&gt; -m &lt;module_name&gt; -a &lt;module_arguments&gt;</pre>
			<p>The purpose of ad hoc commands is to do something quickly when it is not necessary to repeat it. For example, we may want to check whether a server is alive or power off all the machines for the Christmas break. This mechanism can be seen as a command execution on a group of machines, with the additional syntax simplification provided by the modules. The real power of Ansible automation, however, lies in playbooks.</p>
			<h2 id="_idParaDest-197"><a id="_idTextAnchor196"/>Playbooks</h2>
			<p>An <strong class="bold">Ansible playbook</strong> is a<a id="_idIndexMarker760"/> configuration file that describes how servers should be configured. It provides a way to define a sequence of tasks that should be performed on each of the machines. A playbook<a id="_idIndexMarker761"/> is expressed in the YAML configuration language, which makes it human-readable and easy to understand. Let's start with a sample playbook, and then see how we can use it.</p>
			<h3>Defining a playbook</h3>
			<p>A playbook <a id="_idIndexMarker762"/>is composed of one or many plays. Each play contains a host group name, tasks to perform, and configuration details (for example, the remote username or access rights). An example playbook might look like this:</p>
			<pre>---
- hosts: web1
  become: yes
  become_method: sudo
  tasks:
  - name: ensure apache is at the latest version
    apt: name=apache2 state=latest
  - name: ensure apache is running
    service: name=apache2 state=started enabled=yes</pre>
			<p>This configuration contains one play, which performs the following:</p>
			<ul>
				<li>Only executes on the <code>web1</code> host</li>
				<li>Gains root access using the <code>sudo</code> command</li>
				<li>Executes two tasks:<ul><li><code>apt</code> Ansible module (called with two parameters, <code>name=apache2</code> and <code>state=latest</code>) checks whether the <code>apache2</code> package is installed on the server, and if it isn't, it uses the <code>apt-get</code> tool to install it.</li><li><code>service</code> Ansible module (called with three parameters, <code>name=apache2</code>, <code>state=started</code>, and <code>enabled=yes</code>) checks whether the <code>apache2</code> Unix service is started, and if it isn't, it uses the <code>service</code> command to start it.</li></ul></li>
			</ul>
			<p>Note that each task has a <a id="_idIndexMarker763"/>human-readable name, which is used in the console output, such that <code>apt</code> and <code>service</code> are Ansible modules, and <code>name=apache2</code>, <code>state=latest</code>, and <code>state=started</code> are module arguments. You already saw Ansible modules and arguments while using ad hoc commands. In the preceding playbook, we only defined one play, but there can be many of them, and each can be related to different groups of hosts.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">Note that since we used the <code>apt</code> Ansible module, the playbook is dedicated to Debian/Ubuntu servers.</p>
			<p>For example, we could define two groups of servers in the inventory: <code>database</code> and <code>webservers</code>. Then, in the playbook, we could specify the tasks that should be executed on all database-hosting machines, and some different tasks that should be executed on all the web servers. By using one command, we could set up the whole environment.</p>
			<h3>Executing the playbook</h3>
			<p>When <code>playbook.yml</code> is<a id="_idIndexMarker764"/> defined, we can execute it using the <code>ansible-playbook</code> command:</p>
			<pre>$ ansible-playbook playbook.yml
PLAY [web1] ***************************************************************
TASK [setup] **************************************************************
ok: [web1]
TASK [ensure apache is at the latest version] *****************************
changed: [web1]
TASK [ensure apache is running] *******************************************
ok: [web1]
PLAY RECAP ****************************************************************
web1: ok=3 changed=1 unreachable=0 failed=0 </pre>
			<p class="callout-heading">Tip </p>
			<p class="callout">If the server requires entering the <a id="_idIndexMarker765"/>password for the <code>sudo</code> command, then we need to add the <code>--ask-sudo-pass</code> option to the <code>ansible-playbook</code> command. It's also possible to pass the <code>sudo</code> password (if required) by setting the extra variable, <code>-e ansible_become_pass=&lt;sudo_password&gt;</code>.</p>
			<p>The playbook configuration was executed, and therefore, the <code>apache2</code> tool was installed and started. Note that if the task has changed something on the server, it is marked as <code>changed</code>. On the <a id="_idIndexMarker766"/>contrary, if there was no change, the task is marked as <code>ok</code>.</p>
			<p class="callout-heading">Tip </p>
			<p class="callout">It is possible to run tasks in parallel by using the <code>-f &lt;num_of_threads&gt;</code> option.</p>
			<h3>The playbook's idempotency</h3>
			<p>We can execute the command <a id="_idIndexMarker767"/>again, as follows:</p>
			<pre>$ ansible-playbook playbook.yml
PLAY [web1] ***************************************************************
TASK [setup] **************************************************************
ok: [web1]
TASK [ensure apache is at the latest version] *****************************
ok: [web1]
TASK [ensure apache is running] *******************************************
ok: [web1]
PLAY RECAP ****************************************************************
web1: ok=3 changed=0 unreachable=0 failed=0</pre>
			<p>Note that the output is slightly different. This time, the command didn't change anything on the server. That's because each Ansible module is designed to be idempotent. In other words, executing the same module many times in a sequence should have the same effect as executing it only once.</p>
			<p>The simplest way to achieve<a id="_idIndexMarker768"/> idempotency is to always check first whether the task has been executed yet, and only execute it if it hasn't. Idempotency is a powerful feature, and we should always write our Ansible tasks this way.</p>
			<p>If all the tasks are idempotent, then we can execute them as many times as we want. In that context, we can think of the playbook as a description of the desired state of remote machines. Then, the <code>ansible-playbook</code> command takes care of bringing the machine (or group of machines) into that state.</p>
			<h3>Handlers</h3>
			<p>Some operations should <a id="_idIndexMarker769"/>only be executed if some other tasks are changed. For example, imagine that you copy the configuration file to the remote machine and the Apache server should only be restarted if the configuration file has changed. <em class="italic">How could we approach such a case?</em></p>
			<p>Ansible provides an event-oriented mechanism to notify about the changes. In order to use it, we need to know two keywords:</p>
			<ul>
				<li><code>handlers</code>: This specifies the tasks executed when notified.</li>
				<li><code>notify</code>: This specifies the handlers that should be executed.</li>
			</ul>
			<p>Let's look at the following example of how we could copy the configuration to the server and restart Apache only if the configuration has changed:</p>
			<pre>tasks:
- name: copy configuration
  copy:
    src: foo.conf
    dest: /etc/foo.conf
  notify:
  - restart apache
handlers:
- name: restart apache
  service:
    name: apache2
    state: restarted</pre>
			<p>Now, we can <a id="_idIndexMarker770"/>create the <code>foo.conf</code> file and run the <code>ansible-playbook</code> command:</p>
			<pre>$ touch foo.conf
$ ansible-playbook playbook.yml
...
TASK [copy configuration] ************************************************
changed: [web1]
RUNNING HANDLER [restart apache] *****************************************
changed: [web1]
PLAY RECAP ***************************************************************
web1: ok=5 changed=2 unreachable=0 failed=0   </pre>
			<p class="callout-heading">Information</p>
			<p class="callout">Handlers are always executed at the end of the play, and only once, even if triggered by multiple tasks.</p>
			<p>Ansible <a id="_idIndexMarker771"/>copied the file and restarted the Apache server. It's important to understand that if we run the command again, nothing will happen. However, if we change the content of the <code>foo.conf</code> file and then run the <code>ansible-playbook</code> command, the file will be copied again (and the Apache server will be restarted):</p>
			<pre>$ echo "something" &gt; foo.conf
$ ansible-playbook playbook.yml
...
TASK [copy configuration] *************************************************
changed: [web1]
RUNNING HANDLER [restart apache] ******************************************
changed: [web1]
PLAY RECAP ****************************************************************
web1: ok=5 changed=2 unreachable=0 failed=0   </pre>
			<p>We used the <code>copy</code> module, which is smart enough to detect whether the file has changed and then make a change on the server.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">There is also a publish-subscribe mechanism in Ansible. Using it means assigning a topic to many handlers. Then, a task notifies the topic to execute all related handlers.</p>
			<h3>Variables</h3>
			<p>While the Ansible <a id="_idIndexMarker772"/>automation makes things identical and repeatable for multiple hosts, it is inevitable that servers may require some differences. For example, think of the application port number. It can be different, depending on the machine. Luckily, Ansible provides variables, which are a good mechanism to deal with server differences. Let's create a new playbook and define a variable:</p>
			<pre>---
- hosts: web1
  vars:
    http_port: 8080</pre>
			<p>The configuration defines the <code>http_port</code> variable with the value <code>8080</code>. Now, we can use it by using the <code>Jinja2</code> syntax:</p>
			<pre>tasks:
- name: print port number
  debug:
    msg: "Port number: {{ http_port }}"</pre>
			<p class="callout-heading">Tip </p>
			<p class="callout">The <code>Jinja2</code> language allows for doing way more than just getting a variable. We can use it to create conditions, loops, and much more. You can find more details on the Jinja page, at <a href="https://jinja.palletsprojects.com/">https://jinja.palletsprojects.com/</a>.</p>
			<p>The <code>debug</code> module prints the message while executing. If we run the <code>ansible-playbook</code> command, we can see the variable usage:</p>
			<pre>$ ansible-playbook playbook.yml
...
TASK [print port number] **************************************************
ok: [web1] =&gt; {
      "msg": "Port number: 8080"
}  </pre>
			<p>Apart from user-defined<a id="_idIndexMarker773"/> variables, there are also predefined automatic variables. For example, the <code>hostvars</code> variable stores a map with the information regarding all hosts from the inventory. Using the Jinja2 syntax, we can iterate and print the IP addresses of all the hosts in the inventory:</p>
			<pre>---
- hosts: web1
  tasks:
  - name: print IP address
    debug:
      msg: "{% for host in groups['all'] %} {{
              hostvars[host]['ansible_host'] }} {% endfor %}"</pre>
			<p>Then, we can execute the <code>ansible-playbook</code> command:</p>
			<pre>$ ansible-playbook playbook.yml
...
TASK [print IP address] **************************************************
ok: [web1] =&gt; {
      "msg": " 192.168.64.12  192.168.64.13 "
}</pre>
			<p>Note that with the use of the Jinja2 language, we can specify the flow control operations inside the Ansible playbook file.</p>
			<h2 id="_idParaDest-198"><a id="_idTextAnchor197"/>Roles</h2>
			<p>We can install any<a id="_idIndexMarker774"/> tool on the remote server by using Ansible playbooks. Imagine that <a id="_idIndexMarker775"/>we would like to have a server with MySQL. We could easily prepare a playbook similar to the one with the <code>apache2</code> package. However, if you think about it, a server with MySQL is quite a common case, and someone has surely already prepared a playbook for it, so maybe we can just reuse it. This is where Ansible roles and Ansible Galaxy come into play.</p>
			<h3>Understanding roles</h3>
			<p>An Ansible role is a <a id="_idIndexMarker776"/>well-structured playbook part prepared to be included in playbooks. Roles <a id="_idIndexMarker777"/>are separate units that always have the following directory structure:</p>
			<pre>templates/
tasks/
handlers/
vars/
defaults/
meta/</pre>
			<p class="callout-heading">Information </p>
			<p class="callout">You can read more about<a id="_idIndexMarker778"/> roles and what each directory means on the official Ansible page at <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html">https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html</a>.</p>
			<p>In each of the directories, we can define the <code>main.yml</code> file, which contains the playbook parts that can be included in the <code>playbook.yml</code> file. Continuing the MySQL case, there is a role <a id="_idIndexMarker779"/>defined on GitHub at <a href="https://github.com/geerlingguy/ansible-role-mysql">https://github.com/geerlingguy/ansible-role-mysql</a>. This repository contains task templates that can be used in our playbook. Let's look at a part of the <code>tasks/setup-Debian.yml</code> file, which installs the <code>mysql</code> package in Ubuntu/Debian:</p>
			<pre>...
- name: Ensure MySQL Python libraries are installed.
  apt:
    name: "{{ mysql_python_package_debian }}"
    state: present
 
- name: Ensure MySQL packages are installed.
  apt:
    name: "{{ mysql_packages }}"
    state: present
  register: deb_mysql_install_packages
...</pre>
			<p>This is only one of the tasks defined in the <code>tasks/main.yml</code> file. Others tasks are responsible for the installation of MySQL into other operating systems.</p>
			<p>If we use this role in order to install MySQL on the server, it's enough to create the following <code>playbook.yml</code>:</p>
			<pre>---
- hosts: all
  become: yes
  become_method: sudo
  roles:
  - role: geerlingguy.mysql</pre>
			<p>Such a configuration installs the MySQL database on all servers using the <code>geerlingguy.mysql</code> role.</p>
			<h3>Ansible Galaxy</h3>
			<p>Ansible Galaxy is to <a id="_idIndexMarker780"/>Ansible what Docker Hub is to Docker—it stores common roles so that they can be reused by others. You can browse the available roles on the Ansible <a id="_idIndexMarker781"/>Galaxy page at <a href="https://galaxy.ansible.com/">https://galaxy.ansible.com/</a>.</p>
			<p>To install a role from Ansible Galaxy, we can use the <code>ansible-galaxy</code> command:</p>
			<pre>$ ansible-galaxy install username.role_name</pre>
			<p>This command automatically downloads the role. In the case of the MySQL example, we could download the role by executing the following:</p>
			<pre>$ ansible-galaxy install geerlingguy.mysql</pre>
			<p>The command downloads the <code>mysql</code> role, which can later be used in the playbook file. If you defined <code>playbook.yml</code> as described in the preceding snippet, the following command installs MySQL into all of your servers:</p>
			<pre>$ ansible-playbook playbook.yml</pre>
			<p>Now that you know about the basics of Ansible, let's see how we can use it to deploy our own applications.</p>
			<h1 id="_idParaDest-199"><a id="_idTextAnchor198"/>Deployment with Ansible</h1>
			<p>We have covered the most fundamental features of Ansible. Now, let's forget, just for a little while, about Docker, Kubernetes, and most of the things we've learned so far. Let's configure a complete deployment step by only using Ansible. We will run the calculator service on one server and the Hazelcast service on the second server.</p>
			<h2 id="_idParaDest-200"><a id="_idTextAnchor199"/>Installing Hazelcast</h2>
			<p>We can specify a play in the<a id="_idIndexMarker782"/> new playbook. Let's create the <code>playbook.yml</code> file, with the following content:</p>
			<pre>---
- hosts: web1
  become: yes
  become_method: sudo
  tasks:
  - name: ensure Java Runtime Environment is installed
    apt: 
      name: default-jre
      state: present
      update_cache: yes
  - name: create Hazelcast directory
    file:
      path: /var/hazelcast
      state: directory
  - name: download Hazelcast
    get_url:
      url: https://repo1.maven.org/maven2/com/hazelcast/hazelcast/5.0.2/hazelcast-5.0.2.jar
      dest: /var/hazelcast/hazelcast.jar
      mode: a+r
  - name: copy Hazelcast starting script
    copy:
      src: hazelcast.sh
      dest: /var/hazelcast/hazelcast.sh
      mode: a+x
  - name: configure Hazelcast as a service
    file:
      path: /etc/init.d/hazelcast
      state: link
      force: yes
      src: /var/hazelcast/hazelcast.sh
  - name: start Hazelcast
    service:
      name: hazelcast
      enabled: yes
      state: started</pre>
			<p>The configuration is <a id="_idIndexMarker783"/>executed on the <code>web1</code> server and it requires root permissions. It performs a few steps that will lead to a complete Hazelcast server installation. Let's walk through what we defined:</p>
			<ol>
				<li><strong class="bold">Prepare the environment</strong>: This task ensures that the Java runtime environment is installed. Basically, it prepares the server environment so that Hazelcast will have all the necessary dependencies. With more complex applications, the list of dependent tools and libraries can be way longer.</li>
				<li><strong class="bold">Download Hazelcast tool</strong>: Hazelcast is provided in the form of a JAR, which can be downloaded from the internet. We hardcoded the version, but in a real-life scenario, it would be better to extract it to a variable.</li>
				<li><code>/etc/init.d/</code> directory.</li>
				<li><strong class="bold">Start the Hazelcast service</strong>: When Hazelcast is configured as a Unix service, we can start it in the standard way.</li>
			</ol>
			<p>In the same directory, let's<a id="_idIndexMarker784"/> create <code>hazelcast.sh</code>, which is a script (shown as follows) that is responsible for running Hazelcast as a Unix service:</p>
			<pre>#!/bin/bash
### BEGIN INIT INFO
# Provides: hazelcast
# Required-Start: $remote_fs $syslog
# Required-Stop: $remote_fs $syslog
# Default-Start: 2 3 4 5
# Default-Stop: 0 1 6
# Short-Description: Hazelcast server
### END INIT INFO
java -cp /var/hazelcast/hazelcast.jar com.hazelcast.core.server.HazelcastMemberStarter &amp;</pre>
			<p>After this step, we could execute the playbook and have Hazelcast started on the <code>web1 </code>server machine. However, let's first create a second play to start the calculator service, and then run it all together.</p>
			<h2 id="_idParaDest-201"><a id="_idTextAnchor200"/>Deploying a web service</h2>
			<p>We prepare the<a id="_idIndexMarker785"/> calculator web service in two steps:</p>
			<ol>
				<li value="1">Change the Hazelcast host address.</li>
				<li>Add calculator <a id="_idIndexMarker786"/>deployment to the playbook.</li>
			</ol>
			<h3>Changing the Hazelcast host address</h3>
			<p>Previously, we <a id="_idIndexMarker787"/>hardcoded the Hazelcast host address as <code>hazelcast</code>, so now we should change it in the <code>src/main/java/com/leszko/calculator/CalculatorApplication.java</code> file to <code>192.168.64.12</code> (the same IP address we have in our inventory, as <code>web1</code>).</p>
			<p class="callout-heading">Tip </p>
			<p class="callout">In real-life projects, the application properties are usually kept in the <code>properties</code> file. For example, for the Spring Boot framework, it's a file called <code>application.properties</code> or <code>application.yml</code>. Then, we could change them with Ansible and therefore be more flexible.</p>
			<h3>Adding calculator deployment to the playbook</h3>
			<p>Finally, we <a id="_idIndexMarker788"/>can add the deployment <a id="_idIndexMarker789"/>configuration as a new play in the <code>playbook.yml</code> file. It is similar to the one we created for Hazelcast:</p>
			<pre>- hosts: web2
  become: yes
  become_method: sudo
  tasks:
  - name: ensure Java Runtime Environment is installed
    apt:
      name: default-jre
      state: present
      update_cache: yes
  - name: create directory for Calculator
    file:
      path: /var/calculator
      state: directory
  - name: copy Calculator starting script
    copy:
      src: calculator.sh
      dest: /var/calculator/calculator.sh
      mode: a+x
  - name: configure Calculator as a service
    file:
      path: /etc/init.d/calculator
      state: link
      force: yes
      src: /var/calculator/calculator.sh
  - name: copy Calculator
    copy:
      src: build/libs/calculator-0.0.1-SNAPSHOT.jar
      dest: /var/calculator/calculator.jar
      mode: a+x
    notify:
    - restart Calculator
  handlers:
  - name: restart Calculator
    service:
      name: calculator
      enabled: yes
      state: restarted</pre>
			<p>The configuration<a id="_idIndexMarker790"/> is very similar to what we saw in the <a id="_idIndexMarker791"/>case of Hazelcast. One difference is that this time, we don't download the JAR from the internet, but we copy it from our filesystem. The other difference is that we restart the service using the Ansible handler. That's because we want to restart the calculator each time a new version is copied.</p>
			<p>Before we start it all together, we also need to define <code>calculator.sh</code>:</p>
			<pre>#!/bin/bash
### BEGIN INIT INFO
# Provides: calculator
# Required-Start: $remote_fs $syslog
# Required-Stop: $remote_fs $syslog
# Default-Start: 2 3 4 5
# Default-Stop: 0 1 6
# Short-Description: Calculator application
### END INIT INFO
java -jar /var/calculator/calculator.jar &amp;</pre>
			<p>When everything is prepared, we will use this configuration to start the complete system.</p>
			<h2 id="_idParaDest-202"><a id="_idTextAnchor201"/>Running the deployment</h2>
			<p>As always, we can <a id="_idIndexMarker792"/>execute the playbook using the <code>ansible-playbook</code> command. Before that, we need to build the calculator project with Gradle:</p>
			<pre>$ ./gradlew build
$ ansible-playbook playbook.yml</pre>
			<p>After the successful deployment, the service should be available, and we can check that it's working at <code>http://192.168.64.13:8080/sum?a=1&amp;b=2</code> (the IP address should be the same one that we have in our inventory as <code>web2</code>). As expected, it should return <code>3</code> as the output.</p>
			<p>Note that we have configured the whole environment by executing one command. What's more, if we need to scale the service, then it's enough to add a new server to the inventory and rerun the <code>ansible-playbook</code> command. Also, note that we could package it as an Ansible role and upload it to GitHub, and from then on, everyone could run the same system on their Ubuntu servers. That's the power of Ansible!</p>
			<p>We have shown how to use Ansible for environmental configuration and application deployment. The next step is to use Ansible with Docker and Kubernetes.</p>
			<h1 id="_idParaDest-203"><a id="_idTextAnchor202"/>Ansible with Docker and Kubernetes</h1>
			<p>As you may have noticed, Ansible and Docker (along with Kubernetes) address similar software deployment issues:</p>
			<ul>
				<li><strong class="bold">Environmental configuration</strong>: Both Ansible and Docker provide a way to configure the<a id="_idIndexMarker793"/> environment; however, they use different means. While <a id="_idIndexMarker794"/>Ansible uses scripts (encapsulated inside the Ansible modules), Docker encapsulates the whole environment inside a container.</li>
				<li><strong class="bold">Dependencies</strong>: Ansible provides a way to deploy different services on the same or different hosts and lets them be deployed together. Kubernetes has similar functionality, which allows for running multiple containers at the same time.</li>
				<li><strong class="bold">Scalability</strong>: Ansible helps to scale the services providing the inventory and host groups. Kubernetes has similar functionality to automatically increase or decrease the number of running containers.</li>
				<li><code>playbook.yml</code>. In the<a id="_idIndexMarker795"/> case of Docker and Kubernetes, we have <code>Dockerfile</code> for the environment and <code>deployment.yml</code> for the dependencies and scaling.</li>
				<li><strong class="bold">Simplicity</strong>: Both<a id="_idIndexMarker796"/> tools are very simple to use and provide a way to set up the whole running environment with a configuration file and just one command execution.</li>
			</ul>
			<p>If we compare the tools, Docker does a little more, since it provides isolation, portability, and a kind of security. We could even imagine using Docker/Kubernetes without any other configuration management tools. Then, <em class="italic">why do we need Ansible at all?</em></p>
			<h2 id="_idParaDest-204"><a id="_idTextAnchor203"/>Benefits of Ansible</h2>
			<p>Ansible may seem redundant; however, it brings additional benefits to the delivery process, which are as<a id="_idIndexMarker797"/> follows:</p>
			<ul>
				<li><strong class="bold">Docker environment</strong>: The Docker/Kubernetes hosts themselves have to be configured and managed. Every container is ultimately running on Linux machines, which need kernel patching, Docker Engine updates, and network configuration, for example. What's more, there may be different server machines with different Linux distributions, and the responsibility of Ansible is to make sure everything is up and running.</li>
				<li><strong class="bold">Non-Dockerized applications</strong>: Not everything is run inside a container. If part of the infrastructure is containerized and part is deployed in the standard way or in the cloud, then Ansible can manage it all with the playbook configuration file. There may be different reasons for not running an application as a container; for example, performance, security, specific hardware requirements, or working with the legacy software.</li>
				<li><strong class="bold">Inventory</strong>: Ansible offers a very friendly way to manage the physical infrastructure by using inventories, which store information about all the servers. It can also split the physical infrastructure into different environments—production, testing, and development.</li>
				<li><strong class="bold">Cloud provisioning</strong>: Ansible can be responsible for provisioning Kubernetes clusters or installing Kubernetes in the cloud; for example, we can imagine integration tests in which the first step is to create a Kubernetes cluster on <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) (only then can we deploy the whole application and perform the testing process).</li>
				<li><strong class="bold">GUI</strong>: Ansible offers <a id="_idIndexMarker798"/>GUI managers (commercial Ansible Tower and open source AWX), which aim to improve the experience of infrastructure management.</li>
				<li><strong class="bold">Improving the testing process</strong>: Ansible can help with integration and acceptance testing, as it can encapsulate testing scripts.</li>
			</ul>
			<p>We can look at Ansible as the tool that takes care of the infrastructure, while Docker and Kubernetes are tools that take care of the environmental configuration and clustering. An overview is presented in the following diagram:</p>
			<div><div><img src="img/B18223_07_02.jpg" alt="Figure 7.2 – Ansible as the infrastructure manager&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.2 – Ansible as the infrastructure manager</p>
			<p>Ansible manages the<a id="_idIndexMarker799"/> infrastructure: <strong class="bold">Kubernetes clusters</strong>, <strong class="bold">Docker servers</strong>, <strong class="bold">Docker registries</strong>, <strong class="bold">servers without Docker</strong>, and <strong class="bold">cloud providers</strong>. It also takes care of the physical location of the servers. Using the inventory host groups, it can link the web services to the databases that are close to their geographic locations.</p>
			<p>Let's look at how we can use Ansible to install Docker on a server and deploy a sample application.</p>
			<h2 id="_idParaDest-205"><a id="_idTextAnchor204"/>The Ansible Docker playbook</h2>
			<p>Ansible integrates with<a id="_idIndexMarker800"/> Docker smoothly, because it provides a set of Docker-dedicated modules. If we create an Ansible playbook for Docker-based deployment, then the first task is to make sure that the Docker Engine is installed on every machine. Then, it should run a container using Docker.</p>
			<p>First, let's install Docker on an Ubuntu server.</p>
			<h3>Installing Docker</h3>
			<p>We can install the <a id="_idIndexMarker801"/>Docker Engine by using the following task in the Ansible playbook:</p>
			<pre>- hosts: web1
  become: yes
  become_method: sudo
  tasks:
  - name: Install required packages
    apt:
      name: "{{ item }}"
      state: latest
      update_cache: yes
    loop:
    - apt-transport-https
    - ca-certificates
    - curl
    - software-properties-common
    - python3-pip
    - virtualenv
    - python3-setuptools
  - name: Add Docker GPG apt Key
    apt_key:
      url: https://download.docker.com/linux/ubuntu/gpg
      state: present
  - name: Add Docker Repository
    apt_repository:
      repo: deb https://download.docker.com/linux/ubuntu focal stable
      state: present
  - name: Update apt and install docker-ce
    apt:
      name: docker-ce
      state: latest
      update_cache: yes
  - name: Install Docker Module for Python
    pip:
      name: docker</pre>
			<p class="callout-heading">Information </p>
			<p class="callout">The playbook looks slightly different for each operating system. The one presented here is for Ubuntu 20.04.</p>
			<p>This configuration<a id="_idIndexMarker802"/> installs Docker and Docker Python tools (needed by Ansible). Note that we used a new Ansible syntax, <code>loop</code>, in order to make the playbook more concise.</p>
			<p>When Docker is installed, we can add a task that will run a Docker container.</p>
			<h3>Running Docker containers</h3>
			<p>Running <a id="_idIndexMarker803"/>Docker containers is done with the use of the <code>docker_container</code> module, and it looks as follows:</p>
			<pre>- hosts: web1
  become: yes
  become_method: sudo
  tasks:
  - name: run Hazelcast container
    community.docker.docker_container:
      name: hazelcast
      image: hazelcast/hazelcast
      state: started
      exposed_ports:
      - 5701</pre>
			<p class="callout-heading">Information </p>
			<p class="callout">You can read more about all of the <a id="_idIndexMarker804"/>options of the <code>docker_container</code> module at <a href="https://docs.ansible.com/ansible/latest/collections/community/docker/docker_container_module.html">https://docs.ansible.com/ansible/latest/collections/community/docker/docker_container_module.html</a>.</p>
			<p>With the two <a id="_idIndexMarker805"/>playbooks presented previously, we configured the Hazelcast server using Docker. Note that this is very convenient because we can run the same playbook on multiple (Ubuntu) servers.</p>
			<p>Now, let's take a look at how Ansible can help with Kubernetes.</p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor205"/>The Ansible Kubernetes playbook</h2>
			<p>Similar to Docker, Ansible can<a id="_idIndexMarker806"/> help with Kubernetes. When you have your Kubernetes cluster configured, then you can create Kubernetes resources using the Ansible <code>k8s</code> module. Here's a sample Ansible task to create a namespace in Kubernetes:</p>
			<pre>- name: Create namespace
  kubernetes.core.k8s:
    name: my-namespace
    api_version: v1
    kind: Namespace
    state: present</pre>
			<p>The configuration here <a id="_idIndexMarker807"/>makes sure a namespace called <code>my-namespace</code> is created in the Kubernetes cluster.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">You can find more information about the <a id="_idIndexMarker808"/>Ansible <code>k8s</code> module at <a href="https://docs.ansible.com/ansible/latest/collections/kubernetes/core/k8s_module.html">https://docs.ansible.com/ansible/latest/collections/kubernetes/core/k8s_module.html</a>.</p>
			<p>We have covered configuration management with Ansible, which is a perfect approach if your deployment environment consists of bare-metal servers. You can also use Ansible with cloud providers, and there are a number of modules dedicated to that purpose. For example, <code>amazon.aws.ec2_instance</code> lets you create and manage AWS EC2 instances. However, when it comes to the cloud, there are better solutions. Let's see what they are and how to use them.</p>
			<h1 id="_idParaDest-207"><a id="_idTextAnchor206"/>Introducing IaC</h1>
			<p>IaC is the process <a id="_idIndexMarker809"/>of managing and provisioning computing resources instead of physical hardware configuration. It is mostly associated with the cloud approach, in which you can request the necessary infrastructure in a programmable manner.</p>
			<p>Managing computer infrastructure was always a hard, time-consuming, and error-prone activity. You had to manually place the hardware, connect the network, install the operating system, and take care of its updates. Together with the cloud, things became simple; all you had to do was to write a few commands or make a few clicks in the web UI. IaC goes one step further, as it allows you to specify in a declarative manner what infrastructure you need. To understand it better, let's take a look at the following diagram:</p>
			<div><div><img src="img/B18223_07_03.jpg" alt="Figure 7.3 – IaC&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.3 – IaC</p>
			<p>You prepare a<a id="_idIndexMarker810"/> declarative description of your infrastructure, for example, that you need three servers, a Kubernetes cluster, and a load balancer. Then, you pass this configuration to a tool that uses a cloud-specific API (for example, the AWS API) in order to make sure the infrastructure is as requested. Note that you should store the infrastructure configuration in the source code repository, and you can create multiple identical environments from the same configuration.</p>
			<p>You can see that the IaC idea is very similar to configuration management; however, while configuration management makes sure your software is configured as specified, IaC makes sure that your infrastructure is configured as specified.</p>
			<p>Now, let's look into the benefits of using IaC.</p>
			<h2 id="_idParaDest-208"><a id="_idTextAnchor207"/>Benefits of IaC</h2>
			<p>There are a number of <a id="_idIndexMarker811"/>benefits that infrastructure brings into all DevOps activities. Let's walk through the most important ones:</p>
			<ul>
				<li><strong class="bold">Speed</strong>: Creating the whole infrastructure means nothing more than running a script, which significantly reduces the time needed before we can start deploying the applications.</li>
				<li><strong class="bold">Cost reduction</strong>: Automating the infrastructure provisioning reduces the number of DevOps team members required to operate server environments.</li>
				<li><strong class="bold">Consistency</strong>: IaC configuration files become the single point of truth, so they guarantee that every created environment is exactly the same.</li>
				<li><strong class="bold">Risk reduction</strong>: Infrastructure configuration is stored in the source code repository and follows the standard code review process, which reduces the probability of making a mistake.</li>
				<li><strong class="bold">Collaboration</strong>: Multiple<a id="_idIndexMarker812"/> people can share the code and work on the same configuration files, which increases work efficiency.</li>
			</ul>
			<p>I hope these points have convinced you that IaC is a great approach. Let's now look into the tools you can use for IaC. </p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor208"/>Tools for IaC</h2>
			<p>When it comes to IaC, there <a id="_idIndexMarker813"/>are a number of tools you can use. The choice depends on the cloud provider you use and on your own preferences. Let's walk through the most popular solutions:</p>
			<ul>
				<li><strong class="bold">Terraform</strong>: The most popular IaC tool on the market. It's open source and uses plugin-based modules<a id="_idIndexMarker814"/> called <em class="italic">providers</em> to support different infrastructure APIs. Currently, more than 1,000 Terraform<a id="_idIndexMarker815"/> providers exist, including AWS, Azure, GCP, and DigitalOcean.</li>
				<li><strong class="bold">Cloud provider specific</strong>: Each major <a id="_idIndexMarker816"/>cloud provider has its own IaC tool:<ul><li><strong class="bold">AWS CloudFormation</strong>: An <a id="_idIndexMarker817"/>Amazon service that allows you to specify AWS resources in the form <a id="_idIndexMarker818"/>of YAML or JSON template files</li><li><strong class="bold">Azure Resource Manager</strong> (<strong class="bold">ARM</strong>): A Microsoft Azure service that allows you to create and manage <a id="_idIndexMarker819"/>Azure resources <a id="_idIndexMarker820"/>with the use of ARM template files</li><li><strong class="bold">Google Cloud Deployment Manager</strong>: A Google service that allows you to manage Google Cloud <a id="_idIndexMarker821"/>Platform <a id="_idIndexMarker822"/>resources with the use of YAML files</li></ul></li>
				<li><strong class="bold">General configuration management</strong>: Ansible, Chef, and Puppet all provide dedicated modules to provision the <a id="_idIndexMarker823"/>infrastructure in the most popular cloud solutions.</li>
				<li><strong class="bold">Pulumi</strong>: A very flexible<a id="_idIndexMarker824"/> tool that allows you to specify the desired infrastructure<a id="_idIndexMarker825"/> using general-purpose programming languages, such as JavaScript, Python, Go, or C#.</li>
				<li><strong class="bold">Vagrant</strong>: Usually <a id="_idIndexMarker826"/>associated with virtual machine <a id="_idIndexMarker827"/>management, it provides a number of plugins to <a id="_idIndexMarker828"/>provision infrastructure using AWS and other cloud providers.</li>
			</ul>
			<p>Of all the solutions mentioned, Terraform is by far the most popular. That is why we'll spend some more time understanding how it works.</p>
			<h1 id="_idParaDest-210"><a id="_idTextAnchor209"/>Introduction to Terraform</h1>
			<p>Terraform is an<a id="_idIndexMarker829"/> open source tool created and maintained by HashiCorp. It allows you to specify your infrastructure in the form of human-readable configuration files. Similar to Ansible, it works in a declarative manner, which means that you specify the expected outcome, and Terraform makes sure your environment is created as specified.</p>
			<p>Before we dive into a concrete example, let's spend a moment understanding how Terraform works.</p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor210"/>Understanding Terraform</h2>
			<p>Terraform<a id="_idIndexMarker830"/> reads a configuration file and adjusts the cloud resources accordingly. Let's look at the following diagram, which presents this process:</p>
			<div><div><img src="img/B18223_07_04.jpg" alt="Figure 7.4 – Terraform workflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.4 – Terraform workflow</p>
			<p>A user creates <strong class="bold">Configuration File</strong> and starts the <strong class="bold">Terraform</strong> tool. Then, <strong class="bold">Terraform</strong> checks the <strong class="bold">Terraform State</strong> and uses <strong class="bold">Terraform Provider</strong> to translate the declarative configuration file into the requests called against <strong class="bold">Target API</strong>, which is specific for the given cloud provider. As an example, we can think of a configuration file that defines three AWS EC2 instances. Terraform uses the AWS provider, which executes requests to the AWS API to make sure that <a id="_idIndexMarker831"/>three AWS EC2 instances are created.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">There are more than 1,000 Terraform providers available, and you can browse them via the Terraform Registry<a id="_idIndexMarker832"/> at <a href="https://registry.terraform.io/">https://registry.terraform.io/</a>.</p>
			<p>The Terraform workflow always consists of three stages:</p>
			<ul>
				<li><strong class="bold">Write</strong>: User defines <a id="_idIndexMarker833"/>cloud resources as a configuration file.</li>
				<li><strong class="bold">Plan</strong>: Terraform <a id="_idIndexMarker834"/>compares the configuration file with the current state and prepares the execution plan.</li>
				<li><strong class="bold">Apply</strong>: User <a id="_idIndexMarker835"/>approves the plan and Terraform executes the planned operations using the cloud API.</li>
			</ul>
			<p>This approach is very convenient because, with the plan stage, we can always check what Terraform is going to change in our infrastructure, before actually applying the change.</p>
			<p>Now that we understand the idea behind Terraform, let's look at how it all works in practice, starting from the Terraform installation process.</p>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor211"/>Installing Terraform</h2>
			<p>The installation process<a id="_idIndexMarker836"/> depends on the operating system. In the case of Ubuntu, you can execute the following commands:</p>
			<pre>$ curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -
$ sudo apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
$ sudo apt-get update
$ sudo apt-get install terraform</pre>
			<p class="callout-heading">Information </p>
			<p class="callout">You can find the installation guides for all the operating systems on the official Terraform website, at <a href="https://www.terraform.io/downloads">https://www.terraform.io/downloads</a>.</p>
			<p>After the installation process, we can verify that the <code>terraform</code> command works correctly:</p>
			<pre>$ terraform version
Terraform v1.1.5</pre>
			<p>After Terraform is configured, we can move to the Terraform example.</p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor212"/>Using Terraform</h2>
			<p>As an example, let's <a id="_idIndexMarker837"/>use Terraform to provision an AWS EC2 instance. For this purpose, we need to first configure AWS.</p>
			<h3>Configuring AWS</h3>
			<p>To access AWS from <a id="_idIndexMarker838"/>your machine, you will need the following:</p>
			<ul>
				<li>An AWS account</li>
				<li>The AWS CLI installed<p class="callout-heading">Information </p><p class="callout">You can create a free AWS account<a id="_idIndexMarker839"/> at <a href="https://aws.amazon.com/free">https://aws.amazon.com/free</a>. To install the AWS CLI tool<a id="_idIndexMarker840"/>, please check the following instructions: <a href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html">https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html</a>.</p></li>
			</ul>
			<p>Let's configure the AWS CLI with the following command:</p>
			<pre>$ aws configure</pre>
			<p>The AWS command prompts your AWS access key ID and AWS secret access key.</p>
			<p class="callout-heading">Information </p>
			<p class="callout">For instructions on how to create an AWS access key pair, please visit <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html#cli-configure-quickstart-creds">https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html#cli-configure-quickstart-creds</a>.</p>
			<p>After these steps, access to your AWS account is configured and we can start playing with Terraform.</p>
			<h3>Writing Terraform configuration</h3>
			<p>In a fresh <a id="_idIndexMarker841"/>directory, let's create the <code>main.tf</code> file and add the following content:</p>
			<pre>terraform {
  required_version = "&gt;= 1.1"                 (1)
  required_providers {
    aws = {                                   (2)
      source  = "hashicorp/aws"
      version = "~&gt; 3.74"
    }
  }
}
provider "aws" {
  profile = "default"                         (3)
  region  = "us-east-1"                       (4)
}
resource "aws_instance" "my_instance" {       (5)
  ami           = "ami-04505e74c0741db8d"     (6)
  instance_type = "t2.micro"                  (7)
}</pre>
			<p>In the preceding configuration, we defined the following parts:</p>
			<ol>
				<li value="1">The Terraform <a id="_idIndexMarker842"/>tool version should be at least <code>1.1</code>.</li>
				<li>The configuration uses the <code>hashicorp/aws</code> provider:<ul><li>The provider version needs to be at least <code>3.74</code>.</li><li>Terraform will automatically download it from the <strong class="bold">Terraform Registry</strong>.</li></ul></li>
				<li>The credentials for the <code>aws</code> provider are stored in the <code>default</code> location created by the AWS CLI.</li>
				<li>The provider creates all resources in the <code>us-east-1</code> region.</li>
				<li>The provider creates <code>aws_instance</code> (an AWS EC2 instance) named <code>my_instance</code>.</li>
				<li>An EC2 instance is created from <code>ami-04505e74c0741db8d</code> (Ubuntu 20.04 LTS in the <code>us-east-1</code> region).</li>
				<li>The instance <a id="_idIndexMarker843"/>type is <code>t2.micro</code>.</li>
			</ol>
			<p>You can see that the whole configuration is declarative. In other words, we define what we want, not the algorithm for how to achieve it.</p>
			<p>When the configuration is created, we need to download the required provider from the Terraform Registry.</p>
			<h3>Initializing Terraform configuration</h3>
			<p>Let's execute the <a id="_idIndexMarker844"/>following command:</p>
			<pre>$ terraform init</pre>
			<p>This command downloads all required providers and stores them in the <code>.terraform</code> directory. Now, let's finally apply the Terraform configuration.</p>
			<h3>Applying Terraform configuration</h3>
			<p>Before we make any <a id="_idIndexMarker845"/>Terraform changes, it's good to first execute <code>terraform plan</code> to check what changes stand ahead of us:</p>
			<pre>$ terraform plan
Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create
...</pre>
			<p>We can see that by applying the configuration, we will create a resource in our infrastructure as described in the console output.</p>
			<p>Let's now apply our configuration:</p>
			<pre>$ terraform apply
...
Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.
  Enter a value: yes
...
Apply complete! Resources: 1 added, 0 changed, 0 destroyed.</pre>
			<p>After confirming the <a id="_idIndexMarker846"/>change, you should see a lot of logs and the last <code>Apply complete!</code> message, which means that our infrastructure is created.</p>
			<p>Now, let's verify that everything is as expected.</p>
			<h3>Verifying the infrastructure</h3>
			<p>From the Terraform<a id="_idIndexMarker847"/> perspective, we can execute the following command to see the state of our infrastructure:</p>
			<pre>$ terraform show
# aws_instance.my_instance:
resource "aws_instance" "my_instance" {
...
}</pre>
			<p>This prints all the information about the resource we created.</p>
			<p class="callout-heading">Information</p>
			<p class="callout">Terraform, the same as Ansible, favors idempotent operations. That is why, if we execute <code>terraform plan</code> or <code>terraform apply</code> again, nothing will change. You will only see the following message: <code>No changes. Your infrastructure matches the configuration</code>.</p>
			<p>We can now verify that our <a id="_idIndexMarker848"/>AWS EC2 instance is really created. Since we already installed the AWS CLI, we can check it with the following command:</p>
			<pre>$ aws ec2 describe-instances --region us-east-1
{
    "Reservations": [
        {
            "Groups": [],
            "Instances": [
                {
                    "AmiLaunchIndex": 0,
                    "ImageId": "ami-04505e74c0741db8d",
                    "InstanceId": "i-053b633c810728a97",
                    "InstanceType": "t2.micro",
...</pre>
			<p>If you prefer, you can also check in the AWS web console that the instance is created.</p>
			<div><div><img src="img/B18223_07_05.jpg" alt="Figure 7.5 – AWS EC2 instance created with Terraform&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.5 – AWS EC2 instance created with Terraform</p>
			<p>We just verified that our <a id="_idIndexMarker849"/>Terraform configuration works as expected.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">When working together with Ansible, we can make use of Ansible's dynamic inventories and let Ansible discover created EC2 instances. Read more at <a href="https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html">https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html</a>.</p>
			<p>To make our example complete, let's also see how to delete created resources.</p>
			<h3>Destroying the infrastructure</h3>
			<p>Let's remove the <a id="_idIndexMarker850"/>resources we created with the following command:</p>
			<pre>$ terraform destroy
aws_instance.my_instance: Refreshing state... [id=i-053b633c810728a97]
Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  - destroy
...
Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.
  Enter a value: yes
...
Destroy complete! Resources: 1 destroyed.</pre>
			<p>After the user <a id="_idIndexMarker851"/>confirmation, Terraform removed all the resources. You can check that our AWS EC2 instance does not exist anymore.</p>
			<p>As the last thing with Terraform, let's see how it interacts with Kubernetes.</p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor213"/>Terraform and Kubernetes</h2>
			<p>There are two different use <a id="_idIndexMarker852"/>cases when it comes to the interaction between Terraform and Kubernetes:</p>
			<ul>
				<li>Provisioning a Kubernetes cluster</li>
				<li>Interacting with a Kubernetes cluster</li>
			</ul>
			<p>Let's present them one by one.</p>
			<h3>Provisioning a Kubernetes cluster</h3>
			<p>Each of the major cloud providers<a id="_idIndexMarker853"/> offers managed Kubernetes clusters, and we can provision them using Terraform. The following Terraform providers are available:</p>
			<ul>
				<li><strong class="bold">AWS</strong>: This can<a id="_idIndexMarker854"/> provision<a id="_idIndexMarker855"/> clusters in Amazon<strong class="bold"> Elastic Kubernetes Service</strong> (<strong class="bold">EKS</strong>).</li>
				<li><strong class="bold">Google</strong>: This <a id="_idIndexMarker856"/>can provision clusters<a id="_idIndexMarker857"/> in <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>).</li>
				<li><strong class="bold">AzureRM</strong>: This can<a id="_idIndexMarker858"/> provision clusters <a id="_idIndexMarker859"/>in <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>).</li>
			</ul>
			<p>Using each of these providers is relatively simple and works similarly to how we described in our<a id="_idIndexMarker860"/> Terraform example.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">If you install Kubernetes on bare-metal servers, you should use a configuration management tool, such as Ansible. To provision a cloud-managed Kubernetes cluster, you can use either Ansible or Terraform, but the former is a better fit.</p>
			<p>Let's also look at the second usage of Terraform with Kubernetes.</p>
			<h3>Interacting with a Kubernetes cluster</h3>
			<p>Similar to Ansible, we can <a id="_idIndexMarker861"/>use Terraform to interact with a Kubernetes cluster. In other words, instead of applying Kubernetes configurations using the <code>kubectl</code> command, we can use a dedicated Terraform Kubernetes provider.</p>
			<p>A sample Terraform configuration to change Kubernetes resources looks as follows:</p>
			<pre>resource "kubernetes_namespace" "example" {
  metadata {
    name = "my-first-namespace"
  }
}</pre>
			<p>The preceding configuration creates a namespace called <code>my-namespace</code> in the Kubernetes cluster.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">There are multiple ways you can interact with a Kubernetes cluster: <code>kubectl</code>, Ansible, Terraform, or some other tool. As a rule of thumb, I would always first try the simplest approach, which is the <code>kubectl</code> command, and only incorporate Ansible or Terraform if you have some special requirements; for example, you manage multiple Kubernetes clusters at the same time.</p>
			<p>We covered the basics of Terraform, so let's wrap up this chapter with a short summary.</p>
			<h1 id="_idParaDest-215"><a id="_idTextAnchor214"/>Summary</h1>
			<p>We have covered configuration management and IaC approaches, together with the related tooling. Note that whether you should use Ansible, Terraform, or neither of them inside your continuous delivery pipeline highly depends on your particular use case.</p>
			<p>Ansible shines when you have multiple bare-metal servers to manage, so if your release means making the same change into many servers at the same time, you'll most probably place Ansible commands inside your pipeline.</p>
			<p>Terraform works best when you use the cloud. Therefore, if your release means making a change to your cloud infrastructure, then Terraform is the way to go.</p>
			<p>However, if your environment is only a single Kubernetes cluster, then there is nothing wrong with executing <code>kubectl</code> commands inside your pipeline.</p>
			<p>The other takeaway points from this chapter are as follows:</p>
			<ul>
				<li>Configuration management is the process of creating and applying the configurations of the application.</li>
				<li>Ansible is one of the most trending configuration management tools. It is agentless, and therefore, it requires no special server configuration.</li>
				<li>Ansible can be used with ad hoc commands, but the real power lies in Ansible playbooks.</li>
				<li>The Ansible playbook is a definition of how the environment should be configured.</li>
				<li>The purpose of Ansible roles is to reuse parts of playbooks.</li>
				<li>Ansible Galaxy is an online service to share Ansible roles.</li>
				<li>IaC is a process of managing cloud resources.</li>
				<li>Terraform is the most popular tool for IaC.</li>
			</ul>
			<p>In the next chapter, we will wrap up the continuous delivery process and complete the final Jenkins pipeline.</p>
			<h1 id="_idParaDest-216"><a id="_idTextAnchor215"/>Exercises</h1>
			<p>In this chapter, we covered the fundamentals of Ansible and ways to use it with Docker and Kubernetes. As exercises, try the following tasks:</p>
			<ol>
				<li value="1">Create the server infrastructure and use Ansible to manage it:<ol><li>Connect a physical machine or run a VirtualBox machine to emulate the remote server.</li><li>Configure SSH access to the remote machine (SSH keys).</li><li>Install Python on the remote machine.</li><li>Create an Ansible inventory with the remote machine.</li><li>Run the Ansible ad hoc command (with the <code>ping</code> module) to check that the infrastructure is configured correctly.</li></ol></li>
				<li>Create a Python-based <code>hello world</code> web service and deploy it in a remote machine using Ansible playbook:<ol><li>The service can look exactly the same as we described in the exercises for the chapter.</li><li>Create a playbook that deploys the service into the remote machine.</li><li>Run the <code>ansible-playbook</code> command and check whether the service was deployed.</li></ol></li>
				<li>Provision a GCP virtual machine instance using Terraform:<ol><li>Create an account in GCP.</li><li>Install the <code>gcloud</code> tool and authenticate (<code>gcloud init</code>).</li><li>Generate credentials and export them into the <code>GOOGLE_APPLICATION_CREDENTIALS</code> environment variable.</li><li>Create a Terraform configuration that provisions a virtual machine instance.</li><li>Apply the configuration using Terraform.</li><li>Verify that the instance was created.</li></ol></li>
			</ol>
			<h1 id="_idParaDest-217"><a id="_idTextAnchor216"/>Questions</h1>
			<p>To verify your knowledge from this chapter, please answer the following questions:</p>
			<ol>
				<li value="1">What is configuration management?</li>
				<li>What does it mean that the configuration management tool is agentless?</li>
				<li>What are the three most popular configuration management tools?</li>
				<li>What is Ansible inventory?</li>
				<li>What is the difference between Ansible ad hoc commands and playbooks?</li>
				<li>What is an Ansible role?</li>
				<li>What is Ansible Galaxy?</li>
				<li>What is IaC?</li>
				<li>What are the most popular tools for IaC?</li>
			</ol>
			<h1 id="_idParaDest-218"><a id="_idTextAnchor217"/>Further reading</h1>
			<p>To read more about configuration management and IaC, please refer to the following resources:</p>
			<ul>
				<li><strong class="bold">Official Ansible documentation</strong>: <a href="https://docs.ansible.com/">https://docs.ansible.com/</a></li>
				<li><strong class="bold">Official Terraform documentation</strong>: <a href="https://www.terraform.io/docs">https://www.terraform.io/docs</a></li>
				<li><strong class="bold">Michael T. Nygard, Release It!</strong>: (<a href="https://pragprog.com/titles/mnee2/release-it-second-edition/">https://pragprog.com/titles/mnee2/release-it-second-edition/</a>)</li>
				<li><strong class="bold">Russ McKendrick, Learn Ansible</strong>: (<a href="https://www.packtpub.com/virtualization-and-cloud/learn-ansible">https://www.packtpub.com/virtualization-and-cloud/learn-ansible</a>)</li>
			</ul>
		</div>
	</body></html>