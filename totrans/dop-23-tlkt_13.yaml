- en: Managing Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Without an indication how much CPU and memory a container needs, Kubernetes
    has no other option than to treat all containers equally. That often produces
    a very uneven distribution of resource usage. Asking Kubernetes to schedule containers
    without resource specifications is like entering a taxi driven by a blind person.
  prefs: []
  type: TYPE_NORMAL
- en: We have come a long way, from humble beginnings, towards understanding many
    of the essential Kubernetes object types and principles. One of the most important
    things we're missing is resource management. Kubernetes was blindly scheduling
    the applications we deployed so far. We never gave it any indication how much
    resources we expect those applications to use, nor established any limits. Without
    them, Kubernetes was carrying out its tasks in a very myopic fashion. Kubernetes
    could see a lot, but not enough. We'll change that soon. We'll give Kubernetes
    a pair of glasses that will provide it a much better vision.
  prefs: []
  type: TYPE_NORMAL
- en: Once we learn how to define resources, we'll go further and make sure that certain
    limitations are set, that some defaults are determined, and that there are quotas
    that will prevent applications from overloading the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is the last piece of the puzzle. Once we solve it, we'll be ready
    to start thinking about using Kubernetes in production. You won't know everything
    you should know about operating Kubernetes. No one does. But, you will know just
    enough to get you going in the right direction.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll go through almost the same routine as we did in the previous chapters.
    We'll enter the directory where we cloned the `vfarcic/k8s-specs` repository,
    pull the latest code, start a Minikube cluster, and so on and so forth. The only
    new thing we'll do this time is to enable one more addon. We'll add Heapster to
    the cluster. It's too soon to explain what it does and why we'll need it. That
    will come later. For now, just remember that there will soon be something in your
    cluster called Heapster. If you do not already know what it is, consider this
    a teaser meant to build suspense.
  prefs: []
  type: TYPE_NORMAL
- en: All the commands from this chapter are available in the [`13-resource.sh`](https://gist.github.com/cc8c44e1e84446dccde3d377c131a5cd)
    ([https://gist.github.com/vfarcic/cc8c44e1e84446dccde3d377c131a5cd](https://gist.github.com/vfarcic/cc8c44e1e84446dccde3d377c131a5cd))
    Gist.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now that the latest code is pulled, the cluster is running, and the add-ons
    are enabled, we can proceed and explore how to define container memory and CPU
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: Defining container memory and CPU resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we did not specify how much memory and CPU containers should use, nor
    what their limits should be. If we do that, Kubernetes' scheduler will have a
    much better idea about the needs of those containers, and it'll make much better
    decisions on which nodes to place the Pods and what to do if they start "misbehaving".
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at a modified `go-demo-2` definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The specification is almost the same as those we used before. The only new entries
    are in the `resources` section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We specified `limits` and `requests` entries in the `resources` section.
  prefs: []
  type: TYPE_NORMAL
- en: CPU resources are measured in `cpu` units. The exact meaning of a `cpu` unit
    depends on where we host our cluster. If servers are virtualized, one `cpu` unit
    is equivalent to one **virtualized processor** (**vCPU**). When running on bare-metal
    with Hyperthreading, one `cpu` equals one Hyperthread. For the sake of simplification,
    we'll assume that one `cpu` resource is one CPU processor (even though that is
    not entirely true).
  prefs: []
  type: TYPE_NORMAL
- en: If one container is set to use `two` CPU, and the other is set to `one` CPU,
    the later is guaranteed half as much processing power.
  prefs: []
  type: TYPE_NORMAL
- en: CPU values can be fractioned. In our example, the `db` container has the CPU
    requests set to `0.5` which is equivalent to half CPU. The same value could be
    expressed as `500m`, which translates to five hundred millicpu. If you take another
    look at the CPU specs of the `api` container, you'll see that its CPU limit is
    set to `400m` and the requests to `200m`. They are equivalent to `0.4` and `0.2`
    CPUs.
  prefs: []
  type: TYPE_NORMAL
- en: Memory resources follow a similar pattern as CPU. The significant difference
    is in the units. Memory can be expressed as **K** (**kilobyte**), **M** (**Megabyte**),
    **G** (**Gigabyte**), **T** (**Terabyte**), **P** (**Petabyte**), and **E** (**Exabyte**).
    We can also use the power-of-two equivalents `Ki`, `Mi`, `Gi`, `Ti`, `Pi`, and
    `Ei`.
  prefs: []
  type: TYPE_NORMAL
- en: If we go back to the `go-demo-2-random.yml` definition, we'll see that the `db`
    container has the limit set to **200Mi** (**two hundred megabytes**) and the requests
    to **100Mi** (**one hundred megabytes**).
  prefs: []
  type: TYPE_NORMAL
- en: We have already mentioned `limits` and `requests` quite a few times and yet
    we have not explained what each of them mean.
  prefs: []
  type: TYPE_NORMAL
- en: A limit represents the amount of resources that a container should not pass.
    The assumption is that we define limits as upper boundaries which, when reached,
    indicate that something went wrong, as well as a way to guard our resources from
    being overtaken by a single rouge container due to memory leaks or similar problems.
  prefs: []
  type: TYPE_NORMAL
- en: If a container is restartable, Kubernetes will restart a container that exceeds
    its memory limit. Otherwise, it might terminate it. Bear in mind that a terminated
    container will be recreated if it belongs to a Pod (as all Kubernetes-controlled
    containers do).
  prefs: []
  type: TYPE_NORMAL
- en: Unlike memory, CPU limits never result in termination or restarts. Instead,
    a container will not be allowed to consume more than the CPU limit for an extended
    period.
  prefs: []
  type: TYPE_NORMAL
- en: Requests represent the expected resource utilization. They are used by Kubernetes
    to decide where to place Pods depending on actual resource utilization of the
    nodes that form the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: If a container exceeds its memory requests, the Pod it resides in might be evicted
    if a node runs out of memory. Such eviction usually results in the Pod being scheduled
    on a different node, as long as there is one with enough available memory. If
    a Pod cannot be scheduled to any of the nodes due to lack of available resources,
    it enters the pending state waiting until resources on one of the nodes are freed,
    or a new node is added to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Simply discussing the theory of `resources` might be confusing if not followed
    by practical examples. Therefore, we''ll move on and create the resources defined
    in the `go-demo-2-random.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We created the resources and waited until the `go-demo-2-api` Deployment was
    rolled out. The output of the later command should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s describe the `go-demo-2-api` Deployment and see its `limits` and `requests`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the `limits` and the `requests`, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the `limits` and the `requests` correspond to those we defined
    in the `go-demo-2-random.yml` file. That should come as no surprise.
  prefs: []
  type: TYPE_NORMAL
- en: Let's describe the nodes that form the cluster (even though there's only one).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the resource-related entries, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `Capacity` represents the overall capacity of a node. In our case, the `minikube`
    node has 2 CPUs, 2GB of RAM, and can run up to one hundred and ten Pods. Those
    are the upper limits imposed by the hardware or, in our case, the size of the
    VM created by Minikube.
  prefs: []
  type: TYPE_NORMAL
- en: Further down is the `Non-terminated Pods` section. It lists all the Pods with
    the CPU and memory limits and requests. We can, for example, see that the `go-demo-2-db`
    Pod has the memory limit set to `100Mi`, which is `5%` of the capacity. Similarly,
    we can see that not all Pods have specified resources. For example, the `heapster-snq2f`
    Pod has all the values set to `0`. Kubernetes will not be able to handle those
    Pods appropriately. However, since this is a demo cluster, we'll give the Minikube
    authors a pass and ignore the lack of resource specification.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `Allocated resources` section provides summed values from all the
    Pods. We can, for example, see that the CPU limits are `55%`. Limits can be even
    higher than `100%`, and that would not necessarily be a thing to worry about.
    Not all the containers will have memory and CPU bursts over the requested values.
    Even if that happens, Kubernetes will know what to do.
  prefs: []
  type: TYPE_NORMAL
- en: What truly matters is that the total amount of requested memory and CPU is within
    the limits of the capacity. That, however, leads us to an interesting question.
    What is the basis for the resources we defined so far?
  prefs: []
  type: TYPE_NORMAL
- en: Measuring actual memory and CPU consumption
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How did we come up with the current memory and CPU values? Why did we set the
    memory of the MongoDB to `100Mi`? Why not `50Mi` or `1Gi`? It is embarrassing
    to admit that the values we have right now are random. I guessed that the containers
    based on the `vfarcic/go-demo-2` image require less resources than Mongo database,
    so their values are comparatively smaller. That was the only criteria I used to
    define the resources.
  prefs: []
  type: TYPE_NORMAL
- en: Before you frown upon my decision to put random values for resources, you should
    know that we do not have any metrics to back us up. Anybody's guess is as good
    as mine.
  prefs: []
  type: TYPE_NORMAL
- en: The only way to truly know how much memory and CPU an application uses is by
    retrieving metrics. We'll use Heapster ([https://github.com/kubernetes/heapster](https://github.com/kubernetes/heapster))
    for that purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Heapster collects and interprets various signals like compute resource usage,
    lifecycle events, and so on. In our case, we're interested only in CPU and memory
    consumption of the containers we're running in our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: When we created the cluster, we enabled the `heapster` addon and Minikube deployed
    it as a system application. Not only that, but it also deployed InfluxDB ([https://github.com/influxdata/influxdb](https://github.com/influxdata/influxdb))
    and Grafana ([https://grafana.com/](https://grafana.com/)). The former is the
    database where Heapster stores data and the latter can be used to visualize it
    through dashboards.
  prefs: []
  type: TYPE_NORMAL
- en: You might be inclined to think that Heapster, InfluxDB, and Grafana might be
    the solution for your monitoring needs. I advise against such a decision. We're
    using Heapster only because it's readily available as a Minikube addon. The idea
    to develop Heapster as a tool for monitoring needs is mostly abandoned. Its primary
    focus is to serve as an internal tool required for some of the Kubernetes features.
    Instead, I'd suggest a combination of Prometheus ([https://prometheus.io/](https://prometheus.io/))
    combined with the Kubernetes API as the source of metrics and Alertmanager ([https://prometheus.io/docs/alerting/alertmanager/](https://prometheus.io/docs/alerting/alertmanager/))
    for your alerting needs. However, those tools are not in the scope of this chapter,
    so you might need to educate yourself from their documentation, or wait until
    the sequel to this book is published (the tentative name is *Advanced Kubernetes*).
  prefs: []
  type: TYPE_NORMAL
- en: Use Heapster only as a quick-and-dirty way to retrieve metrics. Explore the
    combination of Prometheus and Alertmanager for your monitoring and alerting needs.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we clarified what Heapster is good for, as well as what it isn't, we
    can proceed and confirm that it is indeed running inside our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the `heapster` and `influxdb-grafana` Pods are running.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll explore Heapster just enough to retrieve the data we need. For that,
    we''ll need access to its API. However, Minikube didn''t expose its port so that''ll
    be the first thing we''ll do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll need to find out which `NodePort` was created for us. To do that, we
    need to get familiar with the JSON definition of the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We are looking for the `nodePort` entry inside the `spec.ports` array. The
    command that retrieves it and assigns the output to the `PORT` variable is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We used the `jsonpath` output to retrieve only `nodePort` of the first (and
    the only) entry of the `spec.ports` array.
  prefs: []
  type: TYPE_NORMAL
- en: Let's try a very simple query of the Heapster API.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the `curl` request is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We don't really need Heapster to retrieve the list of Pods. What we do need
    are metrics of one of the Pods. For that, we need it's name.
  prefs: []
  type: TYPE_NORMAL
- en: We'll use a similar command we used to retrieve Heapster's service port.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We retrieved all the Pods with the labels `service=go-demo-2` and `type=db`,
    and formatted the output so that `metadata.name` from the first item is retrieved.
    The value is stored as the `DB_POD_NAME` variable.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can take a look at the available metrics of the `db` container inside
    the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, most of the available metrics are related to memory and CPU.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see whether memory usage indeed corresponds with the memory resources
    we defined for the `go-demo-2-db` Deployment. As a reminder, we set memory request
    to `100Mi` and memory limit to `200Mi`.
  prefs: []
  type: TYPE_NORMAL
- en: A request that retrieves memory usage of the `db` container is as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited only to a few entries, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We can see that memory usage is somewhere around 38 megabytes. That's quite
    a big difference from `100Mi` we set. Sure, this service is not under real production
    load but, since we're simulating a "real" cluster, we'll pretend that `38Mi` is
    indeed memory usage under "real" conditions. That means that we overestimated
    the requests by assigning a value almost three times larger than the actual usage.
  prefs: []
  type: TYPE_NORMAL
- en: How about CPU? Did we make such a colossal mistake with it as well? As a reminder,
    we set the CPU request to `0.3` and the limit to `0.5`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The output, limited to only a few entries, is as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the CPU usage is around `5m` or `0.005` CPU. We, again, made
    a huge mistake with resource specification. Our value is around sixty times higher.
  prefs: []
  type: TYPE_NORMAL
- en: Such deviations between our expectations (resource requests and limits) and
    the actual usage can lead to very unbalanced scheduling with undesirable effects.
    We'll correct the resources soon. For now, we'll explore what happens if the amount
    of resources is below the actual usage.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the effects of discrepancies between resource specifications and resource
    usage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s take a look at a slightly modified version of the `go-demo-2` definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: When compared with the previous definition, the difference is only in `resources`
    of the `db` container in the `go-demo-2-db` Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The memory limit is set to `10Mi` and the request to `5Mi`. Since we already
    know from Heapster's data that MongoDB requires around `38Mi`, memory resources
    are, this time, much lower than the actual usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what will happen when we apply the new configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We applied the new configuration and retrieved the Pods. The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: In your case, the status might not be `OOMKilled`. If so, wait for a while longer
    and retrieve the Pods again. The status should eventually change to `CrashLoopBackOff`.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the status of the `go-demo-2-db` Pod is `OOMKilled` (**Out Of
    Memory Killed**). Kubernetes detected that the actual usage is way above the limit
    and it declared the Pod as a candidate for termination. The container was terminated
    shortly afterwards. Kubernetes will recreate the terminated container a while
    later only to discover that the memory usage is still above the limit. And so
    on, and so forth. The loop will continue.
  prefs: []
  type: TYPE_NORMAL
- en: A container can exceed its memory request if the node has enough available memory.
    On the other hand, a container is not allowed to use more memory than the limit.
    When that happens, it becomes a candidate for termination.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s describe the Deployment and see the status of the `db` container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the last state of the `db` container is `OOMKilled`. When we
    explore the events, we can see that, so far, the container was restarted eight
    times with the reason `BackOff`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s explore another possible situation through yet another updated definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Just as before, the change is only in the `resources` of the `go-demo-2-db`
    Deployment. The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This time, we specified that the requested memory is twice as much as the total
    memory of the node (2GB). The memory limit is even higher.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s apply the change and observe what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the latter command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This time, the status of the Pod is `Pending`. Kubernetes could not place it
    anywhere in the cluster and is waiting until the situation changes.
  prefs: []
  type: TYPE_NORMAL
- en: Even though memory requests are associated with containers, it often makes sense
    to translate them into Pods requirements. We can say that the requested memory
    of a Pod is the sum of the requests of all the containers that form it. In our
    case, the Pod has only one container, so the requests of the two are equal. The
    same can be said for limits.
  prefs: []
  type: TYPE_NORMAL
- en: During the scheduling process, Kubernetes sums the requests of a Pod and looks
    for a node that has enough available memory and CPU. If Pod's request cannot be
    satisfied, it is placed in the pending state in the hope that resources will be
    freed on one of the nodes, or that a new server will be added to the cluster.
    Since such a thing will not happen in our case, the Pod created through the `go-demo-2-db`
    Deployment will be pending forever, unless we change the memory request again.
  prefs: []
  type: TYPE_NORMAL
- en: When Kubernetes cannot find enough free resources to satisfy the resource requests
    of all the containers that form a Pod, it changes its state to `Pending`. Such
    Pods will remain in this state until requested resources become available.
  prefs: []
  type: TYPE_NORMAL
- en: Let's describe the `go-demo-2-db` Deployment and see whether there is some additional
    useful information in it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the events section, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: We can see that it has already `FailedScheduling` seven times and that the message
    clearly indicates that there is `Insufficient memory`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll revert to the initial definition. Even though we know that its resources
    are incorrect, we know that it satisfies all the requirements and that all the
    Pods will be scheduled successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Now that all the Pods are running, we should try to write a better definition.
    For that, we need to observe memory and CPU usage and use that information to
    decide the requests and the limits.
  prefs: []
  type: TYPE_NORMAL
- en: Adjusting resources based on actual usage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We saw some of the effects that can be caused by a discrepancy between resource
    usage and resource specification. It's only natural that we should adjust our
    specification to reflect the actual memory and CPU usage better.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We retrieved the name of the database Pod and used it to obtain memory and CPU
    usage of the `db` container. As a result, we now know that memory usage is somewhere
    between `30Mi` and `40Mi`. Similarly, we know that the CPU consumption is somewhere
    around `5m`
  prefs: []
  type: TYPE_NORMAL
- en: Let's take the same metrics for the `api` container.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: As expected, an `api` container uses even less resources than MongoDB. Its memory
    is somewhere between `3Mi` and `7Mi`. Its CPU usage is so low that Heapster rounded
    it to `0m`.
  prefs: []
  type: TYPE_NORMAL
- en: Equipped with this knowledge, we can proceed to update our YAML definition.
    Still, before we do that, I need to clarify a few things.
  prefs: []
  type: TYPE_NORMAL
- en: The metrics we collected are based on applications that do nothing. Once they
    start getting real load and start hosting production size data, the metrics would
    change drastically. What you need is a way to predict how much resources an application
    will use in production, not in a simple test environment. You might be inclined
    to run stress tests that would simulate production setup. Do that. It's significant,
    but it does not necessarily result in real production-like behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Replicating production and behavior of real users is tough. Stress tests will
    get you half-way. For the other half, you'll have to monitor your applications
    in production and, among other things, adjust resources accordingly. There are
    many additional things you should take into account but, for now, I wanted to
    stress that applications that do nothing are not a good measure of resource usage.
    Still, we're going to imagine that the applications we're currently running are
    under production-like load and that the metrics we retrieved represent how the
    applications would behave in production.
  prefs: []
  type: TYPE_NORMAL
- en: Simple test environments do not reflect production usage of resources. Stress
    tests are a good start, but not a complete solution. Only production provides
    real metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at a new definition that better represents resource usage
    of the applications.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: That is much better. The resource requests are only slightly higher than the
    current usage. We set the memory limits value to double that of the requests so
    that the applications have ample resources for occasional (and short-lived) bursts
    of additional memory consumption. CPU limits are much higher than requests mostly
    because I was too embarrassed to put anything less than a tenth of a CPU as the
    limit. Anyways, the point is that requests are close to the observed usage and
    limits are higher so that applications have some space to breathe in case of a
    temporary spike in resource usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'All that''s left is to apply the new definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The `deployment "go-demo-2-api"` was successfully rolled out, and we can move
    onto the next subject.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring quality of service (QoS) contracts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we send a request to Kubernetes API to create a Pod (directly or through
    one of the Controllers), it initiates the scheduling process. What happens next
    or, to be more precise, where it will decide to run a Pod, depends hugely on the
    resources we defined for the containers that form the Pod. In a nutshell, Kubernetes
    will decide to deploy a Pod, whenever it is possible, inside one of the nodes
    that has enough available memory.
  prefs: []
  type: TYPE_NORMAL
- en: When memory requests are defined, Pods will get the memory they requested. If
    memory usage of one of the containers exceeds the requested amount, or if some
    other Pod needs that memory, the Pod hosting it might be killed. Please note that
    I wrote that a Pod *might* be killed. Whether that will happen depends on the
    requests from other Pods and the available memory in the cluster. On the other
    hand, containers that exceed their memory limits are always killed (unless it
    was a temporary situation).
  prefs: []
  type: TYPE_NORMAL
- en: CPU requests and limits work a bit differently. Containers that exceed specified
    CPU resources are not killed. Instead, they are throttled.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we shed a bit of light around Kubernetes' killing activities, we should
    note that (almost) nothing happens randomly. When there aren't enough resources
    to serve the needs of all the Pods, Kubernetes will destroy one or more containers.
    The decision which one it will be is anything but random. Who will be the unlucky
    one depends on the assigned **Quality of Service** (**QoS**). Those with the lowest
    priority are killed first.
  prefs: []
  type: TYPE_NORMAL
- en: Since this might be the first time you heard about QoS, we'll spend some time
    explaining what they are and how they work.
  prefs: []
  type: TYPE_NORMAL
- en: Pods are the smallest units in Kubernetes. Since almost everything ends up as
    a Pod (one way or another), it is no wonder that Kubernetes promises specific
    guarantees to all the Pods running inside the cluster. Whenever we send a request
    to the API to create or update a Pod, it gets assigned one of the QoS classes.
    They are used to make decisions such as where to schedule a Pod or whether to
    evict it.
  prefs: []
  type: TYPE_NORMAL
- en: We do not specify QoS directly. Instead, they are assigned based on the decisions
    we make with resource requests and limits.
  prefs: []
  type: TYPE_NORMAL
- en: At the moment, three QoS classes are available. Each Pod can have the *Guaranteed*,
    the *Burstable*, or the *BestEffort* QoS.
  prefs: []
  type: TYPE_NORMAL
- en: '**Guaranteed QoS** is assigned only to Pods which have set both CPU requests
    and limits, and memory requests and limits for all of their containers. The Pods
    we created with the last definition match that criteria. However, there''s one
    more necessary condition that must be met. The requests and limits values must
    be the same per container. Still, there is a catch. When a container specifies
    only limits, requests are automatically set to the same values. In other words,
    containers without requests will have Guaranteed QoS if their limits are defined.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can summarize criteria for Guaranteed QoS as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Both memory and CPU limits must be set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory and CPU requests must be set to the same values as the limits, or they
    can be left empty, in which case they default to the limits (we'll explore them
    soon)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pods with Guaranteed QoS assigned are the top priority and will never be killed
    unless they exceed their limits or are unhealthy. They are the last to go when
    things go wrong. As long as their resource usage is within limits, Kubernetes
    will always choose to kill Pods with other QoS assignments when resource usage
    is over the capacity.
  prefs: []
  type: TYPE_NORMAL
- en: Let's move to the next QoS.
  prefs: []
  type: TYPE_NORMAL
- en: '**Burstable QoS** is assigned to Pods that do not meet the criteria for Guaranteed
    QoS but have at least one container with memory or CPU requests defined.'
  prefs: []
  type: TYPE_NORMAL
- en: Pods with the Burstable QoS are guaranteed minimal (requested) memory usage.
    They might be able to use more resources if they are available. If the system
    is under pressure and needs more available memory, containers belonging to the
    Pods with the Burstable QoS are more likely to be killed than those with Guaranteed
    QoS when there are no Pods with the BestEffort QoS. You can consider the Pods
    with this QoS as medium priority.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we reached the last QoS.
  prefs: []
  type: TYPE_NORMAL
- en: '**BestEffort QoS** is given to the Pods that do not qualify as Guaranteed or
    Burstable. They are Pods that consist of containers that have none of the resources
    defined. Containers in Pods qualified as BestEffort can use any available memory
    they need.'
  prefs: []
  type: TYPE_NORMAL
- en: When in need of more resources, Kubernetes will start killing containers residing
    in the Pods with BestEffort QoS. They are the lowest priority, and they are the
    first to disappear when more memory is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look which QoS our `go-demo-2-db` Pod got assigned.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The Pod was assigned Burstable QoS. Its limits are different from requests,
    so it did not qualify for Guaranteed QoS. Since its resources are set, and it
    is not eligible for Guaranteed QoS, Kubernetes assigned it the second best QoS.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at a slightly modified definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This time, we specified that both `cpu` and `memory` should have the same values
    for both the `requests` and the `limits` for the containers that will be created
    with the `go-demo-2-db` Deployment. As a result, it should be assigned Guaranteed
    QoS.
  prefs: []
  type: TYPE_NORMAL
- en: The containers of the `go-demo-2-api` Deployment are void of any `resources`
    definitions and, therefore, will be assigned BestEffort QoS.
  prefs: []
  type: TYPE_NORMAL
- en: Let's confirm that both assumptions (not to say guesses) are indeed correct.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: We applied the new definition and output the rollout status of the `go-demo-2-db`
    Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can describe the Pod created thought the `go-demo-2-db` Deployment and
    check its QoS.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Memory and CPU limits and requests are the same and, as a result, the QoS is
    `Guaranteed`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's check the QoS of the Pods created through the `go-demo-2-api` Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The three Pods created through the `go-demo-2-api` Deployment are without any
    resources definitions and, therefore, their QoS is set to `BestEffort`.
  prefs: []
  type: TYPE_NORMAL
- en: We won't be needing the objects we created so far so we'll remove them before
    moving onto the next subject.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Defining resource defaults and limitations within a namespace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We already learned how to leverage Kubernetes namespaces to create clusters
    within a cluster. When combined with RBAC, we can create namespaces and give users
    permissions to use them without exposing the whole cluster. Still, one thing is
    missing.
  prefs: []
  type: TYPE_NORMAL
- en: We can, let's say, create a `test` namespace and allow users to create objects
    without permitting them to access other namespaces. Even though that is better
    than allowing everyone full access to the cluster, such a strategy would not prevent
    people from bringing the whole cluster down or affecting the performance of applications
    running in other namespaces. The piece of the puzzle we're missing is resource
    control on the namespace level.
  prefs: []
  type: TYPE_NORMAL
- en: We already discussed that every container should have resource `limits` and
    `requests` defined. That information helps Kubernetes schedule Pods more efficiently.
    It also provides it with the information it can use to decide whether a Pod should
    be evicted or restarted. Still, the fact that we can specify `resources` does
    not mean that we are forced to define them. We should have the ability to set
    default `resources` that will be applied when we forget to specify them explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: Even if we define default `resources`, we also need a way to set limits. Otherwise,
    everyone with permissions to deploy a Pod can potentially run an application that
    requests more resources than we're willing to give.
  prefs: []
  type: TYPE_NORMAL
- en: All in all, our next task is to define default requests and limits as well as
    to specify minimum and maximum values someone can define for a Pod.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start by creating a `test` Namespace.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: With a playground namespace created, we can take a look at a new definition.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: We specified that the resource should be of `LimitRange` kind. It's `spec` has
    four `limits`.
  prefs: []
  type: TYPE_NORMAL
- en: The `default` limit and `defaultRequest` entries will be applied to the containers
    that do not specify resources. If a container does not have memory or CPU limits,
    it'll be assigned the values set in the `LimitRange`. The `default` entries are
    used as limits, and the `defaultRequest` entries are used as requests.
  prefs: []
  type: TYPE_NORMAL
- en: When a container does have the resources defined, they will be evaluated against
    `LimitRange` thresholds specified as `max` and `min`. If a container does not
    meet the criteria, the Pod that hosts the containers will not be created.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll see a practical implementation of the four `limits` soon. For now, the
    next step is to create the `limit-range` resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: We created the `LimitRange` resource.
  prefs: []
  type: TYPE_NORMAL
- en: Let's describe the `test` namespace where the resource was created.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: The output, limited to the relevant parts, is as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the `test` namespace has the resource limits we specified. We
    set four out of five possible values. The `maxLimitRequestRatio` is missing and
    we'll describe it only briefly. When `MaxLimitRequestRatio` is set, container
    request and limit resources must both be non-zero, and the limit divided by the
    request must be less than or equal to the enumerated value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at yet another variation of the `go-demo` definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: The only thing to note is that none of the containers have any resources defined.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we'll create the objects defined in the `go-demo-2-no-res.yml` file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: We created the objects inside the `test` namespace and waited until the `deployment
    "go-demo-2-api"` was successfully rolled out.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s describe one of the Pods we created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Even though we did not specify the resources of the `db` container inside the
    `go-demo-2-db` Pod, the resources are set. The `db` container was assigned the
    `default` limits of the `test` Namespace as the container limit. Similarly, the
    `defaultRequest` limits were used as container requests.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, any attempt to create Pods hosting containers without resources
    will result in the namespace limits applied.
  prefs: []
  type: TYPE_NORMAL
- en: We should still define container resources instead of relying on namespace default
    limits. They are, after all, only a fallback in case someone forgot to define
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see what happens when resources are defined, but they do not match the
    namespace `min` and `max` limits.
  prefs: []
  type: TYPE_NORMAL
- en: We'll use the same `go-demo-2.yml` we used before.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: What matters is that the `resources` for both Deployments are defined.
  prefs: []
  type: TYPE_NORMAL
- en: Let's create the objects and retrieve the events. They will help us understand
    better what is happening.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the latter command, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: We can see that we are forbidden from creating either of the two Pods. The difference
    between those events is in what caused Kubernetes to reject our request.
  prefs: []
  type: TYPE_NORMAL
- en: The `go-demo-2-db-*` Pod could not be created because its `maximum memory usage
    per Container is 80Mi, but limit is 100Mi`. On the other hand, we are forbidden
    from creating the `go-demo-2-api-*` Pods because the `minimum memory usage per
    Container is 10Mi, but request is 5Mi`.
  prefs: []
  type: TYPE_NORMAL
- en: All the containers within the `test` namespace will have to comply with the
    `min` and `max` limits. Otherwise, we are forbidden from creating them. Container
    limits cannot be higher than the namespace `max` limits. On the other hand, container
    resource requests cannot be smaller than namespace `min` limits.
  prefs: []
  type: TYPE_NORMAL
- en: If we think about namespace limits as lower and upper thresholds, we can say
    that container requests cannot be below them, and that container limits can't
    be above.
  prefs: []
  type: TYPE_NORMAL
- en: Press the *Ctrl* + *C* keys to stop watching the events.
  prefs: []
  type: TYPE_NORMAL
- en: It might be easier to observe the effects of the `max` and `min` limits if we
    create Pods directly, instead of through Deployments.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: We tried to create a Pod with the memory request set to `100Mi`. Since the namespace
    limit is `80Mi`, the API returned the error message stating that the `Pod "test"
    is invalid`. Even though the `max` limit refers to container `limit`, memory request
    was used in its absence.
  prefs: []
  type: TYPE_NORMAL
- en: We'll run a similar exercise but, this time, with only `1Mi` set as memory request.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, the error is slightly different. We can see that `pods "test" is
    forbidden: minimum memory usage per Container is 10Mi, but request is 1Mi`. What
    we requested is below the `min` limit of the `test` namespace and, therefore,
    we are forbidden from creating the Pod.'
  prefs: []
  type: TYPE_NORMAL
- en: We'll delete the `test` namespace before we move into the next subject.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: Defining resource quotas for a namespace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Resource defaults and limitations are a good first step towards preventing malicious
    or accidental deployment of Pods that can potentially produce adverse effects
    on the cluster. Still, any user with the permissions to create Pods in a namespace
    can overload the system. Even if `max` values are set to some reasonably small
    amount of memory and CPU, a user could deploy thousands, or even millions of Pods,
    and "eat" all the available cluster resources. Such an effect might not be even
    produced out of malice but accidentally. A Pod might be attached to a system that
    scales it automatically without defining upper bounds and, before we know it,
    it might scale to too many replicas. There are also many other ways things might
    get out of control.
  prefs: []
  type: TYPE_NORMAL
- en: What we need is to define namespace boundaries through quotas.
  prefs: []
  type: TYPE_NORMAL
- en: With quotas, we can guarantee that each namespace gets its fair share of resources.
    Unlike `LimitRange` rules that are applied to each container, `ResourceQuota`
    defines namespace limits based on aggregate resource consumption.
  prefs: []
  type: TYPE_NORMAL
- en: We can use `ResourceQuota` objects to define the total amount of compute resources
    (memory and CPU) that can be spent in a namespace. We can also use it to limit
    storage utilization or the number of objects of a certain type that can be created
    in a namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at the cluster resources we have in our Minikube cluster.
    It is small, and it's not even a real cluster. However, it's the only one we have
    (for now), so please use your imagination and pretend that it's "real".
  prefs: []
  type: TYPE_NORMAL
- en: Our cluster has 2 CPUs and 2 GB of memory. Now, let's say that this cluster
    serves only development and production purposes. We can use the `default` namespace
    for production and create a `dev` namespace for development. We can assume that
    the production should consume all the resources of the cluster minus those given
    to the `dev` namespace which, on the other hand, should not exceed a specific
    limit.
  prefs: []
  type: TYPE_NORMAL
- en: The truth is that with 2 CPUs and 2 GB of memory, there isn't much we can give
    to developers. Still, we'll try to be generous. We'll give them 500 MB and 0.8
    CPUs for requests. We'll allow occasional bursts in resource usage by defining
    limits of 1 CPU and 1 GB of memory. Furthermore, we might want to limit the number
    of Pods to ten. Finally, as a way to reduce risks, we will deny developers the
    right to expose node ports.
  prefs: []
  type: TYPE_NORMAL
- en: Isn't that a decent plan? I'll imagine that, at this moment, you are nodding
    as a sign of approval so we'll move on and create the quotas we discussed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the `dev.yaml` definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Besides creating the `dev` namespace, we're also creating a `ResourceQuota`.
    It specifies a set of `hard` limits. Remember, they are based on aggregated data,
    and not on per-container basis like LimitRanges.
  prefs: []
  type: TYPE_NORMAL
- en: We set requests quotas to `0.8` CPUs and `500Mi` of RAM. Similarly, limit quotas
    as set to `1` CPU and `1Gi` of memory. Finally, we specified that the `dev` namespace
    can have only `10` Pods and that there can be no NodePorts. That's the plan we
    formulated and defined. Now let's create the objects and explore the effects.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: We can see from the output that the `namespace "dev"` was created as well as
    the `resourcequota "dev"`. To be on the safe side, we'll describe the newly created
    `devquota`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the hard limits are set and that there's currently no usage.
    That was to be expected since we're not running any objects in the `dev` namespace.
    Let's spice it up a bit by creating the already too familiar `go-demo-2` objects.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'We created the objects from the `go-demo-2.yml` file and waited until the `go-demo-2-api`
    Deployment rolled out. Now we can revisit the values of the `dev` quota:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Judging from the `Used` column, we can see that we are, for example, currently
    running `4` Pods and that we are still below the limit of `10`. One of those Pods
    was created through the `go-demo-2-db` Deployment, and the other three with the
    `go-demo-2-api`. If you summarize resources we specified for the containers that
    form those Pods, you'll see that the values match the used `limits` and `requests`.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we did not reach any of the quotas. Let's try to break at least one
    of them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: The definition of the `go-demo-2-scaled.yml` is almost the same as the one in
    `go-demo-2.yml`. The only difference is that the number of replicas of the `go-demo-2-api`
    Deployment is increased to fifteen. As you already know, that should result in
    fifteen Pods created through that Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: I'm sure you can guess what will happen if we apply the new definition. We'll
    do it anyway.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: We applied the new definition. We'll give Kubernetes a few moments to do the
    work before we take a look at the events it'll generate. So, take a deep breath
    and count from one to the number of processors in your Laptop. In my case, it's
    one Mississippi, two Mississippi, three Mississippi, all the way until sixteen
    Mississippi.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of a few of the events generated inside the `dev` namespace is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: We can see that we reached two of the limits imposed by the namespace quota.
    We reached the maximum amount of CPU (`1`) and Pods (`10`). As a result, ReplicaSet
    controller was forbidden from creating new Pods.
  prefs: []
  type: TYPE_NORMAL
- en: We should be able to confirm which hard limits were reached by describing the
    `dev` namespace.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the `Resource Quotas` section, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: As the events showed us, the values of `limits.cpu` and `pods` resources are
    the same in both `User` and `Hard` columns. As a result, we won't be able to create
    any more Pods, nor will we be allowed to increase CPU limits for those that are
    already running.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let's take a look at the Pods inside the `dev` namespace.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Following is the output of the preceding command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: The `go-demo-2-api` Deployment managed to create nine Pods. Together with the
    Pod created through the `go-demo-2-db`, we reached the limit of ten.
  prefs: []
  type: TYPE_NORMAL
- en: We confirmed that the limit and the Pod quotas work. We'll revert to the previous
    definition (the one that does not reach any of the quotas) before we move onto
    the next verification.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: The output of the latter command should indicate that the `deployment "go-demo-2-api"
    was successfully rolled out`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at yet another slightly modified definition of the `go-demo-2`
    objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the relevant parts, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: Both memory request and limit of the `api` container of the `go-demo-2-api`
    Deployment is set to `200Mi` while the database remains with the memory request
    of `50Mi`. Knowing that the `requests.memory` quota of the `dev` namespace is
    `500Mi`, it's enough to do simple math and come to the conclusion that we won't
    be able to run all three replicas of the `go-demo-2-api` Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: Just as before, we should wait for a while before taking a look at the events
    of the `dev` namespace.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to one of the entries, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: We reached the quota of the `requests.memory`. As a result, creation of at least
    one of the Pods is forbidden. We can see that we requested creation of a Pod that
    requests `200Mi` of memory. Since the current summary of the memory requests is
    `455Mi`, creating that Pod would exceed the allocated `500Mi`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a closer look at the namespace.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the `Resource Quotas` section, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: Indeed, the amount of used memory requests is `455Mi`, meaning that we could
    create additional Pods with up to `45Mi`, not `200Mi`.
  prefs: []
  type: TYPE_NORMAL
- en: We'll revert to the `go-demo-2.yml` one more time before we explore the last
    quota we defined.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: The only quota we did not yet verify is `services.nodeports`. We set it to `0`
    and, as a result, we should not be allowed to expose any node ports. Let's confirm
    that is indeed true.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: All our quotas work as expected. But, there are others. We won't have time to
    explore examples of all the quotas we can use. Instead, we'll list them all for
    future reference.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can divide quotas into several groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Compute resource quotas** limit the total sum of the compute resources. They
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Resource name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `cpu` | Across all pods in a non-terminal state, the sum of CPU requests
    cannot exceed this value. |'
  prefs: []
  type: TYPE_TB
- en: '| `limits.cpu` | Across all pods in a non-terminal state, the sum of CPU limits
    cannot exceed this value. |'
  prefs: []
  type: TYPE_TB
- en: '| `limits.memory` | Across all pods in a non-terminal state, the sum of memory
    limits cannot exceed this value. |'
  prefs: []
  type: TYPE_TB
- en: '| `memory` | Across all pods in a non-terminal state, the sum of memory requests
    cannot exceed this value. |'
  prefs: []
  type: TYPE_TB
- en: '| `requests.cpu` | Across all pods in a non-terminal state, the sum of CPU
    requests cannot exceed this value. |'
  prefs: []
  type: TYPE_TB
- en: '| `requests.memory` | Across all pods in a non-terminal state, the sum of memory
    requests cannot exceed this value. |'
  prefs: []
  type: TYPE_TB
- en: '**Storage resource quotas** limit the total sum of the storage resources. We
    did not yet explore storage (beyond a few local examples) so you might want to
    keep the list that follows for future reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Resource name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `requests.storage` | Across all persistent volume claims, the sum of storage
    requests cannot exceed this value. |'
  prefs: []
  type: TYPE_TB
- en: '| `persistentvolumeclaims` | The total number of persistent volume claims that
    can exist in the namespace. |'
  prefs: []
  type: TYPE_TB
- en: '| `[PREFIX]/requests.storage` | Across all persistent volume claims associated
    with the storage-class-name, the sum of storage requests cannot exceed this value.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `[PREFIX]/persistentvolumeclaims` | Across all persistent volume claims associated
    with the storage-class-name, the total number of persistent volume claims that
    can exist in the namespace. |'
  prefs: []
  type: TYPE_TB
- en: '| `requests.ephemeral-storage` | Across all pods in the namespace, the sum
    of local ephemeral storage requests cannot exceed this value. |'
  prefs: []
  type: TYPE_TB
- en: '| `limits.ephemeral-storage` | Across all pods in the namespace, the sum of
    local ephemeral storage limits cannot exceed this value. |'
  prefs: []
  type: TYPE_TB
- en: Please note that `[PREFIX]` should be replaced with `<storage-class-name>.storageclass.storage.k8s.io`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Object count quotas** limit the number of objects of a given type. They are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Resource name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `configmaps` | The total number of config maps that can exist in the namespace.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `persistentvolumeclaims` | The total number of persistent volume claims that
    can exist in the namespace. |'
  prefs: []
  type: TYPE_TB
- en: '| `pods` | The total number of pods in a non-terminal state that can exist
    in the namespace. A pod is in a terminal state if status.phase in (Failed, Succeeded)
    is true. |'
  prefs: []
  type: TYPE_TB
- en: '| `replicationcontrollers` | The total number of replication controllers that
    can exist in the namespace. |'
  prefs: []
  type: TYPE_TB
- en: '| `resourcequotas` | The total number of resource quotas that can exist in
    the namespace. |'
  prefs: []
  type: TYPE_TB
- en: '| `services` | The total number of services that can exist in the namespace.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `services.loadbalancers` | The total number of services of type load balancer
    that can exist in the namespace. |'
  prefs: []
  type: TYPE_TB
- en: '| `services.nodeports` | The total number of services of type node port that
    can exist in the namespace. |'
  prefs: []
  type: TYPE_TB
- en: '| `secrets` | The total number of secrets that can exist in the namespace.
    |'
  prefs: []
  type: TYPE_TB
- en: What now?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Wasn't that a ride?
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes relies heavily on available resources spread throughout the cluster.
    Still, it cannot do magic. We need to help it out by defining resources we expect
    our containers will consume.
  prefs: []
  type: TYPE_NORMAL
- en: Even though Heapster is not the best solution for collecting metrics, it is
    already available in our Minikube cluster, and we used it to learn how much resources
    our applications use and, through that information, we refined our resource definitions.
    Without metrics, our definitions are pure guesses. When we guess, Kubernetes needs
    to guess as well. A stable system is a predictable system based on facts, not
    someone's imagination. Heapster helped us transform our assumptions into measurable
    facts which we fed into Kubernetes which, in turn, used them in its scheduling
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Exploration of resource definitions led us to **Quality Of Service** (**QoS**).
    Even though Kubernetes decides which QoS will be used, knowing the rules used
    in the decision process is essential if we are to prioritize applications and
    their availability.
  prefs: []
  type: TYPE_NORMAL
- en: All that leads us to the culmination of the strategies that make our clusters
    secure, stable, and robust. Dividing a cluster into Namespaces and employing RBAC
    is not enough. RBAC prevents unauthorized users from accessing the cluster and
    provides permissions to those we trust. However, RBAC does not prevent users from
    accidentally (or intentionally) putting the cluster in danger through too many
    deployments, too big applications, or inaccurate sizing. Only by combining RBAC
    with resource defaults, limitations, and quotas can we hope for a fault tolerant
    and robust cluster capable of reliably hosting our applications.
  prefs: []
  type: TYPE_NORMAL
- en: We learned almost all the essential Kubernetes objects and principles. The time
    has come to move to a "real" cluster. We are about to delete the Minikube cluster
    for the last time (at least in this book).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: Kubernetes resource management compared to docker swarm equivalent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Resource management can be divided into a few categories. We need to define
    how much memory and CPU we except a container will use and what are the limits.
    This information is crucial for a scheduler to make "intelligent" decisions when
    calculating where to place containers. In this aspect, there is no essential difference
    between Kubernetes and Docker Swarm. Both are using requested resources to decide
    where to deploy containers and limits when to evict them. Both of them are, more
    or less, the same in this aspect.
  prefs: []
  type: TYPE_NORMAL
- en: How can we know how much memory and CPU to dedicate to each of our containers?
    That's one of the questions I heard way too many times. The answer is simple.
    Collect metrics, evaluate them, adjust resources, take a break, repeat. Where
    do we collect metrics? Wherever you want. Prometheus is a good choice. Where will
    it get metrics? Well, it depends which scheduler you use. If it's Docker Swarm,
    you'll need to run a bunch of exporters. Or, you might be brave enough and try
    the experimental feature that exposes Docker's internal metrics in Prometheus
    format. You might even be enthusiastic enough to think that they will be enough
    for all your monitoring and alerting needs. Maybe, by the time you read this,
    the feature is not experimental anymore. On the other hand, Kubernetes has it
    all, and so much more. You can use Heapster, or you might discover that it is
    too limiting and configure Prometheus to scrape metrics directly from Kubernetes
    API. Kubernetes exposes a vast amount of data. More than you'll probably ever
    need. You will be able to fetch memory, CPU, IO, network, and a myriad of other
    metrics and make intelligent decisions not only about the resources your containers
    require but about so much more.
  prefs: []
  type: TYPE_NORMAL
- en: To make things clear, you can get the same metrics no matter whether you're
    running Kubernetes or Docker Swarm. The major difference is that Kubernetes exposes
    them through its API, while with Swarm you'll have to struggle between the decisions
    whether to use its limited metrics or go into the trouble of setting up the exporters
    like cAdvisor and Node Exporter. Most likely, you'll discover that you'll need
    both the metrics from Swarm's API and those from the exporters. Kubernetes has
    a more robust solution, even though you might still need an exporter or two. Still,
    having most, if not all, of the metrics you'll need from its API is a handy thing
    to have.
  prefs: []
  type: TYPE_NORMAL
- en: Frankly, the differences in the way we retrieve metrics from the two schedulers
    are not of great importance. If this would be where the story about resources
    ends, I'd conclude that both solutions are, more or less, equally good. But, the
    narrative continues. This is where similarities stop. Or, to be more precise,
    this is where Docker Swarm ends, and Kubernetes only just began.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes allows us to define resource defaults and limitations that are applied
    to containers that do not specify resources. It allows us to specify resource
    quotas that prevent accidental or malicious over-usage of resources. The two combined
    with Namespaces provide very powerful safeguards. They give us some of the means
    with which we can design the system that is truly fault tolerant by preventing
    rogue containers, uncontrolled scaling, and human errors from bringing our clusters
    to a grinding halt. Don't think, even for a second, that quotas are the only thing
    required for building a robust system. It isn't the only piece of the puzzle,
    but it is a significant one never the less.
  prefs: []
  type: TYPE_NORMAL
- en: Namespaces combined with quotas are important. I'd even say that they are crucial.
    Without them, we would be forced to create a cluster for every group, team, or
    a department in our organizations. Or, we might have to resort to further tightening
    of the processes that prevent our teams from exploiting the benefits behind container
    orchestrators. If the goal is to provide freedom to our teams without sacrificing
    cluster stability, Kubernetes has a clear edge over Docker Swarm.
  prefs: []
  type: TYPE_NORMAL
- en: This battle is won by Kubernetes, but the war still rages.
  prefs: []
  type: TYPE_NORMAL
- en: OK. I exaggerated a bit with the words *battle* and *war*. It's not a conflict,
    and both communities are increasing collaboration and sharing ideas and solutions.
    Both platforms are merging. Still, for now, Kubernetes has a clear edge over Docker
    Swarm on the subject of resource management.
  prefs: []
  type: TYPE_NORMAL
