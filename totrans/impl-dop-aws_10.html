<html><head></head><body><div class="chapter" title="Chapter&#xA0;10.&#xA0;AWS Tips and Tricks"><div class="titlepage"><div><div><h1 class="title"><a id="ch10"/>Chapter 10. AWS Tips and Tricks</h1></div></div></div><p>In this chapter, I would like to provide you with a selection of random bits of advice. Some of them are derived from my own experience with using AWS; others are found in the AWS whitepapers or related blogs.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note86"/>Note</h3><p><span class="strong"><strong>A few links on the subject</strong></span>:</p><p><a class="ulink" href="https://d0.awsstatic.com/whitepapers/AWS_Cloud_Best_Practices.pdf">https://d0.awsstatic.com/whitepapers/AWS_Cloud_Best_Practices.pdf</a></p><p><a class="ulink" href="https://wblinks.com/notes/aws-tips-i-wish-id-known-before-i-started/">https://wblinks.com/notes/aws-tips-i-wish-id-known-before-i-started/</a></p><p><a class="ulink" href="https://launchbylunch.com/posts/2014/Jan/29/aws-tips/">https://launchbylunch.com/posts/2014/Jan/29/aws-tips/</a>
</p></div></div><div class="section" title="Using VPCs"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec39"/>Using VPCs</h1></div></div></div><p>Apart from the initial, minor setup overhead, it is generally accepted that you are better off deploying your infrastructure inside a VPC. AWS even provides you one by default and tends to deploy resources in it unless you ask otherwise. A VPC gives you more flexibility when operating EC2 instances, better control of your networking, and enhanced security. Also, it is free.</p></div></div>
<div class="section" title="Keep the Main route table as a fallback"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec40"/>Keep the Main route table as a fallback</h1></div></div></div><p>If you follow the previous tip, you will notice that a new VPC comes with a route table marked as <span class="strong"><strong>Main</strong></span>:</p><p>
</p><div class="mediaobject"><img src="graphics/image_10_001.jpg" alt="Keep the Main route table as a fallback"/></div><p>
</p><p>I would recommend that it is left as it is, with a single, local route, and create additional route tables for any custom routing needs instead.</p><p>This way, the main or default route table becomes a sort of a safety net for any subnets that get created but remain unassociated, be it by mistake or intent.</p></div>
<div class="section" title="Staying within the VPC"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec41"/>Staying within the VPC</h1></div></div></div><p>As tempting as it may be, try to avoid exposing your VPC resources, as this defeats the purpose. This is to say, instead of assigning public IPs to your EC2 instances, which might give you quick and easy access, use a designated ssh-gateway host (also known as a bastion or a jump host) to hop through.</p><p>You would assign a public (Elastic) IP only this single machine, ensure its security group is locked down to the static IPs of your home and/or work place, and use it to connect (say over ssh) to any other instances within your VPC.</p></div>
<div class="section" title="Creating IAM roles in advance"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec42"/>Creating IAM roles in advance</h1></div></div></div><p>We have already discussed EC2 instance roles as a much better way of providing credentials to your application.</p><p>A good practice is to always create and assign an IAM role to your instances, even if it is not needed at the time and holds no permissions.</p><p>This is because IAM roles can only be assigned when an EC2 instance is being launched.</p></div>
<div class="section" title="Groups over users"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec43"/>Groups over users</h1></div></div></div><p>As you create your first deployment, you might not necessarily have that many users needing access to your AWS account.</p><p>Nevertheless, it is still a good idea to assign permissions to an IAM group and make your IAM users members of it, as opposed to granting privileges to each user as they come.</p><p>In the long term, it is often the case that team members tend to require (reuse) the same list of permissions.</p></div>
<div class="section" title="Knowing the AWS service limits"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec44"/>Knowing the AWS service limits</h1></div></div></div><p>An AWS account comes with certain limits that can be found in the AWS console:</p><p>
</p><div class="mediaobject"><img src="graphics/image_10_002.jpg" alt="Knowing the AWS service limits"/></div><p>
</p><p>These are meant to protect the customer as well as the provider against any unintentional use. The following are examples:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A coding error in your CloudFormation template, resulting in an unexpected amount of storage or other resources being provisioned</li><li class="listitem" style="list-style-type: disc">A misconfigured Auto Scaling Group, launching tens or hundreds of instances</li><li class="listitem" style="list-style-type: disc">Your user making an API call to request an unusual number of instances</li></ul></div><p>As we can see, the said limits are an overall good idea, most of the time.</p><p>If you find yourself in a production environment, getting ready for a major event and the traffic spike that comes with it, you certainly want to be aware of your current AWS service limits. Most instance types are initially limited to 20, VPC EIPs to 5, and storage types to 20 TB.</p><p>Ideally, you would review these as soon as you get an idea of your expected usage baseline (allowing for bursting) and contact AWS Support requesting a limit increase where needed.</p></div>
<div class="section" title="Pre-warm ELBs if needed"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec45"/>Pre-warm ELBs if needed</h1></div></div></div><p>On the subject of traffic spikes, while ELBs are impressively performant, there might be occasions where you will need to pre-warm them.</p><p>As you probably already know, an ELB is a collection of EC2 instances managed by AWS, running proprietary load balancing software.</p><p>An algorithm ensures that the number of ELB EC2 instances grows or shrinks in response to the traffic pattern of your application. This process of adaptive scaling is done based on averaged traffic measurements taken over time and as such is not very rapid.</p><p>To ensure that this feature does not become a problem, AWS allows you to request an ELB to be pre-warmed, that is to say, scaled-up ahead of time.</p><p>If you are on the premium support plan, you could probably wait until a few hours prior to the event; otherwise, you should contact the support team sooner to account for the extra response time.</p><p>You will be asked a series of questions relating to the expected requests per second, average payload size, event duration, and other traffic properties, which will help AWS Support determine whether pre-warming is necessary at all.</p></div>
<div class="section" title="Using termination protection"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec46"/>Using termination protection</h1></div></div></div><p>
</p><div class="mediaobject"><img src="graphics/image_10_003.jpg" alt="Using termination protection"/></div><p>
</p><p>It goes without saying that one should not keep state on machines if it can be helped.</p><p>After all, the beauty of AWS is that it allows you to not focus so much on individual instances any more. It promotes a cluster or service culture where the health of the endpoint is of importance.</p><p>For the rare cases where we must have one of those management or similar type of non-autoscaling node, however, you have nothing but to gain from protecting yourself against accidentally making the wrong API call or a console click.</p></div>
<div class="section" title="Tagging what you can"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec47"/>Tagging what you can</h1></div></div></div><p>This sounds like a chore, but it does indeed pay back later. Whether for the much better clarity on your AWS bill or the extra flexibility you get when managing your resources, tags are always useful.</p><p>Instrument your tools to apply tags whenever an asset is provisioned, then start scanning your estate regularly for any untagged resources.</p></div>
<div class="section" title="Deploying across multiple zones"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec48"/>Deploying across multiple zones</h1></div></div></div><p>Unarguably, deploying within the same physical location should yield the lowest latency.</p><p>In the majority of use cases however, the added few milliseconds in return for a multiple increase in resilience are worth it.</p><p>Try to span your deployment across two availability zones at least.</p></div>
<div class="section" title="Enhancing your ELB health-checks"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec49"/>Enhancing your ELB health-checks</h1></div></div></div><p>The stock ELB health checks allow you to check raw TCP responses or go higher in the stack and look for an HTTP/200 response.</p><p>Either is good. A basic check should get you started but as your application and its dependencies evolve, you might need to enrich your health checks too.</p><p>Let us suppose that you were serving a web application that relies on a cache and a database backend.</p><p>If the ELB was checking <code class="literal">TCP:80</code> then as long as your HTTP daemon is running, it will receive an OK. If you were checking for an HTTP/200, instead that would verify access to the application's file(s) on disk but likely not much more.</p><p>Instead, you could benefit much more from pointing the ELB at a dedicated health check endpoint within your application, which verifies all its dependencies (disk: OK, cache: OK, db: OK) before returning a green light. But beware of impacting the overall application performance: the more frequently the health check is called, the more lightweight it ought to be.</p></div>
<div class="section" title="Offloading SSL onto the ELB"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec50"/>Offloading SSL onto the ELB</h1></div></div></div><p>AWS now issues free SSL certificates as part of the <span class="strong"><strong>Certificate Manager service</strong></span> which also takes care of renewals. This seems like a pretty good reason on its own.</p><p>Managing certificates on the ELB itself is much more convenient in comparison to doing the same across a number of EC2 backend instances. Also, there must be at least a small amount of CPU performance to be gained by delegating the SSL operations.</p></div>
<div class="section" title="EIP versus public IP"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec51"/>EIP versus public IP</h1></div></div></div><p>A few points about the two types, in case you have not used these much.</p><p>Public IPs:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">You choose whether an instance should have a public IP at the time you are launching it</li><li class="listitem" style="list-style-type: disc">The address will persist across reboots but not a stop/start</li><li class="listitem" style="list-style-type: disc">These come at no extra cost</li></ul></div><p>Elastic IPs:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">You can associate/disassociate an EIP with an instance at any time after it has been launched</li><li class="listitem" style="list-style-type: disc">An EIP remains associated across reboots or start/stop operations</li><li class="listitem" style="list-style-type: disc">EIPs incur cost (when kept unused)</li><li class="listitem" style="list-style-type: disc">EIPs can be migrated between EC2 instances</li></ul></div><p>In light of the IPv4 deficit we are facing today, AWS is cleverly trying to incentivize sensible provisioning by charging for any dormant EIP resources.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip87"/>Tip</h3><p>Be a gentleman/lady and release your IPs when you are done with them.</p></div></div></div>
<div class="section" title="Mind the full-hour billing"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec52"/>Mind the full-hour billing</h1></div></div></div><p>It is great that AWS allows you to pay-for-what-you-use and as-you-go. Something to keep in mind, however, is that AWS meters usage in hourly increments.</p><p>So, say you were running a number of batch jobs, launching and terminating an instance every 10 minutes. After an hour and 10 minutes, you would have launched and terminated six instances (6x smallest increment of 1h) resulting in 6 hours of billable usage despite the fact the neither of them lasted more than 10 minutes.</p><p>At any rate, to avoid surprises, it is highly recommended you to set up billing alerts. These are simple CloudWatch alarms which can notify you when your estimated bill has reached a threshold.</p></div>
<div class="section" title="Using Route53 ALIAS records"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec53"/>Using Route53 ALIAS records</h1></div></div></div><p>This is a special in-house type of DNS record specific to the Route53 service.</p><p>For an AWS user an Alias record is a great alternative to a CNAME (for supported resources).</p><p>Some of the main advantages are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Aliases resolve directly to an IP address, saving the extra lookup which a CNAME would require</li><li class="listitem" style="list-style-type: disc">Alias records are supported at the zone apex, so you could create an alias which uses the top of a domain (for example <code class="literal">mydomain.com</code>)</li><li class="listitem" style="list-style-type: disc">Alias records allow advanced Route53 features such as weighted/latency/geo routing and failovers</li><li class="listitem" style="list-style-type: disc">There is no AWS cost associated with Alias lookups</li></ul></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note88"/>Note</h3><p>NB: A Route53 Alias record can currently only point to a limited set of AWS resources. For more information please see: <a class="ulink" href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html">http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html</a>
</p></div></div></div>
<div class="section" title="The S3 bucket namespace is global"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec54"/>The S3 bucket namespace is global</h1></div></div></div><p>This means that if you get a name conflict when creating a bucket, it is likely because somebody else in the AWS universe has beaten you to it.</p><p>Devise a naming schema that offers some uniqueness; perhaps, use your organization's name or a random prefix/suffix to the bucket name.</p><p>S3 bucket deletion tends to propagate slowly. Pay attention to the region in which you are creating your bucket. If you get it wrong, you will need to delete then wait for 20-30 minutes in my experience before you can recreate it in the right place.</p></div>
<div class="section" title="- versus . in the S3 bucket name"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec55"/>- versus . in the S3 bucket name</h1></div></div></div><p>It seems that there is often the question of whether one should name buckets as <code class="literal">images-example-com</code> or <code class="literal">images.example.com</code>.</p><p>Two things to consider are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Would you like to use S3 over HTTPS?</li><li class="listitem" style="list-style-type: disc">Would you like to use a custom domain name instead of the default S3 bucket URL?</li></ul></div><p>Strictly speaking, buckets with dots in the name will show an SSL mismatch warning when you address them over HTTPS using the default bucket URI.</p><p>This is due to the fact that S3 operates on the <code class="literal">.amazonaws.com</code> domain, and any extra dots will make it seem as if a bucket is a subdomain (not covered by the SSL certificate).</p><p>On the other hand, you have to use dots if you want to have a custom domain (CNAME) pointed at your bucket. That is to say, the bucket name has to match the said custom URL in order for S3's virtual-host style service to work.</p><p>For example, we call our bucket <code class="literal">images.example.com</code> and add a DNS record of <code class="literal">images.example.com</code> CNAME <code class="literal">images.example.com.s3.amazonaws.com</code>.</p><p>S3 would then forward incoming request to any bucket with a name matching the host in the HTTP headers (refer to <a class="ulink" href="http://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html">http://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html</a>).</p><p>So, it would seem that based on the name we chose, we can use either one of the features or the other (HTTPS vs CNAME). But there is a solution to this dilemma: CloudFront.</p><p>Placing a CloudFront distribution in front of our bucket allows a custom domain, plus a custom SSL certificate, to be specified.</p></div>
<div class="section" title="Randomizing S3 filenames"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec56"/>Randomizing S3 filenames</h1></div></div></div><p>An important fact is that S3 takes filenames (object keys) into consideration when distributing data. You are likely to get better performance when your content does not use a sequential naming convention. For more details on the distribution mechanism please refer to <a class="ulink" href="http://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html">http://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html</a>
</p></div>
<div class="section" title="Initializing (pre-warm) EBS volumes"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec57"/>Initializing (pre-warm) EBS volumes</h1></div></div></div><p>It used to be the case that all EBS storage was meant to be initialized to avoid the first-time-access penalty, which becomes a noticeable overhead as you start dealing with larger and larger volumes. Nowadays, the situation has improved as new volumes need no pre-warming (ref: <a class="ulink" href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html</a>); however, one should still consider the added delay to the boot process (if the volume is needed at boot time) against any potential performance gains.</p><p>For very large volumes, initialization might be prohibitive, but in any other case, it is certainly worth doing. Or if you run your own database servers on EC2, then you should definitely consider pre-warming volumes regardless of size.</p><p>You could use the suggested command-line steps to measure time spent performing this type of optimization (refer to <a class="ulink" href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html</a>).</p></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec58"/>Summary</h1></div></div></div><p>In this chapter, we looked at some tips, tricks, facts, and general information, which are useful to keep in mind when using AWS.</p><p>This is naturally just a small selection of such public secrets, and if you are also excited about the peculiarities of the AWS environment plus the creative hacks that users come up with to work around them – I would recommend you to check out <a class="ulink" href="https://aws.amazon.com/blogs/aws/">https://aws.amazon.com/blogs/aws/</a>.</p></div></body></html>