- en: Chapter 2. Optimizing Docker Images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have built and deployed our Docker containers, we can start reaping
    the benefits of using them. We have a standard package format that lets developers
    and sysadmins work together to simplify the management of our application's code.
    Docker's container format allows us to rapidly iterate the versions of our application
    and share it with the rest of our organization. Our development, testing, and
    deployment time has decreased because of the lightweight feature and speed of
    Docker containers. The portability of Docker containers allows us to scale our
    applications from physical servers to virtual machines in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: However, we will start noticing that the same reasons for which we used Docker
    in the first place are losing their effect. Development time is increasing because
    we have to always download the newest version of our application's Docker image
    runtime library. Deployment takes a lot of time because Docker Hub is slow. At
    worst, Docker Hub may be down, and we would not be able to do any deployment at
    all. Our Docker images are now so big, in the order of gigabytes, that simple
    single-line updates take the whole day.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following scenarios of how Docker containers get
    out of hand and suggest steps to remediate the problems mentioned earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: Reducing image deployment time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing image build time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing image size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing deployment time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As time goes by while we build our Docker container, its size gets bigger and
    bigger. Updating running containers in our existing Docker hosts is not a problem.
    Docker takes advantage of the Docker image layers that we build over time as our
    application grows. However, consider a case in which we want to scale out our
    application. This requires deploying more Docker containers to additional Docker
    hosts. Each new Docker host has to then download all the large image layers that
    we built over time. This section will show you how a *large* Docker application
    affects deployment time on new Docker hosts. First, let''s build this problematic
    Docker application by carrying out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Write the following `Dockerfile` to create our "large" Docker image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, build the `Dockerfile` as `hubuser/largeapp` using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Take note of how large the created Docker image is. In the following illustrated
    output, the size is `662 MB`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the `time` command, record how long it takes to push and pull it from
    Docker Hub, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we can note in the preceding time values highlighted, it takes a lot of time
    when we perform `docker push` to upload an image to Docker Hub. Upon deployment,
    `docker pull` takes just as long in order to propagate our newly created Docker
    image to our new production Docker hosts. These upload and download time values
    also depend on the network connection between Docker Hub and our Docker hosts.
    Ultimately, when Docker Hub goes down, we will lose the ability to deploy new
    Docker containers or scale out to additional Docker hosts on demand.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to take advantage of Docker''s fast delivery of applications and ease
    of deployment and scaling, it is important that our method of pushing and pulling
    Docker images is reliable and fast. Fortunately, we can run our own Docker registry
    to be able to host and distribute our Docker images without relying on the public
    Docker Hub. The next few steps describe how to set this up to confirm the improvement
    in performance:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run our own Docker registry by typing the following command. This gives
    us a local one running at `tcp://dockerhost:5000`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let''s confirm how our Docker image deployments have improved. First,
    create a tag for the image we created earlier in order to push it to the local
    Docker registry via the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Observe how much faster it is to push the same Docker image over our newly
    running Docker registry. The following tests show that pushing Docker images is
    now at least 10 times faster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, confirm the new performance of the pulling of our Docker images before
    testing that of the pulling of images from our local Docker registry. Let''s make
    sure we remove the image we built earlier. The following tests show that the downloading
    of Docker images is now 30 times faster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The main cause of these improvements is that we uploaded and downloaded the
    same images from our local network. We saved on the bandwidth of our Docker hosts,
    and our deployment time got shorter. The best part of all is that we no longer
    have to rely on the availability of Docker Hub in order to deploy.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to deploy our Docker images to other Docker hosts, we need to set up
    security for our Docker registry. Details on how to set this up are outside the
    scope of this book. However, more details on how to set up a Docker registry are
    available at [https://docs.docker.com/registry/deploying](https://docs.docker.com/registry/deploying).
  prefs: []
  type: TYPE_NORMAL
- en: Improving image build time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker images are the main resulting artifacts that developers work on all the
    time. The simplicity of Docker files and speed of container technology allows
    us to enable rapid iteration on the application that we are working on. However,
    these advantages of using Docker start to diminish once the time it takes to build
    Docker images starts to grow uncontrollably. In this section, we will discuss
    some cases of building Docker images that take some time to run. Then, we will
    give you a few tips on how to remediate these effects.
  prefs: []
  type: TYPE_NORMAL
- en: Using registry mirrors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A big contributor to image build time is the time spent in fetching upstream
    images. Suppose we have a `Dockerfile` with the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This image will have to download `java:8u45-jre` to be built. When we move to
    another Docker host, or if the `java:8u45-jre` image is updated in Docker Hub,
    our build time will increase momentarily. Configuring a local registry mirror
    will reduce such image build time instances. This is very useful in an organization
    setting, where each developer has his/her own Docker hosts at their workstations.
    The organization's network only downloads the image from Docker Hub once. Each
    workstation Docker host in the organization can now directly fetch the images
    from the local registry mirror.
  prefs: []
  type: TYPE_NORMAL
- en: 'Setting up a registry mirror is as simple as setting up a local registry in
    the previous section. However, in addition, we need to configure the Docker host
    to be aware of this registry mirror by passing the `--registry-mirror` option
    to the Docker daemon. Here are the steps to perform this setup:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our Debian Jessie Docker host, configure the Docker daemon by updating and
    creating a Systemd drop-in file at `/etc/systemd/system/docker.service.d/10-syslog.conf
    to contain the following line`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will reload Systemd to pick up the new drop-in configuration for the
    `docker.service` unit, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, restart the Docker daemon to start it with the newly configured Systemd
    unit via the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, run the registry mirror Docker container. Run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To confirm that the registry mirror works as expected, perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Build the `Dockerfile` described at the start of this subsection and take note
    of its build time. Note that most of the time needed to build the Docker image
    is taken up by the time to download the upstream `java:8u45-jre` Docker image,
    as shown in the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, remove the image and its upstream dependency and rebuild the image again
    using the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When the `java:8u45-jre` Docker image was downloaded for the second time, it
    was retrieved from the local registry mirror instead of being connected to Docker
    Hub. Setting up a Docker registry mirror improved the time of downloading the
    upstream image by almost two times the usual. If we have other Docker hosts pointed
    at this same registry mirror, it will do the same thing: skip the downloading
    from Docker Hub.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This guide on how to set up a registry mirror is based on the one on the Docker
    documentation website. More details can be found at [https://docs.docker.com/articles/registry_mirror](https://docs.docker.com/articles/registry_mirror).
  prefs: []
  type: TYPE_NORMAL
- en: Reusing image layers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we already know, a Docker image consists of a series of layers combined using
    the union filesystem of a single image. When we work on building our Docker image,
    the preceding instructions in our `Dockerfile` are examined by Docker to check
    whether there is an existing image in its build cache that can be reused instead
    of creating a similar or duplicate image for these instructions. By finding out
    how the build cache works, we can greatly increase the speed of the subsequent
    builds of our Docker images. A good example of this is when we develop our application's
    behavior; we will not add dependencies to our application all the time. Most of
    the time, we will just want to update the core behavior of the application itself.
    Knowing this, we can design the way we will build our Docker images around this
    in our development workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Detailed rules on how `Dockerfile` instructions are cached can be found at [http://docs.docker.com/articles/dockerfile_best-practices/#build-cache](http://docs.docker.com/articles/dockerfile_best-practices/#build-cache).
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, suppose we are working on a Ruby application whose source tree
    looks similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reusing image layers](img/00003.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The `config.ru` would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Gemfile` would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Dockerfile` would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The following steps will show you how to build the Ruby application we wrote
    earlier as a Docker image:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s build this Docker image through the following command. Note that
    the time it took to build is around one minute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, update `config.ru` to change the application''s behavior, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s now build again the Docker image and note the time it takes to finish
    the build. Run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can note that even with a single-line change to our application, we have
    to run `bundle install` for each iteration of the Docker image that we are building.
    This can be very inefficient, and it disrupts the flow of our development because
    it takes one minute to build and run our Docker application. For impatient developers
    such as us, this feels like an eternity!
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to optimize this workflow, we can separate the phase in which we prepare
    our application''s dependencies from that in which we prepare its actual artifacts.
    The next steps show us how to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, update our `Dockerfile` with the following changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, build the newly refactored Docker image via this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The build time is still the same at first, but note the image ID generated
    in `Step 3`. Now, try updating `config.ru` again and rebuilding the image, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we can note in the preceding output, `docker build` reused the cache until
    `Step 3` as there was no change in `Gemfile`. Note that our Docker image's build
    time decreased by 80 times the usual!
  prefs: []
  type: TYPE_NORMAL
- en: This kind of refactoring for our Docker image is also useful to reduce deployment
    time. As our Docker hosts in production already have image layers until `Step
    3` of our Docker image in the previous version of our container, having a new
    version of our Docker application will only require the Docker host to pull new
    image layers for `Step 4` to `Step 6` in order to update our application.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing the build context size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s suppose that we have a `Dockerfile` in the Git version control similar
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reducing the build context size](img/00004.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'At some point, we will notice that our `.git` directory is too big. This is
    probably the result of having more and more code committed into our source tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, when we build our Docker application, we will notice that the time taken
    to build our Docker application is very big as well. Take a look at the following
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: If we look closely at the preceding output, we will see that the Docker client
    uploaded the whole `.git` directory of 1 GB onto the Docker daemon because it
    is a part of our build context. Also, as this is a large build context, it takes
    time for the Docker daemon to receive it before being able to start building our
    Docker image.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, these files are not necessary to build our application. Moreover,
    these Git-related files are not at all needed when we run our application in production.
    We can set Docker to ignore a specific set of files that are not needed to build
    our Docker image. Follow the next few steps to perform this optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `.dockerignore` file with the following content in the same directory
    as our `Dockerfile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, build our Docker image again by executing the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note now that the build time is improved by over 500 times the usual just by
    decreasing the size of the build context!
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: More information on how to use .`dockerignore` files can be found at [https://docs.docker.com/reference/builder/#dockerignore-file](https://docs.docker.com/reference/builder/#dockerignore-file).
  prefs: []
  type: TYPE_NORMAL
- en: Using caching proxies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another common source causing the long runtime in building Docker images are
    instructions that download dependencies. For example, a Debian-based Docker image
    needs to fetch packages from APT repositories. Depending on how large these packages
    are, the build time for an `apt-get install` instruction may be long. A useful
    technique to reduce the time for these build instructions is to introduce proxies
    that cache such dependency packages. A popular caching proxy is `apt-cacher-ng`.
    This section will describe running and setting it up to improve our Docker image
    building workflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example `Dockerfile` that installs a lot of Debian packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that its build time in the following output is quite long because this
    `Dockerfile` file downloads a lot of dependencies and packages related to Java
    (`openjdk-8-jre-headless`). Run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to improve the workflow for building this Docker image, we will set
    up a caching proxy with `apt-cacher-ng`. Fortunately, it is already available
    as a ready-to-run container from Docker Hub. Follow the next few steps to prepare
    `apt-cacher-ng`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command in our Docker host to start `apt-cacher-ng`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After this, we will use the caching proxy we ran earlier, as described in the
    following `Dockerfile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the `Dockerfile` we created earlier as a Docker image tagged as `hubuser/debian:jessie`
    via the following command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, make `hubuser/debian:jessie` our new base Docker image by updating
    our `Dockerfile` that installs a lot of Debian packages for dependencies such
    as the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To confirm the new workflow, run an initial build to warm up the cache using
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, execute the following commands to build the image again. However,
    make sure to remove the image first:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note how the subsequent build is faster even though we do not use Docker's build
    cache. This technique is useful when we develop base Docker images for our team
    or organization. Team members that try to rebuild our Docker image will run their
    builds 6.5 times faster because they can download packages from our organization's
    cache proxy that we prepared earlier. Builds on our continuous integration server
    will also be faster upon check-in because we already warmed up the caching server
    during development.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section gave a glance at how to use a very specific caching server. Here
    are a few others that we can use and their corresponding pages of documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**apt-cacher-ng**: This supports caching Debian, RPM, and other distribution-specific
    packages and can be found at [https://www.unix-ag.uni-kl.de/~bloch/acng](https://www.unix-ag.uni-kl.de/~bloch/acng).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sonatype Nexus**: This supports Maven, Ruby Gems, PyPI, and NuGet packages
    out of the box. It is available at [http://www.sonatype.org/nexus](http://www.sonatype.org/nexus).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Polipo**: This is a generic caching proxy useful for development that can
    be found at [http://www.pps.univ-paris-diderot.fr/~jch/software/polipo](http://www.pps.univ-paris-diderot.fr/~jch/software/polipo).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Squid**: This is another popular caching proxy that can work with other types
    of network traffic as well. You can look this up at [http://www.squid-cache.org](http://www.squid-cache.org).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing Docker image size
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we keep working on our Docker applications, the size of images tends to get
    bigger and bigger if we are not careful. Most people using Docker observe that
    their team's custom Docker images increase in size to at least 1 GB or more. Having
    larger images means that the time to build and deploy our Docker application increases
    as well. As a result, the feedback we get to determine the result of the application
    we're deploying gets reduced. This diminishes the benefits of Docker, enabling
    us to develop and deploy our applications in rapid iterations.
  prefs: []
  type: TYPE_NORMAL
- en: This section examines some further details of how Docker's image layers work
    and how they affect the size of the resulting image. Next, we will learn how to
    optimize these image layers by exploiting how Docker images work.
  prefs: []
  type: TYPE_NORMAL
- en: Chaining commands
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Docker images get big because some instructions are added that are unnecessary
    to build or run an image. A popular use case is packaging metadata and cache.
    After installing the packages necessary to build and run our application, such
    downloaded packages are no longer needed. The following patterns of instructions
    in a `Dockerfile` are commonly found in the wild (such as in Docker Hub) to *clean*
    the images of such unnecessary files from Docker images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'However, a Docker image''s size is basically the sum of each individual layer
    image; this is how union filesystems work. Hence, the *clean* steps do not really
    delete the space. Take a look at the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: There is no such thing as "negative" layer size. Hence, each instruction in
    a Dockerfile can only keep the image size constant or increase it. Also, as each
    step also introduces some metadata, the total size keeps increasing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to reduce the total image size, the cleaning steps should be performed
    in the same image layer. Hence, the solution is to chain commands from the previously
    multiple instructions into a single one. As Docker uses `/bin/sh` to run each
    instruction, we can use the Bourne shell''s `&&` operator to perform the chaining,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Note how each individual layer is much smaller now. As the individual layers''
    sizes were reduced, the total image size also decreased. Now, run the following
    commands and take a look at the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Separating build and deployment images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another source of unnecessary files in Docker images are build time dependencies.
    Source libraries, such as compilers and source header files, are only necessary
    when building an application inside a Docker image. Once the application is built,
    these files are no longer necessary as only the compiled binary and related shared
    libraries are needed to run the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, build the following application that is now ready to be deployed
    to a Docker host that we prepared in the cloud. The following source tree is a
    simple web application written in Go:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Separating build and deployment images](img/00005.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is the content of `hello.go` describing the application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The following corresponding `Dockerfile` shows how to build the source code
    and run the resulting binary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next few steps, we will show you how this Docker application''s image
    size gets big:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, build the Docker image and note its size. We will run the following
    commands for this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, compare this to the size of the actual application that is run, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: One of the advantages of writing Go applications, and compiled code in general,
    is that we can produce a single binary that is easy to deploy. The remaining size
    of the Docker image is made up of the unnecessary files provided by the base Docker
    image. We can note the large overhead coming from the base Docker image that increases
    the total image size by 100 times the usual.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also optimize the end Docker image deployed to production by only packing
    the final `hello` binary and some dependent shared libraries. Follow the next
    few steps to perform the optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, copy the binary from the running container to our Docker host via the
    following command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If the preceding library were a static binary, we would now be done and would
    proceed with the next step. However, Go tooling builds share binaries by default.
    In order for the binary to run properly, it needs the shared libraries. Run the
    following command to list them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, save all required shared libraries to our Docker host. Issuing the following
    `docker cp -L` commands will do this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new `Dockerfile` to build this "binary-only" image. Note how the `ADD`
    instructions recreate the shared library paths that the `hello` application expects
    in this new Docker image in the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now we have all the necessary files needed to run the new "binary-only" Docker
    image. In the end, the files in our directory tree will look similar to the following
    screenshot:![Separating build and deployment images](img/00006.jpeg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, build the deployable `binary` Docker image with the following `build/Dockerfile`.
    The resulting image will be smaller now:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The same approach can also be used to make other compiled applications, such
    as the software normally installed using the `./configure && make && make install`
    combinations. We can do the same for interpreted languages such as Python, Ruby,
    or PHP. However, it will need a little more work to create a "runtime" Ruby Docker
    image from a "build" Ruby Docker image. An example of a good time to perform this
    kind of optimization is when the delivery of our applications gets too long because
    the images are too big for a sustainable development workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you learned more about how Docker builds images and applied
    it to improve several factors, such as the deploy time, build time, and image
    size. The techniques specified in this chapter are not comprehensive; there will
    surely be more ways on how to achieve these objectives as more people discover
    how to use Docker for their applications. More techniques will also arise as Docker
    itself matures and develops more features. The most important guiding factor for
    these optimizations is to ask ourselves whether we are really getting the benefits
    of using Docker. Some good example questions to ask are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Is deploy time improving?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the development team getting feedback fast enough from what the operations
    team learned when running our application?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are we able to iterate on new features fast enough to incorporate the new feedback
    that we discovered from customers using our application?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By keeping in mind our motivation and objective of using Docker, we can come
    with our own ways to improve our workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Using some of the preceding optimizations will require updating the configuration
    of our Docker hosts. To be able to manage several Docker hosts at a scale, we
    will need some form of automation for their provisioning and configuration. In
    the next chapter, we will talk about how to automate setting up Docker hosts with
    configuration management software.
  prefs: []
  type: TYPE_NORMAL
