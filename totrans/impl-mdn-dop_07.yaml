- en: Docker Swarm and Kubernetes - Clustering Infrastructure
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker Swarm 和 Kubernetes - 集群基础设施
- en: So far, we have seen how powerful Docker is but we have not unleashed the full
    potential of containers. You have learned how to run containers on a single host
    with the local resources without the possibility of clustering our hardware resources
    in a way that allows us to uniformly use them as one big host. This has a lot
    of benefits, but the most obvious one is that we provide a middleware between
    developers and ops engineers that acts as a common language so that we don't need
    to go to the ops team and ask them for a machine of a given size. we just provide
    the definition of our service and the Docker clustering technology will take care
    of it.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了 Docker 的强大，但我们还没有释放容器的全部潜力。你已经学会了如何在单一主机上运行容器，并利用本地资源，但没有办法将我们的硬件资源以一种可以将其统一作为一个大主机来使用的方式进行集群。这带来了许多好处，但最明显的一点是，我们为开发人员和运维工程师之间提供了一个中间件，它作为一种通用语言，这样我们就不需要去找运维团队请求指定大小的机器了。我们只需提供我们的服务定义，Docker
    集群技术就会处理这些事情。
- en: In this chapter, we are going to dive deep into deploying and managing applications
    on Kubernetes, but we will also take a look at how Docker Swarm works.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨如何在 Kubernetes 上部署和管理应用程序，但我们也会看看 Docker Swarm 是如何工作的。
- en: 'People usually tend to see Kubernetes and Docker Swarm as competitors, but
    in my experience, they solve different problems:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 人们通常倾向于将 Kubernetes 和 Docker Swarm 视为竞争对手，但根据我的经验，它们解决的是不同的问题：
- en: '**Kubernetes** is focused on advanced microservices topologies that offer all
    the potential of years of experience running containers in Google'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes** 专注于先进的微服务拓扑，提供了多年的容器运行经验的全部潜力，源自 Google。'
- en: '**Docker Swarm** offers the most straightforward clustering capabilities for
    running applications in a very simple way'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker Swarm** 提供了最直接的集群能力，用于以非常简单的方式运行应用程序。'
- en: In short, Kubernetes is more suited for advanced applications, whereas Docker
    Swarm is a version of Docker on steroids.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，Kubernetes 更适合于高级应用，而 Docker Swarm 是一种增强版的 Docker。
- en: 'This comes at a cost: managing a Kubernetes cluster can be very hard, whereas
    managing a Docker Swarm cluster is fairly straightforward.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这有一个代价：管理 Kubernetes 集群可能非常困难，而管理 Docker Swarm 集群相对简单。
- en: There are other clustering technologies that are used in the current DevOps
    ecosystem, such as DC/OS or Nomad, but unfortunately, we need to focus on the
    ones that are, in my opinion, the most suited for DevOps and focus specifically
    on Kubernetes that, in my opinion, is eating the DevOps market.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的 DevOps 生态系统中还存在其他集群技术，如 DC/OS 或 Nomad，但不幸的是，我们需要关注那些在我看来最适合 DevOps 的技术，特别是
    Kubernetes，我认为它正在吞噬 DevOps 市场。
- en: Why clustering ?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要集群？
- en: In [Chapter 1](0b33ce27-d21e-4021-87ad-6865c65b7e33.xhtml), *DevOps in the Real
    World,* you learned about organizational alignment and why is important to shift
    roles in a company to accommodate DevOps tools. It is not okay anymore to just
    be a developer or a sysadmin; now you need to be a full stack DevOps engineer
    in order to get success in any project. Full stack DevOps means that you need
    to understand the business and the technology used in the organisation. Think
    about it; if you became a civil engineer instead of an IT engineer, it is mandatory
    to know the local rules (the business) plus the commercial names of the tools
    used to build roads and bridges (the technology) but also be able to coordinate
    their building (ops). Maybe not every engineer needs to know everything but they
    need to be aware of in the full picture in order to ensure the success of the
    project.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 1 章](0b33ce27-d21e-4021-87ad-6865c65b7e33.xhtml)《*现实世界中的 DevOps*》中，你学习了组织对齐以及为什么在公司中调整角色以适应
    DevOps 工具是如此重要。现在仅仅作为开发者或系统管理员已经不再足够；你现在需要成为一名全栈 DevOps 工程师，才能在任何项目中获得成功。全栈 DevOps
    意味着你需要理解企业和组织中使用的技术。想一想，如果你成为了一名土木工程师，而不是 IT 工程师，你必须了解当地的规则（业务），以及用于建造道路和桥梁的工具的商业名称（技术），同时还要能够协调它们的建设（运维）。也许并不是每个工程师都需要知道所有的内容，但他们需要了解整个图景，以确保项目的成功。
- en: Coming back to containers and DevOps, making concepts simple for everyone to
    understand is something that's mandatory nowadays. You want to ensure that all
    the engineers in your project are able to trace the software from conception (requirements)
    to deployment (ops) but also have in mind predictability so that the business
    people that barely speak tech are able to plan strategies around the products
    that you build.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 回到容器和 DevOps，今天让每个人都能理解的概念是必不可少的。你需要确保项目中的所有工程师都能够追溯软件的整个过程，从构思（需求）到部署（运维），同时也要考虑可预测性，这样那些几乎不懂技术的业务人员也能围绕你所构建的产品规划策略。
- en: 'One of the keys to achieving the flow described here is predictability, and
    the way to achieve predictability is making uniform and repeatable use of your
    resources. As you learned earlier, cloud data centers such as Amazon Web Services
    or Google Cloud Platform provide us with a virtually unlimited pool of resources
    that can be used to build our systems in a traditional way:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这里描述的流的关键之一是可预测性，而实现可预测性的方法是对资源进行统一和可重复的使用。正如你之前学到的那样，像 Amazon Web Services
    或 Google Cloud Platform 这样的云数据中心为我们提供了一个几乎无限的资源池，可以按照传统方式构建我们的系统：
- en: Define the size of the VMs
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义虚拟机的大小
- en: Provision VMs
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置虚拟机
- en: Install the software
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装软件
- en: Maintain it
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护它
- en: 'Or, if we want to draw a diagram so we can understand it better, it would be
    similar to the next one:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果我们想绘制一个图表，以便更好地理解，它将类似于下图：
- en: '![](img/a68c76ed-810f-4527-bbbc-c2226fefe7fc.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a68c76ed-810f-4527-bbbc-c2226fefe7fc.png)'
- en: 'Here are a few considerations:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几点需要考虑：
- en: Clear separation between Development and Operations (this may vary depending
    on the size of your company
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发和运维之间的明确分离（这可能会根据公司规模有所不同）
- en: Software components owned by Development and deployments and configuration owned
    by Operations
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由开发部门拥有的软件组件以及由运维部门拥有的部署和配置
- en: Some servers might be relatively underutilized (**Server 1**) and on a very
    low load
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些服务器可能相对低效（**服务器 1**），负载非常低
- en: 'This has been the picture for 40 odd years of software development, and it
    is still the picture if we are running Docker containers, but there are few problems
    in it:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是40多年来软件开发的情景，如果我们在运行 Docker 容器时仍然是这种情况，但其中有几个问题：
- en: If a problem arises in **Component 3** in production, who is responsible for
    it?
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果在生产环境中**组件 3**出现问题，谁负责处理？
- en: If there is a configuration mismatch, who will fix it if developers are not
    supposed to see what is going on in production?
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果配置不匹配，当开发人员不应该看到生产环境中的情况时，谁来修复它？
- en: '**Server 1** is running a software component that might be called only once
    or twice a day (imagine an authentication server for workstations); do we need
    a full VM just for it?'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务器 1**运行着一个可能一天只调用一次或两次的软件组件（比如工作站的认证服务器）；我们需要为它配置一个完整的虚拟机吗？'
- en: How do we scale our services in a transparent manner?
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何以透明的方式扩展我们的服务？
- en: 'These questions can be answered, but usually, they get an answer too late in
    the game plus "the hidden requirements" are only seen once the problems arise
    at the worst possible time:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题是可以解答的，但通常它们的答案往往来得太晚，而“隐藏的需求”只有在最糟糕的时刻才会显现出来：
- en: Service discovery
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务发现
- en: Load balancing
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负载均衡
- en: Self-healing infrastructure
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自愈基础设施
- en: Circuit breaking
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电路断开
- en: 'During college years, one of the things in common across all the different
    subjects was reusability and extensibility. Your software should be extensible
    and reusable so that we can potentially build libraries of components creating
    the engineering sweet spot (not just software development): build once, use everywhere.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在大学时期，所有不同学科的共同点之一是可重用性和可扩展性。你的软件应该具有可扩展性和可重用性，这样我们就可以创建组件库，形成工程的最佳实践（不仅仅是软件开发）：构建一次，到处使用。
- en: 'This has been completely overlooked in the operations part of the software
    development until recent years. If you get a job as a Java developer in a company,
    there is a set of accepted practices that every single Java developer in the world
    knows and makes use of so you can nearly hit the ground running without too many
    problems (in theory). Now let''s raise a question: if all the Java apps follow
    the same practices and set of common patterns, why does every single company deploy
    them in a different way?'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件开发的运维部分，这一点一直被完全忽视，直到近年来才开始受到重视。如果你在一家公司担任 Java 开发人员，那么有一套被世界上每一个 Java 开发人员接受并使用的实践，这样你几乎可以毫无问题地快速上手（理论上是这样）。现在我们提出一个问题：如果所有的
    Java 应用都遵循相同的实践和公共模式，为什么每家公司却以不同的方式部署它们？
- en: A continuous delivery pipeline has the same requirements in pretty much every
    company in the IT world, but I have seen at least three different ways of organizing
    it with a huge amount of custom magic happening that only one or two people within
    the company know of.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在 IT 世界中，持续交付流水线几乎每个公司都需要，但我见过至少三种不同的组织方式，而且这些方式背后有着大量只有一两个人知道的定制“魔法”。
- en: 'Clusters are here to save us. Let''s reshuffle the image from before:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 集群在这里拯救我们。让我们重新排列一下之前的图像：
- en: '![](img/9e0e0ad8-b84a-468c-bc50-e7d0bd7f2627.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9e0e0ad8-b84a-468c-bc50-e7d0bd7f2627.png)'
- en: 'In this case, we have solved few of our problems:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们解决了我们的一些问题：
- en: 'Now development and ops are connected via a middleware: the cluster.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，开发和运维通过中间件连接起来：集群。
- en: Components can be replicated (refer to component 1 and component 1') without
    provisioning extra hardware.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组件可以被复制（参考组件 1 和组件 1'），无需额外的硬件支持。
- en: DevOps engineers are the glue between the two teams (development and ops), making
    things happen at a fast pace.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DevOps 工程师是两个团队（开发和运维）之间的纽带，让事情以更快的节奏推进。
- en: 'The stability of the full system does not depend on a single server (or component)
    as the cluster is built in a way that can accept some level of failure by just
    degrading performance or taking down the less critical services: it is okay to
    sacrifice e-mailing in order to keep the accounting processes of the company running.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整个系统的稳定性并不依赖于单一服务器（或组件），因为集群是以能够接受一定程度故障的方式构建的，这样可以通过降低性能或关闭较不关键的服务来容忍故障：为了保持公司财务流程的正常运行，牺牲邮件服务是可以接受的。
- en: And about the hidden requirements. Well, this is where we need to make a decision
    about which clustering technology we want to use as they approach the service
    discovery, load balancing, and auto-scaling from different angles.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 说到隐藏的需求。这就是我们需要决定使用哪种集群技术的地方，因为它们从不同角度处理服务发现、负载均衡和自动扩展。
- en: Docker Swarm
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker Swarm
- en: As we have seen in previous chapters, Docker is a fantastic tool that follows
    the most modern architectural principles used for running applications packed
    as containers. In this case, Docker Swarm runs only Docker containers, ignoring
    other technologies that, at the moment, are not suitable for production, such
    as Rkt. Even Docker is quite new to the scene up to a point that some companies
    hesitate in deploying it in their production systems, as there is not so much
    expertise in the market as well as many doubts about security or how Docker works
    in general.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的章节中看到的，Docker 是一个非常棒的工具，它遵循了运行作为容器打包的应用的最现代的架构原则。在这种情况下，Docker Swarm
    仅运行 Docker 容器，忽略了其他目前不适用于生产环境的技术，比如 Rkt。甚至 Docker 本身也在某种程度上是新兴的，以至于一些公司在将其部署到生产系统时犹豫不决，因为市场上没有太多的专业知识，也存在许多关于安全性或
    Docker 工作原理的疑虑。
- en: '**Docker Swarm** is the clustered version of Docker, and it solves the problem
    described in the previous section in a very simple manner: pretty much all the
    docker commands that you learned in the Docker chapter works in Docker Swarm so
    that we can federate our hardware without actually taking care of the hardware
    itself. Just add nodes to the pool of resources and Swarm will take care of them,
    leveraging the way we build our systems to purely containers.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**Docker Swarm** 是 Docker 的集群版，它以非常简单的方式解决了上一节中描述的问题：几乎所有你在 Docker 章节中学到的 Docker
    命令都可以在 Docker Swarm 中使用，这样我们就可以在不直接管理硬件的情况下联邦化我们的硬件资源。只需将节点添加到资源池中，Swarm 就会管理它们，并充分利用我们构建纯容器系统的方式。'
- en: 'Docker Swarm is not something that we need to install aside from the Docker
    engine: it comes embedded into it and it is a mode rather than a server itself.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 不是我们需要单独安装的东西，它是嵌入在 Docker 引擎中的一种模式，而不是一个独立的服务器。
- en: Docker Swarm is evolving quite quickly and it is dragging Docker itself along
    as more and more features are being baked into it due to its usage in the Swarm
    mode. The most interesting part of this is how we can leverage our Docker knowledge
    into it without any extra as the swarm mode of our Docker engine takes care of
    the resources.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 正在快速发展，并且随着更多特性的加入，它正在带动 Docker 本身的发展，特别是在 Swarm 模式下使用时。最有趣的部分是，我们如何在没有额外操作的情况下利用我们的
    Docker 知识，因为 Docker 引擎的 Swarm 模式会自动处理资源。
- en: 'This is also a problem: we are limited by the Docker API, whereas with Kubernetes
    (we will come back to it in a second), we are not only limited by the Docker API,
    but we can also extend the Kubernetes API to add new objects to fulfill our needs.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是一个问题：我们受限于 Docker API，而在 Kubernetes 中（稍后我们会详细讲解），我们不仅不受 Docker API 的限制，还可以扩展
    Kubernetes API 来添加新对象，以满足我们的需求。
- en: Docker Swarm can be operated through `docker-compose` (up to a certain extent),
    which provides a decent approach to infrastructure as code but is not very comprehensive
    when our application is somehow complex.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 可以通过 `docker-compose` 进行操作（在一定程度上），它为基础设施即代码提供了一个不错的方案，但当我们的应用程序变得复杂时，它并不是特别全面。
- en: In the current IT market, Kubernetes seems to be the clear winner of the orchestration
    battle, and as such, we are going to focus on it, but if you want to learn more
    about Docker Swarm, the official documentation can be found at [https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前的 IT 市场中，Kubernetes 似乎是编排战斗的明显赢家，因此我们将重点关注它，但如果你想了解更多关于 Docker Swarm 的内容，可以参考官方文档，链接为
    [https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/)。
- en: Kubernetes
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes
- en: Kubernetes is the jewel of the crown of the containers orchestration. The product
    itself was vamped by Google leveraging years of knowledge on how to run containers
    in production. Initially, it was an internal system used to run Google services,
    but at some point, it became a public project. Nowadays, it is an open source
    project maintained by few companies (Red Hat, Google, and so on) and is used by
    thousands of companies.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是容器编排的皇冠上的明珠。该产品本身由 Google 利用多年的生产容器运行经验进行改进。最初，它是一个内部系统，用于运行 Google
    的服务，但在某个时刻，它成为了一个公开的项目。如今，它是一个由少数几家公司（如 Red Hat、Google 等）维护的开源项目，并被成千上万的公司使用。
- en: At the time of writing this, the demand for Kubernetes engineers has skyrocketed
    up to a point that companies are willing to hire people without expertise in the
    field but with a good attitude to learn new technologies.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Kubernetes 工程师的需求已经飙升，达到了公司愿意聘用那些虽然在该领域没有专业知识，但有良好学习态度的人来学习新技术的程度。
- en: 'Kubernetes has become so popular due to, in my opinion, the following factors:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为 Kubernetes 之所以变得如此流行，主要有以下几个原因：
- en: It solves all the deployment problems
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它解决了所有的部署问题
- en: It automates micro services' operations
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它自动化微服务的运维
- en: It provides a common language to connect ops and development with a clean interface
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了一种通用的语言，将运维和开发连接起来，拥有一个清晰的接口
- en: Once it is setup, it is very easy to operate
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦设置完成，它非常容易操作
- en: Nowadays, one of the biggest problems in companies that want to shorten the
    delivery life cycle is the **red tape that has grown around the delivery process**.
    Quarter releases are not acceptable anymore in a market where a company of five
    skilled engineers can overtake a classic bank due to the fact that they can cut
    the red tape and streamline a delivery process that allows them to release multiple
    times a day.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，许多公司希望缩短交付周期，而其中最大的一个问题就是**围绕交付过程积累的繁文缛节**。在一个市场中，五名熟练的工程师能够赶超传统银行，因为他们能够消除繁文缛节，简化交付流程，使得他们可以每天发布多次。
- en: 'One of my professional activities is to speak at conferences (meet-ups in Dublin,
    RebelCon in Cork, **Google Developer Groups** (**GDGs**) in multiple places, Google
    IO Extended) and I always use the same words in all the talks: release management
    should stop being a big bang event that stops the world for three hours in order
    to release a new version of your company''s application and **s**tart being a
    painless process that can be rolled back at any time so that we remove the majority
    of the stress from it by providing the tools to manage a faulty release.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我的职业活动之一是参加各种会议（在都柏林的聚会、科克的 RebelCon、多个地方的 **Google Developer Groups** (**GDGs**)、Google
    IO Extended），我在所有的演讲中总是使用相同的话语：发布管理应该不再是一个重大的事件，让整个世界停顿三小时才能发布公司应用的新版本，而应该变成一个无痛的过程，可以随时回滚，从而通过提供管理故障发布的工具来减轻大部分压力。
- en: 'This (not just this, but mainly this) is Kubernetes: a set of tools and virtual
    objects that will provide the engineers with a framework that can be used to streamline
    all the operations around our apps:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这（不仅仅是这个，但主要是这个）就是 Kubernetes：一套工具和虚拟对象，它们为工程师提供了一个框架，可以用来简化所有与我们应用相关的操作：
- en: Scale up
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展规模
- en: Scale down
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩减规模
- en: Zero downtime rollouts
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零停机发布
- en: Canary deployments
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 金丝雀发布
- en: Rollbacks
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回滚
- en: Secret management
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密钥管理
- en: 'Kubernetes is built in a technology-agnostic way. Docker is the main container
    engine, but all the components were designed with interchangeability in mind:
    once Rkt is ready, it will be easy to switch to Rkt from Docker, which gives an
    interesting perspective to the users as they don''t get tied to a technology in
    particular so that avoiding vendor locking becomes easier. This applies to the
    software defined network and other Kubernetes components as well.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是以技术无关的方式构建的。Docker 是主要的容器引擎，但所有组件都设计为具有可互换性：一旦 Rkt 就绪，切换到 Rkt 会很容易，这给用户带来了有趣的视角，因为他们不会被某一种特定技术绑定，这样避免供应商锁定就变得更加容易。这同样适用于软件定义网络和其他
    Kubernetes 组件。
- en: One of the pain points is the steep learning curve for setting it up as well
    as for using it.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一个痛点是设置和使用 Kubernetes 的陡峭学习曲线。
- en: Kubernetes is very complex, and being skilled in its API and operations can
    take any smart engineer a few weeks, if not months, but once you are proficient
    in it, the amount of time that you can save completely pays off all the time spent
    learning it.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 非常复杂，熟练掌握其 API 和操作可能需要几周，甚至几个月的时间，但一旦你精通它，你所节省的时间完全能够弥补所有学习所花费的时间。
- en: 'On the same way, setting up a cluster is not easy up to a point that companies
    have started selling Kubernetes as a service: they care about maintaining the
    cluster and you care about using it.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，设置集群并不容易，甚至有公司开始将 Kubernetes 作为一种服务出售：它们负责维护集群，你负责使用它。
- en: One of the (once again, in my opinion) most advanced providers for Kubernetes
    is the **Google Container Engine** (**GKE**), and it is the one that we are going
    to use for the examples in this book.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来（再次强调，这是我的个人看法），Kubernetes 的一个最先进的提供商是 **Google 容器引擎** (**GKE**)，这也是我们将在本书中用于示例的提供商。
- en: 'When I was planning the contents of this chapter, I had to make a decision
    between two items:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当我在规划本章内容时，我必须在两个选项之间做出决定：
- en: Setting up a cluster
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置集群
- en: Showing how to build applications around Kubernetes
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展示如何围绕 Kubernetes 构建应用程序
- en: 'I was thinking about it for a few days but then I realized something: there
    is a lot of information and about half a dozen methods to set up a cluster and
    none of them are official. Some of them are supported by the official Kubernetes
    GitHub repository, but there is no (at the time of writing this) official and
    preferred way of setting up a Kubernetes instance either on premises or in the
    cloud, so the method chosen to explain how to deploy the cluster might be obsolete
    by the time this book hits the market. The following options are the most common
    ways of setting up a Kubernetes cluster currently:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我考虑了几天，后来我意识到一件事：有大量的信息和大约半打方法来设置集群，而且没有一个是官方的。其中一些方法得到了官方 Kubernetes GitHub
    仓库的支持，但在撰写本文时（截至撰写时），并没有官方的、首选的设置 Kubernetes 实例的方法，无论是在本地还是在云端。因此，选择的讲解集群部署的方法可能在本书上市时已经过时。以下是目前最常见的设置
    Kubernetes 集群的方式：
- en: '**Kops**: The name stands for Kubernetes operations and it is a command-line
    interface for operating clusters: creating, destroying, and scaling them with
    a few commands.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kops**：这个名字代表 Kubernetes 操作，它是一个用于操作集群的命令行接口：通过几条命令创建、销毁和扩展集群。'
- en: '**Kubeadm**: Kubeadm is alpha at the moment and breaking changes can be integrated
    at any time into the source code. It brings the installation of Kubernetes to
    the execution of a simple command in every node that we want to incorporate to
    the cluster in the same way as we would do if it was Docker Swarm.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubeadm**：目前，Kubeadm 还处于 alpha 阶段，任何时候都可能会有破坏性更新集成到源代码中。它通过在每个我们希望加入集群的节点上执行简单的命令，简化了
    Kubernetes 的安装，就像我们使用 Docker Swarm 时的做法一样。'
- en: '**Tectonic**: Tectonic is a product from CoreOS to install Kubernetes in a
    number of providers (AWS, Open Stack, Azure) pretty much painlessly. It is free
    for clusters up to nine nodes and I would highly recommend that, at the very least,
    you play around it to learn about the cluster topology itself.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tectonic**：Tectonic 是 CoreOS 推出的一个产品，用于在多个云服务提供商（如 AWS、Open Stack、Azure）上轻松安装
    Kubernetes。它对于最多九个节点的集群是免费的，我强烈建议你至少尝试一下，以了解集群拓扑结构。'
- en: '**Ansible**: Kubernetes'' official repository also provides a set of playbooks
    to install a Kubernetes cluster on any VM provider as well as on bare metal.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ansible**：Kubernetes 官方仓库还提供了一套 playbooks，用于在任何虚拟机提供商或裸机上安装 Kubernetes 集群。'
- en: All of these options are very valid to set up a cluster from scratch as they
    automate parts of Kubernetes architecture by hiding the details and the full picture.
    If you really want to learn about the internals of Kubernetes, I would recommend
    a guide written by Kelsey Hightower called Kubernetes the hard way, which basically
    shows you how to set up everything around Kubernetes, from the etcd cluster needed
    to share information across nodes to the certificates used to communicate with
    `kubectl`, the remote control for Kubernetes. This guide can be found at [https://github.com/kelseyhightower/kubernetes-the-hard-way](https://github.com/kelseyhightower/kubernetes-the-hard-way).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些选项都是从头开始搭建集群的有效方法，因为它们通过隐藏细节和全貌，自动化了 Kubernetes 架构的部分内容。如果你真的想了解 Kubernetes
    的内部工作原理，我推荐 Kelsey Hightower 写的一本指南《Kubernetes the hard way》，它展示了如何围绕 Kubernetes
    设置一切，从需要在节点间共享信息的 etcd 集群，到用于与 `kubectl`（Kubernetes 的远程控制工具）通信的证书。你可以在 [https://github.com/kelseyhightower/kubernetes-the-hard-way](https://github.com/kelseyhightower/kubernetes-the-hard-way)
    找到这本指南。
- en: And it is maintained and up to date with new versions of Kubernetes.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 而且它会随着 Kubernetes 新版本的发布而更新。
- en: As you can guess from this explanation, in this chapter, you are going to learn
    about the architecture of Kubernetes, but mainly, we will focus on how to deploy
    and operate applications on Kubernetes so that by the end of this chapter, we
    have a good understanding of how we can benefit from an already running cluster.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从这个解释中可以猜到的，在这一章中，你将学习 Kubernetes 的架构，但主要，我们将专注于如何在 Kubernetes 上部署和操作应用程序，以便在本章结束时，我们能够充分理解如何从一个已经运行的集群中获益。
- en: Kubernetes logical architecture
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 逻辑架构
- en: The first problem that you will find once you start playing with Kubernetes
    is creating a mental map on how and where everything runs in Kubernetes as well
    as how everything is connected.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你开始使用 Kubernetes，你会发现第一个问题是如何在脑海中构建一个关于 Kubernetes 中一切如何运行以及如何连接的思维地图。
- en: 'In this case, it took me few weeks to fully understand how it all was wiring
    up, but once I had the picture in my mind, I drew something similar to what is
    shown in the following diagram:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我花了几周时间才完全理解这一切是如何连接的，但一旦我脑海中有了这个全貌，我画出了类似于下图所示的结构：
- en: '![](img/02b1c383-6951-4f06-a713-c3934fe10ace.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02b1c383-6951-4f06-a713-c3934fe10ace.png)'
- en: 'This is Kubernetes on a very high level: a master node that orchestrates the
    running of containers grouped in pods across different Nodes (they used to be
    called minions but not anymore).'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Kubernetes 的一个非常高层次的概述：一个主节点负责协调容器的运行，这些容器被分组在不同节点上的 pods 中运行（它们曾经被称为 minions，但现在已经不再使用这个术语）。
- en: 'This mental map helps us understand how everything is wired up and brings up
    a new concept: the pod. A pod is basically a set of one or more containers running
    in orchestration to achieve a single task. For example, think about a cache and
    a cache warmer: they can run in different containers but on the same pod so that
    the cache warmer can be packed as an individual application. We will come back
    to this later on.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这张思维地图帮助我们理解一切如何连接起来，并引入了一个新的概念：pod。Pod 本质上是一组一个或多个容器，它们在协同操作中执行单一任务。例如，想象一个缓存和一个缓存预热器：它们可以在不同的容器中运行，但在同一个
    pod 上，这样缓存预热器就可以作为一个独立应用程序来打包。我们稍后会再讨论这个概念。
- en: 'With this picture, we are also able to identify different physical components:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这张图，我们还能够识别出不同的物理组件：
- en: Master
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主节点
- en: Nodes
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点
- en: The master is the node that runs all support services such as DNS (for service
    discovery) as well as the API server that allows us to operate the cluster. Ideally,
    your cluster should have more than one master, but in my opinion, being able to
    recover a master quickly is more important than having a high availability configuration.
    After all, if the master goes down, usually, it is possible to keep everything
    running until we recover the master that usually is as simple as spawning a new
    VM (on the cloud) with the same template as the old master was using.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点是运行所有支持服务的节点，如DNS（用于服务发现）以及API服务器，允许我们操作集群。理想情况下，您的集群应该有多个主节点，但在我看来，能够快速恢复主节点比拥有高可用性配置更重要。毕竟，如果主节点宕机，通常可以保持一切正常运行，直到我们恢复主节点，通常只需生成一个使用与旧主节点相同模板的新VM（在云上）即可。
- en: It is also possible to have a master running with the IP Tables blocking connections
    to key ports so that it does not join the cluster and remove the IP Tables rules
    once you want the master to become the lead of your cluster.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以运行一个带有IP Tables阻止连接到关键端口的主节点，以防它加入集群，并在希望主节点成为集群领导时移除IP Tables规则。
- en: 'The nodes are basically workers: they follow instructions from the master in
    order to deploy and keep applications alive as per the specified configuration.
    They use a software called Kubelet, which is basically the Kubernetes agent that
    orchestrates the communication with the master.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 节点基本上是工作节点：它们根据指令从主节点部署和维持应用程序的运行，按照指定的配置。它们使用一个名为Kubelet的软件，这基本上是Kubernetes的代理程序，负责与主节点进行通信。
- en: 'Regarding the networking, there are two layers of network in here:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 关于网络，这里有两层网络：
- en: Hardware network
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件网络
- en: Software network
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件网络
- en: The hardware network is what we all know and that is used to interconnect the
    VMs on the cluster. It is defined in our cloud provider (AWS, Google Cloud Platform,
    and so on), and there is nothing special about it, just bear in mind that ideally,
    this network should be a high profile network (Gigabyte Ethernet) as the inter-node
    traffic can be quite high.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件网络是我们所熟知的，用于连接集群中的虚拟机（VM）。它在我们的云服务提供商（如AWS，Google Cloud Platform等）中定义，并没有什么特别之处，只需记住，理想情况下，这个网络应该是高性能网络（千兆以太网），因为节点间的流量可能会很大。
- en: The software network (or **Software Defined Network**, **SDN**) is a network
    that runs on top of Kubernetes middleware and is shared between all the nodes
    via **etcd**, which is basically a distributed key value storage that is used
    by Kubernetes as a coordination point to share information about several components.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 软件网络（或**软件定义网络，SDN**）是运行在Kubernetes中间件之上的网络，通过**etcd**与所有节点共享，etcd基本上是一种分布式键值存储，Kubernetes用它作为协调点来共享关于多个组件的信息。
- en: 'This SDN is used to interconnect the pods: the IPs are virtual IPs that do
    not really exist in the external network and only the nodes (and master) know
    about. They are used to rout the traffic across different nodes so that if an
    app on the node 1 needs to reach a pod living in the **Node 3**, with this network,
    the application will be able to reach it using the standard `http/tcp` stack.
    This network would look similar to what is shown in the following figure:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这个SDN用于连接各个Pod：IP地址是虚拟IP，不在外部网络中实际存在，只有节点（和主节点）知道。它们用于在不同节点之间路由流量，因此，如果节点1上的应用程序需要访问**节点3**上的Pod，使用这个网络，应用程序可以通过标准的`http/tcp`协议栈进行访问。这个网络看起来与下图类似：
- en: '![](img/6ff1c1a6-6e62-44c8-aeed-57a30964dedd.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6ff1c1a6-6e62-44c8-aeed-57a30964dedd.png)'
- en: 'Let''s explain this a bit:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简单解释一下这个网络结构：
- en: The addresses on the network 192.168.0.0/16 are the physical addresses. They
    are used to interconnect the VMs that compound the cluster.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络上的地址192.168.0.0/16是物理地址。它们用于连接组成集群的虚拟机（VM）。
- en: The addresses on the network 10.0.0.0/24 are the software defined network addresses.
    They are not reachable from outside the cluster and only the nodes are able to
    resolve these addresses and forward the traffic to the right target.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络上的地址10.0.0.0/24是软件定义网络地址。它们无法从集群外部访问，只有节点能够解析这些地址并将流量转发到正确的目标。
- en: Networking is a fairly important topic in Kubernetes, and currently, the most
    common bottleneck in performance is that traffic forwarding is common across nodes
    (we will come back to this later on in this chapter), and this causes extra inter-node
    traffic that might cause a general slowdown of the applications running in Kubernetes.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 网络是 Kubernetes 中一个相当重要的话题，目前性能瓶颈最常见的原因是节点之间的流量转发（我们将在本章稍后讨论），这会导致额外的节点间流量，从而可能导致
    Kubernetes 中运行的应用程序普遍变慢。
- en: In general and for now, this is all we need to know about the Kubernetes architecture.
    The main idea behind Kubernetes is to provide a uniform set of resources that
    can be used as a single computing unit with easy zero downtime operations. As
    of now, we really don't know how to use it, but the important thing is that we
    have a mental model of the big picture in a Kubernetes cluster.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，现阶段我们需要了解的 Kubernetes 架构就是这些。Kubernetes 的核心理念是提供一组统一的资源，这些资源可以作为一个单一的计算单元，支持零停机操作的简便实现。目前，我们还不清楚如何使用它，但重要的是我们已经有了对
    Kubernetes 集群整体架构的理解。
- en: Setting up a cluster in GCP
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 GCP 上设置集群
- en: The first thing we need to start playing with in Kubernetes is a cluster. There
    are several options, but we are going to use GKE as we have already signed for
    the trial and there should be enough credit in there for going through the full
    book.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 Kubernetes 中要开始操作的第一件事就是集群。虽然有多种选择，但我们将使用 GKE，因为我们已经注册了试用，并且账户里应该有足够的信用额度来完成整个书中的内容。
- en: Another option if you did not sign for the trial on GCP is Minikube. Minikube
    is an out-of-the-box, easy-to-install local cluster that runs on VMs and is a
    very good tool for experimenting with new features without being afraid of breaking
    something.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有在 GCP 上注册试用，另一个选择是 Minikube。Minikube 是一个开箱即用、易于安装的本地集群，它运行在虚拟机上，是一个非常好的工具，可以在不担心破坏任何东西的情况下尝试新特性。
- en: The Minikube project can be found at [https://github.com/kubernetes/minikube](https://github.com/kubernetes/minikube).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Minikube 项目可以在 [https://github.com/kubernetes/minikube](https://github.com/kubernetes/minikube)
    上找到。
- en: Its documentation is fairly comprehensive.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 它的文档相当全面。
- en: 'In order to create a cluster in GCP, the first thing we need to do is open
    the container engine in the online console in GCP that will show something similar
    to what is shown in the following screenshot:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在 GCP 上创建一个集群，首先我们需要做的是在 GCP 的在线控制台中打开容器引擎，它将显示类似于以下截图的内容：
- en: '![](img/317e21d3-388e-4dc9-b6bc-fc66f39a85c1.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/317e21d3-388e-4dc9-b6bc-fc66f39a85c1.png)'
- en: 'This means that you have no clusters at the moment. Click on the Create a container
    cluster button and fill in the following form:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你目前没有集群。点击“创建容器集群”按钮，并填写以下表单：
- en: '![](img/44a48f26-1eee-4542-b5fb-5ac6df3c3ce5.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/44a48f26-1eee-4542-b5fb-5ac6df3c3ce5.png)'
- en: 'Just a few considerations here:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几点需要考虑的事项：
- en: Give a comprehensive name to the cluster. In my case, I named it `testing-cluster`.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给集群起个全面的名字。在我的例子中，我命名为 `testing-cluster`。
- en: Choose a zone that is close to you geographically, in my case, `europe-west1-c`.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择一个地理位置上靠近你的区域，在我的例子中是 `europe-west1-c`。
- en: Regarding the cluster version, choose the default one. This is the version of
    Kubernetes that you want your cluster to run. It can be seamlessly upgraded later.
    Also, be aware that Kubernetes releases a new version every 2 months (apporximately),
    so by the time you are reading this book, it is most likely that there will be
    a more modern version available.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于集群版本，选择默认版本。这是你希望集群运行的 Kubernetes 版本，之后可以无缝升级。此外，请注意 Kubernetes 每大约两个月发布一个新版本，因此到你读这本书时，很可能会有更现代的版本可用。
- en: The machine type should also be the standard one (1 vCPU 3.75 GB of RAM).
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器类型也应该选择标准类型（1 个 vCPU，3.75 GB 的 RAM）。
- en: Size is the number of machines that we want to use in our cluster. Three is
    a good number for testing and it can also be increased (or decreased later on).
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群的规模是我们希望在集群中使用的机器数量。三台是测试的一个不错选择，也可以在以后增加或减少。
- en: Everything else should be default. Auto-upgrade and auto-repair are beta functionalities
    that I would hesitate to use in a production cluster yet. These two options allow
    GCP to take actions if there is a new version of Kubernetes available or one of
    the nodes breaks for some reason.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 其他内容应该是默认的。自动升级和自动修复是 Beta 功能，我现在还不建议在生产集群中使用。这两个选项允许 GCP 在有新版本的 Kubernetes
    发布或某个节点因某种原因发生故障时自动采取措施。
- en: 'Once the form is completed click on Create Cluster, and that is everything.
    Now Google is provisioning a cluster for us. In order to check what is going on,
    open the tab of the Compute Engine in the GCP and you should see something similar
    to what is shown in the following screenshot:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 填写完表单后，点击创建集群，这样就完成了。现在 Google 正在为我们配置一个集群。为了查看发生了什么，打开 GCP 中的 Compute Engine
    标签，你应该看到类似下面的截图：
- en: '![](img/2890b604-2b63-4fd3-97db-22e6d31a8fca.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2890b604-2b63-4fd3-97db-22e6d31a8fca.png)'
- en: Three machines have been created in the compute engine with the prefix "`gke-`",
    which means that they belong to the GKE, **K** is for **Kubernetes**. They are
    regular machines, and there's nothing special about them aside from the fact that
    Google has provisioned all the software required to set up a Kubernetes Node,
    but where is the master?
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 三台带有 "`gke-`" 前缀的机器已经在计算引擎中创建，这意味着它们属于 GKE，**K** 代表 **Kubernetes**。它们是普通机器，除了
    Google 已经配置好设置 Kubernetes 节点所需的所有软件外，没什么特别之处，但是主节点在哪里？
- en: 'Here is the interesting thing about running Kubernetes in Google Cloud Platform:
    they look after your master so there is no need to worry about the high availability
    or upgrading it as it is done automatically.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Google Cloud Platform 上运行 Kubernetes 的有趣之处在于：他们会管理你的主节点，因此你无需担心高可用性或升级问题，这些操作是自动完成的。
- en: 'The master of our cluster is hosting one of the key components of our whole
    cluster: the API server. All the operations in Kubernetes are done via the API
    server with a component called `kubectl`. Kubectl stands for Kubernetes Control
    and is basically a terminal program that you can install on your local machine
    (or in a continuous integration server), add the configuration for a given cluster,
    and start issuing commands to our cluster.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们集群的主节点托管着我们整个集群的关键组件之一：API 服务器。Kubernetes 中的所有操作都是通过 API 服务器与一个名为 `kubectl`
    的组件进行的。`kubectl` 代表 Kubernetes 控制，是一个终端程序，可以安装在本地机器（或持续集成服务器）上，添加给定集群的配置，然后开始向我们的集群发出命令。
- en: 'First, we are going to install `kubectl`. In the previous chapters, we already
    installed the Google Cloud SDK (`gcloud` command), which can be used to install
    `kubectl` with the following command:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将安装 `kubectl`。在前面的章节中，我们已经安装了 Google Cloud SDK（`gcloud` 命令），可以通过以下命令来安装
    `kubectl`：
- en: '[PRE0]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'And that''s it. Now we can use `kubectl` in our system as if it was any other
    command, but we need to add our cluster configuration. As of now, `kubectl` is
    not configured to operate our cluster, so the first thing we need to do is fetch
    the required configuration. Google Cloud Platform makes it very easy. If you open
    the Google Container Engine tab, it now should look similar to the following one:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。现在我们可以像使用任何其他命令一样在系统中使用 `kubectl`，但我们需要添加我们的集群配置。到目前为止，`kubectl` 并未配置为操作我们的集群，因此我们首先需要获取所需的配置。Google
    Cloud Platform 使这变得非常简单。如果你打开 Google Container Engine 标签页，它现在应该类似于下面的界面：
- en: '![](img/78bc4e64-e930-49b3-bd60-83a16b3d782b.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/78bc4e64-e930-49b3-bd60-83a16b3d782b.png)'
- en: 'As you can see, there is a button called Connect on the right-hand side of
    the screen. By clicking on it, you will be presented with the following form:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，屏幕右侧有一个名为“连接”的按钮。点击它后，你将看到如下表单：
- en: '![](img/4e2ca1a1-c476-4fe8-8241-9aacb15e9323.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4e2ca1a1-c476-4fe8-8241-9aacb15e9323.png)'
- en: 'The date in the form will be slightly different (as the name of your cluster
    and project will be different), but there are two commands presented in there:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 表单中的日期会略有不同（因为你的集群和项目的名称会不同），但表单中会显示两个命令：
- en: A `gcloud` command to get the configuration of our Kubernetes cluster in our
    local machine
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取本地机器上 Kubernetes 集群配置的 `gcloud` 命令
- en: A `kubectl` command to start the proxy into the Kuberentes Dashboard UI
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动代理到 Kubernetes Dashboard UI 的 `kubectl` 命令
- en: 'The first command is easy. Just execute it:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令很简单。只需执行它：
- en: '[PRE1]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And the output will be similar to the following one:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将类似于下面的内容：
- en: '[PRE2]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'So, what happened here is that `gcloud` fetched the configuration and installed
    it locally for us to operate the cluster. You can try this by running the following
    command:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，发生的情况是 `gcloud` 获取了配置并将其本地安装，以便我们可以操作集群。你可以通过运行以下命令来尝试：
- en: '[PRE3]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This will output the list of nodes in your cluster. Kubectl is a very extensive
    command-line tool. With it, we can do pretty much anything inside the cluster,
    as we will learn in the rest of this chapter.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出集群中节点的列表。Kubectl 是一个功能非常强大的命令行工具。通过它，我们几乎可以在集群内做任何事，正如我们将在本章的其余部分中学习的那样。
- en: 'The second command in the preceding screenshot is used to start a proxy in
    Kubernetes:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 前面截图中的第二个命令用于启动 Kubernetes 中的代理：
- en: '[PRE4]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will output the following:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出以下内容：
- en: '[PRE5]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Let's explain what happened here. Kubernetes makes heavy usage of client certificates.
    In order to communicate with the master, our machine needs to proxy the requests
    sending the certificate to validate them.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来解释一下这里发生了什么。Kubernetes 强烈依赖客户端证书。为了与主节点通信，我们的机器需要代理请求并发送证书来验证它们。
- en: 'So, if we browse to the URL in the preceding screenshot now, `http://localhost:8001/ui`,
    we get presented with the Kubernetes dashboard:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果我们现在浏览前面截图中的 URL，`http://localhost:8001/ui`，我们会看到 Kubernetes 仪表盘：
- en: '![](img/6f4986fd-fc75-4ae3-82d9-4d605efc0768.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f4986fd-fc75-4ae3-82d9-4d605efc0768.png)'
- en: The dashboard is basically a nice way of presenting all the information of our
    running cluster to the end users. It is also possible to operate the cluster up
    to a certain extent from the dashboard, but my recommendation will be to master
    `kubectl` as it is way more powerful. On the dashboard, we can see a lot of information,
    such as the state of the nodes, the items deployed into the cluster (Pods, Replica
    Sets, Daemon Sets, and so on), and the namespaces as well as many other elements.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表盘基本上是一个很好的方式，用于展示我们运行的集群中的所有信息。虽然也可以通过仪表盘操作集群（到一定程度），但我的建议是精通`kubectl`，因为它要强大得多。在仪表盘上，我们可以看到很多信息，比如节点的状态、部署到集群中的项目（Pods、Replica
    Sets、Daemon Sets 等）、命名空间以及其他许多元素。
- en: Explore around a bit and get yourself familiar with the dashboard as it is a
    nice tool to actually see things happening in your cluster.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 四处浏览一下，熟悉一下仪表盘，因为它是一个很好的工具，能够让你实际看到集群中发生的事情。
- en: 'Kubernetes divides the workloads into namespaces. A namespace is a virtual
    cluster that allows the engineers to segregate resources (up to a point) across
    different teams. It is also used by Kubernetes to run its own internal components.
    This is important because Kubernetes spreads the key components across different
    nodes to ensure high availability. In this case, we have three components that
    are running on every node:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 将工作负载划分为命名空间。命名空间是一个虚拟集群，允许工程师在不同团队之间隔离资源（在一定程度上）。Kubernetes 也利用命名空间来运行其内部组件。这一点非常重要，因为
    Kubernetes 将关键组件分布在不同的节点上，以确保高可用性。在这种情况下，我们有三个组件在每个节点上运行：
- en: The Kubernetes dashboard
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 仪表盘
- en: Kubernetes proxy (`kube-proxy`)
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 代理（`kube-proxy`）
- en: Kubernetes DNS (`kube-dns`)
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes DNS（`kube-dns`）
- en: 'The Kubernetes dashboard is what we just have seen: a user interface to represent
    the information within the Kubernetes cluster.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 仪表盘就是我们刚刚看到的：一个用户界面，用于展示 Kubernetes 集群中的信息。
- en: Kubernetes proxy is a proxy that the nodes use to resolve IP addresses in the
    SDN from Pods addresses to node addresses so that the cluster is able to redirect
    the traffic to the right Node.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 代理是节点用来从 Pod 地址到节点地址解析 SDN 中的 IP 地址的代理，以便集群能够将流量重定向到正确的节点。
- en: The Kubernetes DNS is basically a load balancing and service discovery mechanism.
    In the next section, you will learn about the building blocks that we can use
    for deploying applications to Kubernetes. In particular, Services are strongly
    coupled with this DNS service in a way that in order to locate an application
    within Kubernetes, we just need to know its name and the configuration of the
    Service that groups the Pods compounding the given application.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes DNS 基本上是一个负载均衡和服务发现机制。在接下来的部分中，你将学习如何使用 Kubernetes 中的构建块来部署应用程序。特别是，Services
    与此 DNS 服务紧密耦合，为了在 Kubernetes 中定位一个应用程序，我们只需要知道它的名称以及配置该服务的服务配置，从而将组成该应用程序的 Pods
    聚合在一起。
- en: 'The fact that we are running these components in every node enables Kubernetes
    to enter into an autopilot mode in case of a master going down: applications will
    continue working (in the majority of the cases) even without a master, so losing
    a master is not a catastrophic event.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在每个节点上运行这些组件的事实使得 Kubernetes 能够进入自动驾驶模式，以应对主节点宕机的情况：即使没有主节点，应用程序也能继续工作（在大多数情况下），因此丢失主节点并不是灾难性事件。
- en: Once we have configured `kubectl` in our machines, it is time to learn about
    the building blocks that we can use in Kubernetes in order to build extremely
    robust applications.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们在机器上配置了`kubectl`，就可以开始了解 Kubernetes 中的一些构建块，从而构建非常健壮的应用程序。
- en: Kubernetes building blocks
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 构建块
- en: 'In the preceding section, you learned about the cluster topology, but now we
    need the tools to run applications on it. We have already introduced one of the
    Kubernetes building blocks: the Pod. In this section, we are going to look at
    some of the most important API objects (building blocks) that Kubernetes provide
    in order to build our applications.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，您已经了解了集群拓扑，但现在我们需要工具来在其上运行应用程序。我们已经介绍了 Kubernetes 构建块之一：Pod。在本节中，我们将看一些
    Kubernetes 提供的最重要的 API 对象（构建块），以便构建我们的应用程序。
- en: 'When I started learning Kubernetes, I was working in the second company that
    was deploying applications in a continuous delivery way, and I always had a question
    in mind: why are different companies trying to solve the same problem in different
    ways?'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始学习 Kubernetes 时，我在第二家公司工作，他们以持续交付方式部署应用程序，我一直心里有一个问题：为什么不同的公司试图以不同的方式解决同样的问题？
- en: 'Then I realized why: The element missing was the domain-specific language for
    continuous delivery. The lack of a common standard and well understood way of
    rolling out applications was preventing them to work efficiently and deliver value
    early in the chain. Everybody knows what a load balancer is or a proxy or many
    other elements that are involved in the deployment of a new version of an app,
    but the way people uses the in, say, imaginative ways is where the problem lies.
    If you hire a new engineer, their previous knowledge of continuous delivery becomes
    obsolete as they need to learn your way of doing things.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 后来我意识到：缺失的元素是持续交付的领域特定语言。缺乏共同的标准和良好理解的应用程序推出方式，阻碍了它们有效工作和早期交付价值。每个人都知道什么是负载均衡器或代理，以及在应用程序的新版本部署中涉及的许多其他元素，但问题所在是人们使用它们的方式不尽相同。如果您雇用新工程师，他们以前对持续交付的了解将变得过时，因为他们需要学习您的做事方式。
- en: Kubernetes solves this problem with a set of objects (Pods, ReplicaSets, DameonSets,
    and so on) that are described in YAML files (or JSON). Once we finish this section,
    we will already have enough knowledge to be able to, from the YAML or JSON files
    defining our resources, build a diagram about what the system looks like. These
    files, alongside the Docker images, are enough for Kubernetes to run our system,
    and we will look at a few examples.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 通过一组对象（Pod、ReplicaSets、DameonSets 等）解决了这个问题，这些对象在 YAML 文件（或 JSON）中描述。一旦我们完成本节，我们将已经具备足够的知识，可以从定义我们资源的
    YAML 或 JSON 文件中构建一个关于系统外观的图表。这些文件和 Docker 镜像足以让 Kubernetes 运行我们的系统，我们将看几个例子。
- en: Pods
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pods
- en: Pods are the most basic element of the Kubernetes API. A Pod basically is a
    set of containers that work together in order to provide a service or part of
    it. The concept of Pod is something that can be misleading. The fact that we can
    run several containers working together suggests that we should be sticking the
    frontend and backend of our application on a single pod as they work together.
    Even though we can do this, it is a practice that I would strongly suggest you
    avoid. The reason for this is that by bundling together the frontend and the backend,
    we are losing a lot of flexibility that Kubernetes is providing us with, such
    as autoscaling, load balancing, or canary deployments.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 是 Kubernetes API 的最基本元素。一个 Pod 基本上是一组共同工作的容器，以提供服务的全部或部分。Pod 的概念可能会引起误解。我们可以运行多个共同工作的容器，这表明我们应该将应用程序的前端和后端放在单个
    Pod 中。尽管我们可以这样做，但我强烈建议您避免这样做。原因是将前端和后端捆绑在一起会丧失 Kubernetes 提供的许多灵活性，如自动缩放、负载均衡或金丝雀部署。
- en: 'In general, pods contain a single container and it is, by far, the most common
    use case, but there are few legitimate use cases for multi-container pods:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 一般情况下，Pod 包含一个单一容器，这是迄今为止最常见的用例，但是多容器 Pod 有一些合法的使用案例：
- en: Cache and cache warmer
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存与缓存预热
- en: Precalculating and serving HTML pages
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预计算和提供 HTML 页面
- en: File upload and file processing
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件上传与文件处理
- en: As you can see, all of these are activities that are strongly coupled together,
    but if the feeling is that the containers within a pod are working toward different
    tasks (such as backend and frontend), it might be worth placing them in different
    Pods.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，所有这些活动都是紧密耦合在一起的，但如果 Pod 内部容器的感觉是它们朝着不同的任务（如后端和前端）工作，可能值得将它们放在不同的 Pods
    中。
- en: 'There are two options for communication between containers inside a pod:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Pod 内部容器之间进行通信有两个选项：
- en: Filesystem
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件系统
- en: Local network interface
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地网络接口
- en: 'As Pods are indivisible elements running on a single machine, volumes mounted
    in all the containers of a pod are shared: files created in a container within
    a pod can be accessed from other containers mounting the same volume.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Pod是不可分割的元素，且运行在同一台机器上，所有挂载在Pod内容器中的卷是共享的：在Pod中的一个容器创建的文件，可以通过挂载相同卷的其他容器访问。
- en: The local network interface or loopback is what we commonly know as localhost.
    Containers inside a pod share the same network interface; therefore, they can
    communicate via localhost (or `127.0.0.1`) on the exposed ports.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 本地网络接口或回环接口就是我们常说的localhost。Pod中的容器共享相同的网络接口；因此，它们可以通过localhost（或`127.0.0.1`）在暴露的端口上进行通信。
- en: Deploying a pod
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署一个pod
- en: 'As mentioned earlier, Kubernetes relies heavily on **Yet Another Markup Language**
    (**YAML**) files to configure API elements. In order to deploy a pod, we need
    to create a yaml file, but first, just create a folder called **deployments**,
    where we are going to create all the descriptors that we will be created on this
    section. Create a file called `pod.yaml` (or `pod.yml`) with the following content:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Kubernetes在配置API元素时依赖于**Yet Another Markup Language**（**YAML**）文件。为了部署一个pod，我们需要创建一个yaml文件，但首先，创建一个名为**deployments**的文件夹，在其中创建我们将在本节中创建的所有描述符。创建一个名为`pod.yaml`（或`pod.yml`）的文件，内容如下：
- en: '[PRE6]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As you can see, the preceding `yaml` is fairly descriptive, but some points
    need clarification:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，前面的`yaml`文件相当具有描述性，但有些点需要进一步说明：
- en: '`apiVersion`: This is the version of the Kubernetes API that we are going to
    use to define our resource (in this case, pod). Kuberentes is a living project
    that evolves very quickly. The version is the mechanism used to avoid deprecating
    resources with new releases. In general, Kuberentes works with three branches:
    alpha, beta, and stable. In the preceding case, we are using the stable version.
    More information can be found at [https://kubernetes.io/docs/concepts/overview/kubernetes-api/](https://kubernetes.io/docs/concepts/overview/kubernetes-api/).'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apiVersion`：这是我们将要使用的Kubernetes API版本，用来定义我们的资源（在此情况下为pod）。Kubernetes是一个快速发展的项目，版本是避免在新版本发布时弃用资源的机制。一般来说，Kubernetes有三个分支：alpha、beta和稳定版本。在前述例子中，我们使用的是稳定版。更多信息请参见[https://kubernetes.io/docs/concepts/overview/kubernetes-api/](https://kubernetes.io/docs/concepts/overview/kubernetes-api/)。'
- en: '`metadata`: In this section, we are defining one of the most powerful discovery
    mechanisms that I have ever seen: the pattern matching. The section label, specifically,
    will be used later on to expose pods with certain **l**abels to the outer world.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata`：在这一部分，我们定义了我见过的最强大的发现机制之一：模式匹配。特别是，标签部分将在后续用于将具有特定**标签**的pods暴露给外部。'
- en: '`spec`: This is where we define our container. In this case, we are deploying
    an `nginx` instance so that we can easily see how everything works without focusing
    too much on the application itself. As expected, the image and the exposed port
    have been specified. We have also defined the CPU and memory limitations for this
    Pod, so we prevent an outbreak in resource consumption (note that the YAML file
    is requesting the resources; they might not be available so the pod will operate
    with lower profile resources).'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spec`：在这里，我们定义我们的容器。在此情况下，我们部署了一个`nginx`实例，以便我们可以轻松看到一切是如何工作的，而不需要过多关注应用程序本身。正如预期的那样，镜像和暴露的端口已被指定。我们还为该Pod定义了CPU和内存限制，以防资源消耗失控（注意，YAML文件请求的资源可能不可用，因此pod将使用较低配置的资源运行）。'
- en: 'This is the simplest configuration for an item that we can create in Kubernetes.
    Now it''s time to deploy the resource in our cluster:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们可以在Kubernetes中创建的最简单配置项。现在是时候将资源部署到我们的集群中了：
- en: '[PRE7]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This will produce an output similar to the following one:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生类似如下的输出：
- en: '[PRE8]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Disclaimer: there are several ways of creating a resource, but in this book,
    I will use `apply` as much as possible. Another possibility would be to use `create`:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 免责声明：创建资源的方式有很多种，但在本书中，我将尽可能使用`apply`。另一种可能的方式是使用`create`：
- en: '[PRE9]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The advantage that `apply` has over create is that apply does a three-way diff
    between the previous version, the current version, and the changes that you want
    to apply and decides how is best to update the resource. This is letting Kubernetes
    do what it does best: automate container orchestration.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`apply`相较于`create`的优势在于，`apply`会对比以前的版本、当前版本以及你想要应用的更改，进行三方差异比较，并决定如何最好地更新资源。这让Kubernetes能够做它最擅长的事：自动化容器编排。'
- en: 'With create, Kubernetes does not save the state of the resource, and if we
    want to run apply afterward in order to gracefully change the state of a resource,
    a warning is produced:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 create，Kubernetes 不会保存资源的状态，如果我们希望随后运行 apply 以优雅地更改资源的状态，系统会发出警告：
- en: '[PRE10]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This means that we can push our system to an unstable state for few seconds,
    which might not be acceptable depending on your use case.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可以将系统推向不稳定状态几秒钟，这在某些使用场景中可能是不可接受的。
- en: 'Once we have applied our YAML file, we can use `kubectl` to see what is going
    on in Kubernetes. Execute the following command:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们应用了我们的 YAML 文件，我们可以使用`kubectl`查看 Kubernetes 中的情况。执行以下命令：
- en: '[PRE11]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This will output our pod:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出我们的 Pod：
- en: '![](img/2a6b0b4e-706a-4686-b11f-43592c818f96.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a6b0b4e-706a-4686-b11f-43592c818f96.png)'
- en: 'We can do this for other elements of our cluster, such as the nodes:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对集群中的其他元素进行类似操作，比如节点：
- en: '[PRE12]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And this will output the following:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出以下内容：
- en: '![](img/d4b67f6b-c276-4f97-917e-e1e95b2eeb2b.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4b67f6b-c276-4f97-917e-e1e95b2eeb2b.png)'
- en: The `kubectl get` works for all the workflows in Kubernetes and the majority
    of the API objects.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl get`适用于 Kubernetes 中的所有工作流以及大多数 API 对象。'
- en: Another way of seeing what is going on in Kubernetes is using the dashboard.
    Now that we have created a pod, open the dashboard at `http://localhost:8001/ui`
    and navigate to the pods section on the left-hand side.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 Kubernetes 中发生的事情的另一种方式是使用仪表盘。现在我们已经创建了一个 Pod，打开`http://localhost:8001/ui`并在左侧导航到
    Pod 部分。
- en: Remember that in order to access the dashboard, first, you need to execute `kubectl
    proxy` on a Terminal.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，要访问仪表盘，你首先需要在终端执行`kubectl proxy`。
- en: 'There; you will see the list of the current deployed pods, in this case, just
    nginx. Click on it and the screen should look very similar to what is shown here:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在那里，你将看到当前已部署的 Pod 列表，这里只有 nginx。点击它，屏幕应该与这里展示的非常相似：
- en: '![](img/15fd80e2-8bb2-4d68-830f-ffb7d6fb62a8.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](img/15fd80e2-8bb2-4d68-830f-ffb7d6fb62a8.png)'
- en: 'Here, we get a ton of information, from the memory and CPU that the pod is
    consuming to the node where it is running and a few other valuable items, such
    as the annotations applied to the pod. We can get this using the ''`describe`''
    command of `kubectl`, as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以获取大量信息，从 Pod 正在消耗的内存和 CPU 到它运行的节点，还有一些其他有价值的项目，比如应用到 Pod 上的注解。我们可以使用`kubectl
    describe`命令来获取这些信息，如下所示：
- en: '[PRE13]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Annotations are a new concept and are the data around our API element, in this
    case, our pod. If you click on Last applied configuration in the Details section,
    you can see the data from the YAML file, as shown in the following screenshot:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 注解是一个新概念，它是围绕我们的 API 元素的数据，在这种情况下是我们的 Pod。如果你点击“最后应用的配置”在详情部分，你可以看到来自 YAML 文件的数据，如下图所示：
- en: '![](img/9577ed4e-2e88-4681-aeaf-42ca6d67379e.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9577ed4e-2e88-4681-aeaf-42ca6d67379e.png)'
- en: And this relates to the three-way diff that was explained earlier and is used
    by Kubernetes to decide the best way of upgrading a resource without getting into
    an inconsistent state.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这与之前解释的三方差异（three-way diff）有关，Kubernetes 使用它来决定在不进入不一致状态的情况下升级资源的最佳方式。
- en: 'As of now, our pod is running in Kubernetes but is not connected to the outer
    world; therefore, there is no way to open a browser and navigate to the nginx
    home page from outside the cluster. One thing that we can do is open a remote
    session to a bash Terminal in the container inside the pod in a manner similar
    to what we would do with Docker:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 截至目前，我们的 Pod 正在 Kubernetes 中运行，但尚未连接到外部世界；因此，无法从集群外部打开浏览器并导航到 nginx 首页。我们可以做的一件事是打开一个远程会话，进入
    Pod 内容器的 bash 终端，方式类似于我们在 Docker 中的操作：
- en: '[PRE14]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: And we are in. Effectively, we have gained access to a root terminal inside
    our container and we can execute any command. We will use this functionality later
    on.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进入了。实际上，我们已经获得了容器内根终端的访问权限，可以执行任何命令。我们稍后会使用这个功能。
- en: 'Once we have seen how pods work, you might have a few questions abound what
    Kubernetes is supposed to do:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们了解了 Pod 的工作原理，你可能会有一些关于 Kubernetes 应该做什么的问题：
- en: How can we scale pods?
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何扩展 Pod？
- en: How can we roll out new versions of an application?
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何发布应用程序的新版本？
- en: How can we access our application?
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何访问我们的应用程序？
- en: We will answer all these questions, but first, we need to know other 'building
    blocks'.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将回答所有这些问题，但首先，我们需要了解其他的“构建模块”。
- en: Replica Sets
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 副本集
- en: So far, we know how to deploy applications in pods. The sole concept of pod
    is very powerful, but it lacks robustness. It is actually impossible to define
    scaling policies or even make sure that the pods remain alive if something happens
    (such as a node going down). This might be okay in some situations, but here is
    an interesting question. If we are biting the bullet on the overhead of maintaining
    a Kubernetes cluster, why don't we take the benefits of it?
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们知道如何在pod中部署应用。单个pod的概念非常强大，但它缺乏鲁棒性。实际上，无法定义扩展策略，甚至无法确保在发生故障（例如节点宕机）时pod能够保持存活。在某些情况下这可能没问题，但这里有一个有趣的问题。如果我们已经承担了维护Kubernetes集群的开销，为什么不充分利用它的优势呢？
- en: 'In order to do that, we need to work with **Replica Sets**. A Replica Set is
    like a traffic cop in a road full of pods: they make sure that the traffic flows
    and everything works without crashing and moving the pods around so that we make
    the best use of the road (our cluster, in this case).'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们需要使用**Replica Sets**。Replica Set就像一位在满是pod的道路上的交通警察：它们确保交通流畅，一切正常运作，避免崩溃，并移动pod以便最大化利用道路（在这种情况下是我们的集群）。
- en: 'Replica Sets are actually an update of a much older item: the Replication Controller.
    The reason for the upgrade is the labeling and selecting of resources, which we
    will see visit when we dive deep into the API item called Service.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: Replica Sets实际上是对更早期的一个项目——Replication Controller的更新。升级的原因是标签和资源选择的功能，这一点我们将在深入探讨名为Service的API项目时看到。
- en: 'Let''s take a look at a Replica Set:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下Replica Set：
- en: '[PRE15]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Again, this a YAML file that is basically fairly easy to understand but might
    require some explanation:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，这是一个YAML文件，基本上是相当容易理解的，但可能需要一些解释：
- en: 'In this case, we have used the extensions API on the version `v1beta1`. If
    you remember from the pod section (previously), Kubernetes has three branches:
    stable, alpha, and beta. The complete reference can be found in the official documentation,
    and it is very likely to change often as Kubernetes is a vibrant and always evolving
    project.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这种情况下，我们使用了`v1beta1`版本的扩展API。如果你还记得pod部分（前面提到过），Kubernetes有三个分支：stable、alpha和beta。完整的参考可以在官方文档中找到，并且由于Kubernetes是一个充满活力且始终在发展的项目，API很可能经常变化。
- en: 'In the spec section is where the important things happen: we have defined a
    set of labels for the Replica Set, but we have also defined a pod (in this case,
    with a single container) and specified that we want three instances of it (replicas:
    three).'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在spec部分发生了重要的事情：我们为Replica Set定义了一组标签，同时还定义了一个pod（在这个例子中，是一个单容器的pod），并指定我们希望它有三个实例（replicas：三）。
- en: Simple and effective. Now we have defined a resource called Replica Set, which
    allows us to deploy a pod and keep it alive as per configuration.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 简单而有效。现在我们定义了一个名为Replica Set的资源，它可以根据配置部署一个pod并保持它的存活。
- en: 'Let''s test it:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来测试一下：
- en: '[PRE16]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Once the command returns, we should see the following message:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦命令返回，我们应该看到以下消息：
- en: '[PRE17]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let''s verify it using `kubectl`:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用`kubectl`来验证它：
- en: '[PRE18]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'As the output of the preceding command, you should see the Replica Set explaining
    that there are three desired pods, three actually deployed, and three ready. Note
    the difference between current and ready: a pod might be deployed but still not
    ready to process requests.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的命令输出，你应该看到Replica Set说明有三个预期的pod，三个已经部署，并且三个准备就绪。注意“current”和“ready”之间的区别：一个pod可能已经部署，但仍未准备好处理请求。
- en: 'We have specified that our `replicaset` should keep three pods alive. Let''s
    verify this:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已指定我们的`replicaset`应该保持三个pod存活。让我们来验证一下：
- en: '[PRE19]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'No surprises here: our `replicaset` has created three pods, as shown in the
    following screenshot:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有惊讶：我们的`replicaset`创建了三个pod，如下图所示：
- en: '![](img/f1055e82-5872-477b-91a8-6d200347d72b.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f1055e82-5872-477b-91a8-6d200347d72b.png)'
- en: 'We have four pods:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有四个pod：
- en: One created in the preceding section
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在前面部分创建的一个
- en: Three created by the Replica Set
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Replica Set创建的三个
- en: 'Let''s kill one of the pods and see what happens:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们杀掉一个pod，看看会发生什么：
- en: '[PRE20]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'And now, query how many pods are running:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，查询一下运行了多少个pod：
- en: '![](img/508833b4-48b0-4dc0-a0e4-119ead927a8e.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![](img/508833b4-48b0-4dc0-a0e4-119ead927a8e.png)'
- en: Bingo! Our `replicaset` has created a new pod (you can see which one in the
    AGE column). This is immensely powerful. We have gone from a world where a pod
    (an application) being killed wakes you up at 4 a.m. in the morning to take action
    to a world where when one of our application dies, Kubernetes revives it for us.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 轰！我们的`replicaset`创建了一个新的 Pod（你可以在 AGE 列中看到是哪一个）。这非常强大。我们从一个 Pod（应用程序）被杀掉时，你会在早上
    4 点醒来采取措施的世界，转变为一个当我们的应用程序崩溃时，Kubernetes 会为我们恢复它的世界。
- en: 'Let''s take a look at what happened in the dashboard:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看仪表盘中发生了什么：
- en: '![](img/5bf89559-f168-4880-bac5-c038679168b7.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5bf89559-f168-4880-bac5-c038679168b7.png)'
- en: As you can expect, the Replica Set has created the pods for you. You can try
    to kill them from the interface as well (the period icon to the very right of
    every pod will allow you to do that), but the Replica Set will re-spawn them for
    you.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所预期的，Replica Set 为你创建了 Pods。你也可以尝试通过界面杀死它们（每个 Pod 最右边的周期图标允许你这么做），但是 Replica
    Set 会为你重新生成它们。
- en: 'Now we are going to do something that might look like it''s from out of this
    world: we are going to scale our application with a single command, but first,
    edit `replicaset.yml` and change the `replicas` field from three to five.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们要做一些看起来像是来自外太空的事情：我们将通过一个命令来扩展我们的应用程序，但首先，编辑 `replicaset.yml` 并将 `replicas`
    字段从 3 改为 5。
- en: 'Save the file and execute this:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 保存文件并执行以下命令：
- en: '[PRE21]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now take a look at the dashboard again:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 现在再看看仪表盘：
- en: '![](img/8f92bebd-c741-495b-a01b-3b9be7fb475d.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f92bebd-c741-495b-a01b-3b9be7fb475d.png)'
- en: As you can see, Kubernetes is creating pods for us following the instructions
    of the Replica Set, `nginx-rs`. In the preceding sreenshot, we can see one pod
    whose icon is not green, and that is because its status is Pending, but after
    a few seconds, the status becomes Ready, just like any other pod.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，Kubernetes 正在根据 Replica Set `nginx-rs` 的指示为我们创建 Pods。在上面的截图中，我们可以看到一个 Pod，其图标没有变绿，因为它的状态是
    Pending，但几秒钟后，它的状态变为 Ready，就像其他任何 Pod 一样。
- en: 'This is also very powerful, but there is a catch: who scales the application
    if the load spike happens at 4 a.m. in the morning? Well, Kubernetes provides
    a solution for this: Horizontal Pod Autoscalers.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是非常强大的，但有一个问题：如果负载高峰发生在早上 4 点钟，谁来扩展应用程序？好吧，Kubernetes 为此提供了解决方案：水平 Pod 自动扩展器。
- en: 'Let''s execute the following command:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下命令：
- en: '[PRE22]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'With the preceding command, we have specified that Kubernetes should attach
    a Horizontal Pod Autoscalers to our Replica Set. If you browse the Replica Set
    in the dashboard again, the situation has changed dramatically:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 通过上述命令，我们指定 Kubernetes 应该将水平 Pod 自动扩展器附加到我们的 Replica Set。如果你再次浏览仪表盘中的 Replica
    Set，情况已经发生了显著变化：
- en: '![](img/6f948bb0-7e82-4b40-b53e-dc9d12fac20f.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f948bb0-7e82-4b40-b53e-dc9d12fac20f.png)'
- en: 'Let''s explain what happened here:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释一下这里发生了什么：
- en: 'We have attached an Horizontal Pod Autoscalers to our Replica Set: minimum
    `1` pod, maximum `10`, and the trigger for creating or destroying pods is the
    CPU utilization going over `80%` on a given pod.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经将水平 Pod 自动扩展器附加到我们的 Replica Set：最小 `1` 个 Pod，最大 `10` 个，创建或销毁 Pods 的触发条件是某个
    Pod 的 CPU 使用率超过 `80%`。
- en: The Replica Set has scaled down to one pod because there is no load on the system,
    but it will scale back to up to 10 nodes if required and stay there for as long
    as the burst of requests is going on and scale back to the minimum required resources.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Replica Set 已经缩减到一个 Pod，因为系统没有负载，但如果需要，它会扩展回最多 10 个节点，并在请求高峰期间保持在此状态，之后会缩减到最低所需的资源。
- en: 'Now this is actually the dream of any sysadmin: no-hassle autoscaling and self-healing
    infrastructure. As you can see, Kubernetes starts making sense altogether, but
    there is one thing disturbing in the autoscaler part. It was a command that we
    ran in the terminal, but it is captured nowhere. So how can we keep track of our
    infrastructure (yes, an Horizontal Pod Autoscaler is part of the infrastructure)?'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是任何系统管理员的梦想：无障碍自动扩展和自我修复的基础设施。正如你所看到的，Kubernetes 开始变得合乎逻辑，但在自动扩展部分有一个让人困扰的地方。我们在终端中运行了一个命令，但它并没有被记录下来。那么我们该如何跟踪我们的基础设施呢（是的，水平
    Pod 自动扩展器也是基础设施的一部分）？
- en: 'Well, there is an alternative; we can create a YAML file that describes our
    Horizontal Pod Autoscaler:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 其实有一个替代方案；我们可以创建一个 YAML 文件来描述我们的水平 Pod 自动扩展器：
- en: '[PRE23]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'First, from the dashboard, remove `HorizontalPodAutoscaler` created from the
    previous example. Then, write the preceding content into a file called `horizontalpodautoscaler.yml`
    and run the following command:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，从仪表盘中删除前面例子中创建的`HorizontalPodAutoscaler`。然后，将前面的内容写入一个名为`horizontalpodautoscaler.yml`的文件，并运行以下命令：
- en: '[PRE24]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This should have the same effect as the `autoscale` command but with two obvious
    benefits:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该和`autoscale`命令有相同的效果，但有两个明显的好处：
- en: We can control more parameters, such as the name of the HPA, or add metadata
    to it, such as labels
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以控制更多的参数，比如HPA的名称，或者为其添加元数据，例如标签
- en: We keep our infrastructure as code within reach so we know what is going on
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将基础设施作为代码保持在触手可及的地方，这样我们就能知道发生了什么
- en: 'The second point is extremely important: we are in the age of the infrastructure
    as code and Kubernetes leverages this powerful concept in order to provide traceability
    and readability. Later on, in [Chapter 8](127a7b5f-4bd7-4290-bea0-3e8db867e4af.xhtml),
    *Release Management – Continuous Delivery*, you will learn how to create a continuous
    delivery pipeline with Kubernetes in a very easy way that works on 90% of the
    software projects.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 第二点极为重要：我们正处在基础设施即代码的时代，Kubernetes利用这个强大的概念来提供可追溯性和可读性。在后续的[第8章](127a7b5f-4bd7-4290-bea0-3e8db867e4af.xhtml)，*发布管理
    – 持续交付*中，你将学习如何使用Kubernetes以一种非常简便的方式创建一个适用于90%软件项目的持续交付流水线。
- en: Once the preceding command returns, we can check on the dashboard and see that
    effectively, our Replica Set has attached an Horizontal Pod Autoscaler as per
    our configuration.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦前面的命令执行完毕，我们可以在仪表盘上查看，确认我们的Replica Set确实根据配置附加了一个Horizontal Pod Autoscaler。
- en: Deployments
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署（Deployments）
- en: 'Even though the Replica Set is a very powerful concept, there is one part of
    it that we have not talked about: what happens when we apply a new configuration
    to a Replica Set in order to upgrade our applications? How does it handle the
    fact that we want to keep our application alive 100% of the time without service
    interruption?'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 即使Replica Set是一个非常强大的概念，但我们还没有讨论其中的一部分：当我们应用新的配置到Replica Set以便升级我们的应用时，会发生什么？它如何处理我们希望应用在100%的时间内保持运行而不发生服务中断的问题？
- en: 'Well, the answer is simple: it doesn''t. If you apply a new configuration to
    a Replica Set with a new version of the image, the Replica Set will destroy all
    the Pods and create newer ones without any guaranteed order or control. In order
    to ensure that our application is always up with a guaranteed minimum amount of
    resources (Pods), we need to use Deployments.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，答案很简单：它不会。如果你应用新的配置到一个Replica Set并使用了新的镜像版本，Replica Set将销毁所有Pods并创建新的Pods，且没有任何保证的顺序或控制。为了确保我们的应用始终保持运行并且有最少的资源（Pods）保障，我们需要使用Deployments。
- en: 'First, take a look at what a deployment looks like:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，看看部署（deployment）是怎样的：
- en: '[PRE25]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'As you can see, it is very similar to a Replica Set, but there is a new section:
    strategy. In strategy, we are defining how our `rollout` is going to work, and
    we have two options:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，它与Replica Set非常相似，但有一个新的部分：strategy（策略）。在策略中，我们定义了`rollout`的工作方式，且有两个选项：
- en: '`RollingUpdate`'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RollingUpdate`'
- en: '`Recreate`'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Recreate`'
- en: '`RollingUpdate` is the default option as it seems the most versatile in modern
    24/7 applications: It coordinates two replica sets and starts shutting down pods
    from the old replica set at the same time that it is creating them in the new
    Replica Set. This is very powerful because it ensures that our application always
    stays up. Kubernetes decides what is best to coordinate the pods'' rescheduling,
    but you can influence this decision with two parameters:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '`RollingUpdate`是默认选项，因为它似乎在现代24/7应用中最为通用：它协调两个Replica Set，并在创建新Replica Set中的pod时，同时关闭旧Replica
    Set中的pod。这是非常强大的，因为它确保了我们的应用始终保持运行。Kubernetes决定最好的pod重新调度方式，但你可以通过两个参数影响这个决策：'
- en: '`maxUnavailable`'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxUnavailable`'
- en: '`maxSurge`'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxSurge`'
- en: The first one defines how many pods we can loose from our Replica Set in order
    to perform a `rollout`. As an example, if our Replica Set has three replicas,
    a `rollout` with the `maxUnavailable` value of `1` will allow Kubernetes to transition
    to the new Replica Set with only two pods in the status `Ready` at some point.
    In this example, `maxUnavailable` is `0`; therefore, Kubernetes will always keep
    three pods alive.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个定义了在执行`rollout`时，我们可以从Replica Set中丢失多少个pod。举个例子，如果我们的Replica Set有三个副本，且`maxUnavailable`值为`1`，那么Kubernetes将在某个时刻允许新Replica
    Set中只有两个pod处于`Ready`状态。在这个例子中，`maxUnavailable`是`0`；因此，Kubernetes会始终保持三个pod处于存活状态。
- en: '`MaxSurge` is similar to maxUnavailable, but it goes the other way around:
    it defines how many pods above the replicas can be scheduled by Kubernetes. In
    the preceding example, with three replicas with `maxSurge` set on `1`, the maximum
    amount of pods at a given time in our `rollout` will be `4`.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '`MaxSurge`与`maxUnavailable`类似，但它的作用相反：它定义了Kubernetes可以调度多少个超过副本数量的Pod。在前面的示例中，设置了`maxSurge`为`1`，且有三个副本，这时在我们的`rollout`中，任何时刻Pod的最大数量将是`4`。'
- en: 'Playing with these two parameters as well as the replicas'' number, we can
    achieve quite interesting effects. For example, by specifying three replicas with
    `maxSurge 1` and `maxUnavailable 1`, we are forcing Kubernetes to move the pods
    one by one in a very conservative way: we might have four pods during the `rollout`,
    but we will never go below three available pods.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调整这两个参数以及副本的数量，我们可以实现相当有趣的效果。例如，通过指定三个副本和`maxSurge 1`以及`maxUnavailable 1`，我们强制Kubernetes以一种非常保守的方式逐一移动Pod：在`rollout`过程中，我们可能会有四个Pod，但我们永远不会低于三个可用的Pod。
- en: Coming back to the strategies, Recreate basically destroys all the pods and
    creates them again with the new configuration without taking uptime into account.
    This might be indicated in some scenarios, but I would strongly suggest that you
    use `RollingUpdate` when possible (pretty much always) as it leads to smoother
    deployments.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 回到策略上，Recreate基本上是销毁所有的Pod，并使用新的配置重新创建它们，而不考虑上线时间。在某些情况下，这可能是必要的，但我强烈建议你在可能的情况下使用`RollingUpdate`（几乎总是这样），因为它可以带来更平滑的部署过程。
- en: It is also possible to attach a Horizontal Pod Autoscaler to a Deployment in
    the same way that we would do with a Replica Set.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以像对待副本集一样，向一个部署附加一个水平Pod自动扩缩器。
- en: 'Let''s test our deployment. Create a file called `deployment.yml` and apply
    it to our cluster:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试一下我们的部署。创建一个名为`deployment.yml`的文件，并将其应用到我们的集群中：
- en: '[PRE26]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Once the command returns, we can go to the Kubernetes dashboard (`localhost:8001/ui`
    with the proxy active) and check what happened in the Deployments section in the
    menu on the left-hand side:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦命令返回，我们可以进入Kubernetes仪表板（如果代理已激活，地址是`localhost:8001/ui`），并查看左侧菜单中的Deployments部分，检查发生了什么：
- en: '![](img/da68eada-ed69-491f-b51a-851d95ceb92f.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![](img/da68eada-ed69-491f-b51a-851d95ceb92f.png)'
- en: 'We have a new Deployment called `nginx-deployment`, which has created a Replica
    Set that also contains the specified pods. In the preceding command, we have passed
    a new parameter: `--record`. This saves the command in the `rollout` history of
    our deployment so that we can query the `rollout` history of a given deployment
    to see the changes applied to it. In this case, just execute the following:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个新的部署叫做`nginx-deployment`，它已经创建了一个副本集，并且该副本集也包含了指定的Pod。在前面的命令中，我们传递了一个新的参数：`--record`。这会将命令保存到我们的部署的`rollout`历史中，这样我们就可以查询给定部署的`rollout`历史，以查看它应用了哪些变更。在这种情况下，只需执行以下命令：
- en: '[PRE27]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This will show you all the actions that altered the status of a deployment
    called `nginx-deployment`. Now, let''s execute some change:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 这将展示所有改变了名为`nginx-deployment`的部署状态的操作。现在，让我们执行一些更改：
- en: '[PRE28]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We have used `kubectl` to change the version of the `nginx` container back
    to version 1.9.1 (`kubectl` is very versatile; the official documentation offers
    shortcuts for pretty much everything), and a few things happened. The first one
    is that a new Replica Set has been created and the pods have been moved over to
    it from the old replica set. We can verify this in the Replica Sets section of
    the menu on the left-hand side of the dashboard:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`kubectl`将`nginx`容器的版本改回了1.9.1版本（`kubectl`非常多功能，官方文档为几乎所有操作提供了快捷方式），并且发生了几件事。第一件事是，创建了一个新的副本集，Pod从旧的副本集转移到了新的副本集中。我们可以在仪表板左侧菜单的Replica
    Sets部分验证这一点：
- en: '![](img/914506b4-95bc-4bb3-a8f7-cbc5da1cc2d1.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![](img/914506b4-95bc-4bb3-a8f7-cbc5da1cc2d1.png)'
- en: As you can see, the old replica set has 0 pods, whereas the new one that took
    over has three pods. This all happened without you noticing it, but it is a very
    clever workflow with a lot of work from the Kubernetes community and the companies
    behind it.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，旧的副本集有0个Pod，而接管的新副本集有三个Pod。所有这些都在你不注意的情况下发生，但这是一种非常巧妙的工作流程，背后有Kubernetes社区和相关公司的大量努力。
- en: 'The second thing that happened was that we have a new entry in our rollout
    history. Let''s check it out:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 发生的第二件事是我们在`rollout`历史中有了一个新的条目。我们来查看一下：
- en: '[PRE29]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Which one should produce an output similar to the following one:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会产生类似于以下内容的输出：
- en: '![](img/b1947f72-a1f1-410f-b4e1-8d946788f00e.png)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1947f72-a1f1-410f-b4e1-8d946788f00e.png)'
- en: Now we have two entries that describe the changes applied to our deployment.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有两个条目来描述我们对部署所做的更改。
- en: 'If you have been into IT for few years, by now, you have reached the conclusion
    that a rollback strategy is always necessary because bugs flowing into production
    are the reality no matter how good our QA is. I am a big fan of building the systems
    in a way that deployments are unimportant events (from a technical point of view),
    as shown with Kuberentes, and the engineers always have an easy way out if things
    start to fail in production. Deployments offer an easy rollback if something goes
    wrong:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在IT行业工作了几年，你现在应该已经得出结论：回滚策略总是必要的，因为无论我们的QA有多好，生产环境中都会出现bug，这是现实。 我是那种喜欢以“部署是无关紧要的事件（从技术角度看）”的方式构建系统的人，就像Kubernetes所展示的那样，并且工程师总能在生产环境出现问题时轻松找到解决办法。如果出现问题，部署会提供一个简单的回滚方式：
- en: '[PRE30]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Execute the preceding and browse back to the dashboard on the **Replica Sets**
    section again:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 执行前面的步骤，然后再次浏览到**副本集**部分的仪表盘：
- en: '![](img/18a385bd-ca4c-44b3-8b36-6a0508f690cc.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![](img/18a385bd-ca4c-44b3-8b36-6a0508f690cc.png)'
- en: 'That''s right. In a matter of seconds, we have gone from instability (a broken
    build) to the safety of the old known version without interrupting the service
    and without involving half of the IT department: a simple command brings back
    the stability to the system. The rollback command has a few configurations, and
    we can even select the revision where we want to jump to.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 没错。在几秒钟内，我们已经从不稳定状态（构建失败）恢复到已知的旧版本，而且没有中断服务，也没有涉及到IT部门的大部分人员：一个简单的命令将稳定性带回系统。回滚命令有一些配置，我们甚至可以选择想要跳转到的修订版本。
- en: 'This is how powerful Kubernetes is and this is how simple our life becomes
    by using Kubernetes as the middleware of our enterprise: a modern CD pipeline
    assembled in a few lines of configuration that works in the same way in all the
    companies in the world by facilitating command `rollouts` and rollbacks. That''s
    it...simple and efficient.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是Kubernetes的强大之处，也是我们通过使用Kubernetes作为企业中间件让生活变得如此简单的原因：一个现代化的CD管道，通过几行配置拼凑而成，在全球所有公司中都能以相同的方式工作，简化了`rollouts`和回滚操作。就是这样……简单而高效。
- en: Right now, it feels like we know enough to move our applications to Kubernetes,
    but there is one thing missing. So far, up until now, we have just run predefined
    containers that are not exposed to the outer world. In short, there is no way
    to reach our application from outside the cluster. You are going to learn how
    to do that in the next section.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们似乎已经掌握了将应用程序迁移到Kubernetes所需的足够知识，但仍然缺少一个重要部分。到目前为止，我们仅运行了未对外暴露的预定义容器。简而言之，无法从集群外部访问我们的应用程序。你将在下一节中学习如何做到这一点。
- en: Services
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务
- en: Up until now, we were able to deploy containers into Kubernetes and keep them
    alive by making use of pods, Replica Sets, and Horizontal Pods Autoscalers as
    well as Deployments, but so far, you have not learned how to expose applications
    to the outer world or make use of service discovery and balancing within Kubernetes.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经能够将容器部署到Kubernetes中，并通过使用Pod、Replica Sets、水平Pod自动扩展器以及Deployments将它们保持活跃，但到目前为止，你还没有学会如何将应用程序暴露到外部世界，或者如何在Kubernetes中使用服务发现和负载均衡。
- en: '**Services** are responsible for all of the above. A Service in Kubernetes
    is not an element as we are used to it. A Service is an abstract concept used
    to give entity to a group of pods through pattern matching and expose them to
    different channels via the same interface: a set of labels attached to a Pod that
    get matched against a selector (another set of labels and rules) in order to group
    them.'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '**服务**负责上述所有操作。在Kubernetes中，服务并不是我们所习惯的元素。服务是一个抽象概念，用来通过模式匹配为一组Pod赋予实体，并通过相同的接口将其暴露到不同的通道：一组附加到Pod上的标签与选择器（另一组标签和规则）匹配，从而将它们分组。'
- en: 'First, let''s create a service on top of the deployment created in the previous
    section:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们在上一节中创建的部署基础上创建一个服务：
- en: '[PRE31]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Easy and straightforward, but there''s one detail: the selector section has
    a hidden message for us. The selectors are the mechanisms that Kubernetes uses
    to connect components via pattern matching algorithms. Let''s explain what pattern
    matching is. In the preceding Service, we are specifying that we want to select
    all the Pods that have a label with the `app` key and the `nginx` value. If you
    go back to the previous section, you''ll understand our deployment has these labels
    in the pod specification. This is a match; therefore, our service will select
    these pods. We can check this by browsing in the dashboard in the Services section
    and clicking on `nginx-service`, but first, you need to create the `service`:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 简单直接，但有一个细节：选择器部分隐藏了一个信息。选择器是 Kubernetes 用来通过模式匹配算法连接组件的机制。让我们解释一下什么是模式匹配。在前面的
    Service 中，我们指定了要选择所有具有 `app` 键和 `nginx` 值标签的 Pods。如果你回到前一部分，你会明白我们的部署在 pod 规范中有这些标签。这是一个匹配；因此，我们的服务会选择这些
    pods。我们可以通过在仪表盘中的服务部分浏览并点击 `nginx-service` 来检查这一点，但首先，你需要创建 `service`：
- en: '[PRE32]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Then, check out the dashboard:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，查看仪表盘：
- en: '![](img/8e9b3f8f-cae8-4dee-8969-95fad1d7814e.png)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8e9b3f8f-cae8-4dee-8969-95fad1d7814e.png)'
- en: As you can see, there are three pods selected, and they all belong to the deployment
    `nginx` that we created in the preceding section.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，选择了三个 pods，它们都属于我们在前一部分创建的 `nginx` 部署。
- en: Don't remove the deployment from the previous section; otherwise, there will
    be no pods to select by our service.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 不要删除前一部分的部署，否则我们的服务将无法选择 pods。
- en: 'This screen has a lot of interesting information. The first piece of information
    is that the service has an IP: this IP is denominated as `clusterIP`. Basically,
    it is an IP within the cluster that can be reached by our pods and other elements
    in Kubernetes. There is also a field called `Type`, which allows us to chose the
    service type. There are three types:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这个界面有很多有趣的信息。第一条信息是服务有一个 IP：这个 IP 被称为 `clusterIP`。基本上，它是集群内的一个 IP，可以被我们的 pods
    和 Kubernetes 中的其他元素访问。还有一个字段叫 `Type`，允许我们选择服务类型。有三种类型：
- en: '`ClusterIP`'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ClusterIP`'
- en: '`NodePort`'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NodePort`'
- en: '`LoadBalancer`'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LoadBalancer`'
- en: '`ClusterIP` is what we just created and explained.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '`ClusterIP` 就是我们刚刚创建并解释过的。'
- en: '`NodePort` is another type of service that is rarely used in Cloud but is very
    common on premises. It allocates a port on all the nodes to expose our application.
    This allows Kubernetes to define the ingress of the traffic into our pods. This
    is challenging for two reasons:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '`NodePort` 是另一种服务类型，在云环境中很少使用，但在本地环境中非常常见。它会在所有节点上分配一个端口来暴露我们的应用程序。这使 Kubernetes
    能够定义流量进入我们 pods 的入口。由于以下两个原因，这带来了挑战：'
- en: It generates extra traffic in our internal network as the nodes need to forward
    the traffic across to reach the pods (imagine a cluster of 100 nodes that has
    an app with only three pods, it is very unlikely to hit the node that is running
    one of them).
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它在我们的内部网络中生成额外的流量，因为节点需要将流量转发以到达 pods（想象一下一个有 100 个节点的集群，但只有三个 pods 运行应用程序，几乎不可能击中运行其中一个的节点）。
- en: The ports are allocated randomly so you need to query the Kubernetes API to
    know the allocated port.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端口是随机分配的，因此你需要查询 Kubernetes API 以了解分配的端口。
- en: '`LoadBalancer` is the jewel in the crown here. When you create a service of
    type `LoadBalancer`, a cloud load balancer is provisioned so that the client applications
    hit the load balancer that redirects the traffic into the correct nodes. As you
    can imagine, for a cloud environment where infrastructure is created and destroyed
    in matter of seconds, this is the ideal situation.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '`LoadBalancer` 是这里的皇冠上的明珠。当你创建一个类型为 `LoadBalancer` 的服务时，会配置一个云负载均衡器，使客户端应用程序访问负载均衡器，负载均衡器将流量重定向到正确的节点。正如你想象的那样，对于一个在几秒钟内就能创建和销毁基础设施的云环境来说，这是理想的情况。'
- en: 'Coming back to the previous screenshot, we can see another piece of interesting
    information: the internal endpoints. This is the service discovery mechanism that
    Kubernetes is using to locate our applications. What we have done here is connect
    the pods of our application to a name: `nginx-service`. From now on, no matter
    what happens, the only thing that our apps need to know in order to reach our
    `nginx` pods is that there is a service called `nginx` that knows how to locate
    them.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 回到前面的截图，我们可以看到另一条有趣的信息：内部端点。这是 Kubernetes 用来定位我们应用程序的服务发现机制。我们所做的就是将应用程序的 pods
    连接到一个名称：`nginx-service`。从现在开始，不管发生什么，我们的应用程序要想访问我们的 `nginx` pods，只需要知道有一个名为 `nginx`
    的服务，知道如何定位它们。
- en: 'In order to test this, we are going to run an instance of a container called
    `busybox`, which is basically the Swiss army knife of command-line tools. Run
    the following command:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行测试，我们将运行一个名为 `busybox` 的容器实例，它基本上是命令行工具的瑞士军刀。运行以下命令：
- en: '[PRE33]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The preceding command will present us with a shell inside the container called
    `busybox` running in a pod so we are inside the Kubernetes cluster and, more importantly,
    inside the network so that we can see what is going on. Be aware that the preceding
    command runs just a pod: no deployment or replica set is created, so once you
    exit the shell, the pod is finalized and resources are destroyed.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的命令将为我们提供一个名为`busybox`的容器的 shell，这个容器运行在 Pod 中，因此我们处于 Kubernetes 集群内部，更重要的是，处于网络内部，这样我们就能看到发生了什么。请注意，前面的命令仅仅运行了一个
    Pod：没有创建部署或副本集，因此一旦你退出 shell，Pod 就会结束，资源也会被销毁。
- en: 'Once we get the prompt inside `busybox`, run the following command:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦进入 `busybox`，运行以下命令：
- en: '[PRE34]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This should return something similar to the following:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该返回类似如下内容：
- en: '[PRE35]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Okay, what happened here? When we created a service, we assigned a name to
    it: `nginx-service`. This name has been used to register it in an internal DNS
    for service discovery. As mentioned earlier, the DNS service is running on Kubernetes
    and is reachable from all the Pods so that it is a centralised repository of common
    knowledge. There is another way that the Kubernetes engineers have created in
    order to carry on with the service discovery: the environment variables. In the
    same prompt, run the following command:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这里发生了什么？当我们创建服务时，我们为它指定了一个名称：`nginx-service`。这个名称已用于将其注册到用于服务发现的内部 DNS 中。如前所述，DNS
    服务运行在 Kubernetes 上，所有 Pod 都可以访问，因此它是一个集中式的公共知识库。Kubernetes 工程师还创造了另一种方式来继续服务发现：环境变量。在相同的提示符下，运行以下命令：
- en: '[PRE36]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This command outputs all the environment variables, but there are few that
    are relevant to our recently defined service:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令会输出所有环境变量，但其中有几个与我们刚刚定义的服务相关：
- en: '[PRE37]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'These variables, injected by Kubernetes at creation time, define where the
    applications can find our service. There is one problem with this approach: the
    environment variables are injected at creation time, so if our service changes
    during the life cycle of our pods, these variables become obsolete and the pod
    has to be restarted in order to inject the new values.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 这些由 Kubernetes 在创建时注入的变量，定义了应用程序如何找到我们的服务。这个方法有一个问题：环境变量是在创建时注入的，因此如果我们的服务在
    Pod 生命周期中发生变化，这些变量就会变得过时，Pod 必须重新启动以注入新的值。
- en: 'All this magic happens through the selector mechanism on Kubernetes. In this
    case, we have used the equal selector: a label must match in order for a pod (or
    an object in general) to be selected. There are quite a few options, and at the
    time of writing this, this is still evolving. If you want to learn more about
    selectors, here is the official documentation: [https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/).'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些魔法都通过 Kubernetes 上的选择器机制发生。在这种情况下，我们使用了等号选择器：标签必须匹配才能选择一个 Pod（或一般对象）。有很多选择器选项，截至本文写作时，这仍在不断发展。如果你想了解更多关于选择器的信息，以下是官方文档：[https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/)。
- en: As you can see, services are used in Kubernetes to glue our applications together.
    Connecting applications with services allows us to build systems based on microservices
    by coupling REST endpoints in the API with the name of the service that we want
    to reach on the DNS.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，Kubernetes 中的服务用于将我们的应用程序连接在一起。通过服务连接应用程序，让我们可以构建基于微服务的系统，通过将 API 中的
    REST 端点与我们要通过 DNS 到达的服务名称关联起来。
- en: 'Up until now, you have learned how to expose our applications to the rest of
    our cluster, but how do we expose our applications to the outer world? You have
    also learned that there is a type of service that can be used for this: `LoadBalancer`.
    Let''s take a look at the following definition:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经学会了如何将我们的应用程序暴露给集群中的其他部分，但我们如何将应用程序暴露给外部世界呢？你也已经了解了有一种服务类型可以用于此：`LoadBalancer`。让我们看一下以下定义：
- en: '[PRE38]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'There is one change in the preceding definition: the service type is now `LoadBalancer`.
    The best way to explain what this causes is by going to the Services section of
    the dashboard:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的定义中有一个变化：服务类型现在是`LoadBalancer`。解释这一变化的最佳方式是查看仪表盘中的“服务”部分：
- en: '![](img/8f694bd9-47e9-49dd-9f6d-1b0d2fdfd334.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f694bd9-47e9-49dd-9f6d-1b0d2fdfd334.png)'
- en: As you can see, our newly created service got assigned an external endpoint.
    If you browse it, bingo! The `nginx` default page is rendered.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们新创建的服务分配了一个外部端点。如果您访问它，成功！`nginx` 默认页面被呈现出来。
- en: 'We have created two services, `nginx-service` and `nginx-service-lb`, of the
    type `ClusterIP` and `LoadBalancer`, respectively, which both point to the same
    pods that belong to a deployment and are managed through a replica set. This can
    be a bit confusing, but the following diagram will explain it better:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了两个服务，分别为 `nginx-service` 和 `nginx-service-lb`，类型分别为 `ClusterIP` 和 `LoadBalancer`，它们都指向属于某个部署的相同
    Pods，并且通过 ReplicaSet 管理。这个概念可能有点混乱，但下面的图表会更好地解释它：
- en: '![](img/1647789c-12c0-459c-866b-7956a0919600.png)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1647789c-12c0-459c-866b-7956a0919600.png)'
- en: The preceding diagram is the perfect explanation of what we've built in this
    section. As you can see, the load balancer is outside of Kubernetes, but everything
    else is inside our cluster as virtual elements of an API.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图表完美地解释了我们在本节中所构建的内容。如您所见，负载均衡器位于 Kubernetes 外部，而其他所有内容都作为 API 的虚拟元素位于我们的集群内部。
- en: Other Building Blocks
  id: totrans-362
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他构建块
- en: 'In the previous sections, you learned the basics needed to deploy applications
    into Kubernetes successfully. The API objects that we visited are as follows:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，您已经学习了成功将应用程序部署到 Kubernetes 所需的基本知识。我们讨论过的 API 对象如下：
- en: Pod
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod
- en: ReplicaSet
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReplicaSet
- en: Deployment
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署
- en: Service
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Service
- en: In Kubernetes, there are many other building blocks that can be used to build
    more advanced applications; every few months, the Kubernetes engineers add new
    elements to improve or add functionality.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，还有许多其他构建块可以用来构建更复杂的应用程序；每隔几个月，Kubernetes 的工程师们都会添加新元素来改善或增加功能。
- en: One example of these additions is the ReplicaSet that was designed to replace
    another item called ReplicationController. The main difference between the ReplicationController
    and the ReplicaSet is that the latter one has a more advance semantics label selection
    for the Pods that were recently re-engineered in Kubernetes.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个新增元素是 ReplicaSet，它旨在替代另一个叫做 ReplicationController 的组件。ReplicationController
    和 ReplicaSet 的主要区别在于，后者为 Pods 提供了更先进的语义标签选择，而这些 Pods 最近在 Kubernetes 中经过了重新设计。
- en: As a new product, Kuberentes is constantly changing (in fact, it is possible
    that by the time that you read this book, the core elements might have changed),
    so the engineers try to keep the compatibility across different versions so that
    people are not urged to upgrade in a short period of time.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一款新产品，Kubernetes 正在不断变化（事实上，当您阅读这本书时，核心元素可能已经发生变化），因此工程师们会尽力保持不同版本之间的兼容性，以便用户不需要在短时间内强制升级。
- en: 'Other examples of more advanced building blocks are the following:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 其他更高级的构建块示例如下：
- en: DaemonSet
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DaemonSet
- en: PetSets
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PetSets
- en: Jobs and CronJobs
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jobs 和 CronJobs
- en: CronJobs
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CronJobs
- en: In order to go in deep to the full stack in Kubernetes, we would need a full
    book (or more!). Let's visit some of them.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 若要深入了解 Kubernetes 的全栈，我们需要一本完整的书（甚至更多！）。让我们来看看其中的一些。
- en: Daemon Sets
  id: totrans-377
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Daemon Sets
- en: 'Daemon Sets are an API element used to **ensure that a Pod is running in all
    (or some) nodes**. One of the assumptions in Kubernetes is that the pod should
    not worry about which node is being run, but that said, there might be a situation
    where we want to ensure that we run at least one pod on each node for a number
    of reasons:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: Daemon Sets 是一个 API 元素，用于 **确保 Pod 在所有（或部分）节点上运行**。Kubernetes 的一个假设是，Pod 不需要关心在哪个节点上运行，但考虑到这一点，可能会有一种情况，我们希望确保至少有一个
    Pod 在每个节点上运行，原因如下：
- en: Collect logs
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集日志
- en: Check the hardware
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查硬件
- en: Monitoring
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控
- en: In order to do that, Kubernetes provides an API element called Daemon Set. Through
    a combination of labels and selectors, we can define something called **affinity**,
    which can be used to run our pods on certain nodes (we might have specific hardware
    requirements that only a few nodes are able to provide so that we can use tags
    and selectors to provide a hint to the pods to relocate to certain nodes).
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，Kubernetes 提供了一个名为 Daemon Set 的 API 元素。通过标签和选择器的组合，我们可以定义所谓的 **affinity**（亲和性），这可以用来在某些节点上运行我们的
    Pods（我们可能有特定的硬件需求，只有少数节点能够提供，因此我们可以使用标签和选择器为 Pods 提供提示，指示它们迁移到特定节点）。
- en: 'Daemon Sets have several ways to be contacted, from the DNS through a headless
    service (a service that works as a load balancer instead of having a cluster IP
    assigned) to the node IP, but Daemon Sets work best when they are the initiators
    of the communication: something happens (an event) and a Daemon Set sends an event
    with information about that event (for example, a node is running low on space).'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: Daemon Sets 有多种方式可以被联系，从 DNS 通过无头服务（一个作为负载均衡器工作的服务，而不是分配有集群 IP）到节点 IP，但 Daemon
    Sets 在作为通信发起者时效果最佳：某个事件发生后，Daemon Set 会发送一个带有该事件信息的事件（例如，节点空间不足）。
- en: PetSets
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PetSets
- en: '**PetSets** are an interesting concept within Kubernetes: they are strong named
    resources whose naming is supposed to stay the same for a long term. As of now,
    a pod does not have a strong entity within a Kubernetes cluster: you need to create
    a service in order to locate a pod as they are ephemeral. Kubernetes can reschedule
    them at any time without prior notice for changing their name, as we have seen
    before. If you have a deployment running in Kubernetes and kill one of the pods,
    its name changes from (for example) *pod-xyz* to *pod-abc i*n an unpredictable
    way. so we cannot know which names to use in our application to connect to them
    beforehand.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '**PetSets** 是 Kubernetes 中一个有趣的概念：它们是强命名资源，其名称应该长期保持不变。目前，Pod 在 Kubernetes
    集群中没有强实体：你需要创建一个服务来定位 Pod，因为它们是短暂的。Kubernetes 可以在任何时候重新调度它们，且无需提前通知以更改其名称，正如我们之前所见。如果你在
    Kubernetes 中运行一个部署并杀死其中一个 Pod，它的名称会从（例如）*pod-xyz* 改为 *pod-abc*，这种变化是不可预测的。因此我们无法提前知道应用程序中要连接的名称。'
- en: 'When working with a Pet Set, this changes completely. A pet set has an ordinal
    order, so it is easy to guess the name of the pod. Let''s say that we have deployed
    a Pet Set called mysql, which defines pods running a MySQL server. If we have
    three replicas, the naming will be as follows:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用 Pet Set 时，情况完全不同。Pet Set 有一个顺序，因此很容易猜测 Pod 的名称。假设我们部署了一个名为 mysql 的 Pet Set，它定义了运行
    MySQL 服务器的 Pod。如果我们有三个副本，则命名方式如下：
- en: '`mysql-0`'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mysql-0`'
- en: '`mysql-1`'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mysql-1`'
- en: '`mysql-2`'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mysql-2`'
- en: 'So, we can bake this knowledge in our application to reach them. This is suboptimal
    but good enough: we are still coupling services by name (DNS service discovery
    has this limitation), but it works in all cases and is a sacrifice that is worth
    paying for because in return, we get a lot of flexibility. The ideal situation
    in service discovery is where our system does not need to know even the name of
    the application carrying the work: just throw the message into the ether (the
    network) and the appropriated server will pick it up and respond accordingly.'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以将这些知识内建到我们的应用程序中来访问它们。这虽然不是最优解，但足够好：我们仍然是通过名称来耦合服务（DNS 服务发现存在这个限制），但是在所有情况下它都能正常工作，这是值得付出的牺牲，因为作为回报，我们获得了更多的灵活性。理想的服务发现情况是，我们的系统甚至不需要知道执行工作的应用程序的名称：只需将消息投递到虚空（网络）中，适当的服务器会接收并做出响应。
- en: 'Pet Sets have been replaced in later versions of Kubernetes with another item
    called **Stateful Set.** The Stateful Set is an improvement over the Pet Set mainly
    in how Kubernetes manages the **master knowledge to avoid a split brain situation**:
    where two different elements think that they are in control.'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 的后续版本中，Pet Sets 被另一个名为 **Stateful Set** 的元素所替代。Stateful Set 相比
    Pet Set 主要在 Kubernetes 如何管理 **主控知识以避免脑裂情况** 上有所改进：即两个不同的元素认为它们自己在控制中。
- en: Jobs
  id: totrans-392
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jobs
- en: A **Job** in Kubernetes is basically an element that spawns the defined number
    of pods and waits for them to finish before completing its life cycle. It is very
    useful when there is a need to run a one-off task, such as rotating logs or migrating
    data across databases.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，**Job** 本质上是一个元素，它生成指定数量的 Pod，并在这些 Pod 完成任务之前等待它们完成其生命周期。当需要运行一次性任务时，比如旋转日志或跨数据库迁移数据，Job
    非常有用。
- en: Cron jobs have the same concept as Jobs, but they get triggered by time instead
    of a one-off process.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: Cron 作业与 Jobs 有相同的概念，但它们是通过时间触发的，而不是一次性过程。
- en: 'Both in combination are very powerful tools to keep any system running. If
    you think about how we rotate logs without Kubernetes via ssh, it is quite risky:
    there is no control (by default) over who is doing what, and usually, there is
    no review process in the ssh operations carried by an individual.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 这两者结合起来是非常强大的工具，能够保持任何系统运行。如果你考虑一下如何通过 SSH 在没有 Kubernetes 的情况下旋转日志，那是相当危险的：默认情况下无法控制是谁在做什么，通常也没有审查个人执行的
    SSH 操作。
- en: With this approach, it is possible to create a Job and get other engineers to
    review it before running it for extra safety.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，可以创建一个Job，并让其他工程师在运行之前进行审查，确保安全性。
- en: Secrets and configuration management
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 密钥和配置管理
- en: 'On Docker in general, as of today, secrets are being passed into containers
    via environment variables. This is very insecure: first, there is no control over
    who can access what, and second, environment variables are not designed to act
    as secrets and a good amount of commercial software (and open source) outputs
    them into the standard output as part of bootstrapping. Needless to say, that''s
    rather inconvenient.'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，在Docker中，密钥通过环境变量传递到容器中。这是非常不安全的：首先，没有控制谁可以访问什么，其次，环境变量并不是设计用来作为密钥的，很多商业软件（包括开源软件）会将它们输出到标准输出中作为启动过程的一部分。不用说，这非常不方便。
- en: 'Kubernetes has solved this problem quite gracefully: instead of passing an
    environment variable to our container, a volume is mounted with the secret on
    a file (or several) ready to be consumed.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes已经非常优雅地解决了这个问题：它不是通过环境变量将密钥传递给容器，而是将密钥挂载为一个文件（或多个文件）卷，准备供使用。
- en: By default, Kubernetes injects a few secrets related to the cluster into our
    containers so that they can interact with the API and so on, but it is also possible
    to create your own secrets.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Kubernetes会将一些与集群相关的密钥注入到我们的容器中，以便它们能够与API等进行交互，但也可以创建你自己的密钥。
- en: 'There are two ways to create secrets:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方式来创建密钥：
- en: Using `kubectl`
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`kubectl`
- en: Defining an API element of type secret and using `kubectl` to deploy it
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义一个类型为密钥的API元素，并使用`kubectl`进行部署
- en: 'The first way is fairly straightforward. Create a folder called *secrets* in
    your current work folder and execute the following commands inside it:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法相当简单。在你当前的工作文件夹中创建一个名为*secrets*的文件夹，并在其中执行以下命令：
- en: '[PRE39]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This creates two files with two strings (simple strings as of now). Now it
    is time to create the secret in Kubernetes using `kubectl`:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建两个文件，其中包含两个字符串（目前是简单字符串）。现在是时候使用`kubectl`在Kubernetes中创建密钥了：
- en: '[PRE40]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'And that''s it. Once we are done, we can query the secrets using `kubectl`:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。一旦完成，我们可以使用`kubectl`查询密钥：
- en: '[PRE41]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This, in my case, returns two secrets:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 这在我的情况下返回了两个密钥：
- en: A service account token injected by the cluster
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群注入的服务账户令牌
- en: My newly created secret (`my-secrets`)
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我新创建的密钥（`my-secrets`）
- en: 'The second way of creating a secret is by defining it in a `yaml` file and
    deploying it via `kubectl`. Take a look at the following definition:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 创建密钥的第二种方法是通过在`yaml`文件中定义它，并通过`kubectl`进行部署。看一下下面的定义：
- en: '[PRE42]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'First, the values for `secret1` and `secret2`, seem to be encrypted, but they
    are not; they are just encoded in `base64`:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`secret1`和`secret2`的值似乎是加密的，但实际上它们并没有加密，它们只是被编码为`base64`：
- en: '[PRE43]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'This will return the values that you can see here. The type of the secret is
    Opaque, which is the default type of secret, and the rest seems fairly straightforward.
    Now create the secret with kubectl (save the preceding content in a file called
    `secret.yml`):'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回你在这里看到的值。密钥的类型是Opaque，这是密钥的默认类型，其余部分看起来相当简单。现在使用kubectl创建密钥（将前面的内容保存在一个名为`secret.yml`的文件中）：
- en: '[PRE44]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: And that's it. If you query the secrets again, note that there should be a new
    one called `my-secret-yaml`. It is also possible to list and see the secrets in
    the dashboard on the Secrets link in the menu on left-hand side.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。如果你再次查询密钥，注意应该会有一个名为`my-secret-yaml`的新密钥。也可以通过左侧菜单中的Secrets链接，在仪表盘中列出并查看密钥。
- en: 'Now it is time to use them. In order to use the secret, two things need to
    be done:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候使用它们了。为了使用这个密钥，需要做两件事：
- en: Claim the secret as a volume
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将密钥声明为一个卷
- en: Mount the volume from the secret
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从密钥挂载卷
- en: 'Let''s take a look at a `Pod` using a secret:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个使用密钥的`Pod`：
- en: '[PRE45]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'So, you have learned a new thing here: `kubectl` also understands JSON. If
    you don''t like YAML, it is possible to write your definitions in JSON without
    any side-effects.'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你在这里学到了一件新事物：`kubectl`也能理解JSON。如果你不喜欢YAML，可以将定义写成JSON而不会有任何副作用。
- en: Now, looking at the JSON file, we can see how first, the secret is declared
    as a volume and then how the secret is mounted in the path/secrets.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，查看JSON文件，我们可以看到首先密钥是如何被声明为一个卷，然后密钥是如何挂载到路径/secrets中的。
- en: 'If you want to verify this, just run a command in your container to check it:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想验证这一点，只需在你的容器中运行一个命令来检查：
- en: '[PRE46]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: This should list the two files that we have created, `secret1.txt` and `secret2.txt`,
    containing the data that we have also specified.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 这里应该列出我们创建的两个文件，`secret1.txt` 和 `secret2.txt`，其中包含我们指定的数据。
- en: Kubernetes- moving on
  id: totrans-430
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes- 继续前进
- en: In this chapter, you learned enough to run simple applications in Kubernetes,
    but even though we cannot claim ourselves to be experts, we got the head start
    in becoming experts. Kubernetes is a project that evolves at the speed of light,
    and the best thing that you can do to keep yourself updated is follow the project
    on GitHub at [https://github.com/kubernetes](https://github.com/kubernetes).
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你已经学习了足够的内容来运行简单的 Kubernetes 应用程序，尽管我们不能自称为专家，但我们已经在成为专家的路上取得了领先一步。Kubernetes
    是一个以光速发展的项目，保持最新状态的最佳方法就是在 GitHub 上关注这个项目，链接地址为 [https://github.com/kubernetes](https://github.com/kubernetes)。
- en: The Kubernetes community is very responsive with issues raised by the users
    and are also very keen on getting people to contribute to the source code and
    documentation.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 社区对于用户提出的问题反应迅速，并且非常鼓励大家为源代码和文档做出贡献。
- en: If you keep working with Kubernetes, some help will be required. The official
    documentation is quite complete, and even though it feels like it needs a reshuffle
    sometimes, it is usually enough to keep you going.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你继续使用 Kubernetes，可能会需要一些帮助。官方文档相当完整，尽管有时它似乎需要进行一些重组，但通常它足以让你继续前进。
- en: The best way that I've found to learn Kubernetes is by experimenting in Minikube
    (or a test cluster) before jumping into a bigger commitment.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现学习 Kubernetes 最好的方法是在 Minikube（或测试集群）中进行实验，而不是直接投入到更大的项目中。
- en: Summary
  id: totrans-435
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we looked at a good amount of concepts required to deploy an
    application on Kubernetes. As mentioned earlier, it is impossible to cover everything
    abound Kubernetes in a single chapter, but with the amount of knowledge from this
    chapter, we are going to be able to set up a continuous delivery pipeline in the
    following chapter in a way that we automate zero downtime deployments without
    the big bang effect (the big deployment that stops the world), enabling our organization
    to move faster.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了部署 Kubernetes 应用程序所需的一些重要概念。正如之前所提到的，在一章中不可能涵盖所有与 Kubernetes 相关的内容，但通过本章的知识，我们将能够在接下来的章节中设置一个持续交付管道，以实现零停机部署，并避免“大爆炸效应”（即会停顿世界的大规模部署），从而让我们的组织变得更快。
