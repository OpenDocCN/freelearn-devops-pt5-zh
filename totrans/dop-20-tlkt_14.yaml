- en: Chapter 14. Clustering and Scaling Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '|   | *Organizations which design systems ... are constrained to produce designs
    which are copies of the communication structures of these organizations.* |  
    |'
  prefs: []
  type: TYPE_TB
- en: '|   | --*M. Conway* |'
  prefs: []
  type: TYPE_TB
- en: Many will tell you that they have a *scalable system*. After all, scaling is
    easy. Buy a server, install WebLogic (or whichever other monster application server
    you're using) and deploy your applications. Then wait for a few weeks until you
    discover that everything is so fast that you can click a button, have some coffee,
    and, by the time you get back to your desk, the result will be waiting for you.
    What do you do? You scale. You buy few more servers, install your monster applications
    servers and deploy your monster applications on top of them. Which part of the
    system was the bottleneck? Nobody knows. Why did you duplicate everything? Because
    you must. And then some more time passes, and you continue scaling until you run
    out of money and, simultaneously, people working for you go crazy. Today we do
    not approach scaling like that. Today we understand that scaling is about many
    other things. It's about elasticity. It's about being able to quickly and easily
    scale and de-scale depending on variations in your traffic and growth of your
    business, and that, during that process, you should not go bankrupt. It's about
    the need of almost every company to scale their business without thinking that
    IT department is a liability. It's about getting rid of those monsters.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us, for a moment take a step back and discuss why we want to scale applications.
    The main reason is *high availability*. Why do we want high availability? We want
    it because we want our business to be available under any load. The bigger the
    load, the better (unless you are under DDoS). It means that our business is booming.
    With high availability our users are happy. We all want speed, and many of us
    simply leave the site if it takes too long to load. We want to avoid having outages
    because every minute our business is not operational can be translated into a
    money loss. What would you do if an online store is not available? Probably go
    to another. Maybe not the first time, maybe not the second, but, sooner or later,
    you would get fed up and switch it for another. We are used to everything being
    fast and responsive, and there are so many alternatives that we do not think twice
    before trying something else. And if that something else turns up to be better...
    One man's loss is another man's gain. Do we solve all our problems with scalability?
    Not even close. Many other factors decide the availability of our applications.
    However, scalability is an important part of it, and it happens to be the subject
    of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: What is scalability? It is a property of a system that indicates its ability
    to handle increased load in a graceful manner or its potential to be enlarged
    as demand increases. It is the ability to accept increased volume or traffic.
  prefs: []
  type: TYPE_NORMAL
- en: The truth is that the way we design our applications dictates the scaling options
    available. Applications will not scale well if they are not designed to scale.
    That is not to say that an application not designed for scaling cannot scale.
    Everything can scale, but not everything can scale well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Commonly observed scenario is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: We start with a simple architecture, sometimes with load balancer sometimes
    without, setup a few application servers and one database. Everything is great,
    complexity is low, and we can develop new features very fast. The cost of operations
    is low, income is high (considering that we just started), and everyone is happy
    and motivated.
  prefs: []
  type: TYPE_NORMAL
- en: Business is growing, and the traffic is increasing. Things are beginning to
    fail, and performance is dropping. Firewalls are added, additional load balancers
    are set up, the database is scaled, more application servers are added and so
    on. Things are still relatively simple. We are faced with new challenges, but
    obstacles can be overcome in time. Even though the complexity is increasing, we
    can still handle it with relative ease. In other words, what we're doing is still
    more or less the same but bigger. Business is doing well, but it is still relatively
    small.
  prefs: []
  type: TYPE_NORMAL
- en: And then it happens. The big thing you've been waiting for. Maybe one of the
    marketing campaigns hit the spot. Maybe there was a negative change in your competition.
    Maybe that last feature was indeed a killer one. No matter the reasons, business
    got a big boost. After a short period of happiness due to this change, your pain
    increases tenfold. Adding more databases does not seem to be enough. Multiplying
    application servers does not appear to fulfill the needs. You start adding caching
    and what so not. You start getting the feeling that every time you multiply something,
    benefits are not equally big. Costs increase, and you are still not able to meet
    the demand. Database replications are too slow. New application servers do not
    make such a big difference anymore. Operational costs are increasing faster than
    you expected. The situation hurts the business and the team. You are starting
    to realize that the architecture you were so proud of cannot fulfill this increase
    in load. You can not split it. You cannot scale things that hurt the most. You
    cannot start over. All you can do is continue multiplying with ever decreasing
    benefits of such actions.
  prefs: []
  type: TYPE_NORMAL
- en: The situation described above is quite common. What was good at the beginning,
    is not necessarily right when the demand increases. We need to balance the need
    for **You ain't going to need it** (**YAGNI**) principle and the longer term vision.
    We cannot start with the system optimized for large companies because it is too
    expensive and does not provide enough benefits when business is small. On the
    other hand, we cannot lose the focus from one of the main objectives of any business.
    We cannot not think about scaling from the very first day. Designing scalable
    architecture does not mean that we need to start with a cluster of a hundred servers.
    It does not mean that we have to develop something big and complex from the start.
    It means that we should start small, but in the way that, when it becomes big,
    it is easy to scale. While microservices are not the only way to accomplish that
    goal, they are indeed a good way to approach this problem. The cost is not in
    development but operations. If operations are automated, that cost can be absorbed
    quickly and does not need to represent a massive investment. As you already saw
    (and will continue seeing throughout the rest of the book), there are excellent
    open source tools at our disposal. The best part of automation is that the investment
    tends to have lower maintenance cost than when things are done manually.
  prefs: []
  type: TYPE_NORMAL
- en: We already discussed microservices and automation of their deployments on a
    tiny scale. Now it's time to convert this small scale to something bigger. Before
    we jump into practical parts, let us explore what are some of the different ways
    one might approach scaling.
  prefs: []
  type: TYPE_NORMAL
- en: We are often limited by our design and choosing the way applications are constructed
    limits our choices severely. Although there are many different ways to scale,
    most common one is called *Axis Scali* *ng*.
  prefs: []
  type: TYPE_NORMAL
- en: Axis scaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Axis scaling can be best represented through three dimensions of a cube; *x-axis*,
    *y-axis* and *z-axis*. Each of those dimensions describes a type of scaling.
  prefs: []
  type: TYPE_NORMAL
- en: '**X-Axis**: Horizontal duplication'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Y-Axis**: Functional decomposition'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Z-Axis**: Data partitioning![Axis scaling](img/B05848_14_01.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 14-1 – Scale cube
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let's go through axes, one at the time.
  prefs: []
  type: TYPE_NORMAL
- en: X-Axis scaling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In a nutshell, *x-axis scaling* is accomplished by running multiple instances
    of an application or a service. In most cases, there is a load balancer on top
    that makes sure that the traffic is shared among all those instances. The biggest
    advantage of x-axis scaling is simplicity. All we have to do is deploy the same
    application on multiple servers. For that reason, this is the most commonly used
    type of scaling. However, it comes with its set of disadvantages when applied
    to monolithic applications. Having a huge application usually requires big cache
    that demands heavy usage of memory. When such an application is multiplied, everything
    is multiplied by it, including the cache.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another, often more important, problem is inappropriate usage of resources.
    Performance problems are almost never related to the whole application. Not all
    modules are equally affected, and, yet, we multiply everything. That means that
    even though we could be better of by scaling only part of the application that
    require such an action, we scale everything. Never the less, x-scaling is important
    no matter the architecture. The major difference is the effect that such a scaling
    has. By using microservices, we are not removing the need for x-axis scaling but
    making sure that due to their architecture such scaling has more effect than with
    alternative and more traditional approaches to architecture. With microservices
    we have the option to fine-tune scaling. We can have many instances of services
    that suffer a lot under heavy load and only a few instances of those that are
    used less often or require fewer resources. On top of that, since they are small,
    we might never reach a limit of a service. A small service in a big server would
    need to receive a truly massive amount of traffic before the need for scaling
    arises. Scaling microservices is more often related to fault tolerance than performance
    problems. We want to have multiple copies running so that, if one of them dies,
    the others can take over until recovery is performed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![X-Axis scaling](img/B05848_14_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-2 – Monolithic application scaled inside a cluster
  prefs: []
  type: TYPE_NORMAL
- en: Y-Axis scaling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Y-axis scaling is all about decomposition of an application into smaller services.
    Even though there are different ways to accomplish this decomposition, microservices
    are probably the best approach we can take. When they are combined with immutability
    and self-sufficiency, there is indeed no better alternative (at least from the
    prism of y-axis scaling). Unlike x-axis scaling, the y-axis is not accomplished
    by running multiple instances of the same application but by having multiple different
    services distributed across the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Z-Axis scaling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Z-axis scaling is rarely applied to applications or services. Its primary and
    most common usage is among databases. The idea behind this type of scaling is
    to distribute data among multiple servers thus reducing the amount of work that
    each of them needs to perform. Data is partitioned and distributed so that each
    server needs to deal only with a subset of the data. This type of the separation
    is often called sharding, and there are many databases specially designed for
    this purpose. Benefits of z-axis scaling are most noticeable in I/O and cache
    and memory utilization.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A server cluster consists of a set of connected servers that work together and
    can be seen as a single system. They are usually connected through fast local
    area network (LAN). The major difference between a cluster and simply a group
    of servers is that the cluster acts as a single system trying to provide high
    availability, load balancing, and parallel processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we deploy applications, or services, to individually managed servers and
    treat them as separate units, the utilization of resources is sub-optimum. We
    cannot know in advance which group of services should be deployed to a server
    and utilize resources to their maximum. More importantly, resource usage tends
    to fluctuate. While, in the morning, some service might require a lot of memory,
    during the afternoon that usage might be lower. Having predefined servers does
    not allow us elasticity that would balance that usage in the best possible way.
    Even if such a high level of dynamism is not required, predefined servers tend
    to create problems when something goes wrong, resulting in manual actions to redeploy
    the affected services to a healthy node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Clustering](img/B05848_14_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-3 – Cluster with containers deployed to predefined servers
  prefs: []
  type: TYPE_NORMAL
- en: Real clustering is accomplished when we stop thinking in terms of individual
    servers and start thinking of a cluster; of all servers as one big entity. That
    can be better explained if we drop to a bit lower level. When we deploy an application,
    we tend to specify how much memory or CPU it might need. However, we do not decide
    which memory slots our application will use nor which CPUs it should utilize.
    For example, we don't specify that some application should use CPUs 4, 5 and 7\.
    That would be inefficient and potentially dangerous. We only decide that three
    CPUs are required. The same approach should be taken on a higher level. We should
    not care where an application or a service will be deployed but what it needs.
    We should be able to define that the service has certain requirements and tell
    some tool to deploy it to whichever server in our cluster, as long as it fulfills
    the needs we have. The best (if not the only) way to accomplish that is to consider
    the whole cluster as one entity. We can increase or decrease the capacity of that
    cluster by adding or removing servers but, no matter what we do, it should still
    be a single entity. We define a strategy and let our services be deployed somewhere
    inside the cluster. Those using cloud providers like **Amazon Web Services** (**AWS**),
    Microsoft's Azure and **Google Cloud Engine** (**GCP**) are already accustomed
    to this approach, even though they might not be aware of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout the rest of this chapter, we''ll explore ways to create our cluster
    and explore tools that can help us with that objective. The fact that we''ll be
    simulating the cluster locally does not mean that the same strategies cannot be
    applied to public or private clouds and data centers. Quite the opposite:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Clustering](img/B05848_14_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-4 – Cluster with containers deployed to servers based on a predefined
    strategy
  prefs: []
  type: TYPE_NORMAL
- en: Docker Clustering Tools Compared – Kubernetes versus Docker Swarm versus Mesos
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes and Docker Swarm are probably the two most commonly used tools to
    deploy containers inside a cluster. Both are created as helper platforms that
    can be used to manage a cluster of containers and treat all servers as a single
    unit. While their goals are, somewhat, similar, they differ considerably in their
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Kubernetes is based on Google's experience of many years working with Linux
    containers. It is, in a way, a replica of what Google has been doing for a long
    time but, this time, adapted to Docker. That approach is great in many ways, most
    important being that they used their experience from the start. If you started
    using Kubernetes around Docker version 1.0 (or earlier), the experience with Kubernetes
    was great. It solved many of the problems that Docker itself had. We can mount
    persistent volumes that allow us to move containers without losing data, it uses
    flannel to create networking between containers, it has load balancer integrated,
    it uses etcd for service discovery, and so on. However, Kubernetes comes at a
    cost. When compared with Docker, it uses a different CLI, different API, and different
    YAML definitions. In other words, you cannot use Docker CLI, nor you can use Docker
    Compose to define containers. Everything needs to be done from scratch exclusively
    for Kubernetes. It's as if the tool was not written for Docker (which is partly
    true). Kubernetes brought clustering to a new level but at the expense of usability
    and steep learning curve.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Docker Swarm took a different approach. It is a native clustering for Docker.
    The best part is that it exposes standard Docker API meaning that any tool that
    you used to communicate with Docker (Docker CLI, Docker Compose, Dokku, Krane,
    and so on) can work equally well with Docker Swarm. That in itself is both an
    advantage and a disadvantage at the same time. Being able to use familiar tools
    of your choosing is great but for the same reasons we are bound by the limitations
    of Docker API. If the Docker API doesn't support something, there is no way around
    it through Swarm API, and some clever tricks need to be performed.
  prefs: []
  type: TYPE_NORMAL
- en: Apache Mesos
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The next in line of tools that can be used to manage a cluster is Apache Mesos.
    It is the clustering veteran. Mesos abstracts CPU, memory, storage, and other
    resources away from machines (physical or virtual), enabling fault-tolerant and
    elastic distributed systems to be easily built and run efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Mesos is made using the same principles as the Linux kernel, only at a different
    level of abstraction. Mesos kernel runs on every machine and provides applications
    with APIs for resource management and scheduling across entire datacenter and
    cloud environments. Unlike Kubernetes and Docker Swarm, Mesos is not limited to
    containers. It can work with almost any type of deployments including Docker containers.
  prefs: []
  type: TYPE_NORMAL
- en: Mesos uses Zookeeper for service discovery. It uses Linux containers to isolate
    processes. If, for example, we deploy Hadoop without using Docker, Mesos will
    run it as a native Linux container providing similar features as if we packed
    it as a Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: Mesos provides few features that Swarm doesn't have at this moment, mainly more
    powerful scheduler. Apart from the scheduler, what makes Mesos attractive is that
    we can use it for both Docker and non-Docker deployments. Many organizations might
    not want to use Docker, or they might decide to use a combination of both Docker
    and non-Docker deployments. In such a case, Mesos is truly an excellent option
    if we do not want to deal with two sets of clustering tools; one for containers
    and the other for the rest of deployments.
  prefs: []
  type: TYPE_NORMAL
- en: However, Mesos is old and too big for what we're trying to accomplish. More
    importantly, Docker containers are an afterthought. The platform was not designed
    with them in mind but added Docker support later on. Working with Docker and Mesos
    feels awkward, and it becomes apparent from the very start that those two were
    not meant to be used together. Given the existence of Swarm and Kubernetes, there
    is nothing that Mesos can offer to those decided to embrace Docker. Mesos is falling
    behind. The main advantage it has over the other two tools is its wide adoption.
    Many started using it before the emergence of Docker and might choose stick with
    it. For those that have the option to start fresh, the choice should fall between
    Kubernetes and Docker Swarm.
  prefs: []
  type: TYPE_NORMAL
- en: We'll explore Kubernetes and Docker Swarm in more details and leave Mesos behind.
    The exploration will be based on their setup and features they provide for running
    containers in a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Setting It Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Setting up Docker Swarm is easy, straightforward and flexible. All we have to
    do is install one of the service discovery tools and run the `swarm` container
    on all nodes. Since the distribution itself is packed in a Docker container, it
    works in the same way no matter the operating system. We run the `swarm` container,
    expose a port and inform it about the address of the service discovery. It could
    hardly be easier than that. We can even start using it without any service discovery
    tool, see whether we like it and when our usage of it becomes more serious, add
    etcd, Consul or some of the other supported tools.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes setup is quite more complicated and obfuscated. Installation instructions
    differ from OS to OS and provider to provider. Each OS or a hosting provider comes
    with its set of instructions, each of them having a separate maintenance team
    with a different set of problems. As an example, if you choose to try it out with
    Vagrant, you are stuck with Fedora. That does not mean that you cannot run it
    with Vagrant and, let's say, Ubuntu or CoreOS. You can, but you need to start
    searching for instructions outside the official Kubernetes Getting Started page.
    Whatever your needs are, it's likely that the community has the solution, but
    you still need to spend some time searching for it and hoping that it works from
    the first attempt. The bigger problem is that the installation relies on a bash
    script. That would not be a big deal in itself if we would not live in the era
    where configuration management is a must. We might not want to run a script but
    make Kubernetes be part of our Puppet, Chef, or Ansible definitions. Again, this
    can be overcome as well. You can find Ansible playbooks for running Kubernetes,
    or you can write your own. None of those issues are a big problem but, when compared
    with Swarm, they are a bit painful. With Docker, we were supposed not to have
    installation instructions (aside from a few `docker run` arguments). We were supposed
    to run containers. Swarm fulfills that promise, and Kubernetes doesn't.
  prefs: []
  type: TYPE_NORMAL
- en: While some might not care about which discovery tool is used, I love the simplicity
    of Swarm and the logic "batteries included but removable". Everything works out-of-the-box,
    but we still have the option to substitute one component for the other. Unlike
    Swarm, Kubernetes is an opinionated tool. You need to live with the choices it
    made for you. If you want to use Kubernetes, you have to use etcd. I'm not trying
    to say that etcd is bad (quite contrary), but if you prefer, for example, to use
    Consul, you're in a very complicated situation and would need to use one for Kubernetes
    and the other for the rest of your service discovery needs. Another thing I dislike
    about Kubernetes is its need to know things in advance, before the setup. You
    need to tell it the addresses of all your nodes, which role each of them has,
    how many minions there are in the cluster and so on. With Swarm, we just bring
    up a node and tell it to join the network. Nothing needs to be set in advance
    since the information about the cluster is propagated through the `gossip` protocol.
  prefs: []
  type: TYPE_NORMAL
- en: Setup might not be the most significant difference between those tools. No matter
    which tool you choose, sooner or later everything will be up and running, and
    you'll forget any trouble you might have had during the process. You might say
    that we should not choose one tool over the other only because one is easier to
    set up. Fair enough. Let's move on and speak about differences in how you define
    containers that should be run with those tools.
  prefs: []
  type: TYPE_NORMAL
- en: Running Containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do you define all the arguments needed for running Docker containers with
    Swarm? You don't! Actually, you do, but not in any form or way different from
    the way you were defining them before Swarm. If you are used to running containers
    through Docker CLI, you can keep using it with (almost) the same commands. If
    you prefer to use Docker Compose to run containers, you can continue using it
    to run them inside the Swarm cluster. Whichever way you've used to run your containers,
    the chances are that you can continue doing the same with Swarm but on a much
    larger scale.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes requires you to learn its CLI and configurations. You cannot use
    `docker-compose.yml` definitions you created earlier. You'll have to create Kubernetes
    equivalents. You cannot use Docker CLI commands you learned before. You'll have
    to learn Kubernetes CLI and, likely, make sure that the whole organization learns
    it as well.
  prefs: []
  type: TYPE_NORMAL
- en: No matter which tool you choose for deployments to your cluster, chances are
    you are already familiar with Docker. You are probably already used to Docker
    Compose as a way to define arguments for the containers you'll run. If you played
    with it for more than a few hours, you are using it as a substitute for Docker
    CLI. You run containers with it, tail their logs, scale them, and so on. On the
    other hand, you might be a hard-core Docker user who does not like Docker Compose
    and prefers running everything through Docker CLI or you might have your bash
    scripts that run containers for you. No matter what you choose, it should work
    with Docker Swarm.
  prefs: []
  type: TYPE_NORMAL
- en: If you adopt Kubernetes, be prepared to have multiple definitions of the same
    thing. You will need Docker Compose to run your containers outside Kubernetes.
    Developers will continue needing to run containers on their laptops, your staging
    environments might or might not be a big cluster, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, once you adopt Docker, Docker Compose or Docker CLI are unavoidable.
    You have to use them one way or another. Once you start using Kubernetes you will
    discover that all your Docker Compose definitions (or whatever else you might
    be using) need to be translated to Kubernetes way of describing things and, from
    there on, you will have to maintain both. With Kubernetes, everything will have
    to be duplicated resulting in higher cost of maintenance. And it's not only about
    duplicated configurations. Commands you'll run outside the cluster will be different
    from those inside the cluster. All those Docker commands you learned and love
    will have to get their Kubernetes equivalents inside the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Guys behind Kubernetes are not trying to make your life miserable by forcing
    you to do things "their way". The reason for such a big differences is in different
    approaches Swarm and Kubernetes are using to tackle the same problem. Swarm team
    decided to match their API with the one from Docker. As a result, we have (almost)
    full compatibility. Almost everything we can do with Docker we can do with Swarm
    as well only on a much larger scale. There's nothing new to do, no configurations
    to be duplicated and nothing new to learn. No matter whether you use Docker CLI
    directly or go through Swarm, API is (more or less) the same. The negative side
    of that story is that if there is something you'd like Swarm to do and that something
    is not part of the Docker API, you're in for a disappointment. Let us simplify
    this a bit. If you're looking for a tool for deploying containers in a cluster
    that will use Docker API, Swarm is the solution. On the other hand, if you want
    a tool that will overcome Docker limitations, you should go with Kubernetes. It
    is power (Kubernetes) against simplicity (Swarm). Or, at least, that's how it
    was until recently. But, I'm jumping ahead of myself.
  prefs: []
  type: TYPE_NORMAL
- en: The only question unanswered is what those limitations are. Two of the major
    ones were networking, persistent volumes and automatic failover in case one or
    more containers or a whole node stopped working.
  prefs: []
  type: TYPE_NORMAL
- en: Until Docker Swarm release 1.0 we could not link containers running on different
    servers. We still cannot link them, but now we have `multi-host networking` to
    help us connect containers running on different servers. It is a very powerful
    feature. Kubernetes used `flannel` to accomplish networking and now, since the
    Docker release 1.9, that feature is available as part of Docker CLI.
  prefs: []
  type: TYPE_NORMAL
- en: Another problem was persistent volumes. Docker introduced them in release 1.9\.
    Until recently, if you persist a volume, that container was tied to the server
    that volume resides. It could not be moved around without, again, resorting to
    some nasty tricks like copying volume directory from one server to another. That
    in itself is a slow operation that defies the goals of the tools like Swarm. Besides,
    even if you have time to copy a volume from one to the other server, you do not
    know where to copy since clustering tools tend to treat your whole datacenter
    as a single entity. Your containers will be deployed to a location most suitable
    for them (least number of containers running, most CPUs or memory available, and
    so on). Now we have persistent volumes supported by Docker natively.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, automatic failover is probably the only feature advantage Kubernetes
    has over Swarm. However, failover solution provided by Kuberentes is incomplete.
    If a container goes down, Kubernetes will detect that and start it again on a
    healthy node. The problem is that containers or whole nodes often do not fail
    for no reason. Much more needs to be done than a simple re-deployment. Someone
    needs to be notified, information before a failure needs to be evaluated, and
    so on. If re-deployment is all you need, Kubernetes is a good solution. If more
    is needed, Swarm, due to its "batteries included but removable" philosophy, allows
    you to build your solution. Regarding the failover, it's a question whether to
    aim for an out-of-the-box solution (Kubernetes) that is hard to extend or go for
    a solution that is built with the intention to be easily extended (Swarm).
  prefs: []
  type: TYPE_NORMAL
- en: Both networking and persistent volumes problems were one of the features supported
    by Kubernetes for quite some time and the reason many were choosing it over Swarm.
    That advantage disappeared with Docker release 1.9\. Automatic fail-over remains
    an advantage Kubernetes has over Swarm when looking at out-of-the-box solutions.
    In the case of Swarm, we need to develop failover strategies ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: The Choice
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When trying to make a choice between Docker Swarm and Kubernetes, think in following
    terms. Do you want to depend on Docker solving problems related to clustering.
    If you do, choose Swarm. If Docker does not support something, it will be unlikely
    that it will be supported by Swarm since it relies on Docker API. On the other
    hand, if you want a tool that works around Docker limitations, Kubernetes might
    be the right one for you. Kubernetes was not built around Docker but is based
    on Google's experience with containers. It is opinionated and tries to do things
    in its own way.
  prefs: []
  type: TYPE_NORMAL
- en: The real question is whether Kubernetes' way of doing things, which is quite
    different from how we use Docker, is overshadowed by advantages it gives. Or,
    should we place our bets into Docker itself and hope that it will solve those
    problems? Before you answer those questions, take a look at the Docker release
    1.9\. We got persistent volumes and software networking. We also got `unless-stopped`
    restart policy that will manage our unwanted failures. Now, there are three things
    less of a difference between Kubernetes and Swarm. Actually, these days there
    are very few advantages Kubernetes has over Swarm. Automatic failover featured
    by Kubernetes is a blessing and a curse at the same time. On the other hand, Swarm
    uses Docker API meaning that you get to keep all your commands and Docker Compose
    configurations. Personally, I'm placing my bets on Docker engine getting improvements
    and Docker Swarm running on top of it. The difference between the two is small.
    Both are production ready but Swarm is easier to set up, easier to use and we
    get to keep everything we built before moving to the cluster; there is no duplication
    between cluster and non-cluster configurations.
  prefs: []
  type: TYPE_NORMAL
- en: My recommendation is to go with Docker Swarm. Kubernetes is too opinionated,
    hard to set up, too different from Docker CLI/API and at the same time, besides
    automatic failover, it doesn't have real advantages over Swarm since the Docker
    release 1.9\. That doesn't mean that there are no features available in Kubernetes
    that are not supported by Swarm. There are feature differences in both directions.
    However, those differences are, in my opinion, not significant ones and the gap
    is getting smaller with each Docker release. Actually, for many use cases, there
    is no gap at all while Docker Swarm is easier to set up, learn and use.
  prefs: []
  type: TYPE_NORMAL
- en: Let us give Docker Swarm a spin and see how it fares.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm walkthrough
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To set up Docker Swarm, we need one of the service discovery tools. Consul
    served us well, and we''ll continue using it for this purpose. It is a great tool
    and works well with Swarm. We''ll set up three servers. One will act as master
    and the other two as cluster nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker Swarm walkthrough](img/B05848_14_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-5 – Docker Swarm cluster with Consul used for service discovery
  prefs: []
  type: TYPE_NORMAL
- en: 'Swarm will use Consul instances to register and retrieve information about
    nodes and services deployed in them. Whenever we bring up a new node or halt an
    existing one, that information will be propagated to all Consul instances and
    reach Docker Swarm, which, in turn, will know where to deploy our containers.
    The master node will have Swarm master running. We''ll use its API to instruct
    Swarm what to deploy and what the requirements are (number of CPUs, the amount
    of memory, and so on). Node servers will have Swarm nodes deployed. Each time
    Swarm master receives an instruction to deploy a container, it will evaluate the
    current situation of the cluster and send instructions to one of the nodes to
    perform the deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker Swarm walkthrough](img/B05848_14_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-6 – Docker Swarm cluster with one master and two nodes
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll start with the *spread* strategy that will deploy containers to a node
    that has the least number of containers running. Since, in the beginning, nodes
    will be empty, when given instruction to deploy the first container, Swarm master
    will propagate it to one of the nodes since both are empty at the moment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker Swarm walkthrough](img/B05848_14_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-7 – Docker Swarm cluster with the first container deployed
  prefs: []
  type: TYPE_NORMAL
- en: 'When given the second instruction to deploy a container, Swarm master will
    decide to propagate it to the other Swarm node, since the first already has one
    container running:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker Swarm walkthrough](img/B05848_14_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-8 – Docker Swarm cluster with the second container deployed
  prefs: []
  type: TYPE_NORMAL
- en: 'If we continue deploying containers, at some point our tiny cluster will become
    saturated, and something would need to be done before the server collapses:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker Swarm walkthrough](img/B05848_14_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-9 – Docker Swarm cluster with all nodes full
  prefs: []
  type: TYPE_NORMAL
- en: 'The only thing we would need to do to increase the cluster capacity is to bring
    up a new server with Consul and Swarm node. As soon as such a node is brought
    up, its information would be propagated throughout Consul instances as well as
    to Swarm master. From that moment on, Swarm would have that node in the account
    for all new deployments. Since this server would start with no containers and
    we are using a simple *spread* strategy, all new deployments would be performed
    on that node until it reaches the same number of running containers as the others:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker Swarm walkthrough](img/B05848_14_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-10 – Docker Swarm cluster with container deployed to the new node
  prefs: []
  type: TYPE_NORMAL
- en: 'Opposite scenario can be observed in case one node stops responding due to
    a failure. Consul cluster would detect that one of it''s members is not responding
    and propagate that information throughout the cluster, thus reaching Swarm master.
    From that moment on, all new deployments would be sent to one of the healthy nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Docker Swarm walkthrough](img/B05848_14_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-11 – Docker Swarm cluster one node failed and containers distributed
    over healthy nodes
  prefs: []
  type: TYPE_NORMAL
- en: Let us dive into simple examples we just discussed. Later on, we'll explore
    other strategies as well as the ways Swarm behaves when certain constraints are
    set; CPU, memory and the like.
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up Docker Swarm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To see Docker Swarm in action, we''ll simulate an Ubuntu cluster. We''ll bring
    up the `cd` node that we''ll use for orchestration, one node that will act as
    Swarm master and two nodes that will form the cluster. Up to this point, we always
    used Ubuntu 14.04 LTS (long term support) since it is considered stable and supported
    for a long time. The next long term support version will be 15.04 LTS (not released
    at the time this book was written). Since some of the features we''ll explore
    later on, throughout this chapter, will need a relatively new Kernel, the `swarm`
    nodes will be running Ubuntu 15.04\. If you open the Vagrantfile, you''ll notice
    that Swarm master and nodes have the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`Vivid64` is the code name for Ubuntu 15.04.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us bring up the nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'With all the four nodes up and running, we can proceed, and create the Swarm
    cluster. As before, we''ll do the provisioning using Ansible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us use our time wisely and explore the `swarm.yml` playbook, while Ansible
    is provisioning our servers. The content of the `swarm.yml` file is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We started by setting up *docker*. Since this time we're using a different version
    of Ubuntu, we had to specify those differences as variables, so that the correct
    repository is used (`debian_version`), as well as to reload service configuration
    (`is_systemd`). We also set the `docker_cfg_dest` variable so that the configuration
    file is sent to the correct location.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have few more variables set in the `hosts/prod` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We'll explore `swarm_master` and `swarm_master_ip` later on. For now, please
    remember that they are defined in the `prod` file so that they can be applied
    (or omitted) based on the server type (master or node). Depending on whether we
    are provisioning master or node, Docker configuration file is `docker-swarm-master.service`
    or `docker-swarm-node.service`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the `ExecStart` part of the master node Docker configuration
    (the rest is the same as the standard one that comes with the Docker package)
    defined in `roles/docker/templates/docker-swarm-master.service`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re telling Docker to allow insecure registry on the IP/port where our private
    registry runs (located in the `cd` node). We''re also specifying that Swarm cluster
    information should be stored in Consul running on the same node, as well as that
    it should be advertised to the port `2375`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The node configuration defined in `roles/docker/templates/docker-swarm-node.service`
    has few more arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Apart from those arguments that are the same as in the master node, we''re
    telling Docker to allow communication on the port `2375` (`-H tcp://0.0.0.0:2375`)
    as well as through the socket (`-H unix:///var/run/docker.sock`):'
  prefs: []
  type: TYPE_NORMAL
- en: Both `master` and `node` configurations are following the standard settings
    recommended by the official Docker Swarm documentation when used in conjunction
    with Consul.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the roles used in the `swarm.yml` playbook are `consul`, `swarm`,
    and `registrator`. Since we already used and saw Consul and Registrator roles,
    we''ll explore only tasks belonging to the `swarm` role defined in the `roles/swarm/tasks/main.yml`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, running Swarm is pretty straightforward. All we have to do is
    run the `swarm` container and, depending on whether it's master or node, specify
    one command or the other. If server acts as a Swarm node, the command is `join
    --advertise={{ ip }}:2375 consul://{{ ip }}:8500/swarm` which, translated into
    plain words, means that it should join the cluster, advertise its existence on
    port `2375` and use Consul running on the same server for service discovery. The
    command that should be used in the Swarm master is even shorter; `manage consul://{{
    ip }}:8500/swarm`. All we had to do is specify that this Swarm container should
    be used to manage the cluster and, as with Swarm nodes, use Consul for service
    discovery.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, the playbook we run earlier finished its execution. If it didn't,
    grab a coffee and continue reading once it's done. We're about to check whether
    our Swarm cluster is working as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Since we are still inside the `cd` node, we should tell Docker CLI to use a
    different host.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'With the Docker client running on `cd` and using the `swarm-master` node as
    a host, we can control the Swarm cluster remotely. For a start, we can check the
    information of our cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Isn't this great? With a single command, we have an overview of the whole cluster.
    While, at this moment, we have only two servers (`swarm-node-1` and `swarm-node-2`),
    if there would be hundred, thousand, or even more nodes, `docker info` would provide
    information about all of them. In this case, we can see that four containers are
    running and four images. That is correct since each node is running Swarm and
    Registrator containers. Further on, we can see the `Role`, `Strategy`, and `Filters`.
    Next in the line are nodes that constitute our cluster followed by information
    about each of them. We can see how many containers each is running (currently
    two), how many CPUs and memory is reserved for our containers, and labels associated
    with each node. Finally, we can see the total number of CPUs and memory of the
    whole cluster. Everything presented by `docker info` acts not only as information
    but also a functionality of the Swarm cluster. For now, please note that all this
    information is available for inspection. Later on, we'll explore how to utilize
    it for our benefit.
  prefs: []
  type: TYPE_NORMAL
- en: 'The best part of Docker Swarm is that it shares the same API as Docker, so
    all the commands we already used throughout this book are available. The only
    difference is that instead of operating Docker on a single server, with Swarm
    we are operating a whole cluster. For example, we can list all images and processes
    throughout the entire Swarm cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'By running `docker images` and `docker ps -a` we can observe that there are
    two images pulled into the cluster and four containers running (two containers
    on each of the two servers). The only visual difference is that names of running
    containers are prefixed with the name of the server they are running on. For example,
    the container named `registrator` is presented as `swarm-node-1/registrator` and
    `swarm-node-2/registrator`. The combined output of those two commands is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now that we know that Docker commands work in the same way when run against
    the remote server (`swarm-master`) and can be used to control the whole cluster
    (`swarm-node-1` and `swarm-nod` `e-2`), let's try to deploy our `books-ms` service.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying with Docker Swarm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll start by repeating the same deployment process we did before, but, this
    time, we''ll be sending commands to the Swarm master:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We cloned the `books-ms` repository and, now, we can run the service through
    Docker Compose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the `app` target is linked with the `db`, Docker Compose run both. So
    far, everything looks the same as if we run the same command without Docker Swarm.
    Let us take a look at the processes that were created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, both containers are running on `swarm-node-2`. In your case,
    it could be `swarm-node-1`. We did not make the decision where to deploy the containers.
    Swarm did that for us. Since we are using the default strategy that, without specifying
    additional constraints, runs containers on a server that has the least number
    of them running. Since both `swarm-node-1` and `swarm-node-2` were equally empty
    (or full), Swarm had an easy choice and could have placed containers on either
    one of those servers. In this case, it chose `swarm-node-2`.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with the deployment we just performed is that the two targets (`app`
    and `db`) are linked. In such a case, Docker has no other option but to place
    both containers on the same server. That, in a way, defies the objective we're
    trying to accomplish. We want to deploy containers to the cluster and, as you'll
    soon discover, be able to scale them easily. If both containers need to be run
    on the same server, we are limiting Swarm's ability to distribute them properly.
    In this example, those two containers would be better of running on separate servers.
    If, before deploying those containers, both servers had the equal number of containers
    running, it would make more sense to run the `app` on one and the `db` on the
    other. That way we'd distribute resource usage much better. As it is now, the
    `swarm-node-2` needs to do all the work, and the `swarm-node-1` is empty. The
    first thing we should do is to get rid of the link.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s stop the containers we''re running and start over:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: That was another example of advantages Swarm provides. We sent the `stop` and
    `rm` commands to the Swarm master and it located containers for us. From now on,
    all the behavior will be the same, in the sense that, through the Swarm master,
    we'll treat the whole cluster as one single unit oblivious of the specifics of
    each server.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying with Docker Swarm without Links
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To deploy containers to Docker Swarm cluster properly, we''ll use a different
    file for Docker Compose definition; `docker-compose-no-links.yml`. The targets
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The only significant difference between `app` and `db` targets defined in `docker-compose.yml`
    and `docker-compose-swarm.yml` is that the latter does not use links. As you will
    see soon, this will allow us to distribute freely containers inside the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at what happens if we bring up *db* and *app* containers without
    the link.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the `docker ps` command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this time, Swarm decided to place each container on a different
    server. It brought up the first container and, since from that moment on one server
    had more containers than the other, it choose to bring up the second on the other
    node.
  prefs: []
  type: TYPE_NORMAL
- en: 'By removing linking between containers, we solved one problem but introduced
    another. Now our containers can be distributed much more efficiently, but they
    cannot communicate with each other. We can address this issue by using a `proxy`
    service (nginx, HAProxy, and so on). However, our `db` target does not expose
    any ports to the outside world. A good practice is to expose only ports of services
    that are publicly accessible. For that reason, the `app` target exposes port `8080`
    and the `db` target doesn''t expose any. The `db` target is meant to be used internally,
    and only by the `app`. Since the Docker release 1.9, linking can be considered
    deprecated, for a new feature called *networking*:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s remove the containers and try to bring them up networking enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Deploying with Docker Swarm and Docker Networking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At the time I was writing this chapter, Docker introduced the new release 1.9\.
    It is, without a doubt, the most significant release, since version 1.0\. It gave
    us two long awaited features; multi-host networking and persistent volumes. Networking
    makes linking deprecated and is the feature we need to connect containers across
    multiple hosts. There is no more need for proxy services to connect containers
    internally. That is not to say that proxy is not useful, but that we should use
    a proxy as a public interface towards our services and networking for connecting
    containers that form a logical group. The new Docker networking and proxy services
    have different advantages and should be used for different use cases. Proxy services
    provide load balancing and can control the access to our services. Docker networking
    is a convenient way to connect separate containers that form a single service
    and reside on the same network. A typical use case for Docker networking would
    be a service that requires a connection to a database. We can connect those two
    through networking. Furthermore, the service itself might need to be scaled and
    have multiple instances running. A proxy service with load balancer should fulfill
    that requirement. Finally, other services might need to access this service. Since
    we want to take advantage of load balancing, that access should also be through
    a proxy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying with Docker Swarm and Docker Networking](img/B05848_14_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-12 – Multi-host networking combined with a proxy and load balancing
    service
  prefs: []
  type: TYPE_NORMAL
- en: The figure 14-12 represents one common use case. We have a scaled service with
    two instances running on `nodes-01` and `nodes-03`. All communication to those
    services is performed through a proxy service that takes care of load balancing
    and security. Any service (be it external or internal) that wants to access our
    service needs to go through the proxy. Internally, the service uses the database.
    The communication between the service instances and the database is internal and
    performed through the multi-host network. This setting allows us to scale easily
    within the cluster while keeping internal all communication between containers
    that compose a single service. In other words, all communication between containers
    that compose a single service is done through networking while the communication
    between services is performed through the proxy.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different ways to create a multi-host network. We can set up the
    network manually:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the `network ls` command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that one of the networks is `my-network` we created earlier. It
    spans the whole Swarm cluster and we can use it with the `--net` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We started two containers that compose a single service; `books-ms` is the API
    that communicates with `books-ms-db` that acts as a database. Since both containers
    had the `--net my-network` argument, they both belong to the `my-network` network.
    As a result, Docker updated hosts file providing each container with an alias
    that can be used for internal communication.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s enter the `books-ms` container and take a look at the hosts file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the `exec` command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The interesting part of the `hosts` file are the last two entries. Docker detected
    that the `books-ms-db` container uses the same network as the `books-ms` container,
    and updated the `hosts` file by adding `books-ms-db` and `books-ms-db.my-network`
    aliases. If some convention is used, it is trivial to code our services in a way
    that they use aliases like that one to communicate with resources located in a
    separate container (in this case with the database).
  prefs: []
  type: TYPE_NORMAL
- en: 'We also passed an environment variable `DB_HOST` to the `book-ms`. That indicates
    to our service which host to use to connect to the database. We can see this by
    outputting environments of the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, one of the environment variables is `DB_HOST` with the value
    `books-ms-db`.
  prefs: []
  type: TYPE_NORMAL
- en: What we have right now is Docker networking that created hosts alias `books-ms-db`
    pointing to the IP of the network Docker created. We also have an environment
    variable `DB_HOST` with value `books-ms-db`. The code of the service uses that
    variable to connect to the database.
  prefs: []
  type: TYPE_NORMAL
- en: As expected, we can specify `network` as part of our Docker Compose specification.
    Before we try it out, let's remove those two containers and the network.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, we''ll run containers through Docker Compose. We''ll use the `net`
    argument inside `docker-compose-swarm.yml` and, in that way, do the same process
    as we did earlier. The alternative would be to use new Docker Compose argument
    `--x-networking` that would create the network for us but, at this moment, it
    is in the experimental stage and not entirely reliable. Before we proceed, let
    us take a quick look at the relevant targets inside the `docker-compose-swarm.yml`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The only important difference is the addition of the `net` argument. Everything
    else is, more or less, the same as in many other targets we explored by now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us create the network and run our containers through Docker Compose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the command we just run is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Before creating the services `app` and `db`, we created a new network called
    `books-ms`. The name of the network is the same as the value of the *net* argument
    specified in the `docker-compose-swarm.yml` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can confirm that the network was created by running the `docker network
    ls` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the `overlay` network `books-ms` has been created.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also double check that the `hosts` file inside containers has been updated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s see how did Swarm distribute our containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Swarm deployed the `app` container to the `swarm-node-1` and the `db` container
    to the `swarm-node-2`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s test whether the `book-ms` service is working properly. We
    do not know where did Swarm deploy the container nor which port is exposed. Since
    we do not (yet) have a proxy, we''ll retrieve the IP and the port of the service
    from Consul, send a PUT request to store some data in the database residing in
    a different container and, finally, send a GET request to check whether we can
    retrieve the record. Since we do not have a proxy service that would make sure
    that requests are redirected to the correct server and port, we''ll have to retrieve
    the IP and the port from Consul:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: If the service could not communicate with the database located on a different
    node, we would not be able to put, nor to get data. Networking between containers
    deployed to separate servers worked! All we had to do is use an additional argument
    with Docker Compose (*net*) and make sure that the service code utilizes information
    from the hosts file.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of Docker networking is that, if one container stops working,
    we can redeploy it (potentially to a separate server) and, assuming that the service
    can handle the temporary connection loss, continue using it as if nothing happened.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling Services with Docker Swarm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you''ve already seen, scaling with Docker Compose is easy. While examples
    we run by now were limited to a single server, with Docker Swarm we can extend
    scaling to the whole cluster. Now that we have one instance of `books-ms` running,
    we can scale it to, let''s say, three:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the `ps` command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: We can see that Swarm continues distributing containers evenly. Each node is
    currently running two containers. Since we asked Docker Swarm to scale the `books-ms`
    containers to three, two of them are now running alone and the third one is deployed
    together with the database. Later on, when we start working on the automation
    of the deployment to the Docker Swarm cluster, we'll also make sure that all the
    instances of the service are properly set in the proxy.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the future reference, we might want to store the number of instances in
    Consul. Later on, it might come in handy if, for example, we want to increase
    or decrease that number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we told Swarm to scale (down) to one instance and, at that moment, there
    were three of them running, Swarm removed instances two and three leaving the
    system with only one running. That can be observed from the output of the `docker
    ps` command that is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: We descaled and went back to the beginning, with one instance of each target
    running.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are about to explore few more Swarm options. Before we proceed, let us stop
    and remove running containers, and start over:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Scheduling Containers Depending on Reserved CPUs and Memory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Up until now, Swarm was scheduling deployments to servers that have the least
    number of them running. That is the default strategy applied when there is no
    other constraint specified. It is often not realistic to expect that all containers
    require equal access to resources. We can further refine Swarm deployments by
    giving hints of what we expect from containers. For example, we can specify how
    many CPUs we need for a particular container. Let's give it a spin.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The relevant parts of the output of the command are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Even though we are already running two containers on each node (`Registrator`
    and `Swarm`), there are no reserved CPUs, nor reserved memory. When we run those
    containers, we did not specify that CPU or memory should be reserved.
  prefs: []
  type: TYPE_NORMAL
- en: Let's try running Mongo DB with one CPU reserved for the process. Keep in mind
    that this is only a hint and will not prevent other containers already deployed
    on those servers from using that CPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Since each node has only one CPU assigned, we could not assign more than one.
    The relevant parts of the output of the `docker info` command are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, `swarm-node-1` has one (out of one) CPU reserved. Since there are
    no more available CPUs on that node, if we repeat the process and bring up one
    more Mongo DB with the same constraint, Swarm will have no option but to deploy
    it to the second node. Let''s try it out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The relevant parts of the output of the `ps` command are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: This time, both nodes have all the CPUs reserved.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can take a look at the processes and confirm that both DBs are indeed running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Indeed, both containers are running, one on each node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what happens if we try to bring up one more container that requires
    one CPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, Swarm returned the following error message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: We requested deployment of a container that requires one CPU, and Swarm got
    back to us saying that there are no available nodes that fulfill that requirement.
    Before we proceed to explore other constraints, please bear in mind that *CPU
    Shares* do not work in the same way with Swarm as when applied to a Docker running
    on a single server. For more information regarding such a case, please consult
    [https://docs.docker.com/engine/reference/run/#cpu-share-constraint](https://docs.docker.com/engine/reference/run/#cpu-share-constraint)
    page for more information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s remove our containers and start over:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also use memory as a constraint. For example, we can direct Swarm to
    deploy a container reserving one CPU and one GB of memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the `docker info` command is as follows (limited to relevant
    parts):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'This time not only that one CPU is reserved, but almost all of the memory as
    well. While we could not demonstrate much when using CPU constraints, since our
    nodes have only one each, with memory we have a bit bigger margin to experiment.
    For example, we can bring up three instances of Mongo DB with 100 MB reserved
    for each:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the `docker info` command is as follows (limited to relevant
    parts):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'It is obvious that all of those three containers were deployed to the `swarm-node-2`.
    Swarm realized that the second node had less available memory on the `swarm-node-1`
    and decided to deploy the new container to the `swarm-node-2`. That decision was
    repeated two more times since the same constraints were used. As a result, the
    `swarm-node-2` now has all those three containers running and 300 MB of memory
    reserved. We can confirm that by checking the running processes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: There are many other ways we can give hints to Swarm where to deploy containers.
    We won't explore all of them. I invite you to check Docker documentation for Strategies
    ([https://docs.docker.com/swarm/scheduler/strategy/](https://docs.docker.com/swarm/scheduler/strategy/))and
    Filters ([https://docs.docker.com/swarm/scheduler/filter/](https://docs.docker.com/swarm/scheduler/filter/)).
  prefs: []
  type: TYPE_NORMAL
- en: At this moment, we have more than enough knowledge to attempt deployment automation
    to the Docker Swarm cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we proceed, let''s remove the containers we run until now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Automating Deployment with Docker Swarm and Ansible
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are already familiar with Jenkins Workflow, and it should be relatively easy
    to extend this knowledge to Docker Swarm deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'First things first. We need to provision our `cd` node with Jenkins:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The two playbooks deployed the familiar Jenkins instance with two nodes. This
    time, the slaves we are running are `cd` and `swarm-master`. Among other jobs,
    the playbook created the `books-ms-swarm` job based on the `Multibranch Workflow`.
    The only difference between this and the other multibranch jobs we used earlier
    is in the `Include branches` filter that, this time, is set to `swarm`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Automating Deployment with Docker Swarm and Ansible](img/B05848_14_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-13 – Configuration screen of the books-ms-swarm Jenkins job
  prefs: []
  type: TYPE_NORMAL
- en: Let's index the branches and let the job run while we explore the Jenkinsfile
    located in the `books-ms swarm` branch.
  prefs: []
  type: TYPE_NORMAL
- en: Please open the `books-ms-swarm` job and click **Branch Indexing** followed
    by **Run Now**. Since there is only one branch matching the specified filter,
    Jenkins will create one subproject called `swarm` and start building it. If you
    are curious about the progress of the build, you can monitor the progress by opening
    the build console.
  prefs: []
  type: TYPE_NORMAL
- en: Examining the Swarm Deployment Playbook
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The content of the Jenkins workflow defined in the Jenkinsfile is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: I added comments to the modified and added lines (when compared with Jenkinsfile
    from the previous chapter) so that we can explore the differences from the Jenkinsfile
    defined in the blue-green branch.
  prefs: []
  type: TYPE_NORMAL
- en: The variables `prodIp` and `proxyIp` have been changed to point to the `swarm-master`
    node. This time, we are using two Ansible playbooks to provision the cluster.
    The `swarmPlaybook` variable holds the name of the playbook that configures the
    whole `Swarm` cluster while the `proxyPlaybook` variable references the playbook
    in charge of setting up the `nginx` proxy on the `swarm-master` node. In real
    world situations, Swarm master and the proxy service should be separated but,
    in this case, I opted against an additional VM to save a bit of resources on your
    laptop. Finally, the `instances` variable with the default value of `1` is added
    to the script. We'll explore its usage shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only truly notable difference is the usage of the `deploySwarm` function
    that replaces `deployBG`. It is one more utility function defined in the `workflow-util.groovy`
    script. Its contents are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: As before, we start by pulling the latest container from the registry. The new
    addition is the creation of a Docker network. Since it can be created only once,
    and all subsequent attempts will result in an error, the `sh` command is enclosed
    inside a `try/catch` block that will prevent the script from failing.
  prefs: []
  type: TYPE_NORMAL
- en: The creation of the network is followed by deployment of the `db` and `app`
    targets. Unlike DB that, in this scenario, is always deployed as a single instance,
    the `app` target might need to be scaled. For that reason, the first one is deployed
    through the `up` and the other through the `scale` command available through Docker
    Compose. The `scale` command utilizes the `instances` variable to determine how
    many copies of the release should be deployed. We can increase or decrease their
    number simply by changing the `instances` variable in the Jenkinsfile. Once such
    a change is committed to the repository, Jenkins will run a new build and deploy
    as many instances as we specified.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we are putting the number of instances to Consul by invoking the helper
    function `putInstances` which, in turn. executed a simple Shell command. Even
    though we won't be using the information right now, it will come in handy in the
    next chapter when we start building a self-healing system.
  prefs: []
  type: TYPE_NORMAL
- en: That's it. There were only a few changes we had to apply to the Jenkinsfile
    to have the `blue-green` deployment extended from a single server to the whole
    Swarm cluster. Both Docker Swarm and Jenkins Workflow proved to be very easy to
    work with, even easier to maintain, and, yet, very powerful.
  prefs: []
  type: TYPE_NORMAL
- en: 'By this time, the build of the `swarm` sub-project probably finished. We can
    validate that from the build console screen or, directly, by opening the `books-ms-swarm`
    job and confirming that the status of the last build is represented with the `blue`
    ball. If you are curious why the success is represented with blue instead of green
    color, please read the *Why does Jenkins have blue balls?* article at [https://jenkins.io/blog/2012/03/13/why-does-jenkins-have-blue-balls/](https://jenkins.io/blog/2012/03/13/why-does-jenkins-have-blue-balls/):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Examining the Swarm Deployment Playbook](img/B05848_14_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14-14 – The books-ms-swarm Jenkins job screen
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand what is behind the *Jenkinsfile* script and the build
    is finished, we can manually validate that everything seems to be working correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Running the Swarm Jenkins Workflow
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first run of the swarm subproject was initiated by Jenkins automatically
    once it finished indexing branches. All that's left for us is to double check
    that the whole process was indeed executed correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'This was the first deployment so the blue release should be running somewhere
    inside the cluster. Let''s take a look where did Swarm decide to deploy our containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the ps command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, Swarm deployed the `books-ms` container to the `swarm-node-2`
    and the Mongo DB to the `swarm-node-1`. We can also verify whether the service
    was correctly stored in Consul:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of all three commands is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: According to Consul, the release was deployed to `swarm-node-2` (`10.100.192.202`)
    and has the port `32768`. We are currently running the `blue` release, and have
    only one instance running.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can double check that the service is indeed working by sending
    a few requests to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: The first request was PUT, sending a signal to the service that we want to store
    the book. The second retrieved the list of all books.
  prefs: []
  type: TYPE_NORMAL
- en: The automated process seems to be working correctly when run for the first time.
    We'll execute the build again and deploy the green release.
  prefs: []
  type: TYPE_NORMAL
- en: The Second Run of the Swarm Deployment Playbook
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's deploy the next release.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please open the swarm subproject and click the Build Now link. The build will
    start, and we can monitor it from the Console screen. After a few minutes, the
    build will finish executing, and we''ll be able to check the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the ps command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we run the `green` release, the `blue` release is in the `Exited` status.
    We can observe the information about the currently running release from Consul:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The response from the Consul request is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can test the service itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Since we already have the Consul UI running, please open the `http://10.100.192.200:8500/ui`
    address in your favorite browser to get a visual representation of services we
    deployed.
  prefs: []
  type: TYPE_NORMAL
- en: As an exercise, fork the `books-ms` repository and modify the job to use you
    repository. Open the *Jenkinsfile* inside the `swarm` branch, change it to deploy
    three instances of the service, and push the changes. Run the build again and,
    once it's finished, confirm that three instances were deployed to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning Up
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This concludes our tour of Docker Swarm. We''ll use it more throughout the
    next chapters. Before moving to the next subject, lets destroy the VMs. We''ll
    create them again when we need them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: The solution we developed still has quite a few problems. The system is not
    fault tolerant, and is difficult to monitor. The next chapter will address the
    first of those problems through creation of a self-healing system.
  prefs: []
  type: TYPE_NORMAL
