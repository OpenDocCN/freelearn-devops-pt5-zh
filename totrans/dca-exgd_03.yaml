- en: Building Docker Images
  prefs: []
  type: TYPE_NORMAL
- en: Building images is the first step in deploying your own container-based applications.
    It is a simple process and anyone can build images from scratch, but it is not
    easy to create images with sufficient quality and security for production. In
    this chapter, we will learn all the basics and tips and tricks for creating good,
    production-ready images. We will review the requirements for saving and distributing
    our work, as well as how to improve these processes to get better performance
    when the number of images and releases is substantial in enterprise environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Building Docker images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding copy-on-write filesystems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building images with a Dockerfile reference
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image tagging and meta-information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker registries and repositories
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Securing images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing images and other related objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multistage building and image caches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Templating images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image releases and updates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn about Docker image building concepts. We'll provide
    some labs at the end of this chapter that will help you understand and learn about
    the concepts explained here. These labs can be run on your laptop or PC using
    the provided Vagrant standalone environment or any already deployed Docker host
    of your own. You can find additional information in this book's GitHub repository
    at [https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git](https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '"[https://bit.ly/31v3AJq](https://bit.ly/31v3AJq)"'
  prefs: []
  type: TYPE_NORMAL
- en: Building Docker images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Developers create their own images, along with their own code and runtime components,
    to run their application components. However, the building process usually starts
    with a previous image. All image build processes will start with a `FROM` statement.
    This indicates that the previous image (compound on layers) will be used to add
    new components, binaries, configurations, or actions for building our new image.
  prefs: []
  type: TYPE_NORMAL
- en: You may be asking yourself, *who is responsible for image creation?* Developers
    will probably create application images if they are not automatically generated
    using Continuous Integration platforms, but there will be teams who create images
    to be used by other users as base images. For example, database administrators
    would create database base images because they know what components should be
    included and how to ensure their security. Developers will take those base images
    for their components. In a big organization, there will be many teams creating
    images, or at least defining what components must be included, which users to
    use, ports to expose, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: There is something else, however. Many applications these days come prepared
    for container environments, and software manufacturers will provide you with images
    to deploy their software. Enterprises will look for homogenization and architecture,
    while DevOps teams will provide their colleagues with standard base images. The
    container's infrastructure runtime would be common to all of them and monitoring
    applications, middleware, databases, and so on would be running on this environment
    alongside developed business application components.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three methods for creating images:'
  prefs: []
  type: TYPE_NORMAL
- en: Using a file with all the instructions to create this image (Dockerfile)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interacting with files in different container layers, executing one container,
    modifying its content, and then storing the changes made (commit)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using an empty layer and adding components by hand, file by file, also known
    as creating an image from scratch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, we will review each one, along with their pros and cons and use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Creating images with Dockerfiles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A Dockerfile is a script file that describes all the steps required to create
    a new image. Each step will be interpreted and, in many cases, create a container
    to execute declared changes against previous layers. On this Dockerfile, we will
    have a guide to creating this image. This guide creates a reproducible process.
    We will ensure that every time we use this script, we will get the same results.
    Of course, this can depend on some variables, but with some key mechanisms, we
    can ensure the same results. In this chapter, we will cover the main primitives
    available for creating image Dockerfiles.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Dockerfile looks similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In this simple example, and as we mentioned previously, we have a `FROM` sentence
    at the beginning:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we used Ubuntu 18.04 as the base image. To use this image, we need it
    in our building environment. Therefore, if the image is not present in our environment,
    Docker daemon will download its layers for us to make it available locally for
    the next steps. This will happen automatically; Docker daemon will do this for
    us.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the downloaded Ubuntu 18.04 layers, Docker will automatically run a container
    using this image and execute the declared commands since we used the `RUN` primitive.
    In this simple case, the shell (because it is the default command on the Ubuntu
    18.04 image) will execute `apt-get update` to update the container package cache.
    If everything goes well with this command, it will execute the installation of
    `package1` and `package2` using `apt-get install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After software installation, Docker will execute a `Docker container commit`
    command internally to persist these changes on a new layer in order to use them
    as a base for the next step. The third line will copy our current directory content
    into the application code directory on a new running container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next line will execute `make` (this is just an example; we haven't said
    anything about the programming language used for my application and so on). This
    line will run this action in a new container. As a result, a new image will be
    created automatically when the action has finished.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We learned that a container is always created using an image as a template.
    The last line of code defines the command line to be run each time we create a
    container using this image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In summary, Dockerfiles provide a guide of all the steps required to create
    an image so that we can run our application. It is a reproducible process and
    therefore, every time we create a new image using this file, we should obtain
    the same results (for example, in this case, we have updated the package cache
    and installed the required software; perhaps these packages changed since last
    time we did a build, but if not, we will have the same image).
  prefs: []
  type: TYPE_NORMAL
- en: The built image has a unique identification in the `algorithm:hexadecimal_code_using_algorithm`
    format. This means that every time we build this image, we will get the same image
    identification unless there is some kind of change that's made during the process.
    This image ID, or digest ID, is calculated using an algorithm in relation to a
    layer's content, so we will get a new one with any layer change. This identification
    allows Docker Engine to verify whether the image described is the correct one
    to use. A Docker image contains information about all of its layers and informs
    Docker Engine of the layers' content that is required for the new container.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we inspect the image information, we will get all the necessary layers
    to create this image, `RootFS`. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This output shows different layers being created using defined code in the Dockerfile.
    These layers will be interchangeable between images wherever possible. If we create
    an image using Dockerfile's first two lines, the layers that are created by those
    commands will be shared with the previous image. This ensures minimum disk space
    usage.
  prefs: []
  type: TYPE_NORMAL
- en: Creating images interactively
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Images can be created interactively by running a container and making changes
    on the fly to `rootfs`. This is very useful when an application''s installation
    cannot be automated but lacks reproducibility. Let''s look at this process in
    action using an example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start an interactive container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Once started, we will receive a command prompt because we launched the container
    by allocating a pseudo-terminal and did so interactively. We need to update the
    package''s database and then install, for example, the `postfix` package, which
    needs some interactive configurations (please note that some of the output will
    be truncated and omitted):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The software was installed, and you were asked to confirm the installation
    of the `postfix` package and some default configuration. Now, we can exit the
    current container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'What we have done here is exit the current main process (which is a shell in
    a Debian image) and, as a result, returned to our host. We will look for the last
    container that was executed on our host and then save the container layer as a
    new image layer (which means that we have created a new image with a name or identification
    if we omit it):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we review the newly created image on our host system (the IDs may
    change in your environment):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this method, we have created a new image interactively using a previously
    running Debian Docker container. As we can see, the new image has a different
    digest. If we inspect its meta-information, we can identify its preceding image
    layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: One key concept of images that are created using a Docker container commit is
    that they are not reproducible; you really don't know how they were created, so
    the necessary steps should be documented in relation to updates and management.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is an image action that provides a detailed review of the steps to create
    an image. `docker image history` will provide a historic view of the steps that
    were taken to create that image. However, it will not work on images that are
    created using committed containers. We will just have a line with a bash, for
    example, indicating that all the actions that were taken were made on an active
    container and therefore, no additional information can be extracted. For example,
    using the previously created image, executing `docker image history debian-with-postfix`
    will provide the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4207a0e-d19a-4867-98c6-eb8f8080ffdc.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Creating images from scratch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Creating images from scratch is the most effective method. In this case, we
    will use a Dockerfile, as described in the first method, but the initial base
    image will be an empty reserved one known literally as `scratch`. A simple example
    definition will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The main difference in the Dockerfile definition is the `FROM` line because
    we use a defined empty image named `scratch`. `scratch` is not a real image; it
    only contains the root filesystem structure and its meta-information. Images built
    using this method must contain all binaries, libraries, and files required by
    our process (as should always be the case). However, we are not using a predefined
    image and its content; it will be empty and we have to add each required file.
    This procedure is not easy and requires much more practice, but images are way
    better because they will only contain the pieces required for our application.
    We will see a complete lab at the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding copy-on-write filesystems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned what a container is. The isolated process
    or processes running inside a container will have their own root filesystem among
    other namespaces. The container adds a thin layer on top of image layers and every
    change made during the execution of its processes will be stored only on this
    layer. In order to manage these changes, the Docker storage driver will use stackable
    layers and **copy-on-write** (sometimes referenced as **CoW**).
  prefs: []
  type: TYPE_NORMAL
- en: When a process inside a container needs to modify a file, the Docker daemon
    storage filesystem mechanism will make a copy of that file from the underlying
    layers to the top one. These are only available for container usage. The same
    happens when a new file is created; it will only be written to the top container
    storage layer. All the other processes running on other containers will manage
    their own version of the file. In fact, this will be the original file from the
    other layers if no changes were made. Each container uses its own top layer to
    write file changes.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen how the image building process works using containers for each
    layer's creation. We learned that we can commit a container's layers to obtain
    a new image. The creation of images using Dockerfiles will run intermediate containers
    using previous images that will be committed in order to obtain an intermediate
    image with all file changes between their layers. This process will run sequentially,
    following the order defined in the Dockerfile's code. As a result, an image will
    be created that's a compendium of thin layers with the changes or differences
    between them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker copy-on-write reduces the space needed to run containers and the time
    required to launch them because it is only required for the creation of this writable
    layer for each container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bd2f1683-477f-4674-9674-c80b5074e3a2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This image represents an NGINX process running as a container. The base image
    was created from a fresh `alpine` 3.5 image. We added some packages, performed
    some configurations, and copied our own `nginx.conf` file. Finally, we added some
    meta-information to be able to create containers using this image, declared which
    port we will use to expose NGINX, and declared the command line that will be used
    to run a container by default, starting NGINX in the foreground.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three strategies for CoW logic:'
  prefs: []
  type: TYPE_NORMAL
- en: On AUFS and overlay-based drivers, Docker uses union filesystems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On BTFS and ZFS drivers, Docker uses filesystem snapshots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On device-mapper (available on a Red Hat-like OS), Docker uses an LVM snapshot
    for blocks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nowadays, almost all Docker host OSes use overlay-based drivers by default whenever
    possible. There are some old implementations that use block devices instead, but
    today, these are deprecated. Overhead added by the CoW process depends on the
    driver used.
  prefs: []
  type: TYPE_NORMAL
- en: We can review how much space a container is using. Docker provides the `docker
    container ls -s/--size` option for this. It will return the current thin layer's
    used space and the read-only data used from the original image, defined as **virtual**.
    To understand how much space containers are really consuming, we will need to
    combine both sizes for each container to obtain the total amount of data used
    by all containers in our environment. This will not include volumes or a container's
    log files, among other small pieces that contribute to real used space.
  prefs: []
  type: TYPE_NORMAL
- en: CoW was prepared for maximum disk space efficiency, but it depends on how many
    layers are shared in your local images and how many containers will run using
    the same images. As you can imagine, containers that write a lot of data to their
    writable layer consume much more space than other containers.
  prefs: []
  type: TYPE_NORMAL
- en: CoW is a very fast process, but for heavy-write operations on containers, it
    is not enough. If we have a process that requires the creation of many small files,
    a very deep directory structure, or just very big files, we need to bypass CoW
    operations because performance will be impacted. This will lead us to using volumes
    to mitigate such situations. We will learn about volumes, which are the objects
    used for container persistent storage, in [Chapter 4](e7804d8c-ed8c-4013-8449-b746ee654210.xhtml),
    *Container Persistency and Networking*.
  prefs: []
  type: TYPE_NORMAL
- en: Building images with a Dockerfile reference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned previously, building images is easy, but building good images
    is not. This section will guide you through the basics and provide you with tips
    and tricks that you can use to improve the image building process using Dockerfiles.
  prefs: []
  type: TYPE_NORMAL
- en: Dockerfile quick reference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have already learned which methods are available for building images. For
    production, it is recommended to use Dockerfiles because this method provides
    reproducibility and we can use a code versioning methodology. We will introduce
    the main Dockerfile instructions in their standard order of usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Instruction** | **Description and usage** |'
  prefs: []
  type: TYPE_TB
- en: '| `FROM` | This instruction sets the base image and initializes a new build
    (we will review this concept in the *Multistage building and image caches* section,
    later in this chapter). It is the only mandatory instruction that all Dockerfiles
    should start with. We can use any valid image as the base image for building or
    the reserved `scratch` word to start with an empty root filesystem, as we learned
    in the previous section.We can define a name for the build stage initialized using
    `AS name` in the same `FROM` instruction. We will use it in the *Multistage building*
    section at the end of this chapter.The base image can be defined using either
    its image name (repository) and a specific tag (version of that image) or its
    digest; for example, `FROM <image>[:tag] or FROM <image>[@digest]`. |'
  prefs: []
  type: TYPE_TB
- en: '| `ARG` | The `ARG` instruction defines a variable that will be set to the
    value provided when building, passing its value as an argument using `--build-arg
    <variable>=<value>`. To avoid problems when building with missing values, we can
    use `ARG` to define a default value for a variable that will be overwritten if
    an argument is passed.`ARG` will take the value every time it is invoked. This
    is very important when creating Dockerfiles.`ARG` can be used, preceding the `FROM`
    instruction, to specify different base images using arguments. |'
  prefs: []
  type: TYPE_TB
- en: '| `LABEL` | With `LABEL`, we can add meta-information to the image. This information
    should be in the key-value format and we can include many keys and values in the
    same `LABEL` sentence. Here, you have a number of brief examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `ENV` | With the `ENV` instruction, we can set an environment variable for
    the next step and all subsequent steps thereafter. We can add more than one environment
    variable in the same sentence and values will be overwritten if we specify new
    values during Docker container creation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `WORKDIR` | `WORKDIR` sets the working directory for the next sentences and
    subsequent ones thereafter. We can specify full paths or relative ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `RUN` | `RUN` will probably be one of the most frequently used sentences
    in your Dockerfiles. It will execute all commands in the line in a new layer and
    will commit the results on a new one (as we described in the previous chapter).
    This new layer will be used in the next sentence as a base layer, with the changes
    made by the `RUN` sentence. This means that every `RUN` sentence will create a
    new layer. Therefore, `RUN` directly affects the resulting number of layers in
    our image. To avoid using more layers than needed, we usually add more than one
    command per `RUN` sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `COPY` | The `COPY` instruction copies new files and directories from the
    build context (set during build execution) into the specified directory of the
    container filesystem (remember that building images is based on execution on containers
    and committing results in images for subsequent stages). `COPY` admits the `--chown=<user>:<group>`
    argument for providing file ownership on Linux containers. The owner will be `root:root`
    if it is not used.`COPY` accepts `--from=<name or index>` in order to copy files
    or directories from other build stages (this is key when employing multistage
    building, as we will learn later in this chapter):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `ADD` | `ADD` is similar to `COPY`, but can be used with URLs and TAR package
    files as well. It accepts the same ownership arguments for changing destination
    files and directory permissions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `USER` | The `USER` instruction is used to specify the user, along with the
    group to use in the following sentences. It is very important to understand the
    required permissions of our process and specify a user and its group with `USER`.
    If it is not present, the steps will use `root:root` and the process inside the
    container will run as root. It should be mandatory in production to use a specific
    non-root user for container processes and, if root is required, we should use
    user mappings (as described in the previous chapter):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `VOLUME` | The `VOLUME` definition will create a mount point to bypass the
    CoW system. This means that this set directory''s content will be out of the container''s
    life cycle. As it is outside the container, any change in subsequent sentences
    affecting that directory will be discarded, so if we want to provide certain files
    during volume initialization, the `VOLUME` sentence should be after we''ve provisioned
    files inside the directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `EXPOSE` | `EXPOSE` is used to inform Docker daemon about listening ports
    for containers created using this image. This does not mean that the defined ports
    listen at the Docker host level. They will just listen internally, inside the
    container''s network. We can define which transport protocol to use – UDP or TCP
    (by default):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `CMD` | The `CMD` instruction defines the default process or argument when
    executing a container based on this image. This behavior will be applied irrespective
    of whether the `ENTRYPOINT` instruction is defined. By default, and depending
    on the format used, `CMD` will provide the default arguments for a shell, which
    is the default entry point (the main executor for processes inside a container):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| `ENTRYPOINT` | The `ENTRYPOINT` directive will set which command container
    will run as an executable. As we learned previously, `CMD` will be the argument
    for this command.The interaction between `CMD` and `ENTRYPOINT` defines the command
    that will be executed when running a container. They are not required, but it
    is a good practice to define at least `CMD` so as to have a default process to
    launch on execution. |'
  prefs: []
  type: TYPE_TB
- en: '| `HEALTHCHECK` | `HEALTHCHECK` defines a command line that will run inside
    the container to verify the health of the process or processes. Without `HEALTHCHECK`,
    Docker daemon will only verify if the main process is alive, and if it isn''t,
    the container will be exited. The `HEALTHCHECK` instruction allows us to improve
    the health of the application by defining a better script or binary-based process
    status monitoring.We can adjust the interval between checks, timeout, and the
    number of retries in case of failure before declaring a non-healthy state. And,
    if we have a process that takes time to start, we can set when to start monitoring
    the container processes'' health:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: It is very important to understand that, by default, the main process running
    inside a container that is not working as expected (the process is alive but the
    health check is failing) will not be set as unhealthy until there are three failed
    verifications, with 30 seconds between them by default. This means that, by default,
    a process could be failing for 90 seconds before the container is marked as unhealthy.
    This is too much in many cases, and you should take action to change this behavior.We
    can use our own scripts inside containers and we just have to manage two different
    exit statuses for the output (`0` – verification is OK; `1` – verification is
    wrong). |
  prefs: []
  type: TYPE_NORMAL
- en: Be careful if you defined a primitive key multiple times in a Dockerfile. These
    files are read top to bottom and definition precedence matters because instruction
    values will be overwritten in some cases (`ARG`, `ENV`, `CMD`, `ENTRYPOINT`, `LABEL`,
    `USER`, `WORKDIR`, `HEALTHCHECK`, and so on) or added in others (`VOLUME`, `EXPOSE`,
    and so on).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some instructions that admit two different formats, `shell` and `exec`,
    that have different behaviors in each case:'
  prefs: []
  type: TYPE_NORMAL
- en: '`RUN`:When using the `shell` form, all commands will be launched in a shell,
    as if we were using `/bin/sh -c` (on Linux by default) or `cmd /S` or `cmd /C`
    (on Windows by default). We can change which shell to use in this format by means
    of the `SHELL` directive:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We will need to use the `exec` format in Windows containers. This format is
    required in this case because the defined values for some keys, such as directory
    paths, will contain slashes (`\`) and must be avoided.
  prefs: []
  type: TYPE_NORMAL
- en: '`CMD`: This key will be used to define the command or arguments to pass to
    the main container process:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As we learned previously, the shell form uses a shell to execute commands (this
    can be changed by setting a different shell using the `SHELL` key).
  prefs: []
  type: TYPE_NORMAL
- en: In order to execute CMD commands without a shell, we must use the `exec` form.
    If we want to use CMD values as arguments for a defined entrypoint, we will use
    the `exec` form too, but this must be used on both `ENTRYPOINT` and CMD definitions.
  prefs: []
  type: TYPE_NORMAL
- en: '`ENTRYPOINT`: This key will be used to define the main process to be executed
    inside the created container:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The same behavior is expected here in shell form, but in this case, using this
    form will not allow the use of CMD values as arguments. Using the shell form for
    `ENTRYPOINT` is not recommended because it uses `/bin/sh -c` to launch the main
    process and, in this case, it will not have PID 1 and will not receive Unix signals
    directly (we will review how Unix signals interact with container processes in
    [Chapter 3](c2dd78c4-066f-40b4-94e7-a7e2904d7ec2.xhtml), *Running Docker Containers*.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, in order to use CMD values as `ENTRYPOINT` arguments, `ENTRYPOINT`
    must be defined in `exec` form.
  prefs: []
  type: TYPE_NORMAL
- en: When we use a base image to create new ones, the base image's defined values
    are inherited by new images. This means that CMD and `ENTRYPOINT` definitions
    will be used unless we overwrite them, thereby setting new values on our image.
    However, there is an exception; if we set a new `ENTRYPOINT` on our new image,
    CMD will be reset to an empty value.
  prefs: []
  type: TYPE_NORMAL
- en: Building process actions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Docker command line provides management actions for Docker objects, as we
    learned in the previous chapter. Images are Docker objects and the command line
    will provide tools for building and manipulating them.
  prefs: []
  type: TYPE_NORMAL
- en: I encourage the use of `docker image build` instead of the frequently used `docker
    build`. As you may have noticed, `docker image build` follows the `object action`
    schema, which is easier to remember.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can review Docker image actions in different categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**For management**: `ls`, `prune`, `rm`, and `tag`. These actions allow us
    to list, remove, and set identifications for images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**To get information**: `history` and `inspect`. These actions provide information
    about the steps that need to be followed to create that image and all its properties.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**To share images between hosts:** `pull`, `push`, `load`, `import`, and `save`.
    These actions allow us to interact with the registry to download and upload image
    layers, and different ways to import and export images to and from different Docker
    hosts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**To create new images**: `build`. Using the `build` action, we will be able
    to create new images, using base images or starting from an empty root filesystem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, we will use the Docker image build to create new images. There are
    a few very important options that change the building behavior, and these must
    be reviewed for the Docker Certified Associate exam.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We will use `docker image build [options] <context>` with some additional options:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--add-host`: This option allows us to include host-to-IP entries with an image.
    It is very useful for adding non-DNS entries or for masking external resources,
    for example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--build-arg`: Using arguments during the construction of new images is standard
    in Continuous Integration pipelines combined with templated Dockerfiles.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In cluster environments, we will need to specify which nodes should build the
    required image. To ensure that images are built on specific nodes, we will specify
    some of their labels as constraints by using them as arguments; for example, using
    `--build-arg constraint:ostype==linux` on a cluster with both Windows and Linux
    nodes will send the building process just to Linux ones.
  prefs: []
  type: TYPE_NORMAL
- en: '`--file` or `-f`: We can define which Dockerfile to use. We can have different
    files for each environment, architecture, and so on, but nowadays, there are other
    features, such as "target definition," that allow us to use a unique Dockerfile
    for different purposes and build each one as required.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--force-rm`: This option will keep your environment clean as it will remove
    all intermediate containers. By default, intermediate containers are only removed
    after a successful build.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--isolation`: This option is mandatory when building Windows images as we
    will choose which isolation to use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--label`: This option allows us to add meta-information in key-value pairs
    format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--no-cache`: By default, Docker daemon will use host cached layers when building
    a new image. There are some circumstances when we need to create a new fresh image,
    including, for example, new package updates. In these cases, we will avoid using
    previously built layers with this option. Take care of time and overheads when
    using this option since disabling caching will increase build times and we need
    to execute all the steps to produce a new image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--tag` or `-t`: Tagging an image should be mandatory. By default, Docker will
    not "name" your images and we will just be able to reference the image using its
    `IMAGE` ID (we learned about this earlier in this chapter). It is very important
    to specify a repository name (we will learn what a repository is in the forthcoming
    sections; for now, just understand this concept as a simple name) and its version
    to help us with image management. We can apply more than one tag at build time
    using multiple `--tag` or `-t` arguments with image names and tags. We will learn
    that image names are also known as repository names and that we have to add our
    own registry (with a non-standard port), username, and team or organization that
    we belong to as a prefix when not using Docker Hub.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IMAGE` IDs are unique. Each created image will have a unique ID that identifies
    this compound of layers on all systems. But we can add tags to this `IMAGE` ID
    for ease of management. An image will have just one unique identifier but can
    have many names and versions. This concept is very important and is key to ensuring
    the correct image is executed in production.'
  prefs: []
  type: TYPE_NORMAL
- en: '`--target`: We can have multiple build stage definitions on the same Dockerfile.
    These definitions allow us to execute multistage builds using compiled binaries
    between different resulting images, for example, but they also allow us to have
    multiple architectures or environment definitions and choose which one to build,
    instead of using different Dockerfile files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can limit the resources used when building using options such as `--cpu-quota`,
    `--cpu-shares`, and `--memory`, which will limit the number of resources available
    on each container's execution during the build process.
  prefs: []
  type: TYPE_NORMAL
- en: The build context is a set of files located in a directory or URL (a Git URL
    or a tarball file) and we use it to refer to its files when building. These files
    are sent to Docker daemon, to either use them or not during the image build. Therefore,
    it's very important to know which files in the context directory, Git repository,
    or tarball are actually needed during compilation. If we have many small files
    inside our build context or very big files, Docker daemon will retrieve those
    files and will either incorporate them or not in the image, depending on the Dockerfile
    instruction. Therefore, the context directory should only contain those files
    required for the image. Files that should not be managed by Docker during image
    building should not be in the context path.
  prefs: []
  type: TYPE_NORMAL
- en: Irrespective of whether you use Git URLs or tarball files, the behavior will
    be similar. Docker daemon will retrieve the repository or `.tar` file and will
    unpackage or uncompress data to be able to treat the temporary directory as a
    build context.
  prefs: []
  type: TYPE_NORMAL
- en: We usually store Dockerfiles with our application code and, as a result, the
    build context is the location where the Dockerfile is located. Due to this, we
    use `.` to indicate the current directory if we launch the build from the same
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple command-line example of image building with a number of options is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Docker daemon will try to find any file named Dockerfile to script the build.
    If you are not using this standard name, use `--file` or `-f`, along with the
    file location (we can use the full or relative path for Dockerfile, but take care
    of the build context location relative to it).
  prefs: []
  type: TYPE_NORMAL
- en: 'And, having substituted some real values, we will have something along the
    lines of the following (this line has been taken from one of the labs at the end
    of this chapter):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are using a non-standard Dockerfile name, creating an image named `templated:production`
    using the `ENVIRONMENT` variable with a `production` value inside the building
    process, and using the current location as the build context. Notice the `.` at
    the end of the command. This means that we are using the current directory as
    the build context to create the image. If we run this command from the previous
    directory, we will use the directory containing the required Dockerfile as the
    build context.
  prefs: []
  type: TYPE_NORMAL
- en: Using the same Git repository philosophy, if there are some files that we want
    to be stored within our Docker build context (for example, files that come with
    our Git repository data), but that we do not want to be processed during the build,
    we can use the `.dockerignore` file to avoid them. Just write down unwanted filenames
    in `.gitignore` and Docker daemon will not treat them during the image build.
  prefs: []
  type: TYPE_NORMAL
- en: Image tagging and meta-information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Usually, you won't manage just a few images but probably hundreds or thousands,
    so having as much information as possible about them is very important.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using labels, we will be able to search for specific images by environment,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Remember that an image can have multiple names and tags, but its digest is unique.
    Using different tags and names is very useful for interacting with different CI/CD
    workflow stages, using the same image content. For example, developers will create
    many images during development and testing, but only a few will make it to the
    quality and assurance or certification stages. We can automate these processes
    based on image names and tags on Docker Enterprise, as we will learn in [Chapter
    13](108b5948-15a9-40fb-b8dd-5a44c54efd7d.xhtml), *Implementing an Enterprise-Grade
    Registry with DTR*.
  prefs: []
  type: TYPE_NORMAL
- en: We've already learned that we can have many names for the same image, so removing
    one image by its name will not really delete its content if it is still in use
    by other names. If we use its image ID to remove `docker image rm <imageid>`,
    Docker daemon will inform us about multiple images with different names using
    the same layers and will not delete the image unless we use `--force`, in which
    case it will remove that image, along with all its layers and referenced names.
  prefs: []
  type: TYPE_NORMAL
- en: We can use `docker rmi` as a command alias for `docker image rm`. On the other
    hand, `docker image prune` will be used to remove dangling images.
  prefs: []
  type: TYPE_NORMAL
- en: There are special **untagged images** that will appear in our Docker build hosts
    as we create new images. These images are the result of making changes between
    different compilations. They are unreferenced and unused. In your host, when used
    as their layers, they are not used by any other image and therefore can be removed
    from our system (in fact, you should remove them because they are using precious
    disk space). These images are usually known as **dangling** images, and we will
    learn how to purge them later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: To add a new tag to an image, we will use the Docker image tag, `SOURCE_IMAGE[:TAG]
    TARGET_IMAGE[:TAG]`. By default, if we omit tags, we are using the `latest` tag.
    Avoid using the `latest` tag for your images as this doesn't really indicate that
    this was the latest image built. The only way to ensure when the image was built
    is by reviewing its date of creation.
  prefs: []
  type: TYPE_NORMAL
- en: Docker registries and repositories
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Images must be stored somewhere. Locally, each Docker host stores its own data
    under `/var/lib/docker/image` in Linux and `c:\programdata\docker\image` in Windows,
    by default. But these directories will work locally only, and we usually need
    to use images to build new ones and share them across multiple nodes.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the Docker command line to export and import image layers on different
    hosts, but this is hard to maintain and this method does not scale. Docker Registry
    is a server application that will store and let us download and upload images
    as required. It provides an API for sharing information and image layers using
    a Docker client. As a result, we can define a registry as a store and content
    delivery system for container images. Images will be stored locally using the
    settings defined at the Docker daemon level. To use remote registries, we will
    set up different storage backends that can handle S3, Microsoft Azure, OpenStack
    Swift for cloud environments, and NFS for your local data center.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of this chapter, we will have a lab in which we will create a local
    registry. Docker Registry is an open source solution and can be configured using
    the `/etc/docker/registry/config.yml` configuration file to change storage backends,
    ports, and other advanced settings.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Hub is the cloud-based registry provided by Docker. We can use it to
    store public or private images and, as a software as a service solution, there
    are some features that require a paid subscription.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Registry will not provide any authentication method, nor TLS, to allow
    Docker clients to use encrypted connectivity. These security enhancements are
    only available in Docker Hub (Docker public/private image registry as a service)
    and Docker Trusted Registry (Registry deployed on the Docker Enterprise platform).
  prefs: []
  type: TYPE_NORMAL
- en: 'We usually describe three different image namespaces or naming conventions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Root (docker.io hosted images)**: We reference these images using their names
    and tags; for example, `nginx:alpine` and `postgres:12.0`. They are public.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User or organization images under root (docker.io hosted images)**: In this
    case, images could be private or public, depending on user licensing. Image names
    will contain the username or an organization, where users are allowed to pull
    or push their images, for example, `frjaraur/simplest-demo:simplestapp` or `codegazers/colors:1.13`**.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Full registry format (used for private registries on the cloud or on your
    own data center)**: We will use usernames, teams, or organizations, but we will
    need to use the fully qualified name of the registry; for example, `dtr.myorganization.com[:my_registry_port][/myteam
    or /myoraganization][/myusername]/<repository>[:tag]`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In fact, root registries and repository names can be completed using the full
    registry format; for example, we can pull the `docker.io/codegazers/colors:1.13`
    image using this full name convention.
  prefs: []
  type: TYPE_NORMAL
- en: You should have noticed that in this case, we added `my_registry_port` and `repository`.
    We added the first because, by default, Docker Hub and Docker Trusted Registry
    use HTTPS, and therefore the port is `443`, but we can deploy our own registries
    using custom ports. `repository` is a reference to a compound of same-named images,
    each one with a different `IMAGE` ID (unique) and tags (multiple). Consequently,
    when we talked about the `nginx:alpine` image, we were referring to the `docker.io`
    registry, the `nginx` repository, and the alpine tag, and the same rule should
    be applied to all other images used throughout the course of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Securing images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As seen in the previous chapter, Docker containers are secure by default, but
    this is because they run inside namespaces and cgroups isolation. Images are different
    objects and their security is related to their content. With this idea, it is
    easy to understand that having less content will be more secure. So, the main
    rules for securing images are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Images should only contain mandatory binaries, libraries, and configurations
    to run our containerized process. Don't add any non-required applications or debug
    tools to production images. Less attack surface is better, and having many binaries
    increases this surface.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Always declare resources on your images. In this case, we use the term *resources*
    to describe users, exposed ports, and volumes. Always describe what is needed
    to run your image and avoid root usage inside a container.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update image content packages if there is some security bug fix, rebuild all
    derived images, and redeploy the containers. In fact, there are more steps to
    follow, but this statement is true. If you identify any exploit or bug that could
    result in any security issue, you must fix it as soon as possible using a Docker
    container's life cycle. To fix the base image with an updated build and rebuild
    all their derivatives, follow the CI/CD workflow and pass all the tests again
    before deploying these new image versions to production.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the Docker Enterprise sections, we will learn about Docker image security
    scanning, which is an automated tool that verifies all of an image's content against
    the CVE database. We can mark images as insecure if a bug or exploit is found.
    This tool can trigger new events to implement a secure pipeline, scan all images
    before they go into the production stage, and provide information regarding any
    security risks found.
  prefs: []
  type: TYPE_NORMAL
- en: We know that image layers are read-only for containers and that a new writable
    layer will be created for each container. In the next chapter, we will learn that
    we can improve this situation using the read-only root filesystem, allowing only
    write access to external volumes.
  prefs: []
  type: TYPE_NORMAL
- en: Managing images and other related objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have learned how to manage image containers throughout this chapter, so now,
    let's take a look at the most common image administration tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Dangling images can be a nightmare if you do not take care of them from the
    very beginning. As we mentioned in the previous sections, *dangling images* are
    images that aren't referenced and therefore, are not used by any other image.
    In fact, they are the result of continuous builds as Docker uses them for caching
    and improving build performance. They are just layers used during image builds
    that are no longer used because, in a particular step, we changed a package, we
    updated our code, we changed a configuration file, and so on, and, as a result,
    it is not necessary. We should delete these images since they can consume a significant
    amount of disk space.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since version 1.13, Docker provides the *Docker* image prune action, which,
    by default, will remove all dangling images. However, we can choose what images
    we want to remove, for example, by filtering by date or labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This command line has removed all dangling images with an environment label
    equal to `test`.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker image prune not only removes the dangling images but also the old
    images. However, you should manage this situation because it depends on what containers
    you have been running in your environment. Before removing non-dangling images
    in production, verify that there are no containers running using that image; for
    example, `docker container ls --filter ancestor=<image_to_be_removed>`.
  prefs: []
  type: TYPE_NORMAL
- en: Many containers are used in building operations. By default, Docker daemon will
    delete all the containers used during builds that exited correctly, so all the
    containers that were used during correct builds will be removed. However, containers
    that have been used on faulty builds should be removed by hand. It is easy to
    identify faulty containers related to image builds. We will usually set container
    names in all containers launched by hand in other situations. In *Section 2*,
    *Containers Orchestration*, dedicated to orchestration, we will learn about the
    naming patterns used by Kubernetes and Swarm orchestrators to create containers,
    thereby helping us identify their origin.
  prefs: []
  type: TYPE_NORMAL
- en: It is always useful to take a look at Docker host filesystem usage, especially
    the space used by Docker daemon. We can use `docker system df --verbose` to obtain
    fine-grained information about the images, containers, and volume usage of each
    host.
  prefs: []
  type: TYPE_NORMAL
- en: Other common tasks involve inspecting images to understand the resources required
    in each case and sharing them.
  prefs: []
  type: TYPE_NORMAL
- en: Listing images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Listing images is a common task for reviewing host system content. We can modify
    the default `docker image ls` command''s output using the `--format` modifier
    in the GoLang format structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: As we learned in the previous examples, we can filter this output using labels,
    for example, to only show specific images.
  prefs: []
  type: TYPE_NORMAL
- en: Sharing images using registries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We learned that registries are servers where images can be stored using the
    HTTP REST API. The Docker client knows how to manage the required requests, thereby
    facilitating image management at these locations.
  prefs: []
  type: TYPE_NORMAL
- en: Images are always required to execute a container. Therefore, each time we run
    a new container, the image will be downloaded from a registry if it is not present
    on the Docker host.
  prefs: []
  type: TYPE_NORMAL
- en: We can download images manually using `docker image pull <IMAGE:TAG>`. This
    will download all image layers and we will be ready to launch a new container
    based on this image. This is very useful for warming hosts before launching containers;
    think of a 2 GB image that should be downloaded from the internet, for example.
  prefs: []
  type: TYPE_NORMAL
- en: We can download all the images from a repository using `--all-tags`; for example,
    `docker image pull --all-tags --quiet codegazers/colors`. Using this command line,
    we are downloading all the images (all tags) that are available in the `codegazers/colors`
    repository without any output.
  prefs: []
  type: TYPE_NORMAL
- en: Consequently, we will use Docker `push` to upload images to registries. But
    remember to use the full name, including the registry's fully qualified domain
    name and port (if we are not using `docker.io` and the default `443` port). We
    will use the full path with custom registries – `myregistry.com[:non-default-port]/myusername/myrepository[:tag]`;
    for example, `$ docker push docker.io/codegazers/colors:test`.
  prefs: []
  type: TYPE_NORMAL
- en: Docker registries should require a login to access them, for both pulling and
    pushing. Usually, we will use TLS encryption to connect to registries and it is
    enabled by default on Docker Client. Docker Engine needs to trust registry certificates
    to permit login and image pulling or pushing. If you do not want to use this feature,
    you will need to add a registry as an insecure registry in `/etc/docker/daemon.json`
    and restart Docker Daemon.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are other methods for sharing images. We can save an image, along with
    all its layers and meta-information, using `docker image save`. This command will
    stream content to standard output by default, so we usually use `--output` to
    store all the content in a file (or redirect its output to a file):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: As a result, `docker image save` will create a `.tar` file containing all the
    layers, along with all their files, and the manifest file (among other meta-information)
    required to recreate that image in your host. Notice that we choose the filename
    and its extension (`.tar` will not be added by default, but it does not affect
    content upload).
  prefs: []
  type: TYPE_NORMAL
- en: Uploading this image `.tar` file is easy. We have two options.
  prefs: []
  type: TYPE_NORMAL
- en: The first option will be to use `docker image import`. With this action, we
    will just import image layers, without any meta-information, and so we will not
    have a defined entry point, command arguments, exposed ports, volume definitions,
    and so on. It will just import the layers provided by the image into our host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consequently, we will not be able to run a container using this image as is
    (but we will be able to add Dockerfile-like instructions on import to avoid this
    situation):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use `docker image load` to upload a saved image, along with all its
    layers and information for launching containers. This is a direct step, without
    any modifications, and we can use this loaded image as is. This command uses standard
    input to read content by default, but we can use a `.tar` file by adding the `--input`
    argument or simply by using redirection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: As you will have noticed, we haven't used any name because it takes it from
    the image `.tar` file's meta-information.
  prefs: []
  type: TYPE_NORMAL
- en: Using `docker image save` on the original host and Docker import/load on the
    destination host, we can avoid the use of external storage, but as the platform
    grows in terms of the number of images and hosts, this is not enough and you should
    use a registry to manage sharing images.
  prefs: []
  type: TYPE_NORMAL
- en: Multistage building and image caches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multistage building is a feature that appeared with Docker 17.05\. Prior to
    this version, if we wanted to ensure minimum image size and void compilers on
    final production images, we usually had to install the packages required for compiling,
    execute the binary's build, and then remove all non-required software, including
    used compilers, which are a real security problem in production.
  prefs: []
  type: TYPE_NORMAL
- en: Automating this kind of compilation was not easy, and sometimes, we needed to
    create our own scripts to reproduce those steps on every build, usually using
    third-party CI/CD orchestrations.
  prefs: []
  type: TYPE_NORMAL
- en: We can use many build definitions on a Dockerfile to create small and compiler-free
    images. These images will only include application libraries, executables, and
    configurations. All compilations steps will be done on another image and we will
    just include the resulting files in a new one. We could also use external images
    in this process. We will only copy the required files for our application to a
    new image. This is known as multistage building.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example that will help us understand this new process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we start a building stage named `sdk`. We add the name to be
    able to use it as a reference in the next stage. In the `sdk` stage, we compile
    our C code after installing the `alpine-sdk` package with the required tools for
    that task. As a result, we obtain a hello binary with our application, located
    in the `/myapp/bin` directory (check the `WORKDIR` instruction). In the next stage,
    we start again with a fresh alpine image and we just copy the compiled hello binary
    from the `sdk` build stage (from the previously compiled image container) to `/myapp/hello`
    on our new stage build container. And, as always in a building process, this container
    is committed as our new image.
  prefs: []
  type: TYPE_NORMAL
- en: Multistage building simplifies the creation of images and improves security.
    This way, the process will just add previously created binaries and libraries
    instead of compilers, which can cause a security breach.
  prefs: []
  type: TYPE_NORMAL
- en: Templating images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using prepared Dockerfiles with a certain template format is common. It is certainly
    a very useful approach. Passing arguments and using environment variables during
    builds will create different images for different CI/CD stages, for example, using
    the same Dockerfile.
  prefs: []
  type: TYPE_NORMAL
- en: 'Templating is key when building using CI/CD orchestration, but there are a
    few rules:'
  prefs: []
  type: TYPE_NORMAL
- en: Don't use debugging tools in production images, so take care of these images
    and use slimmer ones (with fewer components) by default in templates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don't use credentials as arguments when building. There are other mechanisms
    for managing users and passwords and the Docker `history` command will reveal
    this information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Proxy settings are prepared for use as arguments. Therefore, the `HTTP_PROXY`,
    `HTTPS_PROXY`, `FTP_PROXY`, and `NO_PROXY` environment variables can be used during
    build time. These variables will be excluded from the Docker history output and
    will not be cached, so we will need to use an ARG definition to allow changes
    in proxy settings between compilations using the same Dockerfile. In other words,
    before using the `HTTP_PROXY` variable, we should call the `ARG` instruction to
    retrieve its value from the Docker build arguments:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The previous code shows an example that illustrates the behavior described since
    the proxy settings will get updated on every build if its value has changed.
  prefs: []
  type: TYPE_NORMAL
- en: Operating systems and other applications would use `http_proxy`, `https_proxy`,
    `ftp_proxy`, and `no_proxy` instead of the capital strings described in this section.
    Review the application's requirements and use the appropriate format.
  prefs: []
  type: TYPE_NORMAL
- en: We will see a simple, but illustrative, lab at the end of this chapter that
    uses a templated Dockerfile that will build a different version for production
    and development, along with a different base image that includes some debugging
    tools for developers.
  prefs: []
  type: TYPE_NORMAL
- en: Image releases and updates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Earlier, we mentioned how we should manage image updates. In that instance,
    we were focused on security updates to avoid bugs and exploits in production.
    Similarly, we can apply this concept to application fixes and releases.
  prefs: []
  type: TYPE_NORMAL
- en: Base images should be updated in critical image components and these changes
    do not happen very frequently. Usually, the application releases are weekly or
    even daily (or hourly, depending on numerous factors, such as business requirements
    and critical fixes).
  prefs: []
  type: TYPE_NORMAL
- en: Depending on how many containers are running based on a specific image, a new
    image release can be a big change. These changes can be done in a couple of minutes
    or they can take you an hour. However, the procedure using containers is very
    quick; *let the orchestrator do its job*. Kubernetes and Swarm will provide automated
    image updates and rollback and we will be able to manage how this deployment should
    be done, how many containers will update their images in parallel, how much time
    we will wait between these updates, and more.
  prefs: []
  type: TYPE_NORMAL
- en: It is easy to understand that changes to base images (used for building the
    others) require special care. Those image updates must be managed in cascade to
    all derived images. We will usually automate this kind of cascade building. These
    changes will require all the derived images to be rebuilt and will involve much
    more effort. It is recommended to use a Continuous Integration orchestrator to
    automate these kinds of tasks.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, when we create a code or binary update, the changes will
    be easier because we will only affect the containers that were created for a specific
    application. We can deploy these updates quickly after passing all the required
    tests in our organization.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter labs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will review the most important concepts for the Docker Certified
    Associate exam. For these labs, we will be using a CentOS Linux host with a Docker
    engine installed, which we covered in the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Deploy `environments/standalone-environment` from this book's GitHub repository
    ([https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git](https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git))
    if you have not done so yet. You can use your own CentOS 7 server. Use `vagrant
    up` from the `environments/standalone-environment` folder to start your virtual
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using `standalone-environment`, wait until it is running. We can
    check the status of our nodes using `vagrant status`. Connect to your lab node
    using `vagrant ssh standalone`. `standalone` as the name of your node. You will
    be using the `vagrant` user with root privileges using `sudo`. You should get
    the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now connect to the `standalone` node using `vagrant ssh standalone`.
    This process may vary if you''ve already deployed a `standalone` virtual node
    before and you''ve just started it using `vagrant up`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Now, you are ready to start the labs.
  prefs: []
  type: TYPE_NORMAL
- en: Docker build caching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This lab will show us how caching works when building images. We will be able
    to speed up the building process, but it will depend on how the image layers are
    sorted. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create a directory named `chapter2` in your home directory on your Docker
    host. We will use this directory for these labs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a file named `Dockerfile.cache` with the following simple content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, build an image named `test1` while using this directory as an image context:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we have not used any specific tag, Docker adds `latest`. Now, rebuild
    the image without any changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can list our images using the `lab` label we created during the build:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Although we have not changed anything, the image ID is different. This is because
    we have avoided layer caches and we have always compiled each layer. Because we
    launched image buildings one after the other, only a few seconds passed between
    them. However, the meta-information has changed between them and they have different
    IDs, even though they contain the same content.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will use caching because it will improve the build time. In many situations,
    this can make a big difference. Let''s add just a line for installing Python on
    our Dockerfile. Updating the package cache and the Python installation with its
    dependencies will take some time. When we use cached layers that have been created
    from previous builds, the building process will be quicker:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we build again without caching, measuring how many seconds it took for
    the process to complete:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, add a new line for adding `httpie`, which needs Python (and the package
    cache) to be installed. Now, let''s run the build with and without caching:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Without caching, it will take more than a minute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Before launching a new build with caching, we removed the `test4` image using
    `docker image rm test4` because we just wanted to use the previous layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using caching, it will just take a few seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Since this process used the previously cached layers, it only took 15 seconds
    (`test4`, without caching, took 1 minute and 28 seconds to build). We have just
    added one layer and, to install just one package, we got more than 1 minute of
    difference, even though the images are small (around 100 MB in size). It can take
    hours to compile 5 GB images (which is not recommended, even though it is a good
    approach for caching).
  prefs: []
  type: TYPE_NORMAL
- en: Where to use volumes in Dockerfiles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this lab, we will review how the `VOLUME` key definition will be managed
    by Docker Daemon to specify persistent storage or to avoid container space when
    building. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider a small Dockerfile that''s using a volume to persist data between
    layers when building. The volume definition will also inform Docker Daemon about
    bypassing the volume directory from the CoW mechanism. We will name this Dockerfile
    `Dockerfile.chapter2.lab2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s build this image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, run a container using the `ch2lab2` image to retrieve the container''s
    `/data` directory content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will change the `VOLUME` instruction order. We write the `VOLUME` definition
    before the execution of `echo`. We will use a new file named `Dockerfile.chapter2.lab2-2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s build a new image and review what happened with the `/data` content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s review the `/data` content again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: As we expected, the `VOLUME` directive allows containers to bypass the CoW filesystem.
    During builds, containers will not maintain volume content because the commit
    action will just transform container content into images, and volumes are not
    found inside containers.
  prefs: []
  type: TYPE_NORMAL
- en: Multistage building
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this lab, we will create a simple hello world binary in C and use an intermediate
    image to compile this code in the first stage and then copy the binary to a cleaner
    image. As a result, we will obtain a small image containing just the required
    components to run our compiled application. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new directory named `multistage` inside the `chapter2` directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create a `helloword.c` file with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Prepare a multistage Dockerfile based on `alpine` called `Dockerfile.multistage`.
    The first stage will be named `compiler` and in it, we will install `alpine-sdk`
    to compile C code. We compile the C code in the first stage and we just use a
    `COPY` sentence to copy the binary from the previous stage. It will look like
    this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the previous code, we will build a new image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now verify that `helloworld:latest` works as expected and that it will
    just contain the `/myapp/helloworld` binary on top of a clean `alpine:latest`
    image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will list the images in order to review the image we created recently:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Deploying a local registry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this lab, we will run a local registry and push/pull an image. Let''s get
    started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll deploy a registry using the official Docker Registry image. We
    will launch it on the standard registry port, `5000`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we need to download a simple `alpine:latest` image (if you don''t already
    have one):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we need to add a new tag to this image to be able to upload it to our
    local registry, which is running on port `5000`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: We will use `docker image tag <ORIGINAL_TAG> <NEW_TAG>` to add names and tags
    to images. This will add new names and tags; the old ones will stay until they
    are removed. We will use `docker image rm` to remove image names and tags. This
    will remove only the names and tags passed as arguments. Other images associated
    with the same ID will remain until they are specifically removed. If we create
    a new build, some layers will be un-referenced and even pushed out of any image
    construction chain.
  prefs: []
  type: TYPE_NORMAL
- en: We can remove all the images associated with a specific ID using `docker image
    rm --force <IMAGE_ID>`. All image names and tags associated with it will be removed.
  prefs: []
  type: TYPE_NORMAL
- en: Unreferenced images, also known as **dangling** images, should be removed, especially
    on image-building hosts. These are common in CI/CD environments where we assign
    some nodes to this process. We will use `docker image prune` to execute this image's
    housekeeping.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we push the image to our local registry:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'To ensure that no other alpine image is present, we remove it by its ID:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'We remove this ID and all its children (the IDs may vary):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we run a container using the `localhost:5000/my-alpine:latest` image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Here, we used the image we downloaded from our `localhost:5000` registry.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned previously, Docker Registry is insecure by default. It is easy
    to deploy but we will need authentication and authorization in production. Authentication
    can be deployed using a frontend proxy with validation. NGINX can be deployed
    even with basic authentication and can also provide TLS certificate encryption.
    Authorization is not as easy, so Docker Trusted Registry is a better solution.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we published our registry on local port `5000`. The application
    container will restart if the main process dies and the image's data will be stored
    on the host under the `/var/lib/docker/volumes/REGISTRY_DATA/_data` directory.
    We have used the `REGISTRY_DATA` named volume, so the registry data will remain
    even if we remove the `registry` container.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Registry can be configured to use different storage backends. We will
    learn about this feature regarding DTR in [Chapter 13](108b5948-15a9-40fb-b8dd-5a44c54efd7d.xhtml),
    *Implementing an Enterprise-Grade Registry with DTR*. Docker Registry can be configured
    using the `/etc/docker/registry/config.yml` file. To deploy a localhost configuration
    file under the current directory, we will use `$(pwd)/config.yml:/etc/docker/registry/config.yml`.
    This will integrate a custom file as a bind-mount volume.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we remove the registry we deployed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Image templating using Dockerfiles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This lab will show us how we can build images for different environments by
    adding some debugging tools, for example, to debug a container's processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new directory named `templating` inside the `chapter2` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'We will have a couple of images: one for production and one for development.
    We will build each one with its own Dockerfile; in this case, we will use a simple
    `nginx:alpine` image as the basis for both:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Development – `Dockerfile.nginx-dev`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Production – `Dockerfile.nginx`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s build both images:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We build both images as `baseimage:development` and `baseimage:production`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can review the image''s sizes. These are pretty different because the
    debugging image has `curl` and `httpie` for testing (this is an example lab).
    We will use these images to launch debugging tools in order to review a container''s
    processes or against other components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can build our application image for development and production environments
    using the `ENVIRONMENT` variable and a templated `Dockerfile.application` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we simply prepare a simple text file named `index.html` with some content
    inside the `html` directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we just compile both images for the `DEV` and `PROD` environments.
    For development, we use the `ENVIRONMENT` argument, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'For the production environment, we will do the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: With this lab, we built different images using just one Dockerfile. Arguments
    will change the building process.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter guided us in terms of building container images. We learned about
    all the building steps and tips and tricks that will help us to ensure we have
    security in images. Building good and secure images is key for production and,
    as we learned, having good base images will help us build better application images.
    We will reuse many layers, so it is safer to ensure security from the bottom to
    the top. To ensure security, we just need to add the requisite software, expose
    the required processes, and avoid the root processes if they are not required.
  prefs: []
  type: TYPE_NORMAL
- en: We also learned how to store images and their meta-information using code versioning-like
    tags to ensure that the correct image is running in production.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we learned how to implement templates to create images for different
    environments or stages on CI/CD pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to run containers.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How can we uniquely identify an image?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) All images with their tags are unique
  prefs: []
  type: TYPE_NORMAL
- en: b) The image ID is what really makes an image unique; we can have an image ID
    with many names and tags, but they will all reference the same layers and meta-information
  prefs: []
  type: TYPE_NORMAL
- en: c) Only base images on the root registry namespace are unique because all other
    images are based on these
  prefs: []
  type: TYPE_NORMAL
- en: d) All the preceding answers are correct
  prefs: []
  type: TYPE_NORMAL
- en: Which methods can be used to create container images?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) We can build images from containers, committing their read-write layers on
    top of read-only ones
  prefs: []
  type: TYPE_NORMAL
- en: b) We can use a Dockerfile, starting with a base image
  prefs: []
  type: TYPE_NORMAL
- en: c) We can start from an empty one, known as scratch
  prefs: []
  type: TYPE_NORMAL
- en: d) All of the above.
  prefs: []
  type: TYPE_NORMAL
- en: Which image creation methods are reproducible?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Committing containers to images is reproducible because we know which steps
    we followed
  prefs: []
  type: TYPE_NORMAL
- en: b) Using Dockerfiles, we will ensure that the requisite steps are written and
    that the creation process is reproducible
  prefs: []
  type: TYPE_NORMAL
- en: c) There is no reproducible method for creating images
  prefs: []
  type: TYPE_NORMAL
- en: d) All of the above options are incorrect
  prefs: []
  type: TYPE_NORMAL
- en: Which Dockerfile instructions admit Shell and Exec formats?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `RUN`
  prefs: []
  type: TYPE_NORMAL
- en: b) Only `CMD`
  prefs: []
  type: TYPE_NORMAL
- en: c) `ENTRYPOINT` and `CMD`
  prefs: []
  type: TYPE_NORMAL
- en: d) All Dockerfile instructions admit both Exec and Shell formats
  prefs: []
  type: TYPE_NORMAL
- en: How can we avoid using command arguments when launching a container based on
    an image?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) We can avoid user modification of the main process arguments and parameters
    by using the shell format for `ENTRYPOINT`
  prefs: []
  type: TYPE_NORMAL
- en: b) It is never possible to modify the container main process
  prefs: []
  type: TYPE_NORMAL
- en: c) It is always possible to modify the main container process arguments, irrespective
    of the `ENTRYPOINT` format used
  prefs: []
  type: TYPE_NORMAL
- en: d) None of the above options are correct
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can refer to the following links for more information on topics covered
    in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Multi-architecture images using new builds: [https://www.docker.com/blog/multi-arch-images/](https://www.docker.com/blog/multi-arch-images/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dockerfile best practices: [https://www.docker.com/blog/intro-guide-to-dockerfile-best-practices/](https://www.docker.com/blog/intro-guide-to-dockerfile-best-practices/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dockerfile reference: [https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
