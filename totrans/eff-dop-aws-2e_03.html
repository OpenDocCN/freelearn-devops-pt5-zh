<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Treating Your Infrastructure as Code</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we familiarized ourselves with AWS. We also created an EC2 instance and deployed a Hello World web application onto it. However, to get there, we had to go through a number of steps to configure the instance and its security groups. Because we did that in a very manual fashion using the command-line interface, the steps that we went through will not be reusable or auditable, as you may recall from the first chapter when implementing DevOps best practices. Two key concepts that you should rely on <span>as often as possible </span><span>are source control (version control) and automation. In this chapter, we will explore how to apply those principles to our infrastructure.</span></p>
<p>In a cloud environment, where almost everything is abstracted and served through the intermediary of virtual resources, it is easy to imagine that code can describe the topology of a network and the configuration of a system. To go through that transformation, we will learn about two key concepts in an effective DevOps organization. The first one is commonly called <strong>Infrastructure as Code</strong> (<strong>IAC</strong>). This is the process of describing all your virtual resources <span>in the form of codes.</span> <span>These resources may include</span> virtual servers, load balancers, storage, the network layer, and so o<span>n</span><span>. The second concept, which is very close to IAC, focuses further on system configuration and is called <strong>configuration management</strong>. Through configuration management systems, developers and system administrators have the ability to automate operating system configuration, package installation, and even application deployment.</span></p>
<p>Going through that transformation is a crucial step for any DevOps-focused organization. By having the code to describe the different resources and their configurations, we will be able to use the same tools and processes as we do when developing applications. We will be able to use source control and make smaller changes to individual branches, as well as submitting pull requests, following standard review processes, and finally, testing changes before they are applied to our production environment. This will give us better clarity, accountability, and auditability for infrastructure changes. Because of that, we will also be able to manage a much bigger fleet of resources without necessarily needing more engineers or without spending a lot more time operating all the resources. This will also open up the door to further automation, as we will see with continuous deployment in <span class="ChapterrefPACKT"><a href="">Chapter 5</a>, <em>Adding Continuous Integration and Continuous Deployment</em></span>. In this chapter, we will cover the following topics:</p>
<ul>
<li>Managing your infrastructure with CloudFormation</li>
<li>Adding a configuration management system</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p class="mce-root">The technical requirements for this chapter are as follows:</p>
<ul>
<li>AWS Console</li>
<li>AWS CloudFormation</li>
<li>AWS CloudFormation Designer</li>
<li>CloudFormer</li>
<li>Troposphere</li>
<li>Git</li>
<li>GitHub</li>
<li>Ansible</li>
</ul>
<p class="mce-root">The GitHub links to find the codes in this chapter are as follows:</p>
<ul>
<li><a href="https://raw.githubusercontent.com/yogeshraheja/Effective-DevOps-with-AWS/master/Chapter03/EffectiveDevOpsTemplates/helloworld-cf-template-part-1.py"><span class="MsoHyperlink">https://raw.githubusercontent.com/yogeshraheja/Effective-DevOps-with-AWS/master/Chapter03/EffectiveDevOpsTemplates/helloworld-cf-template-part-1.py</span></a></li>
<li><a href="https://raw.githubusercontent.com/yogeshraheja/Effective-DevOps-with-AWS/master/Chapter03/EffectiveDevOpsTemplates/helloworld-cf-template.py"><span class="MsoHyperlink">https://raw.githubusercontent.com/yogeshraheja/Effective-DevOps-with-AWS/master/Chapter03/EffectiveDevOpsTemplates/helloworld-cf-template.py</span></a></li>
<li><span class="MsoHyperlink"><a href="https://github.com/yogeshraheja/Automation-with-Ansible-By-Yogesh-Raheja">https://github.com/yogeshraheja/Automation-with-Ansible-By-Yogesh-Raheja</a> </span></li>
</ul>
<ul>
<li><a href="https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/nodejs/tasks/main.yml" target="_blank"><span class="MsoHyperlink">https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/nodejs/tasks/main.yml</span></a></li>
<li><a href="https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/helloworld/tasks/main.yml"><span class="MsoHyperlink">https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/helloworld/tasks/main.yml</span></a></li>
<li><a href="https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/helloworld/meta/main.yml"><span class="MsoHyperlink">https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/helloworld/meta/main.yml</span></a></li>
<li><a href="https://github.com/yogeshraheja/Effective-DevOps-with-AWS/tree/master/Chapter03/ansible"><span class="MsoHyperlink">https://github.com/yogeshraheja/Effective-DevOps-with-AWS/tree/master/Chapter03/ansible</span></a></li>
<li><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ansiblebase-cf-template.py"><span class="MsoHyperlink">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ansiblebase-cf-template.py</span></a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Managing your infrastructure with CloudFormation</h1>
                </header>
            
            <article>
                
<p>CloudFormation introduces a new way to manage services and their configurations. Through the creation of JSON or YAML files, CloudFormation lets you describe the AWS architecture you would like to build. Once your files are created, you can simply upload them to CloudFormation, which will execute them, and automatically create or update your AWS resources. Most AWS-managed tools and services are supported. You can get the full list at <a href="http://amzn.to/1Odslix" target="_blank">http://amzn.to/1Odslix</a>. In this chapter, we will only look at the infrastructure we have built so far, but we will add more resources in the following chapters. After a brief overview of how CloudFormation is structured, we will create a minimal list stack to recreate the Hello World web application from <span class="ChapterrefPACKT"><a href="1abe175d-50df-434d-bc0a-097397a39cee.xhtml">Chapter 2</a>, <em>Deploying Your First Web Application</em></span>. After that, we will see two more options to create CloudFormation templates—the designer, which lets you visually edit your template in a Web GUI, and CloudFormer, a tool to generate templates from existing infrastructure.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting started with CloudFormation</h1>
                </header>
            
            <article>
                
<p>As you would expect, you can access CloudFormation through the AWS console at <a href="https://console.aws.amazon.com/cloudformation" target="_blank">https://console.aws.amazon.com/cloudformation</a>, or by using the following command line:</p>
<pre><strong>$ aws cloudformation help # for the list of options</strong> </pre>
<p>The service is organized around the concept of stacks. Each stack typically describes a set of AWS resources and their configuration in order to start an application. When working with CloudFormation, most of your time is spent editing those templates. There are different ways to get started with the actual editing of the templates. One of the easiest ways is to edit existing templates. AWS has a number of well-written examples available at <a href="http://amzn.to/27cHmrb" target="_blank">http://amzn.to/27cHmrb</a>. At the highest level, templates are structured as follows:</p>
<pre>{ 
"AWSTemplateFormatVersion" : "version date", "Description" : "Description", "Resources" : { }, 
"Parameters" : { }, 
"Mappings" : { }, 
"Conditions" : { }, 
"Metadata" : { }, 
"Outputs" : { } 
} </pre>
<p>The <kbd>AWSTemplateFormatVersion</kbd> section is currently always <kbd>2010-09-09</kbd> and this represents the version of the template language used. This version is currently the only valid value. The <kbd>Description</kbd> section is there for you to summarize what the template does. The <kbd>Resources</kbd> section describes which AWS services will be instantiated and what their configurations are. When you launch a template, you have the ability to provide some extra information to CloudFormation, such as which SSH key-pair to use. For example, if you want to give SSH access to your EC2 instances, this kind of information goes into the <kbd>Parameters</kbd> section. The <kbd>Mappings</kbd> section is useful when you try to create a more generic template.</p>
<p>You can, for example, define which <strong>Amazon Machine Image</strong> (<strong>AMI</strong>) to use for a given region, so that the same template can be used to start an application in that AWS region. The <kbd>Conditions</kbd> section allows you to add conditional logic to your other sections (if statements, logical operators, and so on), while the <kbd>Metadata</kbd> section lets you add more arbitrary information to your resources. Finally, the <kbd>Outputs</kbd> section lets you extract and print out useful information based on the execution of your template, such as the IP address of the EC2 server created, for example. In addition to those examples, AWS also provides a couple of tools and services around CloudFormation template creation. The first tool you can use to create your templates is called CloudFormation Designer.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">AWS CloudFormation Designer</h1>
                </header>
            
            <article>
                
<p class="CDPAlignLeft CDPAlign">AWS CloudFormation Designer is a tool that lets you create and edit CloudFormation templates using a graphic user interface. Designer hides a lot of the complexity of editing a CloudFormation template using a standard text editor. You can access this directly at <a href="https://console.aws.amazon.com/cloudformation/designer" target="_blank">https://console.aws.amazon.com/cloudformation/designer</a>, or in the CloudFormation dashboard after you click on the <span class="packt_screen">Create Stack</span> button, as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><em><img src="assets/541decf4-3186-4bf3-9884-063c3c136b53.png"/></em></p>
<p>The workflow is fairly simple. You simply drag and drop resources from the left-hand side menu into a canvas.</p>
<p>Once your resources are added, you can then connect them to other resources using the small dots surrounding each resource icon. In the preceding example, we are connecting an EC2 instance to its security group. There are a number of hidden gems that can help you when designing your template. You can right-click on resources and directly access the documentation for the CloudFormation resource as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/be7eedd3-01e4-4e1d-abfb-8f7ec71abd1c.png" style="width:14.92em;height:16.92em;"/></p>
<p>When dragging a dot to connect two resources, a designer will highlight resources that are compatible with that connection. The editor on the bottom section of the designer supports auto completion using <em>Ctrl</em> + Spacebar:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c1e036f6-de32-47a4-bcbb-8d3d509870d4.png" style="width:36.83em;height:16.42em;"/></p>
<p>Once your template is complete, you can simply click on a button and go from designing your stack to launching it. The next tool we will look at is called <strong>CloudFormer</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CloudFormer</h1>
                </header>
            
            <article>
                
<p>CloudFormer is a tool that lets you create CloudFormation templates by looking at pre-existing resources. If you have a set of resources that you have already created on an ad hoc basis, as we have done so far in the book, then you can use CloudFormer to group them under a new CloudFormation template. You can then later customize the template that CloudFormer generates using a text editor or even CloudFormation designer, making it fit your needs. Unlike most AWS tools and services, CloudFormer isn't completely managed by AWS; it's a self-hosted tool that you can instantiate on demand using CloudFormation. To do so, follow the given steps:</p>
<ol>
<li>Open <a href="https://console.aws.amazon.com/cloudformation">h</a><a href="https://console.aws.amazon.com/cloudformation">t</a><a href="https://console.aws.amazon.com/cloudformation">t</a><a href="https://console.aws.amazon.com/cloudformation">p</a><a href="https://console.aws.amazon.com/cloudformation">s</a><a href="https://console.aws.amazon.com/cloudformation">://c</a><a href="https://console.aws.amazon.com/cloudformation">o</a><a href="https://console.aws.amazon.com/cloudformation">n</a><a href="https://console.aws.amazon.com/cloudformation">s</a><a href="https://console.aws.amazon.com/cloudformation">o</a><a href="https://console.aws.amazon.com/cloudformation">l</a><a href="https://console.aws.amazon.com/cloudformation">e</a><a href="https://console.aws.amazon.com/cloudformation">.</a><a href="https://console.aws.amazon.com/cloudformation">a</a><a href="https://console.aws.amazon.com/cloudformation">w</a><a href="https://console.aws.amazon.com/cloudformation">s</a><a href="https://console.aws.amazon.com/cloudformation">.</a><a href="https://console.aws.amazon.com/cloudformation">a</a><a href="https://console.aws.amazon.com/cloudformation">m</a><a href="https://console.aws.amazon.com/cloudformation">a</a><a href="https://console.aws.amazon.com/cloudformation">z</a><a href="https://console.aws.amazon.com/cloudformation" target="_blank">o</a><a href="https://console.aws.amazon.com/cloudformation">n</a><a href="https://console.aws.amazon.com/cloudformation">.</a><a href="https://console.aws.amazon.com/cloudformation">c</a><a href="https://console.aws.amazon.com/cloudformation">o</a><a href="https://console.aws.amazon.com/cloudformation">m</a><a href="https://console.aws.amazon.com/cloudformation">/c</a><a href="https://console.aws.amazon.com/cloudformation">l</a><a href="https://console.aws.amazon.com/cloudformation">o</a><a href="https://console.aws.amazon.com/cloudformation">u</a><a href="https://console.aws.amazon.com/cloudformation">d</a><a href="https://console.aws.amazon.com/cloudformation">f</a><a href="https://console.aws.amazon.com/cloudformation">o</a><a href="https://console.aws.amazon.com/cloudformation">r</a><a href="https://console.aws.amazon.com/cloudformation">m</a><a href="https://console.aws.amazon.com/cloudformation">a</a><a href="https://console.aws.amazon.com/cloudformation">t</a><a href="https://console.aws.amazon.com/cloudformation">i</a><a href="https://console.aws.amazon.com/cloudformation">o</a><a href="https://console.aws.amazon.com/cloudformation">n</a> in your browser.</li>
<li>Now, scroll down the AWS console screen, select<strong> </strong><span class="packt_screen">Create a Template from your Existing Resources</span> option, and click on the <span class="packt_screen">Launch CloudFormer</span> button.</li>
<li>In the <span class="packt_screen">S</span><span class="packt_screen">elect a sample template</span> drop-down menu, choose the <span class="packt_screen">CloudFormer</span> option and click on the <span class="packt_screen">Next</span> button, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><strong><img src="assets/46751091-bae2-4af6-986f-5e86de98a60f.png"/></strong></p>
<ol start="4">
<li>On that screen, at the top, you can provide a stack name (feel free to keep the default name, <kbd>AWSCloudFormer</kbd>) and in the bottom part, you are asked to provide three additional parameters, a <span class="packt_screen">Username</span>, a <span class="packt_screen">Password</span> and <span class="packt_screen">VPC Selection</span>. This username and password will be used later to log into CloudFormer. Pick a username and a password, select the <span class="packt_screen">Default</span> VPC, and click on the <span class="packt_screen">Next</span> button.</li>
<li>On the next screen, you can provide extra tags and more advanced options, but we will simply continue by clicking on the <span class="packt_screen">Next</span> button.</li>
<li>This brings us to the review page, where we will check the checkbox to acknowledge that this will cause AWS CloudFormation to create IAM resources. Click on the <span class="packt_screen">Create</span> button.</li>
<li>This will bring us back to the main screen of the CloudFormation console, where we can see our AWS CloudFormer stack being created . Once the <span class="packt_screen">Status</span> column goes from <span class="packt_screen">CREATE_IN_PROGRESS</span> to <span class="packt_screen">CREATE_COMPLETE</span>, select it and click on the <span class="packt_screen">Outputs</span> tab at the bottom. At that point, you have created the resources needed to use CloudFormer. In order to create a stack with it, do the following: in the <span class="packt_screen">Outputs</span> tab (which illustrates the <span class="packt_screen">Outputs</span> section of CloudFormation), click on the website URL link. This will open up the CloudFormer tool. Log in using the username and password provided in the fourth step of the previous set of instructions, and you should see something like the following:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d45f2219-b0a7-44cd-ac34-1369a16757b9.png"/></p>
<ol start="8">
<li>Select the AWS region where you want to create the template and then click on the <span class="packt_screen">Create Template</span> button. The following screen will then appear:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/1bc2ff71-ff2a-4068-861d-f15ff6855af6.png"/></p>
<ol start="9">
<li>Follow the workflow proposed by the tool to select the different resources that you want for your CloudFormation template, as far as the last step.</li>
<li>In the end, you will be able to download the generated template or save it directly in S3.</li>
</ol>
<p style="color: black">The CloudFormation template generated by CloudFormer will usually need a bit of editing, as you will often want to create a more flexible stack with input parameters and an <span class="packt_screen">Outputs</span> section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recreating our Hello World example with CloudFormation</h1>
                </header>
            
            <article>
                
<p style="color: black">Designer and CloudFormer are two very useful tools when you are in the process of architecting your infrastructure and trying to add source control to your design. That said, whenever you wear your DevOps hat, it's a different story. Using those tools markedly reduces the added value that CloudFormation provides by using the JSON format. If you got a chance to read some of the templates available, or tried to use CloudFormer on your existing infrastructure, you probably noticed that raw CloudFormation templates tend to be fairly long and not <strong>Don't Repeat Yourself</strong> (<strong>DRY</strong>).</p>
<p style="color: black">From a DevOps perspective, one of the most powerful aspects of CloudFormation is the ability to write code to dynamically generate those templates. To illustrate that point, we are going to turn to Python, and a library called <kbd>troposphere</kbd>, to generate our Hello World CloudFormation template.</p>
<div class="packt_infobox">There are also a number of more advanced tools to assist with the creation of CloudFormation templates. If you plan on using other third-party services in addition to AWS, you can take a look at Terraform from Hashicorp (available at <a href="https://www.terraform.io" target="_blank"><span class="MsoHyperlink">https://www.terraform.io</span></a>), for example, which handles a number of other cloud providers and services in addition to CloudFormation.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Troposphere to create a Python script for our template</h1>
                </header>
            
            <article>
                
<p style="color: black">We will first install the <kbd>troposphere</kbd> library. Again, we are demonstrating all of the outputs from a CentOS 7.x-based Linux distribution, but the process applies equally to all of the supported platforms mentioned. The following is the command to install the <kbd>troposphere</kbd> library:</p>
<pre style="color: black"><strong>$ pip install troposphere</strong>  </pre>
<div class="packt_infobox">One known issue with the Troposphere is the upgraded version of <kbd>setuptools</kbd>. If you come across the following issue, then the solution is to upgrade <kbd>setuptools</kbd> using the <kbd>pip install -U setuptools</kbd> <span>command.</span></div>
<p>Once you have run the preceding command, you may encounter the following error:</p>
<pre style="color: black"><strong>....</strong><br/><strong>setuptools_scm.version.SetuptoolsOutdatedWarning: your setuptools is too old (&lt;12)     
-----------------------------------
Command "python setup.py egg_info" failed with error code 1 in /tmp/pip-install-pW4aV4/cfn-flip/</strong>        </pre>
<p class="mce-root">In order to fix the error, you can run the following command:</p>
<pre><strong>$ pip install -U setuptools<br/></strong><br/><strong>Collecting setuptools</strong><br/><strong>   Downloading https://files.pythonhosted.org/packages/ff/f4/385715ccc461885f3cedf57a41ae3c12b5fec3f35cce4c8706b1a112a133/setuptools-40.0.0-py2.py3-none-any.whl (567kB)</strong><br/><strong>        100% |████████████████████████████████| 573kB 22.2MB/s</strong><br/><strong>Installing collected packages: setuptools</strong><br/><strong>   Found existing installation: setuptools 0.9.8</strong><br/><strong>      Uninstalling setuptools-0.9.8:</strong><br/><strong>        Successfully uninstalled setuptools-0.9.8</strong><br/><strong>Successfully installed setuptools-40.0.0</strong> </pre>
<p style="color: black">Once the installation is complete, you can then create a new file called <kbd>helloworld-cf-template.py</kbd>.</p>
<p style="color: black">We will start our file by importing a number of definitions from the <kbd>troposphere</kbd> module as follows:</p>
<pre style="color: black">"""Generating CloudFormation template."""<br/><br/>from troposphere import (<br/>    Base64,<br/>    ec2,<br/>    GetAtt,<br/>    Join,<br/>    Output,<br/>    Parameter,<br/>    Ref,<br/>    Template,<br/>)  </pre>
<p style="color: black">We are also going to define a first variable that will make editing the code easier for the remainder of the book. This is because we will create new scripts by building on this initial template:</p>
<pre style="color: black">ApplicationPort = "3000"  </pre>
<p style="color: black">From a code standpoint, the first thing we will do is initialize a <kbd>Template</kbd> variable. By the end of our script, the template will contain the entire description of our infrastructure and we will be able to simply print its output to get our CloudFormation template:</p>
<pre style="color: black">t = Template() </pre>
<p style="color: black">Throughout this book, we will create and run several CloudFormation templates <span>concurrently</span><span>. To help us identify what's in a given stack, we have the ability to provide a description. After the creation of the template, add the description as follows:</span></p>
<pre style="color: black">add_description("Effective DevOps in AWS: HelloWorld web application") </pre>
<p style="color: black">When we launched EC2 instances using the web command-line interface, we selected which key-pair to use in order to gain SSH access to the host. In order to not lose this ability, the first thing our template will have is a parameter to offer the CloudFormation user the ability to select which key-pair to use when launching the EC2 instance. To do that, we are going to create a <kbd>Parameter</kbd> object and initialize it by providing an identifier, a description, a parameter type, a description of the parameter type, and a constraint description to help make the right decision when we launch the stack. In order for this parameter to exist in our final template, we will also use the <kbd>add_parameter()</kbd> function defined in the template class:</p>
<pre style="color: black">t.add_parameter(Parameter(<br/>    "KeyPair",<br/>    Description="Name of an existing EC2 KeyPair to SSH",<br/>    Type="AWS::EC2::KeyPair::KeyName",<br/>    ConstraintDescription="must be the name of an existing EC2 KeyPair.",<br/>))</pre>
<p style="color: black">The next thing we will look at is the security group. We will proceed exactly as we did for our <kbd>KeyPair</kbd> parameter. We want to open up <kbd>SSH/22</kbd> and <kbd>TCP/3000</kbd> to the world. Port <kbd>3000</kbd> was defined in the <kbd>ApplicationPort</kbd> <span>variable</span><span> </span><span>declared earlier. In addition, this time, the information defined isn't a parameter like before, but a resource. Consequently, we will add that new resource using the</span> <kbd>add_resource()</kbd> <span>function as follows:</span></p>
<pre style="color: black">t.add_resource(ec2.SecurityGroup(<br/>    "SecurityGroup",<br/>    GroupDescription="Allow SSH and TCP/{} access".format(ApplicationPort),<br/>    SecurityGroupIngress=[<br/>        ec2.SecurityGroupRule(<br/>            IpProtocol="tcp",<br/>            FromPort="22",<br/>            ToPort="22",<br/>            CidrIp="0.0.0.0/0",<br/>        ),<br/>        ec2.SecurityGroupRule(<br/>            IpProtocol="tcp",<br/>            FromPort=ApplicationPort,<br/>            ToPort=ApplicationPort,<br/>            CidrIp="0.0.0.0/0",<br/>        ),<br/>    ],<br/>))</pre>
<p style="color: black">In our next section, we will replace the need to log on to our EC2 instance and install the <kbd>helloworld.js</kbd> file and its <kbd>init</kbd> scripts by hand. To do so, we will take advantage of the <kbd>UserData</kbd> features that EC2 offers. When you create an EC2 instance, the <kbd>UserData</kbd> optional parameter gives you the ability to provide a set of commands to run once the virtual machine has spawned up (you can read more on this topic at <a href="http://amzn.to/1VU5b3s" target="_blank">http://amzn.to/1VU5b3s</a>). One of the constraints of the <kbd>UserData</kbd> parameter is that the script must be base64-encoded in order to be added to our API call.</p>
<p style="color: black">We are going to create a small script to reproduce the steps that we went through in <span class="ChapterrefPACKT"><a href="1abe175d-50df-434d-bc0a-097397a39cee.xhtml">Chapter 2</a>, </span><em>Deploying Your First Web Application.</em> <span class="ChapterrefPACKT">Here, we will </span>encode, deploy our first web application deployment step in base-64 and store it in a variable called <kbd>ud</kbd>. Note that installing the application in the <kbd>home</kbd> directory of <kbd>ec2-user</kbd> isn't very clean. For now, we are trying to stay consistent with what we did in <a href="1abe175d-50df-434d-bc0a-097397a39cee.xhtml">Chapter 2</a>, <em>Deploying Your First Web Application</em>. We will fix that in <a href="">Chapter 5</a>, <em>Adding Continuous Integration and Continuous Deployment</em>, as we improve our deployment system:</p>
<pre style="color: black">ud = Base64(Join('\n', [<br/>    "#!/bin/bash",<br/>    "sudo yum install --enablerepo=epel -y nodejs",<br/>    "wget http://bit.ly/2vESNuc -O /home/ec2-user/helloworld.js",<br/>    "wget http://bit.ly/2vVvT18 -O /etc/init/helloworld.conf",<br/>    "start helloworld"<br/>]))</pre>
<p style="color: black">We will now focus on the main resource of our template, which is our EC2 instance. The creation of the instance requires providing a name for identifying the resource, an image ID, an instance type, a security group, the key-pair to use for the SSH access, and the user data. In order to keep things simple, we will hardcode the AMI ID (<kbd>ami-cfe4b2b0</kbd>) and instance type (<kbd>t2.micro</kbd>).</p>
<p style="color: black">The remaining pieces of information needed to create our EC2 instances are the security group information and the <kbd>KeyPair</kbd> name, which we collected previously by defining a parameter and a resource. In CloudFormation, you can refer to pre-existing subsections of your template by using the <kbd>Ref</kbd> <span>keyword</span>. In Troposphere, this is done by calling the <kbd>Ref()</kbd> function. As before, we will add the resulting output to our template with the help of the <kbd>add_resource</kbd> function:</p>
<pre style="color: black">...<br/>t.add_resource(ec2.Instance(<br/>    "instance",<br/>    ImageId="ami-cfe4b2b0",<br/>    InstanceType="t2.micro",<br/>    SecurityGroups=[Ref("SecurityGroup")],<br/>    KeyName=Ref("KeyPair"),<br/>    UserData=ud,<br/>)) <br/>...</pre>
<p style="color: black">In the last section of our script, we will focus on producing the <kbd>Outputs</kbd> section of the template that gets populated when CloudFormation creates a stack. This selection allows you to print out useful information that was computed during the launch of the stack. In our case, there are two useful pieces of information—the URL to access our web application, and the public IP address of the instance, so that we can SSH into it if we want to. In order to retrieve such information, CloudFormation uses the <kbd>Fn::GetAtt </kbd><span> function</span><span>. In Troposphere, this is translated into the</span>  <kbd>GetAtt()</kbd> <span>function:</span></p>
<pre style="color: black">...<br/>t.add_output(Output(<br/>    "InstancePublicIp",<br/>    Description="Public IP of our instance.",<br/>    Value=GetAtt("instance", "PublicIp"),<br/>))<br/><br/>t.add_output(Output(<br/>    "WebUrl",<br/>    Description="Application endpoint",<br/>    Value=Join("", [<br/>        "http://", GetAtt("instance", "PublicDnsName"),<br/>        ":", ApplicationPort<br/>    ]),<br/>)) <br/>...</pre>
<p style="color: black">At that point, we can make our script output the final result of the template we generated:</p>
<pre style="color: black">print t.to_json() </pre>
<p style="color: black">The script is now complete. We can save this and quit our editor. The file created should look like the file at the following link:  <span class="MsoHyperlink"><a href="https://raw.githubusercontent.com/yogeshraheja/Effective-DevOps-with-AWS/master/Chapter03/EffectiveDevOpsTemplates/helloworld-cf-template-part-1.py" target="_blank">https://raw.githubusercontent.com/yogeshraheja/Effective-DevOps-with-AWS/master/Chapter03/EffectiveDevOpsTemplates/helloworld-cf-template-part-1.py</a>.</span></p>
<p style="color: black">We can now run our script, giving it the proper permissions and generating the CloudFormation template by saving the output of our script in a file as follows:</p>
<pre style="color: black"><strong>$ python helloworld-cf-template.py &gt; helloworld-cf.template</strong> </pre>
<div class="packt_infobox"><kbd>cloud-init</kbd> is a set of Python scripts compatible with most Linux distributions and cloud providers. This complements the <kbd>UserData</kbd> field by moving most standard operations, such as installing packages, creating files, and running commands into different sections of the template. This book doesn't cover that tool, but if your CloudFormation templates <span>rely</span> heavily on the <kbd>UserData</kbd> field, take a look at it. You can get its documentation at <a href="http://bit.ly/1W6s96M">http://bit.ly/1W6s96M</a>.<a href="http://bit.ly/1W6s96M"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating the stack in the CloudFormation console</h1>
                </header>
            
            <article>
                
<p style="color: black">At this point, we can launch our template using the following steps:</p>
<ol>
<li>Open the CloudFormation web console in your browser with the following link: <a href="https://console.aws.amazon.com/cloudformation" target="_blank">https://console.aws.amazon.com/cloudformation</a>. Click on the <span class="packt_screen">Create Stack</span> button.</li>
<li>On the next screen, we will upload our newly generated template, <kbd>helloworld- cf.template</kbd>, by selecting <span class="packt_screen">Upload a template to Amazon S3</span>, and then browsing to select our <kbd>helloworld-cf.template</kbd> file.</li>
<li>We will then pick a stack name, such as <kbd>HelloWorld</kbd>.</li>
<li>After the stack name, we can see the <span class="packt_screen">Parameters</span> section of our template in action. CloudFormation lets us pick which SSH key-pair to use. Select your key-pair using the drop-down menu.</li>
<li>On the next screen, we have to ability the add optional tags to our resources; in the <span class="packt_screen">Advanced</span> section, we can see how we can potentially integrate CloudFormation and SNS, make decisions on what to do when a failure or a timeout occurs, and even add a stack policy that lets you control who can edit the stack, for example. For now, we will simply click on the <span class="packt_screen">Next</span> button.</li>
</ol>
<ol start="6">
<li>This leads us to the review screen where we can verify the information selected and even estimate how much it will cost to run that stack. Click on the <span class="packt_screen">Create</span> button.</li>
<li>This will bring us to the main CloudFormation console. On that screen, we are able to see how our resources are created in the <span class="packt_screen">Events</span> tab.</li>
<li>When the creation of the template is complete, click on the <span class="packt_screen">Outputs</span> tabs, which will reveal the information we generated through the <span class="packt_screen">Outputs</span> section of our template, as shown here:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/59eb8843-7aa6-4dbb-adaf-f1c0f329a337.png"/></p>
<ol start="9">
<li>Click on the link in the value of the <span class="packt_screen">WebUrl</span> key, which will open our Hello World page.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding our template to a source control system</h1>
                </header>
            
            <article>
                
<p style="color: black">Now that we have tested our template and know it's working, we are going to commit it to our source control system. This will allow us to keep track of changes, making it possible to treat our infrastructure code at the same standard as our application code (more on this in <span class="ChapterrefPACKT"><a href="">Chapter 5</a>, <em>Adding Continuous Integration and Continuous Deployment</em>)</span>.</p>
<p style="color: black">To do that, we will rely on Git. AWS has a service called AWS CodeCommit (<a href="http://amzn.to/2tKUj0n" target="_blank">http://amzn.to/2tKUj0n</a>), which lets you manage Git repositories <span>easily. H</span><span>owever, because this service is a lot less popular than GitHub (</span><a href="https://github.com/" target="_blank">https://github.com</a><span>), we will instead use the latter. If you don't have an account for GitHub yet, start by signing up for the service—it's completely free.</span></p>
<p style="color: black">Once logged into GitHub, create a new repository for the CloudFormation template:</p>
<ol>
<li>In your browser, open <a href="https://github.com/new" target="_blank">https://github.com/new</a>.</li>
<li>Call the new repository the following: <kbd>EffectiveDevOpsTemplates</kbd>.</li>
<li>Check the <span class="packt_screen">Initialize this repository with a README</span> checkbox.</li>
<li>Finally, click on the <span class="packt_screen">Create repository </span>button, as shown here:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/91f23a82-9d36-415c-a6ca-a84e91b880d3.png" style="width:52.50em;height:35.67em;"/></p>
<ol start="5">
<li>Once your repository is created, you will want to clone it into your computer. For that, you need to have Git installed (search on Google for instructions on how to install Git for your operating system if you don't have it yet). For CentOS, you just need to run <kbd>yum -y install git</kbd>, as the Git package is a part of Linux distribution now:</li>
</ol>
<pre class="mce-root" style="padding-left: 90px"><strong>$ </strong><strong>git clone</strong> <strong>https://github.com/&lt;your_github_username&gt;/EffectiveDevOpsTemplat</strong><strong>e</strong><strong>s  </strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="6">
<li>Now that the repository is cloned, we will go into it and copy the template previously created in the new GitHub repository:</li>
</ol>
<pre style="color: black;padding-left: 90px"><strong>$ cd EffectiveDevOpsTemplates</strong>
<strong>$ cp &lt;path_to_helloworld_template&gt;/helloworld-cf-template.py .</strong></pre>
<ol start="7">
<li>Finally, we will add and commit that new file to our project and push it to GitHub as follows:</li>
</ol>
<pre style="color: black;padding-left: 90px"><strong>$ git add helloworld-cf-template.py</strong>
<strong>$ git commit -m "Adding helloworld Troposphere template"</strong>
<strong>$ git push</strong>  </pre>
<div class="packt_tip"><strong>Monorepo versus multirepo: </strong>When managing your code, there are two common approaches to organizing your code repositories. You can create one repository for each project you have, or decide to put your entire organization code under a single repository. We will choose the simplest option for this book, which is one repository per project, but with the recent releases of several open source projects, such as Bazel from Google, Buck from Facebook, or Pants from Twitter, using a monorepo becomes a very compelling option as it avoids juggling between multiple repositories when making big changes to your infrastructure and services simultaneously.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Updating our CloudFormation stack</h1>
                </header>
            
            <article>
                
<p style="color: black">One of the biggest benefits of using the CloudFormation template to manage our resources is that the resources created from CloudFormation are tightly coupled to our stack. If we want to make a change to our stack, we can update the template and apply the change to our existing CloudFormation stack. Let's see how that works.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Updating our Python script</h1>
                </header>
            
            <article>
                
<p style="color: black">Our <kbd>helloworld-cf-template.py</kbd> script is fairly basic. At this point, we are only taking advantage of Python as far as using the <kbd>troposphere</kbd> library to easily generate JSON output in a more pleasant way than if we had to write it by hand. Of course, you might already realize that we are barely scratching the surface of what we can do when we have the ability to write scripts to create and manage infrastructures. The following section is a simple example that will let us write a couple more lines of Python and illustrate the concept of updating a CloudFormation stack, while taking advantage of more services and external resources.</p>
<p style="color: black">The security groups we created in our previous example open up two ports to the world: <kbd>22</kbd> (SSH) and <kbd>3000</kbd> (the web application port). We could try to harden one aspect of our security by only allowing our own IP to use SSH. This means changing the <strong>Classless Inter-Domain Routing</strong> (<strong>CIDR</strong>) IP information in our Python script on the security group that handles the port <kbd>22</kbd> traffic. There are a number of free services online that will let us know what our public IP is. We are going to use one of these, available at <a href="https://api.ipify.org/">https://api.ipify.org</a>. We can see it in action with a simple <kbd>curl</kbd> command:</p>
<pre style="color: black"><strong>$ curl https://api.ipify.org 54.164.95.231</strong>  </pre>
<p style="color: black">We are going to take advantage of that service in our script. One of the reasons for using this particular service is that it has been packaged into a Python library. You can read more on this at <a href="https://github.com/rdegges/python-ipify" target="_blank">https://github.com/rdegges/python-ipify</a>. You can first install that library as follows:</p>
<pre style="color: black"><strong>$ pip install ipify</strong></pre>
<p class="mce-root">In case you come across some <kbd>pip</kbd> related errors, as shown in the following code block, the fix would be to downgrade the <kbd>pip</kbd> version, install <kbd>ipify</kbd>, and then upgrade the <kbd>pip</kbd> version <span>again</span><span> </span><span>to the latest version:</span></p>
<pre style="color: black"><strong>Cannot uninstall 'requests'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.</strong>    </pre>
<p>The preceding error can be fixed with the following commands:</p>
<pre style="padding-left: 30px"><strong>$ pip install --upgrade --force-reinstall pip==9.0.3</strong><br/><strong>$ pip install ipify</strong><br/><strong>$ pip install --upgrade pip</strong>  </pre>
<p style="color: black">Our script requires a CIDR. In order to convert our IP address to CIDR, we will also install another library, called <kbd>ipaddress</kbd>. The main advantage of combining these libraries is that we don't have to worry about handling IPv4 versus IPv6:</p>
<pre style="color: black"><strong>$ </strong><strong>pip install ipaddress</strong> </pre>
<p style="color: black">Once those libraries are installed, reopen <kbd>helloworld-cf-template.py</kbd> in your editor. At the top of our script, we are going to import the libraries, then, after the <kbd>ApplicationPort</kbd> variable definition, we will define a new variable called <kbd>PublicCidrIp</kbd> and, combining the two libraries mentioned previously, we can extract our CIDR as follows:</p>
<pre style="color: black">...<br/>from ipaddress import ip_network<br/>from ipify import get_ip<br/>from troposphere import (<br/>    Base64,<br/>    ec2,<br/>    GetAtt,<br/>    Join,<br/>    Output,<br/>    Parameter,<br/>    Ref,<br/>    Template,<br/>)<br/><br/>ApplicationPort = "3000"<br/>PublicCidrIp = str(ip_network(get_ip()))<br/>...</pre>
<p style="color: black">Lastly, we can change the <kbd>CidrIp</kbd> declaration for the SSH group rule as follows:</p>
<pre style="color: black">SecurityGroupIngress=[<br/>        ec2.SecurityGroupRule(<br/>            IpProtocol="tcp",<br/>            FromPort="22",<br/>            ToPort="22",<br/>            CidrIp=PublicCidrIp,<br/>        ),    <br/>....<br/>    ]</pre>
<p style="color: black">We can now save these changes. The file created should look like the file at <a href="https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/EffectiveDevOpsTemplates/helloworld-cf-template.py" target="_blank">https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/EffectiveDevOpsTemplates/helloworld-cf-template.py</a>.<a href="https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/EffectiveDevOpsTemplates/helloworld-cf-template.py" target="_blank"/></p>
<p style="color: black">We can now generate a new <kbd>diff</kbd> command to visually verify the change:</p>
<pre style="color: black"><strong>$ python helloworld-cf-template.py &gt; helloworld-cf-v2.template</strong><br/><strong>$ diff helloworld-cf-v2.template helloworld-cf.template </strong><br/><strong>46c46</strong><br/><strong>&lt;             "CidrIp": "54.164.95.231/32",</strong><br/><strong>---</strong><br/><strong>&gt;             "CidrIp": "0.0.0.0/0",</strong><br/><strong>               91a92</strong><br/><strong>&gt;</strong><br/><strong>$</strong></pre>
<p style="color: black">As we can see, our CIDR IP is now correctly restricting the connection to our IP. We can now apply that change.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Updating our stack</h1>
                </header>
            
            <article>
                
<p style="color: black">Having generated the new JSON CloudFormation template, we can get in the CloudFormation console and update the stack as follows:</p>
<ol>
<li>Open the CloudFormation web console in your browser at <a href="https://console.aws.amazon.com/cloudformation" target="_blank">https://console.aws.amazon.com/cloudformation</a>.</li>
<li>Select the <kbd>HelloWorld</kbd> stack that we created<span> previously </span>.</li>
<li>Click on the <span class="packt_screen">Actions</span> drop-down menu, and then choose the <span class="packt_screen">Update Stack</span> option.</li>
<li>Choose the <kbd>helloworld-cf-v2.template</kbd> file by clicking the <span class="packt_screen">Browse</span> button, selecting the file, and then  clicking on the <span class="packt_screen">Next</span> button.</li>
<li>This brings us to the next screen that lets us update the details of our stack. In our case, nothing has changed in the parameters, so we can continue by clicking on the <span class="packt_screen">Next</span> button.</li>
<li>In the next screen as well, since we simply want to see the effect of our IP change, we can click on the <span class="packt_screen">Next</span> button:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7f0b5618-87d5-41b5-882d-2290b9798910.png"/></p>
<ol start="7">
<li>This brings us to the review page, where, after a couple of seconds, we can see CloudFormation giving us a preview of our change:</li>
</ol>
<p class="CDPAlignCenter CDPAlign" style="color: black"><img src="assets/6f7c9956-37d8-4a3e-8888-dc1fcb625efb.png"/></p>
<ol start="8">
<li>As you can see, the only change will be an update on the security group. Now click on the <span class="packt_screen">Update</span> button. This will bring us back to the CloudFormation template, where we will see the change being applied.</li>
<li style="color: black">In this particular example, AWS is able to simply update the security group to take our change into account. We can verify the change by extracting the physical ID from either the review page, or in the <span class="packt_screen">Resource</span><span class="packt_screen">s</span> tab <span>back in the console</span><span>:</span></li>
</ol>
<pre style="color: black;padding-left: 60px"> <strong>$ aws ec2 describe-security-groups \</strong>
 <strong>--group-names HelloWorld-SecurityGroup-1XTG3J074MXX</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Change sets</h1>
                </header>
            
            <article>
                
<p style="color: black">Our template only includes a web server and a security group that makes updating CloudFormation a fairly harmless operation. Furthermore, our change was fairly trivial, as AWS could simply update the existing security group, as opposed to having to replace it. As you can imagine, as the architecture becomes more and more complex, so does the CloudFormation template. Depending on the update you want to perform, you might encounter unexpected changes when you review the change set in the final step of updating a template. AWS offers an alternative and safer way to update templates; this feature is called <strong>change sets</strong> and is accessible from the CloudFormation console. Follow this procedure <span>in order </span><span>to use change sets to review the updates, followed by execution:</span></p>
<ol>
<li style="color: black">Open the CloudFormation web console in your browser at <a href="https://console.aws.amazon.com/cloudformation" target="_blank">https://console.aws.amazon.com/cloudformation</a><a href="https://console.aws.amazon.com/cloudformation" target="_blank"/></li>
<li>Select the <kbd>HelloWorld</kbd> stack that we previously created</li>
<li>Click on the <span class="packt_screen">Actions</span> drop-down menu and then click the <span class="packt_screen">Create Change Set For Current Stack</span> option</li>
</ol>
<p style="color: black">From there, you can follow the same steps you took to create a simple update in the <em>Updating our stack</em> section. The main difference happens on the last screen, shown here:</p>
<p class="CDPAlignCenter CDPAlign" style="color: black"><img src="assets/0deeb19b-d946-4819-97ec-0843960fdce0.png"/></p>
<p style="color: black">Unlike the regular stack updates, change sets have a strong emphasis on giving you the ability to review a change before applying it. If you are satisfied with the changes displayed, you have the ability to execute the update. Lastly, when using a change set to update your stack, you can easily audit recent changes using the <span class="packt_screen">Change Sets</span> tab of your stack in the CloudFormation console. Finally, we will commit the changes to the Troposphere script with the following command:</p>
<pre style="color: black"><strong>$ git commit -am "Only allow ssh from our local IP"</strong>
<strong>$ git push</strong> </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deleting our CloudFormation stack</h1>
                </header>
            
            <article>
                
<p style="color: black">In the last section, we saw how CloudFormation was able to update resources as we update our template. The same goes when you want to remove a CloudFormation stack and its resources. In a couple of clicks, you can delete your template and the various resources that were created at launch time. From a best practice standpoint, it is highly recommended to always use CloudFormation to make changes to your resources that were previously initialized with CloudFormation, including when you don't need your stack any more.</p>
<p style="color: black">Deleting a stack is very simple, and you should proceed as follows:</p>
<ol>
<li>Open the CloudFormation web console in your browser at <a href="https://console.aws.amazon.com/cloudformation" target="_blank">https://console.aws.amazon.com/cloudformation</a><a href="https://console.aws.amazon.com/cloudformation" target="_blank"/></li>
<li>Select the <kbd>HelloWorld</kbd> stack that we created <span>previously </span></li>
<li>Click on the <span class="packt_screen">Actions</span> drop-down menu, and then click on the <span class="packt_screen">Delete Stack</span> option</li>
</ol>
<p style="color: black">As always, you will be able to track completion in the <span class="packt_screen">Events </span>tab:</p>
<p class="CDPAlignCenter CDPAlign" style="color: black"><img src="assets/97b24707-f9c2-4c6e-be1e-f1ed2aa3b374.png"/></p>
<p style="color: black">CloudFormation has a unique place in the AWS ecosystem. As complex as they are, most architectures can be described and managed through CloudFormation, allowing you to keep tight control over your AWS resources creation. While CloudFormation does a great job of managing the creation of resources, it doesn't always make things easy. This is especially the case when you want to make simple changes on services such as EC2. Because CloudFormation doesn't keep track of the state of the resources once they are launched, the only reliable way to update an EC2 instance is, for example, to recreate a new instance and swap it with the existing instance when it is ready. This creates somewhat of an immutable design (assuming that you don't run any extra commands when the instance is created). This may be an attractive architecture choice and, in some cases, it may take you a long way, but you may wish to have the ability to have long-running instances where you can, as this allows you to quickly and reliably make changes through a controlled pipeline, like we did with CloudFormation. This is what configuration management systems excel at.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding a configuration management system</h1>
                </header>
            
            <article>
                
<p style="color: black">Configuration management systems are probably the most well known components of classic DevOps-driven organizations. Present in most companies (including in the enterprise market), configuration management systems are quickly replacing home-grown Shell, Python, and Perl scripts. There are many reasons why configuration management systems should be a part of your environment. One reason is that they offer domain-specific languages, which improves the readability of the code, and they are tailored to the specific needs that arise in organizations when trying to configure systems. This results in a lot of useful built-in features. Furthermore, the most common configuration management tools have a big and active user community, which often means that you will be able to find existing code for the system you are trying to automate.</p>
<p style="color: black">Some of the most popular configuration management tools include <strong>Puppet</strong>, <strong>Chef</strong>, <strong>SaltStack</strong>, and <strong>Ansible</strong>. While all of those options are fairly good, this book will focus on Ansible, the easiest of the four tools mentioned. There are a number of key characteristics that make Ansible a very popular and easy-to-use solution. Unlike other configuration management systems, Ansible is built to work without a server, a daemon, or a database. You can simply keep your code in source control and download it on the host whenever you need to run it or use a push mechanism through SSH. The automation code you write is in YAML static files, which makes the learning curve a lot less steep than some of the other alternatives that use Ruby or specific DSL. In order to store our configuration files, we will instead rely on our version control system (in our case, GitHub.)</p>
<div class="packt_tip packt_infobox"><strong>AWS OpsWorks and its Chef integration</strong>: While Amazon hasn't really released a service dedicated to configuration management, it supports Chef and Puppet within the OpsWorks service. Unlike the services we have explored so far in the book, OpsWorks aims at being a <em>complete application life cycle, including resource provisioning, configuration</em> <em>management, application deployment, software updates, monitoring, and access control</em><em>. </em>If you are willing to sacrifice some flexibility and control, OpsWorks might be able to handle what you need in order to run a simple web application. You can learn more about this at <a href="http://amzn.to/1O8dTsn" target="_blank">http://amzn.to/1O8dTsn</a><span class="MsoHyperlink">.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting started with Ansible</h1>
                </header>
            
            <article>
                
<p style="color: black">Begin by installing Ansible on your computer. After doing this, create an EC2 instance that will let us illustrate the basic usage of Ansible. After that, we will work on recreating the Hello World Node.js application by creating and executing what Ansible calls a playbook. We will then look at how Ansible can run in pull mode, which offers a new approach to deploying changes. Finally, we will look at replacing the <kbd>UserData</kbd> block in our CloudFormation template with Ansible to combine the benefits of both CloudFormation and our configuration management system.</p>
<div class="packt_infobox">Ansible is fairly easy to use and well documented throughout the web. This book will cover enough to get you started and up to speed on simple configurations, such as the one we need in our examples. However, you might be interested in spending a bit more time learning about Ansible in order to be really efficient with it.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing Ansible on your computer</h1>
                </header>
            
            <article>
                
<p style="color: black">As mentioned before, Ansible is a really simple application with very few dependencies. You can install Ansible on your computer using your operating system package manager, or through <kbd>pip</kbd>, as Ansible is written in Python. We will be demonstrating all of the outputs from a CentOS 7.x-based Linux distribution, but the process applies equally to all supported platforms. (For more information, refer to the following link in order to find and install Ansible binaries on your operating system: <span class="MsoHyperlink"><a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html#installing-the-control-machine" target="_blank">https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html#installing-the-control-machine</a></span>.) <span>The following command will install a number of binaries, libraries, and Ansible modules:</span></p>
<pre style="color: black;padding-left: 30px"><strong>$ yum install ansible</strong> </pre>
<p>Note that no daemon or database is installed at this point. This is because, by default, Ansible relies on static files and SSH in order to run. At this point, we are ready to use Ansible:</p>
<pre style="color: black"><strong>$ ansible --version<br/><br/>ansible 2.6.2<br/>  config file = /etc/ansible/ansible.cfg<br/>  configured module search path = [u'/root/.ansible/plugins/modules',  <br/>  u'/usr/share/ansible/plugins/modules']<br/>  ansible python module location = /usr/lib/python2.7/site-<br/>  packages/ansible<br/>  executable location = /bin/ansible<br/>  python version = 2.7.5 (default, Aug 4 2017, 00:39:18) [GCC 4.8.5 <br/>  20150623 (Red Hat 4.8.5-16)]<br/></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating our Ansible playground</h1>
                </header>
            
            <article>
                
<p style="color: black">To illustrate the basic functionalities of Ansible, we are going to start by re-launching our Hello World application.</p>
<p style="color: black">In the previous section, we saw how to create a stack using the web interface. As you would expect, it is also possible to launch a stack using the command-line interface. Go into the <kbd>EffectiveDevOpsTemplates</kbd> directory where you previously generated the <kbd>helloworld-cf-v2.template</kbd> file and run the following command:</p>
<pre style="color: black"><strong>$ aws cloudformation create-stack \</strong><br/><strong>    --capabilities CAPABILITY_IAM \</strong><br/><strong>    --stack-name ansible \</strong><br/><strong>    --template-body file://helloworld-cf-v2.template \</strong><br/><strong>    --parameters ParameterKey=KeyPair,ParameterValue=EffectiveDevOpsAWS</strong><br/><strong>{</strong><br/><strong>    "StackId": "arn:aws:cloudformation:us-east-<br/>     1:094507990803:stack/ansible/bb29cb10-9bbe-11e8-9ee4-500c20fefad2"</strong><br/><strong>} </strong> </pre>
<p style="color: black">Our instance will soon be ready. We can now bootstrap our environment by creating a workspace.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating our Ansible repository</h1>
                </header>
            
            <article>
                
<p style="color: black">With Ansible, our first goal is to be able to run commands on remote hosts. In order to do that efficiently, we need to configure our local environment. Because we don't want to have to redo those steps repeatedly, and because, ultimately, we want to source-control everything, we will create a new Git repository. To do that, we will repeat the same steps that we used when we created our <kbd>EffectiveDevOpsTemplate</kbd> repository.</p>
<p style="color: black">Once logged into GitHub, create a new repository for the CloudFormation template as follows:</p>
<ol>
<li>In your browser, open this link: <a href="https://github.com/new" target="_blank">https://github.com/new</a>.<a href="https://github.com/new" target="_blank"/></li>
<li>Give the new repository the name <kbd>ansible</kbd>, as shown here:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b43c4445-ba61-459d-96a5-ad3d035a4b97.png"/></p>
<ol start="3">
<li>Check the <span class="packt_screen">Initialize this repository with a README</span> checkbox.</li>
<li>Finally, click on the <span class="packt_screen">Create repository</span><strong> </strong>button.</li>
<li>Once your repository is created, clone it onto your computer as follows:</li>
</ol>
<pre style="color: black;padding-left: 90px"><strong>$ git clone https://github.com/&lt;your_github_username&gt;/ansible</strong></pre>
<ol start="6">
<li>Now that the repository is cloned, we will go into this and copy the template  created <span>previously </span>in the new GitHub repository:</li>
</ol>
<pre style="color: black;padding-left: 90px"><strong>$ cd ansible</strong></pre>
<p class="mce-root"/>
<p style="color: black">At its base, Ansible is a tool that can run commands remotely on the hosts in your inventory. The inventory can be managed manually by creating an <kbd>INI</kbd> file where you list all your hosts and/or IPs. It can also be managed dynamically if it can query an API. As you can imagine, Ansible is perfectly capable of taking advantage of the AWS API in order to fetch our inventory. To do so, we will download a Python script from the official Ansible Git repository and give the execution permissions as follows:</p>
<pre style="color: black"><strong><strong>$ curl -Lo ec2.py </strong><strong>http://bit.ly/2v4SwE5</strong>
</strong><strong><strong>$ chmod +x ec2.py</strong></strong>  </pre>
<p style="color: black">Before we can start testing this Python script, we also need to provide a configuration for it. Create a new file in the same directory and call it <kbd>ec2.ini</kbd>. In this file, we will put the following configuration:</p>
<pre style="color: black">[ec2] 
regions = all 
regions_exclude = us-gov-west-1,cn-north-1 destination_variable = public_dns_name vpc_destination_variable = ip_address route53 = False 
cache_path = ~/.ansible/tmp cache_max_age = 300 
rds = False </pre>
<p style="color: black">Once this is done, you can finally validate that the inventory is working by executing the <kbd>ec2.py</kbd> script as follows:</p>
<pre style="color: black"><strong>$ ./ec2.py</strong>  </pre>
<p style="color: black">This command should return a big nested JSON of the different resources found on your AWS account. Among these is the public IP address of the EC2 instance that we created in the previous section. The last step in our bootstrapping is to configure Ansible itself, such that it knows how to get the inventory of our infrastructure; which user to use when it tries to SSH into our instances; how to become a root; and so on. We will create a new file in the same location and call it <kbd>ansible.cfg</kbd>. Its content should be as follows:</p>
<pre style="color: black">[defaults] 
inventory      = ./ec2.py <br/>remote_user  = ec2-user <br/>become = True <br/>become_method  = sudo <br/>become_user    = root <br/>nocows     = 1 </pre>
<p style="color: black">At that point, we are ready to start running Ansible commands. Ansible has a few commands and some simple concepts. We will first look at the <kbd>ansible</kbd> command and the concept of modules.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Executing modules</h1>
                </header>
            
            <article>
                
<p style="color: black">The <kbd>ansible</kbd> command is the main command that drives the execution of the different modules on the remote hosts. Modules are libraries that can be executed directly on remote hosts. Ansible comes with a number of modules, as listed at <a href="http://bit.ly/24rU0yk" target="_blank">http://bit.ly/24rU0yk</a>. In addition to the standard modules, you can also create your own custom modules using Python. These are the modules for most common use cases and technologies. The first module we will see is a simple module called <kbd>ping</kbd>, which tries to connect to a host and returns <kbd>pong</kbd> if the host is usable.</p>
<div class="packt_infobox">Module documentation can also be accessed using the <kbd>ansible-doc</kbd> command, shown as follows:<br/>
<kbd>$ ansible-doc &lt;Module-Name&gt;</kbd><br/>
<kbd>$ ansible-doc ping</kbd><br/>
Here, <kbd>ping</kbd> is one of the Ansible module names.</div>
<p style="color: black">When creating our Ansible playground section, we created a new EC2 instance using CloudFormation. So far, we haven't looked up the IP address for this. Using Ansible and the <kbd>ping</kbd> module, we will discover that information. As mentioned before, we need to be in the <kbd>ansible</kbd> directory in order to run the <kbd>ansible</kbd> command. The command is as follows:</p>
<pre class="mce-root"><strong>$ ansible --private-key ~/.ssh/EffectiveDevOpsAWS.pem ec2 -m ping <br/>18.206.223.199 | SUCCESS =&gt; {<br/>    "changed": false,<br/>    "ping": "pong"<br/>}  </strong></pre>
<p style="color: black">As we can see, Ansible was able to find our EC2 instance by querying the AWS EC2 API. The newly created instance is now ready to be used.</p>
<div class="packt_infobox"><strong>Configuring SSH</strong>: As Ansible relies heavily on SSH, it is worth dedicating a bit of time to configuring SSH through the <kbd>$HOME/.ssh/config</kbd> file. For instance, you can use the following options to avoid having to specify <kbd>--private-key</kbd> and <kbd>-u</kbd> in the preceding example:<br/>
<p class="mce-root"><kbd>IdentityFile ~/.ssh/EffectiveDevOpsAWS.pem</kbd><br/>
<kbd>User ec2-user StrictHostKeyChecking no</kbd><br/>
<kbd>PasswordAuthentication no</kbd><br/>
<kbd>ForwardAgent yes</kbd></p>
<p class="mce-root"><span>Once configured, you won't need to provide the</span> <kbd>--private-key</kbd> <span>option to Ansible.</span></p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running arbitrary commands</h1>
                </header>
            
            <article>
                
<p style="color: black">The <kbd>ansible</kbd> command can also be used to run arbitrary commands on remote servers. In the following example, we will <span>only </span><span>run the <kbd>df</kbd> command on hosts matching</span> <kbd>18.206.223.*</kbd>  <span>for their public IP address </span><span>(you will need to adapt this command to match your instance public IP, as returned in the <kbd>ping</kbd> command in the previous example):</span></p>
<pre style="color: black"><strong>$ ansible --private-key ~/.ssh/EffectiveDevOpsAWS.pem '18.206.223.*' \</strong><br/><strong>-a 'df -h'</strong><br/><strong>18.206.223.199 | SUCCESS | rc=0 &gt;&gt;</strong><br/><strong>Filesystem  Size  Used  Avail  Use%  Mounted on</strong><br/><strong>devtmpfs    484M  56K   484M   1%    /dev</strong><br/><strong>tmpfs       494M   0    494M   0%    /dev/shm</strong><br/><strong>/dev/xvda1  7.8G   1.1G 6.6G   15%   /</strong></pre>
<p style="color: black">Now that we have a basic understanding of how Ansible works, we can start combining calls to different Ansible modules to put in place for automation. This is called creating a <strong>playbook</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ansible playbooks</h1>
                </header>
            
            <article>
                
<p style="color: black">Playbooks are the files that contain Ansible's configuration, deployment, and orchestration language. By creating those files, you sequentially define the state of your systems, from the OS configuration down to application deployment and monitoring. Ansible uses YAML, which is fairly easy to read. For that reason, an easy way to get started with Ansible, <span>similarly to what we did with CloudFormation, </span><span>is to look at some examples inside the official Ansible GitHub repository, available at </span><a href="https://github.com/ansible/ansible-examples" target="_blank">https://github.com/ansible/ansible-examples</a><span>. Alternatively, you can even look in my repository, which makes it fairly simple and easy to understand playbooks, and which can be found at </span> <span class="MsoHyperlink"><a href="https://github.com/yogeshraheja/Automation-with-Ansible-By-Yogesh-Raheja" target="_blank">https://github.com/yogeshraheja/Automation-with-Ansible-By-Yogesh-Raheja</a> for the book <em>Automation with Ansible</em></span><span>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a playbook</h1>
                </header>
            
            <article>
                
<p style="color: black">Ansible provides a number of best practices on their website, available at <a href="http://bit.ly/1ZqdcLH" target="_blank">http://bit.ly/1ZqdcLH</a>. One emphasis in their documentation is on using roles. One crucial way to organize your playbook content is Ansible's <em>roles</em> organization feature, which is documented as part of the main playbooks page. Creating roles is a key component in making Ansible code sharable and modular enough so that you can reuse your code across services and playbooks. To demonstrate a proper structure, we are going to create a role that our playbook will then call.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating roles to deploy and start our web application</h1>
                </header>
            
            <article>
                
<p style="color: black">We are going to use roles to recreate the Hello World stack we made <span>previously</span><span> using the</span> <kbd>UserData</kbd> <span>block of CloudFormation. If you recall, the</span> <kbd>UserData</kbd> <span>section looked roughly like this:</span></p>
<pre style="color: black"><strong>yum install --enablerepo=epel -y nodejs 
wget http://bit.ly/2vESNuc -O /home/ec2-user/helloworld.js <br/>wget http://bit.ly/2vVvT18 -O /etc/init/helloworld.conf start helloworld</strong></pre>
<p style="color: black">You will notice three different types of operation in the preceding script. We are first preparing the system to run our application. To do that, in our example, we are simply installing a Node.js package. Next, we copy the different resources needed to run the application. In our case, this is the JavaScript code and the upstart configuration. Finally, we start the service. As always when doing programming, it is important to keep the code DRY. If deploying and starting our application is very unique to our Hello World project, installing Node.js likely isn't. In order to make the installation of Node.js a reusable piece of code, we are going to create two roles—one to install Node.js, and one to deploy and start the Hello World application.</p>
<p style="color: black">By default, Ansible expects to see roles inside a <kbd>roles</kbd> directory at the root of the Ansible repository. So, the first thing we need to do is to go inside the <kbd>ansible</kbd> directory that we created under the <em>Creating our Ansible repository</em> <span>section</span><span>. C</span><span>reate the <kbd>roles</kbd> directory inside, and <kbd>cd</kbd> the following into it:</span></p>
<pre style="color: black"><strong>$ mkdir roles</strong>
<strong>$ cd roles</strong>  </pre>
<p style="color: black">We can now create our roles. Ansible has an <kbd>ansible-galaxy</kbd> command that can be used to initialize the creation of a role. The first role we will look into is the role that will install Node.js:</p>
<pre style="color: black"><strong>$ ansible-galaxy init nodejs</strong>
<strong>- nodejs was created successfully</strong>  </pre>
<div class="packt_infobox">As briefly mentioned, Ansible, like most other configuration management systems, has a strong support <span>community</span><span> </span><span>who share roles online through </span><a href="https://galaxy.ansible.com/">h</a><a href="https://galaxy.ansible.com/">t</a><a href="https://galaxy.ansible.com/">t</a><a href="https://galaxy.ansible.com/">p</a><a href="https://galaxy.ansible.com/">s</a><a href="https://galaxy.ansible.com/">://g</a><a href="https://galaxy.ansible.com/">a</a><a href="https://galaxy.ansible.com/">l</a><a href="https://galaxy.ansible.com/">a</a><a href="https://galaxy.ansible.com/">x</a><a href="https://galaxy.ansible.com/">y</a><a href="https://galaxy.ansible.com/">.</a><a href="https://galaxy.ansible.com/">a</a><a href="https://galaxy.ansible.com/" target="_blank">n</a><a href="https://galaxy.ansible.com/">s</a><a href="https://galaxy.ansible.com/">i</a><a href="https://galaxy.ansible.com/">b</a><a href="https://galaxy.ansible.com/">l</a><a href="https://galaxy.ansible.com/">e</a><a href="https://galaxy.ansible.com/">.</a><a href="https://galaxy.ansible.com/">c</a><a href="https://galaxy.ansible.com/">o</a><a href="https://galaxy.ansible.com/">m</a><a href="https://galaxy.ansible.com/">/</a><span>. In addition to using the</span> <kbd>ansible-galaxy</kbd> <span>command to create the skeleton for new roles, you can also use</span> <kbd>ansible-galaxy</kbd> <span>to import and install community supported roles.</span></div>
<p style="color: black">This creates a <kbd>nodejs</kbd> <span>directory, </span>and a number of sub-directories that will let us structure the different sections of our role. W<span>e will enter this directory with the following command</span>:</p>
<pre style="color: black"><strong>$ cd nodejs</strong>  </pre>
<p style="color: black">The most important directory inside the <kbd>nodejs</kbd> directory is the one called <kbd>tasks</kbd>. When Ansible executes a playbook, it runs the code present in the <kbd>tasks/main.yml</kbd> file. Open the file with your favorite text editor.</p>
<p style="color: black">When you first open <kbd>tasks/main.yml</kbd>, you will see the following:</p>
<pre style="color: black"><strong>---<br/></strong><strong># tasks file for nodejs</strong>  </pre>
<p style="color: black">The goal of the <kbd>nodejs</kbd> role is to install Node.js and <kbd>npm</kbd>. To do so, we will proceed similarly to how we did with the <kbd>UserData</kbd> script, and use the <kbd>yum</kbd> command to perform those tasks.</p>
<p style="color: black">When writing a task in Ansible, you sequence a number of calls to various Ansible modules. The first module we are going to look at is a wrapper around the <kbd>yum</kbd> command. The documentation on it is available at <a href="http://bit.ly/28joDLe" target="_blank">http://bit.ly/28joDLe</a>. This will let us install our packages. We are also going to introduce the concept of loops. Since we have two packages to install, we will want to call the <kbd>yum</kbd> module twice. We will use the operator's <kbd>with_items</kbd><strong>.</strong> All Ansible codes are written in YAML, which is very easy to start with and use. After the initial three dashes and comments, which indicate the start of a YAML file, we are going to call the <kbd>yum</kbd> module in order to install our packages:</p>
<pre style="color: black">--- 
# tasks file for nodejs 
 
name: Installing node and npm yum: 
name: "{{ item }}" enablerepo: epel state: installed 
with_items: 
nodejs 
npm </pre>
<p style="color: black">Whenever Ansible runs that playbook, it will look at packages installed on the system. If it doesn't find the <kbd>nodejs</kbd> or <kbd>npm</kbd> packages, it will install them.</p>
<p style="color: black">Your file should look like the example available at <a href="https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/nodejs/tasks/main.yml">https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/nodejs/tasks/main.yml</a>. This first role is complete. For the purpose of this book, we are keeping the role very simple, but you can imagine how, in a more production-type environment, you might have a role that will install specific versions of Node.js and <kbd>npm</kbd>, fetch the binaries directly from <a href="https://nodejs.org/en/" target="_blank">https://nodejs.org/en/</a>, and maybe even install specific dependencies. Our next role will be dedicated to deploying and starting the Hello World application that we built previously. We are going to go one directory up back into the <kbd>roles</kbd> directory, and call <kbd>ansible-galaxy</kbd> one more time:</p>
<pre style="color: black"><strong>$ cd ..</strong>
<strong>$ ansible-galaxy init helloworld</strong>
<strong>- helloworld was created successfully</strong>  </pre>
<p style="color: black">Like before, we will now go inside the newly created <kbd>helloworld</kbd> directory as follows:</p>
<pre style="color: black"><strong>$ cd helloworld</strong>  </pre>
<p style="color: black">This time, we will explore some of the other <span>directories present. One of the sub-directories that was created when we ran the <kbd>ansible-galaxy</kbd> command was the directory called <kbd>files</kbd>. Adding files to that directory will give us the ability to copy files on the remote hosts. To do so, we are first going to download our two files in this directory as follows:</span></p>
<pre style="color: black"><strong>$ wget http://bit.ly/2vESNuc -O files/helloworld.js</strong>
<strong>$ wget http://bit.ly/2vVvT18 -O files/helloworld.conf</strong>  </pre>
<p style="color: black">We can now use task files to perform the copy on the remote system. Open the <kbd>tasks/main.yml</kbd> file and, after the initial three dashes and comments, add the following:</p>
<pre style="color: black">--- 
# tasks file for helloworld 
- name: Copying the application file copy: 
src: helloworld.js dest: /home/ec2-user/ owner: ec2-user group: ec2-user 
mode: 0644 
notify: restart helloworld </pre>
<p style="color: black">We are taking advantage of the copy module documented at <a href="http://bit.ly/1WBv08E">h</a><a href="http://bit.ly/1WBv08E">t</a><a href="http://bit.ly/1WBv08E">t</a><a href="http://bit.ly/1WBv08E">p</a><a href="http://bit.ly/1WBv08E">://b</a><a href="http://bit.ly/1WBv08E">i</a><a href="http://bit.ly/1WBv08E">t</a><a href="http://bit.ly/1WBv08E">.</a><a href="http://bit.ly/1WBv08E">l</a><a href="http://bit.ly/1WBv08E">y</a><a href="http://bit.ly/1WBv08E">/1W</a><a href="http://bit.ly/1WBv08E">B</a><a href="http://bit.ly/1WBv08E">v</a><a href="http://bit.ly/1WBv08E" target="_blank">08E</a> to copy our application file in the home directory of the <kbd>ec2-user</kbd>. On the last line of that call, we add a notify option <span>at the end </span><span>(note how the</span> <kbd>notify</kbd> <span>statement is aligned with the call to the copy module). Notify actions are triggers that can be added at the end of each block of tasks in a playbook. In this example, we are telling Ansible to call the restart <kbd>helloworld</kbd> directive if the file <kbd>helloworld.js</kbd> changed, and not to perform a restart if nothing is changed in the code (we will define how to do a restart of the <kbd>helloworld</kbd> application in a different file </span><span>a bit later</span><span>).</span></p>
<p style="color: black"><span>One of the big differences between CloudFormation and Ansible is that Ansible is expected to run multiple times throughout the lifetime of your systems. A lot of the functionalities built into Ansible are optimized for long-running instances. As such, the <kbd>notify</kbd> option makes it easy to trigger events when a system changes state. Similarly, Ansible will know to stop the execution when an error encountered prevents outages as far as possible.</span></p>
<p style="color: black">Now that we have copied our application file, we can add our second file, the <kbd>upstart</kbd> script. After the previous call to copy the <kbd>helloword.js</kbd> file, we are going to add the following call:</p>
<pre style="color: black">- name: Copying the upstart file copy: 
src: helloworld.conf 
dest: /etc/init/helloworld.conf owner: root 
group: root mode: 0644 </pre>
<p style="color: black">The last task we need to perform is to start our service. We will use the <kbd>service</kbd> module for that. The module documentation is available at <a href="http://bit.ly/22I7QNH" target="_blank">http://bit.ly/22I7QNH</a><span class="MsoHyperlink">:</span></p>
<pre style="color: black">- name: Starting the HelloWorld node service service: 
name: helloworld state: started </pre>
<p style="color: black">Our task file is now completed. You should end up with something resembling the sample available at <a href="https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/helloworld/tasks/main.yml" target="_blank"><span class="MsoHyperlink">https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/helloworld/tasks/main.yml</span></a>.</p>
<p style="color: black">Having finished our task file, we are going to move on to the next file, which will give Ansible knowledge of how and when to restart <kbd>helloworld</kbd>, as called out in the <kbd>notify</kbd> parameter of our task. These types of interaction are defined in the <kbd>handler</kbd> section of the role. We are going to edit the <kbd>handlers/main.yml</kbd> file. Here too, we are going to use the <kbd>service</kbd> module. The following is a comment:</p>
<pre style="color: black">---<br/># handlers file for helloworld</pre>
<p style="color: black">Add the following <span>to the <kbd>main.yml</kbd> file</span>:</p>
<pre style="color: black">- name: restart helloworld service: 
name: helloworld state: restarted </pre>
<p style="color: black">No surprises here; we are using the same module we previously used to manage the service. We need one more step in our role. In order for the <kbd>helloworld</kbd> role to work, the system needs to have Node.js installed. Ansible supports the concept of role dependencies. We can explicitly tell that our <kbd>helloworld</kbd> role depends on the <kbd>nodejs</kbd> role we previously created, so that, if the <kbd>helloworld</kbd> role is executed, it will first call the <kbd>nodejs</kbd> role and install the necessary requirements to run the app.</p>
<p style="color: black">Open the <kbd>meta/main.yml</kbd> file. This file has two sections. The first one, under <kbd>galaxy_info</kbd>, lets you fill in the information on the role you are building. If you wish, you can ultimately publish your role on GitHub and link it back into <kbd>ansible-galaxy</kbd> to share your creation with the Ansible community. The second section at the bottom of the file is called <kbd>dependencies</kbd><strong> </strong>and this is the one we want to edit to make sure that <kbd>nodejs</kbd> is present on the system prior to starting our application. Remove the square brackets ([]) and add an entry to call <kbd>nodejs</kbd> as follows:</p>
<pre style="color: black">dependencies: 
- nodejs </pre>
<p style="color: black">Your file should look like the sample available at <a href="https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/helloworld/meta/main.yml" target="_blank">https://github.com/yogeshraheja/Effective-DevOps-with-AWS/blob/master/Chapter03/ansible/roles/helloworld/meta/main.yml</a><span class="MsoHyperlink">.</span> This concludes the creation of the code for the role. From a documentation standpoint, it is good practice to also edit <kbd>README.md</kbd>. Once done, we can move on to creating a playbook file that will reference our newly created role.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating the playbook ﬁle</h1>
                </header>
            
            <article>
                
<p style="color: black">At the top level of our Ansible repository (two directories up from the <kbd>helloworld</kbd> role), we are going to create a new file called <kbd>helloworld.yml</kbd>. In this file, we are going to add the following:</p>
<pre style="color: black">--- 
- hosts: "{{ target | default('localhost') }}" become: yes 
roles: 
- helloworld </pre>
<p style="color: black">This basically tells Ansible to execute the <kbd>helloworld</kbd> <span>role</span><span> </span><span>onto the hosts listed in the <kbd>target</kbd> variable, or <kbd>localhost</kbd> if the target isn't defined. The <kbd>become</kbd> option will tell Ansible to execute the role with elevated privileges (in our case, <kbd>sudo</kbd>). At this point, your Ansible repository should look like the example at</span> <span class="MsoHyperlink"><a href="https://github.com/yogeshraheja/Effective-DevOps-with-AWS/tree/master/Chapter03/ansible">https://github.com/yogeshraheja/Effective-DevOps-with-AWS/tree/master/Chapter03/ansible</a>.</span> <span>We are now ready to test our playbook.</span></p>
<p style="color: black"><span>Note that in practice, on a bigger scale, the roles sections could include more than a single role. If you deploy multiple applications or services to a target, you will often see playbook looking like this. In later chapters, we will see more examples of this:</span></p>
<pre style="color: black">--- 
hosts: webservers roles: 
foo 
bar 
baz </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Executing a playbook</h1>
                </header>
            
            <article>
                
<p style="color: black">The execution of playbooks is done using the dedicated <kbd>ansible-playbook</kbd> command. This command relies on the same Ansible configuration file that we used previously, and therefore, we want to run the command from the root of our Ansible repository. The syntax of the command is as follows:</p>
<pre style="color: black"><strong>ansible-playbook &lt;playbook.yml&gt; [options] </strong></pre>
<p style="color: black">We will first run the following command (adapt the value of the <kbd>private-key</kbd> option):</p>
<pre class="mce-root"><strong>$ ansible-playbook helloworld.yml \
    --private-key ~/.ssh/EffectiveDevOpsAWS.pem \
    -e target=ec2 \
    --list-hosts</strong></pre>
<p style="color: black">The option <kbd>-e</kbd> (or <kbd>--extra-vars</kbd>) allows us to pass extra options for execution. In our case, we are defining the <kbd>target</kbd> variable (which we declared in the <kbd>hosts</kbd> section of our playbook) to be equal to <kbd>ec2</kbd>. This first <kbd>ansible-playbook</kbd> command will tell Ansible to target all EC2 instances. The <kbd>--list-hosts</kbd> <span>option</span><span> </span><span>will make Ansible return a list of hosts that match the hosts criteria, but it won't actually run anything against those hosts. The output of the command will be something like this:</span></p>
<pre style="color: black"><strong>playbook: helloworld.yml 
  play #1 (ec2): ec2 TAGS:[] 
    pattern: [u'ec2'] 
    hosts (1): 
      18.206.223.199 </strong></pre>
<p style="color: black">The <kbd>list-hosts</kbd> option is a good way to verify your inventory and, on more complex playbooks with more specific host values, to verify which hosts would run actual playbooks, allowing you to verify that they are targeting the hosts you expect.</p>
<p style="color: black">We now know which hosts will be impacted if we were to use this value for the target. The next thing we want to check is what will happen if we run our playbook. The <kbd>ansible- playbook</kbd> command has an option <kbd>-C</kbd> (or <kbd>--check</kbd>) that will try to predict the change a given playbook will make; this is sometimes also called <strong>dry-run</strong> mode in Ansible:</p>
<pre style="color: black"><strong>$ ansible-playbook helloworld.yml \</strong><br/><strong>    --private-key ~/.ssh/EffectiveDevOpsAWS.pem \</strong><br/><strong>    -e target=18.206.223.199 \</strong><br/><strong>    --check</strong><br/><br/><strong>PLAY [18.206.223.199] **************************************************************************************************************************************************</strong><br/><br/><strong>TASK [Gathering Facts] *************************************************************************************************************************************************</strong><br/><strong>ok: [18.206.223.199]</strong><br/><br/><strong>TASK [nodejs : Installing node and npm] ********************************************************************************************************************************</strong><br/><strong>changed: [18.206.223.199] =&gt; (item=[u'nodejs', u'npm'])</strong><br/><br/><strong>TASK [helloworld : Copying the application file] ***********************************************************************************************************************</strong><br/><strong>changed: [18.206.223.199]</strong><br/><br/><strong>TASK [helloworld : Copying the upstart file] ***************************************************************************************************************************</strong><br/><strong>changed: [18.206.223.199]</strong><br/><br/><strong>TASK [helloworld : Starting the HelloWorld node service] ***************************************************************************************************************</strong><br/><strong>changed: [18.206.223.199]</strong><br/><br/><strong>RUNNING HANDLER [helloworld : restart helloworld] **********************************************************************************************************************</strong><br/><strong>changed: [18.206.223.199]</strong><br/><br/><strong>PLAY RECAP *************************************************************************************************************************************************************</strong><br/><strong>18.206.223.199 : ok=6 changed=5 unreachable=0 failed=0</strong></pre>
<p style="color: black">Running that command will execute our playbook in dry-run mode. Through that mode, we can ensure that the proper tasks will be executed. Because we are in dry-run mode, some of the modules don't really find everything they need in order to simulate how they would run. This is the reason why we sometimes see service start errors at the end of the service module. If you see this, then don't worry, it will get executed when the packages are installed in the real-mode. Having verified the hosts and code, we can finally run <kbd>ansible-playbook</kbd> and execute our changes in a real-mode as follows:</p>
<pre style="color: black"><strong>$ ansible-playbook helloworld.yml \</strong>
    <strong>--private-key ~/.ssh/EffectiveDevOpsAWS.pem \</strong>
    <strong>-e target=18.206.223.199</strong> </pre>
<p style="color: black">The output is very similar to the <kbd>--check</kbd> command, except that this time, the execution is performed in real-mode. Our application is now installed and configured, and we can verify that it is running <span>correctly</span><span> as follows</span><span>:</span></p>
<pre style="color: black"><strong>$ curl 18.206.223.199:3000</strong>
<strong>Hello World</strong>  </pre>
<p style="color: black">We were able to reproduce what we did <span>previously </span><span>with CloudFormation using Ansible. Now that we have tested our first playbook, we can commit our changes. We will do that in two commits to break down the initialization of the repository and the creation of the role. From the root of your Ansible repository, run the following commands:</span></p>
<pre style="color: black"><strong>$ git add ansible.cfg ec2.ini ec2.py</strong>
<strong>$ git commit -m "Configuring ansible to work with EC2"</strong>
<strong>$ git add roles helloworld.yml</strong>
<strong>$ git commit -m "Adding role for nodejs and helloworld"</strong>
<strong>$ git push</strong>  </pre>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Canary-testing changes</h1>
                </header>
            
            <article>
                
<p style="color: black">One of the great benefits of using Ansible to manage services is that you can easily make changes to your code and quickly push the change. In some situations where you have a big fleet of services managed by Ansible, you may wish to push out a change only to a single host to make sure things are how you expect them to be. This is often called <strong>canary testing</strong>. With Ansible, doing this is really easy. To illustrate that, we are going to open the <kbd>roles/helloworld/files/helloworld.js</kbd> file and then simply change the response on line 11 from <kbd>Hello World</kbd> to <kbd>Hello World, Welcome again</kbd>:</p>
<pre style="color: black">// Send the response body as "Hello World" 
response.end('Hello World, Welcome again\n'); 
}).listen(3000); </pre>
<p style="color: black">Save the file, and then run <kbd>ansible-playbook</kbd> again. Do this with the <kbd>--check</kbd> option first:</p>
<pre style="color: black"><strong>$ ansible-playbook helloworld.yml \</strong>
    <strong>--private-key ~/.ssh/EffectiveDevOpsAWS.pem \</strong>
    <strong>-e target=18.206.223.199 \</strong>
    <strong>--check</strong></pre>
<p style="color: black">This time, Ansible detects only two changes. The first one overwrites the application file and the second one executes the <kbd>notify</kbd> statement, which means restarting the application. Seeing that it is what we expect, we can run our playbook without the <kbd>--check</kbd> options:</p>
<pre style="color: black"><strong>$ ansible-playbook helloworld.yml \</strong>
    <strong>--private-key ~/.ssh/EffectiveDevOpsAWS.pem \</strong>
    <strong>-e target=18.206.223.199</strong>  </pre>
<p style="color: black">This produces the same output as in our previous command, but this time the change is in effect:</p>
<pre style="color: black"><strong>$ curl 18.206.223.199:3000</strong>
<strong>Hello World, Welcome again</strong>  </pre>
<p style="color: black">Our change was very simple, but if we had done this by updating our CloudFormation template, CloudFormation would have had to create a new EC2 instance to make it happen. Here, we simply updated the code of the application and pushed it through Ansible on the target host. We will now revert this change locally in Git as follows:</p>
<pre style="color: black"><strong>$ git checkout roles/helloworld/files/helloworld.js</strong>  </pre>
<p><span>We will demonstrate this by removing the changes from the EC2 instance as we illustrate a new concept. In the next section, we will be running Ansible asynchronously in a reverse mode (in this case, in pull mode).</span></p>
<div class="packt_tip"><strong>The sooner, the better: </strong>Being able to push changes in seconds instead of minutes may seem like a small win, but it isn't. Speed matters; it is what sets apart successful start-ups and technologies. The ability to deploy new servers in minutes instead of days is a big factor in cloud adoption. Similarly, the recent success of containers, as we will see later in the book, is also likely driven by the fact that it only takes seconds to run a new container, while it still takes minutes to start a virtual server.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running Ansible in pull mode</h1>
                </header>
            
            <article>
                
<p style="color: black">Having the ability to instantly make a change like we just did is a very valuable feature. We could easily and synchronously push the new code out and verify that the Ansible execution was successful. On a larger scale, while being able to change anything across a fleet of servers remains as valuable as in our example, it is also sometimes a bit trickier. The risk with making changes that way is that you have to be very disciplined with regards to not pushing changes to only a subset of hosts, and forgetting other hosts that are also sharing the role that just got updated. Otherwise, the increasing number of changes between the Ansible configuration repository and the running servers quickly makes running Ansible a riskier operation. For those situations, it is usually preferable to use a pull mechanism that will automatically pull in the changes. Of course, you don't have to choose one or the other—it is easy to configure both push and pull mechanisms to deploy changes. Ansible provides a command called <kbd>ansible-pull</kbd>, which, as its name suggests, makes it easy to run Ansible in pull mode. The <kbd>ansible-pull</kbd> command works very much like <kbd>ansible-playbook</kbd>, except that it starts by pulling your code from your GitHub repository.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing Git and Ansible on our EC2 instance</h1>
                </header>
            
            <article>
                
<p style="color: black">Since we need to be able to run Ansible and Git remotely, we first need to install those packages on our EC2 instance. For now, we will do that by manually installing those two packages. We will implement a reusable solution later in this chapter. Since Ansible is a perfect tool for running remote commands and this has a module to manage most common requirements such as installing packages, instead of logging in on the host through <kbd>ssh</kbd> and running some commands, we are going to use Ansible to push out those changes. We will install Git and Ansible from the EPEL <kbd>yum</kbd> repository. This will require running commands as <strong>root</strong>, which you can do with the help of the <kbd>become</kbd> option. After adapting the IP address of your EC2 instance, run the following commands:</p>
<pre style="color: black"><strong>$ ansible '18.206.223.199' \</strong>
    <strong>--private-key ~/.ssh/EffectiveDevOpsAWS.pem \</strong>
    <strong>--become \</strong>
    <strong>-m yum -a 'name=git enablerepo=epel state=installed'<br/></strong>
<strong>$ ansible '18.206.223.199' \</strong>
    <strong>--private-key ~/.ssh/EffectiveDevOpsAWS.pem \</strong>
    <strong>--become \</strong>
    <strong>-m yum -a 'name=ansible enablerepo=epel state=installed'</strong></pre>
<p style="color: black">With <kbd>ansible-pull</kbd>, our goal is for Ansible to apply the change locally. We can make a change to our Ansible repository in order to optimize this operation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuring Ansible to run on localhost</h1>
                </header>
            
            <article>
                
<p style="color: black">Since <kbd>ansible-pull</kbd> relies on Git to <span>locally</span><span> </span><span>clone the repository and execute it, we don't need the execution to happen over SSH. Go to the <kbd>root</kbd> directory of your Ansible repository to create a new file. The file should be called</span> <kbd>localhost</kbd> <span>and it should contain the following:</span></p>
<pre style="color: black">[localhost] 
localhost ansible_connection=local </pre>
<p style="color: black">Essentially, what we are doing is creating a static inventory and asking <kbd>ansible</kbd> to run commands in local mode (as opposed to using SSH) when the target host is <kbd>localhost</kbd>. We can save the changes and commit the new file to GitHub as follows:</p>
<pre style="color: black"><strong>$ git add localhost</strong>
<strong>$ git commit -m "Adding localhost inventory"</strong>
<strong>$ git push</strong> </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding a cron job to our EC2 instance</h1>
                </header>
            
            <article>
                
<p style="color: black">We are now going to create a cron tab entry to periodically call <kbd>ansible-pull</kbd>. Here, too, we will rely on Ansible to create our cron job remotely. Run the following command by adapting the IP address:</p>
<pre style="color: black"><strong>$ ansible '18.206.223.199' \</strong>
<strong>--private-key ~/.ssh/EffectiveDevOpsAWS.pem \</strong>
<strong>-m cron -a 'name=ansible-pull minute="*/10" job="/usr/bin/ansible-pull -U https://github.com/&lt;your_username&gt;/ansible helloworld.yml -i localhost --sleep 60"'</strong>  </pre>
<p style="color: black">In the preceding command, we are telling Ansible to use the <kbd>cron</kbd> module targeting our <kbd>ec2</kbd> instance. Here, we are providing a name that Ansible will use to track the cron job over time, telling <kbd>cron</kbd> to run the job every <kbd>10</kbd> minutes, followed by the command to execute and its parameters. The parameters we are giving to <kbd>ansible-pull</kbd> are the GitHub URL of our branch, the inventory file we just added to our repository, and a <kbd>sleep</kbd> parameter that will make the command start sometime between <kbd>1</kbd> and <kbd>60</kbd> seconds after the call started. This will help spread out the load on the network and prevent all node services from restarting at the same time if we have more than one server. After waiting for a bit, we can verify that our change is effective through the following:</p>
<pre style="color: black"><strong>$ curl 54.175.86.38:3000</strong>
<strong>Hello World</strong>  </pre>
<p style="color: black">After manually integrating Ansible to the EC2 instance we created using CloudFormation, we can now formalize the procedure.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Integrating Ansible with CloudFormation</h1>
                </header>
            
            <article>
                
<p style="color: black">While there are different strategies to integrate Ansible to CloudFormation, in our situation there is an obvious path to take. We are going to take advantage of the <kbd>UserData</kbd> field, and initialize Ansible through the <kbd>ansible-pull</kbd> command.</p>
<p style="color: black">We are now going to start the Troposphere script that we created earlier in this chapter. We will duplicate this and call the new script as follows:</p>
<pre style="color: black">ansiblebase-cf-template.py. </pre>
<p style="color: black">Go to your template repository and duplicate the previous template as follows:</p>
<pre style="color: black"><strong>$ cd EffectiveDevOpsTemplates 
$ cp helloworld-cf-template.py ansiblebase-cf-template.py</strong> </pre>
<p style="color: black">Next, open the <kbd>ansiblebase-cf-template.py</kbd> script with your editor. To keep the script readable, we will first define several variables. Before the declaration of the application port, we will define an application name:</p>
<pre style="color: black">ApplicationName = "helloworld" 
ApplicationPort = "3000" </pre>
<p style="color: black">We will also set a number of constants around the GitHub information. Replace the value of <kbd>GithubAccount</kbd> with your GitHub username or GitHub organization name as follows:</p>
<pre style="color: black">ApplicationPort = "3000" 
 
GithubAccount = "EffectiveDevOpsWithAWS" 
GithubAnsibleURL = "https://github.com/{}/ansible".format(GithubAccount) </pre>
<p style="color: black">After the definition of <kbd>GithubAnsibleURL</kbd>, we are going to create one more variable that will contain the command line we want to execute in order to configure the host through Ansible. We will call <kbd>ansible-pull</kbd> and use the <kbd>GithubAnsibleURL</kbd> and <kbd>ApplicationName</kbd> <span>variables</span><span> </span><span>that we just defined. This is what this looks like:</span></p>
<pre style="color: black">AnsiblePullCmd = \ 
"/usr/bin/ansible-pull -U {} {}.yml -i localhost".format( GithubAnsibleURL, 
ApplicationName 
) </pre>
<p style="color: black">We are now going to update the <kbd>UserData</kbd> block. Instead of installing Node.js, downloading our application files and starting the service, we will change this block to install <kbd>git</kbd> and <kbd>ansible</kbd>, execute the command contained in the <kbd>AnsiblePullCmd</kbd> variable, and finally create a cron job to re-execute that command every <kbd>10</kbd> minutes. Delete the previous <kbd>ud</kbd> variable definition and replace it with the following:</p>
<pre style="color: black">ud = Base64(Join('\n', [ "#!/bin/bash", 
"yum install --enablerepo=epel -y git", "pip install ansible", 
AnsiblePullCmd, 
"echo '*/10 * * * * {}' &gt; /etc/cron.d/ansible- pull".format(AnsiblePullCmd) 
])) </pre>
<p style="color: black">We can now save our file, use it to create our JSON template, and test it. Your new script should look like the sample at <span class="MsoHyperlink"><a href="https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ansiblebase-cf-template.py" target="_blank">https://github.com/yogeshraheja/EffectiveDevOpsTemplates/blob/master/ansiblebase-cf-template.py</a>:</span></p>
<pre style="color: black"><strong>$ python ansiblebase-cf-template.py &gt; ansiblebase.template</strong><br/><strong>$ aws cloudformation update-stack \</strong><br/><strong>    --stack-name ansible \</strong><br/><strong>    --template-body file://ansiblebase.template \</strong><br/><strong>    --parameters ParameterKey=KeyPair,ParameterValue=EffectiveDevOpsAWS</strong><br/><strong>{</strong><br/><strong>"StackId": "arn:aws:cloudformation:us-</strong><br/><strong>east-1:511912822958:stack/HelloWorld/ef2c3250-6428-11e7-a67b-50d501eed2b3"</strong><br/><strong>}</strong></pre>
<p style="color: black">You can even create a new stack yourself. For example, let's say <kbd>helloworld</kbd>, instead of changing the existing <kbd>ansible</kbd> stack. In this case, you need to run the following command for stack creation:</p>
<pre style="color: black"><strong>$ aws cloudformation create-stack \</strong><br/><strong>    --stack-name helloworld \</strong><br/><strong>    --template-body file://ansiblebase.template \</strong><br/><strong>    --parameters ParameterKey=KeyPair,ParameterValue=EffectiveDevOpsAWS</strong><br/><strong>{</strong><br/><strong>    "StackId": "arn:aws:cloudformation:us-east-<br/>     1:094507990803:stack/helloworld/5959e7c0-9c6e-11e8-b47f-<br/>     50d5cd26c2d2"</strong><br/><strong>}  </strong></pre>
<p style="color: black">We can now wait until the execution is complete:</p>
<pre style="color: black"><strong>$ aws cloudformation wait stack-update-complete \</strong>
        <strong>--stack-name ansible</strong></pre>
<p style="color: black">Now that the stack creation is complete, we can query CloudFormation to get the output of the stack and, more specifically, its public IP address:</p>
<pre style="color: black"><strong>$ aws cloudformation describe-stacks \</strong>
    <strong>--stack-name ansible \</strong>
    <strong>--query 'Stacks[0].Outputs[0]'</strong>
  <strong>{</strong>
    <strong> "Description": "Public IP of our instance.",</strong>
    <strong> "OutputKey": "InstancePublicIp",</strong>
    <strong> "OutputValue": "35.174.138.51"</strong>
  <strong>}</strong>  </pre>
<p style="color: black">And finally, we can verify that our server is up and running as follows:</p>
<pre style="color: black"><strong>$ curl 35.174.138.51:3000</strong>
<strong>Hello World</strong>  </pre>
<p style="color: black">We can now commit our newly created <kbd>troposphere</kbd> script to our GitHub repository as follows:</p>
<pre style="color: black"><strong>EffectiveDevOpsTemplates repository:</strong>
<strong>$ git add ansiblebase-cf-template.py</strong>
<strong>$ git commit -m "Adding a Troposphere script to create a stack that relies on Ansible to manage our application"</strong>
<strong>$ git push</strong>  </pre>
<p style="color: black">We now have a complete solution for efficiently managing our infrastructure using code. We demonstrated this through a very simple example. However, as you can imagine, everything is applicable to bigger infrastructure with a greater number of services. This section is almost over; we can now delete our stack to free up the resources that we are currently consuming. In the earlier part of the chapter, we did this using the web interface. As you can imagine, this can also be done easily using the following command-line interface:</p>
<pre style="color: black"><strong>$ aws cloudformation delete-stack --stack-name ansible</strong>  </pre>
<p style="color: black">Note that if you have created a new <kbd>helloworld</kbd> <span>stack </span><span>for this example, then remove that too using the following command:</span></p>
<pre style="color: black"><strong>aws cloudformation delete-stack --stack-name helloworld</strong> </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring</h1>
                </header>
            
            <article>
                
<p style="color: black">As you probably know by now, monitoring and measuring everything is an important aspect of a DevOps-driven organization. On the internet, you will find a number of well written blog posts and examples of how to efficiently monitor CloudFormation and Ansible. When working on monitoring CloudFormation, you will want to subscribe to an SNS topic for your stack creation to receive all events relating to your stack life cycle. It is also important to look out for CloudFormation stack creation failure. Ansible has a system of callbacks that will also give you a way to create some automation around the Ansible execution. Similarly to CloudFormation, receiving notifications when Ansible fails to run is important (it's even more important when Ansible is configured to run in pull mode). </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p style="color: black">In this chapter, we learned how to efficiently manage infrastructure by using code. We also explored CloudFormation, an AWS service that allows you to create templates for your different services in order to describe each AWS component used, as well as its configuration. In order to simplify the creation of those templates, we looked at a couple of options, ranging from CloudFormation designer, a tool with a graphic user interface, to Troposphere, a Python library. After that, we looked at configuration management, one of the most well-known aspects of the DevOps philosophy. To illustrate this topic, we looked at Ansible, one of the most popular configuration management solutions. We first looked at the different ways to use Ansible commands and ran simple commands against our infrastructure. We then looked at how to create playbooks, which allowed us to orchestrate the different steps to deploy our web server. Finally, we looked at how Ansible can be used in pull mode, which usually makes more sense when managing sizable infrastructure.</p>
<p style="color: black">We now have a good production environment that is ready to host any application, and we have seen how to architect it and monitor our servers. In <span class="ChapterrefPACKT"><a href="">Chapter 5</a>, <em>Adding Continuous Integration and Continuous Deployment</em></span>, we will continue to use CloudFormation and Ansible, but in the context of software delivery: we will learn how to put in place continuous integration testing and continuous deployment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li style="color: black">What does IaC stand for?</li>
<li>How can a simple Hello World application be deployed using the AWS CloudFormation Console?</li>
<li style="color: black">List some of the popular SCM offerings. How is a GitHub account useful for source control management?</li>
<li style="color: black">Install Git (Local Version Control) package, clone your GitHub global repository created in the previous example and push your <kbd>helloworld-cf.template</kbd> to your GitHub repository.</li>
<li>What is Ansible? List some of its important characteristics.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<p style="color: black">In order to explore this topic in more detail, please visit the following links: </p>
<ul>
<li style="color: black"><em>AWS CloudFormation details</em> at <a href="https://console.aws.amazon.com/cloudformation">https://console.aws.amazon.com/cloudformation</a></li>
<li style="color: black"><em>Troposphere – Python library to create AWS CloudFormation descriptions</em> at <a href="https://github.com/cloudtools/troposphere">https://github.com/cloudtools/troposphere</a></li>
<li style="color: black"><em>Ansible configuration management tool</em> at <a href="https://docs.ansible.com/ansible">https://docs.ansible.com/ansible</a></li>
</ul>


            </article>

            
        </section>
    </body></html>