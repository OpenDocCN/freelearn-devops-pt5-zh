- en: Assessments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chapter 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The correct answers are **D** and **E**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A Docker container is to IT what a shipping container is to the transportation
    industry. It defines a standard on how to package goods. In this case, goods are the
    application(s) developers write. The suppliers (in this case, the developers) are
    responsible for packaging the goods into the container and making sure everything
    fits as expected. Once the goods are packaged into a container, it can be shipped.
    Since it is a standard container, the shippers can standardize their means of
    transportation, such as lorries, trains, or ships. The shipper doesn't really care
    what's in a container. Also, the loading and unloading process from one transportation
    means to another (for example, train to ship) can be highly standardized. This
    massively increases the efficiency of transportation. Analogous to this is an
    operations engineer in IT, who can take a software container built by a developer
    and ship it to a production system and run it there in a highly standardized way,
    without worrying about what's in the container. It will just work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Some of the reasons why containers are game changers are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Containers are self-contained and thus if they run on one system, they run anywhere
    that a container can run.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers run on premises and in the cloud, as well as in hybrid environments.
    This is important for today's typical enterprises since it allows a smooth transition
    from on premises to the cloud.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Container images are built or packaged by the people who know best – the developers.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Container images are immutable, which is important for good release management.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers are enablers of a secure software supply chain based on encapsulation
    (using Linux namespaces and cgroups), secrets, content trust, and image vulnerability
    scanning.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Any given container runs anywhere where containers can run for the following
    reasons:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Containers are self-contained black boxes. They encapsulate not only an application
    but all its dependencies, such as libraries and frameworks, configuration data,
    certificates, and so on.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers are based on widely accepted standards such as OCI.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The answer is **B**. Containers are useful for modern applications as well as
    to containerize traditional applications. The benefits for an enterprise when
    doing the latter are huge. Cost savings in the maintenance of legacy apps of 50%
    or more have been reported. The time between new releases of such legacy applications
    could be reduced by up to 90%. These numbers have been publicly reported by real enterprise
    customers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 50% or more.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Containers are based on Linux namespaces (network, process, user, and so on) and
    cgroups (control groups).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker-machine` can be used for the following scenarios:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To create a VM on various providers such as VirtualBox, Hyper-V, AWS, MS Azure,
    or Google Compute Engine that will serve as a Docker Host.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To start, stop, or kill a previously generated VM.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To SSH into a local or remote Docker Host VM created with this tool.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To re-generate certificates for the secure use of a Docker Host VM.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A. True. Yes, with Docker for Windows, you can develop and run Linux containers.
    It is also possible, but not discussed in this book, to develop and run native
    Windows containers with this edition of Docker for Desktop. With the macOS edition,
    you can only develop and run Linux containers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scripts are used to automate processes and hence avoid human errors. Building,
    testing, sharing, and running Docker containers are tasks that should always be
    automated to increase their reliability and repeatability.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following Linux distros are certified to run Docker: RedHat Linux (RHEL),
    CentOS, Oracle Linux, Ubuntu, and more.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following Windows OS are certified to run Docker: Windows 10 Pro, Windows
    Server 2016, and Windows Server 2019'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The possible states of a Docker container are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`created`: A container that has been created but not started'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`restarting`: A container that is in the process of being restarted'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`running`: A currently running container'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`paused`: A container whose processes have been paused'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`exited`: A container that ran and completed'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dead`: A container that the Docker engine tried and failed to stop'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use `docker container ls` (or the old, shorter version, `docker ps`)
    to list all containers that are currently running on our Docker host. Note that
    this will NOT list the stopped containers, for which you need the extra parameter`--all` (or `-a`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To list all IDs of containers, running or stopped, we can use `docker container
    ls -a -q`, where `-q` stands for output ID only.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Dockerfile` could look like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note that in Ubuntu, the `ping` tool is part of the `iputils-ping` package.
    Build the image called `pinger`—for example— with `docker image build -t my-pinger`.
  prefs: []
  type: TYPE_NORMAL
- en: '2\. The `Dockerfile` could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Build the image with `docker image build -t my-alpine:1.0`.
  prefs: []
  type: TYPE_NORMAL
- en: '3\. The `Dockerfile` for a Go application could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You can find the full solution in the `~/fod/ch04/answer03` folder.
  prefs: []
  type: TYPE_NORMAL
- en: '4\. A Docker image has the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. It is immutable.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. It consists of one-to-many layers.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. It contains the files and folders needed for the packaged application to
    run.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. **C.** First, you need to log in to Docker Hub; then, tag your image correctly
    with the username; and finally, push the image.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way to play with volumes is to use the Docker Toolbox because when
    directly using Docker for Desktop, the volumes are stored inside a (somewhat hidden)
    Linux VM that Docker for Desktop uses transparently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, we suggest the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'And now that you''re inside a Linux VM called `volume-test`, you can do the following
    exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a named volume, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'To get the path on the host for the volume, use this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This (if you''re using `docker-machine` and VirtualBox) should result in this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In another terminal, execute this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute a command such as this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Exit both containers and then, back on the host, execute this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The answer is B. Each container is a sandbox and thus has its very own environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Collect all environment variables and their respective values in a configuration
    file, which you then provide to the container with the `--env-file` command-line
    parameter in the `docker run` command, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Chapter 6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Possible answers: a) Volume mount your source code in the container; b) use
    a tool that automatically restarts the app running inside the container when code
    changes are detected; c) configure your container for remote debugging.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can mount the folder containing the source code on your host in the container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you cannot cover certain scenarios easily with unit or integration tests
    and if the observed behavior of the application cannot be reproduced when the
    application runs on the host. Another scenario is a situation where you cannot
    run the application on the host directly due to the lack of the necessary language
    or framework.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the application is running in production, we cannot easily gain access
    to it as developers. If the application shows unexpected behavior or even crashes,
    logs are often the only source of information we have to help us reproduce the
    situation and pinpoint the root cause of the bug.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pros and cons:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pro: We don''t need to have the particular shell, tool, or language required
    by the task installed on our host.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pro: We can run on any Docker host, from Raspberry Pi to a mainframe computer;
    the only requirement is that the host can run containers.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pro: After a successful run, the tool is removed without leaving any traces
    from the host when the container is removed.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Con: We need to have Docker installed on the host.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Con: The user needs to have a basic understanding of Docker containers.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Con: Use of the tool is a bit more indirect than when using it natively.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Running tests in a container has the following advantages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They run equally well on a developer machine than on a test or CI system.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It is easier to start each test run with the same initial conditions.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All developers working with the code use the same setup, for example, versions
    of libraries and frameworks.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, we expect a diagram that shows a developer writing code and checking it
    in, for example, GitHub. We then want to see an automation server such as Jenkins
    or TeamCity in the picture that is either periodically polling GitHub for changes
    or the GitHub triggers the automation server (with an HTTP callback) to create
    a new build. The diagram should also show that the automation server then runs
    all tests against the built artifacts and, if they all succeed, deploys the application
    or service to an integration system where it is again tested, for example, with
    a few smoke tests. Once again, if those tests succeed, the automation server should
    either ask a human for approval to deploy to production (this equals to continuous
    delivery) or the automation server should automatically deploy to production (continuous
    deployment).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: You could be working on a workstation with limited resources or capabilities,
    or your workstation could be locked down by your company so that you are not allowed
    to install any software that is not officially approved. Sometimes, you might
    need to do proof of concepts or experiments using languages or frameworks that
    are not yet approved by your company (but might be in the future if the proof
    of concept is successful).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bind-mounting a Docker socket into a container is the recommended method when
    a containerized application needs to automate some container-related tasks. This
    can be an application such as an automation server such as Jenkins that you are
    using to build, test, and deploy Docker images.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Most business applications do not need root-level authorizations to do their
    job. From a security perspective, it is hence strongly recommended to run such
    applications with the least necessary access rights to their job. Any unnecessary
    elevated privileges could possibly be exploited by hackers in a malicious attack.
    By running the application as a non-root user, you make it more difficult for
    potential hackers to compromise your system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Volumes contain data and the lifespan of data most often needs to go far beyond
    the life cycle of a container or an application, for that matter. Data is often
    mission-critical and needs to be stored safely for days, months, even years. When
    you delete a volume, you irreversibly delete the data associated with it. Hence,
    make sure you know what you're doing when deleting a volume.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: In a distributed application architecture, every piece of the software and infrastructure
    needs to be redundant in a production environment, where the continuous uptime
    of the application is mission-critical. A highly distributed application consists
    of many parts and the likelihood of one of the pieces failing or misbehaving increases
    with the number of parts. It is guaranteed that, given enough time, every part
    will eventually fail. To avoid outages of the application, we need redundancy
    in every part, be it a server, a network switch, or a service running on a cluster
    node in a container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In highly distributed, scalable, and fault-tolerant systems, individual services
    of the application can move around due to scaling needs or due to component failures.
    Thus, we cannot hardwire different services with each other. Service A, which
    needs access to Service B, should not have to know details such as the IP address
    of Service B. It should rely on an external provider of this information. DNS
    is such a provider of location information. Service A just tells it that it wants
    to talk to Service B and the DNS service will figure out the details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A circuit breaker is a means to avoid cascading failures if a component in a
    distributed application is failing or misbehaving. Similar to a circuit breaker
    in electric wiring, a software-driven circuit breaker cuts the communication between
    a client and a failed service. The circuit breaker will directly report an error
    back to the client component if the failed service is called. This gives the system
    the opportunity to recover or heal from failure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A monolithic application is easier to manage that a multi-service application
    since it consists of a single deployment package. On the other hand, a monolith
    is harder to scale to account for increased demand. In a distributed application,
    each service can be scaled individually and each service can run on optimized
    infrastructure, while a monolith needs to run on infrastructure that is OK for
    all or most of the features implemented in it. Maintaining and updating a monolith
    is much harder than a multi-service application, where each service can be updated
    and deployed independently. The monolith is often a big, complex, and tightly
    coupled pile of code. Minor modifications can have unexpected side effects. (Micro-)
    Services, on the other hand, are self-contained, simple components that behave
    like black boxes. Dependent services know nothing about the inner workings of
    the service and thus do not depend on it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A blue-green deployment is a form of software deployment that allows for zero
    downtime deployments of new versions of an application or an application service.
    If, say, Service A needs to be updated with a new version, then we call the currently
    running version blue. The new version of the service is deployed into production,
    but not yet wired up with the rest of the application. This new version is called
    green. Once the deployment succeeds and smoke tests have shown it's ready to go,
    the router that funnels traffic to blue is reconfigured to switch to green. The
    behavior of green is observed for a while and if everything is OK, blue is decommissioned.
    On the other hand, if green causes difficulties, the router can simply be switched
    back to blue and green can be fixed and later redeployed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The three core elements are **sandbox**, **endpoint**, and **network**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Execute this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Run this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Test that both NGINX instances are up and running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: You should be seeing the welcome page of NGINX in both cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the IPs of all attached containers, run this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see something similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'To get the subnet used by the network, use the following (for example):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'You should receive something along the lines of the following (obtained from
    the previous example):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The `host` network allows us to run a container in the networking namespace
    of the host.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Only use this network for debugging purposes or when building a system-level tool.
    Never use the `host` network for an application container running a production
    environment!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `none` network is basically saying that the container is not attached to
    any network. It should be used for containers that do not need to communicate
    with other containers and do not need to be accessed from outside.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `none` network could, for example, be used for a batch process running in
    a container that only needs access to local resources such as files that could
    be accessed via a host mounted volume.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Traefik can be used to provide Layer 7 or application-level routing. This is
    especially useful if you want to break out functionality from a monolith with
    a well-defined API. In this case, you have a need to reroute certain HTTP calls
    to the new container/service. This is just one of the possible usage scenarios,
    but it's also the most important one. Another one could be to use Traefik as a
    load balancer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code can be used to run the application in detached or daemon
    mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the following command to display the details of the running service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This should result in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command can be used to scale up the web service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Chapter 12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: A mission-critical, highly available application that is implemented as a highly
    distributed system of interconnected application services that are just too complex
    to manually monitor, operate, and manage. Container orchestrators help in this
    regard. They automate most of the typical tasks, such as reconciling a desired
    state, or collecting and aggregating key metrics of the system. Humans cannot
    react quick enough to make such an application elastic or self-healing. Software
    support is needed for this in the form of the mentioned container orchestrators.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A container orchestrator frees us from mundane and cumbersome tasks such as
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scaling services up and down
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Load balancing requests
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Routing requests to the desired target
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring the health of service instances
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Securing a distributed application
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The winner in this space is Kubernetes, which is open sourced and owned by the
    CNCF. It was originally developed by Google. We also have Docker Swarm, which
    is proprietary and has been developed by Docker. AWS offers a container service
    called ECS, which is also proprietary and tightly integrated into the AWS ecosystem.
    Finally, Microsoft offers AKS, which has the same pros and cons as AWS ECS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The correct answer is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The `--advertise-addr` is optional and is only needed if you the host have more than
    one IP address.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the worker node that you want to remove, execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: On one of the master nodes, execute the command `$ docker node rm -f<node ID>`,
    where <`node ID>` is the ID of the worker node to remove.
  prefs: []
  type: TYPE_NORMAL
- en: 'The correct answer is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The correct answer is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The correct answer is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Chapter 14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Zero-downtime deployment means that a new version of a service in a distributed
    application is updated to a new version without the application needing to stop
    working. Usually, with Docker SwarmKit or Kubernetes (as we will see), this is
    done in a rolling fashion. A service consists of multiple instances and those
    are updated in batches so that the majority of the instances are up and running
    at all times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By default, Docker SwarmKit uses a rolling updated strategy to achieve zero-downtime
    deployments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Containers are self-contained units of deployment. If a new version of a service
    is deployed and does not work as expected, we (or the system) need to only roll
    back to the previous version. The previous version of the service is also deployed
    in the form of self-contained containers. Conceptually, there is no difference
    in rolling forward (update) or backward (rollback). One version of a container
    is replaced by another one. The host itself is not affected by such changes in
    any way.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Docker secrets are encrypted at rest. They are only transferred to the services
    and containers that use the secrets. Secrets are transferred encrypted due to
    the fact that the communication between swarm nodes uses mutual TLS. Secrets are
    never physically stored on a worker node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The command to achieve this is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '6\. First, we need to remove the old secret from the service, and then we need
    to add the new version to it (directly updating a secret is not possible):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Chapter 15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The Kubernetes master is responsible for managing the cluster. All requests
    to create objects, reschedule pods, manage ReplicaSets, and more happen on the
    master. The master does not run the application workload in a production or production-like
    cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On each worker node, we have the kubelet, the proxy, and container runtime.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The answer is A. **Yes**. You cannot run standalone containers on a Kubernetes
    cluster. Pods are the atomic units of deployment in such a cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All containers running inside a pod share the same Linux kernel network namespace.
    Thus, all processes running inside those containers can communicate with each
    other through `localhost` in a similar way to how processes or applications directly
    running on the host can communicate with each other through `localhost`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `pause` container's sole role is to reserve the namespaces of the pod for
    containers that run in it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is a bad idea since all containers of a pod are co-located, which means
    they run on the same cluster node. Also, if multiple containers run in the same
    pod, they can only be scaled up or down all at once. However, the different components
    of the application (that is, `web`, `inventory`, and `db`) usually have very different
    requirements with regard to scalability or resource consumption. The `web` component
    might need to be scaled up and down depending on the traffic and the `db` component,
    in turn, has special requirements regarding storage that the others don't have.
    If we do run every component in its own pod, we are much more flexible in this
    regard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We need a mechanism in order to run multiple instances of a pod in a cluster
    and make sure that the actual number of pods running always corresponds to the
    desired number, even when individual pods crash or disappear due to network partition or
    cluster node failures. The ReplicaSet is the mechanism that provides scalability
    and self-healing to any application service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We need deployment objects whenever we want to update an application service in
    a Kubernetes cluster without causing downtime to the service. Deployment objects
    add rolling updates and rollback capabilities to ReplicaSets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Kubernetes service objects are used to make application services participate
    in service discovery. They provide a stable endpoint to a set of pods (normally
    governed by a ReplicaSet or a deployment). Kube services are abstractions that define
    a logical set of pods and a policy regarding how to access them. There are four types
    of Kube service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**ClusterIP**: Exposes the service on an IP address that''s only accessible
    from inside the cluster; this is a virtual IP (VIP).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NodePort**: Publishes a port in the range 30,000–32,767 on every cluster node.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LoadBalancer**: This type exposes the application service externally using
    a cloud provider''s load balancer, such as ELB on AWS.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ExternalName**: Used when you need to define a proxy for a cluster''s external
    service such as a database.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming we have a Docker image in a registry for the two application services, the
    web API and Mongo DB, we then need to do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a deployment for Mongo DB using a StatefulSet; let's call this deployment `db-deployment`.
    The StatefulSet should have one replica (replicating Mongo DB is a bit more involved
    and is outside the scope of this book).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Define a Kubernetes service called `db` of the `ClusterIP` type for `db-deployment`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Define a deployment for the web API; let's call it `web-deployment`. Let's scale
    this service to three instances.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Define a Kubernetes service called `api` of the `NodePort` type for `web-deployment`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If we use secrets, then define those secrets directly in the cluster using kubectl.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy the application using kubectl.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: To implement layer 7 routing for an application, we ideally use an IngressController.
    The IngressController is a reverse proxy such as Nginx that has a sidecar listening
    on the Kubernetes Server API for relevant changes and updating the reverse proxy's
    configuration and restarting it if such a change has been detected. Then, we need
    to define Ingress resources in the cluster that define the routing, for example,
    from a context-based route such as `https://example.com/pets to <a service name>/<port>` or
    a pair such as `api/32001`. The moment Kubernetes creates or changes this Ingress
    object, the IngressController's sidecar picks it up and updates the proxy's routing configuration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Assuming this is a cluster internal inventory service, then we do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When deploying version 1.0, we define a deployment called `inventory-deployment-blue` and
    label the pods with a label of `color: blue`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We deploy the Kubernetes service of the `ClusterIP` type called inventory for
    the preceding deployment with the selector containing `color: blue`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When we''re ready to deploy the new version of the payments service, we define
    a deployment for version 2.0 of the service and call it `inventory-deployment-green`.
    We add a label of `color: green` to the pods.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can now smoke test the "green" service and when everything is OK, we can
    update the inventory service so that the selector contains `color: green`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Some forms of information that are confidential and thus should be provided
    to services through Kubernetes secrets include passwords, certificates, API key
    IDs, API key secrets, and tokens.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sources for secret values can be files or base64-encoded values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: We cannot do any live debugging on a production system for performance and security
    reasons. This includes interactive or remote debugging. Yet application services
    can show unexpected behavior to code defects or other infrastructure-related issues
    such as network glitches or external services that are not available. To quickly
    pinpoint the reason for the misbehavior or failure of a service, we need as much
    logging information as possible. This information should give us a clue about,
    and guide us to, the root cause of the error. When we instrument a service, we
    do exactly this — we produce as much information as reasonable in the form of
    log entries and published metrics.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prometheus is a service that is used to collect functional or non-functional
    metrics that are provided by other infrastructure services and most importantly
    by application services. Since Prometheus itself is pulling those metrics periodically
    from all configured services, the services themselves do not have to worry about
    sending data. Prometheus also defines the format in which the metrics are to be
    presented by the producers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To instrument a Node.js-based application service we need to do the following
    four steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a Prometheus adapter to the project. The maintainers of Prometheus recommend
    the library called `siimon/prom-client`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure the Prometheus client during startup of the application. This includes
    the definition of a metrics registry.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Expose an HTTP GET endpoint/metrics where we return the collection of metrics
    defined in the metrics registry.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we define custom metrics of the `counter`, `gauge`, or `histogram` type,
    and use them in our code; for example, we increase a metric of the `counter` type
    each time a certain endpoint is called.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Normally in production, a Kubernetes cluster node only contains a minimal OS
    to keep its attack surface as limited as possible and to not waste precious resources.
    Thus we cannot assume that the tools typically used to troubleshoot applications
    or processes are available on the respective host. A powerful and recommended
    way to troubleshoot is to run a special tools or troubleshoot container as part
    of an ad hoc pod. This container can then be used as a bastion from which we can
    investigate network and other issues with the troubled service. A container that
    has been successfully used by many Docker field engineers at their customers site is `netshoot`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some sample answers to the questions presented in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To install UCP in AWS, we do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a VPC with subnets and an SG.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, provision a cluster of Linux VMs, possibly as part of an ASG. Many Linux
    distributions are supported, such as CentOS, RHEL, and Ubuntu.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, install Docker on each VM.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, select one VM on which to install UCP using the `docker/ucp` image.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Once UCP is installed, join the other VMs to the cluster either as worker nodes
    or manager nodes.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are a few reasons to consider a hosted Kubernetes offering:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You do not want to, or do not have the resources to, install and manage a Kubernetes
    cluster.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You want to concentrate on what brings value to your business, which in most
    cases is the applications that are supposed to run on Kubernetes and not Kubernetes
    itself.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You prefer a cost model where you pay only for what you need.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The nodes of your Kubernetes cluster are automatically patched and updated.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Upgrading the version of Kubernetes with zero downtime is easy and straightforward.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The two main reasons to host container images on the cloud provider''s container
    registry (such as ACR on Microsoft Azure) are these:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The images are geographically close to your Kubernetes cluster and thus the
    latency and transfer network costs are minimal.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Production or production-like clusters are ideally sealed from the internet,
    and thus the Kubernetes cluster nodes cannot access Docker Hub directly.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
