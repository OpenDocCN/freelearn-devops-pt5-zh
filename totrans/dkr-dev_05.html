<html><head></head><body>
		<div><h1 id="_idParaDest-57"><em class="italic"><a id="_idTextAnchor059"/>Chapter 4</em>: Composing Systems Using Containers</h1>
			<p>In the previous chapter, we created a server-side application using microservices architecture. The application was made up of five separate containers: three official images and two custom images. The official images were for MongoDB, Redis, and Mosca (MQTT).</p>
			<p>For the most part, communication between containers is done via MQTT message passing. The<a id="_idIndexMarker183"/> subscriber container carries out the database <code>localhost </code>(<code>127.0.0.1</code>) and both subscriber and publisher programs to access Mosca/MQTT at <code>localhost</code>, too.</p>
			<p>In this chapter, we are going to discuss composing systems—specifically, Docker Compose.  We are also going to learn how to keep network access private so that services can be accessed from within our containers but not be accessible from the host. We will learn how we can share volumes in the filesystem between containers. There are alternatives to Docker Compose, and we will look at some of them.</p>
			<p>We will cover the following topics in this chapter:</p>
			<ul>
				<li>Introduction to Docker Compose</li>
				<li>Using Docker local networking</li>
				<li>Local volumes</li>
				<li>Other composition tools</li>
			</ul>
			<p>To recap, we have three official image containers for MongoDB, Mosca, and Redis. We have an additional two containers created for this book—publisher and subscriber microservices.  </p>
			<p>The publisher microservice has been modified to present a form in a web browser. The fields in the form and the submit buttons allow us to exercise the various operations supported by the subscriber microservice:</p>
			<div><div><img src="img/B11641_04_001.jpg" alt="Figure 4.1 – The form generated by our updated publisher program"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.1 – The form generated by our updated publisher program</p>
			<p>You can choose which database to perform CRUD operations on. You can also set a value that is to be used for the <strong class="bold">List</strong>, <strong class="bold">Count</strong>, <strong class="bold">Add</strong>, and <strong class="bold">Remove</strong> operations. There is a button for each of the CRUD operations, as well as a <strong class="bold">Flush</strong> button, which removes all the records from the selected database. The return value/result of the operation is shown beneath the form under the <strong class="bold">Result</strong> heading.</p>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor060"/>Technical requirements</h1>
			<p>The prerequisite software for this chapter includes Docker, Docker Compose (see <a href="https://docs.docker.com/compose/install/">https://docs.docker.com/compose/install/</a>), Git, and a web browser, such as Google Chrome or Safari.</p>
			<p>The Docker and Docker Compose documentation use the term <em class="italic">service</em>, whereas we use the term <em class="italic">microservice</em>. For the purposes of this chapter, the terms are interchangeable.</p>
			<p>In the GitHub repository (<a href="https://github.com/PacktPublishing/Docker-for-Developers">https://github.com/PacktPublishing/Docker-for-Developers</a>), there is a <code>chapter4/</code> directory that accompanies this chapter. It contains a modified version of the microservices architecture code used in the previous chapter.</p>
			<p>Check out the following video to see the Code in Action:</p>
			<p><a href="https://bit.ly/3iRWqoH">https://bit.ly/3iRWqoH</a></p>
			<h1 id="_idParaDest-59"><a id="_idTextAnchor061"/>Introduction to Docker Compose</h1>
			<p>A composing <a id="_idIndexMarker184"/>system for containers is a tool that allows us to describe the whole microservices architecture program in a configuration file and then perform operations on the system described. Docker Compose is one such tool. Before we get into what Docker Compose is and does, let's look at the reason why we need a tool like this.</p>
			<h2 id="_idParaDest-60"><a id="_idTextAnchor062"/>The problem with .sh scripts</h2>
			<p>So far, we've <a id="_idIndexMarker185"/>been using <code>.sh</code> scripts to make working with our microservices application easy. We have used the following scripts:</p>
			<ul>
				<li>start-mongodb.sh</li>
				<li>start-redis.sh</li>
				<li>start-mosca.sh</li>
				<li><code>subscriber/</code>start-subscriber.sh</li>
				<li><code>publisher/</code>start-publisher.sh</li>
				<li><code>subscriber/</code>build.sh</li>
				<li><code>publisher/</code>build.sh</li>
				<li><code>subscriber/</code>push.sh</li>
				<li><code>publisher/</code>push.sh</li>
			</ul>
			<p>Instead of having to invoke each of these as separate commands, we can make a single start-all.sh script that invokes them all:</p>
			<pre>#!/bin/sh
./start-mosca.sh
./start-mongodb.sh
./start-redis.sh
cd subscriber &amp;&amp; ./start-subscriber.sh &amp; cd ..
cd publisher &amp;&amp; ./start-publisher.sh &amp; cd ..</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">The start-all.sh script is presented for informational purposes. We will not be using it going forward!</p>
			<p>This approach works, but the information about what ports are open and other container-specific access information is hidden within those <code>.sh</code> scripts. For example, the mongodb.sh script starts MongoDB and binds port <code>27017</code> of the container to port <code>27017</code> of the host.  </p>
			<p>Making changes<a id="_idIndexMarker186"/> to the configuration may require editing each of those <code>.sh</code> scripts, and maybe even the start-all.sh script itself, as well as its counterpart, stop-sll.sh. We have several additional scripts as well for building and publishing the containers and to perform other housekeeping tasks. This approach is both inconvenient and error-prone.</p>
			<p>The Docker Compose tool solves most of the issues with <code>.sh</code> scripts, although we might still want to use <code>.sh</code> scripts to invoke the <code>docker-compose</code> command with its various command-line arguments.</p>
			<h2 id="_idParaDest-61"><a id="_idTextAnchor063"/>Docker Compose configuration files</h2>
			<p>Configuration for<a id="_idIndexMarker187"/> Docker Compose is done via <code>.yml</code> files, the contents of which are YAML.  YAML is a markup language that allows data serialization. It is similar to JSON format but is much more human-friendly in its syntax.</p>
			<p>A file named <code>docker-compose.yml</code> is Docker Compose's default configuration file. You may have multiple configuration files, and you can tell Docker Compose which configuration files to use via a command-line switch.</p>
			<p>Let's look at the <code>docker-compose-example.yml</code> file in the <code>chapter4/</code> directory in the repository. The Docker Compose tool can replace the shell script methodology we've used so far:</p>
			<pre># Example Docker Compose file for our chapter 4 application
version: '3'
services:</pre>
			<p>Docker Compose supports different versions of the <code>docker-compose.yml</code> format. Newer versions have higher version numbers and add additional <code>docker-compose</code> features. In the <code>services</code> section, we describe each of the containers that are to be built and run.</p>
			<p>We have our <code>redis</code> container under the <code>services</code> section. The <code>image</code> field specifies that we will be using<a id="_idIndexMarker188"/> the <code>redis</code> image from Docker Hub. We persist the database in <code>/tmp/redis</code> so that the data is not lost when the container is stopped and restarted:</p>
			<pre>  redis:
    image: redis
    volumes:
      - /tmp/redis:/data
    ports:
      - 6379:6379</pre>
			<p>We expose port <code>6379</code>, the default Redis port, on the host. Exposing this port allows the host and other containers to access the Redis server.</p>
			<p>After Redis, we have our MongoDB container. We are going to use the <code>mongo</code> image from Docker Hub. We persist the data in the host's <code>/tmp/mongo</code> directory so that the database's contents are retained between stopping and restarting the container:</p>
			<pre>  mongodb:
    image: mongo
    volumes:
      - /tmp/mongo:/data/db
    ports:
      - 27017:27017</pre>
			<p>The default TCP port for MongoDB is <code>27017</code>, and we expose it to map port <code>27017</code> in the container to port <code>27017</code> on the host. Tools on the host and within our containers can access MongoDB via <code>localhost</code>, and we don't need to specify a port on the command lines since the default is configured.</p>
			<p>Next is the Mosca container. We are using the <code>matteocollina/mosca</code> image from Docker Hub. We set the <code>/db</code> volume in the container to <code>/tmp/mosca</code> on the host to persist Mosca's <a id="_idIndexMarker189"/>state:</p>
			<pre>  mosca:
    image: matteocollina/mosca
    volumes:
      - /tmp/mosca:/db
    ports:
      - 1883:1883
      - 80:80</pre>
			<p>We expose ports <code>1883</code> and <code>80</code> as the same ports on the host. Port <code>1883</code> is the default MQTT port. Port <code>80</code> is provided to support MQTT over WebSocket, so you can use MQTT in JavaScript programs in the browser.</p>
			<p>In our <code>publisher</code> container, the <code>build:</code> line tells <code>docker-compose</code> that we need to build the container specified in the <code>publisher/</code> directory. The Dockerfile in the <code>publisher</code> directory is used to define how the container is to be built:</p>
			<pre>  publisher:
    build: publisher
    environment:
    - MQTT_HOST=${HOSTIP}
    - REDIS_HOST=${HOSTIP}
    - MONGO_HOST=${HOSTIP}
    ports:
      - 3000:3000</pre>
			<p>We expose port <code>3000</code> so that we can access the web server that is running in the container using a web browser on the host.</p>
			<p>In our <code>subscriber</code> container, the <code>build:</code> line tells <code>docker-compose</code> that we need to build the container specified in the <code>subscriber/</code> directory. The Dockerfile in the <code>subscriber</code> directory is used to define how the container is to be built:</p>
			<pre>  subscriber:
    build: subscriber
    environment:
    - MQTT_HOST=${HOSTIP}
    - REDIS_HOST=${HOSTIP}
    - MONGO_HOST=${HOSTIP}</pre>
			<p>We don't expose <a id="_idIndexMarker190"/>anything—the subscriber performs all of its I/O operations via direct API calls for MongoDB and Redis, as well as accepting commands and reporting status via MQTT.</p>
			<p>Some things to note are as follows:</p>
			<ul>
				<li>All the containers are described neatly within the single configuration file.</li>
				<li>The containers still expose the same ports on the host as with the <code>.sh</code> scripts.</li>
				<li>The containers must still find the database and MQTT broker containers via the <code>HOSTIP</code> environment variable. This variable must still be set as explained in the previous chapter.</li>
			</ul>
			<p>To use our <code>docker-compose-example.yml</code> script to bring up all five microservices, we use the <code>docker-compose up</code> command. The <code>-f</code> switch tells <code>docker-compose</code> which Docker Compose <code>.yml</code> file to use:</p>
			<pre>% docker-compose -f docker-compose-example.yml up</pre>
			<p>By default, <code>docker-compose</code> runs all the containers in the configuration file in debug mode. They will print their output to the Terminal/console in the order that the lines are printed. You may see lines printed by the subscriber, then lines printed by the publisher, then lines printed by subscriber again. If you hit <em class="italic">Ctrl</em> + <em class="italic">C</em>, it will terminate all of the containers and return you to Command Prompt.</p>
			<p>If you want the containers to run in detached or daemon mode, use the <code>-d</code> switch:</p>
			<pre>% docker-compose -f docker-compose-example.yml up -d</pre>
			<p>In detached or daemon mode, the containers will not print output to the Terminal/console and you will be returned to the prompt right away.</p>
			<p>To stop all five microservices, we use a similar <code>docker-compose</code> command:</p>
			<pre>% docker-compose -f docker-compose-example.yml down</pre>
			<p>If we do not specify the Docker Compose configuration file to use (<code>-f docker-compose-example.yml</code>), then the <code>docker-compose</code> command will look for and use a file named <code>docker-compose.yml</code> instead.</p>
			<p>The <code>docker-compose up</code>/<code>down</code> commands allow us to start and stop one or more of our services as<a id="_idIndexMarker191"/> well. For example, we can start only the <code>mongodb</code> and <code>redis</code> containers:</p>
			<pre>% docker-compose -f docker-compose-example.yml up mongodb redis</pre>
			<p>The existing <code>mongodb</code> and/or <code>redis</code> containers will be stopped and new ones started. It is up to your programs to detect whether the connections to these services were stopped and to handle the error accordingly.  </p>
			<p>We can build any or all of our services using <code>docker-compose</code>:</p>
			<pre>% docker-compose -f docker-compose-example.yml build publisher</pre>
			<p>This command builds our publisher container but does not start any containers.</p>
			<p>The key takeaway from the ability to specify none (none means <em class="italic">all</em>) or one or more of our containers (by name) replaces several of our old <code>.sh</code> scripts. We don't need start scripts anymore because we can use <code>docker-compose up</code>; we don't need stop scripts because we can use <code>docker-compose down</code>; we don't need build scripts because we can use <code>docker-compose build</code>; and more! See <a href="https://docs.docker.com/compose/reference/">https://docs.docker.com/compose/reference/</a> for details on other <code>docker-compose</code> command functionality.</p>
			<p>We are likely to have different setups for development and production, if not additional scenarios. With <code>.sh</code> scripts, we have a debug.sh and run.sh script for development and production. The problem with this <code>.sh</code> file scheme is that we have almost identical <code>docker run</code> commands in each, with only minor differences.  </p>
			<p>Docker Compose has <a id="_idIndexMarker192"/>an inheritance feature where multiple configuration files can be specified on the <code>docker-compose</code> command line.  </p>
			<h2 id="_idParaDest-62"><a id="_idTextAnchor064"/>Inheritance using multiple configuration files</h2>
			<p>We can<a id="_idIndexMarker193"/> implement a base <code>docker-compose.yml</code> file and then override the settings in that file with our own override <a id="_idIndexMarker194"/>configuration files. This feature is called <code>docker-compose</code> file and override the settings for our purposes. </p>
			<p>Docker Compose starts with the first configuration file on the command line, then merges the second one into it, then merges the third (if there is one), and so on. To merge means to apply settings in the second (or third) configuration file to the current state of the configuration, which will ultimately be used. Any settings in the second configuration file will replace the ones in the first configuration file, if they exist, or will add new services or settings if they don't already exist.</p>
			<p>Let's look at the <code>docker-compose.yml</code> base file, which we'll use from now on:</p>
			<pre>version: '3'
services:
  redis:
    image: redis
  mongodb:
    image: mongo
    volumes:
      - /tmp/mongo:/data/db
  mosca:
    image: matteocollina/mosca
    volumes:
      - /tmp/mosca:/db
  publisher:
    build: publisher
    
    depends_on:
      - "mosca"
      - "subscriber"
  subscriber:
    build: subscriber
    depends_on:
      - "redis"
      - "mongodb"
      - "mosca"</pre>
			<p>This looks <a id="_idIndexMarker195"/>like the <code>docker-compose-example.yml</code> file from the previous section, but you may notice a couple of differences:</p>
			<ul>
				<li>There are two <code>depends_on</code> options—one for the publisher and one for the subscriber.</li>
				<li>We are no longer exposing or binding the container's ports to the host's ports.</li>
			</ul>
			<p>Let's take a look at them in detail in the following sections.</p>
			<h2 id="_idParaDest-63"><a id="_idTextAnchor065"/>The depends_on option</h2>
			<p>The <code>depends_on</code> option<a id="_idIndexMarker196"/> allows us to control the start-up order of the containers (refer to <a href="https://docs.docker.com/compose/startup-order/">https://docs.docker.com/compose/startup-order/</a>). Additionally, <code>depends_on</code> expresses an interdependency between containers. Refer to https://docs.docker.com/compose/compose-file/#depends-on#depends_on for more information about the <code>depends_on</code> option.</p>
			<p>Service dependencies cause the following behaviors:</p>
			<ul>
				<li><code>docker-compose up</code> starts services in dependency order. In our example, <code>redis</code>, <code>mongo</code>, and the <code>mosca</code> services are started before the <code>subscriber</code> container, and both <code>mosca</code> and <code>subscriber</code> are started before <code>publisher</code>.</li>
				<li><code>docker-compose up SERVICE</code> automatically includes dependencies under <code>SERVICE</code>.</li>
			</ul>
			<p><code>docker-compose stop</code> stops services in dependency order (<code>mosca</code>, then <code>mongodb</code>, then <code>redis</code> in our <code>docker-compose.yml</code> file). </p>
			<p>The order in which the services are started is important because if we start <code>publisher</code> before <code>mosca</code> is running, the logic to connect to the MQTT broker in the <code>publisher</code> program <a id="_idIndexMarker197"/>will fail. Similarly, starting <code>subscriber</code> before the database and MQTT broker services would likely cause the logic in <code>subscriber</code> to connect to the databases and the MQTT broker to fail. It doesn't make sense to start <code>publisher</code> before <code>subscriber</code> is running because anything <code>publisher</code> sends via MQTT will fall on deaf ears, so to speak.</p>
			<p>Even though a container has started, there is no guarantee that the container's program will have completed its initialization by the time the microservices that use them try to connect.  In our publisher and subscriber code, we created a <code>wait_for_services()</code> method that ensures that we can connect to the services only when they are up and ready.  </p>
			<p>We call <code>wait_for_services()</code> first thing in our publisher and subscriber programs to ensure we have waited just long enough for the dependent services to be up and ready.</p>
			<p>The <code>wait_for_services()</code> method in <code>publisher/</code>index.js is as follows:</p>
			<pre>/**
 * wait_for_services
 *
 * This method is called at startup to wait for any dependent containers to be running.
 */
const waitOn = require("wait-on"),
  wait_for_services = async () =&gt; {
  try {
    await waitOn({ resources: [`tcp:${mqtt_host}:${mqtt_port}`] });
  } catch (e) {
    debug("waitOn exception", e.stack);
  }
};</pre>
			<p>Our <code>publisher</code> microservice <a id="_idIndexMarker198"/>only connects to the MQTT broker, so the <code>wait_for_services()</code> method only waits for our MQTT broker's TCP port to be accessible.</p>
			<p>The <code>wait_for_services()</code> method in <code>subscriber/</code>index.js is a bit more complicated:</p>
			<pre>/**
 * wait_for_services
 *
 * This method is called at startup to wait for any dependent containers to be running.
 */
const waitOn = require("wait-on"),
  wait_for_services = async () =&gt; {
  try {
    debug(`waiting for mqtt (${mqtt_host}:${mqtt_port})`);
    await waitOn({ resources: [`tcp:${mqtt_host}:${mqtt_port}`] });
    debug(`waiting for redis (${redis_host}:${redis_port})`);
    await waitOn({ resources: [`tcp:${redis_host}:${redis_port}`] });
    debug(`waiting for mongo (${mongo_host}:${mongo_port})`);
    await waitOn({ resources: [`tcp:${mongo_host}:${mongo_port}`] });
  } catch (e) {
    debug("***** exception ", e.stack);
  }
};</pre>
			<p>The <code>subscriber</code> microservice <a id="_idIndexMarker199"/>needs to connect to the MQTT broker, the <code>redis</code> server, and the <code>mongo</code> server. We wait for the TCP ports of those servers to be accessible.</p>
			<p>There are other ways to wait for services to be available that involve installing command-line programs/scripts in the container and running them before starting our publisher or subscriber service. For example, you might use this handy wait-for-it.sh script, which can be found at <a href="https://github.com/vishnubob/wait-for-it">https://github.com/vishnubob/wait-for-it</a>.</p>
			<p>The lack of options in the <code>docker-compose.yml</code> file to expose container ports is not an oversight. We are fully able to specify those options in an override file that can provide options to existing containers.</p>
			<h2 id="_idParaDest-64"><a id="_idTextAnchor066"/>Adding port bindings using overrides</h2>
			<p>In the <code>chapter4/</code> directory<a id="_idIndexMarker200"/> in the code repository, we have a <code>docker-compose-simple.yml</code> file that is an example of an override file:</p>
			<pre>version: '3'
services:
  redis:
    ports:
      - 6379:6379
  mongodb:
    ports:
      - 27017:27017
  mosca:
    ports:
      - 1883:1883
      - 80:80
  publisher:
    environment:
    - MQTT_HOST=${HOSTIP}
    - REDIS_HOST=${HOSTIP}
    - MONGO_HOST=${HOSTIP}
    ports:
      - 3000:3000
  subscriber:
    environment:
    - MQTT_HOST=${HOSTIP}
    - REDIS_HOST=${HOSTIP}
    - MONGO_HOST=${HOSTIP}</pre>
			<p>Here, we specify the ports for each<a id="_idIndexMarker201"/> container. We are inheriting the options from our <code>docker-compose.yml</code> file and adding options to expose the ports for each of our containers.  </p>
			<p>We don't expose any ports for the <code>subscriber</code> microservice because it never exposes any ports to the host's ports.</p>
			<p>We also define three environment variables to be used by the publisher and subscriber containers to access the <code>MQTT_HOST</code> (<code>mosca</code>), <code>REDIS_HOST</code> (<code>redis</code>), and <code>MONGO_HOST</code> (<code>mongodb</code>) services.</p>
			<p>The <code>docker-compose</code> command to bring up our services using the two configuration files (inheritance) is as follows:</p>
			<pre>% HOSTIP=192.168.0.21 docker-compose -f docker-compose.yml -f docker-compose-simple.yml up</pre>
			<p>Since we are not using the <code>-d</code> switch, our containers are not detached but print their console/debug output to the Terminal. You cannot enter more commands until you hit <em class="italic">Ctrl</em>+ <em class="italic">C</em>. Doing this will stop all the containers in reverse <code>depends_on</code> order and return you to Command Prompt:</p>
			<pre>% HOSTIP=192.168.0.21 docker-compose -f docker-compose.yml -f docker-compose-simply.yml up -d</pre>
			<p>Adding the <code>-d</code> switch <a id="_idIndexMarker202"/>causes all the containers to be started in daemon mode. They run in the background and you immediately get a command-line prompt. No further output is sent to the Terminal.</p>
			<p>If containers are running in daemon mode, you can stop them using the <code>docker-compose down</code> command:</p>
			<pre>% HOSTIP=192.168.0.21 docker-compose -f docker-compose.yml -f docker-compose-simple.yml down</pre>
			<p>We can use three or more configuration files as well. Each additional file specified on the command line further extends the containers and options specified within.</p>
			<p>What we have so far is effectively a production that is set up using inheritance. Debugging using this is particularly painful because your only means of diagnosing errors is to add <code>debug()</code> calls to the publisher and/or subscriber, then rebuilding the container(s), and then rerunning the whole application.</p>
			<p>To improve our development and debugging cycles, we can bind/mount our <code>publisher/ </code>and <code>subscriber/</code> directories to the <code>/home/app</code> directory in the containers. The Dockerfiles for both containers use the nodemon (<a href="https://nodemon.io/">https://nodemon.io/</a>) utility to start the application within the container.</p>
			<p>The nodemon utility does a bit more than just starting our program:</p>
			<ul>
				<li>It also monitors the state of the program, and if it stops, nodemon will restart it.  This is useful because our Node.js programs might detect an error from which they cannot easily be recovered, so they just exit and allow nodemon to restart them.</li>
				<li>For development, nodemon also monitors the timestamps of the files in the code directory and will restart the program if any of the files change.  </li>
			</ul>
			<p>Since we <a id="_idIndexMarker203"/>can bind/mount our source code directly in the container, any changes we make to the files using our editor or IDE on the host will immediately affect the changes in the container.</p>
			<p>We can create a <code>docker-compose-simple-dev.yml</code> file, which adds our bind/mounts to publisher and subscriber:</p>
			<pre>version: '3'
services:
  publisher:
    volumes:
      - ./publisher:/home/app
  subscriber:
    volumes:
      - ./subscriber:/home/app </pre>
			<p>We run this using the <code>docker-compose up</code> command:</p>
			<pre>% HOSTIP=192.168.0.21 docker-compose -f docker-compose.yml -f docker-compose-simple.yml -f dockercompose-simple-dev.yml up -d</pre>
			<p>If we edit, say, the <code>publisher/</code>index.js file on the host, we can see that nodemon sees the change and restarts the publisher program:</p>
			<pre>publisher_1   | [nodemon] restarting due to changes...
publisher_1   | [nodemon] starting `node ./index.js`
publisher_1   | 2020-03-30T18:03:39.537Z publisher publisher microservice, about to wait for MQTT host(192.168.0.21, 1883
publisher_1   | 2020-03-30T18:03:39.546Z publisher ---&gt; wait succeeded
publisher_1   | 2020-03-30T18:03:39.587Z publisher publisher connecting to MQTT mqtt://192.168.0.21
publisher_1   | 2020-03-30T18:03:39.591Z publisher connected to  192.168.0.21 port 1883
publisher_1   | 2020-03-30T18:03:39.638Z publisher listening on port  3000</pre>
			<p>We now<a id="_idIndexMarker204"/> have a good handle on <code>docker-compose</code>, but we are binding ports from our containers to the host's ports. This is problematic if you have a container that wants to bind to port <code>80</code> on the host but the host is running a web server or another container for another project that also wants to bind to port <code>80</code>.</p>
			<p>Fortunately, Docker provides a facility to only expose our ports to our containers!</p>
			<h1 id="_idParaDest-65"><a id="_idTextAnchor067"/>Using Docker local networking</h1>
			<p>Both Docker and Docker<a id="_idIndexMarker205"/> Compose have command-line options to specify a Docker local network that the application will use. Using this Docker local network allows our containers to access another container's ports without having to bind/expose these ports to the host's ports.</p>
			<h2 id="_idParaDest-66"><a id="_idTextAnchor068"/>Networking using .sh scripts</h2>
			<p>You use the <code>docker network create</code> command to create a named network that your containers <a id="_idIndexMarker206"/>can use to privately communicate with one another. You can have as many of these private networks defined as you like—you might want to work on multiple unrelated projects simultaneously and each needs its own network:</p>
			<pre>% docker network create chapter4</pre>
			<p>This command creates a network named <code>chapter4</code> that we can use for our microservices example programs. We can destroy networks we have created using the <code>docker network rm</code> command:</p>
			<pre>% docker network rm chapter4</pre>
			<p>This command removes our <code>chapter4</code> network from the system.</p>
			<p>The start-mongodb.sh, start-redis.sh, start-mosca.sh, <code>publisher/</code>run.sh, and <code>subscriber/</code>run.sh scripts are used by the up.sh script to bring up our application's containers using the <code>docker run</code> command.</p>
			<p>Let's examine<a id="_idIndexMarker207"/> our up.sh script:</p>
			<pre>#!/bin/sh
./stop-all.sh</pre>
			<p>We run the <code>docker network create</code> command to create our <code>chapter4</code> network:</p>
			<pre>docker network create chapter4</pre>
			<p>We start our three servers:</p>
			<pre>./start-mosca.sh
./start-mongodb.sh</pre>
			<p>We also run <code>./</code>start-redis.sh:</p>
			<pre>###### SUBSCRIBER
cd subscriber
./run.sh</pre>
			<p>Finally, we start the publisher:</p>
			<pre>###### PUBLISHER
# publisher needs to expose port 3000 
# so we can access the WWW interface
cd ../publisher
./run.sh</pre>
			<p>The start-mongodb.sh and start-redis.sh scripts are roughly the same as the start-mosca.sh script. The relevant lines in the start-mosca.sh script are the ones for the <code>docker run</code> command:</p>
			<pre>docker run \
  --name $SERVICE \
  -d \
  --restart always \
  -e TITLE=$SERVICE \
  --network chapter4 \
  -v /tmp/mosca:/db \
  matteocollina/mosca</pre>
			<p>Only the service<a id="_idIndexMarker208"/> name, which third-party/Docker Hub container to use, and any container to host directory bindings are specific to <code>mongodb</code>, <code>mosca</code>, or <code>redis</code>. They all share the <code>chapter4</code> network.</p>
			<p>The <code>docker run</code> command in the <code>subscriber/</code>run.sh script looks as follows:</p>
			<pre>docker run \
  --name $SERVICE \
  -d \
  --restart always \
  -e TITLE=$SERVICE \
  --network chapter4 \
  dockerfordevelopers/$SERVICE</pre>
			<p>We are no longer defining the <code>HOSTIP</code> environment variable because the Docker local networking system provides a DNS function that allows the programs in our containers to look up the other containers by name. The name is the name of the container, which is specified in the <code>docker run</code> commands scripts with the <code>–name</code> command-line option.</p>
			<p>The relevant lines in <code>subscriber/</code>index.js are as follows:</p>
			<pre>const debug = require("debug")("subscriber"),
  mongo_host = process.env.MONGO_HOST || "mongodb",
  mongo_port = 27017,
  mongoUrl = `mongodb://${mongo_host}:${mongo_port}`,
  mqtt_host = process.env.MQTT_HOST || "mosca",
  mqtt_port = 1883,
  mqttUrl = `mqtt://${mqtt_host}`,
  redis_host = process.env.REDIS_HOST || "redis",
  redis_port = 6379,
  redisUrl = `redis://${redis_host}`;</pre>
			<p>The code is designed<a id="_idIndexMarker209"/> to accept the <code>MONGO_HOST</code> environment variable; otherwise, it will use the <code>mongodb</code> container name. The same is the case for <code>MQTT_HOST</code>/<code>mosca</code> and <code>REDIS_HOST</code>/<code>redis</code>.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">We have been defining the <code>HOSTIP</code>, <code>MONGO_HOST</code>, <code>MQTT_HOST</code>, and <code>REDIS_HOST</code> environment variables, especially in the <code>.sh</code> script examples. Since we've been naming our containers using the <code>--name</code> switch on our <code>docker run</code> commands, Docker's local DNS will work with <code>.sh</code> scripts. That is, we don't need to define those environment variables if we name our containers. We still need to bind container ports to the host's ports, unless we also add the <code>--network</code> switch and <code>docker network create</code> to the Docker local network.</p>
			<p>The down.sh script stops all the containers and removes the <code>chapter4</code> network:</p>
			<pre>#!/bin/sh
docker stop publisher
docker stop subscriber
docker stop redis
docker stop mongodb
docker stop mosca
docker network rm chapter4</pre>
			<p>We can use these <code>.sh</code> scripts, but we've already learned that Docker Compose is the superior <a id="_idIndexMarker210"/>method for managing our microservices.</p>
			<h2 id="_idParaDest-67"><a id="_idTextAnchor069"/>Networking with Docker Compose</h2>
			<p>The <code>docker-compose.yml</code> configuration file that we created is still enough to use as the base for<a id="_idIndexMarker211"/> using the <code>docker-compose</code> commands to <a id="_idIndexMarker212"/>manage our containers.  However, we no longer need to expose or bind container ports to the host's ports; the only exception is we'll continue to bind port <code>3000</code> so that we can access the publisher web pages using our browser on the host. The base <code>docker-compose.yml</code> file does not bind port <code>3000</code>, so we will continue to bind ports using the override file.</p>
			<p>By default, if you specify no configuration files on the command line, <code>docker-compose</code> looks for <code>docker-compose.yml</code> and uses it, and then looks for <code>docker-compose.override.yml</code> and uses that.</p>
			<p>If you need to specify a third configuration file, you must use the <code>-f</code> command-line switch for each configuration file.</p>
			<p>Our <code>docker-compose.override.yml</code> file handles our production case:</p>
			<pre>version: '3'
services:
  redis:
    networks:
      - chapter4
  mongodb:
    networks:
      - chapter4
  mosca:
    networks:
      - chapter4
  publisher:
    ports:
      - 3000:3000
    networks:
      - chapter4
  subscriber:
    networks:
      - chapter4
networks:
  chapter4:</pre>
			<p>This file adds<a id="_idIndexMarker213"/> the <code>chapter4</code> network, assigns<a id="_idIndexMarker214"/> it to each of the containers, and binds port <code>3000</code> in the publisher container to port <code>3000</code> on the host.</p>
			<p>All we need to do to use <code>docker-compose.yml</code> and <code>docker-compose.override.yml</code> is run a simple <code>docker-compose</code> command:</p>
			<pre>% docker-compose up</pre>
			<p>After a few seconds, our five containers are up and running and we can access the application with our browser on the host. We can see it is all working. We can also do the following:</p>
			<ul>
				<li>Use the <code>-d</code> switch to run the containers in detached/daemon mode.</li>
				<li>Use <code>docker-compose</code> to stop and start any one or more containers.</li>
				<li>Use <code>docker-compose</code> to build any one or more containers.</li>
				<li>Use <code>docker-compose logs</code> to show the logs of any of our containers running in daemon mode.</li>
			</ul>
			<p>What we now have is a pair of configuration files that work for production mode. We now need a way<a id="_idIndexMarker215"/> to work in development<a id="_idIndexMarker216"/> mode by binding our source code to the container's home directory.</p>
			<h1 id="_idParaDest-68"><a id="_idTextAnchor070"/>Binding a host filesystem within containers</h1>
			<p>Previously, we<a id="_idIndexMarker217"/> used a third <code>docker-compose</code> configuration file to specify bindings so that our source code directory would be overlaid within the container (in place of the app's home directory). We will do the same for the latest incarnation of our Docker Compose setup.</p>
			<p>We first create a <code>docker-compose-dev.yml</code> file:</p>
			<pre>version: '3'
services:
  publisher:
    volumes:
      - ./publisher:/home/app
  subscriber:
    volumes:
      - ./subscriber:/home/app</pre>
			<p>This override file simply maps the publisher and subscriber source code directory over <code>/home/app</code> in the related container. Now, we can freely edit sources on the host and, thanks to nodemon, our changes will take effect almost immediately within the running containers. There is no need to stop, rebuild, or restart any containers.</p>
			<p>Unfortunately, <code>docker-compose</code> has no facility to remove options using inheritance; we can only modify existing ones or add new ones. If we could remove options, we would bind the source in our <code>docker-compose.override.yml</code> file and remove them in a <code>docker-compose-production.yml</code> file. This would allow us to use the short <code>docker-compose up</code> form for development and to use a command line with three <code>-f</code> switches for production. This would be handy because we would use development most of the time and rarely use production.</p>
			<p>As it is, we<a id="_idIndexMarker218"/> must specify the three <code>-f</code> switches:</p>
			<pre>% docker-compose -f docker-compose.yml -f docker-compose.override.yml -f docker-compose-dev.yml up</pre>
			<p>There are other uses for volumes, which we will explore.</p>
			<h2 id="_idParaDest-69"><a id="_idTextAnchor071"/>Optimizing our container size</h2>
			<p>We can examine<a id="_idIndexMarker219"/> our container images using the <code>docker images</code> command:</p>
			<pre>% docker images | grep pub
chapter4_publisher                latest              15f3a84d348d        24 minutes ago      987MB</pre>
			<p>As you can see, our publisher image is <code>987</code> megabytes! All that for an almost-250-line JavaScript program. We can try to shrink this size by moving our <code>node_modules</code> directory out of the container and into a named volume. This will also speed up the building of our container since <code>node_modules</code> will be persisted in this named volume from build to build, and using the <code>yarn</code> command to install the modules will only install anything that is new.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">We renamed the Dockerfile to <code>Dockerfile.chapter3</code> in the <code>publisher/</code> directory.  The new Dockerfile has been modified to build a very small image.</p>
			<p>A smaller image can be created by optimizing our Dockerfile. What we're going to do is build a base image and our result image. The base image will have <code>node_modules</code> installed.  The base image is only rebuilt when something changes that requires one of its layers to be rebuilt.  </p>
			<p>Let's look at an optimized Dockerfile for the publisher:</p>
			<pre>FROM node:12-alpine</pre>
			<p>We inherit from the alpine OS node v12 image. This image is much lighter than the Debian flavor default node container:</p>
			<pre>ENV TZ=America/Los_Angeles
WORKDIR /home/app
# add a user - this user will own the files in /home/app
RUN adduser -S app
ENV HOME=/home/app
COPY . /home/app</pre>
			<p>The resulting<a id="_idIndexMarker220"/> image is built without installing or updating <code>node_modules</code>. We will install the modules in another step. This saves us from having to use <code>yarn</code> install every time we build our container:</p>
			<pre>CMD  ["yarn", "start"]</pre>
			<p>We use <code>yarn start</code> to launch our publisher app.</p>
			<p>After we run <code>docker-compose build publisher</code>, we can see we have greatly reduced the size of our container!</p>
			<p>Before our optimizations, the container was <code>987</code> megabytes. After the optimizations, <code>89.5</code> megabytes, which is almost a 900-megabyte reduction:</p>
			<pre># docker images | grep pub
chapter4_publisher                   latest              080efb97e0d3        About a minute ago   89.5MB</pre>
			<p>We still need to install our <code>node_modules/</code> modules, which will be done within a named volume and defined in the <code>docker-compose-overrides.yml</code> file. This is done once, and then again only if you add packages to the <code>packages.json</code> file in the <code>publisher/</code> directory:</p>
			<pre># docker-compose run publisher yarn install</pre>
			<p>This command installs the <code>node_modules/</code> packages using <code>yarn install</code> within the publisher container. The named volume is mounted correctly because it is specified within the <code>docker-compose</code> configuration (<code>.yml</code>) files.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">We did not optimize the subscriber build.</p>
			<p>We can verify that the volume was created and does contain the installed <code>node_modules</code> modules by examining the <code>_data</code> directory of our volume, which on Linux <a id="_idIndexMarker221"/>should be in <code>/var/lib/docker/volumes</code>:</p>
			<pre># cd /var/lib/docker/volumes/
# ls -1 chapter4_node_modules_publisher/_data/
abbrev
accepts
ajv
ansi-align
ansi-regex
ansi-styles
anymatch</pre>
			<p>The location of the volumes is significantly different for macOS.  You will need to use the following command to get a shell in the Linux virtual machine that is running Docker:</p>
			<pre># screen ~/Library/Containers/com.docker.docker/Data/vms/0/tty</pre>
			<p>You might have to hit <code>^C</code> a few times to get a shell prompt. This prompt is a shell running in the virtual machine. Within the virtual machine, the volume for the <code>node_modules/</code> directory in the container is at <code>/var/lib/docker/volumes</code>, as with Docker on Linux.</p>
			<p>We can see the speedup of our build. The initial build of the publisher, after completely removing all of the images from the system, takes around 16 seconds:</p>
			<pre># time docker-compose build publisher
Successfully built e50ec5f4d53b
Successfully tagged chapter4_publisher:latest
docker-compose build publisher  0.36s user 0.09s system 2% cpu 16.187 total</pre>
			<p>A subsequent build without <code>node_modules</code> installed takes around a half a second: </p>
			<pre># time docker-compose build publisher
Successfully tagged chapter4_publisher:latest
docker-compose build publisher  0.34s user 0.08s system 74% cpu 0.568 total</pre>
			<p>After <a id="_idIndexMarker222"/>editing index.js and doing a rebuild, it takes less than 1 second:</p>
			<pre># time docker-compose build publisher
Successfully tagged chapter4_publisher:latest
docker-compose build publisher  0.34s user 0.08s system 49% cpu 0.842 total</pre>
			<p>As you can see, we were able to reduce the size and build time of our containers!</p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor072"/>Using the build.sh script</h2>
			<p>There<a id="_idIndexMarker223"/> is a build.sh script provided in the <code>chapter4/</code> directory of the GitHub repository. It just contains a few lines of actual shell commands:</p>
			<pre>#!/bin/sh
# build.sh
# build publisher and subscriber and install node_modules in each
docker-compose build --force-rm --no-cache
docker-compose run publisher yarn install
docker-compose run subscriber yarn install</pre>
			<p>The build.sh script builds all five containers and runs <code>yarn install</code> in both the publisher and subscriber containers to install the <code>node_modules</code> modules in their respective named volumes. The command-line switches to the <code>docker-compose build</code> command are as follows:</p>
			<ul>
				<li><code>--force-rm</code>: Forces Docker to remove all the intermediate container images as it builds</li>
				<li><code>--no-cache</code>: Forces Docker to use no cached/downloaded/built versions of anything</li>
			</ul>
			<p>You can <a id="_idIndexMarker224"/>drop these two switches to greatly improve the build speed. They are provided here to demonstrate a way of forcibly rebuilding everything from scratch.</p>
			<p>That's a decent overview of Docker Compose. It is one of the first, if not the first, composition tools for describing, building, and running Docker applications. But there are also other alternatives out there.</p>
			<h1 id="_idParaDest-71"><a id="_idTextAnchor073"/>Other composition tools</h1>
			<p>We have already <a id="_idIndexMarker225"/>seen how we can compose and build a multiple service application using <code>docker-compose</code> and <code>.sh</code> scripts. But there are some other options that you may want to consider.</p>
			<h2 id="_idParaDest-72"><a id="_idTextAnchor074"/>Docker Swarm</h2>
			<p>Docker Swarm is a cluster <a id="_idIndexMarker226"/>management system. It allows you to deploy containers that are defined with <code>docker-compose</code> to a cluster of nodes or servers. There are some limitations to what you can do with <code>docker-compose.yml</code> if you want to use Docker Swarm. For example, you cannot use volumes with Docker Swarm, and binding container ports to the host should be carefully planned.</p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor075"/>Kubernetes</h2>
			<p>Kubernetes is a <a id="_idIndexMarker227"/>feature-rich alternative to <code>docker-compose</code>. It allows containers to be deployed to a cluster of Docker container servers and uses a configuration file format similar to <code>docker-compose.yml</code>.</p>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor076"/>Packer</h2>
			<p>Packer is a tool that <a id="_idIndexMarker228"/>generates several output formats, including Docker containers. You define your containers using JSON files and the tool reads from them. Packer uses builders to generate output files. The output can be (but is not limited to) the following:</p>
			<ul>
				<li>Azure machine images</li>
				<li>DigitalOcean machine images</li>
				<li>Docker container images</li>
				<li>Google cloud images</li>
				<li>Parallels (for macOS) images</li>
				<li>VirtualBox images</li>
				<li>VMware images</li>
			</ul>
			<p>The composition tool that you choose should make your job easier. Be sure to choose one that truly suits your needs. Docker Compose is the official Docker composition tool. The others may be more modern and solve additional problems that Docker Compose does not.</p>
			<h1 id="_idParaDest-75"><a id="_idTextAnchor077"/>Summary</h1>
			<p>In this chapter, we introduced Docker Compose as a superior management tool for managing and running a complex system of containers. We described several useful <code>docker-compose</code> configuration file options that allow us to specify ports to expose, local networking, and local volumes. We exploited the <code>docker-compose</code> tool's inheritance capabilities as well.</p>
			<p>A critical part of using Docker is the development cycle. We typically edit, build, run, and test each cycle—then repeat. The size of images, as well as the time spent building, publishing, and downloading them, can be strategically reduced.</p>
			<p>We also explored some alternatives to using <code>.sh</code> scripts and <code>docker-compose</code>. These are a natural next step in your Docker education as they provide facilities for deploying your orchestrations to swarms or clusters of servers in production or for testing.</p>
			<p>The next few chapters go into detail about how to deploy your applications and how to implement continuous integration and automated testing. After that, we will cover security considerations for containerized applications.</p>
			<h1 id="_idParaDest-76"><a id="_idTextAnchor078"/>Further reading</h1>
			<p>You can refer to the following URLs for more information on the topics covered in this chapter:</p>
			<ul>
				<li>The official Docker documentation: <a href="https://docs.docker.com">https://docs.docker.com</a></li>
				<li>The official Docker Compose documentation: <a href="https://docs.docker.com/compose/">https://docs.docker.com/compose/</a></li>
				<li>The Dockerfile reference:<a href="https://docs.docker.com/engine/reference/builder/">https://docs.docker.com/engine/reference/builder/</a></li>
				<li>The Docker Hub site:<a href="https://hub.docker.com/">https://hub.docker.com/</a></li>
				<li>The documentation for Docker Hub:<a href="https://docs.docker.com/docker-hub/">https://docs.docker.com/docker-hub/</a></li>
				<li>The documentation for the <code>Node.js</code> containers on Docker Hub:<a href="https://hub.docker.com/_/node">https://hub.docker.com/_/node</a></li>
				<li>The documentation for the Redis containers on Docker Hub:<a href="https://hub.docker.com/_/redis">https://hub.docker.com/_/redis</a></li>
				<li>The documentation for the MongoDB containers on Docker Hub:<a href="https://hub.docker.com/_/mongo">https://hub.docker.com/_/mongo</a></li>
				<li>The documentation for the Mosca containers on Docker Hub:<a href="https://hub.docker.com/r/matteocollina/mosca">https://hub.docker.com/r/matteocollina/mosca</a></li>
			</ul>
		</div>
	</body></html>