<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Scalable Data Implementations</h1>
                </header>
            
            <article>
                
<p><span>In the previous chapter, we covered the storage solutions objective</span><span>. We covered some of the different storage features that Azure offers, as well as when and how to use them. We also covered designing for NoSQL storage, and when to use the available solutions. </span></p>
<p class="mce-root">This is the second chapter of the <span>Domain Design Data Implementation objective. It covers designing for Azure data services, including a high-level overview of the services and solutions that Azure provides. It also covers relational databases in Azure. This consists of the Azure SQL Database and how to design for performance, availability, and two open source relational databases, such as MySQL and PostgreSQL on Azure.</span></p>
<p><span>By the end of this chapter, you should know which data service or relational database to use for your solutions and when.</span></p>
<p>The following topics will be covered:</p>
<ul>
<li><span>Azure Data Catalog</span></li>
<li><span>Azure Data Factory</span></li>
<li><span>Azure SQL Data Warehouse</span></li>
<li><span>Azure Data Lake </span></li>
<li>Azure Analysis Services</li>
<li><span>Azure SQL Database</span></li>
<li><span>Azure Database for MySQL</span></li>
<li><span>Azure Database for PostgreSQL</span></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p style="margin: 0in;font-family: Merriweather;font-size: 12.0pt;color: black"><span>The source code for this chapter can be downloaded</span><span> from </span><a href="https://github.com/SjoukjeZaal/AzureArchitectureBook/tree/master/Chapter%208">https://github.com/SjoukjeZaal/AzureArchitectureBook/tree/master/Chapter%208</a>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Data Catalog</h1>
                </header>
            
            <article>
                
<p>Azure Data Catalog provides a central repository where you can find all of the data sources that are used inside your organization. <span>Most employees inside an organization are not aware of where enterprise data is located or who is responsible for that data. With Azure Data Catalog, any user (such as a developer or analyst, for instance) can discover and consume the data source from a central place.</span></p>
<p>Azure Data Catalog provides <span>one data catalog per Azure AD Tenant, even if you have multiple subscriptions associated with the tenant. A copy of the data source metadata and the location of the data source is added to the catalog. The data itself remains at the original location. Azure Data Catalog offers search functionality to easily discover the data, as well. </span></p>
<p><span>You can import a data source in the Azure Data Catalog using the tooling that Microsoft provides. Azure Data Catalog supports a variety of data sources that can be published using the import tool, such as Azure Blob Storage, Azure Data Lake, SQL Server, and third-party data sources such as Oracle, MySQL, and more. </span><span>When a data source is added to the catalog, the metadata can be enriched to provide extra information to the users. </span><span><br/></span></p>
<p>There are two different versions of the Azure Data Catalog—<strong>Free </strong>and <strong>Standard:</strong></p>
<ul>
<li><strong>Free</strong>: Offers unlimited users and 5,000 registered data assets; the data assets are discoverable by all users</li>
<li><strong>Standard</strong>: Offers <span>unlimited users, 100,000 registered data assets, and asset-level authorization, restricting visibility<br/></span></li>
</ul>
<p>The Azure Data Catalog can also be used programmatically by calling the <span>Data Catalog REST API. It provides calls for registering and deleting data, and for working with annotations.</span></p>
<div class="packt_infobox"><span>For a complete overview of the data sources that Azure Data Catalog supports, you can refer to the article at </span><a href="https://docs.microsoft.com/en-us/azure/data-catalog/data-catalog-dsr">https://docs.microsoft.com/en-us/azure/data-catalog/data-catalog-dsr</a><span>. For more information about the Data Catalog REST API, you can refer to the article at </span><a href="https://docs.microsoft.com/en-us/rest/api/datacatalog/#search-syntax-reference">https://docs.microsoft.com/en-us/rest/api/datacatalog/#search-syntax-reference</a><span>.</span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Data Factory</h1>
                </header>
            
            <article>
                
<p>Azure Data Factory is a cloud service for big data processing and analytics. It uses raw data from various data sources to create valuable insights for business decision makers, analysts, and data scientists. The following features are used to process and compose the data into data-driven workflows:</p>
<ul>
<li><strong>Data pipelines</strong>: Represent a group of activities that perform a unit of work.</li>
<li><strong>Activities</strong>: One activity represents a step in a pipeline. For instance, you can create a Copy Activity to copy data from an Azure Blob Storage account to an HDInsight cluster. Azure Data Factory supports three types of activities: data movement activities, data transformation activities, and data control activities.</li>
<li><strong>Datasets</strong>: These represent the data from the data stores which are used for input and output.</li>
<li><strong>Linked services</strong>: Azure Data Factory uses linked services to connect to the data sources. You can relate this to connection strings. There are two types of linked services—one for connecting to a data store and one for connecting to compute resources.</li>
<li><strong>Triggers</strong>: A trigger starts the execution of the data pipeline. Data Factory supports schedule triggers and tumbling window triggers, which run on a periodic interval. There is no trigger to start the pipeline from custom code. If you want to start it from inside an application, the best method is to change the start time of the schedule trigger to the time you want to start the operation, from inside your code.</li>
<li><strong>Pipeline run</strong>: This is an instance of data pipeline execution. </li>
<li><strong>Parameters</strong>: You can pass arguments to parameters inside the pipeline. They are key-value pairs.</li>
<li><strong>Control flow</strong>: This represents an orchestration of activities. You can process activities in sequence, create for-each iterators, and more.</li>
</ul>
<p>You can create a Data Factory service and data pipelines from the Azure Portal using the Azure Data Lake UI (only from Edge or Chrome), .NET, Python, PowerShell, ARM, or by calling the REST API.</p>
<div class="packt_infobox">At the time of writing this book, Azure offers two versions of Azure Data Factory: V1 and V2. V2 is currently in preview. For a detailed overview of the differences between the versions, you can refer to <a href="https://docs.microsoft.com/en-us/azure/data-factory/compare-versions">https://docs.microsoft.com/en-us/azure/data-factory/compare-versions</a>. <br/>
<span>Azure Data Factories can only be created in the East US, East US2, and West Europe regions. However, they can access data stores and compute services in other Azure regions to move data between data stores or process data using compute services.</span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure SQL Data Warehouse</h1>
                </header>
            
            <article>
                
<p>Azure SQL Data Warehouse offers an Enterprise Data Warehouse in the cloud. It uses <span><strong>Massively Parallel Processing</strong> (<strong>MPP</strong>) combined with Azure Storage, to provide high performance and scalability. To create valuable insights into the data stored inside the Data Warehouse, Azure uses Hadoop/Spark and machine learning.</span></p>
<p><span>Data is stored in relational tables with columnar storage. When using columnar storage, the data is written and read in columns, instead of the rows used in traditional row-oriented databases. So, when you query the data, columnar storage skips all of the irrelevant data by immediately jumping to the appropriate column. This will make your queries run a lot faster. For instance, when you want to look up the average age of all of your customers, columnar storage will jump to the age column immediately, instead of looking at each row for the age column. This also provides better compression of the data, which results in lower storage costs.</span></p>
<p>By using MPP, <span>Azure SQL Data Warehouse decouples the storage layer from the compute layer, which makes it easy to scale out. MPP uses multiple compute nodes to process the data. A client application or storage solution uses PolyBase T-SQL commands to add data to the control node. The control node runs the MPP engine, which uses the <strong>Data Movement Service</strong> (<strong>DMS</strong>) for moving the data between the nodes. It is also responsible for optimizing the queries for parallel processing. When optimized, the MPP engine will pass the queries on to the available compute nodes to execute them in parallel. The compute nodes will then be responsible of storing the data inside Azure Storage:<br/></span></p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-717 image-border" src="Images/bd92ab31-b189-41a2-877b-2b11b43692f2.png" style="width:34.00em;height:30.75em;" width="1094" height="987"/><span><br/></span></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span><span>MPP architecture</span></span></div>
<p>Decoupling the storage layer from the compute layer is also more cost-effective. You can independently scale out the compute nodes of the storage layer, or pause the compute capacity so that you only have to pay for the storage.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Data Lake</h1>
                </header>
            
            <article>
                
<p>Azure Data Lake is a big data storage and analytics service that can store an unlimited amount of structured, semi-structured, or unstructured data. It is based on the Hadoop Yes Another Resource Negotiator (<span>YARN) </span>cluster management platform, which can scale dynamically across Azure SQL Server instances or instances of Azure SQL Data Warehouse.</p>
<div class="packt_infobox">For more information about Hadoop YARN, you can refer to the Hadoop website at <a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html">https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html</a>. </div>
<p><span>Hadoop YARN</span> offers three types of solutions:</p>
<ul>
<li>Azure Data Lake Store</li>
<li>Azure Data Lake Analytics</li>
<li>Azure HDInsight</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Data Lake Store</h1>
                </header>
            
            <article>
                
<p><span>Azure Data Lake Store is a storage repository for big data workloads, where you can store raw data. A data lake is a container where you can store all kinds of data, such as structured, semi-structured, and unstructured data. Data is still unprocessed when it is added to the data lake. This is different from a data warehouse, where you store structured and processed data. </span></p>
<p><span>Azure Data Lake Store is built for Hadoop, which is available from the HDInsight cluster in Azure. It uses the Hadoop filesystem to store the data. Applications call the WebHDFS-compatible REST APIs to add data to the filesystem. It offers unlimited storage, and data can be analyzed using Hadoop analytic frameworks such as MapReduce or Hive. Azure HDInsight clusters can also be configured by using an out-of-the-box connection to directly access data stored in the Azure Data Lake Store. You can use Azure Data Lake Store data inside machine learning models, and you can create batch queries or store data inside a data warehouse:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/f9487796-83c8-4eb2-9c06-af07f6e2f0ab.png" style="width:35.58em;height:21.25em;" width="1400" height="834"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Azure Data Lake Store</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Data Lake Analytics</h1>
                </header>
            
            <article>
                
<p>Azure Data Lake Analytics is a feature of Azure Data Lake that can be used to analyze your data. Your data can come from various data sources, and after the data is analyzed, it can be written to various data sources as well. <span>It works with Azure Data Lake Store, Azure Blob Storage, and Azure SQL Database.<br/></span></p>
<p><span>Azure Data Lake Analytics uses a serverless approach; you don't have to manage a cluster, and you only pay for the actual analysis of your data. It can scale dynamically, and it is integrated with Azure AD for authentication.  </span></p>
<p><span>It comes with two price packages:</span></p>
<ul>
<li><strong>Pay-as-you-go</strong>: Here, you pay only for your use, per minute. There is no further commitment</li>
<li><strong>Monthly commitment</strong>: This price package comes with a couple of different possibilities, where you pay upfront for a certain amount of hours—100, 500, or 1,000 hours, and so on</li>
</ul>
<div class="packt_infobox">For more information on the different price packages, you can refer to <a href="https://azure.microsoft.com/en-us/pricing/details/data-lake-analytics/">https://azure.microsoft.com/en-us/pricing/details/data-lake-analytics/</a>.</div>
<p>Azure Data Analytics uses U-SQL to analyze the data. U-SQL is the <span>big data query language, and it </span>can be used in combination with C#, R, Python, and Cognitive Services. You can create scripts from the Azure Portal and create jobs to execute them on the data. You can use Visual Studio, Visual Studio Code, PowerShell, and CLI for submitting U-SQL scripts, as well.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Analyzing your data using Data Lake Analytics</h1>
                </header>
            
            <article>
                
<p>In this demo, we are going to create a Data Lake Analytics account and analyze some data, storing it in Azure Data Lake Store afterwards. An Azure Data Lake Store account is mandatory for Data Lake Analytics, so we will create that as well:</p>
<ol>
<li>Navigate to the Azure Portal by opening <a href="https://portal.azure.com/">https://portal.azure.com/</a>.</li>
</ol>
<ol start="2">
<li>Click on <strong><span class="packt_screen">New</span></strong><span> </span>and type <span class="packt_screen">Data Lake Analytics</span> in the search bar. </li>
<li class="mce-root"><span>A new blade opens up. At the time of writing this book, Data Lake Analytics can only be created in the regions Central US, East US 2, and North Europe. Add the following settings:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/311d90c1-d52e-4f56-91b6-af33e18c9a65.jpg" style="width:17.08em;height:45.33em;" width="626" height="1660"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Create an Azure Data Lake Analytics account</div>
<ol start="4">
<li>Click <strong><span class="packt_screen">Data Lake Store</span></strong> to create the account for storing your data:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/06013bc0-ee9b-455d-97a6-0be62e2d15a3.png" style="width:36.25em;height:48.33em;" width="827" height="1102"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Create an Azure Data Lake Store</div>
<ol start="5">
<li>Click <span class="packt_screen">OK</span> twice to create both the Data Lake Store and the Data Lake Analytics account.</li>
<li class="mce-root"><span>You can now navigate to the <span>Data Lake </span>Analytics account. </span><span>Next, upload the sample file </span><kbd>SearchLogs.tsv</kbd> <span>to Azure Data Lake Store. Click on </span><strong><span class="packt_screen">Data explorer</span></strong> <span>in the left-hand menu:</span></li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="Images/d7aefe58-e3a7-4ccb-969e-c2bc554e560f.jpg" style="width:12.75em;height:45.17em;" width="463" height="1640"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Data Explorer</div>
<ol start="7">
<li>Create a new folder and name it <kbd>input</kbd>. Upload <kbd>SearchLogs.tsv</kbd><strong> </strong>to the folder:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/4359d172-603e-4d33-a45b-c5cd2580a554.png" style="width:42.83em;height:13.58em;" width="2282" height="725"/></div>
<div style="color: black" class="CDPAlignCenter CDPAlign packt_figref">Create a new input folder</div>
<ol start="8">
<li>Next, click on <span class="packt_screen">New job</span>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/ea2abe2f-1fbe-4317-90b5-699dfb6bfcc6.png" style="width:42.50em;height:30.75em;" width="1457" height="1053"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span><span>Azure Data Lake overview</span></span></div>
<ol start="9">
<li>Name the job, and add the following code to it. This extracts the raw data from the <kbd>SearchLog</kbd> file and creates a new file with headers, and then stores it in a folder called <kbd>output</kbd> in the Azure Data Lake Store:</li>
</ol>
<pre style="padding-left: 60px">@searchlog =<br/>    EXTRACT UserId int,<br/>            Start DateTime,<br/>            Region string,<br/>            Query string,<br/>            Duration int?,<br/>            Urls string,<br/>            ClickedUrls string<br/>    FROM "/input/SearchLog.tsv"<br/>    USING Extractors.Tsv();<br/><br/>OUTPUT @searchlog <br/>    TO "/output/SearchLog-first-u-sql.csv"<br/>    USING Outputters.Csv();</pre>
<ol start="10">
<li>Run the job. The following output will be displayed:</li>
</ol>
<div style="color: black" class="CDPAlignCenter CDPAlign packt_figref"><img src="Images/9ac7e232-d376-429c-a67c-9851bef7e823.jpg" style="width:40.25em;height:29.33em;" width="2263" height="1644"/></div>
<div style="color: black" class="CDPAlignCenter CDPAlign packt_figref">Azure Data Lake output</div>
<ol start="11">
<li>You can now see the result in the Data Explorer. There is a new folder called <kbd>output</kbd> added, where the output file is stored.</li>
</ol>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure HDInsight</h1>
                </header>
            
            <article>
                
<p>Azure HDInsight is a service which deploys Hadoop components in the form of clusters in the cloud. Apache Hadoop is a very popular open source framework for processing and analyzing big data. The Hadoop components on Azure make it very easy to process data because Azure handles the creation of the clusters.</p>
<p>HDInsight offers the following cluster types:</p>
<ul>
<li><strong>Apache Hadoop</strong>: Hadoop can process data in parallel using MapReduce, a programming language that can process data efficiently.</li>
<li><strong>Apache Spark</strong>: Spark can process data in parallel as well by using in-memory processing for better performance. You can use it with SQL, streaming data, and machine learning solutions.</li>
<li><strong>Apache HBase</strong>: This offers a NoSQL database on Hadoop which can be used as input or output for MapReduce jobs. </li>
<li><strong>Microsoft R Server</strong>: Offers a server for hosting and managing R scripts. R is mostly used by data scientists, and provides scalable methods for analyzing data.</li>
<li><strong>Apache Storm</strong>: Offers processing for large streams of data in a very fast way. You can use this to analyze real-time sensor data, for instance.</li>
<li><strong>Apache Interactive Query (Preview)</strong>: Hive queries can now run faster using the in-memory caching mechanism.</li>
<li><strong>Apache Kafka</strong>: Offers streaming for data pipelines, message queuing, and applications.</li>
</ul>
<p><span>Azure HDInsight </span>uses Azure Blob Storage and Azure Data Lake Store as storage solutions. You can build applications on Azure HDInsight using Java, Python, and .NET by using the HDInsight .NET SDK and more.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Analysis Services</h1>
                </header>
            
            <article>
                
<p>Azure Analysis Services use the same architecture that SQL Server Analysis uses, and provides enterprise-grade data modeling in the cloud.</p>
<p>You can easily create a hybrid environment by connecting Azure Analysis Services with your on-premises SQL Analysis Servers. Data from various sources, such as SQL Server Analysis, SQL Server, Azure SQL Server, and more, can then easily be combined. Inside Azure Analysis Services, the models can be processed much faster when compared to on-premises environments. This way, client applications such as Power BI, Excel, Reporting Services, and other third-party applications, can query the data and deliver dashboards much faster:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/624e300e-f892-418b-b368-431c3d50b617.png" style="width:44.33em;height:36.58em;" width="1264" height="1043"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Azure Analysis Services</span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure SQL Database </h1>
                </header>
            
            <article>
                
<p>Azure SQL Database offers a relational database in the cloud. It uses the SQL Server on-premises code base, but by using Azure SQL Database over SQL Server on-premises, you don't have to manage the underlying platform, the operating system, or buy any licenses. Besides that, Microsoft releases updates for Azure SQL Database first, and then for SQL Server.</p>
<p>Azure SQL Database offers scalability without causing any downtime for your databases. It offers column base indexes, which make your queries perform much faster. There is built-in monitoring for your databases and built-in intelligence for increasing the performance of your database automatically, and it provides high availability by providing automatic backups and Point-in-time restores. You can also use active geo-replication, for global applications.</p>
<p>Azure SQL Database offers the following tiers for your databases:</p>
<ul>
<li><strong>Elastic Database Pools</strong>: Elastic pools is a feature that helps in managing and scaling databases that have unpredictable usage demands. All databases in an Elastic Pool are deployed on the same database server and share the same resources. By managing the pool of databases and not the individual databases, they can share performance and scaling. The performance of this tier is expressed in <strong>elastic Database Transaction Units</strong> (<strong>eDTUs</strong>).</li>
<li><strong>Individual databases</strong>: This is a good fit if you have a database with predictable performance. Scaling is done for each database separately. <span>The performance of this tier is expressed in <strong>Database Transaction Units</strong> (<strong>DTUs</strong>).<br/></span></li>
</ul>
<div class="packt_infobox"><span>For more information about <span class="packt_screen">Database Transaction Units (DTUs) and elastic Database Transaction Units (eDTUs)</span>, you can refer to the article at </span><a href="https://docs.microsoft.com/en-us/azure/sql-database/sql-database-what-is-a-dtu">https://docs.microsoft.com/en-us/azure/sql-database/sql-database-what-is-a-dtu</a><span>.<br/></span>There are a number of different service plans and pricing tiers available for Azure SQL Database. As they change often, you can refer to the pricing page for an overview at <a href="https://azure.microsoft.com/en-us/pricing/details/sql-database/">https://azure.microsoft.com/en-us/pricing/details/sql-database/</a>. However, it is strongly advised to look at the different plans for the 70-535 exam.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">SQL Server Stretch Database</h1>
                </header>
            
            <article>
                
<p>SQL Service Stretch Database was introduced in SQL Server 2016, and is a feature that can move or archive your cold data from your on-premises SQL Server to the Azure SQL Database. This results in better performance for your on-premises server, and the stretched data resides in the cloud, where it is easily accessible for other applications.</p>
<p>Inside SQL Server, you can mark a table as a stretch candidate, and SQL Server will move the data to Azure SQL Database <span>transparently</span>. Large transactional tables with lots of historical data can benefit from enabling for stretch. These are mostly massive tables with hundreds or millions of rows in them, which don't have to be queried frequently. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">High availability</h1>
                </header>
            
            <article>
                
<p>Even when your databases are hosted in Azure, there is still a chance that failures and outages will occur. In the case of an outage (such as a total regional failure, which can be caused by a <span>natural disaster, an act of terrorism, war, a government action, or a network or device failure external to the data centers of Microsoft), your data still needs to be accessible. </span></p>
<p><span>To create highly available SQL Server databases on Azure, you can use failover groups and active geo-replication, which are covered in more detail in the following sections.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Backup and recovery</h1>
                </header>
            
            <article>
                
<p>Azure creates geo-redundant backups for each service tier automatically. These backups are then copied to <span><strong>read-access geo-redundant storage</strong> (<strong>RA-GRS</strong>). </span>Azure SQL Database creates a full database backup every week, and a differential backup every hour. A differential backup creates a backup from the data that has changed since the last full backup. Azure SQL Database also creates a transaction log backup every 5 to 10 minutes. </p>
<p>The retention period of these backups varies for each service tier:</p>
<ul>
<li><strong>Basic</strong>: Has a retention of 7 days</li>
<li><strong>Standard</strong>: <span>Has a retention of </span>35 days</li>
<li><strong>Premium</strong>: <span>Has a retention of </span>35 days</li>
</ul>
<p>These retention periods can be extended by creating a <strong>l</strong><span><strong>ong-term backup retention policy</strong>.</span> <span>By using the LTR policy, the retention period can be extended up to 10 years. The backups are copied to the Azure Recovery Services Vault, and data is encrypted at rest. The Azure Recovery Services Vault manages all of the backups and automatically removes backups that have expired. The LTR policy can be created from the Azure Portal or from PowerShell.</span></p>
<p>You can use the backups for the following restoring scenarios:</p>
<ul>
<li><strong>Point-in-time restore</strong>: A database can be restored to any Point-in-time within the retention policy on the same logical server. A new database, which is fully accessible, is created. You can use Point-in-time restore for every service tier, and for single databases and databases deployed into elastic pools. A Point-in-time restore can be restored from the Azure Portal, PowerShell, or the REST API.</li>
<li><strong>Deleted database restore</strong>: A deleted database can be restored up to the time of deletion on the same logical server. You can restore a deleted database to an earlier Point-in-time as well. A deleted database restore can be executed from the Azure Portal, PowerShell, and the REST API.</li>
<li><strong>Geo-restore</strong>: Using geo-restore, you can restore a database backup to any server in any region. You can only use geo-restore for geo-redundant backups. Backups that are created manually are not supported. For this type of restore, you can use the Azure Portal, PowerShell, and the REST API.</li>
<li><strong>Azure Recovery Services Vault restore</strong>: You can use this type of restore for restoring a database to a certain Point-in-time in the available retention policy. This way, you can restore an old version of a database for an application, for instance. <span>For this type of restore, you can use the Azure Portal, PowerShell, and the REST API, as well.</span></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Active geo-replication </h1>
                </header>
            
            <article>
                
<p><span>Geo-replication is a business continuity feature that allows you to replicate the primary database, up to four read-only secondary databases, in the same or different Azure regions. You can use the secondary databases to query data, or for failover scenarios when there is a data center outage. Active geo-replication has to be set up by the user or the application manually. </span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Failover groups</h1>
                </header>
            
            <article>
                
<p>Failover groups is a feature that automatically manages the failovers. It automatically manages the geo-replication relationship between the databases, the failover at scale, and the connectivity. To use failover groups, the primary and the secondary databases need to be created inside of the same Azure subscription. </p>
<p>Automatic failover supports replication of all of the databases that are created in the same failover group to only one secondary database server, in a different region. This is different when using active geo-replication, which can replicate up to four secondary databases.</p>
<p>You can set and manage geo-replication from the Azure Portal, PowerShell, Transact SQL, and the REST API.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Configuring active geo-replication and failover groups</h1>
                </header>
            
            <article>
                
<p><span>In this example, we are going to set up active geo-replication and failover groups for a single database. Note that this can be done for an Elastic Pool, as well:</span></p>
<ol>
<li>Navigate to the Azure Portal by opening <a href="https://portal.azure.com/">https://portal.azure.com/</a>.</li>
<li>First, create the SQL Database. Click on <span class="packt_screen">New</span><span> </span>and type <kbd>SQL Database</kbd> in the search bar. </li>
<li>On the next screen, add the following settings in the creation blade and <span>click on </span><strong><span class="packt_screen">Create</span></strong><span>, as shown in the following screenshot:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/3b7d0eb6-4e07-49ba-a60d-a9e7a4248706.png" style="width:12.83em;height:29.00em;" width="619" height="1401"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Create SQL Database</div>
<ol start="4">
<li>Click on <span class="packt_screen">Create a new s</span><span class="packt_screen">erver</span>, add the following settings, and click on <span class="packt_screen">Select</span>:</li>
</ol>
<div style="color: black;font-size: 1em" class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-724 image-border" src="Images/0f517fb4-2ceb-42de-96f9-6321feb7bcac.png" style="width:36.83em;height:41.67em;" width="818" height="925"/></div>
<div style="color: black" class="CDPAlignCenter CDPAlign packt_figref">Create SQL Server</div>
<ol start="5">
<li>Click the pricing tier; in this blade, you can select the pricing tier and the DTUs and eDTUs that you want to configure for the database. For now, you can keep the default settings and click <span class="packt_screen">Apply</span>:</li>
</ol>
<div style="color: black;font-size: 1em" class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-725 image-border" src="Images/4b1a4dc6-7968-4c9e-a5b8-b575ee84ad42.png" style="width:61.83em;height:32.83em;" width="1291" height="686"/></div>
<div style="color: black" class="CDPAlignCenter CDPAlign packt_figref">Select pricing tier</div>
<ol start="6">
<li>Click on <span class="packt_screen">Create</span> to create the database.</li>
</ol>
<ol start="7">
<li>Navigate to the database and, in the left-hand menu, click <span class="packt_screen">Geo-Replication</span>. There, you can configure to which regions you want your database to be replicated. You can select every region, but the paired region is recommended. You can also click the top banner to create a failover group for your database:</li>
</ol>
<div class="CDPAlignCenter CDPAlign packt_figref"><span><img src="Images/70c03926-2f5d-4ebd-90bf-aa484293c65b.jpg" style="width:63.92em;height:41.25em;" width="2282" height="1469"/><br/></span></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span><span>Geo-replication settings</span></span></div>
<ol start="8">
<li>Select the region, and a new blade will pop up. In there, you have to create the second database in a new server. The steps for creating the new server are identical to the steps that were taken for the first server. Add the following settings, and click <span class="packt_screen">OK</span>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-727 image-border" src="Images/28334205-be60-4a10-8f37-5574cd0b8d44.png" style="width:19.42em;height:44.08em;" width="612" height="1388"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span><span>Create secondary server</span></span></div>
<ol start="9">
<li>To automatically replicate the database, you need to add it to a failover group. Click the banner and add the following settings. Pick the secondary database created in the previous step as a secondary server and click on <span class="packt_screen">Create</span>:</li>
</ol>
<div style="color: black;font-size: 1em" class="CDPAlignCenter CDPAlign"><img src="Images/dc254639-c004-4baa-9e3d-12a2ac32d55f.png" style="width:19.17em;height:43.75em;" width="612" height="1396"/></div>
<div style="color: black" class="CDPAlignCenter CDPAlign packt_figref">Automatic Failover</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Database for MySQL</h1>
                </header>
            
            <article>
                
<p>Azure Database for MySQL is an implementation of the open source relational database MySQL in the cloud. The Azure offering <span>offers the same functionality and capabilities </span>as the MySQL Community Edition. </p>
<p>The MySQL Database is widely used by PHP developers, and for a lot of PHP applications, like the open source CMS WordPress, for instance. MySQL offers the following features and capabilities:</p>
<ul>
<li><strong>Open source</strong>: MySQL is open source but owned by Oracle. It offers commercial versions as well.</li>
<li><strong>ACID compliancy</strong>: It offers <span>Atomicity, Consistency, Isolation, Durability (ACID) transactions. This ensures that there is no data loss in the case of failure. MySQL offers ACID compliancy when using InnoDB and NDB Cluster Storage engines. InnoDB has been the default MySQL storage engine since version 5.6.</span></li>
<li><strong>Replication</strong>: MySQL offers master-standby replication, which includes single master to one standby and multiple standbys, circular replication (A to B to C, and back to A), and master to master.</li>
<li><strong>Performance</strong>: MySQL can under-perform at a heavy load and when it needs to <span>execute complex queries</span>. It is most suitable for web-based projects that need simple, straightforward data transactions.</li>
<li><strong>Security</strong>: MySQL offers security based on <strong>Access Control Lists</strong> (<strong>ACLs</strong>) for <span>all connections, queries, and other operations. It offers support for SSL-encrypted connections between MySQL clients and servers.</span></li>
<li><strong>NoSQL features</strong>: MySQL only offers JSON data type support, and not support for indexing JSON.</li>
<li><strong>Extensibility</strong>: MySQL has no support for extensibility.</li>
<li><strong>Concurrency</strong>: <span>MySQL only has multiversion concurrency control (MVCC) support in InnoDB.</span></li>
<li><strong>Programming languages</strong>: You can only use the MySQL programming language to communicate with the data in the database.</li>
</ul>
<p>By running your MySQL Database on Azure, on top of all the features and capabilities that MySQL offers, Microsoft offers automatic scaling, high availability, encryption for data at rest, automatic backup and Point-in-time restore for up to 35 days, enterprise security and compliance, and more. </p>
<p>MySQL on Azure offers the following pricing tiers:</p>
<ul>
<li><strong>Basic</strong>: Offers a maximum of 1 TB of storage, <span>four logical CPUs,</span> and locally redundant backups</li>
<li><strong>General purpose</strong>: Offers a maximum of 1 TB of storage, <span>four logical CPUs,</span> scalable I/O throughput, and locally redundant and geographically redundant backups</li>
<li><strong>Memory optimized: </strong><span>Offers a maximum of 1 TB of storage, five logical CPUs, scalable I/O throughput, and locally redundant and geographically redundant backups</span></li>
</ul>
<div class="packt_infobox">For more information about the features and capabilities that the MySQL Community Edition offers, you can refer to <a href="https://www.mysql.com/products/community/">https://www.mysql.com/products/community/</a>.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Database for PostgreSQL</h1>
                </header>
            
            <article>
                
<p><span>Azure Database for PostgreSQL is an implementation of the open source relational database PostgreSQL in the cloud. It is also based on the community version of the open source PostgreSQL database engine. PostgreSQL offers capabilities similar to MySQL, but there are differences as well. </span></p>
<p>It offers the following features and capabilities:</p>
<ul>
<li><strong>Open source</strong>: <span>PostgreSQL </span>is completely open source.</li>
<li><strong>ACID compliancy</strong>: Offers ACID<span> transactions. </span></li>
<li><strong>Replication</strong>: <span>PostgreSQL </span>provides master-standby replication, including <span>single master to one standby and multiple standbys, </span>hot standby/streaming replication, bi-directional replication, logical log streaming replication, and cascading replication.</li>
<li><strong>Performance</strong>: It s<span>upports a variety of performance optimizations, and is most suitable for systems that require the execution of complex queries and where read and write speeds are crucial. PostgreSQL performs well in OLTP/OLAP systems and with business intelligence applications.</span></li>
<li><strong>Security</strong>: <span>PostgreSQL</span><strong><span> </span></strong>offers role-based and inherited role-based security. It offers native SSL support for <span>client/server communications, and it offers </span>row level security<span><span>.</span></span></li>
<li><strong>Concurrency</strong>: <span>PostgreSQL</span><span><span> has full multiversion concurrency control (MVCC) support and is extremely responsive in high volume environments.</span></span></li>
<li><strong>NoSQL features</strong>: <span>PostgreSQL supports JSON and other NoSQL features, such as native XML support, JSON indexing, and key-value pairs with HSTORE. </span></li>
<li><strong>Extensibility</strong>: <span>PostgreSQL<strong> </strong></span>offers support for extensibility, such as adding new functions, types, new index types, and more.</li>
<li><strong>Programming languages</strong>:<span> Offers programming language extensions for JavaScript, .Net, R, C/C++, Java, Perl, Python, Ruby, Tcl, and more.</span></li>
</ul>
<p><span>On top of all of the features that PostgreSQL provides, Azure Database for PostgreSQL offers automatic scaling, high availability, encryption for data at rest, automatic backup and Point-in-time restore, and more.</span></p>
<p><span>PostgreSQL </span>on Azure offers identical pricing tiers as MySQL on Azure:</p>
<ul>
<li><strong>Basic</strong>: Offers a maximum of 1 TB of storage, <span>four logical CPUs,</span><span> </span>and locally redundant backups</li>
<li><strong>General purpose</strong>: Offers a maximum of 1 TB of storage, <span>four logical CPUs,</span> scalable I/O throughput, and locally redundant and geographically redundant backups</li>
<li><strong>Memory optimized</strong>: <span>Offers a maximum of 1 TB of storage, five logical CPUs, scalable I/O throughput, and locally redundant and geographically redundant backups</span></li>
</ul>
<div class="packt_infobox"><span>For more information about the features and capabilities that the PostgreSQL database offers, you can refer to <a href="https://www.postgresql.org/">https://www.postgresql.org/</a>.</span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have completed the designing data implementations objective. We've covered the various data implementation solutions that Azure provides, such as the various Azure Data Services and the various relational databases that Azure offers. You should now know which database you should use in different scenarios, how to manage your backup and restore, and how to design for high availability and performance.</p>
<p>Next, we will kick off designing security and identity solutions with securing Azure resources.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<p><span>Answer the following questions to test your knowledge of the information in this chapter. You can find the answers in the <em>Assessments</em> section at the end of this book:</span></p>
<ol>
<li>Can you restore deleted databases in Azure?
<ol>
<li>Yes</li>
<li>No</li>
</ol>
</li>
<li>Can you use SQL Server Stretch Database to extend your on-premises data storage to Azure?
<ol>
<li>Yes</li>
<li>No</li>
</ol>
</li>
<li>Can you use T-SQL for analyzing data in Azure Data Analytics?
<ol>
<li>Yes</li>
<li>No</li>
</ol>
</li>
</ol>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<p><span>You can check the following links for more information about the topics that are covered in this chapter:</span></p>
<ul>
<li><strong>Azure Data Catalog documentation</strong>: <a href="https://docs.microsoft.com/en-us/azure/data-catalog/">https://docs.microsoft.com/en-us/azure/data-catalog/</a>.</li>
<li><strong>Get started with Azure Data Catalog</strong>: <a href="https://docs.microsoft.com/en-us/azure/data-catalog/data-catalog-get-started">https://docs.microsoft.com/en-us/azure/data-catalog/data-catalog-get-started</a>.</li>
<li><strong>What is Azure SQL Data Warehouse?</strong>: <a href="https://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-overview-what-is">https://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-overview-what-is</a>.</li>
<li><strong>Overview of Azure Data Lake Store</strong>: <a href="https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-overview">https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-overview</a>.</li>
<li><strong>Overview of Microsoft Azure Data Lake Analytics</strong>: <a href="https://docs.microsoft.com/en-us/azure/data-lake-analytics/data-lake-analytics-overview">https://docs.microsoft.com/en-us/azure/data-lake-analytics/data-lake-analytics-overview</a></li>
<li><strong>Introduction to Azure HDInsight and the Hadoop and Spark technology stack</strong>: <a href="https://docs.microsoft.com/en-us/azure/hdinsight/hadoop/apache-hadoop-introduction">https://docs.microsoft.com/en-us/azure/hdinsight/hadoop/apache-hadoop-introduction</a>.</li>
<li><strong>Azure SQL Database documentation</strong>: <a href="https://docs.microsoft.com/en-us/azure/sql-database/">https://docs.microsoft.com/en-us/azure/sql-database/</a> <a href="https://docs.microsoft.com/en-us/azure/sql-database/"/></li>
<li><strong>Scaling out with Azure SQL Database</strong>: <a href="https://docs.microsoft.com/en-us/azure/sql-database/sql-database-elastic-scale-introduction">https://docs.microsoft.com/en-us/azure/sql-database/sql-database-elastic-scale-introduction</a></li>
<li><strong>Stretch Database</strong>: <a href="https://docs.microsoft.com/en-us/sql/sql-server/stretch-database/stretch-database">https://docs.microsoft.com/en-us/sql/sql-server/stretch-database/stretch-database</a></li>
<li><strong>Designing highly available services using Azure SQL Database</strong>: <a href="https://docs.microsoft.com/en-us/azure/sql-database/sql-database-designing-cloud-solutions-for-disaster-recovery">https://docs.microsoft.com/en-us/azure/sql-database/sql-database-designing-cloud-solutions-for-disaster-recovery</a></li>
<li><strong>Learning about automatic SQL Database backups</strong>: <a href="https://docs.microsoft.com/en-us/azure/sql-database/sql-database-automated-backups">https://docs.microsoft.com/en-us/azure/sql-database/sql-database-automated-backups</a></li>
<li><strong>Recovering an Azure SQL Database using automated database backups</strong>: <a href="https://docs.microsoft.com/en-us/azure/sql-database/sql-database-recovery-using-backups">https://docs.microsoft.com/en-us/azure/sql-database/sql-database-recovery-using-backups</a></li>
<li><span><strong>What is Azure Database for MySQL?</strong>: <a href="https://docs.microsoft.com/en-us/azure/mysql/overview">https://docs.microsoft.com/en-us/azure/mysql/overview</a>.</span></li>
<li><strong>What is Azure Database for PostgreSQL?</strong>: <a href="https://docs.microsoft.com/en-us/azure/postgresql/overview">https://docs.microsoft.com/en-us/azure/postgresql/overview</a></li>
</ul>


            </article>

            
        </section>
    </div>



  </body></html>