<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Artificial Intelligence, IoT, and Media Services</h1>
                </header>
            
            <article>
                
<p><span>In the previous chapter, we covered Governance and Policies, such as standard and custom roles in Azure, when to use Azure Role-based Access Security, and Azure Resource Policies.</span></p>
<p>In this chapter, you will learn about the various features and capabilities that Azure offers for <span>Artificial Intelligence, IoT, and for streaming media content.</span> By the end of this chapter, you will know how to design state-of-the-art solutions using Azure Cognitive Services, the Azure Bot Service, IoT Hub, Azure Media Services, and more.</p>
<p>The following topics will be covered:</p>
<ul>
<li><span>Azure Cognitive Services</span></li>
<li><span>Azure Bot Service</span></li>
<li><span>Azure Machine Learning</span></li>
<li><span>IoT Hub, Event Hubs, and IoT Edge</span></li>
<li>Azure <span>Stream Analytics</span></li>
<li><span>Azure Time Series Insights</span></li>
<li><span>Azure Media Services</span></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>This chapter uses the following tools for the examples:</p>
<ul>
<li>Visual Studio 2017: <a href="https://www.visualstudio.com/downloads/">https://www.visualstudio.com/downloads/</a></li>
</ul>
<p><span>The source code for this chapter can be downloaded from the following link:</span></p>
<ul>
<li><a href="https://github.com/SjoukjeZaal/AzureArchitectureBook/tree/master/Chapter%2012">https://github.com/SjoukjeZaal/AzureArchitectureBook/tree/master/Chapter%2012</a></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Cognitive Services</h1>
                </header>
            
            <article>
                
<p>With Azure Cognitive Services, you can create modern and intelligent applications. It offers various AI and machine learning APIs and SDKs, which can be used in applications to make them more intelligent, such as speech and facial recognition, <span>speech and language understanding,</span> and more.</p>
<p>Cognitive Services is part of the AI offering of Azure. It offers APIs that can be consumed <em>as-is</em> and APIs that need training and can be used to create your own custom AI solutions. </p>
<p>The APIs are split up into multiple categories, such as vision, speech, language, knowledge, and search APIs. These categories with the available APIs are covered in more detail in the upcoming sections.</p>
<p>Cognitive Services offers a set of APIs and SDKs that are still in the experimental stage as well. These services are added to the labs category. By the time of writing this book, the Labs section offers a gesture, event tracking, academic knowledge, local insights, knowledge exploration service, and entity linking service.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Available services and APIs</h1>
                </header>
            
            <article>
                
<p>Azure Cognitive Services offers the following APIs and services:</p>
<ul>
<li><strong>Vision</strong>:
<ul>
<li><strong>Computer Vision API</strong>: This API provides image processing and recognition. You can use this API for categorizing images, tagging images based on content, recognizing handwritten text, flagging adult content, cropping images, detecting human faces, and more.</li>
<li><strong>Content Moderator</strong>: The c<span>ontent moderator offers automatic moderator capabilities such as </span><span>detecting possible adult and racy content in videos. It offers review tooling where automatic moderation can be used in conjunction with human involvement as well.</span></li>
<li><strong>Custom Vision Service</strong>: This API offers a <span>tool in order to build custom image classifiers. This can be used to identify images, such as certain flowers or dogs for instance. This API needs to be trained by uploading images to it.</span></li>
<li><strong>Face API</strong>:<span> </span>This API can detect human faces in an image. It can extract information from the images, such as pose, facial hair, glasses, gender, age, and head pose. You can use this API for face verification, face grouping, face identification, and finding similar faces. </li>
<li><strong>Emotion API</strong>: This API is part of the Face API and can be used as a standalone API as well. You can use it to detect the emotion of people in images.</li>
<li><strong>Video Indexer</strong>: This API can <span>extract insights from your videos using various artificial intelligence technologies. This API is used inside Azure Media Services as well and will be covered in more detail later in this chapter.</span></li>
</ul>
</li>
<li><strong>Speech</strong>:
<ul>
<li><strong>Microsoft Speech API</strong>: This API provides speech-enabled features, such as voice command control and speech transcription and dictation. It offers speech to text, where human speech is converted into text, which can be used to control applications by speech and text to speech, where text is converted to audio streams, which can be played back in applications.</li>
<li><strong>Custom Speech Service</strong>: <span>This enables you to create customized language models and acoustic models aimed at a specific user population or used for applications in a particular environment. You can train the API to learn product names or jargon.</span></li>
<li><strong>Speaker Recognition API</strong>:<span><span>  This API provides speaker verification, which can be used to identify a person using voice commands for authentication. It provides speaker identification, where it can recognize a person in a group of speakers by their voice.</span></span></li>
<li><strong>Translator Speech API</strong>: This API offers a service that translates <span>conversational speech from one language into the text of another language.</span></li>
</ul>
</li>
<li><strong>Language</strong>:
<ul>
<li><strong>Language Understanding (LUIS)</strong>: LUIS can extract meanings from text. It uses machine learning to train the API.</li>
<li><strong>Bing Spell Check API</strong>: This offers a spell checker and a contextual grammar tool. It is based on all the web searches in Bing and uses machine learning to dynamically train the API.</li>
<li><strong>Linguistic Analysis API</strong>: This API offers three different tools for natural language processing, such as sentence separation and tokenization, part-of-speech tagging, and constituency parsing.</li>
<li><strong>Text Analytics API</strong>: This API provides natural language processing over raw text and includes the features mentioned here. One of the features is language detection for up to 120 languages. It returns a language code and a score indicating the strength of the analyzation. It also provides Key Phrase Extraction, where it extracts key phrases to identify the main points in sentences, and it offers sentiment analysis, which you can use to find out what people think of certain things by analyzing text.</li>
<li><strong>Translator Text API</strong>: This API can be used to provide <span>text-to-text language translation in more then 60 different languages.</span></li>
<li><strong>Web Language Model API</strong>: This offers a <span>variety of standard natural </span>language<span> processing tasks. The models are trained using Bing data at web-scale. </span></li>
</ul>
</li>
<li><strong>Knowledge</strong>:
<ul>
<li><strong>Custom Decision Service</strong>: You can use this API to create a personal experience for your users. It can personalize content or videos on a website or portal. You can use it for ad placement and ranking items in shops.</li>
<li><strong>QnA Maker</strong>: This offers a web API <span><span>that trains an AI model to respond to user's questions in a more natural, conversational way. It can be trained using FAQ, URLs/documents, and more.</span></span></li>
</ul>
</li>
<li><strong>Search:</strong>
<ul>
<li><strong>Bing Search APIs</strong>: This API consists of multiple APIs and functions. It includes all Bing search APIs, such as the Bing web search API, Bing image search API, Bing video search API, and Bing news search API.</li>
<li><strong>Bing Autosuggest API</strong>: This offers suggestions when you are typing the first few characters of a word. You can use it to populate a drop-down box under search boxes.</li>
<li><strong>Bing Custom Search API</strong>: This offers tailored search experiences. You can tailor results based on interests. So, instead of letting users go through pages to search for relevant content, you can filter irrelevant content before providing it to your users.</li>
<li><strong>Bing Entity Search API:</strong> This API provides search results that includes entities and places that can be used for tourist attractions, for instance.</li>
</ul>
</li>
</ul>
<div class="packt_tip">For a complete overview of all the Cognitive Services APIs, you can refer to: <a href="https://docs.microsoft.com/en-us/azure/#pivot=products&amp;panel=ai">https://docs.microsoft.com/en-us/azure/#pivot=products&amp;panel=ai</a>. Want to get started with Cognitive Services? You can refer to the following page to obtain free trial API keys for the various APIs that Cognitive Service offers: <a href="https://azure.microsoft.com/en-us/try/cognitive-services/">https://azure.microsoft.com/en-us/try/cognitive-services/</a>. These trial plans have rate limits. The Azure Portal has paid offerings. You can create Cognitive Services APIs in there as well.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using the Computer Vision API</h1>
                </header>
            
            <article>
                
<p>In this example, we are going to create an application that uses the Computer Vision API to analyze some pictures. </p>
<p>First, you need to obtain an API subscription key from <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/Computer-vision/Vision-API-How-to-Topics/HowToSubscribe">https://docs.microsoft.com/en-us/azure/cognitive-services/Computer-vision/Vision-API-How-to-Topics/HowToSubscribe</a>.</p>
<p>Next you have to open up Visual Studio 2017.</p>
<ol>
<li class="mce-root"><span>Click on <span class="packt_screen">File</span></span> <span>|</span> <span><span class="packt_screen">New</span></span> <span>|</span> <span><span class="packt_screen">Project</span></span><span>, and in the <span class="packt_screen">New Project</span> window, select</span><span class="packt_screen"> Console App</span>.<span> Name the project and click on </span><span class="packt_screen">OK</span><span>:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/c6a04c61-16ce-4b2b-85dc-dfd3bb1d94b6.png" style="width:54.58em;height:37.92em;" width="1376" height="948"/></div>
<div style="color: black" class="CDPAlignCenter CDPAlign packt_figref">Creating Console application</div>
<ol start="2">
<li class="mce-root"><span>Create a new class, named </span><kbd>Extensions.cs</kbd>, <span>and replace the code with the following:</span></li>
</ol>
<pre style="color: black;padding-left: 60px">using System;<br/>using System.Collections.Generic;<br/><br/>namespace PacktCustomerVisionAPI<br/>{<br/>    static class Extensions<br/>    {<br/>        public static void ForEach&lt;T&gt;(this IEnumerable&lt;T&gt; ie, Action&lt;T&gt; action)<br/>        {<br/>            foreach (var i in ie)<br/>            {<br/>                action(i);<br/>            }<br/>        }<br/>    }<br/>}</pre>
<ol start="3">
<li class="mce-root">Add the following namespaces to the <kbd>Main.cs</kbd>:</li>
</ol>
<pre style="color: black;padding-left: 60px">using System;<br/>using System.Collections.Generic;<br/>using System.IO;<br/>using System.Linq;<br/>using System.Net.Http;<br/>using System.Net.Http.Headers;<br/>using System.Text;</pre>
<ol start="4">
<li class="mce-root">Add the following variables to the <kbd>Main.cs</kbd>. Replace the <kbd>subscriptionKey</kbd> value with your valid subscription key:</li>
</ol>
<pre style="color: black;padding-left: 60px">// Fill in the subscription Key<br/>    const string subscriptionKey = "7c98f3e0aa3a4a729f69b20583a0bc18";<br/><br/>    //API Url in West Central US Region<br/>    const string uriBase = "https://westcentralus.api.cognitive.microsoft.com/vision/v1.0/models/celebrities/analyze";</pre>
<ol start="5">
<li class="mce-root">Replace the <kbd>Main</kbd> method with the following:</li>
</ol>
<pre style="color: black;padding-left: 60px">static void Main(string[] args)<br/>   {<br/>      Console.Write("Enter the path to an celebrity image: ");<br/>      string imageFilePath = Console.ReadLine();<br/><br/>       MakeAnalysisRequest(imageFilePath);<br/><br/>       Console.WriteLine("\nPlease wait a moment for the results to appear. Then, press Enter to exit ...\n");<br/>        Console.ReadLine();<br/>    }</pre>
<ol start="6">
<li>Add the following method for creating a request and send it to the customer service API of the class:</li>
</ol>
<pre style="padding-left: 60px">static async void MakeAnalysisRequest(string imageFilePath)<br/>{<br/>   HttpClient client = new HttpClient();<br/><br/>   client.DefaultRequestHeaders.Add("Ocp-Apim-Subscription-Key", subscriptionKey);<br/>        string requestParameters = "model=celebrities";<br/>        string uri = uriBase + "?" + requestParameters;<br/>        HttpResponseMessage response;<br/>        byte[] byteData = GetImageAsByteArray(imageFilePath);<br/>        using (ByteArrayContent content = new ByteArrayContent(byteData))<br/>         {<br/>             content.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");<br/>             response = await client.PostAsync(uri, content);<br/>             string contentString = await response.Content.ReadAsStringAsync();<br/>               Console.WriteLine("\nResponse:\n");<br/>               Console.WriteLine(JsonPrettyPrint(contentString));<br/>          }<br/>}</pre>
<ol start="7">
<li>Add the following method to import the celebrity image below the previous method:</li>
</ol>
<pre style="padding-left: 60px">static byte[] GetImageAsByteArray(string imageFilePath)<br/>{<br/>    FileStream fileStream = new FileStream(imageFilePath, FileMode.Open, FileAccess.Read);<br/>    BinaryReader binaryReader = new BinaryReader(fileStream);<br/>    return binaryReader.ReadBytes((int)fileStream.Length);<br/>}</pre>
<ol start="8">
<li>Add the last method in order to display the JSON results in the Console below the previous method:</li>
</ol>
<pre style="padding-left: 60px"> static string JsonPrettyPrint(string json)<br/>        {<br/>            if (string.IsNullOrEmpty(json))<br/>                return string.Empty;<br/><br/>            json = json.Replace(Environment.NewLine, "").Replace("\t", "");<br/><br/>            string INDENT_STRING = " ";<br/>            var indent = 0;<br/>            var quoted = false;<br/>            var sb = new StringBuilder();<br/>            for (var i = 0; i &lt; json.Length; i++)<br/>            {<br/>                var ch = json[i];<br/>                switch (ch)<br/>                {<br/>                    case '{':<br/>                    case '[':<br/>                        sb.Append(ch);<br/>                        if (!quoted)<br/>                        {<br/>                            sb.AppendLine();<br/>                            Enumerable.Range(0, ++indent).ForEach(item =&gt; sb.Append(INDENT_STRING));<br/>                        }<br/>                        break;<br/>                    case '}':<br/>                    case ']':<br/>                        if (!quoted)<br/>                        {<br/>                            sb.AppendLine();<br/>                            Enumerable.Range(0, --indent).ForEach(item =&gt; sb.Append(INDENT_STRING));<br/>                        }<br/>                        sb.Append(ch);<br/>                        break;<br/>                    case '"':<br/>                        sb.Append(ch);<br/>                        bool escaped = false;<br/>                        var index = i;<br/>                        while (index &gt; 0 &amp;&amp; json[--index] == '\\')<br/>                            escaped = !escaped;<br/>                        if (!escaped)<br/>                            quoted = !quoted;<br/>                        break;<br/>                    case ',':<br/>                        sb.Append(ch);<br/>                        if (!quoted)<br/>                        {<br/>                            sb.AppendLine();<br/>                            Enumerable.Range(0, indent).ForEach(item =&gt; sb.Append(INDENT_STRING));<br/>                        }<br/>                        break;<br/>                    case ':':<br/>                        sb.Append(ch);<br/>                        if (!quoted)<br/>                            sb.Append(" ");<br/>                        break;<br/>                    default:<br/>                        sb.Append(ch);<br/>                        break;<br/>                }<br/>            }<br/>            return sb.ToString();<br/>        }</pre>
<ol start="9">
<li>Now, download a celebrity image, run the application, and provide the full image path.</li>
</ol>
<div class="packt_tip packt_infobox">For a detailed overview of all the capabilities of the Computer Vision API, you can refer to: <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/home#Categorizing">https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/home#Categorizing</a>.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Bot Service</h1>
                </header>
            
            <article>
                
<p>Azure Bot Service offers a complete environment to build and deploy Bots. A Bot is an app that can interact with users in a conversational way. It can communicate with users using speech, text, and cards. You can create Bots that communicate with users using a freeform approach, where a users asks a question in a chatbox, for instance, and gets an answer back from the Bot, or you can use a more guided approach, where you provide choices to the users and take actions based on the choice they make.</p>
<p>You can integrate Bots in all types of applications, such as custom web applications and Azure Functions. You can create bots that integrate in Azure SaaS applications as well. Azure Bot Service offers different channels to connect your Bot to <span>Skype, Facebook, Teams, Slack, SMS, </span>and more. Bots can be created using .NET or Node.js, and there are five different templates provided to get you up to speed with developing them. You can choose from a Basic Bot, a Form Bot that collects user input, a language understanding Bot, which leverages LUIS, a Bot to use for FAQs, and a Bot that alerts users about events.</p>
<p>Azure Bot Service offers the following two different pricing tiers:</p>
<ul>
<li><strong>Free</strong>: This offers unlimited messages for Standard channels and 10,000 messages per month on Premium Channels (such as Microsoft Teams and Skype). </li>
<li><strong>Standard S1</strong>: This o<span>ffers unlimited messages for Standard channels, and you pay a certain amount for 1,000 messages at a time on Premium channels. This pricing tier offers SLA as well.<br/></span></li>
</ul>
<p>You can use Bots from the Azure Portal or from Visual Studio 2017. <span>Microsoft offers a complete solution for building and deploying Bots, which is included in the Bot Builder SDK for .NET. You need to download templates that can be installed inside the Visual Studio <kbd>Template</kbd> folder. This template will then be a starting point for developing Bots.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating a Bot from the Azure Portal</h1>
                </header>
            
            <article>
                
<p>In this example, we are going to create a Bot that can be deployed in a Web App from the Azure Portal:</p>
<ol>
<li>Navigate to the Azure Portal by opening: <a href="https://portal.azure.com/">https://portal.azure.com/</a>.</li>
<li>Click on <span class="packt_screen">New</span><span> </span><span>and type</span> <kbd>Web App Bot</kbd><strong> </strong><span><span>in the search bar. </span></span></li>
</ol>
<ol start="3">
<li>Enter the following settings:</li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="Images/f07a0fbc-a252-46c5-8f5b-6052a43537c3.jpg" style="width:15.00em;height:47.08em;" width="624" height="1959"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Web App Bot settings</div>
<ol start="4">
<li class="mce-root"><span>Click on </span><span class="packt_screen">Bot template</span><span>, select the </span><span class="packt_screen">Form</span> <span>template, and click on <span class="packt_screen">Select</span>:</span></li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="Images/2dd9637b-e9a8-4cc5-901f-9d029a102ca2.jpg" style="width:35.00em;height:50.33em;" width="1157" height="1662"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Selecting Bot template</div>
<ol start="5">
<li class="mce-root"><span>When created, you can navigate to the Bot in the Azure Portal. When you click on</span><span class="packt_screen"> Build</span> <span>in the left menu, you can make changes to the code in the online code editor. There are a couple of tools integrated in the online editor, such as Git, Kudu, and more. You can download the ZIP file to make changes in Visual Studio, and you can configure Continuous Deployment as well:</span></li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="Images/908bd0f2-136c-42c4-b965-d92057f74786.jpg" style="width:64.92em;height:40.08em;" width="2275" height="1404"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Bot Build settings</div>
<ol start="6">
<li class="mce-root"><span>To test the Bot, click on </span><span class="packt_screen">Test in Web Chat</span> <span>in the left menu. This Bot provides an example of a sandwich ordering service, using a guided approach. So, if you type anything in the message box, you get a set of options for sandwiches to order. Pick one, and you can select the length of your sandwich:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/5700fe11-32c9-45d8-ba7d-249ff7dd2773.png" style="width:62.08em;height:39.42em;" width="1174" height="914"/></div>
<div class="mce-root CDPAlignCenter CDPAlign packt_figref">Example of bot</div>
<ol start="7">
<li class="mce-root"><span>For channel registration, you can click on </span><span class="packt_screen">Channels</span> <span>in the left menu. Here, you can register the different channels that you want your Bot to connect to:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/cfc44974-5a1e-4072-9916-2e629feaf22a.png" style="width:57.42em;height:42.75em;" width="1392" height="959"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Different bot channels</div>
<div class="packt_infobox">For more information about how to create Bots using Visual Studio 2017, you can refer to <a href="https://docs.microsoft.com/en-us/bot-framework/dotnet/bot-builder-dotnet-quickstart">https://docs.microsoft.com/en-us/bot-framework/dotnet/bot-builder-dotnet-quickstart</a>.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Machine Learning</h1>
                </header>
            
            <article>
                
<p>We all produce massive amounts of data these days. Data created in the past can give us valuable insights into the future.</p>
<p>Machine learning provides a set of algorithms that can <span>apply complex mathematical calculations to big data automatically and can eventually </span>learn from this data. <span>It is a data science technique, which can be used to predict the future by forecasting outcomes and trends. Applications using this technique can learn from data and experiences without being explicitly programmed. Machine learning models can be trained using large amounts of historical data which applications can act upon.</span></p>
<p>Fraud detection, self-driving vehicles, and personal recommendations on websites are all examples of applications that use machine learning. Artificial intelligence and machine learning possibilities are endless and will have an enormous impact on our daily lives in the near future.</p>
<p>Azure Machine Learning provides a set of tools and capabilities for data scientists and developers to leverage machine learning in their applications. The following tools and capabilities are offered:</p>
<ul>
<li><strong>Machine Learning Studio</strong>: Machine Learning Studio is a drag and drop tool, which you can use to create predictive models. You can use it to deploy and test your solutions as well. You can create <strong>Experiments</strong> on which you can drag and drop datasets and data analyzation activities, named <strong>Modules</strong>. You can train the <strong>Experiments</strong> using parts of the data from the datasets, and when the models are trained properly, you can convert them into <strong>Predictive</strong> experiments and publish them as web services.</li>
<li><strong>Azure Machine Learning Workbench</strong>:<strong> </strong>At the time of writing this book, this tool is still in preview. It offers an integrated end-to-end data science solution for data scientists to prepare data, develop experiences, and deploy models to Azure.</li>
<li><strong>Azure AI Gallery</strong>: The AI Gallery provides various community-driven solutions built with different AI features of Azure. You can use these solutions for learning purposes or as a resource for developing your custom solutions. </li>
<li><strong>Machine Learning Modules</strong>: You can use out-of-the box machine learning models in your experiments for analyzing data. There are machine learning algorithms, data input and output modules, data transformation modules, text analytics modules, and Microsoft-specific modules with algorithms from Bing and Xbox.</li>
<li><strong>Data Science</strong><strong> Virtual Machines</strong>: <span>Azure offers virtual machines that are configured for data science workloads. There are Windows and Linux Data Science VMs and Deep Learning VMs. You can deploy containers for data science workloads as well:</span></li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img src="Images/a3c8bbd2-4d53-4468-aa75-f779023566fe.jpg" style="width:62.58em;height:35.75em;" width="2724" height="1556"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Machine Learning studio</span></div>
<div class="packt_tip">Data science is a specialization; however, Microsoft offers a series of videos that can give some basic understanding of data science. F<span>or these series of videos, y</span>ou can refer to: <a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio/data-science-for-beginners-the-5-questions-data-science-answers#other-videos-in-this-series">https://docs.microsoft.com/en-us/azure/machine-learning/studio/data-science-for-beginners-the-5-questions-data-science-answers#other-videos-in-this-series</a>.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure IoT Hub</h1>
                </header>
            
            <article>
                
<p>In an Internet of Things (IoT) solution, devices send massive amounts of data to Azure for further processing. T<span>he IoT Hub is used </span>to connect these devices securely and route the messages from those devices to different resources in Azure for further processing.</p>
<p>The IoT Hub offers the following capabilities:</p>
<ul>
<li><strong>Bi-directional communication</strong>: It provides bi-directional communication between devices and Azure, such as one-way messaging, file transfer, and request-reply messaging. Devices can send data to Azure IoT Hub, but the IoT Hub can send data to the devices as well. It supports various communication protocols, such as HTTPS, AMQP, and MQTT. It provides built-in declarative message routing to other Azure services.</li>
<li><strong>Secure Connectivity</strong>:<strong> </strong>Communication between devices and the IoT Hub can be secured using <span>per-device security keys or X.509 certificates. Azure IoT Hub does not open any connections, only connected devices initiate all the connections. IoT Hub stores the messages inside a per device queue for two days and waits for the device to connect. It uses Azure AD for user authentication and authorization.</span></li>
<li><strong>Scaling</strong>: IoT Hub offers massive scaling because it can scale up to m<span>illions of simultaneously connected devices and millions of events per second</span><span>.</span></li>
<li><strong>Monitoring</strong>:<strong> </strong>It offers a monitoring solution in Azure. IoT Hub is integrated with Azure Monitor, which gives you detailed information about device management operations and connectivity events.</li>
</ul>
<p class="mce-root"><span>Azure IoT Hub offers the Azure IoT SDK, which consists of Device SDKs and can be used to create apps that run on IoT devices and send data to the IoT Hub. The SDK also offers Service SDKs, which can be used to manage the IoT Hub, and it offers the Azure IoT Edge, which is covered in more detail later in this chapter.</span></p>
<p class="mce-root">IoT Hub comes in the following pricing tiers:</p>
<ul>
<li><strong>Free</strong>:<strong> </strong>This offers total 8,000 messages <span>per unit a day</span>. This tier is most suitable for testing scenarios. </li>
<li><strong>Standard S1</strong>: This offers <span>up to 400,000 messages per day across all connected devices. This is must suitable for scenarios that generate small amounts of data.</span></li>
<li><strong>Standard S2</strong>: This offers up to 6 million messages per unit a day across all connected devices. This is suitable for scenarios with large amounts of data.</li>
</ul>
<ul>
<li><strong>Standard S3</strong>: T<span>his offers up to </span>300 million messages <span>per unit a day</span> across all connected devices. This is suitable for scenarios with large amounts of data as well.</li>
</ul>
<p>Next to the IoT Hub, Azure offers the Azure Event Hub. <span>The Azure Event Hub offers similar capabilities such as the Azure IoT Hub, except that the IoT Hub offers more advanced capabilities. If your architecture demands cloud-to-device communication or per device security and performance management, the IoT Hub is the best solution.</span></p>
<p><span>The Event Hub is covered in more detail in the next section. Azure also offers IoT Edge, which offers additional functionality and will be covered in the next section as well:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/229d6043-97de-4ed7-a9af-26b6797bffb5.png" style="width:59.75em;height:34.33em;" width="1552" height="905"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>IoT architecture overview</span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Event Hub </h1>
                </header>
            
            <article>
                
<p>Azure Event Hub is designed for high <span>throughput ingress of data streams generated by devices and services. It provides a telemetry ingestion service that can collect, transform, and store millions of events.</span></p>
<p><span>It offers similar capabilities such as the IoT Hub, but there are differences as well. When to use which solutions depends on the scenario. If your solution demands high throughput data ingestion only, Azure Event Hubs is a more cost-effective solution than the IoT Hub. However, if your solution needs bi-directional communication, such as communicating from the cloud to your devices, IoT Hub is a better solution.</span></p>
<p>To make the right decision on which solution to use for your IoT architecture, you can look at the following differences:  </p>
<ul>
<li><strong>Device Protocol Support</strong>: Azure Event Hub supports HTTPS, <span>AMQP, and AMQP where the IoT Hub supports  MQTT, MQTT over WebSockets, AMQP, AMQP over WebSockets, and HTTPS, MQTT, MQTT over WebSockets, AMQP, AMQP over WebSockets. IoT Hub supports file upload as well.</span></li>
<li><strong>Communications Patterns</strong>: The Event Hub only supports event ingress where the IoT Hub supports device-to-cloud communications and cloud-to-device communications as well.</li>
<li><strong>Security</strong>:<strong> </strong>The Event Hub supports Shared Access Policies, where the IoT Hub supports per device identity and revocable access control.</li>
<li><strong>Monitoring</strong>: The IoT Hub offers a complete set of monitoring capabilities, where the Event Hub only offers aggregate metrics.</li>
<li><strong>Scale</strong>:<strong> </strong>IoT Hub can scale up to millions of simultaneously connected devices and millions of events per second, where the Event Hub can scale up to 5,000 <span>AMQP connections per namespace.</span></li>
<li><strong>SDKs</strong>: Event Hubs supports .NET and C, where IoT Hub supports <span>.NET, </span><span>C, Node.js, Java, and Python.</span></li>
</ul>
<div class="packt_infobox">For a complete overview of the differences between the Event Hub and the IoT Hub, you can refer to: <a href="https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-compare-event-hubs">https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-compare-event-hubs</a>.</div>
<p>Azure Event Hub offers the following three different pricing tiers:</p>
<ul>
<li><strong>Basic</strong>: This offers a maximum of <span>20 </span>throughput units with <span>1 MB/s ingress and 2 MB/s egress per unit</span>. Maximum message size is 256 KB. A message retention of 1 day, 1 consumer group, and 100 brokered connections.</li>
<li><strong>Standard</strong>:<strong> </strong>On top of the basic features, the standard plan offers lower costs for throughput units and messages. It offers 20 consumer groups and 1,000 brokered connections.</li>
<li><strong>Dedicated</strong>: This offers a dedicated environment for customers. Offers a maximum message size of 1 MB and 50 throughput units, a retention period of 7 days and 25,000 brokered connections.</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure IoT Edge</h1>
                </header>
            
            <article>
                
<p>Azure IoT Edge is an additional feature of Azure IoT Hub, which is installed at the edge of the on-premises network, inside a DMZ or inside the corporate network. Instead of sending messages to Azure, the messages can be sent to Azure IoT Edge, which takes less time because it doesn't have to be sent beyond the on-premises network. Data can be stored and analyzed on the device as well.</p>
<p>You can register the IoT Edge inside the IoT Hub settings page in the Azure Portal. The IoT Edge runtime can then be installed on the IoT Edge device. Devices can be a Windows or Linux machine, a container, or a Raspberry Pi, for instance. This IoT Edge device can then connect to the Azure IoT Hub, collect the data from the devices, and send it to the IoT Hub.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Stream Analytics</h1>
                </header>
            
            <article>
                
<p>Azure Stream Analytics is part of Azure's IoT Suite and offers a pipeline for event processing and real-time analytics for the data that is streaming from various sources. You can use it for scenarios that require real-time analytics on data, such as stock analysis, fraud detection, and analyzing data that comes from a massive amount of sensors, for instance.</p>
<p>Data can come from various sources, such as custom applications, sensors, Azure IoT Hub, and Azure Event Hubs. It can come from Blob Storage as well. Stream Analytics can handle an ingest of data up to 1 GB per second. You can create a Stream Analytics <strong>Job</strong>, where you configure the data source. You can create a <strong>Transformation</strong>, where you can query the data for patterns or relationships using a SQL-like language.</p>
<p>You can create filter, sort, or aggregate the data from the data sources. Finally, the data is sent to an output source, which can be Azure Data Lake, Power BI for creating dashboards, using machine learning, or storing it in a SQL Data Warehouse:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1029 image-border" src="Images/937c2d1a-678a-46bf-8908-7b20edc0a912.png" style="width:68.33em;height:39.25em;" width="1662" height="954"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Azure Stream Analytics</span></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Time Series Insights</h1>
                </header>
            
            <article>
                
<p>Time Series Insights offers a portal that can be used to get valuable insights in your IoT data. It offers database storage for a massive amount of data sent from IoT Hub and Event Hubs. It can join different types of data easily, such as metadata and telemetry, and then visualize this data.</p>
<p>Time Series Insights offers the following features:</p>
<ul>
<li><strong>Integration</strong>: It offers out-of-the-box integration with Azure IoT Hub and Event Hub.</li>
<li><strong>Data Storage</strong>: Time Series Insights stores your data on SSDs and in memory for up to 400 days.</li>
<li><strong>Visualization</strong>: This offers a dedicated portal that offers visualization of your data using the TSI Explorer. </li>
<li><strong>Query Service</strong>: Time Series insights offers a query service inside the <span>TSI Explorer and APIs that can be called from your custom applications. By integrating Time Series Insights in your applications, you can leverage it as a backend for indexing, storing, and aggregating data. You can then build your custom visualization tool on top of it. </span></li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1030 image-border" src="Images/ce469e89-14c2-440e-903e-95b06ccbd088.jpg" style="width:60.58em;height:34.58em;" width="1483" height="846"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Azure Time Series Insights TSI Explorer</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Media Services</h1>
                </header>
            
            <article>
                
<p>Azure Media Services offers a secure and high-quality service in order to stream content to all sorts of devices. It can stream videos or audio files and offers REST APIs to upload, store, and encode package content. Audios and videos can be delivered to clients, such as TVs, computers, and mobile devices using both on-demand streaming and live streaming.</p>
<p>Azure Media Services supports the following flow:</p>
<ul>
<li><strong>Upload</strong>: You can upload your videos using the Azure Portal, .NET SDK, REST API, and you can copy files from Blob Storage.</li>
<li><strong>Encode</strong>:<strong> </strong>AMS offers two different encoding tiers, such as Media Encoder Standard and Media Encoder Premium Workflow. The former offers an encoding service which encodes video and audio files, which are suitable <span>for playback on a variety of devices, such as smartphones and PCs. The latter offers encoding for video and audio files that require a more complex workflow. It offers a Workflow Designer tool, which can be used for combining multiple input files or to create decision-based workflows with dynamic values using parameters. It also supports formats that are required for broadcasting and movies.</span></li>
<li><strong>Secure</strong>: You can secure your media using dynamic encryption using the <span>Advanced Encryption Standard (AES-128) or other major digital rights management (DRM) systems. It offers AES keys and DRM licenses to authorized clients as well. You can secure your Media Services Channels with IP restrictions, so users can only upload media content from allowed IP addresses, and you can access the Azure Media Services API with Azure AD authentication. AMS still supports the Azure Access Control service authentication model using tokens. However, this will be deprecated in the near future, so Azure AD authentication is the preferred authentication method now.</span></li>
<li><strong>Analyze</strong>:<strong> </strong>AMS offers Media Analytics in order to extract insights from media content. It offers a <span>collection of speech and computer vision APIs from Azure Cognitive Services. This is described in the following section in more detail.</span></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Media Analytics</h1>
                </header>
            
            <article>
                
<p>Azure Media Analytics uses various Cognitive Services APIs to analyze media content. It offers the following capabilities:</p>
<ul>
<li><strong>Indexer</strong>: Using the Indexer, you can create <span>closed-captioning tracks and make the media file searchable. By the time of writing, the Indexer offers two different versions of the service, where the Azure Media Indexer 2, which is still in preview, has faster indexing and broader language support. </span></li>
<li><strong>Hyperlapse</strong>: This offers time lapse capabilities and capabilities to create stable videos from first person <span>or action camera content</span>. </li>
<li><strong>Motion Detector</strong>: This offers motion detection, which can be used on static camera footage to identify parts in the video where motion occurs. It generates a metadata file with timestamps of when the motion occurred. This is very useful for security camera footage.</li>
<li><strong>Video Summarization</strong>: This can create summaries for videos by generating snippets from different sections of the video. These snippets can be placed as an overview of all the different sections of the video.</li>
<li><strong>Optical Character Recognition</strong>: <span>Azure Media optical character recognition (OCR) offers converting text content in videos into editable and searchable digital text. For instance, you can use this for making the content of videos of PowerPoint presentations searchable in search engines.</span></li>
<li><strong>Scalable Face Redaction</strong>: You can use scalable face redaction for blurring faces of individuals on video content automatically. </li>
<li><strong>Content Moderation</strong>:<strong> </strong>Azure Content Moderator offers automatic moderator capabilities such as <span>detecting possible adult and racy content in videos. It offers review tooling where automatic moderation can be used in conjunction with human involvement as well.</span></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using the Azure Media Analytics Indexer</h1>
                </header>
            
            <article>
                
<p>In the following example, we are going to create closed caption files for a video using the Azure Media Analytics Media Indexer. <span>Microsoft recommends using Azure Media Analytics over the Video API from Cognitive Services, so that's what we are going to use here. </span>We are going to use the speech to text feature of the Azure Media Indexer 2 Preview media processor (MP) to create subtitles for the video from a Console Application. </p>
<div class="packt_infobox">For this example, you need to create a Media Service Account in the Azure Portal. For a complete walkthrough on how to create this, you can refer to: <a href="https://docs.microsoft.com/en-us/azure/media-services/media-services-portal-create-account">https://docs.microsoft.com/en-us/azure/media-services/media-services-portal-create-account</a><span>.</span></div>
<p>When the Azure Media Service account is created, you can copy the <kbd>PacktIndexer</kbd> folder from GitHub to your <kbd>C:</kbd> drive. You can download the video from the following website and put it inside the <kbd>InputFiles</kbd> folder together with the JSON file: <a href="https://peach.blender.org/download/">https://peach.blender.org/download/</a>. These files will be used for the example. Create a new folder named <kbd>OutputFiles</kbd> in the <kbd>PacktIndexer</kbd> folder as well.</p>
<p>Next, open up Visual Studio 2017 and create a new project.</p>
<ol>
<li>Click on <span class="packt_screen">File</span> | <span class="packt_screen">New</span> | <span class="packt_screen">Project</span>, and in the <span class="packt_screen">New Project</span> windows, select <span class="packt_screen">Console App</span>. Name the project and click on <span class="packt_screen">OK</span>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1031 image-border" src="Images/ddbbf32e-e642-4bd4-b3fc-5d3cb79b7a7c.png" style="width:57.58em;height:39.92em;" width="1510" height="1044"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Create a new Console Application</div>
<ol start="2">
<li>Install the <kbd>windowsazure.mediaservices.extensions</kbd> and the <kbd>windowsazure.mediaservices</kbd><strong> </strong>NuGet packages.</li>
<li class="mce-root"><span>The first step is adding Azure AD authentication to the project. For this demo, we are using</span> <strong>Service principal authentication</strong><span>.</span><strong> </strong><span>You can set this up easily in the Azure Portal in the</span> access blade <span>of the <span class="packt_screen">Azure Media Service Account</span> settings:</span></li>
</ol>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="Images/2fee99bf-ae84-498b-a3dc-2df2f8eca281.jpg" style="width:34.92em;height:40.67em;" width="1163" height="1355"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Creating a App Service Principal</div>
<ol start="4">
<li>Copy the Azure AD tenant name, the API URL, client ID, and client secret from the Azure Portal and add them to the following code:</li>
</ol>
<pre style="padding-left: 60px">var tokenCredentials = new AzureAdTokenCredentials("{YOUR Azure AD TENANT DOMAIN HERE}", new AzureAdClientSymmetricKey("{YOUR CLIENT ID HERE}", "{YOUR CLIENT SECRET}"), AzureEnvironments.AzureCloudEnvironment);<br/><br/>            var tokenProvider = new AzureAdTokenProvider(tokenCredentials);</pre>
<ol start="5">
<li>Add the following code to the <kbd>Main</kbd> method below the authentication code:</li>
</ol>
<pre style="padding-left: 60px">_context = new CloudMediaContext(new Uri("https://packtmediaservices.restv2.westeurope.media.azure.net/api/"), tokenProvider);<br/><br/>            var video = @"C:\PacktIndexer\InputFiles\BigBuckBunny.mp4";<br/>            var config = @"C:\PacktIndexer\InputFiles\config.json";<br/>            var asset = RunIndexingJob(video, config);<br/><br/>            DownloadAsset(asset, @"C:\PacktIndexer\OutputFiles");</pre>
<ol start="6">
<li>Add the following method for creating and running the <kbd>Index Job</kbd>:</li>
</ol>
<pre style="padding-left: 60px">static IAsset RunIndexingJob(string inputMediaFilePath, string configurationFile)<br/>        {<br/>            IAsset asset = CreateAssetAndUploadSingleFile(inputMediaFilePath,<br/>                "Packt Indexing Input Asset",<br/>                AssetCreationOptions.None);<br/><br/>            IJob job = _context.Jobs.Create("Packt Indexing Job");<br/><br/>            string MediaProcessorName = "Azure Media Indexer 2 Preview";<br/><br/>            var processor = GetLatestMediaProcessorByName(MediaProcessorName);<br/>            string configuration = File.ReadAllText(configurationFile);<br/><br/>            ITask task = job.Tasks.AddNew("Packt Indexing Task",<br/>                processor,<br/>                configuration,<br/>                TaskOptions.None);<br/><br/>            task.InputAssets.Add(asset);<br/>            task.OutputAssets.AddNew("Packt Indexing Output Asset", AssetCreationOptions.None);<br/><br/>            job.StateChanged += new EventHandler&lt;JobStateChangedEventArgs&gt;(StateChanged);<br/>            job.Submit();<br/><br/>            Task progressJobTask = job.GetExecutionProgressTask(CancellationToken.None);<br/><br/>            progressJobTask.Wait();<br/><br/>            if (job.State == JobState.Error)<br/>            {<br/>                ErrorDetail error = job.Tasks.First().ErrorDetails.First();<br/>                Console.WriteLine(string.Format("Error: {0}. {1}",<br/>                                                error.Code,<br/>                                                error.Message));<br/>                return null;<br/>            }<br/><br/>            return job.OutputMediaAssets[0];<br/>        }</pre>
<ol start="7">
<li>Add the following method in order to create the <kbd>Asset</kbd>:<span><strong><br/></strong></span></li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><span>static IAsset CreateAssetAndUploadSingleFile(string filePath, string assetName, AssetCreationOptions options)</span><br/><span>        {</span><br/><span>            IAsset asset = _context.Assets.Create(assetName, options);</span><br/><br/><span>            var assetFile = asset.AssetFiles.Create(Path.GetFileName(filePath));</span><br/><span>            assetFile.Upload(filePath);</span><br/><br/><span>            return asset;</span><br/><span>        }</span></pre>
<ol start="8">
<li>Add the following method for downloading the <kbd>Asset</kbd> after indexing:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><span>static void DownloadAsset(IAsset asset, string outputDirectory)</span><br/><span>   {</span><br/><span>     foreach (IAssetFile file in asset.AssetFiles)</span><br/><span>      {</span><br/><span>        file.Download(Path.Combine(outputDirectory, file.Name));</span><br/><span>       }</span><br/><span>    }</span></pre>
<ol start="9">
<li>Add the following code for obtaining the <kbd>MediaProcessor</kbd> that processes the video:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><span>static IMediaProcessor GetLatestMediaProcessorByName(string mediaProcessorName)</span><br/><span>        {</span><br/><span>           var processor = _context.MediaProcessors</span><br/><span>              .Where(p =&gt; p.Name == mediaProcessorName)</span><br/><span>              .ToList()</span><br/><span>              .OrderBy(p =&gt; new Version(p.Version))</span><br/><span>              .LastOrDefault();</span><br/><span>            if (processor == null)</span><br/><span>            throw new ArgumentException(string.Format("Unknown media processor",</span><span>                                               mediaProcessorName));</span><br/><span>            return processor;</span><br/><span>        }</span></pre>
<ol start="10">
<li>At last, add the following code in order to display the process inside the console:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><span> static private void StateChanged(object sender, JobStateChangedEventArgs e)</span><br/><span>    {</span><br/><span>         Console.WriteLine("Job state changed event:");</span><br/><span>         Console.WriteLine(" Previous state: " + e.PreviousState);</span><br/><span>         Console.WriteLine(" Current state: " + e.CurrentState);</span><br/><span>           switch (e.CurrentState)</span><br/><span>           {<br/></span><span>               case JobState.Finished:</span><span>                       <br/>Console.WriteLine();</span><br/><span>               Console.WriteLine("Job is finished.");</span><br/><span>               Console.WriteLine();</span><br/><span>               break;</span><br/><span>                case JobState.Canceling:</span><br/><span>                case JobState.Queued:</span><br/><span>                case JobState.Scheduled:</span><br/><span>                case JobState.Processing:</span><br/><span>                   Console.WriteLine("Please wait...\n");</span><br/><span>                   break;</span><br/><span>               case JobState.Canceled:</span><br/><span>               case JobState.Error:</span><br/><span>                   IJob job = (IJob)sender;</span><br/><span>                   break;</span><br/><span>               default:</span><br/><span>                   break;</span><br/><span>           }</span><br/><span>       }</span></pre>
<ol start="11">
<li>Run the App, and after indexing, you should have a <kbd>WebVtt</kbd> and <kbd>ttml</kbd> file in the <kbd>output</kbd> folder according to the values in the JSON input files. </li>
</ol>
<div class="packt_tip">In this example, we have created closed caption files. You can call other methods for indexing the video as well. The following website provides you with some more examples for the other capabilities that are described earlier: <a href="http://azuremedialabs.azurewebsites.net/demos/Analytics.html">http://azuremedialabs.azurewebsites.net/demos/Analytics.html</a>. </div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we covered how to design solutions using the various AI services that Azure offers. We covered Azure Machine Learning, IoT features, and Azure Media Services.</p>
<p>In the next chapter, we are going to cover the different messaging capabilities that Azure provides and how to design effective messaging architectures.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<p><span>Answer the following questions to test your knowledge of the information in this chapter. You can find the answers in the <em>Assessments</em> section at the end of this book.</span></p>
<ol>
<li>You are designing an IoT Solution using the IoT Hub that needs to process <span>5 million events a day. Does the Standard S1 tier suit your needs?</span>
<ol>
<li>Yes</li>
<li>No</li>
</ol>
</li>
<li>Does Azure Media Services use various Azure Cognitive Services APIs underneath?
<ol>
<li>Yes</li>
<li>No</li>
</ol>
</li>
<li>Should you use Azure Event Hubs in scenario where bi-directional communication between Azure and devices is required?
<ol>
<li>Yes</li>
<li>No</li>
</ol>
</li>
</ol>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<p><span>You can check the following links for more information about the topics that were covered in this chapter:</span></p>
<ul>
<li><strong>Cognitive Services Directory</strong>: <a href="https://azure.microsoft.com/en-us/services/cognitive-services/directory/lang/">https://azure.microsoft.com/en-us/services/cognitive-services/directory/lang/</a></li>
<li><strong>About Bot Service</strong>: <a href="https://docs.microsoft.com/en-us/bot-framework/bot-service-overview-introduction">https://docs.microsoft.com/en-us/bot-framework/bot-service-overview-introduction</a></li>
<li><strong>Introduction to Machine Learning in the Azure Cloud</strong>: <a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio/what-is-machine-learning">https://docs.microsoft.com/en-us/azure/machine-learning/studio/what-is-machine-learning</a></li>
<li><strong>What is Azure Machine Learning Studio?</strong>: <a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio/what-is-ml-studio">https://docs.microsoft.com/en-us/azure/machine-learning/studio/what-is-ml-studio</a></li>
<li><strong>Share and discover resources in the Azure AI Gallery</strong>: <a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio/gallery-how-to-use-contribute-publish">https://docs.microsoft.com/en-us/azure/machine-learning/studio/gallery-how-to-use-contribute-publish</a></li>
<li><strong>Azure Machine Learning WorkBench</strong>: <a href="https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/09/29/azure-machine-learning-workbench/">https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/09/29/azure-machine-learning-workbench/</a></li>
<li><strong>Azure Machine Learning Studio Algorithm and Module Reference</strong>: <a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/index">https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/index</a></li>
<li><strong>Azure IoT Suite</strong>: <a href="https://azure.microsoft.com/en-us/suites/iot-suite/">https://azure.microsoft.com/en-us/suites/iot-suite/</a></li>
<li><strong>Overview of the Azure IoT Hub service</strong>: <a href="https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-what-is-iot-hub">https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-what-is-iot-hub</a></li>
<li><strong>Event Hubs Documentation</strong>: <a href="https://docs.microsoft.com/en-us/azure/event-hubs/">https://docs.microsoft.com/en-us/azure/event-hubs/</a> <a href="https://docs.microsoft.com/en-us/azure/event-hubs/"/></li>
<li><strong>Azure IoT Edge</strong>: <a href="https://docs.microsoft.com/en-us/azure/iot-edge/">https://docs.microsoft.com/en-us/azure/iot-edge/</a></li>
<li><strong>Stream Analytics Documentation</strong>: <a href="https://docs.microsoft.com/en-us/azure/stream-analytics/">https://docs.microsoft.com/en-us/azure/stream-analytics/</a></li>
<li><strong>Azure Time Series Insights</strong>: <a href="https://docs.microsoft.com/en-us/azure/time-series-insights/">https://docs.microsoft.com/en-us/azure/time-series-insights/</a></li>
<li><strong>Media Services Documentation</strong>: <a href="https://docs.microsoft.com/en-us/azure/media-services/">https://docs.microsoft.com/en-us/azure/media-services/</a></li>
</ul>


            </article>

            
        </section>
    </div>



  </body></html>