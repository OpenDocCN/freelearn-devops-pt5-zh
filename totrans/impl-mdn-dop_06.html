<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Server Provisioning</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, you learned how to create the infrastructure that is going to hold our applications. As we saw, the infrastructure automation is something that's new, and we used Terraform for it. The problem with Terraform is that it can only be used to build the infrastructure, but in order to provision the software, we need something different.</p>
<p>Through this chapter, we are going to dive <span>deep</span> into Ansible as, together with Puppet and Chef, it is the most predominant server provisioning tool in the market right now.</p>
<p>Here are the main topics that will be covered in this chapter:</p>
<ul>
<li>Server provisioning software
<ul>
<li>Chef</li>
<li>Puppet</li>
<li>Ansible</li>
</ul>
</li>
<li>Ansible
<ul>
<li>Ansible configuration</li>
<li>Ansible variables
<ul>
<li>Variables</li>
<li>Remote facts</li>
<li>Templates</li>
</ul>
</li>
<li>Flow control</li>
<li>Ansible roles</li>
</ul>
</li>
<li>Ansible tower</li>
</ul>
<p>As you can see, it is quite an extensive chapter with many examples that will enable you to learn the most important features of Ansible.</p>
<p>One thing that you need to be aware while reading through this chapter is the fact that it is impossible to showcase all the features from Ansible in a single chapter. In fairness, it would take us over a book to master all the features up to a proficient level. As you can guess by now, when I need to deal with Ansible, the first thing I do is open the official documentation and have it side by side with the code so that I can always refer to it for examples and features that I have either never dealt with or it has been a long time since I did not work with it.</p>
<p>We will also explore a section Ansible Tower, which is a software used to run Ansible playbooks on a bastion host mode from within your infrastructure instead of running it from a workstation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Server provision software</h1>
                </header>
            
            <article>
                
<p>As mentioned earlier, there are few options for software provisioning. Through this chapter, you will learn how to use Chef and Ansible, focusing on the latter as it is widely used across many companies and is easier to master than Chef.</p>
<p>There are also other options in the market that are valid and good solutions, but we are going to take a special interest in Ansible, which, to me, seems the easiest to learn and extend out of all of them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Chef</h1>
                </header>
            
            <article>
                
<p>Chef is a very interesting software that follows the bastion host principle to run configurations on our servers. A bastion host is a server placed in our private network that is able to reach our servers directly or via proxy in order to execute the actions needed to set them up with the desired state. This is an option not to be overlooked, as one of the biggest challenges that server provisioning presents is the management of secrets and authorization that, for example, Ansible needs to improve via third-party software such as Ansible Tower from Red Hat.</p>
<p>Chef uses recipes to configure parts of the server. A recipe is basically a set of declarative instructions that define what needs to happen in order to get the server to the desired status. For example, take a look at this:</p>
<pre>execute "update-upgrade" do<br/>   command "apt-get update &amp;&amp; apt-get upgrade -y"<br/>   action :run<br/>end<br/><br/>package "apache2" do<br/>   action :install<br/>end</pre>
<p>The preceding code will upgrade our system and then install the Apache2 web server.</p>
<p>This recipe, once finished, gets uploaded into the Chef server from a workstation, and here is the key: in Chef, there are three actors:</p>
<ul>
<li>Server</li>
<li>Workstation</li>
<li>Nodes</li>
</ul>
<p>The server is where the recipes and configuration live. It needs to be installed prior to doing any work, and the instructions can be found at <a href="https://docs.chef.io/install_server.html">https://docs.chef.io/install_server.html</a>.</p>
<p>There are three modalities of the Chef server:</p>
<ul>
<li><strong>Enterprise:</strong> This can be installed inside your infrastructure and it is licensed, so you need to pay depending on the numbers of nodes that it is managing.</li>
<li><strong>Open source:</strong> This can also be installed in your infrastructure but <strong>it does not have any support</strong>. It is free and has to be configured and maintained by your company. It is also a cut-down version of the Enterprise Chef.</li>
<li><strong>Hosted:</strong> The Chef server is hosted on third-party hardware and you don't need to worry about maintaining and upgrading it. It might not be an option depending on the setup of your company.</li>
</ul>
<p>The nodes are the target hosts. Every node is registered in the Chef server and has a run list: a list of recipes that are going to be run on a host when the <kbd>chef-client</kbd> command is executed.</p>
<p>The workstation is the computer used to configure and upload the Chef server. This computer uses a software called knife that can do everything on the Chef server:</p>
<ul>
<li>Configuring roles</li>
<li>Looking for VMs depending on the roles and other parameters</li>
<li>Configuring run lists</li>
<li>Managing secrets</li>
</ul>
<p>Knife uses cryptographic keys to communicate with the Chef server so all the communication happens in a trusted way.</p>
<p>Now, if we want to picture everything, it looks like that is shown in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img height="284" width="266" class="image-border" src="assets/82bdd4ea-1c7d-4309-b637-22350469cded.png"/></div>
<p>As you can see, even though the setup is quite complex (you need to set up a couple of software components) there are obvious benefits: our Chef server is behind the firewall in the demilitarized zone of our infrastructure, but it is managed via a CLI tool so all our secrets and configuration are safe inside our infrastructure.</p>
<p>Chef has a steep learning curve that, once we have gone through the initial learning phase, gets very familiar and easy to add new features and extend the DSL with the power of Ruby and a very well-thought-out interface.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Puppet</h1>
                </header>
            
            <article>
                
<p>Puppet has been around for a while and is widely used in the DevOps world. Puppet comes in two flavors:</p>
<ul>
<li>Open source</li>
<li>Enterprise</li>
</ul>
<p>The open source version comes as is, offering a good set of features that allow you to fully automate the configuration management of your infrastructure.</p>
<p>The enterprise edition, aside from support, comes with an extended set of features that make the life of the engineers in your company a lot easier.</p>
<p>In the same way as Chef, Puppet follows the bastion host architecture: the server is installed within your infrastructure in the demilitarized zone and the nodes (your servers), via the puppet agent, will execute the specified tasks to reach the desired status.</p>
<p>The main difference between Chef and Puppet is the fact that puppet is declarative whereas Chef is more imperative:</p>
<ul>
<li>In Puppet, you specify which state you want your servers on and Puppet takes care of keeping them there</li>
<li>In Chef, you declare a number of steps that will get your server to the desired state</li>
</ul>
<p>That said, Chef also allows you to declare guards, which are conditions for steps to be executed.</p>
<p>Through my experience, I've found that people coming from an DevOps background feel more comfortable with Puppet as it is similar to what they have done through the years, whereas writing Chef recipes is similar to software development.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ansible</h1>
                </header>
            
            <article>
                
<p>Ansible is what we are going to be using to develop the contents of the rest of the book. In my opinion, it is the easiest to learn and extend. It is also easy to understand and offers a fairly comprehensive open source version that works with all the features from Ansible. You can also buy a license of Ansible Tower (or similar) to run Ansible Playbooks in a bastion host configuration as Chef or Puppet.</p>
<p>Ansible is basically a <span><strong>domain-specific language</strong> (<strong>DSL</strong>)</span> for executing operations on remote hosts that are defined in an inventory.</p>
<p>Ansible works by running playbooks in the desired servers via SSH, so unlike Chef or Puppet, we don't need to install anything in the remote hosts; we should just be able to SSH into them. A playbook is basically a <strong>Yet Another Markup Language</strong> (<strong>YAML</strong>) with a set of instructions to get the server into the desired state in the same way as if we were executing a Bash script. A Playbook looks like this:</p>
<pre><strong><span class="nn">---</span></strong><br/><strong><span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">hosts</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">webservers</span></strong><br/><strong>  <span class="l l-Scalar l-Scalar-Plain">vars</span><span class="p p-Indicator">:</span></strong><br/><strong>    <span class="l l-Scalar l-Scalar-Plain">http_port</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span></strong><br/><strong>    <span class="l l-Scalar l-Scalar-Plain">max_clients</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">200</span></strong><br/><strong>  <span class="l l-Scalar l-Scalar-Plain">remote_user</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">root</span></strong><br/><strong>  <span class="l l-Scalar l-Scalar-Plain">tasks</span><span class="p p-Indicator">:</span></strong><br/><strong>  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">ensure apache is at the latest version</span></strong><br/><strong>    <span class="l l-Scalar l-Scalar-Plain">yum</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">name=httpd state=latest</span></strong><br/><strong>  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">write the apache config file</span></strong><br/><strong>    <span class="l l-Scalar l-Scalar-Plain">template</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">src=/srv/httpd.j2 dest=/etc/httpd.conf</span></strong><br/><strong>    <span class="l l-Scalar l-Scalar-Plain">notify</span><span class="p p-Indicator">:</span></strong><br/><strong>    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">restart apache</span></strong><br/><strong>  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">ensure apache is running (and enable it at boot)</span></strong><br/><strong>    <span class="l l-Scalar l-Scalar-Plain">service</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">name=httpd state=started enabled=yes</span></strong><br/><strong>  <span class="l l-Scalar l-Scalar-Plain">handlers</span><span class="p p-Indicator">:</span></strong><br/><strong>    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">restart apache</span></strong><br/><strong>      <span class="l l-Scalar l-Scalar-Plain">service</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">name=httpd state=restarted</span></strong></pre>
<p>Reading through the file will make you understand how easy and straightforward it is to understand what <span>the Playbook</span> doing.</p>
<p>As you can see, in the second line, we are specifying that we want to run this Playbook in the hosts called <kbd>webservers</kbd>. This can be defined in the other part of Ansible: the inventory. The Ansible inventory is basically a file with the list of hosts in your infrastructure, as follows:</p>
<pre><strong><span class="k">[webservers]</span></strong><br/><strong>host1</strong><br/><strong>host2</strong><br/><br/><strong><span class="k">[dbservers]</span></strong><br/><strong>192.168.0.[1:3]</strong></pre>
<p>This file is very straightforward but can get really complicated as well:</p>
<ul>
<li>The names between brackets are groups</li>
<li>The groups contain hosts that can be defined with generators or they can just be listed</li>
<li>Groups can have configuration specific to them or even override variables</li>
</ul>
<p>In the preceding example, we have two groups: <kbd>webservers</kbd> and <kbd>dbservers</kbd>.</p>
<p>Web servers are only two hosts:</p>
<ul>
<li><kbd>Host1</kbd></li>
<li><kbd>Host2</kbd></li>
</ul>
<p>Dbservers use a generator and we have three hosts:</p>
<ul>
<li><kbd>192.168.0.1</kbd></li>
<li><kbd>192.168.0.2</kbd></li>
<li><kbd>192.168.0.3</kbd></li>
</ul>
<p>As mentioned earlier, we can also define variables in the inventory. These variables can be scoped on the group and the host. Let's take a look at the following inventory:</p>
<pre><strong>[dbservers]</strong><br/><strong>192.168.0.[1:3]</strong><br/><br/><strong>[webservers]</strong><br/><strong>host1 role=master</strong><br/><strong>host2</strong><br/><br/><strong>[dbservers:vars]</strong><br/><strong>timezone=utc</strong></pre>
<p>As you can see, we have two variables:</p>
<ul>
<li><kbd>timezone</kbd>: This is applied to all the hosts of the group <kbd>dbservers</kbd>.</li>
<li><kbd>role</kbd>: This is applied to the host <kbd>host1</kbd> of the group <kbd>webservers</kbd><em>.</em></li>
</ul>
<p>This variable can be used in <kbd>playbooks</kbd> in order to have a specific configuration for specific hosts, as we will see later on in this chapter.</p>
<p>Groups can also be combined into bigger groups:</p>
<pre>[dbservers]<br/>192.168.0.[1:3]<br/><br/>[webservers]<br/>host1<br/>host2<br/><br/>[mongoservers]<br/>10.0.0.1<br/>10.0.0.2<br/><br/>[dataservers:child]<br/>mongoservers<br/>dbservers</pre>
<p>In the preceding inventory, we can find the following:</p>
<ul>
<li><kbd>dbservers</kbd></li>
<li><kbd>mongoservers</kbd></li>
<li><kbd>webservers</kbd></li>
<li><kbd>dataservers</kbd></li>
<li><kbd>all</kbd></li>
<li><kbd>ungrouped</kbd></li>
</ul>
<p>Even though we did not specify it, Ansible always has two default groups called <kbd>all</kbd> and <kbd>ungrouped</kbd> that are self-descriptive: <kbd>all</kbd> is all the hosts in the inventory and <kbd>ungrouped</kbd> is all the hosts that are not specified in any group.</p>
<p>As stated earlier, Ansible does not follow the bastion host architecture as Chef or Puppet, but it follows the client/server architecture: our host needs to be able to reach the destination hosts (the ones on the inventory) in order to work.</p>
<p>This can be inconvenient depending on your infrastructure architecture, but it can be worked around using Ansible Tower or Rundeck to execute Ansible playbooks from inside your demilitarized zone.</p>
<p>In this chapter, we are going to use Ansible to build real production-ready examples in combination with Terraform so that we get a grasp of the real usage of the tools.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ansible</h1>
                </header>
            
            <article>
                
<p>In this section, we are going to take our first steps toward a more comprehensive example in Ansible. For now, we are going to install and configure NGINX, a very popular web server so we can showcase the main concepts of Ansible.</p>
<p>First, we are going to create a VM in Google Cloud Platform with an associated static IP so we can target it from our inventory. We are going to use Terraform in order to do it. First, we'll look at our resources file:</p>
<div>
<pre><span>provider</span><span> </span><span>"google"</span><span> </span><span>{<br/></span><span>  </span><span>credentials</span><span> </span><span>= </span><span>"</span><span>${</span><span>file(</span><span>"account.json"</span><span>)</span><span>}</span><span>"<br/></span><span>  </span><span>project</span><span> </span><span>=</span><span> </span><span>"</span><span>${</span><span>var.project_name</span><span>}</span><span>"<br/></span><span>  </span><span>region</span><span> </span><span>=</span><span> </span><span>"</span><span>${</span><span>var.default_region</span><span>}</span><span>"<br/></span><span>}<br/><br/></span><span>resource</span><span> </span><span>"google_compute_instance"<br/></span><span>"nginx"</span><span> </span><span>{<br/></span><span>  </span><span>name</span><span> </span><span>=</span><span> </span><span>"nginx"<br/></span><span>  </span><span>machine_type</span><span> </span><span>=</span><span> </span><span>"n1-standard-1"<br/></span><span>  </span><span>zone</span><span> </span><span>=</span><span> </span><span>"europe-west1-b"<br/></span><span>  disk </span><span>{<br/></span><span>   </span><span>image</span><span> </span><span>=</span><span> </span><span>"ubuntu-os-cloud/ubuntu-1704-zesty-v20170413"<br/></span><span>  }<br/></span><span>  network_interface </span><span>{<br/></span><span>    </span><span>network</span><span> </span><span>=</span><span> </span><span>"default"<br/></span><span>    access_config </span><span>{<br/></span><span>      </span><span>nat_ip</span><span> </span><span>= </span><span>"</span><span>${google_compute_address</span><span>.</span><span>nginx-ip</span><span>.</span><span>address}</span><span>"<br/></span><span>    }<br/></span><span>  }<br/></span><span>}<br/><br/></span><span>resource</span><span> </span><span>"google_compute_address"</span><span> </span><span>"nginx-ip"</span><span> </span><span>{<br/></span><span>  </span><span>name</span><span> </span><span>=</span><span> </span><span>"nginx-ip"<br/></span><span>}</span></pre>
<p>And now, we'll look at our vars file:</p>
<div>
<pre><span>variable</span><span> </span><span>"project_name"</span><span> </span><span>{<br/></span><span>  </span><span>type</span><span> </span><span>=</span><span> </span><span>"string"<br/></span><span>  default</span><span> </span><span>=</span><span> </span><span>"implementing-modern-devops"<br/></span><span>}<br/><br/></span><span>variable</span><span> </span><span>"default_region"</span><span> </span><span>{<br/></span><span>  type</span><span> </span><span>=</span><span> </span><span>"string"<br/></span><span>  default</span><span> </span><span>=</span><span> </span><span>"europe-west1"<br/></span><span>}</span></pre>
<p>In this case, we are reusing the project from the previous chapter as it is convenient to shut down everything once we are done. Now we run our plan so we can see what resources are going to be created:</p>
<pre>+ google_compute_address.nginx-ip<br/> address: "&lt;computed&gt;"<br/> name: "nginx-ip"<br/> self_link: "&lt;computed&gt;"<br/><br/>+ google_compute_instance.nginx<br/> can_ip_forward: "false"<br/> disk.#: "1"<br/> disk.0.auto_delete: "true"<br/> disk.0.image: "ubuntu-os-cloud/ubuntu-1704-zesty-v20170413"<br/> machine_type: "n1-standard-1"<br/> metadata_fingerprint: "&lt;computed&gt;"<br/> name: "nginx"<br/> network_interface.#: "1"<br/> network_interface.0.access_config.#: "1"<br/> network_interface.0.access_config.0.assigned_nat_ip: "&lt;computed&gt;"<br/> network_interface.0.access_config.0.nat_ip: "&lt;computed&gt;"<br/> network_interface.0.address: "&lt;computed&gt;"<br/> network_interface.0.name: "&lt;computed&gt;"<br/> network_interface.0.network: "default"<br/> self_link: "&lt;computed&gt;"<br/> tags_fingerprint: "&lt;computed&gt;"<br/> zone: "europe-west1-b"<br/><br/><br/>Plan: 2 to add, 0 to change, 0 to destroy.</pre></div>
<p>So far, everything looks right. We are creating two resources:</p>
<ul>
<li>
<p>The static IP</p>
</li>
<li>
<p>The VM</p>
</li>
</ul>
<p>Now, we can apply our infrastructure:</p>
<pre>google_compute_address.nginx-ip: Creating...<br/> address: "" =&gt; "&lt;computed&gt;"<br/> name: "" =&gt; "nginx-ip"<br/> self_link: "" =&gt; "&lt;computed&gt;"<br/>google_compute_address.nginx-ip: Still creating... (10s elapsed)<br/>google_compute_address.nginx-ip: Creation complete<br/>google_compute_instance.nginx: Creating...<br/> can_ip_forward: "" =&gt; "false"<br/> disk.#: "" =&gt; "1"<br/> disk.0.auto_delete: "" =&gt; "true"<br/> disk.0.image: "" =&gt; "ubuntu-os-cloud/ubuntu-1704-zesty-v20170413"<br/> machine_type: "" =&gt; "n1-standard-1"<br/> metadata_fingerprint: "" =&gt; "&lt;computed&gt;"<br/> name: "" =&gt; "nginx"<br/> network_interface.#: "" =&gt; "1"<br/> network_interface.0.access_config.#: "" =&gt; "1"<br/> network_interface.0.access_config.0.assigned_nat_ip: "" =&gt; "&lt;computed&gt;"<br/> network_interface.0.access_config.0.nat_ip: "" =&gt; "35.187.81.127"<br/> network_interface.0.address: "" =&gt; "&lt;computed&gt;"<br/> network_interface.0.name: "" =&gt; "&lt;computed&gt;"<br/> network_interface.0.network: "" =&gt; "default"<br/> self_link: "" =&gt; "&lt;computed&gt;"<br/> tags_fingerprint: "" =&gt; "&lt;computed&gt;"<br/> zone: "" =&gt; "europe-west1-b"<br/>google_compute_instance.nginx: Still creating... (10s elapsed)<br/>google_compute_instance.nginx: Still creating... (20s elapsed)<br/>google_compute_instance.nginx: Creation complete<br/><br/>Apply complete! Resources: 2 added, 0 changed, 0 destroyed.</pre></div>
<p>And everything works as expected. If we check Google Cloud Platform, we can see that our VM has been created and has associated a public IP:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/53521020-4335-4113-aae4-c560054b691c.png"/></div>
<p>In this case, the associated public IP is <kbd>35.187.81.127</kbd>. It is important to verify that we can reach the server via SSH. In order to do it, just click on the <span class="packt_screen">SSH</span> button on the right-hand side of your instance row and it should open a Cloud Console window with terminal access.</p>
<div class="packt_tip">If SSH access fails, you need to add an ingress allow rule in the firewall to the port <kbd>22</kbd>. For this example, just allow the traffic from any IP into any port, but don't do this in your real infrastructure as it is a security threat.</div>
<p>Once everything is up and running, it is time to start with Ansible. First, we are going to create our inventory file:</p>
<pre><strong>[nginx-servers]</strong><br/><strong>35.187.81.127</strong></pre>
<p>This is very simple: a group with our public IP address that is connected to our VM. Save the file with the name <kbd>inventory</kbd> in a new folder named, for example, <kbd>ansible-nginx</kbd>. Once the inventory is created, we need to verify that all the hosts can be reached. Ansible provides you the tool to do that:</p>
<pre><strong>ansible -i inventory all -m ping</strong></pre>
<p>If you execute the preceding command, Ansible will <kbd>ping</kbd> (actually, it does not use the ping command but tries to issue a connection to the server) all the hosts in your inventory specified in the parameter <kbd>-i</kbd>. If you change everything for the name of a group, Ansible will try to reach only the hosts in that group.</p>
<p>Let's take a look at the output of the command:</p>
<pre>35.187.81.127 | UNREACHABLE! =&gt; {<br/> "changed": false,<br/> "msg": "Failed to connect to the host via ssh: Permission denied (publickey).\r\n",<br/> "unreachable": true<br/>}</pre>
<p>We are experiencing problems in connecting to our remote host and the cause is that we don't have any key that the host can validate to verify our identity. This is expected as we did not configure it, but now, we are going to solve it by creating a key pair and installing it on the remote host using the Google Cloud SDK:</p>
<pre><strong>gcloud compute ssh nginx</strong></pre>
<p>This command will do three things:</p>
<ul>
<li>Generate a new key pair</li>
<li>Install the key pair in our remote VM</li>
<li>Open a shell in our VM in GCP</li>
</ul>
<p>The new key generated can be found under <kbd>~/.ssh/</kbd> with the name <kbd>google_compute_engine and google_compute_engine.pub</kbd> (private and public key).</p>
<p>Once the command finishes, our shell should look like this:</p>
<div class="CDPAlignCenter CDPAlign"><img height="373" width="525" class="image-border" src="assets/1dc53067-fb7b-4dc8-a40c-995e3a8d1bdd.png"/></div>
<p>Now we have a terminal connected to our VM and we can execute commands. <kbd>gcloud</kbd> configures a user <span>by default;</span> in my case, <kbd>davidgonzalez</kbd> that can use <kbd>sudo</kbd> without password. In this case, we are going to execute the playbook as the root, so we need to be able to login as root into the VM. Copy the file <kbd>~/.ssh/authorized_keys</kbd> into <kbd>/root/.ssh/authorized_keys</kbd> and we should be able to do it. So, we have copied the public key that we generated earlier to the set of authorized keys of the root user.</p>
<div class="packt_tip">In general, root access should be avoided as much as possible, but in this case, we will be executing the playbook as the root for convenience.</div>
<p>In order for Ansible to be able to use the key, we need to add it to the daemon on our server:</p>
<pre><strong>ssh-add ~/.ssh/google_compute_engine</strong></pre>
<p>This command should output the success, stating that the identity was added.</p>
<p>Now we can run our pin command again:</p>
<pre><strong>ansible -i inventory all -m ping</strong></pre>
<p>The output should be very different:</p>
<pre>35.187.81.127 | SUCCESS =&gt; {<br/> "changed": false,<br/> "ping": "pong"<br/>}</pre>
<p>This means that now, Ansible is able to reach our server; therefore, it will be able to execute the playbook against it.</p>
<p>Now it is time to start writing our first <kbd>ansible</kbd> playbook. Inside the same folder, <kbd>ansible-nginx</kbd>, create a file called <kbd>tasks.yml</kbd> with the following content:</p>
<pre><strong>---</strong><br/><strong>- hosts: all</strong><br/><strong> user: root</strong><br/><strong> tasks:</strong><br/><strong> - name: Update sources</strong><br/><strong>   apt:</strong><br/><strong>     update_cache: yes</strong><br/><strong> - name: Upgrade all packages</strong><br/><strong>   apt:</strong><br/><strong>     upgrade: dist</strong></pre>
<p>This is simple to understand:</p>
<ul>
<li>Our playbook is going to affect all the hosts</li>
<li>The user running the playbook is going to be root</li>
<li>And then we are going to execute two tasks:
<ul>
<li>Update the <kbd>apt cache</kbd></li>
<li>Upgrade all the packages</li>
</ul>
</li>
</ul>
<p>Once we have the two files (inventory and playbook), we can run the following command:</p>
<pre><strong>ansible-playbook -i inventory tasks.yml</strong></pre>
<p>We should produce output similar to the following one:</p>
<div class="CDPAlignCenter CDPAlign"><img height="258" width="440" src="assets/b8be2660-7d43-42ad-a448-bcad349dae1c.png"/></div>
<div class="packt_tip">We are going to run few playbooks along the chapter, so I would recommend that you keep the same VM alive and run all of them against it in order to save time and resources. The trial account from Google Cloud Platform will give you enough room to run them across several days or weeks.</div>
<p>Let's explain the output:</p>
<ul>
<li>First, it specifies against which group we are going to execute the playbook. In this case, we specified that the group is <kbd>all</kbd>.</li>
<li>Then, we can see three tasks being executed. As you can see, the description matches the description specified in <kbd>tasks.yml</kbd>. This is very helpful in order to understand the output of your playbooks, especially when they fail.</li>
<li>And then we get a recap:
<ul>
<li>Three tasks were executed</li>
<li>Two of them produced changes on the server</li>
<li>Zero failed</li>
</ul>
</li>
</ul>
<p>Simple and effective. This is the closest to executing a script in the server that we can get: a set of instructions, a target host, and its output.</p>
<p>In Ansible, instead of plain bash instructions, the actions are encapsulated into modules. A module is a component of the DSL, which allows you to do something special. In the playbook from earlier, apt is a module included in the core of Ansible. Documentation for it can be found at <a href="http://docs.ansible.com/ansible/apt_module.html">http://docs.ansible.com/ansible/apt_module.html</a>.</p>
<p>Let's take another look to one of our usages of the <kbd>apt</kbd> module:</p>
<pre><strong>- name: Update sources</strong><br/><strong>  apt:</strong><br/><strong>    update_cache: yes</strong></pre>
<p>This, as you can guess, would be the equivalent to the following:</p>
<pre><strong>apt-cache update</strong></pre>
<p>So, in this case, Ansible provide us with a different module called command, which allows us to execute commands in the hosts of our inventory. Take a look at the following <kbd>yaml</kbd>:</p>
<pre><strong>- name: Update sources</strong><br/><strong>  command: apt-cache update</strong></pre>
<p>This is equivalent to the <kbd>yaml</kbd> from earlier, and both do the same: update <kbd>apt-cache</kbd>.</p>
<p>In general, if there is a module for a given task, it is recommended that you use it as it will handle (or at least you can expect it to) the errors and the outputs better than executing the equivalent command.</p>
<p>Now, once our playbook has succeeded, we can expect our system to be up to date. You can check it by running the playbook again:</p>
<div class="CDPAlignCenter CDPAlign"><img height="236" width="426" src="assets/277e8ee6-2d9a-46e6-9e09-adb4f360b02f.png"/></div>
<p>Now you can see that only one task has produced changes in the server (updating the apt sources).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ansible configuration</h1>
                </header>
            
            <article>
                
<p>One of the features of Ansible is the ability to override the defaults per project. In order to do it that, we just need to create a file called <kbd>ansible.cfg</kbd> in the root of our project and Ansible will read it and apply the configuration.</p>
<p>There is a big number of parameters that can be configured, and all of them can be found in the official documentation at <a href="http://docs.ansible.com/ansible/intro_configuration.html">http://docs.ansible.com/ansible/intro_configuration.html</a>.</p>
<p>As you can see, the documentation for Ansible is quite good, and the majority of the time, it will provide an answer to your problems.</p>
<p>Let's see how the configuration can help us. If you remember from the previous example, we have specified the flag <kbd>-i</kbd> in order to tell Ansible where our inventory file lives. Ansible has a default for this value, which is <kbd>/etc/ansible/hosts</kbd>. In our little project, our inventory is in the same folder as our code, and in order to specify it to Ansible, we need to create a configuration file with the following content:</p>
<pre><strong>[defaults]</strong><br/><strong>inventory = ./inventory</strong></pre>
<p>Now, we run our <kbd>playbook</kbd> again with the following command:</p>
<pre><strong>ansible-playbook tasks.yml</strong></pre>
<p>We did not specify the host list, but Ansible, after reading <kbd>ansible.cfg</kbd> knows that the inventory file can be located at <kbd>./inventory</kbd>.</p>
<p>Ansible has a hierarchy of precedence to find the configuration:</p>
<ul>
<li>The <kbd>ANSIBLE_CONFIG</kbd> environment variable</li>
<li><kbd>ansible.cfg</kbd></li>
<li><kbd>.ansible.cfg</kbd></li>
<li><kbd>/etc/ansible/ansible.cfg</kbd></li>
</ul>
<p>So, if we define an environment variable called <kbd>ANSIBLE_CONFIG</kbd> pointing to a file, the Ansible configuration will be read from that location and the rest of the options will be ignored. This is particularly helpful in segregating environments: our CI server can define its own configuration in the environment file, whereas developers can have the <kbd>ansible.cfg</kbd> file checked in into the source control so that is shared across everyone.</p>
<p>There are a few sections that can be specified in <kbd>ansible.cfg</kbd>. Sections control several aspects of of Ansible, such as connections. Under certain circumstances, we might need to add special parameters for <kbd>ssh</kbd> to work, and it is as easy as adding the following lines to your <kbd>ansible.cfg</kbd> file:</p>
<pre><strong>[ssh_connection]<br/>ssh_args=&lt;your args here&gt;</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ansible variables, remote facts and templates</h1>
                </header>
            
            <article>
                
<p>Variables and templates are an important part of Ansible. They allow us to override values in our configuration (servers and playbooks) so that we can write generic playbooks that can be reused across different configurations with minor tweaks. With templates, we can render configuration files from our host so we could potentially use Ansible to manage the configuration of remote servers with little to no effort. It also can be used to generate and install SSL certificates for different hosts transparently to the user.</p>
<p>Both of them (variables and templates) use a template engine called Jinja2, which allows logic and interpolation to be embedded in our configurations.</p>
<p>In general, there are several ways of defining variables, but we are only going to visit the most common ones (under my criteria), as otherwise, it would take us the size of several chapters to document them properly. If you want to explore further different ways of defining variables, the official documentation provides a fairly comprehensive guide at <a href="http://docs.ansible.com/ansible/playbooks_variables.html">http://docs.ansible.com/ansible/playbooks_variables.html</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ansible variables</h1>
                </header>
            
            <article>
                
<p>Variables are the most simple of the potential customizations. With variables, we can define values that are going to be replaced in our playbooks. Let's take a look at the following playbook:</p>
<div>
<div>
<div>
<pre><span>---<br/></span><span>- </span><span>hosts</span><span>: </span><span>all<br/></span><span>  user</span><span>: </span><span>root<br/></span><span>  tasks</span><span>:<br/></span><span>  - </span><span>debug</span><span>:<br/></span><span>    msg</span><span>: </span><span>"Hello {{ myName }}! I am {{ inventory_hostname }}"</span></pre></div>
</div>
</div>
<p>Replace the content of <kbd>tasks.yml</kbd> with the snippet from earlier. There are two new symbols in our task. Also, our task is new: debug is used to output values from our variables into the terminal while executing the playbook. Let's take a look at the execution (we will use the same configuration as the example from earlier):</p>
<pre><strong>ansible-playbook -i inventory tasks.yml</strong></pre>
<p>It fails:</p>
<div class="CDPAlignCenter CDPAlign"><img height="351" width="682" src="assets/fec26755-e784-48b5-8948-6cfbcb096ab7.png"/></div>
<p>The reason for the failure can be seen in in the message: we have a variable defined called <kbd>name</kbd> that does not have a value associated. Ansible will fail if there is a value that cannot be interpolated, aborting the execution of the task.</p>
<p>There is another interesting piece of information here: Ansible gives you a parameter to retry the playbook only on the hosts that were not successful. If we wanted to retry the playbook only on the failed hosts, we could run the following command:</p>
<pre><strong>ansible-playbook -i inventory tasks.yml --limit @/Users/dgonzalez/code/ansible-variables/tasks.retry</strong></pre>
<p>The new parameter, <kbd>tasks.retry</kbd> is a file with a list of hosts that are okay to rerun the playlist as they failed before.</p>
<p>Going back to our missing variables, we need to define the variable called <kbd>myName</kbd>. There are a few ways of doing that; the first is via the command line:</p>
<pre><strong>ansible-playbook -i inventory tasks.yml -e myName=David</strong></pre>
<p>And you can see that the output of the playbook is looking better now:</p>
<div class="CDPAlignCenter CDPAlign"><img height="224" width="372" src="assets/0cfc28ac-bc49-4244-8166-417cdb1f7d49.png"/></div>
<p>As you can see, the variables got interpolated and we can see the message <kbd>Hello David! I am 35.187.81.127</kbd>.</p>
<p>The second way of defining variables is via inventory, as we have seen earlier:</p>
<pre><strong>[nginx-servers]</strong><br/><strong>35.187.81.127 myName=DavidInventory</strong></pre>
<p>If we modify our inventory to match the preceding snippet, the value of our variable will be <kbd>DavidInventory</kbd> and we don't need to pass a value in the command line:</p>
<pre><strong>ansible-playbook -i inventory tasks.yml</strong></pre>
<p>This will produce the message <span><kbd>Hello DavidInventory! I am 35.187.81.127</kbd>.</span></p>
<p>The third way to define variables in Ansible is by defining them in the playbook itself. Take a look at the following playbook:</p>
<pre>---<br/>- hosts: all<br/> vars:<br/> myName: David<br/> user: root<br/> tasks:<br/> - debug:<br/> msg: "Hello {{ myName }}! I am {{ inventory_hostname }}"</pre>
<p>As simple as it sounds, once you define the variable in the <kbd>vars</kbd> <span>section</span> of your playbook, it becomes available; therefore, there is no need to specify the value anywhere else.</p>
<p>The fourth way to define variables is via files. Ansible is designed to be a self-documented component that can be easily understood by someone with not much experience in it. One of the ways in which Ansible facilitates the task of understanding playbooks is the possibility of writing every single configuration piece in a file. Variables are not the exemption, so Ansible will let you define variables in files or playbooks.</p>
<p>Let's start with the files. Create a file called <kbd>vars.yml</kbd> in the same folder in which you are working (where your playbook and inventory are) with the following content:</p>
<pre><strong>myName: DavidFromFile</strong><br/><strong>yourName: ReaderFromFile</strong></pre>
<p>Now we can run the following command in order to use the variables file:</p>
<pre><strong>ansible-playbook -i inventory playbook.yml -e @vars.yml</strong></pre>
<p>And if you check the output, it would be the same as the one from earlier.</p>
<p>In this case, we have defined a new variable that we are not using (<kbd>yourName</kbd>), but that is fine. I just wanted to show you that Ansible won't complain if there are free variables, but it will raise an error if there are unbound interpolations.</p>
<p>In this case, we have included <kbd>vars.yml</kbd> in our playbook via the command line, referencing your local file with <kbd>@</kbd> in the beginning, but there is another possibility for using variable files in Ansible: including them from within the playbook. Let's take a look at how it is done:</p>
<pre>---<br/>- hosts: all<br/> user: root<br/> tasks:<br/> - name: Include vars<br/> include_vars:<br/> file: vars.yml<br/> - debug:<br/> msg: "Hello {{ myName }}! I am {{ inventory_hostname }}"</pre>
<p>In this case, we have used the <kbd>include_vars</kbd> module in our playbook. Now execute the playbook with the following command:</p>
<pre><strong>ansible-playbook -i inventory tasks.yml</strong></pre>
<p>You will get the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img height="300" width="459" src="assets/11991723-9f2a-4980-98fb-f6932730d6da.png"/></div>
<p>As you can see, there is an extra task that takes a file and injects the variables in the context.</p>
<p>This module is quite flexible and there are several options to include variable files in our playbook. We have used the most straightforward one, but you can check out other options in the official documentation at <a href="http://docs.ansible.com/ansible/include_vars_module.html">http://docs.ansible.com/ansible/include_vars_module.html</a>.</p>
<p>There is another possibility for including a variable file into our playbook, and it is using the <kbd>vars_files</kbd> <span>directive</span> in our playbook:</p>
<pre>---<br/>- hosts: all<br/> user: root<br/> vars_files:<br/> - vars.yml<br/> tasks:<br/> - debug:<br/> msg: "Hello {{ myName }}! I am {{ inventory_hostname }}"</pre>
<p>This will take the <kbd>vars.yml</kbd> <span>file</span> and inject all the defined variables into the context, making them available for use.</p>
<p>As you can see, Ansible is quite flexible around the definition of <span>variables</span>.</p>
<p>There is another interesting way of setting up variables in Ansible that helps us further customize our playbooks: <kbd>set_fact</kbd>. Setting facts allows us to set variables dynamically in our playbooks. <kbd>Set_fact</kbd> can be used in combination with another interesting instruction called register. Let's look at an example:</p>
<pre>---<br/>- hosts: all<br/> user: root<br/> tasks:<br/> - name: list configuration folder<br/> command: ls /app/config/<br/> register: contents<br/> - set_fact:<br/> is_config_empty: contents.stdout == ""<br/> - name: check if folder is empty<br/> debug: msg="config folder is empty"<br/> when: is_config_empty<br/> - name: installing configuration<br/> command: &lt;your command here&gt;<br/> when: is_config_empty</pre>
<p>What we are doing here is basically setting a variable to true if the configuration folder of our app is empty (hypothetic configuration folder) so that we can regenerate it only when it is not present. This is done by making use of the instruction when that allows us to execute instructions conditionally. We will come back to it during this chapter.</p>
<p>We have visited the most common ways of defining variables, but there is one question pending: what is the precedence of the different methods for creating variables?</p>
<p>This is something that I have to query myself whenever I am working in a playbook, and the truth is that at the end of the day, you will use only a couple of methods to create variables so that it is not as important as it should be. In my case, I tend to create a file with variables (when not working with roles), and if I want to override a value, I do that on the command line (or environment variable), which is the highest priority in the chain. The complete list of variable precedence can be found at <a href="http://docs.ansible.com/ansible/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable">http://docs.ansible.com/ansible/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ansible remote facts</h1>
                </header>
            
            <article>
                
<p>Remote facts in Ansible are a way to specify configuration on remote hosts either by an explicit configuration file or by a script that returns data about the server. In general, this feature is very useful for operations such as maintenance, setting up flags that specifically mark the host as out of the pool so that our playbooks have no effect in the hosts.</p>
<p>Take a look at the following command (assuming the inventory from the previous example is present in the folder and the VM is running on Google Cloud Platform):</p>
<pre><strong>ansible all -m setup -i inventory --user=root</strong></pre>
<p>This will output an enormous amount of data (JSON-formatted data). This data is all the known facts about the remote host, such as the CPU type, machine ID, network interfaces, kernel version, and so on. They can be used within our playbooks, but they can also be extended to add more data that is controlled by the remote host without any local configuration.</p>
<p>In order to set up custom remote facts, we have several options, but at the end of the day, the custom facts are defined in JSON files by default under <kbd>/etc/ansible/facts.d/</kbd>. It is also possible to create an executable (a script) under the same folder so that Ansible will execute it and take the output as facts and add them to the facts scope. Take a look at the following file:</p>
<pre>{<br/> "my_name": "David Gonzalez"<br/> }</pre>
<p>Put into the remote box (the one used in all the examples from earlier) and create a file in <kbd>/etc/ansible/facts.d/example.facts</kbd> with the content from earlier<em>.</em></p>
<p>Once this is done, run the following command:</p>
<pre><strong>ansible all -m setup -i inventory --user=root | grep -B 3 -A 3 my_name</strong></pre>
<p>It almost looks magical, but the output of your command should now include the facts that you created earlier:</p>
<pre> },<br/> "ansible_local": {<br/> "example": {<br/> "my_name": "David Gonzalez"<br/> }<br/> },<br/> "ansible_lsb": {</pre>
<p>Now they can be used in your playbook in the <kbd>ansible_local</kbd> variable, for example, to access <kbd>my_name</kbd><em>:</em></p>
<pre>---<br/>- hosts: all<br/> user: root<br/> tasks:<br/> - name: Gather my_name fact.<br/> debug: msg="{{ ansible_local.example.my_name }}"</pre>
<p>As mentioned earlier, Ansible can also gather facts from a script placed in the facts path. This script should have the <kbd>x</kbd> <span>flag</span> present, which indicates that it can be executed and have the extension <kbd>fact</kbd>. Let's look at a very interesting trick that I find quite useful. When I try to diagnose a failure in our systems, the first thing I tend to check is the CPU usage. The majority of the time, our systems are highly observable (monitored) so it is easy to check the CPU load, but sometimes, monitoring might not be in place.</p>
<p>First, go to the server that we have been using in the preceding examples and create a file in <kbd>/etc/ansible/facts.d/cpuload.fact</kbd> with the following content:</p>
<pre>#!/bin/bash<br/>CPU_LOAD=`grep 'cpu ' /proc/stat | awk '{usage=($2+$4)*100/($2+$4+$5)} END {print usage "%"}'`<br/>echo { \"cpu_load\": \"$CPU_LOAD\"}</pre>
<p>This is a simple script that will output JSON with information about the CPU load in your system. Once the file is created, give it execution permissions:</p>
<p><kbd>chmod u+x /etc/ansible/facts.d/cpuload.fact</kbd></p>
<p>And we are done. Before disconnecting the SSH session, make sure that the script works as expected by executing it:</p>
<pre>/etc/ansible/facts.d/cpuload.fact</pre>
<p>This should output something like the following:</p>
<pre>{ "cpu_load": "0.0509883%"}</pre>
<p>Now it is time to test our scripted facts. What we are going to do is create a playbook that gets the CPU load and outputs it to the terminal with a debug message. This is the content:</p>
<pre>- hosts: all<br/> user: root<br/> tasks:<br/> - name: Get CPU load<br/> debug: msg="The CPU load for {{ ansible_hostname }} is {{ ansible_local.cpuload.cpu_load }}"</pre>
<p>Run the preceding playbook:</p>
<pre><strong>ansible-playbook -i inventory tasks.yml</strong></pre>
<p>You should get an output very similar to the following one:</p>
<div class="CDPAlignCenter CDPAlign"><img height="282" width="491" src="assets/5b4ec6b5-a321-4c38-b1f7-b98547d4afa4.png"/></div>
<p>Now we have a rudimentary tool to check the CPU load on our servers with a simple command, leveraging the host groups to Ansible.</p>
<p>One thing we have not explained is the first task that Ansible outputs in every playbook: gathering facts.</p>
<p>This task gets all those facts that we have been talking about in this section and creates the context for the playbook to run, so in this case, the CPU load that we get is the CPU load gathered at the execution of that task.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ansible templates</h1>
                </header>
            
            <article>
                
<p>Templates are another powerful tool from Ansible. They allow us to render configuration files, application properties, and anything that can be stored in a human readable file.</p>
<p>Templates rely heavily on variables and a template engine called Jinja2 , which is used by Ansible to render the templates. First, we are going to install <kbd>ngnix</kbd> on our server with a simple playbook:</p>
<pre>---<br/>- hosts: all<br/> user: root<br/> tasks:<br/> - name: Update sources<br/> apt:<br/> update_cache: yes<br/> - name: Upgrade all packages<br/> apt:<br/> upgrade: dist<br/> - name: Install nginx<br/> apt:<br/> name: nginx<br/> state: present</pre>
<div>As you can see, it is very simple:</div>
<ul>
<li>Update the <kbd>apt cache</kbd></li>
<li>Upgrade the system</li>
<li>Install <kbd>nginx</kbd></li>
</ul>
<p>Now, just run the preceding playbook using the VM created earlier:</p>
<p><kbd>ansible-playbook -i inventory tasks.yaml</kbd></p>
<p>And when the playbook is finished, you should have <kbd>nginx</kbd> running in your remote server. In order to verify it, just open the browser and use the IP of your VM as URL. You should see the <kbd>nginx</kbd> welcome screen.</p>
<p>Now, we are going to create a template with the <kbd>nginx</kbd> configuration, where we can add or remove servers with templates in a fairly easy manner. Create a folder called <kbd>nginx-servers</kbd> in your current directory (where the playbook is) and add a file called <kbd>nginx.yml</kbd> with the following content:</p>
<pre>---<br/>- hosts: all<br/> user: root<br/> vars_files:<br/> <strong>- vars.yml</strong><br/> tasks:<br/> - name: Update sources<br/> apt:<br/> update_cache: yes<br/> - name: Upgrade all packages<br/> apt:<br/> upgrade: dist<br/> - name: Install nginx<br/> apt:<br/> name: nginx<br/> state: present<br/> - template:<br/> src: nginx-servers/nginx-one.conf.j2<br/> dest: /etc/nginx/sites-enabled/default<br/> owner: root<br/> - service:<br/> name: nginx<br/> state: reloaded</pre>
<p>Let's explain the file a bit:</p>
<ul>
<li>The system is upgraded using <kbd>apt</kbd>.</li>
<li>Using apt as well, <kbd>nginx</kbd> is installed. Note that Ansible uses a declarative approach to install packages: you state the name of the package and the state that the package should be in after the playbook is executed.</li>
<li>The playbook renders the configuration for a virtual server in <kbd>nginx</kbd> from a template called <kbd>nginx-one.conf.j2</kbd>. We will come back to this in a second.</li>
<li>The playbook reloads the <kbd>nginx</kbd> service so that the new configuration takes effect.</li>
</ul>
<p>We have a few blocks missing in the preceding playbook. The first block is the file called <kbd>nginx-one.conf.j2</kbd>. This file is a template that is used to render the <kbd>nginx</kbd> configuration for a virtual host in the server. Let's look at the content of that file:</p>
<pre>server {<br/>   listen {{ server_one_port }} default_server;<br/>   index index.html;<br/>}</pre>
<p>Create a folder called <kbd>sites-enabled</kbd> and add the <kbd>nginx-one.conf.j2</kbd> <span>file</span> to it with the preceding content. This file is a standard <kbd>nginx</kbd> server block but with one particularity: we have a <em>server_one_port</em> as a placeholder for the port so that we can control the port where the <kbd>nginx</kbd> virtual host is exposed. This is very familiar to us: we are using the variables to render the templates.</p>
<p>The second block is the file called <kbd>vars.yml ()</kbd> with the following content:</p>
<pre><strong>server_one_port: 3000</strong></pre>
<p>This is very simple: it just defines the variables required to render the template from earlier. One thing that you need to be aware when using templates is that all the variables in the context can be accessed in it, from the facts gathered from the remote server to the variables defined everywhere.</p>
<p>Once we have everything in place (the two files from earlier, the playbook from earlier, and the inventory from the previous example), we can run the playbook as usual and verify that everything works as expected:</p>
<pre><strong>ansible-playbook -i inventory nginx.yml</strong></pre>
<p>If everything worked as expected, you should have a fully functional <kbd>nginx</kbd> server (serving the default page) in your VM in Google Cloud Platform on the port <kbd>3000</kbd>.</p>
<div class="packt_tip packt_infobox">Google Cloud Platform has a deny by default policy in order to enhance security, so you might need to adjust the firewall to allow inbound traffic to certain ports.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Flow control</h1>
                </header>
            
            <article>
                
<p>In Ansible, it is possible to use flow control statements such as loops or conditionals using variables as input. This can be used to repeat tasks on a certain dataset and avoid executing some tasks if a few conditions are not met: we might want to use different commands depending on the underlying system of our server.</p>
<p>We have already seen an example of conditionals using the <kbd>when</kbd> <span>clause</span> in our previous examples, but let's explain it a bit more:</p>
<pre><strong>---</strong><br/><strong>- hosts: all</strong><br/><strong> user: root</strong><br/><strong> tasks:</strong><br/><strong> - command: /bin/false</strong><br/><strong> register: result</strong><br/><strong> ignore_errors: True</strong><br/><br/><strong> - debug: msg="fail!"</strong><br/><strong> when: result|failed</strong><br/><br/><strong> - debug: msg="success!"</strong><br/><strong> when: result|succeeded</strong></pre>
<p>The preceding code is very easy to read: a command is executed (ignoring the potential errors so our playbook continues), and it registers a variable called result. Then, we have two debug tasks:</p>
<ul>
<li>The first one will only be executed <span>only</span> if the <kbd>/bin/false</kbd> <span>command</span> fails</li>
<li>The second one will be executed <span>only</span> if the <kbd>/bin/false</kbd> <span>command</span> succeeds</li>
</ul>
<p>In this playbook, we are using two new tricks:</p>
<ul>
<li><kbd>ignore_errors</kbd>: With this clause, if the task fails, the playbook will continue executing the following tasks. This is very helpful if we want to test for assumptions in the system, for example, if some files are present or a certain network interface is configured.</li>
<li><kbd>Pipe symbol (|)</kbd>: This symbol is called <kbd>pipe</kbd>. It is a Jinja2 expression used to filter values. In this case, we are using the failed and succeeded filters to return true or false depending on the outcome of the command. There are many filters that can be used on Jinja2 to work in a similar way as Unix pipes transforming the data that goes through them.</li>
</ul>
<p>Another type of control flow structure are loops. Let's look at how loops work:</p>
<pre>---<br/>- hosts: all<br/> user: root<br/> vars:<br/> names:<br/> - David<br/> - Ester<br/> - Elena<br/> tasks:<br/> - name: Greetings<br/> debug: msg="Greetings {{ item }}! live long and prosper."<br/> with_items: "{{ names }}"</pre>
<p>Here, we are using something new that we did not see at the time of explaining variables: they can have a structure such as lists and dictionaries. In this case, we are defining a list with a few names and outputting a message for each of them. Now it is time to run the playbook. Save the preceding content in a file called <kbd>loops.yml</kbd> and execute the following command:</p>
<pre><strong>ansible-playbook -i inventory loops.yml</strong></pre>
<p>We will assume that the inventory is the same as the one used in the preceding examples. After finishing, you should see something similar to the following output in your Terminal:</p>
<div class="CDPAlignCenter CDPAlign"><img height="316" width="348" src="assets/65c1b778-c1cd-45a4-9a34-cc2dbe8bdcaf.png"/></div>
<p>It is also possible to define a list using the compact version of the declaration. Take a look at the following statement:</p>
<pre><strong> names:</strong><br/><strong> - David</strong><br/><strong> - Ester</strong><br/><strong> - Elena</strong></pre>
<p>This can be redefined as follows:</p>
<pre><strong>names: ['David', 'Ester', 'Elena']</strong></pre>
<p>And it is totally equivalent.</p>
<p>It is also possible to define dictionaries in Ansible and use them as variables. They can also be used as iterable elements, which enable us to give structure to our data:</p>
<pre>---<br/>- hosts: all<br/> user: root<br/> vars:<br/> namesAge:<br/> - name: David<br/> age: 33<br/> - name: Ester<br/> age: 31<br/> - name: Elena<br/> age: 1<br/> tasks:<br/> - name: Presentations<br/> debug: msg="My name is {{ item.name }} and I am {{ item.age }} years old."<br/> with_items: "{{ namesAge }}"</pre>
<p>If you are familiar with software development, the preceding snippet will make perfect sense to you: a list of structured data (an array of objects) that holds information to be accessed by the key.</p>
<p>In the rest of the book, we will be using more advanced features of flow control structures in Ansible, and we will explain them as we go, but if you want to learn more about it, the following links might be useful for you:</p>
<ul>
<li>Conditionals (<a href="http://docs.ansible.com/ansible/playbooks_conditionals.html">http://docs.ansible.com/ansible/playbooks_conditionals.html</a>)</li>
<li>Loops (<a href="http://docs.ansible.com/ansible/playbooks_loops.html">http://docs.ansible.com/ansible/playbooks_loops.html</a>)</li>
<li>Jinja2 Templating (<a href="http://docs.ansible.com/ansible/playbooks_templating.html">http://docs.ansible.com/ansible/playbooks_templating.html</a>)</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Roles</h1>
                </header>
            
            <article>
                
<p>We have been working on few Ansible playbooks, and as you can imagine, there is a lot that can be abstracted from them into generic units of work. As of now, with our current knowledge of Ansible, the best thing we can do is use a naming convention for playbooks and files so that we don't mix them, but Ansible provides a better approach to this: roles.</p>
<p>Think of roles as common reusable capabilities as you do with modules in software: a highly cohesive set of playbooks, variables, and resources that work together for one purpose. For example, if we are managing <kbd>nginx</kbd>, it makes sense to have all the related resources in a single module (role, in this case) in order to improve the reusability as well as clarity of the code.</p>
<p>One option would be including playbooks using Ansible features. Although we did not talk about it, with Ansible, it is possible to include YAML files with tasks to create dependencies, as shown in the following snippets:</p>
<pre>---<br/>- include: play-include.yml<br/>- hosts: all<br/> user: root<br/> tasks:<br/> - debug: msg="I am the main playbook"<br/> - include: tasks-include.yml</pre>
<p>Let's explain what is going on. We can see two files included:</p>
<ul>
<li>The first include is what Ansible calls a play include. It is a fully functional playbook as is, which gets included in another playbook.</li>
<li>The second include is what Ansible calls a task include. It only includes a list of tasks.</li>
</ul>
<p>This can be explained easily by looking at the content of the two files. First, look at the content of <kbd>play-include.yml</kbd>:</p>
<pre>---<br/>- hosts: all<br/> user: root<br/> tasks:<br/> - debug: msg="I am a play include"</pre>
<p>Second, look at the content of <kbd>tasks-include.yml</kbd>:</p>
<pre>---<br/>- debug: msg="I am a task include"<br/>- debug: msg="I am a task include again"</pre>
<p>Now we are going to execute the playbooks from earlier and see what the output is. Save the content of the first playbook on a file called <kbd>tasks.yml</kbd> and use the same inventory as on all the examples from earlier. Now run the following command:</p>
<pre><strong>ansible-playbook -i inventory tasks.yml</strong></pre>
<p>Once the execution has finished, let's examine the output, which should be very similar to the following one:</p>
<div class="CDPAlignCenter CDPAlign"><img height="456" width="364" src="assets/12934b55-e2fe-40e2-81d0-23881833bda6.png"/></div>
<p>Let's explain this:</p>
<ol>
<li>The play include (<kbd>play-include.yml</kbd>) gets executed by outputting the debug message in there.</li>
<li>The debug task in the main playbook gets executed.</li>
<li>The task includes (<kbd>tasks-include.yml</kbd>) gets executed by executing the two debug messages included there.</li>
</ol>
<p>It is not very complicated, but it gets easier if you play around a bit with the playbooks.</p>
<p>Although the preceding example can lead to a very clean and reusable set of files, there is a much better way of doing this: using roles. Roles are isolated sets of functionalities that allow an easy maintenance cycle like any other software component.</p>
<p>Following the preceding example, we can rewrite it using three roles:</p>
<ul>
<li>The play include (<kbd>play-include.yml</kbd>)</li>
<li>The main tasks (<kbd>tasks.yml</kbd>)</li>
<li>The tasks include (<kbd>tasks-include.yml</kbd>)</li>
</ul>
<p>In order to start creating roles, first, create a new folder called <kbd>ansible-roles</kbd> and a folder called <kbd>roles</kbd> inside the same one. One thing that was not mentioned earlier is the fact that it is a good practice to create a set of folders to hold Ansible resources: tasks folders to hold the tasks, files folder to store all the files that need to be transferred to the remote hosts, and so on. In general, I agree with this setup, but for the examples, we just simplified it in order to make everything easier. For roles, this setup is mandatory. We need to create the folders as appropriated. In this case, as we are only going to use tasks to demonstrate how roles work; we will create the folder tasks inside of every role because otherwise, we won't execute the tasks from the role.</p>
<p>Inside the <strong>roles</strong> folder, we are going to create another folder called <kbd>play-include</kbd>, which is going to be the equivalent to <kbd>play-include.yml</kbd> from the preceding example but in the form of a role.</p>
<p>Now it is time to create our first role playbook: create a file called <kbd>main.yml</kbd> and place it inside the <kbd>play-include/tasks/</kbd> folder. This is the content of the <kbd>main.yml file</kbd>:</p>
<pre>---<br/>- debug: msg="I am a play include"</pre>
<p>Now it is time to add a second role called <kbd>main-tasks</kbd> by creating a folder in <em>roles</em> and adding a file called <kbd>main.yml</kbd> inside of <kbd>roles/main-tasks/tasks</kbd>:</p>
<pre>---<br/>- debug: msg="I am the main playbook"</pre>
<p>And our third and last role is called <kbd>tasks-include</kbd>. Just create the folder as earlier (inside the roles folder) and add a file called <kbd>main.yml</kbd> to it inside of the tasks folder:</p>
<pre>---<br/>- debug: msg="I am a task include"<br/>- debug: msg="I am a task include again"</pre>
<p>And that's it. You have created three roles that can be reused across different Ansible projects. Now it is time to use them. Create a file called <kbd>tasks.yml</kbd> in the root folder of your project (in my case, <kbd>ansible-roles</kbd>) and add the following content:</p>
<pre>---<br/>- hosts: all<br/> user: root<br/> roles:<br/> - main-tasks<br/> - play-include<br/> - tasks-include</pre>
<p>This is how your project should look after adding all the files from earlier:</p>
<div class="CDPAlignCenter CDPAlign"><img height="339" width="304" class="image-border" src="assets/8a102ec6-ec22-41d5-b132-a6e04eeb9f40.png"/></div>
<p>The inventory is the same one as the previous examples (remember, the recommendation was to reuse the same VM). Now it is time to run our playbook:</p>
<pre><strong>ansible-playbook -i inventory tasks.yml</strong></pre>
<p>This will produce output similar to the following one:</p>
<div class="CDPAlignCenter CDPAlign"><img height="460" width="434" src="assets/a3806e54-7c42-4bcc-8f57-45a36f9dfc07.png"/></div>
<p>If we compare the output from the previous example, we can see that it is virtually the same except for the legend of the task, which indicates the role that the task is coming from.</p>
<p>In roles, we can also define variables and access to the variables defined in the global scope as well as many other features. As stated earlier, Ansible is big enough to write an entire book just on it, so we are scratching the surface of the important parts (under my criteria). As usual, the documentation in Ansible is pretty good, and if you want to learn more about roles, the information can be found at <a href="https://docs.ansible.com/ansible-container/roles/index.html">https://docs.ansible.com/ansible-container/roles/index.html</a>.</p>
<p>If I can give you some advice regarding Ansible, it would be that you should always try to use roles. It doesn't matter how big or simple your project is; you will find out very soon that the isolation and reusability that roles provide at pretty much no cost are quite beneficial.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ansible Tower</h1>
                </header>
            
            <article>
                
<p>We have seen an extensive number of features from Ansible that are very useful to any DevOps engineer wanting to automate tasks in any IT department.</p>
<p>There is one design challenge with Ansible, and it is the fact that the playbooks are run from your own computer against remote servers, as shown in the following figure:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/87876d7f-92ee-419a-a0cb-943074ec6508.png"/></div>
<p>This can be a problem because as you are aware by now, Ansible uses secrets (ansible-vault secrets) and, potentially, some sensible information that can be intercepted or stolen from a workstation. This is not a problem in Chef or Puppet as they follow the bastion host approach, but it might be a problem for companies to choose Ansible.</p>
<p>One of the solutions for it comes from Red Hat with the name Ansible Tower. This software gets installed in your IT infrastructure (in this case, Google Cloud Platform) and offers a UI to be operated in the same way as if a CI server was, enabling the role access control to Ansible playbooks as well as a security layer that is not present in plain Ansible: the secrets are kept in a server (Ansible Tower) inside your infrastructure and they never leave it.</p>
<p>Ansible Tower offers all the features present in Ansible so that you don't need to rewrite any playbook,; just adjust them to the new infrastructure geometry.</p>
<p>Let's take a look at the following figure:</p>
<div class="CDPAlignCenter CDPAlign"><img height="245" width="458" class="image-border" src="assets/8e4ab03c-1813-4397-8004-cb74ec6e933e.png"/></div>
<p>As you can see, now our Ansible host is inside of our infrastructure; therefore, it can be operated through a web interface enhancing the security of our IT operations.</p>
<p>Ansible Tower also offers an API that can be used to build integration points with our software or CI server.</p>
<p>Ansible Tower is licensed by Red Hat, so if you want to use it in your company, a license needs to be purchased. At the time of writing this, there are not that many alternatives in the market and the ones that are available are not as feature-full as Ansible Tower. Also, the UI (as shown in the next screenshot) is very sleek, which, even though not a killer, is always something to be considered.</p>
<div class="CDPAlignCenter CDPAlign"><img height="537" width="927" class="image-border" src="assets/8397aec5-e5b8-4dd7-8134-a32cc5d7eada.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, you learned about the main Ansible features, but obviously, we have not covered every single possibility, as it would take us a couple of books to master them. Also, there is another catch here: DevOps tools are evolving constantly.</p>
<p>When you are working on the DevOps side of the IT world, you always need to be willing to learn new things on the fly.</p>
<p>Ansible was originally created to fully provision VMs in the cloud (and on premises), but slowly, it is gravitating toward configuration management as more modern tools, such as Kubernetes or Docker Swarm, are increasing their market share, leveraging Docker into the full software development life cycle in a continuous delivery environment.</p>
<p>In the next chapter, you will learn more about Kubernetes and Docker Swarm as they are the next big things in DevOps. Kubernetes, particularly, is an orchestration tool that I think will take over all the others in the next few months or years as it offers all the resources needed by any IT company leveraging the experience that Google has accumulated through years of running software in containers.</p>
<p>In my opinion, container engines such as Docker are about to surpass the break-even and become the norm for all the software components and architectures of the main software companies around the world.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>