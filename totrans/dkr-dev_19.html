<html><head></head><body>
		<div><h1 id="_idParaDest-325"><em class="italic"><a id="_idTextAnchor347"/>Chapter 16</em>: Conclusion – End of the Road, but not the Journey</h1>
			<p>You have now reached the final chapter of this book. Over the previous 15 chapters, a variety of topics have been covered. As you may have noticed, the book was grouped into three areas—development, DevOps with monitoring, and finally security. So, let's take the time to recap what we studied in each area and where we can go next.</p>
			<p>First, we will run through an overview of what we learned in the book. Next, a summary of the skills we acquired on the development front will be presented. After this, we will explore where we can go next to learn more about DevOps with containers and expand our newly learned skills. Our penultimate review will consider what we learned about security and how we can stay on top of it. Then, we will finish up with a general conclusion on everything we've studied.</p>
			<p>In order to review these items, we've broken them down into the following topics in this chapter:</p>
			<ul>
				<li>Wrapping up – let's get started</li>
				<li>What we learned about development</li>
				<li>Next steps for taking your DevOps knowledge further</li>
				<li>A summary on security and where to go next</li>
			</ul>
			<p>Grab your containerized environment and get ready for our last foray together into the world of Docker.</p>
			<h1 id="_idParaDest-326"><a id="_idTextAnchor348"/>Technical requirements</h1>
			<p>For this chapter, you will need to have access to a Linux machine running Docker. We recommend that you use the setup you have been using so far in this book. This is so you can follow up with some of the tools and techniques recommended in this chapter if you wish.</p>
			<p>Check out the following video to see the Code in Action:</p>
			<p><a href="https://bit.ly/2CpGTfZ">https://bit.ly/2CpGTfZ</a></p>
			<h1 id="_idParaDest-327"><a id="_idTextAnchor349"/>Wrapping up – let's get started</h1>
			<p>Over the course of this book, we have explored the world of containerization. As the technology becomes ever more <a id="_idIndexMarker1178"/>ubiquitous in companies and projects across the world, having a solid handle on the basics and the toolsets supporting containers becomes ever more useful.</p>
			<p>Before we close the book, we are going to wrap up by reviewing what we have learned on the development front. After this, we will discuss what steps can be taken next to build on your DevOps skills and finally do a quick tour of some security projects that may be of interest.</p>
			<p>You may wish to have your project from <a href="B11641_09_Final_NM_ePub.xhtml#_idTextAnchor191"><em class="italic">Chapter 9</em></a>, <em class="italic">Cloud-Native Continuous Deployment Using Spinnaker</em>, ready in order to augment it with some of the recommended projects in this chapter.</p>
			<p>Remember you can revisit the source code for setting up this project here:</p>
			<p><a href="https://github.com/PacktPublishing/Docker-for-Developers/tree/master/chapter9">https://github.com/PacktPublishing/Docker-for-Developers/tree/master/chapter9</a></p>
			<p>With that said, let's look at what we have learned about developing in a Docker-based environment.</p>
			<h1 id="_idParaDest-328"><a id="_idTextAnchor350"/>What we learned about development</h1>
			<p>In the first section of this book, <em class="italic">An Introduction to Docker – Containers and Local Development</em>, we got into the basics of Docker and containers, and how they are used for development purposes.</p>
			<p>First, we introduced the topic of containerization and related <a id="_idIndexMarker1179"/>technologies such as virtualization. Following this, we sized up the differences between Docker containers and virtual machines to see how they compared for development purposes. In <a href="B11641_03_Final_NM_ePub.xhtml#_idTextAnchor044"><em class="italic">Chapter 3</em></a>, <em class="italic">Sharing Containers using Docker Hub</em>, we got our first taste of using Docker Hub to store and retrieve images from a third-party location. Finally, having <a id="_idIndexMarker1180"/>looked at pre-built containers and <a id="_idIndexMarker1181"/>container images, we explored the scenario where multiple containers must work together to form a more complex system.</p>
			<p>These four chapters in this section, taken together, provide the basics for local development and understanding the tooling required to make you a successful engineer in this area. To build upon this knowledge, understanding design patterns for container-based systems would be a logical next step for you to explore.</p>
			<h2 id="_idParaDest-329"><a id="_idTextAnchor351"/>Going deeper – design patterns</h2>
			<p>The first section of this book provided a guide to hands-on development. Just because you are using containers does not mean that architectural patterns for software development have to be abandoned!</p>
			<p>So, you may be asking what a design pattern is if <a id="_idIndexMarker1182"/>you are new to the subject. In short, patterns are reusable blueprints for solving common architectural problems. Much as engineers and architects in the construction industry reuse workable models for constructing buildings, we can use a similar approach for building software systems.</p>
			<p>The following container-oriented patterns provide a great jumping-off point for you to explore the subject further once you have finished this book. In fact, you may recognize some of them from earlier chapters, which is why we have included them here. Let's now take a brief tour of five of them and look at which services and projects in this book have implemented them.</p>
			<h3>A single container – keeping it simple</h3>
			<p>When we first embarked on the projects in this book, we kept things simple and used a <strong class="bold">single container</strong> pattern. This is the <a id="_idIndexMarker1183"/>simplest pattern you can adopt in a container-based environment and the ShipIt Clicker application uses it.</p>
			<h3>The sidecar design pattern – useful for logging</h3>
			<p>We've looked at logging throughout this book and log-monitoring systems are common implementors of <a id="_idIndexMarker1184"/>something known as a <strong class="bold">sidecar</strong> pattern. In its simplest form, we have a container such as the ShipIt Clicker one, and then a second container with a log monitoring tool. This could be Grafana, Datadog, or one of the other tools we experimented with. As you start to build out your own projects, this simple pattern makes a great starting point. Deploy your application on a container, and then use a second container to handle log processing. You will also remember from our exploration of Envoy that the sidecar <a id="_idIndexMarker1185"/>pattern is used here to allow us to create a service mesh without having to directly edit our applications to handle complex networking problems.</p>
			<h3>Leader and elections – adding redundancy </h3>
			<p>We've seen how highly available <a id="_idIndexMarker1186"/>systems are desirable, and how tools such as Kubernetes can help us achieve this goal through orchestrating multiple containers across pods. A common design pattern used in conjunction with Kubernetes is the <strong class="bold">leader and election</strong> approach. Here, data <a id="_idIndexMarker1187"/>can be split across multiple nodes to provide redundancy; for example, the data may be replicated across containers.</p>
			<p>If, for some reason, our container crashes, the other containers will elect a new leader and Kubernetes will spin up a new node to plug the gap.</p>
			<h3>The ambassador design pattern – an approach to proxying</h3>
			<p>Proxying is an important part of many systems, especially in microservice architectures. As you have seen, in Docker-based environments, we can have multiple containers residing on the same virtual network. Each of these containers is assigned a name, which allows containers to communicate with one another.</p>
			<p>An example of where we can <a id="_idIndexMarker1188"/>use the <strong class="bold">ambassador</strong> pattern is in communicating between a backend caching service, such as Redis, and a set of applications. In this instance, the applications communicate with a single Redis proxy node, believing it to be Redis itself. However, the proxy node then distributes the traffic across multiple other Redis nodes on the network.</p>
			<p class="callout-heading">Redis</p>
			<p class="callout">Redis (<a href="http://redis.io">redis.io</a>), as you may <a id="_idIndexMarker1189"/>remember from earlier chapters, is an in-memory, open source caching and message brokering system. It allows you to store a variety of data structures in memory such as lists, sets, and hashes, and can additionally be used as a primary database if you wish (<a href="https://redislabs.com/blog/goodbye-cache-redis-as-a-primary-database/">https://redislabs.com/blog/goodbye-cache-redis-as-a-primary-database/</a>).</p>
			<p>The tool Envoy, which we examined in <a href="B11641_11_Final_NM_ePub.xhtml#_idTextAnchor261"><em class="italic">Chapter 11</em></a>, <em class="italic">Scaling and Load Testing Docker Applications</em>, is very useful for deploying an ambassador-style approach. If you are interested in trying it out with Redis, then check out Dmitry Polyakovsky's article, <em class="italic">Envoy Proxy with Redis</em> (<a href="http://dmitrypol.github.io/redis/2019/03/18/envoy-proxy.html">http://dmitrypol.github.io/redis/2019/03/18/envoy-proxy.html</a>).</p>
			<p>Redis can be obtained from Docker Hub as a container (<a href="https://hub.docker.com/_/redis/">https://hub.docker.com/_/redis/</a>). Let's now look at our final design pattern before moving on.</p>
			<h3>The adapter design pattern – solution reuse</h3>
			<p>Having a consistent way to communicate information between containers is important, and this is especially <a id="_idIndexMarker1190"/>the case when aggregating metrics. For example, if different containers produce logs in different formats, we need to be able to ingest this data in a common format. This is where the <strong class="bold">adapter</strong> pattern comes in. We can use this pattern to develop a uniform interface and subsequently receive log files from multiple containers, standardize them, and then store the data in a centralized monitoring service.</p>
			<p>We saw in <a href="B11641_10_Final_AM_ePub.xhtml#_idTextAnchor226"><em class="italic">Chapter 10</em></a>, <em class="italic">Monitoring Docker Using Prometheus, Grafana, and Jaeger</em>, that Prometheus is a useful tool for container monitoring. However, Prometheus requires a uniform interface from which to pull metrics, that being the metrics API. Where an application does not expose endpoints that are compatible with Prometheus, we can deploy an interface using the adapter pattern that wraps the target service containers with a Prometheus-compatible set of endpoints. This then allows Prometheus to pull data from the containers we are interested in seamlessly via the intermediate interface container.</p>
			<h3>Reading more on design patterns</h3>
			<p>Using container-based design patterns helps to ensure that the right model is being used for your system, only <a id="_idIndexMarker1191"/>introducing as much complexity is as needed, while ensuring the system is resilient and easier to manage.</p>
			<p>If you would like to learn more about container patterns in Kubernetes and Docker, be sure to check out the book, <em class="italic">Kubernetes Design Patterns and Extensions</em>, by Packt.</p>
			<h1 id="_idParaDest-330"><a id="_idTextAnchor352"/>Next steps for taking your DevOps knowledge further</h1>
			<p>The second section, <em class="italic">Running Containers in Production</em>, was geared toward DevOps practices such as <strong class="bold">continuous integration</strong> and <strong class="bold">continuous deployment</strong> (<strong class="bold">CI/CD</strong>), container <a id="_idIndexMarker1192"/>orchestration with Kubernetes, and monitoring with <a id="_idIndexMarker1193"/>tools such as Jaeger.</p>
			<p>To start with, we looked at options around hosting containers in cloud-based systems and hybrid environments. Next up, we explored the simple option of serving up our application on a single host with Docker Compose. After this, experimenting with Jenkins provided us with our first introduction to CI/CD tools and how these can be used with Docker. With the concept of CD under our belt, it was then on to <a href="B11641_08_Final_AM_ePub.xhtml#_idTextAnchor157"><em class="italic">Chapter 8</em></a>, <em class="italic">Deploying Docker Apps to Kubernetes</em>, which gave us our first taste of Kubernetes for container orchestration. Subsequently, the topic of special container-native cloud deployment options in the form of Spinnaker was then trialed, including understanding what deployment methodologies are useful for production environments. The penultimate chapter of section two of this book explored <a id="_idIndexMarker1194"/>monitoring tools for performance, such as Jaeger, Prometheus, and Grafana. Finally, we closed this section with a discussion looking at Envoy service meshes, proxying, and scaling and load testing projects in a production environment.</p>
			<p>The seven chapters in this section provided a wealth of projects that gave you an understanding of some of the core concepts companies face when hosting and serving container-based applications in a production environment. However, there are still plenty of interesting techniques and topics to learn in order to take your DevOps skills to the next level.</p>
			<h2 id="_idParaDest-331"><a id="_idTextAnchor353"/>Chaos engineering and building resilient production systems</h2>
			<p>With a complex production <a id="_idIndexMarker1195"/>system in place, containers being orchestrated in the cloud, and CD happening, how do we ensure our systems are resilient against faults and unexpected crashes? This is where the concept of chaos engineering comes into play. </p>
			<p>Chaos engineering is the <a id="_idIndexMarker1196"/>practice of understanding that code and infrastructure are inherently complex and therefore we should approach the engineering and testing process with this in mind. There are five concepts to chaos engineering that can be summarized <a id="_idIndexMarker1197"/>as follows:</p>
			<ul>
				<li><strong class="bold">Develop a hypothesis around steady state behavior</strong>: Measure outputs from the system over a short period of time to gather a baseline. This baseline is known as the steady state <a id="_idIndexMarker1198"/>and could include metrics such as the error rate, response and latency times, and traffic loads.</li>
				<li><strong class="bold">Test a variety of real-world events</strong>: When testing for real-world events that could impact a production system, consider testing software failures, mangled inputs, containers crashing, and other events that could degrade performance.</li>
				<li><strong class="bold">Experiment in production</strong>: Testing in production may seem like anathema. However, each environment is different and, for authentic results, testing in production is a must.</li>
				<li><strong class="bold">Minimize the impact, aka blast radius</strong>: Running tests in production, however, does not absolve us of the responsibility to ensure that any degradation of performance is temporary and easily recovered from. Always make sure your experiments are well contained. </li>
				<li><strong class="bold">Run automated experiments in a continuous fashion</strong>: Using an automated approach allows you to reduce the labor overhead and for tests and experiments to run at all hours of the day.</li>
			</ul>
			<p>One such tool developed by Netflix implementing this <a id="_idIndexMarker1199"/>concept is Chaos Monkey. Chaos Monkey is a platform to which you deploy your infrastructure that will randomly terminate containers that run in a production environment. The goal is to test how a production system will respond/recover and to allow engineers to tune the system to be more resilient.</p>
			<p>You've already seen how to set up Spinnaker, so as a next step, you can integrate Chaos Monkey into your existing pipeline. Chaos Monkey also works with AWS and Kubernetes. The source <a id="_idIndexMarker1200"/>code can be found at <a href="https://github.com/Netflix/chaosmonkey">https://github.com/Netflix/chaosmonkey</a>.</p>
			<p>If you are interested in installing Chaos Monkey and adding it to the existing CI/CD Spinnaker pipeline that you built in <a href="B11641_09_Final_NM_ePub.xhtml#_idTextAnchor191"><em class="italic">Chapter 9</em></a>, <em class="italic">Cloud-Native Continuous Deployment Using Spinnaker</em>, you can follow the official installation guide at <a href="https://netflix.github.io/chaosmonkey/How-to-deploy/">https://netflix.github.io/chaosmonkey/How-to-deploy/</a>.</p>
			<p>Once it's up and running, you can now test Chaos Monkey in your Spinnaker-based container environment to see how <a id="_idIndexMarker1201"/>it copes with terminating services and what corresponding metrics are displayed in your monitoring tools.</p>
			<p>If you are interested in combining Chaos Monkey with security techniques, be sure to check out Packt's video guide on how you can use Chaos Monkey to <strong class="bold">fuzz</strong> <strong class="bold">test</strong> applications you host:</p>
			<p><a href="https://subscription.packtpub.com/video/virtualization_and_cloud/9781788394901/94651/94677/chaos-monkey-and-fuzz-testing">https://subscription.packtpub.com/video/virtualization_and_cloud/9781788394901/94651/94677/chaos-monkey-and-fuzz-testing</a></p>
			<p class="callout-heading">What is fuzz testing? </p>
			<p class="callout">Fuzz testing is the process of <a id="_idIndexMarker1202"/>testing random, invalid, and incompatible randomized data inputs to an application to see how it responds.</p>
			<p>In addition to Chaos Monkey, the following tools also offer mechanisms for building and testing resilient systems:</p>
			<ul>
				<li><strong class="bold">Gremlin</strong>: A chaos engineering <a id="_idIndexMarker1203"/>platform that can be used with Kubernetes, Mesos, ECS, and Docker Swam, available at <a href="https://www.gremlin.com/">https://www.gremlin.com/</a>.</li>
				<li><strong class="bold">Mangle</strong>: VMware's open source platform for <a id="_idIndexMarker1204"/>orchestrating chaos engineering that supports Kubernetes and Docker, available at <a href="https://vmware.github.io/mangle/">https://vmware.github.io/mangle/</a>.</li>
				<li><strong class="bold">Chaos Mesh</strong>: A cloud-native chaos engineering platform geared toward Kubernetes environments. It can be <a id="_idIndexMarker1205"/>deployed via Helm, and is available at <a href="https://github.com/pingcap/chaos-mesh">https://github.com/pingcap/chaos-mesh</a>.</li>
			</ul>
			<p>We've briefly covered chaos engineering as a concept you could explore further from a DevOps perspective. Let's now recap what we studied under the banner of security.</p>
			<h1 id="_idParaDest-332"><a id="_idTextAnchor354"/>A summary on security and where to go next</h1>
			<p>The final section of this book, <em class="italic">Docker Security – Securing Your Containers</em>, was dedicated to the subject of security. First, we looked at how containers work with the underlying hardware from a security perspective. We studied container and hypervisor security models and quickly dipped our <a id="_idIndexMarker1206"/>toes into security best practices.</p>
			<p>Security fundamentals and best practices came next and provided us with guidance on the best approach <a id="_idIndexMarker1207"/>to handling our Dockerfile and building minimal base images. After this, we looked at how secrets can be handled in Docker Swarm. This provided insight for readers who may need to maintain legacy systems or migrate from Swarm to Kubernetes. We also looked at how tags, metadata, and labels can be used from a security perspective.</p>
			<p>The penultimate chapter of this book, <a href="B11641_15_Final_NM_ePub.xhtml#_idTextAnchor329"><em class="italic">Chapter 15</em></a>, <em class="italic">Scanning, Monitoring, and using Third-Party Tools</em>, gave us a whistle-stop tour of Google, Amazon, and Microsoft's container security features in the cloud. We also installed Anchore for security scanning, looked at some extra monitoring tools that may be useful, and briefly tried out Datadog for container monitoring, which, in turn, can be used in a security context.</p>
			<p>With these basics under your belt, the following are ideas for some next steps regarding container security projects that build upon this knowledge.</p>
			<h2 id="_idParaDest-333"><a id="_idTextAnchor355"/>Metasploit – container-based penetration testing</h2>
			<p>Now that we've built secure containers, and hopefully a secure application too, you can explore penetration <a id="_idIndexMarker1208"/>testing in a container-based environment, such as the one you deployed via Spinnaker. Penetration testing is the <a id="_idIndexMarker1209"/>process of looking for security flaws in a system that can then be leveraged to gain access, exfiltrate data, disrupt performance, or turn the compromised system into a platform to launch other attacks.</p>
			<p>A popular tool for performing penetration tests is the <strong class="bold">Metasploit</strong> framework (<a href="https://www.metasploit.com/">https://www.metasploit.com/</a>). Metasploit is <a id="_idIndexMarker1210"/>an open source framework for developing and deploying security exploit code against a remote target, such as a container running in your environment. Metasploit is available in a container format from Docker Hub, at <a href="https://hub.docker.com/r/metasploitframework/metasploit-framework">https://hub.docker.com/r/metasploitframework/metasploit-framework</a>.</p>
			<p>With this tool in place, you can test vulnerabilities found in containers with tools such as Anchore. Vulnerabilities may include, for example, old versions of software installed on a container that may be open to attack. To grab the latest copy, run the following code:</p>
			<pre>docker pull metasploitframework/metasploit-framework</pre>
			<p>You can then run the container as follows:</p>
			<pre>sudo docker run --rm -it metasploitframework/metasploit-framework</pre>
			<p>Once loaded, you will be dropped into <a id="_idIndexMarker1211"/>the Metasploit shell, called <code>msfconsole</code>:</p>
			<div><div><img src="img/B11641_16_001.jpg" alt="Figure 16.1 – Example of a Metasploit container running"/>
				</div>
			</div>
			<p class="figure-caption">Figure 16.1 – Example of a Metasploit container running</p>
			<p>From here, you can begin to explore the commands available and consider projects you can run from <a id="_idIndexMarker1212"/>inside the container. A free course on using Metasploit can be found on the Offensive Security website at <a href="https://www.offensive-security.com/metasploit-unleashed/">https://www.offensive-security.com/metasploit-unleashed/</a>. Once you are familiar with the basic commands, consider exploring some of the following features in Metasploit.</p>
			<h3>Unprotected TCP socket exploit</h3>
			<p>You will remember <a id="_idIndexMarker1213"/>that we discussed how leaving the TCP socket for Docker exposed could be exploited by attackers. Metasploit provides an example of how this can be achieved. Try running Docker via <code>2375/tcp</code> on a second machine and load up the <code>docker_daemon_tcp</code> module (<a href="https://www.rapid7.com/db/modules/exploit/linux/http/docker_daemon_tcp">https://www.rapid7.com/db/modules/exploit/linux/http/docker_daemon_tcp</a>) in the Metasploit container we just set up. You can now target the compromised socket via this module and create a Docker <a id="_idIndexMarker1214"/>container with the <code>/</code> path mounted with read and write permissions on the underlying target host that is running the container.</p>
			<h3>Testing third-party vulnerable containers – Apache Struts</h3>
			<p>The following is just one example of the many vulnerable containers available for downloading and <a id="_idIndexMarker1215"/>experimenting with. This container, created by <code>piesecurity</code>, includes a vulnerable version of Apache Struts (<a href="https://hub.docker.com/r/piesecurity/apache-struts2-cve-2017-5638/">https://hub.docker.com/r/piesecurity/apache-struts2-cve-2017-5638/</a>).</p>
			<p>Apache Struts is a popular <a id="_idIndexMarker1216"/>framework built in Java for developing web applications. In 2017, a vulnerability was discovered in the framework that allowed an attacker to execute code remotely on the server running it. One of the most well-known victims of this vulnerability was Equifax, who suffered a catastrophic data breach.</p>
			<p>You can deploy and run this container loaded with Struts via Spinnaker and test out the exploit yourself. Once installed, use the Metasploit module <code>struts2_content_type_ognl</code> (<a href="https://www.rapid7.com/db/modules/exploit/multi/http/struts2_content_type_ognl">https://www.rapid7.com/db/modules/exploit/multi/http/struts2_content_type_ognl</a>). This will allow you to launch an attack that creates a reverse shell on the compromised container and demonstrates how security flaws inside third-party frameworks can be exploited even when running in Kubernetes and Docker.</p>
			<p>If you'd like to dig into this further, the book <em class="italic">Advanced Infrastructure Penetration Testing</em> from Packt provides guidance for using the Metasploit Framework and testing container-based environment security.</p>
			<h1 id="_idParaDest-334"><a id="_idTextAnchor356"/>Summary</h1>
			<p>We hope you have enjoyed reading this book. It aimed to provide a comprehensive guide to Docker development, both locally and in the cloud. Throughout the 16 chapters, our goal was to demonstrate not only how to develop applications in containers, but how they can be built, deployed, scanned, and monitored.</p>
			<p>Whether you plan to build a new project from scratch, are maintaining legacy systems on Docker Swarm, or migrating to a Kubernetes-based environment, <em class="italic">Docker For Developers</em> is the type of book you can dip back into again to refresh your knowledge or seek guidance as required.</p>
			<p>We hope you have enjoyed your journey into the world of containers as much as we have enjoyed sharing this knowledge with you. Good luck with your future projects!</p>
		</div>
	</body></html>