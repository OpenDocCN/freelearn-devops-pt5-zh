<html><head></head><body>
        

                            
                    <h1 class="header-title">Managing Containers with OpenShift</h1>
                
            
            
                
<p>Using a comprehensive suite of some of the best and most resilient open source tooling available, Kubernetes is rapidly changing the way that software applications are being built and deployed across organizations and in the cloud. Kubernetes brings with it lessons learned from deploying a containerized infrastructure across a company with one of the largest and most robust infrastructure footprints: Google. As we saw in the previous chapter, Kubernetes is an incredibly flexible and reliable platform for deploying containers at a very high scale, bringing with it the features and functionality to deploy highly available applications across clusters of servers, by running on top of native container engines such as <kbd>Docker</kbd>, <kbd>rkt</kbd>, and <kbd>Runc</kbd>. However, with the great power and flexibility Kubernetes brings, also comes great complexity. Arguably, one of the biggest downsides to deploying a containerized infrastructure using Kubernetes is the high degree of knowledge regarding the Kubernetes architecture that one must acquire prior to migrating workloads over to Kubernetes.</p>
<p>There is a solution to the high degree of overhead and technical complexity that puts Kubernetes out of the reach of many organizations today. In recent years, Red Hat has developed an answer to the problem of simplifying Kubernetes concepts and making the platform more accessible for software developers and DevOps engineers to quickly deploy and rapidly build upon. OpenShift is a suite of tools developed by Red Hat that runs on top of the Red Hat distribution of Kubernetes that provides a sophisticated, yet easy to understand platform for automating and simplifying the deployment of containerized applications. The aim of OpenShift is to provide a reliable and secure Kubernetes environment that provides users with a streamlined web interface and command-line tool used for deploying, scaling, and monitoring applications running in Kubernetes. Furthermore, OpenShift is the second of the major cloud providers currently supported by the Ansible Container project (Kubernetes and OpenShift).</p>
<p>In this chapter we will cover the following topics:</p>
<ul>
<li class="mce-root">What is OpenShift?</li>
<li class="mce-root">Installing Minishift locally</li>
<li class="mce-root">Deploying containers from the web interface</li>
<li class="mce-root">OpenShift web interface tips</li>
<li class="mce-root">An introduction to the OpenShift CLI</li>
<li class="mce-root">OpenShift and Ansible Container</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">What is OpenShift?</h1>
                
            
            
                
<p>OpenShift is a suite of products available from Red Hat for building a production-ready, reliable, and secure Kubernetes platform. Using OpenShift, developers have a tremendous amount of freedom when deploying containerized applications using the OpenShift API, or accessing the Kubernetes API to fine-tune functionality and features. Since OpenShift uses the same underlying container runtime environments, Docker containers can be developed locally and deployed to OpenShift, which leverages all of the Kubernetes primitives, such as namespaces, pods, and deployments, to expose services to the outside world. At the time of writing, Red Hat offers the OpenShift platform with the following configuration options:</p>
<ul>
<li class="mce-root"><strong>OpenShift Origin</strong>: A fully free and open source version of OpenShift that is community-supported. OpenShift Origin can be deployed locally using a project known as <strong>Minishift</strong>.</li>
<li class="mce-root"><strong>OpenShift Online</strong>: OpenShift Online is a fully hosted public cloud offering from Red Hat that allows individuals and organizations to take advantage of OpenShift Origin without committing hardware resources to deploying OpenShift on-premise. Users can sign up for OpenShift online free-tier accounts that allow for application deployments up to 1 gigabyte of RAM, and two vCPUs.</li>
<li class="mce-root"><strong>OpenShift Dedicated/Container Platform</strong>: OpenShift Dedicated and the OpenShift Container Platform provide robust and scalable deployments of OpenShift that are managed and supported by Red Hat either on-premises or through public cloud providers such as Google Cloud, Azure, or AWS.</li>
</ul>
<p>Throughout the course of this chapter, and going forward into the next chapters, we will be using the fully free and open source OpenShift Origin to deploy a local Minishift cluster. Unlike the previous chapter, the free-tier version of OpenShift is unfortunately too limited to cover the breadth of examples this chapter is going to cover. In an effort to fully demonstrate the capabilities of OpenShift, I have opted to walk the user through a local installation of Minishift that is only limited by the hardware running on your local workstation. If you have been tracking with us thus far, Minishift is not much more complicated to set up on VirtualBox than the local Vagrant lab environment we have been using. However, if you want to use the free tier of OpenShift Online, most of these examples can replicated there, albeit in a more limited way than running Minishift in your local environment.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Installing Minishift locally</h1>
                
            
            
                
<p>Minishift is a local OpenShift cluster that can be downloaded and run on your local PC to function as a development environment. The primary use case for Minishift is to provide a sandbox that gives developers a functional development environment that can be launched on your laptop. Minishift is also fully compatible with the <strong>OpenShift Client</strong> (<strong>OC</strong>) CLI that is used to work with OpenShift clusters using a command-line interface. In this portion of the chapter, we will learn how to install Minishift and the OC in order to get it running in your local environment. Before proceeding, you need to have VirtualBox installed on your PC; it will function as a hypervisor for launching the Minishift VM. For the purposes of this demonstration, we will be using Minishift version 1.7.0. Since the time of writing, newer versions of Minishift will have undoubtedly been released. To have the best experience working with Minishift, I would suggest you download the 1.7.0 release, although newer releases will most likely work just as well.</p>
<p>Furthermore, Minishift and the OC are available cross-platform on Windows, Linux, and macOS. This example is going to demonstrate downloading and installing Minishift on Linux. For more information about installing Minishift on other platforms, I have provided the following link: <a href="https://docs.openshift.org/latest/minishift/getting-started/installing.html">https://docs.openshift.org/latest/minishift/getting-started/installing.html</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Installing the Minishift binaries</h1>
                
            
            
                
<p>The proceeding steps should be executed on your local workstation (not the Vagrant lab VM) to install Minishift locally:</p>
<ol>
<li><strong>Download the Minishift binary</strong>: The Minishift 1.7.0 binary can be downloaded from the following GitHub URL for all platforms (<a href="https://github.com/minishift/minishift/releases/tag/v1.7.0">https://github.com/minishift/minishift/releases/tag/v1.7.0</a>). You may download this binary using a web browser, or by using <kbd>wget</kbd> as in this example:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~/minishift$ wget https://github.com/minishift/minishift/releases/download/v1.7.0/minishift-1.7.0-linux-amd64.tgz
--2017-10-09 19:41:08--  https://github.com/minishift/minishift/releases/download/v1.7.0/minishift-1.7.0-linux-amd64.tgz
Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112
Connecting to github.com (github.com)|192.30.253.113|:443... connected.
 'minishift-1.7.0-linux-amd64.tgz' saved [3980931/3980931]</strong></pre>
<ol start="2">
<li><strong>Unpack the Minishift archive</strong>: Minishift comes packaged in an archive format compatible with your operating system. For Linux and OSX, this is a zipped tarball. For Windows, the format is a zipped archive:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~/Development/minishift$ tar -xvf minishift-1.7.0-linux-amd64.tgz
minishift-1.7.0-linux-amd64/
minishift-1.7.0-linux-amd64/LICENSE
minishift-1.7.0-linux-amd64/README.adoc
minishift-1.7.0-linux-amd64/minishift
 </strong></pre>
<ol start="3">
<li><strong>Copy the Minishift binary to your executable path</strong>: Copying the Minishift binary to your local executable path will ensure the <kbd>minishift</kbd> command can be executed from your command line in any context. In Linux, a common path location is <kbd>/usr/local/bin</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~minishift/minishift-1.7.0-linux-amd64$ sudo cp minishift /usr/local/bin</strong></pre>
<p>You may need to check the permissions on the binary to ensure they are set to executable, for example, <kbd>chmod +x /usr/local/bin/minishift</kbd>.</p>
<ol start="4">
<li><strong>Validate the installation</strong>: Executing the <kbd>minishift version</kbd> command should return the relevant Minishift version details, in this case, 1.7.0:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~minishift$ minishift version
minishift v1.7.0+1549135</strong></pre>
<ol start="5">
<li><strong>Download the OC binary</strong>: The OC can be downloaded for Windows, macOS, or Linux at the following URL: <a href="https://mirror.openshift.com/pub/openshift-v3/clients/3.6.173.0.5/">https://mirror.openshift.com/pub/openshift-v3/clients/3.6.173.0.5/</a>. For this demonstration, we will be using version 3.6 of the OC client. Similar to MiniShift, newer versions might have been released since the time of writing. For maximum compatibility with the examples, I suggest you use version 3.6:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~/minishift$ wget https://mirror.openshift.com/pub/openshift-v3/clients/3.6.173.0.5/linux/oc.tar.gz
--2017-10-09 20:03:57--  https://mirror.openshift.com/pub/openshift-v3/clients/3.6.173.0.5/linux/oc.tar.gz
Resolving mirror.openshift.com (mirror.openshift.com)... 54.173.18.88, 54.172.163.83, 54.172.173.155
'oc.tar.gz' saved [36147137/36147137]</strong></pre>
<ol start="6">
<li><strong>Extract the OC client archive</strong>: After extracting this archive, a single binary, <kbd>oc</kbd>, will be extracted. This is the executable binary for the OC:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~/minishift$ tar -xvf oc.tar.gz
oc</strong></pre>
<ol start="7">
<li><strong>Copy the OC to your executable path</strong>: Similar to the Minishift installation, we will copy the OC binary to an executable path location:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local~/minishift$ sudo cp oc /usr/local/bin</strong></pre>
<ol start="8">
<li><strong>Validate installation</strong>: Execute the <kbd>oc version</kbd> command to ensure the OC has been installed successfully and to return the relevant version details:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~/minishift$ oc version
oc v3.6.173.0.5</strong></pre>
<ol start="9">
<li><strong>Start the Minishift cluster</strong>: Now that Minishift and the OC are installed, we start the Minishift cluster using the <kbd>minishift start</kbd> command. By default, Minishift will start by expecting to use the KVM hypervisor and approximately 2 GB of memory. We are going to modify this slightly to use the VirtualBox hypervisor, 8 GB of RAM, and 50 GB of storage. Once the Minishift cluster has launched, it will return a URL you can use to access the OpenShift console:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~$ minishift start --vm-driver=virtualbox --disk-size=50GB --memory=8GB
-- Starting local OpenShift cluster using 'virtualbox' hypervisor ...
-- Minishift VM will be configured with ...
   Memory:    8 GB
   vCPUs :    2
   Disk size: 50 GB

   Downloading ISO 'https://github.com/minishift/minishift-b2d-iso/releases/download/v1.2.0/minishift-b2d.iso'
 40.00 MiB / 40.00 MiB [=========================================================================================================================================================================] 100.00% 0s
-- Starting Minishift VM ................................. OK
-- Checking for IP address ... OK
-- Checking if external host is reachable from the Minishift VM ...
   Pinging 8.8.8.8 ... OK
-- Checking HTTP connectivity from the VM ...
   Retrieving http://minishift.io/index.html ... OK
-- Checking if persistent storage volume is mounted ... OK
-- Checking available disk space ... 0% used OK
-- Downloading OpenShift binary 'oc' version 'v3.6.0'
 34.72 MiB / 34.72 MiB</strong> <strong>[=========================================================================================================================================================================] 100.00% 0s-- Downloading OpenShift v3.6.0 checksums ... OK
-- OpenShift cluster will be configured with ...
   Version: v3.6.0
-- Checking `oc` support for startup flags ...
   host-config-dir ... OK
   host-data-dir ... OK
   host-pv-dir ... OK
   host-volumes-dir ... OK
   routing-suffix ... OK
Starting OpenShift using openshift/origin:v3.6.0 ...
Pulling image openshift/origin:v3.6.0
Pulled 1/4 layers, 26% complete
Pulled 2/4 layers, 71% complete
Pulled 3/4 layers, 90% complete
Pulled 4/4 layers, 100% complete
Extracting
Image pull complete
OpenShift server started.

The server is accessible via web console at:</strong>
   <strong> https://192.168.99.100:8443

You are logged in as:
    User:     developer
    Password: &lt;any value&gt;

To login as administrator:
    oc login -u system:admin</strong></pre>
<p>If you do not have enough resources to allocate 8 GB of RAM to the Minishift deployment, most of these examples can be run using the default 2 GB of RAM.</p>
<ol start="10">
<li><strong>Relax the default security permissions</strong>: On the backend, OpenShift is a highly secured Kubernetes cluster that does not allow containers to run a local root user. Before we dive into our new Minishift installation, we need to first relax the default security context constraints so that we can run any Docker image. Since this is a development environment, this will give us more freedom to explore the platform and run different workloads. In order to do this, we will use the OC to log in as the system administrator. From there, we can use the <kbd>oc adm</kbd> command to add the <kbd>anyuid</kbd> security context constraint to all authenticated OpenShift users:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~/minishift$ oc login -u system:admin
Logged into "https://192.168.99.100:8443" as "system:admin" using existing credentials.

You have access to the following projects and can switch between them with 'oc project &lt;projectname&gt;':

    default
    kube-public
    kube-system
  * myproject
    openshift
    openshift-infra

Using project "myproject".

aric@local:~minishift$ oc adm policy add-scc-to-group anyuid system:authenticated</strong></pre>
<p>It is always a best practice to not modify the OpenShift security context constraints in a production deployment. Container images should always be running as their own user inside of a Docker container. The unfortunate truth is that many developers use the default root user to build and deploy applications. We are relaxing the security permissions just so we can explore the platform more freely without the limitation of only running containers built and run using a dedicated user.</p>
<p>When you have finished working in the Minishift environment, make sure you stop the Minishift VM using the <kbd>minishift stop</kbd> command, as shown in the following snippet. Unlike destroying your local Vagrant lab, the Minishift instance will retain running deployments and service artifacts the next time the VM is started:</p>
<pre><strong>aric@local:~/minishift$ minishift stop</strong><br/><strong>Stopping local OpenShift cluster...</strong><br/><strong>Cluster stopped.</strong></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Deploying containers using the web interface</h1>
                
            
            
                
<p>As you may have noticed, when the <kbd>minishift start</kbd> command completed, it provided an IP address that you can use to access the web user interface. One of the biggest benefits of using OpenShift over standard Kubernetes is that OpenShift exposes almost all of Kubernetes' core functionality through an intuitive web interface. The OpenShift console works in a similar way to other cloud or service dashboards you have used in the past. At a glance, you can see which deployments are running, triggered alarms caused by failed pods, or even new deployments that other users have triggered in the project. To access the web interface, simply copy and paste the IP address in the output of the <kbd>minishift start</kbd> command in any modern web browser installed on your local machine. You may then have to accept the self-signed SSL certificate that comes with Minishift by default, after which you will be prompted with a login screen similar to the following screenshot:</p>
<div><img height="125" width="528" src="img/15cb9fbf-7a8b-4b31-a7c3-ae53f29d09e7.png"/></div>
<p>Figure 1: OpenShift login page</p>
<p>The default credentials to access Minishift are the username <kbd>developer</kbd> and any password you want. It is not important to remember the password you enter, as each time you authenticate as the developer user, you can simply supply any password. Upon successfully logging in, you will be asked to access a project. The default project that Minishift provides for you is called My Project. For the sake of simplicity, we will use this project for the following lab examples, which you can follow along with.</p>
<p>The web interface is laid out by two primary navigation bars along the left and top of the screen, while the central portion of the interface is reserved for showing details about the environment you are currently accessing, modifying settings, or deleting resources:</p>
<div><img height="278" width="453" src="img/e1a7b9ed-939f-42d8-94c7-d1b1d71f686b.png"/></div>
<p>Figure 2: Initial OpenShift project</p>
<p>Now that you are familiar with the OpenShift user interface, let's create a deployment and see what it looks like when pods are running in the cluster. The functionality for creating new pods and deployments can be found towards the top of the screen by selecting the Add to Project drop-down box:</p>
<div><img height="212" width="567" src="img/46e15305-d61e-4472-911b-5656098738d2.png"/></div>
<p>Figure 3: Adding services to your project</p>
<p>We can create a new deployment in a variety of different ways. The default options OpenShift provides is to browse a catalog of pre-built images and services, deploy an image based on a container registry URL, or importing a YAML or JSON manifest that describes the services we are building. Let's deploy one of the catalog services found in the web interface. Selecting the Browse Catalog option from the Add to Project drop-down will open a screen for the OpenShift catalog. Any of the OpenShift examples found in the catalog will run well in OpenShift, but for demonstration purposes let's deploy the framework for a simple Python application. To do this, click on the catalog option for Python, then the Python 3.5 Source Code Application:</p>
<div><img height="271" width="274" src="img/715072cf-e8de-4da9-9397-2f8e44f58a93.png"/></div>
<p>Figure 4: Creating a simple Python service from the OpenShift catalog</p>
<p>On the next screen, OpenShift will prompt you for options to deploy your application with, namely a source code repository, which contains Python source code, and an application name. You can choose any name for the Python application. For this example, I will name mine <kbd>oc-test-deployment</kbd>. Since we do not have a pre-developed Python application, we can click on the Try It link below the Git Repository URL textbox to use the demo application provided by OpenShift:</p>
<div><img height="335" width="528" src="img/544fad49-bc55-467e-a7c2-714fbe326997.png"/></div>
<p>Figure 5: Modifying the attributes of the Python application</p>
<p>If you are a Python developer and have a Django application you would like to deploy instead, feel free to use another Git repository in place of the demo one!</p>
<p>Clicking on the blue Create button will initiate the deployment and launch the container. Depending on the specifications of your workstation, it might take a while for the service to fully deploy. While it is deploying, you can watch the various stages of the deployment by clicking through the pages of the user interface. For example, clicking on Pods in the sidebar will show pods as they are created and go through the various stages to become available in Kubernetes. OpenShift shows circular graphs that describe the state of the resources that are running. Pods that are healthy, responding to requests, and running as intended are shown by blue circles. Other Kubernetes resources that might not be running as intended, throwing errors or warnings instead, are represented by yellow or red circles. This provides an intuitive way to understand how the services are running at a glance:</p>
<div><img src="img/916fb49b-38b7-49a9-98ff-b4a160403352.png"/></div>
<p>Figure 6: A successfully created test Python application</p>
<p>Once the service has been deployed fully, OpenShift will provide a link to access the service. In OpenShift vernacular, this is known as a <strong>route</strong>. Routes function in a similar way to exposed services in Kubernetes, with the exception that they leverage <kbd>nip.io</kbd> DNS forwarding by default. You might notice that the service route pointing to the service we just created has the fully qualified domain name <kbd>servicename.ipaddress.nip.io</kbd>. This provides the user with routable access to reach the Kubernetes cluster without the hassle of configuring external load balancers or service proxies. Accessing that URL in a web browser should open a page that looks similar to the following:</p>
<div><img height="291" width="568" src="img/8526b6f0-3366-4ef2-b012-d0d266af1974.png"/></div>
<p>Figure 7: Python application test page</p>
<p>This is the default Python-Django index page for this simple demo application. If we click back on the OpenShift console, we can go into more detail regarding the pods that are running in this deployment. Similar to kubectl, OpenShift can give us details about the deployment, including running pods, log events, and even allow us to customize the deployment from the web user interface. To view these details, select Applications | Deployments and click on the deployment you wish to look up. In this case, we will look at the details of the only running deployment we have, <kbd>oc-test-deployment</kbd>:</p>
<div><img height="129" width="547" src="img/e02c7343-5efb-44fc-ae88-b16c5444282c.png"/></div>
<p>Figure 8: OpenShift deployments page</p>
<p>From this page, we can view the history of containers, modify the configuration, check or change environment variables, and view the most recent event logs from the deployment. In the upper-right corner of the screen, the Actions drop-down box gives us even more options for adding storage, autoscaling rules, and even modifying the Kubernetes manifest used to deploy this service:</p>
<div><img height="205" width="611" src="img/2e966335-4c18-499b-a38f-eeba5190afb9.png"/></div>
<p>Figure 9: Managing OpenShift applications and deployments</p>
<p>OpenShift provides a great interface for tweaking manifests and experimenting with changes in real time. The OpenShift user interface will give you feedback on changes you make and let you know when there are potential problems.</p>
<p>Information related to the running pods within the deployment can also be accessed through the web user interface. From the Applications menu, select Pods and click on the pod you wish to view information for. In this case, we have a single running pod, <kbd>oc-test-deployment-1-l18l8</kbd>:</p>
<div><img height="170" width="588" src="img/b49c4dbd-c722-4075-acd8-74720f610a54.png"/></div>
<p>Figure 10: Viewing pods within application deployments</p>
<p>On this page, we can view almost any pertinent detail regarding the pods that are running within any of our deployments. From this screen you can view environment configurations, access container logs in real time, and even log into containers through a fully functional terminal emulator:</p>
<div><img height="293" width="599" src="img/4e53f306-aab2-4a46-b24b-f98576bb09a2.png"/></div>
<p>Figure 11: Viewing pod-specific details in OpenShift</p>
<p>Similar to the Deployments menu, we can select the Actions drop-down menu from this screen as well to modify container settings in the YAML editor, or mount storage volumes inside the container.</p>
<p>Finally, using the OpenShift web interface, we can delete deployments and pods. Since OpenShift is essentially a layer that functions on top of Kubernetes, we need to apply many of the same concepts. In order to delete pods, we must first delete the deployment in order to set a new desired state within the Kubernetes API. Within OpenShift this can be accomplished by selecting Applications | Deployments | Your Deployment (oc-test-deployment). From the Actions drop-down menu, select Delete Deployment. OpenShift will prompt you to make sure this is something you really want to do; click Delete to finalize the operation:</p>
<div><img height="185" width="455" src="img/741a8898-5e82-46a9-9346-399fea7c69d7.png"/></div>
<p>Figure 12: Deleting deployments in OpenShift</p>
<p>In a similar fashion, you will have to go to Applications | Service and then Applications | Routes in order to delete the services and routes that OpenShift created for the service. Once this is complete, the screen produced by clicking on the Overview button in the left menu bar will once again be blank, showing that nothing is currently running in the OpenShift cluster.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">OpenShift web user interface tips</h1>
                
            
            
                
<p>The preceding example walked the user through some of the major OpenShift and Kubernetes workflow steps for creating a new deployment, managing the deployment, and ultimately deleting the deployment and other resources. OpenShift exposes far more functionality through the web user interface than this book has time to delve into; I suggest you take time to explore the web interface for yourself to truly become familiar with the features that OpenShift provides. For the sake of not being monotonous, I have provided a few key features to keep your eyes open for in the OpenShift web interface:</p>
<ul>
<li class="mce-root"><strong>Overview dashboard</strong>: The Overview dashboard can be accessed from the navigation bar on the left side of the screen. The overview dashboard shows information about the most recent activity inside the OpenShift cluster. This is useful for accessing the latest deployments and having single-click access to various cluster resources.</li>
<li class="mce-root"><strong>Applications menu</strong>: The Applications menu is a single location to view or modify any deployments or pods that are running across the OpenShift cluster. From Applications, you can access information related to deployments, pods, stateful sets, services, and routes. Think of the Applications menu as a single stop for anything related to the configuration of containers running within the cluster.</li>
<li class="mce-root"><strong>Builds dashboard</strong>: The Builds dashboard features a light <strong>continuous integration</strong> <strong>continuous</strong> <strong>delivery</strong> (<strong>CICD</strong>) workflow for Kubernetes. This is useful for triggering image builds, establishing Jenkins-enabled workflow pipelines, and building automation into OpenShift projects.</li>
<li class="mce-root"><strong>Resources menu</strong>: The Resources menu is used primarily to define quotas and user account privileges used to manage access and limits for users and projects within the OpenShift cluster. Also defined here is a lightweight secret storage interface, as well as config map options to define the configurations for containers within OpenShift projects.</li>
<li class="mce-root"><strong>Storage dashboard</strong>: The Storage dashboard is used to display information regarding persistent volume claims used by containers and deployments on the underlying hardware or VM OpenShift is running on. Volume claims can be created or deleted from this portion of the web interface, as well as managed or modified depending on new or changing requirements.</li>
<li class="mce-root"><strong>Monitoring dashboard</strong>: Finally, the Monitoring dashboard provides the user with details about running pods, triggered events, as well as the historical context regarding the changes in the environment leading up to the events listed. Monitoring can be easily tied to build a pipeline or even used to report on configured service health checks.</li>
</ul>
<p>Leveraging the robust suite of tools provided by OpenShift helps to abstract and simplify many of the Kubernetes concepts we learned about in <a href="ccc07e61-25e7-4984-953b-586b28b12aab.xhtml" target="_blank">Chapter 5</a>, <em>Containers at Scale with Kubernetes</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">An introduction to the OpenShift CLI</h1>
                
            
            
                
<p>The second primary way that users can interact with the OpenShift platform is through the OpenShift command-line interface, OC (short for OpenShift Client). The OpenShift command-line interface uses many of the same concepts we explored in <a href="ccc07e61-25e7-4984-953b-586b28b12aab.xhtml" target="_blank">Chapter 5</a>, <em>Containers at Scale with Kubernetes</em>, using the <kbd>kubectl</kbd> command line interface for managing pods, deployments, and exposing services. However, the OpenShift client also supports many of the features that are specific to OpenShift, such as creating routes to expose deployments and working with integrated security context constraints for access control. Throughout this section, we will look at how to use the OC to accomplish some of the basic workflow concepts we explored through the web user interface, such as creating deployments, creating routes, and working with running containers. Finally, we will look at some tips for diving deeper with the OC and some of the more advanced features that are available. Before proceeding, ensure the OC is installed (see the beginning of this chapter for installation details):</p>
<ol>
<li><strong>Logging into OpenShift</strong>: Similar to the web user interface, we can use the CLI to log into our local OpenShift cluster using the <kbd>oc login</kbd> command. The basic syntax for this command is <kbd>oc login URL:PORT</kbd>, where the user replaces the URL and port with the URL and port number of the OpenShift environment they are logging into. Upon successful login, the prompt will return <kbd>Login Successful</kbd> and grant you access to your default project. In this case, we will log into our local environment at <kbd>192.168.99.100</kbd>, using the <kbd>developer</kbd> username and anything as the password:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~$ oc login https://192.168.99.100:8443
Authentication required for https://192.168.99.100:8443 (openshift)
Username: developer
Password:
Login successful.

You have one project on this server: "myproject"

Using project "myproject".</strong></pre>
<ol start="2">
<li><strong>Check status using OC status</strong>: The <kbd>oc status</kbd> command is used in a similar way to the Overview dashboard in the web user interface to show critical services deployed in the environment, running pods, or anything in the cluster that might be triggering an alarm. Simply typing <kbd>oc status</kbd> will not return anything, since we deleted the deployments, routes, and services we created through the web user interface:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~$ oc status
In project My Project (myproject) on server https://192.168.99.100:8443

You have no services, deployment configs, or build configs.
Run 'oc new-app' to create an application.</strong></pre>
<ol start="3">
<li><strong>Create an OpenShift deployment</strong>: Deployments and other cluster resources can easily be created using the <kbd>oc create</kbd> command. Similar to <kbd>kubectl</kbd>, you can create deployments by using the <kbd>oc create deployment</kbd> command and referencing the name of the container image you wish to use. It should be noted that deployment names are sensitive to using special characters such as underscores and dashes. For the purposes of simplicity, let's re-create our example from <a href="ccc07e61-25e7-4984-953b-586b28b12aab.xhtml" target="_blank">Chapter 5</a>, <em>Containers at Scale with Kubernetes</em>, and create a simple NGINX pod using the official NGINX Docker image using the <kbd>oc create</kbd> command and specifying the object as <kbd>deployment</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~$ oc create deployment webserver --image=nginx
deployment "webserver" created</strong></pre>
<p>Another similarity to kubectl is that OpenShift supports creating deployments based on Kubernetes manifest files using the <kbd>-f</kbd> option.</p>
<ol start="4">
<li><strong>List pods and view the OC status</strong>: Now that we have a deployment and pod running in the OpenShift cluster, we can view running pods using the <kbd>oc get pods</kbd> command, and check the output of the <kbd>oc status</kbd> command to see an overview of the running pods in our cluster:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~/Development/minishift$ oc get pods
NAME                         READY     STATUS    RESTARTS   AGE
webserver-1266346274-m2jvd   1/1       Running   0          9m

aric@local:~/Development/minishift$ oc status
In project My Project (myproject) on server https://192.168.99.100:8443

pod/webserver-1266346274-m2jvd runs nginx

You have no services, deployment configs, or build configs.
Run 'oc new-app' to create an application.</strong></pre>
<ol start="5">
<li><strong>View verbose output using</strong> <kbd>oc describe</kbd>: Aside from simply listing objects that are created and available in the OpenShift cluster, verbose details about specific objects can be viewed using the <kbd>oc describe</kbd> command. Similar to <kbd>kubectl describe</kbd>, <kbd>oc describe</kbd> allows us to view pertinent details about almost any object defined in the cluster. For example, we can use the <kbd>oc describe deployment</kbd> command to view verbose details about the web server deployment we just created:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~/Development/minishift$ oc describe deployment webserver
Name:                   webserver
Namespace:              myproject
CreationTimestamp:      Sun, 15 Oct 2017 15:17:30 -0400
Labels:                 app=webserver
Annotations:            deployment.kubernetes.io/revision=1
Selector:               app=webserver
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  1 max unavailable, 1 max surge
Pod Template:
  Labels:       app=webserver
  Containers:
   nginx:
    Image:              nginx
    Port:
    Environment:        &lt;none&gt;
    Mounts:             &lt;none&gt;</strong>
 <strong> Volumes:              &lt;none&gt;
Conditions:
  Type          Status  Reason
  ----          ------  ------
  Available     True    MinimumReplicasAvailable
OldReplicaSets: &lt;none&gt;
NewReplicaSet:  webserver-1266346274 (1/1 replicas created)
Events:
  FirstSeen     LastSeen        Count   From                    SubObjectPath   Type            Reason                  Message
  ---------     --------        -----   ----                    -------------   --------        ------                  -------
  11m           11m             1       deployment-controller Normal ScalingReplicaSet       Scaled up replica set webserver-1266346274 to 1</strong></pre>
<ol start="6">
<li><strong>Create an OpenShift service</strong>: In order to expose pods that are running in the OpenShift cluster, we must first create a service. You may remember from <a href="ccc07e61-25e7-4984-953b-586b28b12aab.xhtml" target="_blank">Chapter 5</a>, <em>Containers at Scale with Kubernetes</em>, that Kubernetes services are abstractions that work in a similar way to internal load balancers inside of the Kubernetes cluster. Essentially, we are creating a single internal (or external) IP address from which traffic from other pods or services can access any number of pods matched to a given selector. In OpenShift, we will create a service simply called <kbd>webserver</kbd> that will use an internally routed cluster IP address to intercept web server traffic and forward it to the web server pod we created as apart of our deployment. By naming our service <kbd>webserver</kbd>, it will by default use a selector criteria that matches the label <kbd>app=webserver</kbd>. This label was created by default when we created the deployment in OpenShift. Any number of labels or selector criteria can be created, which allows Kubernetes and OpenShift to select pods to load-balance traffic against. For the purposes of this example, we will use an internal cluster IP and map the selector criteria based on naming our service with the same name we named our deployment. Finally, we will select the ports we want to forward from our service externally, to the ports the service is listening on inside the container. To keep things simple, we will forward traffic destined to port <kbd>80</kbd> to the pod port <kbd>80</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~$ oc create service clusterip webserver --tcp=80:80
service "webserver" created</strong></pre>
<p style="padding-left: 90px">We can check the service configuration using the <kbd>oc get services</kbd> command. We can see that our service was created with an internally routed cluster address of <kbd>172.30.136.131</kbd>. Yours will most likely differ as these addresses are pulled from the CNI subnet within Kubernetes:</p>
<pre style="padding-left: 90px" class="western"><strong>aric@lemur:~$ oc get services
NAME        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
webserver   172.30.136.131   &lt;none&gt;        80/TCP    18m</strong></pre>
<ol start="7">
<li><strong>Create a route to enable access</strong>: Finally, we can create a route to access our service using the <kbd>oc expose</kbd> command, followed by the service name we are exposing (<kbd>webserver</kbd>). To make this routable from our workstation, OpenShift uses the <kbd>nip.io</kbd> DNS forwarding based on the IP address of the VM. We can enable this by specifying the <kbd>--hostname</kbd> flag to be any name we want the service to be accessed by, followed by the IP address of the VM, concluding with the suffix <kbd>nip.io</kbd>:</li>
</ol>
<pre style="padding-left: 60px" class="western"><strong>aric@local:~$ oc expose service webserver --hostname="awesomewebapp.192.168.99.100.nip.io"
route "webserver" exposed</strong></pre>
<p style="padding-left: 90px">Executing the <kbd>oc get routes</kbd> command will display the route we just created:</p>
<pre style="padding-left: 90px" class="western"><strong>aric@local:~$ oc get routes
NAME        HOST/PORT                            PATH      SERVICES    PORT      TERMINATION   WILDCARD
webserver   awesomewebapp.192.168.99.100.nip.io             webserver   80-80 None</strong></pre>
<p>To ensure the route is working, we can use a web browser and navigate to the forwarded DNS address we assigned to the route. If everything is working, we will be able to see the NGINX welcome screen:</p>
<div><img height="145" width="443" src="img/6706d81d-e841-4cca-94d7-d6012a7e7492.png"/></div>
<p>Feel free to continue on deploying more complex containerized applications using your local Minishift cluster. When you are finished, make sure you stop the Minishift instance using the <kbd>minishift stop</kbd> command.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">OpenShift and Ansible Container</h1>
                
            
            
                
<p>As we have seen throughout this chapter, OpenShift is a rich platform that provides valuable abstractions on top of Kubernetes. As such, Ansible Container provides ample support for deploying and running containerized application life cycles through OpenShift. Since OpenShift and Ansible Container are both products of the same parent company, Red Hat, it is apparent that OpenShift and Ansible Container will have excellent compatibility. So far, we have primarily discussed building containers using Ansible Container and running them locally on a Docker host.</p>
<p>Now that we have a firm foundation from which to understand Kubernetes and OpenShift, we can combine the knowledge we have gained so far with Ansible Container to learn how to use Ansible Container as a true end-to-end production-ready deployment and life cycle management solution. Things are about to get interesting!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">References</h1>
                
            
            
                
<ul>
<li><strong>OpenShift project</strong>: <a href="https://www.openshift.com/">https://www.openshift.com/</a></li>
<li><strong>MiniShift project</strong>: <a href="https://www.openshift.org/minishift/">https://www.openshift.org/minishift/</a></li>
<li><strong>Installing MiniShift</strong>: <a href="https://docs.openshift.org/latest/minishift/getting-started/installing.html">https://docs.openshift.org/latest/minishift/getting-started/installing.html</a></li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>Container orchestration platforms such as Kubernetes and OpenShift are rapidly being adopted by organizations to ease the complex process of scaling out applications, deploying updates, and ensuring maximum reliability. With the increasing popularity of these platforms, it is even more important that we understand the implications of adopting these technologies in order to support the organizational and cultural shift of mentality these technologies bring to the table.</p>
<p>OpenShift is a platform built on top of the Red Hat distribution of Kubernetes that aims to provide the best experience for working with Kubernetes. At the beginning of the chapter we learned what OpenShift is, and the various capabilities that Red Hat is working to deliver with the OpenShift platform. Next, we learned how to install the Minishift project, which is a developer-oriented solution for deploying OpenShift locally.</p>
<p>Once we had Minishift installed and working locally, we learned how to run pods, deployments, services, and routes from the Minishift web user interface. Finally, we learned about the OpenShift command-line interface, OC, and how it functions in a similar capacity to kubectl to provide CLI access to OpenShift and the innovative functionality that OpenShift builds on top of Kubernetes.</p>
<p>In the next chapter, my aim is to tie our knowledge of OpenShift and Kubernetes back into Ansible Container to learn about the final step in the Ansible Container workflow, deployment. The deployment functionality sets Ansible Container apart as a truly robust tool for not only building and testing container images, but also for deploying them all the way through to containerized production environments running on Kubernetes and OpenShift.</p>


            

            
        
    </body></html>