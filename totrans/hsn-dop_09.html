<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Containers, IoT, and Microservices</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will study the concepts of Containers, Virtualization, Kubernetes, Internet of Things, microservices, and so on.</p>
<ul>
<li>Virtualization:
<ul>
<li>Para virtualization</li>
<li>Container-based virtualization</li>
</ul>
</li>
<li>Introduction to containers:
<ul>
<li>Types of containers</li>
<li>Dockers</li>
<li>Java container services</li>
<li>Amazon container services</li>
<li>Pivotal container services</li>
<li>Google container services</li>
</ul>
</li>
<li>Container orchestration:
<ul>
<li>Kubernetes</li>
<li>Docker Swarm</li>
<li>Mesosphere</li>
</ul>
</li>
<li>IoT</li>
<li>Microservices</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Virtualization</h1>
                </header>
            
            <article>
                
<p>It is a method of logically dividing mainframes to simultaneously allow multiple applications to run concurrently. Bare metal applications were unable to cope up with the advancements to use abundance availability of resources such as the server processing power and capacity improvements. This paved way for designing <strong>virtual machines</strong> (<strong>VMs</strong>), by running specialized software on top of physical servers to emulate a type of underlying hardware system.</p>
<p>The same physical server can host multiple VM, each with different operating systems. Each VM runs a unique operating system and its own binaries/libraries and applications that it supports and services. VMs can be many gigabytes large. Server virtualization benefits are like a consolidation of applications onto a single system, with reduced server footprint, quicker server provisioning, improved disaster recovery, and cost savings.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hypervisor</h1>
                </header>
            
            <article>
                
<p>A hypervisor is software, firmware, or hardware that creates and runs on VMs also named as a virtual machine monitor. It is a layer between the OS and hardware to virtualize the server.</p>
<p>The hypervisor creates the virtual environment to host the guest VM. It supervises the guest systems and allocates resources to them as required. The hypervisor emulates the operation on the host machine's operating system, and provides virtualization services to the VMs in between the physical machine and virtual machines:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="313" src="assets/8a136436-5743-466f-b192-1f5591cc91f7.png" width="286"/></div>
<p>Virtualization technologies have become popular with rapid development in cloud using hypervisors, such as Xen, VMware Player, and KVM, and in incorporation of hardware support in commodity processors, such as Intel VT and AMD-V.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Types of virtualization</h1>
                </header>
            
            <article>
                
<p>The virtualization types are categorized depending on the way it mimics hardware to a guest operating system, and also emulates a guest operating environment.</p>
<p>Primarily, there are three types of virtualization:</p>
<ul>
<li>Emulation</li>
<li>Paravirtualization</li>
<li>Container-based virtualization</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Emulation</h1>
                </header>
            
            <article>
                
<p>Emulation is full virtualization to run the OS kernel of VM entirely in software. This type of hypervisor is termed as <em>Type 2 hypervisor</em>, and is installed on the top of the host operating system in order to translate a guest OS kernel code to software instructions. There is no hardware involvement, and the translation is done entirely in software layer. By emulation to any operating system that supports the underlying environment is emulate; however, the overhead of additional system resource leads to performance reduction as compared with other types of virtualizations.</p>
<p>A few examples are VMware player, VirtualBox, QEMU, Bochs, parallels, and so on are shown in the following digram:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="202" src="assets/a3f457f0-c26f-4885-a016-4d385956614f.png" width="401"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Paravirtualization</h1>
                </header>
            
            <article>
                
<p>Paravirtualization, also referred to as <em>Type 1 hypervisor</em>, runs directly on the bare-metal hardware to provide virtualization services to the VM directly running on it. It supports collaboration between the operating system, the virtualized hardware, and the bare-metal hardware to accomplish optimal performance. These hypervisors do not require extensive resources, and typically run on small footprint.</p>
<p>A few examples are Xen, KVM, and so on:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="160" src="assets/9364d2ce-a37b-41cf-935d-80e158702cae.png" width="368"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Container-based virtualization</h1>
                </header>
            
            <article>
                
<p>Container-based virtualization is also referred to as operating system-level virtualization; within a single operating system kernel, it enables executions of multiple isolated environments. This isolated virtual execution environment is called container-managed with a group of processes. It offers features and benefits such as high performance and dynamic resource management:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="313" src="assets/4d14d4af-9a54-4d71-8d37-eaf0da96ab6b.png" width="581"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Containers</h1>
                </header>
            
            <article>
                
<p>The concept of containers in IT is synonymous to the concept of containers used in the transportation sector. The basic purpose of containers is to carry or port items from source to destination.</p>
<p>Extending the same analogy, containers in IT operate on this basic purpose to port software from one server to another safely and securely. Moving an application from development server to QA (test) server and to production server is usually associated with multiple complexities, such as preparing infrastructure environment checklists, validating the compliers, libraries, runtime dependencies, and so on. The container concept is to ensure that it carries along with it the ecosystem required for an application to run from one bare-metal system to another. A container in that sense is self-sufficient, with all the requisite components, and the environment for the application to run on any server is installed. A container image is a standalone executable package, an abstraction that packages the code and dependencies at the application layer; they consume less space, and operate within the allocated resources.</p>
<p>Containers are a logical packaging mechanism to abstract the applications from the underlying environment they actually operate. Container-based applications because of decoupling can be deployed easily and consistently on a variety of target environments from private data center to the public cloud, or a personal laptop. Containerization separates roles, responsibilities, and concerns; this facilitates developers to work on the application logic and dependencies. IT operations teams, without diving into the specifics for software versions and configurations specific to the applications, can focus on pure deployment and management:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="212" src="assets/3097b100-a0f7-45a3-8678-ce48ebd38ea3.png" width="225"/></div>
<p>The attributes of a container making them quite a popular choice are:</p>
<ul>
<li><strong>Lightweight</strong>: These containers are to use fewer resources and start instantly; many containers can share the operating system kernel and use less resources. They share common files, and images are built from filesystem layers to minimize disk consumption and faster image downtime.</li>
<li><strong>Interoperability</strong>: Containers should be operating on open standards, and portable between platforms of Linux distributions (Debian, Ubuntu, and CentOs), VMs, and Windows.</li>
<li><strong>Security</strong>: Containers offer a high degree of security by isolating and separating both in between the applications and with underlying infrastructure. The isolation of issues related to an application should be contained within the container, and it neither impacts the other applications, nor the entire machine.</li>
</ul>
<p>Multiple tenancy that containers share a common kernel (system resources) through unique mount process. For each container, the commonly shared components are write-enabled, and they have read-only access. Due to this sharing concept, containers bring the following benefits:</p>
<ul>
<li>Being exceptionally lightweight</li>
<li>Quick startup time</li>
<li>Portability on a variety of cloud deployments, public, private, and so on</li>
<li>Development and testing phases are accelerated by quick assembling (package) of applications with dependencies</li>
<li>Management effort reduced to manage a single system compared with multiple servers, reduced effort for patches, and upgrades</li>
<li>Guest OS and Host OS should be compatible, so both should match like Linux, neither should be run on Windows, and vice versa:</li>
</ul>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="174" src="assets/7cd310ad-2b41-4529-a001-40677c8ebe52.png" width="373"/></div>
<ul>
<li><strong>Container security</strong>: The namespaces feature included with Linux kernel led to the creation of the concept of a container. Separate instances are created for global namespaces; the way it works is for every process the container adds a unique ID, and also for every system call, new access control checks are added. These serve as isolated containers wherein the outside objects have neither access nor visibility to the processes running inside the container. Although they share the underlying kernel, each container is treated separately; for example, the root user of each container is restricted for the respective container, adding a high security feature.</li>
<li><strong>Container management</strong>: The common kernel has full visibility among multiple containers, so it's imperative to limit the resource allocation to containers. This is accomplished by the Linux <strong>Control Groups</strong> (<strong>cgroups</strong>) subsystem for resource allocation and scheduling. Container virtualization is enabled by grouping processes to manage their aggregate resource consumption to limit memory and CPU consumption. The management tools to limit resource allocations for Linux containers are LXC, LXD, Linux-VServer, OpenVZ, Docker, systemd-nspawn, lmctfy, Warden, and so on.</li>
<li><strong>Scalability</strong>: Cluster management infrastructure supports scalability to install and operate, to schedule container-enabled applications across the cluster based on resource needs, and availability. It supports the ability to grow from single to multiple instances without additional complexity on how the applications, batch jobs, or microservices are managed, abstracting the complexity of infrastructure.</li>
<li><strong>Task definitions</strong>: Tasks are defined with declarative JSON template called <strong>task definition</strong>. Multiple containers required for the task are specified inside task definitions, and they include Docker repository/image, CPU, memory, and shared data volumes. The way containers are to be linked to each other can be part of a single task definition file registered with service. Version control for application specification is also part of task definition.</li>
<li><strong>Programmatic control</strong>: Container services provide APIs to integrate and extend services such as creation and deletion of clusters, registration and deregistration of Docker containers, including launch and termination tasks, and provide details on the cluster state and information of its instances.</li>
<li><strong>Scheduling</strong>: Applications, batch jobs, and services are managed with schedulers to run as they are designated. Schedulers place containers based on availability requirements and resource needs (such as RAM or CPU) onto the clusters. Provision for custom schedulers and integrate third-party schedulers, container management, and orchestration support with open source projects.</li>
<li><strong>Container auto-recovery</strong>: Containers automatically recover unhealthy containers, to ensure application support with the required number of containers.</li>
<li><strong>Container deployments</strong>: By uploading a newer version of application task definition, the scheduler will automatically stop the old version containers and start the containers with new versions. Ease of updating containers to new versions by conveniently registering and deregistering containers.</li>
<li><strong>Load balancing</strong>: Distribute traffic across containers with <strong>Elastic Load Balancer</strong> (<strong>ELB</strong>), by specifying in the task definition to add and remove containers from ELB. A dynamic port allocation in task definition gives unused port access to the container while scheduled; to share multiple services with ELB path-based routing is also an option.</li>
<li><strong>Local development</strong>: Docker composes an open source tool to define and run multicontainer applications; this can be extended to both work machine and production server.</li>
<li><strong>Monitoring</strong>: Clusters and containers to run tasks, average and aggregate of CPU and memory utilization, grouped by task definition, service or cluster, provision to set up alarms in order to alert to scale up or down the containers.</li>
<li><strong>Logging</strong>: The details of agent logs, API calls, and Docker logs are captured for issue diagnostics, the time of the API call, the API call source IP address, the request parameters, response elements, security analysis, compliance, audit, and resource change tracking.</li>
<li><strong>Repository support</strong>: Container service along with third-party, private Docker registry, or Docker hub image repository accessibility to retrieve appropriate images.</li>
<li><strong>Security</strong>: Inbuilt features to gain visibility into roles and access at task level, and manage instance-based roles and task-based roles separately with least privilege policy.</li>
</ul>
<p>As we have seen, the containers are standardized units of software development, incorporating everything as code, runtime, system tools, and system libraries for software applications to run. The image is a read-only template to create containers. Application components must be architected to deploy and run in containers.</p>
<p>Containers have become popular in digital technology and offered by many vendors a like. Docker is a popular container choice, so its adoption and support is a natural choice by other vendors:</p>
<ul>
<li><span>Dockers</span></li>
<li>Java container services</li>
<li>Amazon</li>
<li>Pivotal</li>
<li>Azure</li>
<li>Google</li>
<li>IBM Bluemix container service</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Docker containers</h1>
                </header>
            
            <article>
                
<p>Docker container platform is available as <strong>Community Edition</strong> (<strong>CE</strong>) and <strong>Enterprise Edition</strong> (<strong>EE</strong>), with optimized installers for a variety of infrastructure:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="311" src="assets/7f95b606-d68a-4dee-80fe-a088924433aa.png" width="276"/></div>
<p>The features of Docker container services are as follows:</p>
<ul>
<li><strong>Universal packaging</strong>: This packages apps of any programming language or service into containers to port them, without the risk of incompatibilities, or version conflicts.</li>
<li><strong>Developer toolkit</strong>: Readily available containers in the Docker store offer everything needed to build, test, and run multicontainer apps for any programming language.</li>
<li><strong>Container orchestration in-built</strong>: In-built clustering at scale with sophisticated scheduling to monitor, build highly available and fault-tolerant services to run apps.</li>
<li><strong>Highly secure</strong>: Security out-of-the-box with mutual TLS, certificate rotation, container isolation, and image signing makes it secure and easy-to-use container app runtimes.</li>
<li><strong>App-centric networking</strong>: Containers connected together with software-defined networking to intelligent routes and load balances traffic. Container-defined networks abstract configuration and deploy apps from underlying network infrastructure.</li>
<li><strong>Extensible architecture</strong>: Integration with third-party systems for Open APIs, plugins, and drivers is convenient to change storage and networking backends with minimal or no code changes.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Java EE containers as a part of Java EE</h1>
                </header>
            
            <article>
                
<p>Thin-client multi-tiered applications to handle transaction and state management, multithreading, resource pooling, and other complex low-level details involve many lines of intricate code and hard-to-maintain Java EE architecture is component-based and platform independent, ensuring convenience for Java EE applications, as business logic is organized into reusable components, and provides underlying services in the form of a container for every component type. Rather than investing to develop these services, concentrate on solving the business problem at hand.</p>
<p>Java containers are the interface between a component and the low-level platform-specific functionality that supports the component. For a web service, the enterprise beans, the application client component must be assembled into a Java EE module, and deployed into its container to be executed.</p>
<p>For the assembly process, container settings are specified for each component of the Java EE application, and also the Java EE application itself. Container settings can be customized with the underlying features of the Java EE server, such as transaction management, <strong>Java Naming and Directory Interface</strong> (<strong>JNDI</strong>) lookups, security, and remote connectivity.</p>
<p>Some features are:</p>
<ul>
<li>The Java EE security model-authorized users are configured access for a web component or enterprise.</li>
<li>The Java EE transaction model treats all methods in one transaction as a single unit, by specifying relationships among methods to cluster them as a single transaction.</li>
<li>A JNDI lookup service helps application components access a unified interface in the enterprise to the multiple naming and directory services.</li>
<li>The Java EE remote connectivity model mimics VM by invoking methods to manage low-level communications between clients after enterprise beans are created.</li>
</ul>
<p>The Java EE architecture features configurable services, and application components within itself, so can provide different functionality like security settings levels of access to database data customized for each production environment. The Java EE container facilitates nonconfigurable services such as enterprise bean and servlet life cycles, data persistence, database connection, resource pooling, and access to the Java EE platform APIs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Java EE server and containers</h1>
                </header>
            
            <article>
                
<p>The container types in the Java EE application components are:</p>
<ul>
<li><strong>Java EE server</strong>: This is the runtime environment of Java EE, and provides EJB and web containers.</li>
<li><strong>Enterprise JavaBeans (EJB) container</strong>: It's part of Java EE server, and it's responsible for the execution of enterprise beans for Java EE applications.</li>
<li><strong>Web container</strong>: They are part of Java EE server. They manage the execution of JSP page and servlet components for Java EE applications. Web components and their containers run on the Java EE server.</li>
<li><strong>Application client container</strong>: This hosts application clients and their containers' execution.</li>
<li><strong>Applet container</strong>: This is responsible for execution of applets, and hosts web browser and Java plugin together to run on the client.</li>
</ul>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="318" src="assets/1af0bd14-06fb-453f-94f1-4ba7c907ffaf.png" width="385"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Amazon ECS container service</h1>
                </header>
            
            <article>
                
<p>Amazon ECS comes with a variety of following features:</p>
<ul>
<li>Highly scalable, fast container management service</li>
<li>Manage Docker containers are easy to run, stop on a cluster of <strong>Amazon Elastic Compute Cloud</strong> (<strong>Amazon EC2</strong>) instances</li>
<li>Container-based applications launch and stop through simple API calls</li>
<li>Centralized service to monitor state of your cluster, and access to many familiar Amazon EC2 features</li>
<li>Schedule the containers placement across the clusters based on resource needs, isolation policies, and availability requirements</li>
<li>Consistent deployment and build experience, manage scale <strong>Extract-Transform-Load</strong> (<strong>ETL</strong>) and batch workloads</li>
<li>Build sophisticated microservices and model-based application architectures</li>
<li>Provides more fine-grained control and access to a wider set of use cases, hence more popular compared with AWS Elastic Beanstalk</li>
</ul>
<p>Amazon ECS is also highly available, which supports the concept of running application containers across multiple availability zones. Container images are stored in and pulled from container registries (either within or outside of AWS). Task definitions and services are defined to specify alignment of Docker container images to run on respective clusters:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="507" src="assets/0765500a-cfb2-4c1f-8898-77cd97447ca9.png" width="423"/></div>
<p>The Amazon ECS multizone architecture components are discussed further.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Containers and images</h1>
                </header>
            
            <article>
                
<p>Application components must be architected to run in containers for deployment to ECS. The standardized unit is Docker container for software development, comprising application requirements to run code, runtime, system tools, system libraries, and so on. An image template is used to create containers, and it specifies all of the components to be part of the container. It is typically a read-only format file created from a plain text Dockerfile, stored in a registry for download and run on container instances:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="240" src="assets/3a096d53-ee07-47c2-a4ed-35db0ceb0017.png" width="528"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Task definitions</h1>
                </header>
            
            <article>
                
<p>Task definitions prepare the application to run on ECS as a blueprint for the application, a JSON format text file. It describes the application use by various parameters as to which containers to use, the corresponding ports to be opened, the repositories to be located, and the data volumes to be used with the containers for the tasks on a web server such as Nginx.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tasks and scheduling</h1>
                </header>
            
            <article>
                
<p>With task definition, the number of tasks are specified for instantiation on a container instance within the cluster. Task scheduler is responsible for placing and scheduling tasks on container instances simultaneously:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/e06a543e-bad0-468f-8a36-c7f36c8a50c0.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Clusters</h1>
                </header>
            
            <article>
                
<p>A cluster is a logical grouping of instances to run tasks. The container images are downloaded from a specified registry to run them on the container instances within the cluster.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Container agent</h1>
                </header>
            
            <article>
                
<p>The container agent runs on each instance within the cluster. It relays the instance's information such as current running tasks and resource utilization to <span>also </span>start and stop tasks as per the requests:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="378" src="assets/645a866e-dd70-4e5e-a8f6-aab6175dafde.png" width="442"/></div>
<p>Amazon ECS functionality can be augmented using additional services in conjunction:</p>
<ul>
<li><strong>Identity and access management</strong>: IAM is a web service to control access to resources securely for users by authentication to control use of resources and authorization on how to access resources. Using IAM roles control access at the container instance level, and also the task level are managed.</li>
<li><strong>Autoscaling</strong>: Autoscaling is a web service to scale out and scale in the container instances, automatically launching or terminating EC2 instances. It could be defined in user-defined policies, health status checks, and schedules.</li>
<li><strong>Elastic Load Balancing</strong>: ELB accomplishes high levels of fault tolerance for applications by distributing the incoming application traffic automatically across multiple EC2 instances, and across services in a cluster.</li>
<li><strong>EC2 Container Registry:</strong> Docker registry service is secure, scalable, and reliable. Resource-based permissions enabled by IAM to access repositories and images on Docker private repositories. Docker CLI can be used to push, pull, and manage images.</li>
<li><strong>AWS Cloud Formation</strong>: AWS Cloud Formation is a convenient way to create, manage, provision, and update a collection of related AWS resources. Cloud Formation script can help define clusters, task definitions, and services in an orderly and predictable fashion as entities in an AWS.</li>
<li><strong>Amazon ECS CLI</strong>: Amazon ECS CLI using Docker compose from a local development environment. It provides high-level commands to create, update, and monitor clusters and tasks.</li>
<li><strong>AWS SDKs</strong>: The SDKs support programming languages, and take care of tasks automatically such as:
<ul>
<li>Signing of service requests cryptographically</li>
<li>Retrying requests</li>
<li>Error responses handling</li>
</ul>
</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pivotal container services</h1>
                </header>
            
            <article>
                
<p>Pivotal technologies offer container services with the following core features:</p>
<ul>
<li>Containerized workloads are reliably deployed and run across private and public clouds.</li>
<li>Container orchestration is built in with high availability, automated health checks, monitoring, and so on.</li>
<li>Suited for Spark and elastic search workloads needing access to infrastructure primitives.</li>
<li>Apt for apps that require specific colocation of container instances, and where multiple port binds are needed.</li>
<li>High operational efficiency for Kubernetes and Open Source Kubernetes with latest stable OSS distribution no proprietary extensions.</li>
<li>On-demand provisioning with BOSH, a powerful release engineering tool chain, a reliable and consistent operational experience on any cloud.</li>
<li>Multicloud flexibility to deploy and consume Kubernetes on-premises with vSphere, or in the public cloud.</li>
<li>Network Management and Security to programmatically manage software-based virtual networks, out-of-the-box network virtualization on vSphere and VMC.</li>
<li>Fully automated Ops can deploy, scale, patch, and upgrade the system without downtime also for Kubernetes clusters.</li>
<li>Easy integration with VMware tools like vRealize Operations Manager, vSAN network storage, and Wavefront for a full-featured on-prem deployment.</li>
<li>Harbor, an enterprise-class container registry server, is part of PKS. Harbor extends features for an open source Docker like vulnerability scanning, identity management, and support for multiple registries.</li>
<li>Integrated with the PCF Service Catalog, easily adds APM tools, database services, and the Service Broker API. Extend PKS with a growing library of add-on services.</li>
<li>Constant compatibility with GKE, can easily move workloads to (and from) GKE.</li>
<li>PKS is built on top Kubo, an open-source project managed by the Cloud Foundry Foundation.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Google container services</h1>
                </header>
            
            <article>
                
<p>Google container services is a popular choice, with features as listed here:</p>
<ul>
<li>Google containerized application management offers multiple advanced features and flexibility</li>
<li>Container engine provides a managed environment for containerized applications to deploy, manage, and scale on a container cluster</li>
<li>Kubernetes open source cluster management system powers container cluster engine</li>
<li>Provides tools and interface to perform administration tasks, manage, deploy applications, and set up policies</li>
<li>Monitors status of application containers, the health of deployed workloads</li>
<li>Load-balancing for compute engine instances</li>
<li>Node pools within a cluster as a subset for additional flexibility</li>
<li>Automatic scaling of cluster's node instances</li>
<li>Automatic upgrades for cluster's node software versions</li>
<li>Auto-repair of node to maintain node health and availability</li>
<li>Stack driver logging and monitoring for visibility into your cluster</li>
<li>Master and node architecture for the cluster</li>
<li>IP aliases, IAM, role-based access, and so on</li>
<li>IP rotation and IP Masquerade agent</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Container orchestration</h1>
                </header>
            
            <article>
                
<p>Container orchestration is the process of automatically deploying multiple containers in an optimized manner to implement an application. This is quite important with a growing number of containers and hosts day by day. Orchestration means the automation of the process, and includes a number of features:</p>
<ul>
<li>Hosts provisioning</li>
<li>Set of containers instantiation</li>
<li>Failed containers rescheduling</li>
<li>Containers linking together with interfaces</li>
<li>Exposing services outside of the cluster to machines</li>
<li>Scaling by adding or removing containers, out or down the cluster</li>
</ul>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/a6c17a1e-227c-49a1-aa92-8d210ef099e9.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Orchestration tools</h1>
                </header>
            
            <article>
                
<p>A few popular orchestration tools are listed here:</p>
<ul>
<li>Mesos</li>
<li>Kubernetics</li>
<li>CorCos Tectonic</li>
<li>Docker Swarm</li>
</ul>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/4b4006b7-7f58-4d0d-9799-41ebbb57e7a3.png"/></div>
<p>The popularity of repositories as per their usage is shown in following image:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="397" src="assets/e7f7aac8-89bd-4877-9ec7-f4382cfc7b1c.png" width="300"/></div>
<p>The three key differentiators among the orchestration tools to select for organization are:</p>
<ul>
<li><strong>Level of abstraction</strong>: Support for containers or services that are container-based</li>
<li><strong>Tooling</strong>: Orchestration management and integration with other services</li>
<li><strong>Architecture</strong>: How does it support scalability and recover from failure?</li>
</ul>
<p>We will discuss the following popular tools in detail:</p>
<ul>
<li>Kubernetes</li>
<li>Docker Swarm</li>
<li>Mesosphere</li>
</ul>
<p>Each orchestration platform has advantages compared with the others. There are multiple evaluations to consider, such as:</p>
<ul>
<li>Enterprise DevOps framework and orchestration methodology along with APIs</li>
<li>Number of hosts if over thousands of physical machines
<ul>
<li>Mesos can be considered for large farm</li>
</ul>
</li>
<li>Are the containers based on bare metal, private VMs, or in the cloud?
<ul>
<li>For cloud deployments, Kubernetes is popular</li>
</ul>
</li>
<li>Need for automated high availability
<ul>
<li>Kubernetes failed pods/containers will be automatically rescheduled by replication controller</li>
<li>In Mesos application's framework, code performs that role for automated high availability</li>
</ul>
</li>
<li>Grouping and load balancing requirement for services
<ul>
<li>Kubernetes provides this, but Mesos application's framework code performs it</li>
</ul>
</li>
<li>Organization skills
<ul>
<li>Mesos allow application to run as a framework programmatically with custom coding</li>
<li>Kubernetes is more declarative</li>
</ul>
</li>
<li>Setting up orchestration frameworks infrastructure can have challenges</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Kubernetes</h1>
                </header>
            
            <article>
                
<p>Kubernetes was created by Google, and now with <strong>Cloud Native Computing Foundation</strong> (<strong>CNCF</strong>). Its concept is to build orchestration for container deployments across multiple domains public clouds to hybrid deployments.</p>
<p>Kubernetes makes deploying and managing application easier, automates deployment, scaling, and management of containerized applications. Kubernetes adds the higher-level functions, such as load balancing, high availability through failover (rescheduling), and elastic scaling, as follows:</p>
<ul>
<li>Automatic health checks against the services</li>
<li>Self-healing, restarting containers that fail, or have stalled</li>
<li>Horizontal scaling, scale services up or down based on utilization</li>
<li>Service discovery and load balancing</li>
<li>Version-controlled automated rollouts and rollbacks</li>
<li>Secret and configuration management</li>
<li>Storage orchestration only running what is needed</li>
<li>Batch execution, declaratively manages your cluster</li>
</ul>
<p>The key components making up Kubernetes are:</p>
<ul>
<li>A cluster is a collection of nodes, either bare-metal servers or VMs providing the resources to run one or more applications.</li>
<li>Pods are co-located resources on the same host groups, such as containers and volumes. Pod-based containers share the same network namespace and use localhost to communicate. Pods are the basic scheduling unit, ephemeral not designed as durable entities.</li>
<li>Labels are tags that allow them to be managed as a group. Like assigned to entities such as containers to be exposed as a service to the outside world.</li>
<li>Services are basic load balancers and references for exposing them to the outside world and other containers.</li>
<li>The replication controller manages the scheduling of pods across the cluster.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Docker orchestration tools</h1>
                </header>
            
            <article>
                
<p>Docker orchestration most common tools are described here:</p>
<ul>
<li><strong>Docker Swarm</strong>: It is one of the most easy-to-use orchestrators, with just a couple of commands. It lets you spin up your first cluster much like the first container.</li>
<li><strong>Docker Engine</strong>: It is the lightweight runtime and tooling engine used to run Docker containers.</li>
<li><strong>Docker Machine</strong>: This provisions hosts and installs Docker Engine software on them.</li>
<li><strong>Docker Swarm</strong>: By clustering multiple Docker hosts together produces a single, virtual Docker host. It enables Docker API to integrate with tools compatible with a single Docker host.</li>
<li><strong>Docker Compose</strong>: Applicable for development, testing, and staging environments. Creates required containers for deploying requisite application from a file defining a multicontainer application along with its dependencies.</li>
<li><strong>Apache Mesos</strong>: It is adopted by large enterprises, such as Twitter, Airbnb, and Apple, as it's designed to scale to tens of thousands of physical machines. A framework in Mesos is an application running on one or more containers. Each frame can accept the resources offered by Mesos. Compared to Kubernetes, Mesos is less in features, involves extra integration work, is programmatic, defining services or batch jobs. Mesos also supports the fine-grained resource allocation across the nodes in a cluster of Kubernetes pods:</li>
</ul>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/ea33a793-296e-453c-9f1c-26b6536c0402.png"/></div>
<p>Mesos is proved to be efficient wherein the application is collocated with other services such as Hadoop, Kafka, and Spark. Mesos is the foundation for few distributed systems as follows:</p>
<ul>
<li><strong>Apache Aurora</strong>: A highly scalable scheduler service for long-running services and cronjobs such as adding rolling updates, service registration, and resource quotas</li>
<li><strong>Chronos</strong>: A fault-tolerant service scheduler for orchestrating scheduled jobs within Mesos as a replacement for Cron</li>
<li><strong>Marathon</strong>: A simple-to-use service scheduler; it enhances performance of Mesos and Chronos by running two Chronos instances simultaneously</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Internet of Things (IoT)</h1>
                </header>
            
            <article>
                
<p>IoT integrates sensory data, big data, networking, robotics, and artificial intelligence technology into an advanced automation and analytics system. IoT, when applied to any industry or system, can bring in greater transparency, control, and performance to deliver a complete product or service.</p>
<p>IoT systems span across industries using smart devices and enabling powerful technology to enhance data collection, analysis, achieve deeper automation, operations and integration through applications apt in any environment.</p>
<p>IoT benefits span across multiple business domains and even lifestyles providing benefits of improved customer engagement, technology optimization, reduced waste, enhanced data collection, and so on.</p>
<p>IoT-perceived challenges are as follows:</p>
<ul>
<li><strong>Security</strong>: An ecosystem of constantly connected devices communicating over networks even with security measures is vulnerable</li>
<li><strong>Privacy</strong>: Substantial personal data is captured without the user's active participation</li>
<li><strong>Complexity</strong>: Design, deployment, and maintenance of IoT systems integrating multiple technologies is a complex system</li>
<li><strong>Flexibility</strong>: IoT systems with several interfacing and locked systems are tightly coupled</li>
<li><strong>Compliance</strong>: When standard software compliance to comply with regulations is challenging, complexity of IoT makes the issue of regulatory compliance much more challenging</li>
</ul>
<p>The most important features of IoT include connectivity, sensors, active engagement, and being a small device and artificial intelligence combination:</p>
<ul>
<li><strong>Connectivity</strong>: New enabling technologies between system devices, specifically IoT networking on a much smaller and cheaper scale, need not be exclusively tied to major providers.</li>
<li><strong>Sensors</strong>: IoT capability comes with sensors that transform IoT from a standard passive network of devices into an interactive integrated system to address real-world needs</li>
<li><strong>Active engagement</strong>: IoT introduces real-time interaction with connected technology, a new paradigm for active content, product, and service engagement</li>
<li><strong>Small devices</strong>: Purpose-built small devices extend IoT capabilities to deliver its precision, scalability, and versatility at low, affordable costs</li>
<li><strong>Artificial intelligence</strong>: IoT essentially enhances every aspect of life with the power of data collection and analytics with artificial intelligence algorithms</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IoT - eco system</h1>
                </header>
            
            <article>
                
<p>IoT systems capture data with hardware devices such as remote dashboard, control devices, sensors, servers, and routing bridge device. Key tasks and functions managed with these devices can extend to system activation, security, communication, action, and detection.</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="180" src="assets/cdffc013-71a3-4c6e-a79b-3efee6e3fc49.png" width="447"/></div>
<p>Multiple devices sensors for different functions are:</p>
<ul>
<li>Accelerometers</li>
<li>Magnetometers</li>
<li>Gyroscopes</li>
<li>Acoustic sensors</li>
<li>Pressure sensors</li>
<li>Humidity sensors</li>
<li>Temperature sensors</li>
<li>Proximity sensors</li>
<li>Image sensors</li>
<li>Light sensors</li>
<li>Gas RFID sensors</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Standard devices</h1>
                </header>
            
            <article>
                
<p>The standard devices such as desktop, tablet, and cell phone are also integrated with IoT for command interfaces and remote management.</p>
<p>Desktop and tablet can offer the highest level of control for the system and its settings.</p>
<p>Cell phone can also provide remote functionality to modify some settings or configurations.</p>
<p>Routers and switches are standard network devices, and key to connected devices.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data synthesis</h1>
                </header>
            
            <article>
                
<p>IoT systems effectiveness is through data collection, device integration, real-time analytics, networking, and action through platforms, embedded systems, partner systems, and middleware. These individual and master applications are responsible for integration with critical business systems, such as ordering systems, robotics, and scheduling within the IoT network.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data collection</h1>
                </header>
            
            <article>
                
<p>The data collection software collects and eventually transmits all collected data to a central server. It collects variety of data such as sensory data, measurements by applying data filtering, data security, and aggregation of data. Through protocols, data from multiple devices and sensors are connected real time with machine-to-machine networks. It also can reverse transmit distributing data back to the devices.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Device integration</h1>
                </header>
            
            <article>
                
<p>Integration of all connected system devices through dependency and relationships binds the IoT ecosystem. It ensures that the necessary cooperation manages the various applications, protocols, and limitations of each device to allow communication and stable networking between devices.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Real-time analytics</h1>
                </header>
            
            <article>
                
<p>The analytics applications collect real-time data input from various devices, and convert it into clear patterns for human analysis and viable actions. The information analysis and visualization techniques can be extended for automation-related tasks specific to industry requirements.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Application and process extension</h1>
                </header>
            
            <article>
                
<p>These IoT applications integrate predefined devices to extend the reach of existing systems such as allowing certain mobile devices, or engineering instruments access and software to allow a wider, more effective system to improved productivity and more accurate data collection and analysis.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technology and protocols</h1>
                </header>
            
            <article>
                
<p>IoT technologies, apart from standard networking protocols, are RFID, NFC, low-energy radio protocols, low-energy Bluetooth, low-energy wireless, LTE-A, and WiFi-Direct, all of which support the specific networking functionality needed in an IoT system. We will review these technologies.</p>
<p><strong>Radio-frequency identification</strong> (<strong>RFID</strong>) and <strong>near-field communication</strong> (<strong>NFC</strong>) are simple, low-energy options connection bootstrapping, and payments for identity and access tokens.</p>
<div class="packt_infobox">More information on the IoT technologies and Protocols can be found at: <a href="https://www.tutorialspoint.com/internet_of_things/internet_of_things_quick_guide.htm"><span class="URLPACKT">https://www.tutorialspoint.com/internet_of_things/internet_of_things_quick_guide.htm</span></a></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IoT - application in multiple fields</h1>
                </header>
            
            <article>
                
<p>The following are the applications of IoT across multiple fields:</p>
<ul>
<li><strong>Wearable electronics</strong>: The penetration of IoT smart wearable electronics, such as helmets, watches, shoes, and glasses</li>
<li><strong>Manufacturing and engineering industry</strong>: Dynamic response to market demands, malfunctions in equipment, problems in the distribution network, customer needs, nonconforming product, lower costs, optimized resource use, and waste reduction</li>
<li><strong>Product safety</strong>: Avoid malfunctions, nonconforming product, and other hazards, avoiding recalls, and controlling nonconforming or product distribution to market</li>
<li><strong>Healthcare applications</strong>: Healthcare in remote areas can be extended by IoT applications to offer high level of medical assistance as in developed areas supporting mobile clinics</li>
<li><strong>Housing, environment, health, and safety applications</strong>: Also use IoT to extend their productivity, benefits for improved quality of life</li>
<li><strong>Transportation application</strong>: Extend to commercial vehicles on road, trains, UAVs provide improved communication, control, and data distribution</li>
<li><strong>Commercial farming</strong>: Exploiting advanced biotechnology, IoT enables deeper automation and analysis</li>
</ul>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/831e33c2-fe48-4aff-aff2-bd0ff62f28da.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IoT platforms for development</h1>
                </header>
            
            <article>
                
<p>There are many IoT development platforms with integrated development tools to support connectivity, analysis for the rapid development, and deployment of smart, connected devices:</p>
<ul>
<li>ThingWorx by PTC</li>
<li>Virtualized Packet Core by Cisco</li>
<li>Electric Imp- Salesforce</li>
<li>Predix by GE</li>
<li>Eclipse IoT</li>
<li>Contiki is open source</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ThingWorx</h1>
                </header>
            
            <article>
                
<p>Enables rapid development with interfaces and embedded tools such as Vuforia, Kepware, Composer, Mashup builder, search engine for storage, collaboration, and connectivity:</p>
<ul>
<li>Vuforia for reality development</li>
<li>Kepware for single-point data distribution to facilitate interoperability in alignment</li>
<li>ThingWorx agent for industrial connectivity</li>
<li>The composer is the modeling environment for design testing</li>
<li>The Mashup builder is a dashboard to build components</li>
<li>SQUEL is the search engine, extension means search, query, and analysis; it's for analyzing and filtering data</li>
<li>Data shapes describe data structures of custom events, infotables, streams, and data tables</li>
<li>Thing templates allow new devices to inherit properties in large IoT systems</li>
<li>Thing shapes define templates, properties, or execute services, allowing developers to avoid repeating device property definitions</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Virtualized Packet Core (VPC)</h1>
                </header>
            
            <article>
                
<p>VPC technology provides core services for 4G, 3G, 2G, Wi-Fi, and small cell networks with key features such as packet core service consolidation, dynamic scaling, and system agility. The networking functionality is delivered as virtualized services for greater scalability and faster deployment at a reduced cost of new services. It distributes and manages packet core functions, whether virtual or physical, across all resources:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="218" src="assets/b67611fb-a583-4c9b-9df3-5927b383531d.png" width="343"/></div>
<p>VPC application is more prominent for network function virtualization, <strong>software-defined networking</strong> (<strong>SDN</strong>), and rapid networked system deployment by supporting low-power, high-flow networking, and the simple deployment of a wide variety of small devices. VPC introduces direct communication over a standard network, enhanced automated monitoring, automatic data updates through smart signs, and native IP networks along with <strong>Power over Ethernet</strong> (<strong>PoE</strong>) technology for all devices, improving overall safety and quality of service.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Electric Imp</h1>
                </header>
            
            <article>
                
<p>Salesforce Electric Imp platform is for quickly connecting devices to the cloud, and developing applications through a high-level, OO, lightweight scripting language named Squirrel language. Applications consist of two modules:</p>
<ul>
<li>The device module runs on the device</li>
<li>The agent module runs in the Electric Imp cloud</li>
</ul>
<p>The Electric Imp platform ensures secure communication messages with a simple call between the modules, standard web application development coding for device interaction, monitoring, and response with a simple, easy-to-learn syntax.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Predix</h1>
                </header>
            
            <article>
                
<p><strong>General Electric</strong> (<strong>GE</strong>) Predix is a software platform for industrial instruments. It's a cloud-based <strong>Platform as a Service</strong> (<strong>PasS</strong>), data collection platforms to enable industrial-grade analytics. It connects factories data, individuals, and equipment in a simple way for operations optimization and performance management. A predix ecosystem consists of an Intel Edison processor module, of a dual core board and a Raspberry Pi board. Developers provide an IP address, Ethernet connection, power supply to automatically establish the connection, register with the central Predix system, to transmit data from sensors.</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/4cca497f-454c-4ba2-8b71-dcc38a540bcc.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Eclipse IoT</h1>
                </header>
            
            <article>
                
<p>An open source technology-based Eclipse IoT is an ecosystem of entities (industry and academia), creating open source frameworks and services for utilization in IoT solutions, developing tools for IoT developers, open source implementations of IoT standard technology. There are a few utilities, as mentioned next:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="103" src="assets/4da20216-0474-4594-9c78-144ef3302cd4.png" width="119"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SmartHome</h1>
                </header>
            
            <article>
                
<p>Eclipse IoT's major service SmartHome is a framework for building smart home solutions, with assorted protocols and standards integration for heterogeneous environments. It facilitates interaction between devices by uniform device and information access consisting of OSGi bundles to deploy in an OSGi runtime, with OSGi services. OSGi bundles are Java class groups and other resources with manifest files containing information on file contents, services to enhance class behavior, and the nature of the aggregate as a component, and so on.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Eclipse SCADA</h1>
                </header>
            
            <article>
                
<p>Eclipse state-of-the-art open source SCADA is to connect various industrial instruments with a shared communication system to post-processes data. The technologies incorporated are shell applications, JDBC, Modbus TCP and RTU, Simatic S7 PLC, OPC, and SNMP. The SCADA system is with communication service, monitoring system, archive, and data visualization for developing custom solutions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Contiki</h1>
                </header>
            
            <article>
                
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="77" src="assets/d34fb6bd-429e-44eb-9e93-6dde03db6c0a.png" width="255"/></div>
<p>Open source operating system Contiki provides functionality for small IoT devices for management of programs, processes, resources, memory, and communication. Its ecosystem is an operating system, a web browser, web server, calculator, shell, telnet client and daemon, email client, VNC viewer, and FTP.</p>
<p>Its popular with academics, organization researchers, and professionals being very lightweight quite apt for devices with limited memory, power, bandwidth, and processing power requires a few kilobytes to run, and within a space of under 30 KB.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Contiki communication</h1>
                </header>
            
            <article>
                
<p>Standard protocols supported by Contiki, and also enabling protocols for IoT include:</p>
<ul>
<li><strong>uIP (for IPv4)</strong>: This TCP/IP supports 8-bit and 16-bit microcontrollers.</li>
<li><strong>uIPv6 (for IPv6)</strong>: Extension to uIP is a fully compliant IPv6.</li>
<li><strong>Rime</strong>: This offers a set of primitives for low-power systems and alternative stack when IPv4 or IPv6 are not applicable.</li>
<li><strong>6LoWPAN</strong>: This stands for IPv6 over low-power wireless personal area networks. A low data rate wireless compression technology to support devices with limited resources.</li>
<li><strong>RPL</strong>: This distance vector IPv6 protocol can find the best path for devices with varied capability in complex network of LLNs (low-power and lossy networks).</li>
<li><strong>CoAP</strong>: This protocol is for simple devices requiring a heavy remote supervisor.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dynamic module loading</h1>
                </header>
            
            <article>
                
<p>Dynamic module loader loads, relocates, and links ELF files to load and link at run-time supports environments to support application behavior changes after deployment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Cooja network simulator</h1>
                </header>
            
            <article>
                
<p>The Cooja Contiki network simulator spawns to compile for working Contiki and control system by Cooja simulator.</p>
<p>IoT devices, security, compliance and maintenance are important features to be thoroughly considered while adopting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Microservices</h1>
                </header>
            
            <article>
                
<p>It is an architecture pattern to structure as loosely coupled services to implement business capabilities, enabling an organization to evolve its technology stack on continuous delivery/deployment of large, complex applications.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Microservices core patterns</h1>
                </header>
            
            <article>
                
<p>Microservice architecture is the core differentiator compared to monolithic architecture.</p>
<p>Monolithic architecture was based on unique requirement for building server-side enterprise application. It has to support a variety of clients, such as browsers from desktop, mobile, expose itself to third-party, and integrate with other applications through web services or message broker. Business logic is executed by handling HTTP requests and messages with a database, and returning a HTML/JSON/XML response:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="229" src="assets/b042db02-06cd-41cd-b518-8a04f7cd6220.png" width="443"/></div>
<p>The challenges associated with such architecture are:</p>
<ul>
<li>The large monolithic code base is difficult to maintain, modularity breaks down over time because there are no hard module boundaries; hence, implementing a change becomes cumbersome over time.</li>
<li><strong>Overloaded IDE</strong>: The slower the IDE with the larger the code base lower productivity.</li>
<li><strong>Overloaded web container</strong>: The larger the application, the longer it takes the container to start up, deployment lowers developer productivity too.</li>
<li><strong>Continuous deployment is difficult</strong>: Large monolithic application frequent deployments for updates are challenge. The user interface need to be developed iterative and redeployed frequently, the risk associated with redeployment increases.</li>
<li><strong>Scaling the application can be difficult</strong>: A monolithic architecture can only scale in one dimension with an increasing transaction volume by running more copies of the application, adjusting the number of instances dynamically based on load. However, with an increasing data volume, the architecture can't scale. Each application instance copy will access all of the data, making the caching less effective and increasing memory consumption and I/O traffic. With a monolithic architecture scaling, each component independently for different resource requirements will be challenge such as CPU intensive and might memory intensive.</li>
<li><strong>Obstacle to scaling development</strong>: A monolithic application prevents the teams from working independently, so it should be coordinated development between the UI team, accounting team, inventory team, and so on. Once the application gets to a certain size, it is an obstacle to scalability to develop involving multiple teams.</li>
<li><strong>Long-term commitment to a technology stack</strong>: A monolithic architecture could be tied to a technology stack, and a particular version of upgrading with some newer technology framework will be tedious. If platform framework subsequently becomes obsolete, then to adopt a newer platform framework rewriting the entire application could be a risky proposal.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Microservices architecture</h1>
                </header>
            
            <article>
                
<p>Microservices are a set of loosely coupled collaborating services that are the building blocks of applications. Each service implements a set of narrowly, related functions such as order management and the customer management services. The services communicate with each other with synchronous protocols such as HTTP/REST, or asynchronous protocols such as AMQP. The services are independently developed and deployed with its own database decoupled from other services with data consistency enforced.</p>
<p>The divers for microservices architecture are:</p>
<ul>
<li>To build application quickly, easy to understand, maintain and continuous deployment.</li>
<li>Scalability and availability to run on multiple machines, multiple copies of the application</li>
<li>Emerging technologies adoption for frameworks, programming languages, and so on</li>
</ul>
<p>An application built on these lines could be of several components such as StoreFrontU to implement the user interface, backend services to check credit, maintaining inventory, and shipping orders. This can take orders from customers, check inventory, credit availability, and ship them:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="298" src="assets/f4c301b2-280f-49af-8baf-2375bd94e491.png" width="363"/></div>
<p>This solution has a number of advantages:</p>
<ul>
<li>Each microservice is relatively nimble to understand, and can build faster and deploy; the IDE is faster and more productive</li>
<li>Each service can be developed by their respective teams, and deployed of other services independently</li>
<li>Frequent deployment for new versions is easier</li>
<li>Improved fault isolation any service memory leak will affect only that service, and other services will continue to handle requests unaffected</li>
<li>Flexible to adopt new technology stack</li>
</ul>
<p>Challenges associated with microservices-based solutions are:</p>
<ul>
<li>Complexity of creating distributed systems with multiple services transactions.</li>
<li>IDE support and testing is difficult, including the inter-service communication mechanism for coordinating multiple services between the teams.</li>
<li>Deployment/operational complexity of deploying and managing a system comprised of many different service types.</li>
<li>Increased memory usage: The microservice architecture runs its own VM to isolate the instances. If there are <em>M</em> instances, there will be <em>M</em> times the VMs causing the overhead.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Microservice decision</h1>
                </header>
            
            <article>
                
<p>Microservice architecture is more appropriate for larger, complex scale of application, rather than small or startup applications where in monolithic is more appropriate. Microservice architecture structures an application as a set of loosely coupled services to accelerate software development by enabling continuous delivery/deployment.</p>
<p>Microservice decision is based on the following:</p>
<ul>
<li>Microservice based on business capability</li>
<li>Microservice based on subdomain</li>
<li><strong>Object-oriented design</strong> (<strong>OOD</strong>)</li>
<li><strong>Single Responsibility Principle</strong> (<strong>SRP</strong>)</li>
<li><strong>Common Closure Principle</strong> (<strong>CCP</strong>)</li>
</ul>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/201a399d-bc5d-48e3-8e43-9d99a94588c9.png"/></div>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="251" src="assets/6f1cacb1-1da3-47a5-bb90-2b1e591d3d02.png" width="408"/></div>
<p><strong>Microservice architecture</strong>--service must be adequately planned to be developed by a small team and to be easily tested. The SRP is a basis for service design to define responsibility of a class and reason to initiate the change. It creates cohesive design of services and implements a small set of strongly related functions. The <strong>common closure principle</strong> (<strong>CCP</strong>) means classes that change for the same reason should be in the same package. If the same business rule is implemented in different aspects by two classes, then for any business rule change only small modifications to be done in code to accommodate the same.</p>
<p>Microservices should correspond to business capabilities/business object to generate value:</p>
<ul>
<li>Inventory management</li>
<li>Order management</li>
<li>Delivery management</li>
</ul>
<p>The corresponding microservice architecture would have services aligned to each of these capabilities. Following this pattern has the benefits such as:</p>
<ul>
<li>The business capabilities are relatively stable so as the architecture</li>
<li>Development teams are delivering business value based on cross-functional, autonomous, and organized, rather than technical features</li>
<li>Services are loosely coupled and cohesive</li>
</ul>
<p>Identifying business capabilities, and hence services require an understanding of the business. An organization's business capabilities and services are identified by analyzing the organization's purpose, business processes, structure, and areas of expertise.</p>
<p>Organization structure can be based on <strong>domain-driven design</strong> (<strong>DDD</strong>) subdomains or business capability groups. DDD is related to the application's problem space as the domain criteria; for example, business groups organized on a basis of regions, domains, locations, and so on.</p>
<p>A domain is made up of multiple subdomains. Different parts of the business corresponds to subdomain as:</p>
<ul>
<li><strong>Core subdomain</strong>: Key business differentiator and the most critical part of the application</li>
<li><strong>Supporting</strong>: Not key business differentiator, can be implemented in-house or outsourced</li>
<li><strong>Generic</strong>: Not business specific and implemented using off-the-shelf software</li>
</ul>
<p>The subdomains of an online store application can be as follows:</p>
<ul>
<li>Product catalog</li>
<li>Inventory management</li>
<li>Order management</li>
<li>Delivery management</li>
</ul>
<p>The corresponding microservice architecture would have services corresponding to each of these subdomains:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/f27df024-ddfc-4b23-99a0-24441d8d12bf.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Microservices deployment patterns</h1>
                </header>
            
            <article>
                
<p>The guiding principles for services are as follows:</p>
<ul>
<li>A variety of languages, frameworks, and framework versions can be used for services</li>
<li>Multiple service instances for each service for throughput and availability</li>
<li>Independently deployable and scalable services</li>
<li>Isolated service instances from one another</li>
<li>Faster build and deploy ability for a service</li>
<li>The resources (CPU and memory) consumed by a service should be constrained</li>
<li>Each service instance should be transparent to monitor behavior</li>
<li>Reliable and cost-effective deployment of service</li>
<li>Application metrics and health check API's</li>
<li>Audit logging and compliance</li>
<li>Distributed tracing and management</li>
<li>Exception tracking and management</li>
<li>Log aggregation, log deployments, and changes</li>
<li>Service component testing and service integration contract testing</li>
<li>UI composition (server-side page fragment, client-side UI)</li>
<li>Security--Access Token based on JSON Web Token identifying the requestor securely to each service</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Distribution patterns</h1>
                </header>
            
            <article>
                
<ul>
<li>Multiple service instances per host, like multiple instances of different services running on a physical or virtual host machine</li>
<li>Deploying a service instance on a shared host</li>
<li>Deploy each service instance as a JVM process, per service instance</li>
<li>Deploy multiple service instances in the same JVM</li>
<li>Avoiding conflicting resource requirements, or dependency versions</li>
<li>Service instance per VM</li>
<li>Service instance linked to each container</li>
<li>Serverless deployment options are explored as follows:
<ul>
<li>AWS Lambda</li>
<li>Google Cloud Functions</li>
<li>Azure Functions</li>
</ul>
</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Microservice chassis</h1>
                </header>
            
            <article>
                
<ul>
<li>Externalized configuration for credentials management, and of external services such as databases and message brokers for network locations</li>
<li><strong>Logging</strong>: Usage of logging framework like log4j or logback</li>
<li><strong>Health checks</strong>: Determine the health of the application through a URL-based monitoring service</li>
<li><strong>Metrics</strong>: Measurement and insight for application performance</li>
<li><strong>Distributed tracing</strong>: A unique identifier between services traced with instrument code-based services</li>
</ul>
<p>For example:</p>
<ul>
<li>Java:
<ul>
<li>Spring Boot and Spring Cloud</li>
<li>Dropwizard</li>
</ul>
</li>
<li>Go:
<ul>
<li>Gizmo</li>
<li>Micro</li>
<li>Go kit</li>
</ul>
</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Communication mode</h1>
                </header>
            
            <article>
                
<p>The various types of communication used in microservices are shared following:</p>
<ul>
<li>Remote Procedure Invocation for interservice communication for client requests by services as listed as follows:
<ul>
<li>REST</li>
<li>gRPC</li>
<li>Apache Thrift</li>
</ul>
</li>
<li>Messaging requests from clients through asynchronous mode by channels as follows:
<ul>
<li>Apache Kafka</li>
<li>RabbitMQ</li>
</ul>
</li>
<li>Domain-specific protocol:
<ul>
<li>Protocols such as SMTP and IMAP for emails</li>
<li>Protocols such as RTMP, HLS, and HDS for media streaming</li>
</ul>
</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data management options</h1>
                </header>
            
            <article>
                
<p>The various modes of data management process in use for microservices are listed following:</p>
<ul>
<li>Database per service ensures loosely coupled services, each service can choose use type of database that's best suited.</li>
<li>Shared database helps, as developer uses ACID transactions to enforce data consistency that are familiar and straightforward.</li>
<li>Event sourcing persists the state of a business entity as a sequence of state-changing events. A new event is appended to the list of events with the state of a business entity changes.</li>
<li>Transaction log tailing.</li>
<li>Database triggers insert events into an EVENTS table to be polled by a separate process that publishes the events.</li>
<li>Application events.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">API interface</h1>
                </header>
            
            <article>
                
<p>The different APIs  used in microservices are as following:</p>
<ul>
<li>UI for desktop and mobile browsers is HTML5/JavaScript-based</li>
<li>Server-side web application generates HTML</li>
<li>Native Android and iPhone clients interact through REST APIs with the server</li>
<li>For third-party applications through the online exposure of details is by REST API</li>
</ul>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="256" src="assets/fe0e6d41-0efa-422c-be76-bded50ec0f4f.png" width="420"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign" style="color: black;font-size: 1em">Usage of Application Program Interface (API) gateway protocols</div>
<p>The following figure shows usage of backend for frontend APIs:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img height="262" src="assets/2d26606d-d0ce-4015-9a66-195ccbdfd26b.png" width="425"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Service discovery</h1>
                </header>
            
            <article>
                
<p>Microservice application is designed where the number of instances of a service and their locations change dynamically to run in a virtualized containerized environment, so the typical problem associated with service discovery is shown here:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="255" src="assets/5119b18e-8404-44a3-8f4b-d65667783124.png" width="337"/></div>
<p>Client-side discovery exposes a remote API such as HTTP/REST or Thrift at a particular location (host and port) for each instance of a service:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="224" src="assets/3c4c8cd1-0518-48a4-8600-8f71d177a889.png" width="361"/></div>
<p>Server-side discovery is making a request to a service by the client through a router (that is, load balancer) that runs at a well identified location address like a service registry, which the router queries and forwards the request to an available service instance:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="213" src="assets/58b47513-d959-44fe-8cd5-9ca5d6993a85.png" width="399"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we covered the topics of containers and flavors offered by different vendors,<br/>
virtualization methods, container orchestrations, Internet of Things, and microservices applications and architectures.</p>


            </article>

            
        </section>
    </body></html>