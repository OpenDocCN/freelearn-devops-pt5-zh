- en: Chapter 8. Onto Production
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 章：进入生产环境
- en: Docker came out of dotCloud's PaaS, where it fulfils the needs of IT to develop
    and deploy web applications in a fast and scalable manner. This is needed to keep
    up with the ever-accelerating pace of using the Web. Keeping everything running
    in our Docker container in production is no simple feat.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 起源于 dotCloud 的 PaaS，满足了 IT 部门在快速、可扩展的方式中开发和部署 Web 应用程序的需求。这是为了跟上 Web
    使用的日益加速的步伐。保持我们的 Docker 容器在生产环境中持续运行绝非易事。
- en: 'In this chapter, we will wrap up what you learned about optimizing Docker and
    illustrate how it relates to operating our web applications in production. It
    consists of the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将总结你所学到的关于优化 Docker 的内容，并阐明它如何与我们在生产环境中操作 Web 应用程序相关。内容包括以下主题：
- en: Performing web operations
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行 Web 操作
- en: Supporting our application with Docker
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Docker 支持我们的应用程序
- en: Deploying applications
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署应用程序
- en: Scaling applications
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展应用程序
- en: Further reading on web operations in general
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进一步阅读关于 Web 操作的一般知识
- en: Performing web operations
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行 Web 操作
- en: Keeping a web application running 24/7 on the Internet poses challenges in both
    software development and systems administration. Docker positions itself as the
    glue that allows both disciplines to come together by creating Docker images that
    can be built and deployed in a consistent manner.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让 Web 应用程序在互联网上 24/7 全天候运行，既是软件开发上的挑战，也是系统管理上的挑战。Docker 将自己定位为连接这两个领域的纽带，通过创建可以一致构建和部署的
    Docker 镜像，来实现这两者的结合。
- en: However, Docker is not a silver bullet to the Web. It is still important to
    know the fundamental concepts in software development and systems administration
    as web applications become more complex. The complexity naturally arises because
    these days, with Internet technologies in particular, the multitude of web applications
    is becoming more ubiquitous in people's lives.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Docker 并不是 Web 的灵丹妙药。随着 Web 应用程序的日益复杂化，仍然需要了解软件开发和系统管理的基本概念。这种复杂性自然地出现，因为如今，特别是在互联网技术的推动下，Web
    应用程序的数量变得更加普及，深入人们的生活。
- en: 'Dealing with the complexity of keeping web applications up and running involves
    mastering the ins and outs of web operations, and like any road to mastery, Theo
    Schlossnagle boils it down to four basic pursuits: knowledge, tools, experience,
    and discipline. *Knowledge* refers to absorbing information about web operations
    available on the Internet, in conferences, and technology meetings like a sponge.
    Understanding them and knowing how to filter out the signal from the noise will
    aid us in designing our application''s architecture when they burn in production.
    With Docker and Linux containers increasing in popularity, it is important to
    be aware of the different technologies that support it and dive into its basics.
    In [Chapter 7](part0046_split_000.html#1BRPS2-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 7. Troubleshooting Containers"), *Troubleshooting Containers*, we showed
    that regular Linux debugging tools are still useful in debugging running Docker
    containers. By knowing how containers interact with our Docker host''s operating
    system, we were able to debug the problems occurring in Docker.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 处理保持 Web 应用程序持续运行的复杂性涉及掌握 Web 操作的方方面面，正如任何通向精通的道路一样，Theo Schlossnagle 将其归结为四个基本追求：知识、工具、经验和纪律。*知识*指的是像海绵一样吸收互联网上、在会议和技术交流会上获得的关于
    Web 操作的信息。理解这些信息，并知道如何从噪音中筛选出有价值的信号，将帮助我们在生产环境中解决应用架构问题。随着 Docker 和 Linux 容器的日益普及，了解支撑它们的不同技术并深入学习其基础非常重要。在[第
    7 章](part0046_split_000.html#1BRPS2-afc4585f6623427885a0b0c8e5b2e22e "第7章：容器故障排除")，*容器故障排除*一章中，我们展示了常规的
    Linux 调试工具在调试运行中的 Docker 容器时依然非常有用。通过了解容器如何与 Docker 主机的操作系统进行交互，我们能够调试 Docker
    中出现的问题。
- en: The second aspect is mastering our *tools*. This book basically revolved around
    mastering the use of Docker by looking at how it works and how to optimize its
    usage. In [Chapter 2](part0018_split_000.html#H5A42-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 2. Optimizing Docker Images"), *Optimizing Docker Images*, we learned
    how to optimize Docker images based on how Docker builds the images and runs the
    container using its copy-on-write filesystem underneath. This was guided by our
    knowledge of web operations on why optimized Docker images are important both
    from a scalability and deployability standpoint. Knowing how to use Docker effectively
    does not happen overnight. Its mastery can only be gained by a continuous practice
    of using Docker in production. Sure, we might be paged at 2 am for our first Docker
    deployment in production, but as time goes by, the experience we gain from continuous
    usage will make Docker an extension of our limbs and senses, as Schlossnagle puts
    it.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个方面是掌握我们的*工具*。本书基本围绕如何掌握Docker的使用展开，探讨了Docker的工作原理以及如何优化其使用。在[第2章](part0018_split_000.html#H5A42-afc4585f6623427885a0b0c8e5b2e22e
    "第2章. 优化Docker镜像")，*优化Docker镜像*中，我们学习了如何根据Docker构建镜像并使用其底层的写时复制文件系统运行容器的方式来优化Docker镜像。这一过程得到了我们在Web运维中对于为何优化Docker镜像在可扩展性和可部署性方面至关重要的知识支持。掌握如何有效使用Docker并非一蹴而就。这种掌握只能通过在生产环境中持续使用Docker的实践来获得。没错，我们可能会在凌晨2点因第一次将Docker部署到生产环境中而接到报警，但随着时间的推移，我们通过不断使用获得的经验将使Docker成为我们身体和感官的延伸，正如Schlossnagle所说。
- en: By applying the knowledge and continuously using our tools, we gain *experience*
    that we can draw upon in the future. This aids us in making good judgments based
    on bad decisions that we made in the past. It is the place where we can see the
    theory of container technology and the practice of running Docker in production
    collide. Scholassnagle mentioned the challenges of acquiring experience in web
    operations and how to survive the bad judgments and draw experiences from them.
    He suggests having limited environments in which a bad decision's impact is minimal.
    Docker is the best place to draw these types of experiences. Having a standard
    format of ready-to-deploy Docker images, junior web operations engineers can have
    their own environments that they can experiment with and learn from their mistakes
    in. Also, since Docker environments look very similar when they move forward to
    production, these engineers will already have their experience to draw upon.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用知识并持续使用我们的工具，我们获得了可以在未来借鉴的*经验*。这帮助我们根据过去做出的错误决策做出正确的判断。这里是容器技术的理论与在生产环境中运行Docker的实践碰撞的地方。Schlossnagle提到了在Web运维中获得经验的挑战，以及如何从错误判断中生还并从中汲取经验。他建议拥有有限的环境，以便错误决策的影响最小化。Docker是获得这种类型经验的最佳场所。通过拥有标准化的、随时可以部署的Docker镜像，初级Web运维工程师可以拥有自己的实验环境，从错误中学习和成长。而且，由于Docker环境在向生产环境推进时非常相似，这些工程师将能够利用自己已经积累的经验。
- en: The last part in the pursuit of mastering web operations is *discipline*. However,
    as it is a very young discipline, such processes are not well defined. Even with
    Docker, it took a few years for people to realize the best ways to use container
    technologies. Before this, the convenience of including the whole kitchen sink
    in Docker images was very common. However, as we can see in [Chapter 2](part0018_split_000.html#H5A42-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 2. Optimizing Docker Images"), *Optimizing Docker Images*, reducing the
    footprint of Docker images helps aid in managing the complexity of the applications
    that we have to debug. This makes the experience of debugging in [Chapter 7](part0046_split_000.html#1BRPS2-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 7. Troubleshooting Containers"), *Troubleshooting Containers*, much simpler
    because we have fewer components and factors to think about. These disciplines
    of using Docker do not come overnight just by reading Docker blogs (well, some
    do). It involves continuous exposure to the knowledge of the Docker community
    and the practice of using Docker in various settings for production use.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握 Web 操作的最后一部分是*自律*。然而，作为一个相对年轻的学科，这些过程尚未得到很好的定义。即使有了 Docker，人们也花了几年时间才意识到容器技术的最佳使用方式。在此之前，将整个厨房用具都包含在
    Docker 镜像中是非常常见的做法。然而，正如我们在[第2章](part0018_split_000.html#H5A42-afc4585f6623427885a0b0c8e5b2e22e
    "第2章：优化 Docker 镜像")，*优化 Docker 镜像*，中看到的，减少 Docker 镜像的体积有助于管理我们必须调试的应用程序的复杂性。这使得在[第7章](part0046_split_000.html#1BRPS2-afc4585f6623427885a0b0c8e5b2e22e
    "第7章：故障排除容器")，*故障排除容器*，中的调试体验更加简单，因为我们需要考虑的组件和因素更少。使用 Docker 的这些技巧并不是通过阅读 Docker
    博客（好吧，有些是）就能一蹴而就的。它涉及到持续接触 Docker 社区的知识，以及在各种生产环境中实践使用 Docker。
- en: In the remaining sections, we will show how the theory and practice of using
    Docker's container technology can aid in the operation of our web applications.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将展示使用 Docker 容器技术的理论与实践如何帮助我们运营 Web 应用。
- en: Supporting web applications with Docker
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Docker 支持 Web 应用
- en: 'The following diagram shows the typical architecture of a web application.
    We have the load balancer tier that receives traffic from the Internet and then
    the traffic, which is typically composed of user requests, is relayed to a farm
    of web application servers in a load-balanced fashion. Depending on the nature
    of the request, some states will be grabbed by the web application from the persistent
    storage tier, similar to database servers:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个典型的 Web 应用架构。我们有一个负载均衡层，它接收来自互联网的流量，然后这些流量，通常由用户请求组成，将以负载均衡的方式转发到一组 Web
    应用服务器。根据请求的性质，Web 应用可能会从持久存储层获取一些状态，类似于数据库服务器：
- en: '![Supporting web applications with Docker](img/00035.jpeg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Docker 支持 Web 应用](img/00035.jpeg)'
- en: As we can see in the preceding diagram, each tier is run inside a Docker container
    on top of a Docker host. With this layout for each component, we can take advantage
    of Docker's uniform way of deploying load balancers, applications, and databases,
    as we did in [Chapter 2](part0018_split_000.html#H5A42-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 2. Optimizing Docker Images"), *Optimizing Docker Images*, and [Chapter
    6](part0041_split_000.html#173721-afc4585f6623427885a0b0c8e5b2e22e "Chapter 6. Load
    Balancing"), *Load Balancing*. However, in addition to the Docker daemons in each
    Docker host, we need supporting infrastructure to manage and observe the whole
    stack of our web architecture in a scalable fashion. On the right-hand side, we
    can see that each of our Docker hosts sends diagnostic information—for example,
    application and system events such as log messages and metrics—to our centralized
    logging and monitoring system. We deployed such a system in [Chapter 4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 4. Monitoring Docker Hosts and Containers"), *Monitoring Docker Hosts
    and Containers*, where we rolled out Graphite and an ELK stack. In addition, there
    might be another system that listens for specific signals in the logs and metrics
    and sends alerts to the engineers responsible for the operation of our Docker-based
    web application stack. These events can relate to critical events, such as the
    availability and performance of our application, that we need to take action on
    to ensure that our application is fulfilling the needs of our business as expected.
    An internally managed system, such as Nagios, or a third-party one, such as PagerDuty,
    is used for our Docker deployments to call and wake us up at 2 am for deeper monitoring
    and troubleshooting sessions as in [Chapter 4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 4. Monitoring Docker Hosts and Containers"), *Monitoring Docker Hosts
    and Containers*, and [Chapter 7](part0046_split_000.html#1BRPS2-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 7. Troubleshooting Containers"), *Troubleshooting Containers*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，每一层都在 Docker 容器中运行，并部署在 Docker 主机上。通过这种每个组件的布局，我们可以利用 Docker 一致的方式来部署负载均衡器、应用程序和数据库，正如我们在[第2章](part0018_split_000.html#H5A42-afc4585f6623427885a0b0c8e5b2e22e
    "第2章. 优化 Docker 镜像")，*优化 Docker 镜像*，和[第6章](part0041_split_000.html#173721-afc4585f6623427885a0b0c8e5b2e22e
    "第6章. 负载均衡")，*负载均衡*中所做的那样。然而，除了每个 Docker 主机中的 Docker 守护进程，我们还需要支持基础设施来以可扩展的方式管理和观察我们整个
    Web 架构的堆栈。在右侧，我们可以看到每个 Docker 主机都会将诊断信息——例如，应用程序和系统事件，如日志消息和度量指标——发送到我们的集中式日志记录和监控系统。我们在[第4章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "第4章. 监控 Docker 主机和容器")，*监控 Docker 主机和容器*中部署了这样的系统，当时我们部署了 Graphite 和 ELK 堆栈。此外，可能还有另一个系统监听日志和度量中的特定信号，并向负责我们基于
    Docker 的 Web 应用堆栈操作的工程师发送警报。这些事件可能与关键事件相关，比如我们应用程序的可用性和性能，这些问题需要我们采取行动以确保我们的应用程序按照预期满足业务需求。我们使用内部管理系统（如
    Nagios）或第三方系统（如 PagerDuty）来处理我们的 Docker 部署，及时向我们发出警报，例如在凌晨 2 点唤醒我们进行更深入的监控和故障排除，就像在[第4章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "第4章. 监控 Docker 主机和容器")，*监控 Docker 主机和容器*，和[第7章](part0046_split_000.html#1BRPS2-afc4585f6623427885a0b0c8e5b2e22e
    "第7章. 故障排除容器")，*故障排除容器*中所提到的那样。
- en: The left-hand side of the diagram contains the configuration management system.
    This is the place where each of the Docker hosts downloads all the settings it
    needs to function properly. In [Chapter 3](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 3. Automating Docker Deployments with Chef"), *Automating Docker Deployments
    with Chef*, we used a Chef server to store the configuration of our Docker host.
    It contained information such as a Docker host's role in our architecture's stack.
    The Chef server stores information on which Docker containers to run in each tier
    and how to run them using the Chef recipes we wrote. Finally, the configuration
    management system also tells our Docker hosts where the Graphite and Logstash
    monitoring and logging endpoints are.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图的左侧包含了配置管理系统。这是每个 Docker 主机下载所需配置的地方，以确保它能够正常工作。在[第3章](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e
    "第3章. 使用 Chef 自动化 Docker 部署")，*使用 Chef 自动化 Docker 部署*中，我们使用 Chef 服务器存储 Docker
    主机的配置。它包含了 Docker 主机在我们架构中的角色等信息。Chef 服务器存储了哪些 Docker 容器需要在每个层中运行，以及如何使用我们编写的
    Chef 配方来运行它们。最后，配置管理系统还告诉我们的 Docker 主机 Graphite 和 Logstash 监控和日志记录的端点位置。
- en: All in all, it takes various components to support our web application in production
    aside from Docker. Docker allows us to easily set up this infrastructure because
    of the speed and flexibility of deploying containers. Nonetheless, we shouldn't
    skip doing our homework about having these supporting infrastructures in place.
    In the next section, we will see the supporting infrastructure of deploying web
    applications in Docker using the skills you learned in the previous chapters.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，除了 Docker 外，还需要各种组件来支持我们生产环境中的 web 应用程序。Docker 使我们能够轻松地设置这些基础设施，因为它在部署容器时具有速度和灵活性。然而，我们不应该忽视对这些支持基础设施的研究。在接下来的章节中，我们将通过你在前面章节中学到的技能，了解如何在
    Docker 中部署 web 应用程序的支持基础设施。
- en: Deploying applications
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署应用程序
- en: 'An important component when tuning the performance of Docker containers is
    the feedback telling us that we were able to improve our web application correctly.
    The deployment of Graphite and the ELK stack in [Chapter 4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 4. Monitoring Docker Hosts and Containers"), *Monitoring Docker Hosts
    and Containers*, gave us visibility on the effects of what we changed in our Docker-based
    web application. As much as it is important to gather feedback, it is more important
    to gather feedback in a timely manner. Therefore, the deployment of our Docker
    containers needs to be in a fast and scalable manner. Being able to configure
    a Docker host automatically, as we did in [Chapter 3](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 3. Automating Docker Deployments with Chef"), *Automating Docker Deployments
    with Chef*, is an important component for a fast and automated deployment system.
    The rest of the components are described in the following diagram:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '在调优 Docker 容器性能时，一个重要的组件是反馈，它能告诉我们是否正确地改善了我们的 web 应用程序。Graphite 和 ELK 堆栈的部署在[第
    4 章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e "第 4 章. 监控
    Docker 主机和容器")，*监控 Docker 主机和容器*，让我们能够看到在基于 Docker 的 web 应用程序中所做的更改所产生的效果。虽然收集反馈很重要，但更重要的是及时收集反馈。因此，我们的
    Docker 容器的部署需要以快速和可扩展的方式进行。正如我们在[第 3 章](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e
    "第 3 章. 使用 Chef 自动化 Docker 部署")，*使用 Chef 自动化 Docker 部署*，中所做的那样，能够自动配置 Docker 主机是实现快速和自动化部署系统的重要组件。其余组件在以下图表中描述：  '
- en: '![Deploying applications](img/00036.jpeg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![部署应用程序](img/00036.jpeg)'
- en: Whenever we submit changes to our application's code or the `Dockerfile` describing
    how it is run and built, we need supporting infrastructure to propagate this change
    all the way to our Docker hosts. In the preceding diagram, we can see that the
    changes we submit to our version control system, such as Git, generate a trigger
    to build the new version of our code. This is usually done through Git's postreceive
    hooks in the form of shell scripts. The triggers will be received by a build server,
    such as Jenkins. The steps to propagate the change will be similar to the blue-green
    deployment process we made in [Chapter 6](part0041_split_000.html#173721-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 6. Load Balancing"), *Load Balancing*. After receiving the trigger to
    build the new changes we submitted, Jenkins will take a look at the new version
    of our code and run `docker build` to create the Docker image. After the build,
    Jenkins will push the new Docker image to a Docker registry, such as Docker Hub,
    as we set up in [Chapter 2](part0018_split_000.html#H5A42-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 2. Optimizing Docker Images"), *Optimizing Docker Images*. In addition,
    it will update the target Docker hosts indirectly by updating the entry in the
    Chef server configuration management system we laid out in [Chapter 3](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 3. Automating Docker Deployments with Chef"), *Automating Docker Deployments
    with Chef*. With the artifacts of changes available in the Chef server and Docker
    registry, our Docker host will now notice the new configuration and download,
    deploy, and run the new version of our web application inside a Docker container.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们提交应用程序代码或描述其运行和构建方式的`Dockerfile`的更改时，我们需要支持的基础设施将这一更改传播到我们的Docker主机。在前面的图示中，我们可以看到，提交到版本控制系统（如Git）的更改会触发构建新版本代码的操作。通常通过Git的postreceive钩子以shell脚本的形式完成此操作。这些触发器会被构建服务器接收，例如Jenkins。传播更改的步骤类似于我们在[第6章](part0041_split_000.html#173721-afc4585f6623427885a0b0c8e5b2e22e
    "第6章. 负载均衡")中实施的蓝绿部署过程，*负载均衡*。在接收到构建我们提交的新更改的触发信号后，Jenkins会查看我们代码的新版本，并运行`docker
    build`来创建Docker镜像。构建完成后，Jenkins会将新的Docker镜像推送到Docker注册表（例如Docker Hub），这正如我们在[第2章](part0018_split_000.html#H5A42-afc4585f6623427885a0b0c8e5b2e22e
    "第2章. 优化Docker镜像")，*优化Docker镜像*中设置的那样。此外，它还会通过更新我们在[第3章](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e
    "第3章. 使用Chef自动化Docker部署")，*使用Chef自动化Docker部署*中布置的Chef服务器配置管理系统中的条目，间接更新目标Docker主机。借助Chef服务器和Docker注册表中可用的更改工件，我们的Docker主机现在会注意到新的配置，并在Docker容器中下载、部署并运行我们Web应用程序的新版本。
- en: In the next section, we will discuss how a similar process is used to scale
    out our Docker application.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论如何使用类似的过程来扩展我们的Docker应用。
- en: Scaling applications
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展应用
- en: 'When we receive alerts from our monitoring system, as in [Chapter 4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 4. Monitoring Docker Hosts and Containers"), *Monitoring Docker Hosts
    and Containers*, that the pool of Docker containers running our web application
    is not loaded, it is time to scale out. We accomplished this using load balancers
    in [Chapter 6](part0041_split_000.html#173721-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 6. Load Balancing"), *Load Balancing*. The following diagram shows the
    high-level architecture of the commands we ran in [Chapter 6](part0041_split_000.html#173721-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 6. Load Balancing"), *Load Balancing*:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们从监控系统收到警报（如在[第4章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "第4章. 监控Docker主机和容器")，*监控Docker主机和容器*中所述）提示运行我们Web应用程序的Docker容器池未加载时，就是时候进行扩展了。我们通过在[第6章](part0041_split_000.html#173721-afc4585f6623427885a0b0c8e5b2e22e
    "第6章. 负载均衡")，*负载均衡*中使用负载均衡器来实现这一目标。下图展示了我们在[第6章](part0041_split_000.html#173721-afc4585f6623427885a0b0c8e5b2e22e
    "第6章. 负载均衡")，*负载均衡*中运行的命令的高层架构：
- en: '![Scaling applications](img/00037.jpeg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![扩展应用](img/00037.jpeg)'
- en: Once we decide to scale out and add an additional Docker host, we can automate
    the process with a scale-out orchestrator component. This can be a series of simple
    shell scripts that we will install inside a build server, such as Jenkins. The
    orchestrator will basically ask the cloud provider API to create a new Docker
    host. This request will then provision the Docker host and run the initial bootstrap
    script to download the configuration from our configuration management system
    in [Chapter 3,](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 3. Automating Docker Deployments with Chef") *Automating Docker Deployments
    with Chef*. This will automatically set up the Docker host to download our application's
    Docker image from the Docker registry. After this whole provisioning process is
    finished, our scale-out orchestrator will then update the load balancer in our
    Chef server with the new list of application servers to forward traffic to. So,
    the next time the `chef-client` inside our load balancer Docker host polls the
    Chef Server, it will add the new Docker host and start forwarding traffic to it.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们决定进行扩展并添加一个额外的Docker主机，我们可以通过一个扩展协调器组件来自动化这个过程。这可以是一系列简单的Shell脚本，我们将把它们安装在构建服务器中，例如Jenkins。该协调器将基本上请求云提供商API创建一个新的Docker主机。然后，这个请求将配置Docker主机并运行初始引导脚本，从我们的配置管理系统中下载配置，这部分内容在[第3章](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e
    "第3章. 使用Chef自动化Docker部署")，*使用Chef自动化Docker部署*中有详细说明。这将自动设置Docker主机，从Docker注册表下载我们的应用程序的Docker镜像。在整个配置过程完成后，我们的扩展协调器将更新Chef服务器中的负载均衡器，添加新的应用服务器列表以转发流量。因此，下次`chef-client`在负载均衡Docker主机中轮询Chef服务器时，它将添加新的Docker主机并开始将流量转发到该主机。
- en: As we can note, learning the way to automate setting up our Docker host in [Chapter
    3](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e "Chapter 3. Automating
    Docker Deployments with Chef"), *Automating Docker Deployments with Chef*, is
    crucial to realizing the scalable load balancing architecture setup we did in
    [Chapter 6](part0041_split_000.html#173721-afc4585f6623427885a0b0c8e5b2e22e "Chapter 6. Load
    Balancing"), *Load Balancing*.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所注意到的，学习如何自动化设置Docker主机在[第3章](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e
    "第3章. 使用Chef自动化Docker部署")，*使用Chef自动化Docker部署*，对于实现我们在[第6章](part0041_split_000.html#173721-afc4585f6623427885a0b0c8e5b2e22e
    "第6章. 负载均衡")，*负载均衡*中所做的可扩展负载均衡架构设置至关重要。
- en: Further reading
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'The supporting architecture to help our web applications use Docker is nothing
    but a scratch on the surface. The fundamental concepts in this chapter are described
    in greater detail in the following books:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 帮助我们的Web应用程序使用Docker的支持架构仅仅是表面上的一点。 本章中的基本概念将在以下书籍中详细描述：
- en: '*Web Operations: Keeping the Data On Time*, which is edited by J. Allspaw and
    J. Robbins. 2010 O''Reilly Media.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Web Operations: Keeping the Data On Time*，由J. Allspaw和J. Robbins编辑。2010年，O''Reilly
    Media出版。'
- en: '*Continuous Delivery*, by J. Humble and D. Farley. 2010 Addison-Wesley.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Continuous Delivery*，由J. Humble和D. Farley编著。2010年，Addison-Wesley出版。'
- en: '*Jenkins: The Definitive Guide*, J. F. Smart. 2011 O''Reilly Media.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Jenkins: The Definitive Guide*，J. F. Smart。2011年，O''Reilly Media出版。'
- en: '*The Art of Capacity Planning: Scaling Web Resources*, J. Allspaw. 2008 O''Reilly
    Media.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*The Art of Capacity Planning: Scaling Web Resources*，J. Allspaw。2008年，O''Reilly
    Media出版。'
- en: '*Pro Git*, S. Chacon and B. Straub. 2014 Apress.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Pro Git*，S. Chacon和B. Straub。2014年，Apress出版。'
- en: Summary
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: You learned a lot about how Docker works throughout this book. In addition to
    the basics of Docker, we looked back at some fundamental concepts of web operations
    and how it helps us realize the full potential of Docker. You gained knowledge
    of key Docker and operating systems concepts to get a deeper understanding of
    what is happening behind the scenes. You now have an idea of how our application
    goes from our code down to the actual call in the operating system of our Docker
    host. You learned a lot about the tools to deploy and troubleshoot our Docker
    containers in production in a scalable and manageable fashion.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，你学到了很多关于Docker如何工作的知识。除了Docker的基础知识外，我们还回顾了一些关于Web操作的基本概念，以及它如何帮助我们实现Docker的全部潜力。你掌握了Docker和操作系统的关键概念，以便更深入地理解背后发生的事情。你现在知道了我们的应用程序是如何从代码走向Docker主机操作系统中的实际调用的。你学到了很多有关在生产环境中以可扩展和可管理的方式部署和排除Docker容器故障的工具。
- en: However, this should not stop you from continuing to develop and practice using
    Docker to run our web applications in production. We should not be afraid to make
    mistakes and gain further experience on the best ways to run Docker in production.
    As the Docker community evolves, so do these practices through the collective
    experience of the community. So, we should continue and be disciplined in learning
    the fundamentals we started to master little by little. Don't hesitate to run
    Docker in production!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这不应阻止你继续开发和实践使用 Docker 在生产环境中运行我们的 web 应用程序。我们不应害怕犯错，而应该在最佳实践中积累经验，逐步掌握在生产环境中运行
    Docker 的方法。随着 Docker 社区的发展，这些实践也在通过社区的集体经验不断演进。因此，我们应该继续并保持规律性地学习我们从一开始就逐步掌握的基础知识。不要犹豫，在生产环境中使用
    Docker！
