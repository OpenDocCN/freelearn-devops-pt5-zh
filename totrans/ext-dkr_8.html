<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch08"/>Chapter 8. Security, Challenges, and Conclusions</h1></div></div></div><p>In this, our final chapter, we are going to be looking at all of the tools we have covered in this book and answering the following questions:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">How the tools can affect the security of your Docker installation?</li><li class="listitem" style="list-style-type: disc">How they can work together and when should they be used?</li><li class="listitem" style="list-style-type: disc">What problems and challenges can the tools be used to resolve?</li></ul></div><div><div><div><div><h1 class="title"><a id="ch08lvl1sec40"/>Securing your containers</h1></div></div></div><p>So far, we have <a id="id556" class="indexterm"/>quite happily been pulling images from the Docker Hub without much thought as to who created them or what is actually installed. This hasn't been too much of a worry as we have been creating ad-hoc environments to launch the containers in.</p><p>As we move towards production and resolving the worked in dev problem, it starts to become important to know what it is that you are installing.</p><p>Throughout the <a id="id557" class="indexterm"/>previous chapters, we have been using the following container images:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">WordPress: <a class="ulink" href="https://hub.docker.com/_/wordpress/">https://hub.docker.com/_/wordpress/</a></li><li class="listitem" style="list-style-type: disc">MySQL: <a class="ulink" href="https://hub.docker.com/_/mysql/">https://hub.docker.com/_/mysql/</a></li><li class="listitem" style="list-style-type: disc">MariaDB: <a class="ulink" href="https://hub.docker.com/_/mariadb/">https://hub.docker.com/_/mariadb/</a></li></ul></div><p>All three of<a id="id558" class="indexterm"/> these <a id="id559" class="indexterm"/>images are classified as official images and have not only been built to a documented standard, they are also peer reviewed at each pull request.</p><p>There are then the<a id="id560" class="indexterm"/> three images from my own Docker Hub account:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Consul: <a class="ulink" href="https://hub.docker.com/r/russmckendrick/consul/">https://hub.docker.com/r/russmckendrick/consul/</a></li><li class="listitem" style="list-style-type: disc">NGINX: <a class="ulink" href="https://hub.docker.com/r/russmckendrick/nginx/">https://hub.docker.com/r/russmckendrick/nginx/</a></li><li class="listitem" style="list-style-type: disc">Cluster Example: <a class="ulink" href="https://hub.docker.com/r/russmckendrick/cluster/">https://hub.docker.com/r/russmckendrick/cluster/</a></li></ul></div><p>Before we<a id="id561" class="indexterm"/> look<a id="id562" class="indexterm"/> at the official images, let's take a<a id="id563" class="indexterm"/> look at the Consul image from my own Docker Hub account and why it is safe to trust it.</p><div><div><div><div><h2 class="title"><a id="ch08lvl2sec81"/>Docker Hub</h2></div></div></div><p>Here, we are<a id="id564" class="indexterm"/> going to look at the three types of images that can be <a id="id565" class="indexterm"/>downloaded from the Docker Hub.</p><p>I have chosen to concentrate on the Docker Hub rather than private registries as the tools we have been looking at the previous chapters all pull from the Docker Hub, and it is also more likely that you or your end users will use the Docker Hub as their primary resource for their image files.</p><div><div><div><div><h3 class="title"><a id="ch08lvl3sec31"/>Dockerfile</h3></div></div></div><p>The Consul container<a id="id566" class="indexterm"/> image is built using a Dockerfile, which is publically <a id="id567" class="indexterm"/>accessibly on my GitHub account. Unlike images that are pushed, more on this later in the chapter, it means that you can exactly see action has been taken to build the image.</p><p>Firstly, we are using the <code class="literal">russmckendrick/base</code> image as our starting point. Again, the Dockerfile for this image is publicly available, so let's look at this now:</p><div><pre class="programlisting">### Dockerfile
#
#   See https://github.com/russmckendrick/docker
#
FROM alpine:latest
MAINTAINER Russ McKendrick &lt;russ@mckendrick.io&gt;
RUN apk update &amp;&amp; apk upgrade &amp;&amp; \
    apk add ca-certificates bash &amp;&amp; \
    rm -rf /var/cache/apk/*</pre></div><p>As you can see, all this does is:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Uses the latest version of the official Alpine Linux image</li><li class="listitem" style="list-style-type: disc">Runs an <code class="literal">apk update</code> and then <code class="literal">apk upgrade</code> to ensure that all the packages are updated</li><li class="listitem" style="list-style-type: disc">Installs the <code class="literal">ca-certificates</code> and <code class="literal">bash</code> packages</li><li class="listitem" style="list-style-type: disc">Cleans up any artifacts left over from the upgrade and installation of the packages</li></ul></div><p>So, now that we know <a id="id568" class="indexterm"/>what the base image looks like, let's move onto the<a id="id569" class="indexterm"/> Dockerfile for the Consul container:</p><div><pre class="programlisting">### Dockerfile
#
#   See https://github.com/russmckendrick/docker
#
FROM russmckendrick/base:latest
MAINTAINER Russ McKendrick &lt;russ@mckendrick.io&gt;
ENV CONSUL_VERSION 0.6.4
ENV CONSUL_SHA256 abdf0e1856292468e2c9971420d73b805e93888e006c76324ae39416edcf0627
ENV CONSUL_UI_SHA256 5f8841b51e0e3e2eb1f1dc66a47310ae42b0448e77df14c83bb49e0e0d5fa4b7
RUN  apk add --update wget \
  &amp;&amp; wget -O consul.zip https://releases.hashicorp.com/consul/${CONSUL_VERSION}/consul_${CONSUL_VERSION}_linux_amd64.zip \
  &amp;&amp; echo "$CONSUL_SHA256 *consul.zip" | sha256sum -c - \
  &amp;&amp; unzip consul.zip \
  &amp;&amp; mv consul /bin/ \
  &amp;&amp; rm -rf consul.zip \
  &amp;&amp; cd /tmp \
  &amp;&amp; wget -O ui.zip https://releases.hashicorp.com/consul/${CONSUL_VERSION}/consul_${CONSUL_VERSION}_web_ui.zip \
  &amp;&amp; echo "$CONSUL_UI_SHA256 *ui.zip" | sha256sum -c - \
  &amp;&amp; unzip ui.zip \
  &amp;&amp; mkdir -p /ui \
  &amp;&amp; mv * /ui \
  &amp;&amp; rm -rf /tmp/* /var/cache/apk/*
EXPOSE 8300 8301 8301/udp 8302 8302/udp 8400 8500 8600 8600/udp
VOLUME [ "/data" ]
ENTRYPOINT [ "/bin/consul" ]
CMD [ "agent", "-data-dir", "/data", "-server", "-bootstrap-expect", "1", "-ui-dir", "/ui", "-client=0.0.0.0"]</pre></div><p>As you can see, there is a little more going on in this Dockerfile:</p><div><ol class="orderedlist arabic"><li class="listitem">We will define that we are using the latest version of <code class="literal">russmckendrick/base</code> as our base image.</li><li class="listitem">Then, we will set three environment variables. Firstly, the version of Consul we want to download, and then the checksum for the files, which we will grab from a third-party website.</li><li class="listitem">We will then install the <code class="literal">wget</code> binary using the APK package manager.</li><li class="listitem">Next up, we will download the Consul binaries from the HashiCorp website, notice that we are downloading over HTTPS and that we are running <code class="literal">sha256sum</code> against the downloaded file to check whether it is has been tampered with. If the file doesn't pass this test, then the build will fail.</li><li class="listitem">Once the zip file is confirmed to be the correct one, we uncompress it and copy the binary in place.</li><li class="listitem">We will then<a id="id570" class="indexterm"/> do the same actions again for the Consul web<a id="id571" class="indexterm"/> interface.</li><li class="listitem">Finally, we will configure some default actions of when the container is launched by exposing the correct port, entry point, and default command.</li></ol></div><p>All of this means that you can see exactly what is installed and how the image is configured before you make the decision to download a container using the image.</p></div><div><div><div><div><h3 class="title"><a id="ch08lvl3sec32"/>Official images</h3></div></div></div><p>There are are just over 100 images that are flagged as official. You view these in the Docker Hub at <a class="ulink" href="https://hub.docker.com/explore/">https://hub.docker.com/explore/</a>. Official images are easy to spot as they are not preceded by a username, for example, the following are the docker pull lines for the official NGINX image and also my own:</p><div><pre class="programlisting">
<strong>docker pull nginx</strong>
<strong>docker pull russmckendrick/nginx</strong>
</pre></div><p>As you can see, the top one is the official image.</p><p>A lot of the<a id="id572" class="indexterm"/> official images are maintained by the upstream <a id="id573" class="indexterm"/>providers, for example, the CentOS, Debian, and Jenkins images <a id="id574" class="indexterm"/>are maintained by members of the respective projects:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><a class="ulink" href="https://github.com/docker-library/official-images/blob/master/library/centos">https://github.com/docker-library/official-images/blob/master/library/centos</a></li><li class="listitem" style="list-style-type: disc"><a class="ulink" href="https://github.com/docker-library/official-images/blob/master/library/debian">https://github.com/docker-library/official-images/blob/master/library/debian</a></li><li class="listitem" style="list-style-type: disc"><a class="ulink" href="https://github.com/docker-library/official-images/blob/master/library/jenkins">https://github.com/docker-library/official-images/blob/master/library/jenkins</a></li></ul></div><p>Also, there is a review process for each pull request submitted. This helps in ensuring that each official image is both consistent and built with security in mind.</p><p>The other important thing to note about official images is that no official image can be derived from, or depend on, non-official images. This means that there should be no way a non-official image's content can find its way into an official image.</p><p>A full detailed explanation on the build standards for official images, as well details of what is expected of an official image maintainer can be found in the Docker Library GitHub page <a id="id575" class="indexterm"/>at <a class="ulink" href="https://github.com/docker-library/official-images/">https://github.com/docker-library/official-images/</a>.</p><p>The downside<a id="id576" class="indexterm"/> of Docker Hub is that it can sometimes be slow, and I mean really slow. The situation has improved over the past 12 months, but there<a id="id577" class="indexterm"/> have been times when Docker's build system has had a big backlog, meaning that your build is queued.</p><p>This is only a problem if you need to trigger a build and want it immediately available, which could be a case if you need to quickly fix this application bug before anyone notices.</p></div><div><div><div><div><h3 class="title"><a id="ch08lvl3sec33"/>Pushed images</h3></div></div></div><p>Finally, there is an<a id="id578" class="indexterm"/> elephant in the room, the complete images, which have been pushed from a user to their Docker Hub.</p><p>Personally, I try to <a id="id579" class="indexterm"/>avoid pushing complete images to my Docker Hub account, as they are something I would typically not recommend using, so why would I expect other users to use them?</p><p>As these images are not being built by a published Dockerfile, it is difficult to get an idea of the standard they have built to and exactly what they contain.</p><p>Docker has tried to address this by introducing content trust to the Docker Hub, what this does is sign the image before it is pushed to the Docker Hub with the publisher's private key. When you download the image, the Docker Engine uses the publisher's public key to verify that the content of the image is exactly how the publisher intended it to be.</p><p>This helps to ensure that the image has not been tampered with at any point of the image's journey from the publisher to you running the container.</p><p>More information <a id="id580" class="indexterm"/>on Content Trust can be found at <a class="ulink" href="https://docs.docker.com/engine/security/trust/content_trust/">https://docs.docker.com/engine/security/trust/content_trust/</a>.</p><p>This is useful if you are using the Docker Hub to publish private images that contain propriety applications or code bases you do want to be publically available.</p><p>However, for publically available images, I would always question why the image had to be pushed to the Docker Hub rather than being built with a Dockerfile.</p></div><div><div><div><div><h3 class="title"><a id="ch08lvl3sec34"/>Docker Cloud</h3></div></div></div><p>Since the<a id="id581" class="indexterm"/> time I started writing this book, Docker has introduced a<a id="id582" class="indexterm"/> commercial service called Docker Cloud. This service is described as a hosted service for Docker container management and deployment by Docker.</p><p>You can find details <a id="id583" class="indexterm"/>of the service at the following URLs:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><a class="ulink" href="https://www.docker.com/products/docker-cloud">https://www.docker.com/products/docker-cloud</a></li><li class="listitem" style="list-style-type: disc"><a class="ulink" href="https://cloud.docker.com/">https://cloud.docker.com/</a></li></ul></div><p>So, why mention this service when we are talking about security? Well, in May 2016, Docker announced that they are adding a Security Scanning feature, which, at the time of writing this book, is free of charge.</p><p>This feature<a id="id584" class="indexterm"/> works with your Private Repositories hosted on the <a id="id585" class="indexterm"/>Docker Hub, meaning that any images you have pushed can be scanned.</p><p>The service performs a static analysis on your images, looking for known vulnerabilities in the binaries you have installed.</p><p>For example, in <a class="link" href="ch06.html" title="Chapter 6. Extending Your Infrastructure">Chapter 6</a>, <em>Extending Your Infrastructure</em>, we created an image using Packer, I still had an old build of this image on my local machine, so I pushed it to a private Docker Hub repository and took advantage of the free trial of both Docker Cloud and Docker Security Scanning.</p><p>As you can see from the following result, the service has found three critical vulnerabilities in the image:</p><div><img src="img/B05468_Ch08_01.jpg" alt="Docker Cloud"/></div><p>This means that it is time to update my base image and the version of NodeJS being used.</p><p>More details <a id="id586" class="indexterm"/>on the service and how it works can be found in the<a id="id587" class="indexterm"/> following announcement blog post:</p><p>
<a class="ulink" href="https://blog.docker.com/2016/05/docker-security-scanning/">https://blog.docker.com/2016/05/docker-security-scanning/</a>
</p><p>There are a few <a id="id588" class="indexterm"/>alternatives to this service, such as:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Clair</strong>: <a class="ulink" href="https://github.com/coreos/clair">https://github.com/coreos/clair</a></li><li class="listitem" style="list-style-type: disc"><strong>Banyan </strong><a id="id589" class="indexterm"/><strong>Collector</strong>: <a class="ulink" href="https://github.com/banyanops/collector">https://github.com/banyanops/collector</a></li><li class="listitem" style="list-style-type: disc"><strong>The Docker Bench for Security</strong>: <a class="ulink" href="https://github.com/docker/docker-bench-security">https://github.com/docker/docker-bench-security</a></li></ul></div><p>However, the newly<a id="id590" class="indexterm"/> launched Docker service is the simplest one to get started with, as it already has deep level of integration with other Docker services.</p></div><div><div><div><div><h3 class="title"><a id="ch08lvl3sec35"/>Private registries</h3></div></div></div><p>Remember that it is possible to use a private registry to distribute your Docker images. I would<a id="id591" class="indexterm"/> recommend taking this approach if you have to bundle your<a id="id592" class="indexterm"/> application's code within an image.</p><p>A private registry is a resource that allows you push and pull images; typically, it is only available to trusted hosts within your network and is not publically available.</p><p>Private registries do not allow you to host automated builds and they do not currently support content trust, this is why they are deployed on private or locked down networks.</p><p>More information on hosting your own private registry can be found at the official documentation<a id="id593" class="indexterm"/> at <a class="ulink" href="https://docs.docker.com/registry/">https://docs.docker.com/registry/</a>.</p></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch08lvl1sec41"/>The challenges</h1></div></div></div><p>So, why<a id="id594" class="indexterm"/> have we been looking at extending the core Docker Engine? Here are a few scenarios that the tools we have covered in the previous chapters could be used to add value or resolve a potential problem.</p><div><div><div><div><h2 class="title"><a id="ch08lvl2sec82"/>Development</h2></div></div></div><p>Way back, at the start of <a class="link" href="ch01.html" title="Chapter 1. Introduction to Extending Docker">Chapter 1</a>, <em>Introduction to Extending Docker</em>, we saw the <em>Worked fine in dev, Ops problem now</em> meme and how it is worryingly still relevant today. Containers go a long way to resolve this issue; in fact, Docker is seen as a great unifier by a lot of people.</p><p>However, if developers do not have a way of easily introducing these tools into their day-to-day lives, then you are not resolving the issue raised by the meme.</p><p>The tools that could help developers start to use Docker locally as the first step of the development <a id="id595" class="indexterm"/>process are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Docker Toolbox</li><li class="listitem" style="list-style-type: disc">Docker Machine</li><li class="listitem" style="list-style-type: disc">Vagrant</li></ul></div><p>Along with the <a id="id596" class="indexterm"/>recently announced, but currently in private beta, native versions of Docker for OS X and Windows, more details on this can be found in the announcement blog post at <a class="ulink" href="https://blog.docker.com/2016/03/docker-for-mac-windows-beta/">https://blog.docker.com/2016/03/docker-for-mac-windows-beta/</a>.</p><p>Additionally, depending on your existing workflows, you could also use the following tools to introduce containers to your existing workflows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Ansible</li><li class="listitem" style="list-style-type: disc">Jenkins</li><li class="listitem" style="list-style-type: disc">Packer</li><li class="listitem" style="list-style-type: disc">Puppet</li></ul></div></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec83"/>Staging</h2></div></div></div><p>Depending on <a id="id597" class="indexterm"/>your requirements, you could use the following plugins in conjunction with Docker Compose to create a basic staging environment<a id="id598" class="indexterm"/> with multi-host networking and storage:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Convoy</li><li class="listitem" style="list-style-type: disc">Docker overlay network</li><li class="listitem" style="list-style-type: disc">Docker Volumes</li><li class="listitem" style="list-style-type: disc">Flocker</li><li class="listitem" style="list-style-type: disc">REX-Ray</li><li class="listitem" style="list-style-type: disc">Weave</li></ul></div><p>You can also use these tools to give you a good level of control over where the containers are deployed within your staging environment:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Ansible</li><li class="listitem" style="list-style-type: disc">Docker Swarm</li><li class="listitem" style="list-style-type: disc">Jenkins</li><li class="listitem" style="list-style-type: disc">Puppet</li><li class="listitem" style="list-style-type: disc">Rancher</li></ul></div><p>Additionally, your developers could have some level of access in order to be able to deploy a test version using these tools either via continuous integration tools, web interfaces, or via command line.</p></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec84"/>Production</h2></div></div></div><p>Again, you <a id="id599" class="indexterm"/>could use the following plugins to <a id="id600" class="indexterm"/>create a basic production-ready environment using Docker Compose:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Convoy</li><li class="listitem" style="list-style-type: disc">Docker Overlay Network</li><li class="listitem" style="list-style-type: disc">Docker Volumes</li><li class="listitem" style="list-style-type: disc">Flocker</li><li class="listitem" style="list-style-type: disc">REX-Ray</li><li class="listitem" style="list-style-type: disc">Weave</li></ul></div><p>However, you <a id="id601" class="indexterm"/>will probably want your production <a id="id602" class="indexterm"/>environment to look more after itself in terms of reacting to failure, scaling events, and automatic registration of containers with services such as DNS and Load Balancers:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Ansible</li><li class="listitem" style="list-style-type: disc">Amazon ECS</li><li class="listitem" style="list-style-type: disc">Docker Swarm</li><li class="listitem" style="list-style-type: disc">Kubernetes</li><li class="listitem" style="list-style-type: disc">Puppet</li><li class="listitem" style="list-style-type: disc">Rancher</li></ul></div><p>All these listed tools should be considered production-ready. However, as Puppet and Ansible offer little in the way of scheduling, you should only really consider them if you are introducing Docker into an existing Puppet or Ansible-managed environment.</p><p>If there is one thing I hope you have taken from this book, it is that there doesn't have to be one size fits all when it comes to using Docker.</p><p>As we discussed, there are tools supplied by both Docker and third parties that allow you scale your containers from a single host to potentially hundreds or thousands.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch08lvl1sec42"/>Summary</h1></div></div></div><p>In the previous chapters, we experienced using combinations of the tools together.</p><p>For example, we have been using both Docker Storage and Network plugins to create a highly available WordPress installation using both the tools provided by Docker themselves, that is, Docker Compose and Docker Swarm, as well Kubernetes and Rancher.</p><p>We also deployed our underlying Docker infrastructure using Docker Machine, Ansible, as well as tools such as Kubernetes and Rancher.</p><p>Then, we deployed various first-party and third-party plugins to help with storage, networking, and features such as load balancing to take full advantage of the environment that we have been deploying to, such as Amazon Web Service and DigitalOcean.</p><p>All the tools that we have looked at compliment the core Docker Engine, and in most cases, there is little or no change needed to be made to your Docker images to start using the plugins or third-party tools.</p><p>All of this means that it is relatively easy to build a highly available, yet easy to use platform to deploy your applications into whether you are using a public cloud, your own virtual machines, bare metal servers, or just your local laptop, and tailor it to your developers, application, and your own needs, all while ensuring that if it worked in development, it will work in production.</p></div></body></html>