<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch04"/>Chapter 4. Docker Swarm</h1></div></div></div><p>So far we have learned how to launch individual Docker hosts locally using Docker for Mac, Docker for Windows, and Docker Machine for remote hosts, as well as using Docker locally on Linux. Individual Docker hosts are great for local development, or launching a few test instances however as you start moving towards production you need fewer single points of failure.</p><p>In this chapter, we are going to get a little more adventurous and create a cluster of Docker hosts. Docker ships a tool called Swarm, when deployed it acts as a scheduler between your Docker client and the Docker host, deciding where to launch containers based on scheduling rules.</p><p>We are going to look at the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Manually launching a Docker Swarm cluster</li><li class="listitem" style="list-style-type: disc">Launching Docker for Amazon Web Services</li><li class="listitem" style="list-style-type: disc">Launching Docker for Azure</li></ul></div><p>And also how to launch containers within our cluster.</p><div><div><div><div><h1 class="title"><a id="ch04lvl1sec28"/>Creating a Swarm manually</h1></div></div></div><p>At the <a id="id181" class="indexterm"/>start of <a class="link" href="ch03.html" title="Chapter 3. Docker in the Cloud">Chapter 3</a>, <em>Docker in the Cloud</em> we looked at using a Docker Machine to launch a Docker host in Digital Ocean. We are going to start with Digital Ocean again, but this time we are going to launch three hosts and then create a Docker Swarm cluster on them.</p><p>To start off with we need to launch the hosts and to do this, run the following commands, remembering to replace the Digital Ocean API access token with your own:</p><div><pre class="programlisting">
<strong>docker-machine create \</strong>
<strong>    --driver digitalocean \</strong>
<strong>    --digitalocean-access-token 57e4aeaff8d7d1a8a8e46132969c2149117081536d50741191c79d8bc083ae73 \</strong>
<strong>    swarm01</strong>

<strong>docker-machine create \</strong>
<strong>    --driver digitalocean \</strong>
<strong>    --digitalocean-access-token 57e4aeaff8d7d1a8a8e46132969c2149117081536d50741191c79d8bc083ae73 \</strong>
<strong>    swarm02</strong>

<strong>docker-machine create \</strong>
<strong>    --driver digitalocean \</strong>
<strong>    --digitalocean-access-token 57e4aeaff8d7d1a8a8e46132969c2149117081536d50741191c79d8bc083ae73 \</strong>
<strong>    swarm03</strong>
</pre></div><p>Once launched, running <code class="literal">docker-machine ls</code> should show you a list of your images. Also, this should be reflected in your Digital Ocean control panel:</p><div><img src="img/B06455_04_02.jpg" alt="Creating a Swarm manually"/></div><p>Now we<a id="id182" class="indexterm"/> have our Docker hosts and we need to assign a role to each of the nodes within the cluster. Docker Swarm has two<a id="id183" class="indexterm"/> node roles:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Manager</strong>: A manager<a id="id184" class="indexterm"/> is a node which dispatches tasks to the workers, all your interaction with the Swarm cluster will be targeted against a manager node. You can have more than one Manger node, however in this example we will be using just one.</li><li class="listitem" style="list-style-type: disc"><strong>Worker</strong>: Worker<a id="id185" class="indexterm"/> nodes accept the tasks dispatched by the Manager node(s), these are where all your services are launched. We will go in to services in more detail once we have our cluster configured.</li></ul></div><p>In our cluster, <strong>swarm01</strong> will be the manager node with <strong>swarm02</strong> and <strong>swarm03</strong> being our two worker nodes. We are going to use the <code class="literal">docker-machine ssh</code> command to execute commands directly on our three nodes, starting with configuring our manager node.</p><div><div><h3 class="title"><a id="note19"/>Note</h3><p>Please note, the commands in the walk through will only work with Mac and Linux, commands to run on Windows will be covered at the end of this section.</p></div></div><p>Before we<a id="id186" class="indexterm"/> initialize the manager node, we need to capture the IP address of <code class="literal">swarm01</code> as a command-line variable:</p><div><pre class="programlisting">
<strong>managerIP=$(docker-machine ip swarm01)</strong>
</pre></div><p>Now that we have the IP address, run the following command to check if it is correct:</p><div><pre class="programlisting">
<strong>echo $managerIP</strong>
</pre></div><p>And then to configure the manager node, run the following command:</p><div><pre class="programlisting">
<strong>docker-machine ssh swarm01 docker swarm init --advertise-addr $managerIP</strong>
</pre></div><p>You will then receive confirmation that <code class="literal">swarm01</code> is now a manager along with instructions on what to run to add a worker to the cluster:</p><div><img src="img/B06455_04_03.jpg" alt="Creating a Swarm manually"/></div><p>You don't have to a make a note of the instructions as we will be running the command in a slightly different way.</p><p>To add our two workers, we need to capture the join token in a similar way we captured the IP address of our manager node using the <code class="literal">$managerIP</code> variable; to do this, run:</p><div><pre class="programlisting">
<strong>joinToken=$(docker-machine ssh swarm01 docker swarm join-token -q worker)</strong>
</pre></div><p>Again, you <code class="literal">echo</code> the variable out to check that it is valid:</p><div><pre class="programlisting">
<strong>echo $joinToken</strong>
</pre></div><p>Now it's time to add our two worker nodes into the cluster by running:</p><div><pre class="programlisting">
<strong>docker-machine ssh swarm02 docker swarm join --token $joinToken $managerIP:2377</strong>
<strong>docker-machine ssh swarm03 docker swarm join --token $joinToken $managerIP:2377</strong>
</pre></div><p>You should see something like the following terminal output:</p><div><img src="img/B06455_04_04.jpg" alt="Creating a Swarm manually"/></div><p>Connect<a id="id187" class="indexterm"/> your local Docker client to the manager node using the following:</p><div><pre class="programlisting">
<strong>eval $(docker-machine env swarm01)</strong>
</pre></div><p>And then running a <code class="literal">docker-machine ls</code> again shows. As you can see from the list of hosts, <code class="literal">swarm01</code> is now active but there is nothing in the <strong>SWARM</strong> column; why is that?</p><p>Confusingly, there are two different types of Docker Swarm cluster, there is the Legacy Docker Swarm which was managed by Docker Machine, and then there is the new Docker Swarm mode which is managed by the Docker Engine itself.</p><p>We have a launched a Docker Swarm Mode cluster. This is now the preferred way of launching Swarm, the legacy Docker Swarm is slowly being retired.</p><p>To get a list of the nodes within our Swarm cluster, we need to run the following command:</p><div><pre class="programlisting">
<strong>docker node ls</strong>
</pre></div><div><img src="img/B06455_04_06.jpg" alt="Creating a Swarm manually"/></div><p>For information on each node you can run the following command (the <code class="literal">--pretty</code> flag renders the JSON output from the Docker API):</p><div><pre class="programlisting">
<strong>docker node inspect swarm01 --pretty</strong>
</pre></div><p>You are given a wealth of information about the host, including the fact that it is a manager and it has been launched in Digital Ocean. Running the same command; but for a worker node shows similar information:</p><div><pre class="programlisting">
<strong>docker node inspect swarm02 --pretty</strong>
</pre></div><p>However, as the node is not a manager that section is missing.</p><p>Before we look at launching services into our cluster, we should look at how to launch our cluster using Docker Machine on Windows. We will be using PowerShell for this rather than the more traditional Windows CMD prompt, however, even using PowerShell there are a few differences in the commands used due differences between PowerShell and bash.</p><p>First, we need<a id="id188" class="indexterm"/> to launch the three hosts:</p><div><pre class="programlisting">
<strong>docker-machine.exe create --driver digitalocean --digitalocean-access-token 57e4aeaff8d7d1a8a8e46132969c2149117081536d50741191c79d8bc083ae73 swarm01</strong>
<strong>docker-machine.exe create --driver digitalocean --digitalocean-access-token 57e4aeaff8d7d1a8a8e46132969c2149117081536d50741191c79d8bc083ae73 swarm02</strong>
<strong>docker-machine.exe create --driver digitalocean --digitalocean-access-token 57e4aeaff8d7d1a8a8e46132969c2149117081536d50741191c79d8bc083ae73 swarm03</strong>
</pre></div><p>Once the three hosts are up and running:</p><div><img src="img/B06455_04_09.jpg" alt="Creating a Swarm manually"/></div><p>You can create the manager node by running:</p><div><pre class="programlisting">
<strong>$managerIP = $(docker-machine.exe ip swarm01)</strong>
<strong>echo $managerIP</strong>
<strong>docker-machine.exe ssh swarm01 docker swarm init --advertise-addr $managerIP</strong>
</pre></div><div><img src="img/B06455_04_10.jpg" alt="Creating a Swarm manually"/></div><p>Once you have <a id="id189" class="indexterm"/>your manager you can add the two worker nodes:</p><div><pre class="programlisting">
<strong>$joinIP = "$(docker-machine.exe ip swarm01):2377"</strong>
<strong>echo $joinIP</strong>
<strong>$joinToken = $(docker-machine.exe ssh swarm01 docker swarm join-token -q worker)</strong>
<strong>echo $joinToken</strong>
<strong>docker-machine.exe ssh swarm02 docker swarm join --token $joinToken $joinIP</strong>
<strong>docker-machine.exe ssh swarm03 docker swarm join --token $joinToken $joinIP</strong>
</pre></div><p>And then configure your local Docker client to use your manager node and check the cluster status:</p><div><pre class="programlisting">
<strong>docker-machine.exe env  swarm01 | Invoke-Expression</strong>
<strong>docker-machine.exe ls</strong>
<strong>docker node ls</strong>
</pre></div><p>At this stage, no matter which operating system you are using, you should have a three node Docker Swarm cluster in Digital Ocean, we can now look at a launching service into our cluster. </p></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec29"/>Launching a service</h1></div></div></div><p>Rather than <a id="id190" class="indexterm"/>launching containers using the <code class="literal">docker container run</code> command you need to create a service A service defines a task which the manager then passes to one of the workers and then a container is launched.</p><p>Let's launch a simple service called cluster which uses the image we looked at in <a class="link" href="ch02.html" title="Chapter 2. Launching Applications Using Docker">Chapter 2</a>, <em>Launching Applications Using Docker</em>:</p><div><pre class="programlisting">
<strong>docker service create --name cluster -p:80:80/tcp russmckendrick/cluster</strong>
</pre></div><p>That's it, we<a id="id191" class="indexterm"/> should now have a single container running on one of our three nodes. To check that the service is running and get a little more information about the service, run the following commands:</p><div><pre class="programlisting">
<strong>docker service ls</strong>
<strong>docker service inspect cluster --pretty</strong>
</pre></div><p>Now that we have confirmed that our service is running, you will be able to open your browser and enter the IP address of one of your three nodes (which you can get by running <code class="literal">docker-machine ls</code>).One of the features of Docker Swarm is it's routing mesh.</p><div><img src="img/B06455_04_13.jpg" alt="Launching a service"/></div><p>A routing mesh? When we exposed the port using the <code class="literal">-p:80:80/tcp</code> flag, we did a little more than map port <code class="literal">80</code> on the host to port <code class="literal">80</code> on the container, we actually created a Swarm load balancer on <code class="literal">port 80</code> across all of the hosts within the cluster. The Swarm load balancer then directs requests to containers within our cluster.</p><p>Running the commands below, should show you which tasks are running on which nodes, remember tasks are containers which have been launched by the service:</p><div><pre class="programlisting">
<strong>docker node ps swarm01</strong>
<strong>docker node ps swarm02</strong>
<strong>docker node ps swarm03</strong>
</pre></div><p>Like me, you probably have your single task running on <code class="literal">swarm01</code>:</p><div><img src="img/B06455_04_14.jpg" alt="Launching a service"/></div><p>We can <a id="id192" class="indexterm"/>make things more interesting by scaling our service to add more tasks, to do this simply run the following commands to scale and check our service:</p><div><pre class="programlisting">
<strong>docker service scale cluster=6</strong>
<strong>docker service ls</strong>
<strong>docker service inspect cluster --pretty</strong>
</pre></div><p>As you should see, we now have 6 tasks running within our cluster service:</p><div><img src="img/B06455_04_15.jpg" alt="Launching a service"/></div><p>Checking the nodes should show that the tasks are evenly distributed between our three nodes:</p><div><pre class="programlisting">
<strong>docker node ps swarm01</strong>
<strong>docker node ps swarm02</strong>
<strong>docker node ps swarm03</strong>
</pre></div><div><img src="img/B06455_04_16.jpg" alt="Launching a service"/></div><p>Hitting refresh in your browser should also update the hostname under the Docker image change, another way of seeing this on Mac and Linux is to run the following command:</p><div><pre class="programlisting">
<strong>curl -s http://$(docker-machine ip swarm01)/ | grep class=</strong>
</pre></div><p>As you can see from the following terminal output, our requests are being load balanced between the running tasks:</p><div><img src="img/B06455_04_17.jpg" alt="Launching a service"/></div><p>Before we <a id="id193" class="indexterm"/>terminate our Docker Swarm cluster let's look at another way we can launch services, before we do we need to remove the currently running service, to do this simply run:</p><div><pre class="programlisting">
<strong>docker service rm cluster</strong>
</pre></div><p>Now that the service has been removed, we can launch a stack.</p></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec30"/>Launching a stack</h1></div></div></div><p>This is where it <a id="id194" class="indexterm"/>may get confusing. If a service is the same as running container then a stack is running a collection of services like you would launch multiple containers using Docker Compose. In fact, you can launch a stack using a Docker Compose file, with a few additions.</p><p>Let's look at launching our Cluster application again. You can find the Docker Compose file we are going to be using in the repo in the <code class="literal">/bootcamp/chapter04/cluster/</code> folder, before we go through the contents of the <code class="literal">docker-compose.yml</code> file, let's launch the stack. To do this run the following command:</p><div><pre class="programlisting">
<strong>docker stack deploy --compose-file=docker-compose.yml cluster</strong>
</pre></div><p>You should get confirmation that the network for the stack has been created along with the service. You can list the services launched by the stack by running:</p><div><pre class="programlisting">
<strong>docker stack ls</strong>
</pre></div><p>And then check on the tasks within the service by running:</p><div><pre class="programlisting">
<strong>docker stack ps cluster</strong>
</pre></div><div><img src="img/B06455_04_18.jpg" alt="Launching a stack"/></div><p>You may be <a id="id195" class="indexterm"/>surprised to see that service has launched its tasks on <code class="literal">swarm02</code> and <code class="literal">swarm03</code> only. For an explanation as to why, let's open the <code class="literal">docker-compose.yml</code> file:</p><div><pre class="programlisting">version: "3"
services:
  cluster:
    image: russmckendrick/cluster
    ports:
      - "80:80"
    deploy:
      replicas: 6
      restart_policy:
        condition: on-failure
placement:
        constraints:
          - node.role == worker</pre></div><p>As you can see, the <code class="literal">docker-compose.yml</code> file looks like what we covered in <a class="link" href="ch02.html" title="Chapter 2. Launching Applications Using Docker">Chapter 2</a>, <em>Launching Applications Using Docker</em>, until we get to the <code class="literal">deploy</code> section.</p><p>You may have already spotted the reason why we only have tasks running on our two worker nodes, as you can see in the <code class="literal">placement</code> section, we have told Docker to only launch our tasks on nodes with the role of worker.</p><p>Next up we have a defined a <code class="literal">restart_policy</code> this tells the Docker what to do should any of the tasks stop responding, in our case we are telling the Docker to restart them <code class="literal">on-failure</code>. Finally, we are telling the Docker to launch six <code class="literal">replicas </code>within our service.</p><p>Let's test that restart policy by terminating one of our two worker nodes. There is a graceful way of doing this by draining the node, however, it more fun to just terminate the node, to do this run the following command:</p><div><pre class="programlisting">
<strong>docker-machine rm swarm03</strong>
</pre></div><p>Running <code class="literal">docker stack ps</code> cluster immediately after removing the host shows that the Docker hasn't caught up yet.</p><p>Running <code class="literal">docker stack ps</code> a few seconds later will show that we still have six tasks running, but as you can see from the terminal output they are now all running on <code class="literal">swarm02</code> and the tasks the new ones have replaced are showing as <strong>shutdown</strong>.</p><p>Our application should still be available by entering the IP address of <code class="literal">swarm01</code> or <code class="literal">swarm02</code> into your browser. Once you have finished with the remain two hosts you can them by running:</p><div><pre class="programlisting">
<strong>docker-machine rm swarm01 swarm02</strong>
</pre></div><p>So far, we <a id="id196" class="indexterm"/>have manually created our Docker Swarm cluster in Digital Ocean, I am sure you agree that so far, the process has been straightforward, especially considering how powerful the clustering technology is, you are already probably starting to think how you can start to deploy services and stacks.</p><p>In the next few sections we are going to look at Docker for Amazon Web Services and Docker for Azure, and how Docker can take advantage of the range of supporting features provided by the two public cloud services.</p></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec31"/>Docker for Amazon Web Services</h1></div></div></div><p>Docker for AWS is a Swarm cluster<a id="id197" class="indexterm"/> which has been tuned by Docker to run in Amazon Web Services.</p><div><div><h3 class="title"><a id="note20"/>Note</h3><p>AWS CloudFormation is a templating engine which allows you to define your AWS infrastructure and resources in a controllable and predictable fashion.</p></div></div><p>The AWS CloudFormation template<a id="id198" class="indexterm"/> can be found at:</p><p><a class="ulink" href="https://editions-us-east-1.s3.amazonaws.com/aws/stable/Docker.tmpl">https://editions-us-east-1.s3.amazonaws.com/aws/stable/Docker.tmpl</a></p><p>As you can see there is quite a lot to it, the image below is a visualization of the template above – while you may not be able to see all the content in the image you should get an idea of the complexity of the <strong>CloudFormation</strong> template supplied by Docker.</p><div><img src="img/B06455_04_21.jpg" alt="Docker for Amazon Web Services"/></div><p>As you can see, the <a id="id199" class="indexterm"/>template does all the heavy lifting for you meaning you don't really have to do much apart from one thing, create an SSH key. To do this login to the AWS console<a id="id200" class="indexterm"/> at <a class="ulink" href="https://console.aws.amazon.com/">https://console.aws.amazon.com/</a>, select <strong>EC2</strong>from the <strong>Services</strong> menu at the top of the screen, once the EC2 dashboard opens click on <strong>Key Pairs </strong>in the left-hand side menu.</p><p>Here you will have the option to <strong>Create Key Pair</strong> or <strong>Import Key Pair</strong>. Once you have your SSH key created or imported you can get to launching your Docker for Amazon Web Services cluster, to this, select <strong>CloudFormation</strong> from the <strong>Services</strong> menu.</p><p>Clicking <strong>Create New Stack</strong> will take you a page which lets you define your stack, as Docker have already done this for us all you need to do is enter the URL of the stack definition file:</p><p><a class="ulink" href="https://editions-us-east-1.s3.amazonaws.com/aws/stable/Docker.tmpl">https://editions-us-east-1.s3.amazonaws.com/aws/stable/Docker.tmpl</a></p><p>In the space below <a id="id201" class="indexterm"/>where is says <strong>Specify an Amazon S3 template URL</strong>, making sure that the radio icon above where you entered the URL is selected click on <strong>Next</strong>:</p><div><img src="img/B06455_04_24.jpg" alt="Docker for Amazon Web Services"/></div><p>The next page you are taken to is where you define how you would like your stack to look, for this quick demonstration I used the following to roughly match the sizes of the manual Swarm cluster we launched in Digital Ocean:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Stack name</strong>: Bootcamp</li><li class="listitem" style="list-style-type: disc"><strong>Number of Swarm managers?</strong> 1</li><li class="listitem" style="list-style-type: disc"><strong>Number of Swarm worker nodes?</strong> 3</li><li class="listitem" style="list-style-type: disc"><strong>Which SSH key to use?</strong>&lt;your own SSH key&gt;</li><li class="listitem" style="list-style-type: disc"><strong>Enable daily resource clea</strong><strong>nup?</strong> No</li><li class="listitem" style="list-style-type: disc"><strong>Use Cloudwatch for container logging?</strong>Yes</li><li class="listitem" style="list-style-type: disc"><strong>Swarm manager instance type?</strong>t2.micro</li><li class="listitem" style="list-style-type: disc"><strong>Manager ephemeral storage volume size?</strong> 20</li><li class="listitem" style="list-style-type: disc"><strong>Manager ephemeral storage volume type</strong> standard</li><li class="listitem" style="list-style-type: disc"><strong>Agent worker instance type?</strong> t2.micro</li><li class="listitem" style="list-style-type: disc"><strong>Worker ephemeral storage volume size?</strong> 20</li><li class="listitem" style="list-style-type: disc"><strong>Worker ephemeral storage vol</strong><strong>ume type</strong>: standard</li></ul></div><p>Once you have filled in all the details, click on the <strong>Next</strong> button at the bottom of the page. The next screen you are taken to contains additional options such as tagging, we don't need to enter anything here so just click on the <strong>Next</strong> button,</p><p>The final page is where we review everything before we comit to launching our stack. If you need to change any of the values you can do so by clicking on <strong>Previous</strong>, once you are happy with how the details you need to tick the box which says, <strong>I acknowledge that AWS CloudFormation might create IAM resources</strong> and then click the <strong>Create</strong> button.</p><p>This will immediately start deploying the resources for your Docker for Amazon Web Service cluster, you can check the status of the deployment by having the <strong>Events</strong> tab open.</p><p>Clicking the <strong>refresh</strong>
<a id="id202" class="indexterm"/> button should show you something like the following screen:</p><div><img src="img/B06455_04_26.jpg" alt="Docker for Amazon Web Services"/></div><p>Launching the stack will take several minutes, once it has completed you should see that the <strong>Status</strong> says <strong>CREATE_COMPLETE</strong>. Once you see this, click on the <strong>Outputs</strong> tab:</p><div><img src="img/B06455_04_27.jpg" alt="Docker for Amazon Web Services"/></div><p>Here you should <a id="id203" class="indexterm"/>see four messages, the first contains the Elastic Load Balancer URL, the second is a message about the availability of your instances and finally you should see a message about <strong>Managers</strong>, this contains a link – click it.</p><p>This takes you to the Instances page of the EC2 dashboard, you will also notice that our single manager node has been filtered, selecting it shows information such as the public URL and IP address of the instance:</p><div><img src="img/B06455_04_28.jpg" alt="Docker for Amazon Web Services"/></div><p>To interact with our cluster, we are going to SSH into the manager node, you need to use the <code class="literal">docker</code> username. I used the following command:</p><div><pre class="programlisting">
<strong>ssh docker@54.194.20.19</strong>
</pre></div><p>If you downloaded a key pair then you would use something like;</p><div><pre class="programlisting">
<strong>ssh docker@54.194.20.19 -I ~/path/to/keypair.pem</strong>
</pre></div><p>Once you are logged in you should see something like:</p><div><img src="img/B06455_04_29.jpg" alt="Docker for Amazon Web Services"/></div><p>Running <code class="literal">docker node ls</code> shows that we have three worker nodes and the one manager node we are logged into:</p><div><img src="img/B06455_04_30.jpg" alt="Docker for Amazon Web Services"/></div><p>Now let's launch <a id="id204" class="indexterm"/>our cluster application, as we are logged into a very basic operating system, in fact as you can from the output of running:</p><div><pre class="programlisting">
<strong>cat /etc/*release</strong>
</pre></div><p>We are logged into an Alpine Linux server:</p><div><img src="img/B06455_04_31.jpg" alt="Docker for Amazon Web Services"/></div><p>Git is not installed by default so let's install it by switching to the root user and install the Git package using APK:</p><div><pre class="programlisting">
<strong>sudo su –</strong>
<strong>apk update</strong>
<strong>apk add git</strong>
</pre></div><p>Now that Git is installed we can clone the Bootcamp repo:</p><div><pre class="programlisting">
<strong>git clone https://github.com/russmckendrick/bootcamp</strong>
<strong>.git</strong>
</pre></div><p>Once Git is installed we can then launch our stack using the following command:</p><div><pre class="programlisting">
<strong>docker stack deploy --compose-file=/root/bootcamp/chapter04/cluster/docker-compose.yml cluster</strong>
<strong>docker stack ls</strong>
<strong>docker stack ps cluster</strong>
</pre></div><p>You should see something like the following output:</p><div><img src="img/B06455_04_33.jpg" alt="Docker for Amazon Web Services"/></div><p>Now that our stack <a id="id205" class="indexterm"/>is launched you can access it using the Elastic Load Balancer URL from the Outputs tab of the CloudFormation stack, in my case the URL was (please note that my URL no longer works):</p><p><code class="literal">http://bootcamp-elb-1145454691.eu-west-1.elb.amazonaws.com/</code></p><p>As you can see from the screen below the page displays as expected with the host name of the container the content is being served from:</p><div><img src="img/B06455_04_34.jpg" alt="Docker for Amazon Web Services"/></div><p>As before, running <a id="id206" class="indexterm"/>curl against the Elastic Load Balancer URL shows that hostname of the container is changing (remember to replace the URL with your own):</p><div><pre class="programlisting">
<strong>curl -s http://bootcamp-elb-1145454691.eu-west-1.elb.amazonaws.com/ | grep class=</strong>
</pre></div><p>Before we teardown our Cluster there is one more to take a quick look at, if you when we launched our Docker for Amazon Web Service stack we said yes to <strong>Use Cloudwatch for container logging</strong>.</p><p>This option streams your container logs to Amazons own central logging service, to view return to the AWS console and select <strong>Cloudwatch</strong> from the <strong>Services</strong> menu, once the Cloudwatch dashboard has loaded, click <strong>Logs</strong> in the left-hand side menu and then click on the <strong>Bootcamp-lg</strong> link, here you should list of the containers which were launched by your <code class="literal">docker stack create</code> command:</p><div><img src="img/B06455_04_36.jpg" alt="Docker for Amazon Web Services"/></div><p>Clicking on one of the log streams will show you everything which that container has logged, which in our case should just be a lot of information from the supervisord process:</p><div><img src="img/B06455_04_37.jpg" alt="Docker for Amazon Web Services"/></div><p>To tear down our <a id="id207" class="indexterm"/>Docker for Amazon Web Services cluster return to the CloudFormation dashboard, select your stack then select <strong>Delete Stack</strong> from the <strong>Actions</strong> menu. This will pop-up a prompt, click the <strong>Yes, Delete</strong> button and deletion of your stack with start immediately.</p><p>Removing all the resource will take several minutes, it is important to ensure that all the resources are removed as Amazon operate a pay-as-go model meaning if a resource such as an EC2 instance is running you will be being charged for it so I would recommend you keep the window open and ensure that the deletion is successful.</p><p>Speaking of charges, you may have noticed that when we launched our stack there was a link to estimated costs, this takes all the resource defined in the CloudFormation template and runs it through Amazon's Simple Cost Calculator application, our four instance Docker for Amazon Web Services would cost us an estimated $66.98 per month to run.</p><p>As you can see, we launched a quite complex configuration without much effort at all, Docker have also applied this same methodology to Microsoft Azure, let's look at that now.</p></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec32"/>Docker for Azure</h1></div></div></div><p>Docker for Azure <a id="id208" class="indexterm"/>needs a little more work up-front before we can deploy. Luckily, Docker have made this as simple as possible by providing the Azure command line interface as a container.</p><p>We need to create a service profile and resource group for our deployment to use, to do this simply run the following command:</p><div><pre class="programlisting">
<strong>docker run -ti docker4x/create-sp-azure bootcamp-sp bootcamp-resource westus</strong>
</pre></div><p>This will download the Azure CLI. The three variables we are passing the command are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The name of the service profile</li><li class="listitem" style="list-style-type: disc">The name of the resource group</li><li class="listitem" style="list-style-type: disc">Which region we would like to launch our cluster in</li></ul></div><p>After a few seconds, you<a id="id209" class="indexterm"/> should receive a URL and an authentication code:</p><div><img src="img/B06455_04_41.jpg" alt="Docker for Azure"/></div><p>Open <a class="ulink" href="https://aka.ms/devicelogin/">https://aka.ms/devicelogin/</a> in your browser and enter the code you were given, which in my case was <strong>DQQXPYV7G</strong>:</p><div><img src="img/B06455_04_42.jpg" alt="Docker for Azure"/></div><p>As you can see from the screen above, the application is identifying itself as <strong>Microsoft Azure Cross-platform Command Line Interface</strong> so we know that the request is right; clicking on Continue will ask you to login. Once logged in you will receive confirmation that your request has been authorised and the application has logged in.</p><p>After a second or two you should see your command line spring into life, the first thing it will do is ask you which subscription it should use:</p><div><img src="img/B06455_04_44.jpg" alt="Docker for Azure"/></div><p>Select the right subscription, and then leave the command to finish, it will take around five minutes to complete. At the of the process you should receive your access credentials, make a note of these as you will need them to launch your stack:</p><div><img src="img/B06455_04_45.jpg" alt="Docker for Azure"/></div><p>Now that we have <a id="id210" class="indexterm"/>completed the preparation it is time to launch the Docker for Azure template, you<a id="id211" class="indexterm"/> can view the template at the following URL:</p><p><a class="ulink" href="https://download.docker.com/azure/stable/Docker.tmpl">https://download.docker.com/azure/stable/Docker.tmpl</a></p><p>And to launch it simply go to the following URL in your browser:</p><p><a class="ulink" href="https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fdownload.docker.com%2Fazure%2Fstable%2FDocker.tmpl">https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fdownload.docker.com%2Fazure%2Fstable%2FDocker.tmpl</a></p><p>You should already be logged in from authorizing the command line interface, if not login and you will be take a to a page which asks for several pieces of information on how you would like your stack to look:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Subscription </strong>&lt;Select your subscription&gt;</li><li class="listitem" style="list-style-type: disc"><strong>Use existing </strong>&lt;Select your resource group generated in the previous step &gt;</li><li class="listitem" style="list-style-type: disc"><strong>Location </strong>&lt;This will be greyed out&gt;</li><li class="listitem" style="list-style-type: disc"><strong>Ad Service Principal App ID </strong>&lt;Enter your AD ServicePrincipal App ID generated in the previous step &gt;</li><li class="listitem" style="list-style-type: disc"><strong>Ad Service Principal App Secret</strong>: &lt;Enter your AD ServicePrincipal App Secret generated in the previous step &gt;</li><li class="listitem" style="list-style-type: disc"><strong>Enable System Prune</strong>: no</li><li class="listitem" style="list-style-type: disc"><strong>Manager Count</strong>: 1</li><li class="listitem" style="list-style-type: disc"><strong>Manager VM Size</strong>: Standard_D2_v2</li><li class="listitem" style="list-style-type: disc"><strong>Ssh Public Key</strong>: &lt;Enter your public key, see below&gt;</li><li class="listitem" style="list-style-type: disc"><strong>Swarm Name</strong>: dockerswarm</li><li class="listitem" style="list-style-type: disc"><strong>Worker Count</strong>: 3</li><li class="listitem" style="list-style-type: disc"><strong>Worker VM </strong><strong>Size</strong>: Standard_D2_v2</li></ul></div><p>To quickly copy your public SSH key to your clipboard on a Mac or Linux run the following command (changing the path to your own key if needed):</p><div><pre class="programlisting">
<strong>cat ~/.ssh/id_rsa.pub | pbcopy</strong>
</pre></div><p>Make sure you tick<a id="id212" class="indexterm"/> the box next to <strong>I agree to the terms and conditions stated above</strong>, once you are happy with the contents of the form click on <strong>Purchase</strong>. This will kick off your deployment, the process will take several minutes, once complete your dashboard will have a new resource added to it, depending on your existing resources you may have to scroll to see it or the page may need to be refreshed.</p><p>Clicking on <strong>See more</strong> in your resource tile will give you a list of all the resources created by Docker for Azure:</p><div><img src="img/B06455_04_48.jpg" alt="Docker for Azure"/></div><p>You should be able to see two public IP addresses assigned, one for a <strong>externalLoadBalancer-public-ip</strong> and one for a <strong>externalSSHLoadBalancer-public-ip</strong> make a note of both as we are going to need them, to find out the IP address click on the resource to find more information.</p><p>Now that we know the two IP addresses we can SSH into our manager node, SSH is listening on port <code class="literal">50000</code>, so to SSH to the node run the following command making sure you use the <strong>externalSSHLoadBalancer-public-ip</strong> address:</p><div><pre class="programlisting">
<strong>ssh docker@52.160.107.69 -p50000</strong>
</pre></div><p>Once logged in, run<a id="id213" class="indexterm"/> <code class="literal">docker node ls</code> and you should see your three worker nodes, if you don't they may still be starting so give it a few minutes more:</p><div><img src="img/B06455_04_50.jpg" alt="Docker for Azure"/></div><p>As with Docker for Amazon Web Services, you are SSH'ed into an Alpine Linux host.</p><p>Meaning that to install Git we need to change to the root user and using APK to install it:</p><div><pre class="programlisting">
<strong>sudo su -</strong>
<strong>apk update</strong>
<strong>apk add git</strong>
</pre></div><p>Once Git is installed we can check out the Bootcamp repository using;</p><div><pre class="programlisting">
<strong>git clone https://github.com/russmckendrick/bootcamp.git</strong>
</pre></div><p>And then launch our application stack using the following command:</p><div><pre class="programlisting">
<strong>docker stack deploy --compose-file=/root/bootcamp/chapter04/cluster/docker-compose.yml cluster</strong>
</pre></div><p>And make sure everything is running by executing:</p><div><pre class="programlisting">
<strong>docker stack ls</strong>
<strong>docker stack ps cluster</strong>
</pre></div><p>Putting the externalLoadBalancer-public-ipaddress into your browser should show you your cluster application. Again, using the CURL command should show us that traffic is being distributed across our containers (remember to use your own Load Balancer IP address):</p><div><pre class="programlisting">
<strong>curl -s http://52.160.105.160/ | grep class=</strong>
</pre></div><p>There you have it, we have successfully deployed Docker for Azure and our cluster application. The last thing to do is to delete the resources so that we do get any unexpected bills, to do this select <strong>Resource groups</strong> from the left-hand menu and then click on the three dots next to the <strong>bootcamp-resource</strong> entry and select <strong>Delete</strong>.</p><p>It will take about 10 minutes to remove all the resources and the group, but it is worth keeping the Azure portal open until the deletion process has completed as you do not want to incur any additional cost.</p><p>Depending on how <a id="id214" class="indexterm"/>long the resources were live this entire demo would have cost less than $0.10.</p></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec33"/>Summary</h1></div></div></div><p>I suspect that by the end of this chapter things were getting very predictable and there were no real surprises, this is by design. As you have experienced, Docker have provided a very powerful clustering solution which once deployed acts in a consistent and predictable way no matter what underlying platform you have launched your cluster on.</p><p>There is one important thing which we yet to touch on yet, persistent storage for our containers. This is important, especially in a cluster, as it allows our containers to not only move between hosts but also introduces ways in which we can do rolling updates of our applications.</p><p>In the next chapter, we are going to look at both Docker network &amp; volume plugins.</p></div></body></html>