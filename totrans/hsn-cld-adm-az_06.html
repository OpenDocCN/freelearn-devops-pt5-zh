<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Storage, Backup, and Site Recovery - Moving your Data to Azure</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will focus on migrating data to Azure. We'll start with Azure Storage as one of the most important services in Azure. Everything begins with Storage and it's important to understand how it's used. We'll discuss how to use Azure Storage for backup and how to migrate your workloads to the cloud. Further, we'll discuss how to use Azure Backup and <strong>Azure Site Recovery</strong> (<strong>ASR</strong>) to speed up your journey and migrate data to Azure.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Azure Storage</li>
<li>Azure Backup</li>
<li>Azure Site Recovery</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating highly available Azure SQL Database</h1>
                </header>
            
            <article>
                
<p>Creating SQL Server high availability solutions can be complicated, hard to configure, and even harder to maintain and manage. Azure SQL Database high availability is much easier to create and requires almost no maintenance.</p>
<p class="mce-root"><span>The option we need to start with is</span> <span class="packt_screen">Geo-Replication</span><span>. The geo-replication blade shows</span><span> </span><span>the</span> <span>world map</span> <span>with marks showing data centers in which databases are currently located</span><span> and all data centers available for replication. The current data center, in which the database is located, is marked in blue. The data center recommended for replication is marked in purple (this will be</span><span> the</span> <span>data center closest to</span><span> the</span> <span>current data center) and all other available data centers are marked green. On the map, you can see information about</span><span> the </span><span>current database that will be our primary database. An image of a geo-replication blade is shown in following image:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-461 image-border" src="Images/c93ac8ca-fe2c-4f7c-8af5-551e6693a9ef.png" style="width:44.50em;height:28.58em;" width="904" height="580"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>To create a new database replica, we can select any data center on the map to start a new blade. The <span class="packt_screen">Create secondary</span> blade will open, in which we need to provide a target SQL Server (create a new server if it doesn't exist in location selected). The <span class="packt_screen">Database name</span> will be<span> the </span>same as<span> the</span> original one, and the database<span> the</span> will be in read-only mode. The <span class="packt_screen">Pricing tier</span> will be same as<span> the</span> original, but you can change<span> the</span> tier to another value. An example of<span> the </span>settings needed to create a secondary database is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-462 image-border" src="Images/340f7479-a3f4-4806-a6a2-a16c9269642c.png" style="width:22.67em;height:41.25em;" width="322" height="586"/></p>
<p>After deployment is finished,<span> the</span> map will change, showing<span> the</span> connection between<span> the</span> primary and secondary database. Deployment time depends on<span> the</span> database size.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>During deployment,<span> the</span> empty database is created in<span> the</span> secondary data center, and then<span> the</span> data is copied from primary to secondary. A map with the replication in place is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-463 image-border" src="Images/60a73975-f797-4724-ad58-aa8afd933587.png" style="width:46.83em;height:33.25em;" width="951" height="676"/></p>
<p>However, notice that this is only creating a readable copy of<span> the</span> primary database. In<span> the</span> case of disaster or if<span> the</span> primary database is unavailable, the secondary database must be manually changed from read-only to read/write and all connection strings to<span> the</span> database must be changed manually. This doesn't really represent a high availability solution, so we need to take an additional step by creating a failover group.</p>
<p>In<span> the</span> <span class="packt_screen">Failover group</span> blade, we need to provide a <span class="packt_screen">Primary server</span>, <span class="packt_screen">Secondary server</span>, <span class="packt_screen">Failover group name</span>, <span class="packt_screen">Read/Write failover policy</span>, and <span class="packt_screen">Read/Write grace period (hours)</span>. The failover group name must be unique, and this will be<span> the</span> new endpoint for<span> the</span> connection to our database. Connecting to<span> the</span> failover group name will automatically point us to<span> the</span> primary server whenever<span> the</span> primary server is available.</p>
<p>If that primary server isn't available, all connections to<span> the</span> failover group name will be pointed to<span> the</span> secondary server. All failover and failback happens automatically and requires no user action. A screenshot of<span> the</span> <span class="packt_screen">Failover group</span> options is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-464 image-border" src="Images/bfd5a959-3b77-45bd-bee3-a41d1b1b6928.png" style="width:20.67em;height:48.50em;" width="332" height="779"/></p>
<p>As you can see, creating<span> the</span> Azure SQL Database high availability solution is simple and fast. It requires no user action once it's created, and failover and failback happen automatically. If you have ever created a similar solution in an on-premises environment, you probably know how complicated a failback process can be.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure SQL Database security</h1>
                </header>
            
            <article>
                
<p>When it comes to data, security is very important (not that other resources should be left unsecured). Under<span> the </span><span class="packt_screen">Azure SQL Database</span> blade, we have a set of options related to security. <span class="packt_screen">SECURITY</span> options include <span class="packt_screen">Advanced Threat Protection</span>, <span class="packt_screen">Auditing</span>, <span class="packt_screen">Dynamic Data Masking</span>, and <span class="packt_screen">Transparent data encryption</span>. <span class="packt_screen">Advanced Threat Protection</span> and <span class="packt_screen">Auditing</span> can be applied on the server level (for all databases on<span> the</span> server) or for a single database.</p>
<p><span class="packt_screen">Advanced Threat Protection</span> contains three subsections: </p>
<ul>
<li><span class="packt_screen">Data Discovery &amp; Classification (preview)</span></li>
<li><span class="packt_screen">Vulnerability Assessment</span></li>
<li><span class="packt_screen">Threat Detection</span></li>
</ul>
<p>The <span class="packt_screen">Data Discovery &amp; Classification<span> (preview)</span></span> feature is still in beta but can be very useful. A scan of<span> the</span> database will be performed, and recommendations will be provided on which columns in your database should be marked as classified. This can be especially useful when considering data that should be considered regarding<span> the</span> <strong>general data protection regulation</strong> (<strong>GDPR</strong>).</p>
<p><span class="packt_screen">Vulnerability Assessment</span> will perform a security scan and provide security recommendations for your database. Examples of recommendations would be to to track firewall rules or to classify sensitive data.</p>
<p><span class="packt_screen">Threat Detection</span> applies machine learning to your security. This feature analyzes normal behavior and alerts you to any action that is out of the ordinary. For example, if one of<span> the</span> SQL logins always accesses<span> the</span> database in work hours and suddenly tries to log in during other periods, you will be alerted. Or, if one of<span> the</span> logins is always coming from a specific IP address and tries to access<span> the</span> database from<span> the</span> other side of the world, action will be detected and you will be alerted.</p>
<p>A screenshot of <span>advanced threat protection is shown here:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-466 image-border" src="Images/440c4355-54e5-414d-a55a-4f3bf0064292.png" style="width:125.17em;height:36.33em;" width="1502" height="436"/></p>
<p>Auditing allows us to track events and log them to<span> the</span> storage account. We can define<span> the</span> log retention period, and whether events are logged on<span> the</span> database or server level. As auditing is often a requirement for many organizations, especially in order to be compliant to different standards, this option allows you to fulfill that requirement. A screenshot for audit logs is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-467 image-border" src="Images/5275f29e-39f1-4433-b8e0-d2afcd17c0af.png" style="width:73.67em;height:21.00em;" width="884" height="252"/></p>
<p>Before we proceed to dynamic data masking, let's run a simple query. Selecting<span> the</span> top 100 rows on<span> the</span> table <kbd>SalesLT.Customers</kbd> will return all information on<span> the</span> first 100 customers from the table. Here we have various types of data, and we may not want everyone with access to<span> the</span> database to see everything. Let's take a phone number, for example. Note that in<span> the following</span> screenshot, we can see that running<span> the</span> query will return<span> the </span>phone column:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1074 image-border" src="Images/87a9fc9d-514c-408d-8108-b8690090f305.png" style="width:89.58em;height:55.33em;" width="1075" height="664"/></p>
<p>The dynamic data masking blade will provide information on all<span> the</span> masking rules currently applied and recommendations for rules that you also may want to consider for masking. Note that<span> the</span> SQL administrator is excluded from data masking, and that you can add additional users to be excluded. A screenshot of dynamic data masking is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-469 image-border" src="Images/c9f37723-53f1-410d-b5b9-8a951053f9a2.png" style="width:43.17em;height:35.75em;" width="683" height="566"/></p>
<p>To add a new rule, we need to provide<span> the</span> <span class="packt_screen">Schema</span>, <span class="packt_screen">Table</span>, <span class="packt_screen">Column</span>, and <span class="packt_screen">Masking field format</span>. The <span class="packt_screen">Masking field format</span> will allow you to control what masked data looks like in a query result. An example of how to add<span> the </span>phone column for data masking is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-470 image-border" src="Images/fe815f65-080c-4b9f-8102-7fa3ace29ece.png" style="width:21.58em;height:34.42em;" width="342" height="545"/></p>
<p class="mce-root"/>
<p>Once<span> the</span> data masking rule is applied, we can run<span> the</span> query again. As you can see in the following screenshot,<span> the</span> result will be different when<span> the </span>masking rule is applied, and<span> the</span> phone column will then return <kbd>xxx</kbd> for all values:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1075 image-border" src="Images/cb8ddac7-a86c-4ce6-a8c2-30a1399e0dbe.png" style="width:96.08em;height:55.50em;" width="1153" height="666"/></p>
<p>Using dynamic data masking, we can control user access to data and prevent them seeing confidential information. For example, if we have billing information and contact information in<span> the</span> same table, we may want to provide access to<span> the</span> table to different users but allow them to see different information. We can allow our sales department to see an email or phone number, but want to prevent them from seeing credit card information. On the other hand, we don't want to prevent everyone from seeing credit card information and want to allow this information to be accessed by<span> the</span> finance department. Dynamic data masking is ideal for this scenario, wherein users can have access to<span> the</span> same table but see different sets of information. </p>
<p><strong>Transparent data encryption</strong> (<strong>TDE</strong>) is used for encrypting databases in rest mode. This feature is available for on-premises versions of SQL Server but requires an implementation that isn't so simple. For Azure SQL Databases, this feature is turned on automatically for newly created databases. This wasn't always the case, and for older databases you can turn it on simply by switching the TDE option on. As simple as that, databases (and all backups) are encrypted at rest. Transparent database encryption is shown in the following screenshot: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-472 image-border" src="Images/f5128e67-618b-4dbb-95c6-9a918ee6da68.png" style="width:38.58em;height:18.67em;" width="634" height="306"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Monitoring and troubleshooting Azure SQL Database</h1>
                </header>
            
            <article>
                
<p><span class="packt_screen">MONITORING</span> options for Azure SQL Databases is very similar to options for other Azure resources. Options available for <span><span class="packt_screen">MONITORING </span></span>are <span class="packt_screen">Alerts (Classic)</span>, <span class="packt_screen">Metrics (preview)</span>, and <span class="packt_screen">Diagnostic settings</span>. All of these features are available for Azure Virtual Machines and Azure Web Apps, and these were covered in previous chapters.</p>
<p><span class="packt_screen">SUPPORT + TROUBLESHOOTING</span> options bring us a few features that are specific to Azure SQL Databases. Features such as <span class="packt_screen">Resource health</span> and <span class="packt_screen">New support request</span> are present, as for other Azure resources. New features are <span class="packt_screen">Performance overview</span>, <span class="packt_screen">Performance recommendations</span>, <span class="packt_screen">Query Performance Insight</span>, and <span class="packt_screen">Automatic tuning</span>.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span class="packt_screen">Performance overview</span> gives us an overview of query performance. Here we can find information on resource consumption by queries. Overview gives us insight into aggregated consumption for queries per resource type. Resource type can be DTU, CPU, and IOPS. This aggregation will show queries which create<span> the</span> biggest resource cost, but as this is aggregated consumption, it can be<span> the</span> result of<span> the</span> query being executed often and not of<span> the</span> query spending resources in a single run. A list of queries which take more time to execute can be found under the <span class="packt_screen">Long running queries</span> tab. This information can help us improve performance, as queries that are often executed and queries that take a long time to execute are spending lot of resources. Editing these queries can improve performance and save money in the long run as well. A graph showing CPU consumption <span>in the <span class="packt_screen">Performance overview</span> category</span> is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-476 image-border" src="Images/907d6721-f6e7-4809-af86-bda292f18c72.png" style="width:50.33em;height:33.75em;" width="880" height="590"/></p>
<p>Under performance list, we can see <span class="packt_screen">Recommendations</span> based on performance history for our database. It will give us a list of <span class="packt_screen">Recommendations</span>, along with the options to automatically apply these recommendations. In the <span class="packt_screen">Performance recommendatio</span><span class="packt_screen">n</span> blade, we can see both new <span class="packt_screen">Recommendations</span> and recommendations already applied, shown as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-477 image-border" src="Images/b68c4a19-0c70-4cd0-93a7-841ef3264c98.png" style="width:81.83em;height:23.25em;" width="982" height="279"/></p>
<p><span class="packt_screen">Query Performance Insight</span> gives us very similar options to performance overview. The difference is that you can customize and edit graphs and dashboards in <span><span class="packt_screen">Query Performance Insight</span></span>. You can change different metrics and time periods that will be displayed, helping you to observe performance over longer periods of time. The default blade for <span><span class="packt_screen">Query Performance Insight</span> </span>is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-479 image-border" src="Images/57123b54-39fb-4ba3-b86e-b7ff5092d7e9.png" style="width:81.08em;height:50.25em;" width="973" height="603"/></p>
<p><span class="packt_screen">Automatic tuning</span> options is a dream come true for all database administrators. This option will use built-in intelligence, observing performance over time and applying machine learning to solutions to improve<span> the</span> performance of<span> the</span> database. The option can be automatically enabled on a server or subscription level. Further, it can be set on and off for individual databases. Settings available for automatic tuning are <span class="packt_screen">FORCE PLAN</span>, <span class="packt_screen">CREATE INDEX</span>, and <span class="packt_screen">DROP INDEX</span>. If enabled, automatic tuning will analyze<span> the</span> performance and automatically apply changes that will improve performance. Examples of automatic tuning settings are shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-480 image-border" src="Images/5b8b29b9-59f0-4d19-97b7-9fd461cf549d.png" style="width:80.75em;height:32.67em;" width="969" height="392"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure SQL Database backup</h1>
                </header>
            
            <article>
                
<p>A very important task for any database administrator is backup. This option is automatically enabled in Azure SQL Database. When a new database is created, geo-redundant storage is created in<span> the</span> process and backups are performed in this storage. This feature is provided automatically and free of charge. For Azure SQL Database, SQL Server backup technology is used to create full, differential, and transaction backups. Transaction backups are performed every 12 hours and differential backups every 5–10 minutes, depending on database size and activity. This allows us to have a point-in-time restore by restoring<span> the</span> last full backup before<span> the</span> point selected, all differential backups between<span> the</span> full backup and<span> the</span> point selected, and, finally, all transnational backups between<span> the</span> last differential backup and<span> the</span> point selected. </p>
<p>The retention period for<span> the</span> backup depends on<span> the</span> database tier and can be from 7–35 days. There is also<span> the</span> option to enable <strong>long-term retention backup</strong> (<strong>LTRB</strong>) and keep backups for up to 10 years. The default backup is<span> the</span> option provided with no additional charge, but LTRB uses additional storage that is charged extra. However, there are situations in which we are required to keep a backup for a longer period of time and this option can be useful. Also,<span> the </span>price of storage is low, so this doesn't create a big addition to your bill.</p>
<p>Another option directly connected to backups is database export. This allows you to keep an additional copy of your database in separate storage. This backup can be used to restore a database on a new server or another subscription. Export will create a BACPAC file that contains schema and data.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Other data services in Azure</h1>
                </header>
            
            <article>
                
<p>SQL Server in <span>VM</span> and Azure SQL Database are just a fraction of the Azure data platform offering.</p>
<p>When we talk about RDBMS in <span>IaaS</span>, we really don't have any restrictions. We can create any type of <span>VM</span> with a number of different operating systems and install anything we want, such as Oracle, MySQL, PostgreSQL, and so on. There are also a number of images that include this software pre-installed. The s<span>ame thing goes for NoSQL databases: we can install anything on our VM, or we can even choose an image that includes MongoDB, CouchDB, and many others.</span></p>
<p>When talking about RDBMS in<span> the </span><span>PaaS</span> model, we have also different options such as <span class="packt_screen">MySQL</span>, <span class="packt_screen">PostgreSQL</span>, <span class="packt_screen">SQL data warehouses</span>, and others. Running NoSQL as <span>PaaS</span> also offers different options, including <span class="packt_screen">Azure Cosmos DB</span> or <span class="packt_screen">MongoDB</span>.</p>
<p>Azure data platform is extended with analytic services in Azure that also have multiple options for both <span>IaaS</span> or <span>PaaS</span> models. </p>
<p>Overall, Microsoft Azure offers different options for data and analytics, whether you're migrating existing solutions or building a new cloud solution. You can choose between different IaaS and PaaS services and combine them for specific scenarios to get the best possible results. </p>
<p>A screenshot showing some of<span> the </span>database and analytics options in Azure follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-481 image-border" src="Images/588a1e6a-1dde-4b33-a85c-923c104236ff.png" style="width:49.58em;height:21.08em;" width="1284" height="546"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>The Azure data platform offers multiple options when deciding to use both <span>IaaS</span> and <span>PaaS</span>. Running databases in IaaS offers more control, but requires more maintenance and administration as well. <span>DaaS</span> has many features which make a database administrator's life easier, but it lacks support to run certain features and legacy applications. The bottom line is that we need to decide how we want to proceed and assess<span> the</span> ideal option for our scenario based on<span> the</span> options required by our solution and offered by different data services. </p>
<p>Once data is in the cloud, Azure offers many analytics options which can help us to extend our solution. Again, we can choose between different IaaS and PaaS services to select<span> the</span> best fit for us.</p>
<p>In previous chapters, we discussed how to set up applications and data in Azure.<span> </span><span>Creating and designing new applications is great, but not always an option. </span>In most cases,<span> the </span>journey starts with moving existing solutions from on-premises to<span> the</span> cloud. In<span> the </span>next chapter, we are going to explain options available for migrating our existing applications and databases to Azure.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>Database in Azure can be run as...
<ol>
<li><span>IaaS</span></li>
<li><span>PaaS </span></li>
<li>Both</li>
</ol>
</li>
<li>Azure Virtual Machine with SQL is different from <span>VM</span> without SQL because of...
<ol>
<li>SQL server configuration</li>
<li>Amount of memory and CPU</li>
<li>Its name</li>
</ol>
</li>
<li>Azure SQL Database is also called...
<ol>
<li><span>Database as a Service</span></li>
<li>SQL as a Service</li>
<li>Data as a Service</li>
</ol>
</li>
<li>The Azure SQL Database tier can be measured in...
<ol>
<li>DTUs</li>
<li>vCores</li>
<li>Both</li>
</ol>
</li>
<li>You can run a query on Azure SQL Database with...
<ol>
<li>SQL Server Management Studio</li>
<li>Query Editor in Azure Portal</li>
<li>Both</li>
</ol>
</li>
<li>To connect to Azure SQL Database, you need to...
<ol>
<li>Add an IP address to a firewall rule</li>
<li>Allow an IP in VNet</li>
<li>Allow an IP in<span> the</span> master database</li>
</ol>
</li>
<li><span>To create an Azure SQL Database replica, you can use...</span>
<ol>
<li>Database backup</li>
<li>Database export</li>
<li>Geo-replication</li>
</ol>
</li>
<li>To create a highly available Azure SQL Database, you need to create a...
<ol>
<li>Failover group</li>
<li>Failover cluster</li>
<li>Always-On</li>
</ol>
</li>
</ol>
<ol start="9">
<li>To mask columns in Azure SQL Database, you use...
<ol>
<li>Transparent data encryption</li>
<li>Dynamic data masking</li>
<li>Data classification </li>
</ol>
</li>
<li>To detect potential threats to your database, you use...
<ol>
<li>Vulnerability assessment </li>
<li>Advanced threat protection</li>
<li>Both</li>
</ol>
</li>
</ol>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>For this chapter, you'll need:</p>
<ul>
<li>An Azure subscription</li>
<li>A local server running Windows Server 2012 R2 or later</li>
<li>A Hyper-V Server</li>
<li>A local instance of SQL Server 2012 or later</li>
</ul>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Storage</h1>
                </header>
            
            <article>
                
<p>Azure Storage is a service that plays a very important part in Microsoft Azure. Almost all Azure services use storage in one form or another. In some cases, it's obvious that storage is used, in others it's a service in the background we don't realize even exists.</p>
<p>For example, if we create a new VM, virtual disks are created in the process. These disks are stored in Azure Storage. If managed disks are used, storage is created in the background and not visible. If we don't use managed disks, storage created in the process is shown among resources, since managing storage is our responsibility when managed disks are not used.</p>
<p>Similar to this, when any <span>PaaS</span> resource is created, storage is created in the background. In most PaaS cases, storage is not directly visible, but we can see the amount of storage available and used in the resource blade. For example, Azure SQL database or Azure App Service plan have a certain amount of resources available depending on the tier. We don't have direct access to storage management but we can see information about storage space.</p>
<p>But Azure Storage can be used as stand alone service and managed independently. In order to explain this service, let's start with creating a new Azure Storage account.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Recovery Service</h1>
                </header>
            
            <article>
                
<p>Another service to help migration to the cloud is the Azure Recovery Service. This service contains features that can help us move data to the cloud:</p>
<ul>
<li>Azure Backup</li>
<li>Azure Site Recovery</li>
</ul>
<p>Both services aren't only used to move data to the cloud but to protect both Azure and on-premises resources. Their primary purpose is in fact to protect resources but once we have data in the cloud, this data can be used to perform migration.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating a recovery service vault</h1>
                </header>
            
            <article>
                
<p>In order to start using the Azure recovery service, we must create a <span class="packt_screen">Recovery Services vault</span>. All usual parameters are needed: <span class="packt_screen">Name</span>, <span class="packt_screen">Subscription</span>, <span class="packt_screen">Resource group</span>, and <span class="packt_screen">Location</span>. Note that <span class="packt_screen">Location</span> is very important if you want to protect Azure resources. You will not be able to protect resources that are in the same location as the recovery services vault. A screenshot showing an example of parameters for recovery services vault is given here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-530 image-border" src="Images/9fbcd0b0-2b4d-4556-998e-128e5ea3d712.png" style="width:22.50em;height:22.25em;" width="421" height="416"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating an Azure Storage account</h1>
                </header>
            
            <article>
                
<p>In order to create an Azure storage account, we need to provide a <span class="packt_screen">Name</span>, <span class="packt_screen">Deployment model</span>, <span class="packt_screen">Account kind</span>, <span class="packt_screen">Location</span>, <span class="packt_screen">Replication</span> policy, <span class="packt_screen">Performance</span>, <span class="packt_screen">Secure transfer required</span>, <span class="packt_screen">Subscription</span>, and <span class="packt_screen">Resource group</span>. <span class="packt_screen">Subscription</span>, <span class="packt_screen">Location,</span> and <span class="packt_screen">Resource group</span> are the usual settings needed for all Azure resources.</p>
<p>The name must be unique within Azure as it's used to form an URL for your storage account. The URL is formed by adding the storage account name in front of the standard DNS suffix. For example, naming the storage account <kbd>packtdemo</kbd> would create the URL <kbd>packtdemo.core.windows.net</kbd> and therefore the storage account name must be unique.</p>
<p>The <span class="packt_screen">Deployment model</span> allows us to choose between <span class="packt_screen">Resource manager</span> and <span class="packt_screen">Classic</span> model. As the <span class="packt_screen">Classic</span> model is outdated and using <span class="packt_screen">Resource manager</span> is recommended, I advise you choose <span class="packt_screen">Resource manager</span> whenever creating a new resource.</p>
<p><span class="packt_screen">Performance</span> allows us to choose between <span class="packt_screen">Standard</span> and <span class="packt_screen">Premium</span> storage. This is basically choosing between HDD and SSD, but will also impact the price of your storage. <span class="packt_screen">Premium</span> storage comes with SSD and significantly better performance, but the price increase is equally significant.</p>
<p class="mce-root"/>
<p><span class="packt_screen">Secure transfer required</span> allows us to choose between enabling and disabling this option. Enabling will require all incoming requests to our storage to be done over HTTPS and automatically blocking any requests coming over HTTP. The feature is very similar to <span class="packt_screen">Allow only HTTPS</span> in Azure web apps. As this feature is security related, I recommend enabling this option. </p>
<p>A screenshot with Azure Storage account options is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-511 image-border" src="Images/5b486daf-03f1-4bb9-8f7d-43336238d8d2.png" style="width:19.75em;height:46.00em;" width="281" height="654"/></p>
<p class="mce-root"/>
<p>Now we come to a couple of settings that are related only to the Azure Storage account. Even through the performance option is also related directly to storage, we can see the option to choose storage performance in other services too, such as <span>VM</span>s or even some <span>PaaS</span> resources. Options unique to the Storage account are account kind and replication.</p>
<p><strong>Account kind</strong> allows us to choose between three options:</p>
<ul>
<li><span class="packt_screen">Storage (general purpose v1)</span></li>
<li><span class="packt_screen"><span>StorageV2 (g</span>eneral purpose v2)</span></li>
<li><span class="packt_screen">Blob storage</span></li>
</ul>
<p>General purpose v2 storage supports all features that are supported by general purpose v1, and brings some newer features. It's recommended you use general purpose v2, especially if you want to use the latest APIs and features such as access tier, that allows you to use hot and cold storage.</p>
<p>Hot and cold storage allows you to choose what kind of access tier you want to use based on the data you are storing. Hot costs more per GB stored but transactions to storage are lower. Cold costs less per GB stored but transactions to storage come with higher prices. This makes the cold access tier more suitable for archive and the hot access tier for active storage. What's great about this feature is that you can switch between access tiers and change from one to another at any time.</p>
<p>An upgrade from general purpose v1 to general purpose v2 can be made at any time (but not the other way around) in case you already have a storage account in v1 and want to benefit from features of v2. However, there are some cases in which you need to use v1 as the only option. For example, when classic deployment is needed (general purpose v2 is only supported in resource manager), or where you need to use an older storage service REST API.</p>
<p><span class="packt_screen">A Blob storage</span> account supports the same features as general purpose v2 when it comes to block blobs, but are limited only to block blobs; they don't support page blobs. As the price is very similar, it's recommended you use general purpose v2 storage as this comes with the same price but more options.</p>
<p class="mce-root"/>
<p>Options for account kind are shown in the screenshot here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-512 image-border" src="Images/b43a14f0-8006-4e4e-8e45-e2f7eebc95ab.png" style="width:20.33em;height:9.67em;" width="300" height="142"/></p>
<p><span class="packt_screen">Replication</span> comes with three options, which are the same as account kind. We can choose between:</p>
<ul>
<li><span class="packt_screen">Locally-redundant storage (LRS)</span></li>
<li><span class="packt_screen">Geo-redundant storage (GRS)</span></li>
<li><span class="packt_screen">Read-access geo-redundant storage (RA-GRS)</span></li>
</ul>
<p>LRS is based on a strategy similar to availability set and availability zones for <span>VM</span>s. Additional copies of data are kept across the Azure Datacenter to provide durability and redundancy in case of hardware faults or updates. It's designed to provide SLA of <span>99.999999999% (11 9s). All data is kept inside a single Datacenter, and possible failover is triggered automatically.</span></p>
<p><span>GRS is designed in a very similar fashion, with the difference being that copies are in different Azure Datacenters which are, thousands of miles away from the original Datacenter. Because of this, additional durability is in place with an SLA of 99.99999999999999% (16 9s) . Redundant copy is available for access only when automatic failover is triggered.</span></p>
<p><span>RA-GRS is designed in the same way as GRS, but with the difference that redundant copy is available for read, even when failover isn't activated.</span></p>
<p><span class="packt_screen">Replication</span> options are shown in following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-513 image-border" src="Images/b4677b4e-8e30-47a8-a602-e5fa6542ad67.png" style="width:20.92em;height:9.50em;" width="303" height="137"/></p>
<p>Additional options for the Azure Storage account are virtual networks and data lake storage v2.</p>
<p>If we enable <span class="packt_screen">Virtual networks</span>, we can select an existing VNet (or create a new one) and select a <span class="packt_screen">Subnets</span>. This will join our storage to the selected subnet on the selected VNet and assign a private IP address to our storage, allowing us to access storage over a private network rather then over the internet. <span>Data lake storage v2 is in preview, and can be enabled only if a few requirements are met. We need to choose general purpose v2 storage, it's available only in a limited number of Azure Datacenters, and preview must be pre-approved. These options are shown in the following screenshot:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-514 image-border" src="Images/22cae5ae-c5c6-4d17-85ff-3efa72bfc3a3.png" style="width:19.92em;height:21.42em;" width="312" height="335"/></p>
<div class="packt_infobox"><span>Note that account kind, replication, and performance will impact the price of Azure Storage. Location is also a factor as not all resources cost the same in all Azure Datacenters, but this doesn't have as much impact as the other three options.</span></div>
<p>Deployment of the Azure Storage account is fast and is usually done in under one minute.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Storage settings</h1>
                </header>
            
            <article>
                
<p>Once the Azure Storage account is created, we can use different options to manage it. Some of the options are similar to the options available to other Azure resources, so let's focus on the Azure Storage account unique options.</p>
<p>The first option under <span class="packt_screen">Settings</span> is <span class="packt_screen">Access keys</span>. <span class="packt_screen">Access keys</span> are used to authenticate access to your Azure Storage account. They are usually used to enable access from applications, so you can find connection strings here along with access keys. There are two access keys available, and you can regenerate them if you think the original keys have been stolen or compromised.</p>
<p><strong>Cross-origin resource sharing</strong> (<strong><span>CORS</span></strong>) allows you to define trusted domains. Web browsers implement security restrictions that prevent applications from calling APIs in a different domain. CORS provides ways for the original domain to <span>securely access an API from another domain.</span></p>
<p><span class="packt_screen">Configuration</span> allows us to change some of the settings that are available when creating the Storage account. Under this option, we can upgrade storage from general purpose v1 to v2, we can change performance, and replication settings, and enable or disable secure transfer requirements.</p>
<p>Azure Storage is automatically encrypted and protects data at rest. Automatic encryption is done using <span>using Microsoft Managed Keys for Azure blobs, tables, files and queues. However, the encryption option allows us to bring our own key and encrypt storage with that key instead.</span></p>
<p><strong>Shared access signature</strong> (<strong>SAS</strong>) provides an access key that lasts a limited time. We can use this key to provide temporary access to our storage and can define how long this access is going to last. After the key expires, it can't be used again.</p>
<p>Under <span class="packt_screen">Firewall</span> and <span class="packt_screen">Virtual network</span> settings, we can change networking and access settings for our storage. We can attach storage to VNet (and subnet) or change the VNet storage it's associated with. Using firewall, we can block access to our storage to anyone who isn't coming from a trusted IP address. We can white list our on-premises IP addresses or other trusted IP addresses to allow Azure Storage access only from these addresses and to prevent anyone else from gaining access.</p>
<p><span class="packt_screen">Properties</span>, <span class="packt_screen">Locks</span>, and <span class="packt_screen">Automation scripts</span> are options available to all Azure resources.</p>
<p>The next set of options is related to blob service. Here we have <span class="packt_screen">Blobs</span>, <span class="packt_screen">Custom domains</span>, <span class="packt_screen">Soft delete</span>, <span class="packt_screen">Azure CDN</span>, and <span class="packt_screen">Azure search</span>.</p>
<p><span class="packt_screen">Blobs</span> allow you to see the current list of blobs in the storage account and perform actions such as creating a new blob or deleting an existing one. Further, you can access a blob and see the list of files inside the blob and perform actions on files such as download or delete.</p>
<p><span class="packt_screen">Custom domain</span> allows you to use a custom domain with your storage account. Instead of using the provided DNS, you can set up CNAME on your custom domain and point it to your storage to start using the custom domain. </p>
<p><span class="packt_screen">Soft delete</span> allows you to set up a retention policy for your storage. If enabled, the default retention policy is seven days but this can be change to up to 365 days. <span class="packt_screen">Soft delete</span> will give you ability to recover any deleted blobs. This extends to blobs that are deleted as result of overwrite, so you can recover deleted blobs or older versions of blobs.</p>
<p><span class="packt_screen">Azure CDN</span> and <span class="packt_screen">Azure search</span> are options to link these Azure services to your storage account. <span class="packt_screen">Azure CDN</span> is used to cache storage content in order to increase performance and minimize latency. <span class="packt_screen">Azure search</span><span> is a fully managed cloud search service that provides a better user experience.</span></p>
<p>The following options allow us to manage the file service, table service, and queue service. For each of these services, we can see a list of existing file services in the storage account and we can perform different operations such as <span class="packt_screen">Delete existing service</span>, <span class="packt_screen">Create a new one</span> or <span class="packt_screen">Set up access policies</span>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Migrating a database to the cloud</h1>
                </header>
            
            <article>
                
<p>Once we have our Storage account, we can start loading data. This can be any type of file, we can use storage as a staging phase in which we prepare uploaded files before they are actually used, or we can upload files that are directly used by our applications. </p>
<p>Over the years, I've seen many organizations using Azure Storage as a backup location for on-premises SQL databases. This is a convenient way to start our cloud journey as we get relatively cheap storage that is offsite and encrypted. </p>
<p>Once databases are stored to cloud, the next step would be to use backups to restore a database in Azure and start using them either as IaaS or <span>PaaS</span>.</p>
<p>Let's see how we can back up our database directly to Azure Storage.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Backing up a database to storage</h1>
                </header>
            
            <article>
                
<p>In order to back up the database to Azure Storage, first we need to open <strong>SQL Server Management Studio</strong> (<strong>SSMS</strong>), select the database we want to back up, and then select <span class="packt_screen">Tasks | </span><span class="packt_screen">Back Up...</span>. The first step is shown in this screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-515 image-border" src="Images/b9eefea3-b389-4148-a63f-26924e56016c.png" style="width:84.17em;height:49.33em;" width="1010" height="592"/></p>
<p>New windows will open with options to select the <span class="packt_screen">Database</span> (this will already be selected if we selected a proper database in the first step, but can be changed or we can select multiple databases), <span class="packt_screen">Backup type</span> (usually a full backup is recommended) and finally, <span class="packt_screen">Destination</span>. The default option is <span class="packt_screen">Disk,</span> and we need to change this to an <span class="packt_screen">URL</span>. A screenshot of these options is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-516 image-border" src="Images/9995ab5d-15c7-4611-8060-78b475a5ab27.png" style="width:89.83em;height:48.75em;" width="1078" height="585"/></p>
<p>After selecting the <span class="packt_screen">URL</span> as the destination, we must select add in order to provide the path. This will open a new window in which we need to provide our Azure account information in order to access our Azure subscription. After this is done, we have access to our Azure subscription from SSMS and can select our storage account and blob where the backup will be stored. As <strong>Shared Access Signature</strong> (<strong>SAS</strong>) is used to perform the backup, we must create a new SAS and provide a date of expiration. Setting up a destination for the backup is shown in this screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-517 image-border" src="Images/98b57bbd-f4e2-4650-8d0e-3d93fac23a11.png" style="width:80.50em;height:34.75em;" width="966" height="417"/></p>
<p>Finally, we click <span class="packt_screen">OK</span> and the backup is performed. Time to perform the backup depends on bandwidth, database size, and storage type. In this case, the storage type is usually standard, as storing backups to premium storage is overkill and we would be paying a premium service for an archive. After the backup is completed, we can see the file information in the Azure portal under the storage account in the blob we selected. An example of the file information in the Azure portal is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-518 image-border" src="Images/83af4d50-b3e9-4079-a430-e56c1c18c7a7.png" style="width:129.83em;height:37.58em;" width="1558" height="451"/></p>
<p>After the backup is performed, we can use this backup to restore the database in Azure. However, full backup can be only restored on an SQL Server running on an Azure Virtual Machine (IaaS). In order to restore a backup in the Azure SQL Database (PaaS), we must use BACPAC. BACPAC contains data and metadata of the SQL database. The process to backup BACPAC to Azure Storage is similar to the process of creating a full backup of the database.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Migrating a database to Azure SQL</h1>
                </header>
            
            <article>
                
<p>Creating backup and restoring it is not the only option on how to migrate the database to Azure. This process can be done without using a backup, directly migrating the database to Azure. </p>
<p>In order to do this, the first step is to select the database, click on bold Tasks and select the option to <span class="packt_screen">Deploy Database to Microsoft Azure SQL Database in SSMS</span>. The first step is shown in this screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-519 image-border" src="Images/52ecb141-3a47-4719-89ee-c7365bc0d09e.png" style="width:81.08em;height:42.50em;" width="973" height="510"/></p>
<p>The second step is to connect to your Azure SQL Server. In order to do this, we select <span class="packt_screen">Connect...</span> in the new window that opened after selecting the options in the first step. This window is shown in this screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-520 image-border" src="Images/35609ae5-65e1-4bcc-b09e-1e0d0fea3e4b.png" style="width:49.92em;height:31.00em;" width="877" height="545"/></p>
<p>In order to connect to the Azure SQL database, we need to provide the server URL, username, and password. Make sure that the public IP address of your server is added to the firewall rule of your Azure SQL Server, otherwise you will not be able to connect. An example of connection options is shown in this screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-521 image-border" src="Images/3f7bd223-ce50-45de-a8c4-7f3121012cd9.png" style="width:44.58em;height:29.25em;" width="707" height="464"/></p>
<p>After a connection is established, we are back to the window from the previous step. Finally, we must provide the database tier for the Azure SQL database that will be used for migration (a new database is created). An example of the database size option is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-522 image-border" src="Images/009235ab-f735-4eec-96c2-8b0de161f6d0.png" style="width:72.83em;height:45.75em;" width="874" height="549"/></p>
<p>After the process is completed, we will receive a message about successful tasks. the time needed to complete migration can depend on many factors such as database size, bandwidth, and Azure SQL database tier. Note that selecting too small a tier (if we are migrating a large database) will result in an error as the performance of the target database can be insufficient to handle the workload needed to perform the migration of a large database. A screenshot of a <span>successful migration is shown here:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-523 image-border" src="Images/f3507786-b1ff-4943-a8a9-22e83f8b8fb8.png" style="width:73.50em;height:61.00em;" width="882" height="732"/></p>
<p>After migration is completed, we can connect to the Azure SQL server with SSMS and find the database that is migrated, as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-524 image-border" src="Images/dc67a728-c737-4957-84ca-72bf9841628f.png" style="width:41.83em;height:10.08em;" width="642" height="155"/></p>
<p>In some cases, migration will fail even when the proper Azure SQL database tier is selected. This is due to database incompatibility with Azure SQL database. For example, when using Azure SQL database, a clustered index is required (recommended for on-premises). If the database that is migrated, doesn't contain clustered indexes, migration will fail. Luckily, there is a tool that can help us perform assessment that will tell us about possible issues and problems on our database.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Database assessment</h1>
                </header>
            
            <article>
                
<p>To create an assessment of our database and make sure it's ready for migration, we can use Microsoft Data Migration Assistant. This is tool is free and can be downloaded from the Microsoft Download Center.</p>
<p>After you install this tool, you can start a new project. Select <span class="packt_screen">Assessment</span>, provide the <span class="packt_screen">Project name</span>, and <span class="packt_screen">Source server type,</span> and <span class="packt_screen">Target server type,</span>. For source, select <span class="packt_screen">SQL Server</span> and for target, select <span class="packt_screen">Azure SQL Database</span>. An example for a new project is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-525 image-border" src="Images/05db4e83-f1e9-419d-b45f-c650c00b5313.png" style="width:24.50em;height:33.92em;" width="294" height="407"/></p>
<p>The second step is to select assessment options. You can select to check compatibility and feature parity. Compatibility will check your database features and provide if there are any blocking issues or deprecated features preventing migration. Feature parity will check if there are any features or functions that are not supported. For example, an Azure SQL database doesn't support <span class="packt_screen">SQL Server Reporting Service</span> (<span class="packt_screen">SSRS</span>), so if your application is using SSRS, this can cause an issue. I recommend selecting both options, as shown here:</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-526 image-border" src="Images/e8a1c420-8f6b-4f9d-8458-ed261506b21a.png" style="width:88.25em;height:29.58em;" width="1059" height="355"/></p>
<p>After selecting what to check, we need to provide a source that will be checked. In order to make an assessment, this tool needs access to the database, so we must provide the SQL Server, credentials, and database. Selected databases will be shown in the list along with the SQL Server version, as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-527 image-border" src="Images/6ae4cf50-0733-41b6-b16a-ec061a737d8a.png" style="width:75.00em;height:18.42em;" width="900" height="221"/></p>
<p>The time needed to perform assessment depends on database size and complexity, and it can take from a couple of minutes to a couple of hours. After assessment is completed, we'll receive two reports. The first report is on feature parity, and an example is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-528 image-border" src="Images/e1c4bdd2-6266-4600-9a4a-61b1455d0347.png" style="width:91.75em;height:37.17em;" width="1101" height="446"/></p>
<p>The second report is on database compatibility. With a little luck, and if the maintenance of the database was performed regularly, you will get a report shown in the following example, showing there are no compatibility issues preventing you from migrating your database to Azure SQL Database:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-529 image-border" src="Images/5d6ec5d4-ec57-4d47-a44d-5ee94c706459.png" style="width:64.42em;height:27.33em;" width="773" height="328"/></p>
<p>One of the possible compatibility issues is a clustered index. It was recommended you have a clustered index for each table in the database but with an Azure SQL database, this is a requirement. Another example are CLR functions that are not supported in an Azure SQL database.</p>
<p>An assessment tool can be used to make an assessment, not only for migration to Azure SQL Database but to other versions of SQL Server. So, if you are planning on migrating a database to a newer version of SQL Server (in Azure or on-premises), this tool can make assessment for these migrations as well.</p>
<p>Microsoft Data Migration Assistant can be used to perform the migration of database as well. Note that the difference between this migration and migration through SSMS is that here the Azure SQL database must be created (empty Azure SQL database) prior to migration.</p>
<p>As a third option for migration, there is the Azure Database Migration Service. This migration is in fact a data sync option as a database and schema must exist before running this service. Azure Database Migration Service allows you to link source and target database and copy data from the source to the target for a complete database or for selected tables.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Enabling Azure Backup</h1>
                </header>
            
            <article>
                
<p>Once the recovery services vault is created, we can start configuring. As mentioned, we have two different services and both services can be used to protect resources in Azure and on-premises.</p>
<p>Let's start with enabling Azure Backup on Azure resources. If we select that we want to protect workloads in Azure under the Azure Backup configuration, options for protections are <span><span class="packt_screen">Virtual machine</span></span>, <span class="packt_screen">Azure FileShare (Preview)</span>, and <span class="packt_screen">SQL Server in Azure VM <span>(Preview)</span></span>. Let's select <span class="packt_screen">Virtual machine</span> and continue. An example of Azure resources for Azure Backup is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-531 image-border" src="Images/44920fcc-ead0-42db-829d-6bc3b124dfe1.png" style="width:24.50em;height:19.58em;" width="398" height="319"/></p>
<p>A list of resources available will be automatically provided. As <span><span class="packt_screen">Virtual machine</span></span> are selected, this will be a list of Azure VMs. If <span class="packt_screen">Azure FileShare <span>(Preview)</span></span> was selected, this would be a list of Azure Storage accounts containing FileShare. We select the <span><span class="packt_screen">Virtual machine</span></span> that we want to back up, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-532 image-border" src="Images/6d908565-88ab-4eb7-b750-52654e90979e.png" style="width:97.08em;height:62.67em;" width="1165" height="752"/></p>
<p>After backup is enabled, we can see a list of protected <span>VM</span>s under backup items. The list will also show the <span class="packt_screen">STATUS</span>, the <span class="packt_screen">TYPE</span> of protected resources, and other useful information as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-533 image-border" src="Images/1730b578-9e66-4205-966a-506b885e006b.png" style="width:101.83em;height:22.83em;" width="1222" height="274"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Backing up on-premises resources</h1>
                </header>
            
            <article>
                
<p>Using Azure Backup to protect on-premises resources requires a little more work. After selecting on-premises resources in the Azure Backup configuration, we get a different list from the one when we selected Azure resources. We can choose between <span class="packt_screen">Files and folders</span>, <span class="packt_screen">Hyper-V Virtual Machines</span>, <span class="packt_screen">VMware Virtual Machines</span>, <span class="packt_screen">Microsoft SQL Server</span>, <span class="packt_screen">Microsoft SharePoint</span>, <span class="packt_screen">Microsoft Exchange</span>, <span class="packt_screen">System state</span>, and <span class="packt_screen">Bare Metal Recovery</span>.</p>
<p>After configuration in the Azure portal, we need to install the Recovery Service Agent, which will allow us to register on-premises resources in the recovery services vault. A screenshot of the Recovery Service Agent is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-534 image-border" src="Images/16efa466-b625-47ad-9cbc-ce68a428a75a.png" style="width:95.75em;height:41.92em;" width="1149" height="503"/></p>
<p>To proceed with registration, we must provide <span class="packt_screen">Vault Credentials</span>. <span class="packt_screen">Vault Credentials</span> are provided in the form of a file that can be downloaded from the recovery services vault. After the <span class="packt_screen">Vault Credentials</span> are provided, the Recovery Service Agent will automatically load backup vault information, as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-536 image-border" src="Images/91e1795b-ee63-4376-a665-d57b01d38857.png" style="width:96.50em;height:56.75em;" width="1158" height="681"/></p>
<p>The following step is to provide a passphrase that will be used to encrypt and decrypt the backup. A passphrase must be a minimum of 16 characters and will be stored in the location of your choice. Make sure that you know where your passphrase is located. Otherwise, you will not be able to restore any of your backups, if needed. The process to create a passphrase is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-537 image-border" src="Images/c9c91152-0e73-4897-8492-4f899e17eb2a.png" style="width:95.92em;height:66.50em;" width="1151" height="798"/></p>
<p>Once the server is registered in the recovery service vault, we can use Microsoft Azure Backup software on the target server (this can be installed on the client OS as well) to configure what and when we are going to back up. We can see the status of current jobs and perform other actions as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-538 image-border" src="Images/28998e28-745b-4dc4-be83-dcacac6c036e.png" style="width:160.58em;height:83.92em;" width="1927" height="1007"/></p>
<p>To configure the backup job, we need to provide what we are going to back up. We can select an entire drive, or select specific files and folders as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-539 image-border" src="Images/b82ee9a1-7080-4113-a039-2626cf0813c1.png" style="width:44.25em;height:33.75em;" width="822" height="627"/></p>
<p>After selecting what to back up, we need to define when and the schedule when backup is going to be performed. We can select a weekly or daily backup (maximum is three times a day). An example of a schedule is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-540 image-border" src="Images/f243b6cf-18b3-427a-bea9-034c4a9b6c26.png" style="width:40.67em;height:14.17em;" width="789" height="275"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>After the schedule, we need to provide a retention policy. A retention policy defines how long our backups are going to be available and can be configured on a weekly, monthly and yearly basis. A default retention policy is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-541 image-border" src="Images/2a211d42-430c-4efe-b932-9fe9cfc439a3.png" style="width:56.83em;height:35.67em;" width="1047" height="657"/></p>
<p>The last option is to configure how the initial backup is going to be performed. As an initial backup usually means that a large amount of data is going to be backed up, we need to define if this is going to be performed directly over the network (possibly creating overload), or in stages by copying parts of data to Azure Storage and then copying data to the recovery vault. An example of options is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-543 image-border" src="Images/fcf0764c-b8b5-4f0b-845e-bd41e5a1f969.png" style="width:46.75em;height:32.92em;" width="797" height="561"/></p>
<p>Time to perform the initial backup depends on the size of data and the network bandwidth. After the initial backup, backups are performed as delta (copying only changes) and should not take long to complete. Note again that keeping the passphrase is very important, backups are encrypted and you will not be able to restore any data without the passphrase used to encrypt. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure Site Recovery</h1>
                </header>
            
            <article>
                
<p>ASR is not a backup solution but a <strong>disaster recovery</strong> (<strong>DR</strong>) site in the cloud. Having a DR site was never easier and never cheaper than having one in Azure. Most traditional DR sites involve equipment identical (or at least very similar) to the site that is protected, and cost around 80% of price of the original site. On the other hand, <span>ASR</span> is charged per protected node and for storage where data is stored, so comes very cheap. If recovery is activated in Azure, then compute prices is added for <span>VM</span>s. This way you are paying only for protection and compute prices only when failover occurs. If we create an on-premises DR site, we must pay for the hardware needed to run DR even when failover isn't in place but only used as protection.</p>
<p><span>ASR</span> can also be used to perform the migration of <span>VM</span>s from on-premises to the cloud. As protecting Azure VMs is fairly simple, we will skip to protecting on-premises VMs and show how to protect local resources and use ASR to perform migration.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Configuring ASR for on-premises resources</h1>
                </header>
            
            <article>
                
<p>To start creating disaster recovery in Azure, we must start by configuring <span>ASR</span> in the recovery services vault. Three steps are involved:</p>
<ol>
<li>Prepare infrastructure</li>
<li>Replicate application</li>
<li>Manage recovery plans</li>
</ol>
<p>After we select to <span class="packt_screen">Prepare infrastructure</span>, a new blade will open. Here we have couple of options that we need to define. First, we need to select if we want to protect Azure or <span class="packt_screen">On-premises</span> resources. As I want to demonstrate how to use ASR for migration, I'll select <span class="packt_screen">On-premises</span>. The next option is to define where we want to replicate our resources, and the options available are Azure or another site.</p>
<p>We need to define if the infrastructure that we want to protect is virtualized, and if it is, we select between Hyper-V and VMware. If we are using Hyper-V, we need to define whether we are using SC VMM or not. A screenshot of the protection goal blade is show here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-544 image-border" src="Images/be7be700-c31f-47c8-a93e-1511979b1928.png" style="width:42.00em;height:31.92em;" width="822" height="624"/></p>
<p class="mce-root"/>
<p>The second step will lead you to <span class="packt_screen">Deployment planning</span>. Here we can download a tool to estimate requirements for ASR in our on-premises infrastructure. This step isn't required but it's recommended as insufficient capacity can lead to replication issues. A deployment planner can be downloaded directly from the Azure portal as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-545 image-border" src="Images/9a41579e-2f10-423e-b27c-4725e1d3de0a.png" style="width:40.17em;height:29.92em;" width="811" height="604"/></p>
<p>If the capacity is in order, we can proceed to <span class="packt_screen">Source</span> preparation. We need to create a Hyper-V site and register a Hyper-V server that should be included in the replication, as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-546 image-border" src="Images/26662ad6-dccc-485e-9557-44a1e77d2882.png" style="width:41.75em;height:30.83em;" width="816" height="602"/></p>
<p>After we create a new site, we need to download and install agents on all Hyper-V hosts that we want to protect on that site. Installation of this agent is similar to the backup agent (we need the vault credentials that can be downloaded from the recovery services vault) and after we have finished, we will have Hyper-V hosts available under our site. Note that after installation, it can take 15 to 30 minutes before Hyper-V hosts are visible in the Azure portal. A successfully registered site and host are shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-547 image-border" src="Images/baa0b991-3339-4d43-a287-09221fe3f580.png" style="width:44.50em;height:37.75em;" width="801" height="680"/></p>
<p>After we set up the <span class="packt_screen">Source</span> environment, we need to prepare the <span class="packt_screen">Target</span> as well. We need to select the Azure <span class="packt_screen">Subscription</span>, and deployment model, and prepare Azure infrastructure. Under infrastructure, we need to provide at least one storage account and one VNet for the target environment. The storage account must be provided for the <span>VM</span> disks and VNet is used in case DR is triggered and VMs must be restored to Azure (VM must be connected to VNet). The <span class="packt_screen">Target</span> configuration is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-548 image-border" src="Images/27a6d21f-0ebb-4592-b0e0-55bbca920b60.png" style="width:40.00em;height:37.00em;" width="813" height="752"/></p>
<p>The last step in infrastructure preparation is to create a replication policy. We need to define rules for frequency, recovery points retention, and some other settings. I recommend leaving everything on default settings except <span class="packt_screen">Copy frequency</span> that may be changed based on the roles of the servers that are protected. You can also create multiple policies and apply them according to your requirements. You probably don't need to replicate a web server as often as a database or file server and can use a different replication policy based on the roles of the protected server. An example of a default replication policy is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-549 image-border" src="Images/bab7f3b8-41da-4ab9-bd4e-514b4655fabe.png" style="width:131.08em;height:63.17em;" width="1573" height="758"/></p>
<p>Based on the previous steps, we can add multiple sources to a single key vault. In the same key vault, we can have registered Azure resources, multiple Hyper-V sites, VMware sites, or physical servers.</p>
<p>After we prepare the infrastructure for ASR, we need to define what we are going to replicate and when. We need to select a source (<span class="packt_screen">Azure</span> or <span class="packt_screen">On-premises</span>) and select an appropriate location registered in recovery services vault. An example of <span class="packt_screen">Source</span> selection is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-550 image-border" src="Images/1a23ab1c-71a9-4179-b74d-f89c5d090cd1.png" style="width:53.75em;height:27.92em;" width="817" height="424"/></p>
<p>After we select <span class="packt_screen">Source</span>, we need to select the <span class="packt_screen">Target</span> as well. Required parameters are the Azure <span class="packt_screen">Subscription</span>, resource group, deployment model, storage, and network settings. The resource group will be used as the location where the VMs will be created in case of failover.</p>
<p>The same goes for the virtual network, it will be used only if failover is in place and VMs need to be created in Azure. Storage is used to place VM disks (VHDs) but it will be used even when failover isn't in place, as data must be stored even when VM is not running. An example of <span class="packt_screen">Target</span> settings is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-551 image-border" src="Images/1cd3b0a9-1798-4583-96db-6b79cd92d8be.png" style="width:42.58em;height:43.58em;" width="740" height="757"/></p>
<p>The <span class="packt_screen">Source</span> and <span class="packt_screen">Target</span> are in place and now we need to select what will be protected. This is done in two steps. The first will be to select <span class="packt_screen">Virtual machines</span> in the previously selected site that we want to protect, as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-552 image-border" src="Images/97984e4e-8642-40a1-9261-e2135f8a980e.png" style="width:35.42em;height:28.25em;" width="719" height="573"/></p>
<p>After the <span><span class="packt_screen">Virtual machines</span></span> that will be protected are selected, we must provide additional settings for these VMs. Settings that are required are the operating system for our VM, and disks that we want to replicate. An example is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-553 image-border" src="Images/1e2ade1b-3c86-4bc0-8928-35bc887d6af6.png" style="width:112.83em;height:45.92em;" width="1354" height="551"/></p>
<p class="mce-root"/>
<p>One of the last steps is to select a replication policy that will be applied. As we can have multiple policies created, we can assign one that best fits the roles and settings of the VMs that are protected. An example of <span class="packt_screen">Replication settings</span> is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-554 image-border" src="Images/cda4cccc-a1ad-432f-a891-a009d3455e9b.png" style="width:86.75em;height:57.25em;" width="1041" height="687"/></p>
<p>Finally, everything is in place and by clicking <span class="packt_screen">OK</span>, we can enable replication and start the protection of our VMs. The last step is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-555 image-border" src="Images/2d984e09-3748-4b4e-bc2c-bb24f2c8224d.png" style="width:21.25em;height:39.67em;" width="366" height="684"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using ASR as a migration tool</h1>
                </header>
            
            <article>
                
<p>After replication is completed, you can see the status of replicated VMs under the protected items in the recovery services vault. You can use the same blade to monitor the replication process and see the percentage of replicated items. Time needed to complete initial replication depends on network bandwidth, storage settings, and the size of data that will be replicated. An example of a successful replication is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1077 image-border" src="Images/5fd7d082-0bac-4221-8fa2-4eabfeaff8d1.png" style="width:109.25em;height:32.33em;" width="1311" height="388"/></p>
<p>If we select any of the VMs under replicated items, we can find additional information on health, events, and options for failover (planned failover, failover, and test failover) as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-558 image-border" src="Images/ff9ee32f-44c3-4be5-92f2-3e9bfbfdeb22.png" style="width:109.25em;height:41.67em;" width="1311" height="500"/></p>
<p>There is a difference on different failovers and how they affect the primary VM. For example, a test failover will create a VM instance in Azure but will not affect the on-premises (primary) VM in any way. On the other hand, a planned failover and failover will create a new VM instance in Azure, declare it primary, and can even turn off the on-premises VM.</p>
<p>Another thing that can be found in this blade is a diagram of the infrastructure involved, showing you how all components involved in the process are connected. A diagram for the Hyper-V site is shown in this screenshot: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-559 image-border" src="Images/122fd4de-4495-41fe-aea8-377251f5692a.png" style="width:66.17em;height:40.75em;" width="794" height="489"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Failover and migrating the VM</h1>
                </header>
            
            <article>
                
<p>As the purpose of our replicating our VM is to migrate it to the cloud, let's move on and show how to perform this task.</p>
<p>First, we will need to perform the failover of our VM. Here we need to select a <span class="packt_screen">Recovery Point</span> we want to use, as we have multiple recovery points. Time needed for failover to complete depends on the size of the VM that will be created, amount of disks, and the size of data on these disks. An example for failover settings is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-560 image-border" src="Images/92dd61e0-a9b3-42fc-8c09-193704ad1659.png" style="width:23.00em;height:39.25em;" width="364" height="621"/></p>
<p>After failover completes, the VM will be running, and Azure and you can manage it as any other Azure VM. Note that this VM will not be using managed disks. This is because ASR replicates disks to storage and creates copies of on-premises VHD. When failover occurs, VHDs are used for our VM and attach to it but as result disks are not managed. However, <span>you can perform migration to managed disks when needed. If you plan to migrate this VM completely, I strongly recommend performing migration to managed disks. The VM after failover is shown here:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1078 image-border" src="Images/2b90e521-6ac7-414c-8229-f8ed8be1c4b6.png" style="width:119.00em;height:64.75em;" width="1428" height="777"/></p>
<p>After we complete failover, the VM is running in Azure but it's still connected to the on-premises VM. We can perform failback at any time and the VM is listed under the replicated items in the recovery services vault. To complete migration and have the VM running only as an Azure VM, we need to perform a complete migration step. This will remove the association of our VM from the on-premises VM and the recovery service vault, as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-562 image-border" src="Images/67fb56a4-ff03-42f7-a35a-7f0ed8b61103.png" style="width:21.92em;height:32.50em;" width="374" height="555"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Other options</h1>
                </header>
            
            <article>
                
<p>Finally, our VM is migrated to the cloud and running in Azure. Migrating with <span>ASR</span> allows us to minimize the downtime of our services but isn't the only option. </p>
<p>AzCopy allows us to copy data from on-premises to the cloud as well, and can be used as a migration tool for all sorts of files. Another option is to use PowerShell to upload VHDs to Azure and use them to deploy the Azure VM.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Azure import/export job is used to transfer a large amount of data to Azure. Imagine you have disks with 4 TB of data. Copying that over internet would take a lot of time. With Azure import/export job, you can create a job in Azure, copy that to physical disks and ship them to the Azure Datacenter. Disks will be then available to you in the Azure portal and you can use this data in the cloud. The process can go in the other direction as well and you can export data from Azure and ship it to yourself.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>After we introduced basic Azure services, both <span>IaaS</span> and PaaS, we explained the process of moving data to Azure. Microsoft offers extended options on how to assess if our data is cloud-ready, and also offers multiple tools to move data from on-premises to Azure. As the cost of inbound traffic is <kbd>0</kbd> and only outbound traffic from Azure is charged, we can see where Microsoft wants data to go.</p>
<p>The next step in the Azure journey is a hybrid cloud that will help us use on-premises resources we already have, and extend them with all the benefits the cloud has to offer. This scenario is the reality for most companies as most of them are already invested in local resources. Ignoring existing resources is not an option and we can leverage the Azure offering by extending existing resources with a hybrid cloud. In <a href="a17b3c61-feb1-4c60-be4d-cd18694088ca.xhtml" target="_blank">Chapter 7</a>, <em><span>Hybrid Cloud with Azure – Extending Local Workloads to the Cloud</span></em>, we'll discuss how to create a secure connection between Azure and local infrastructure, and use Azure as a hybrid cloud.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>An Azure Storage account can be deployed as...
<ol>
<li>Resource manager</li>
<li>Classic</li>
<li>Both</li>
</ol>
</li>
<li>To have maximum SLA, the Storage account should be...
<ol>
<li>Locally redundant</li>
<li>Geo-redundant</li>
<li>Both</li>
</ol>
</li>
<li>The Storage account tier can be...
<ol>
<li>Standard</li>
<li>Premium</li>
<li>Both</li>
</ol>
</li>
</ol>
<ol start="4">
<li>Can a local database be backed up to the Azure Storage account?
<ol>
<li>Yes</li>
<li>No</li>
</ol>
</li>
<li><span>Can a local database be deployed directly to Azure SQL database?</span>
<ol>
<li>Yes</li>
<li>No</li>
</ol>
</li>
<li>To use <span>ASR</span>, you need to create...
<ol>
<li>Azure Storage account</li>
<li>Recovery services vault</li>
<li>Azure Backup</li>
</ol>
</li>
<li><span>With Azure Backup, you can protect...</span>
<ol>
<li>Azure resources</li>
<li>On-premises resources</li>
<li>Both</li>
</ol>
</li>
<li>With <span>ASR</span>, you can protect...
<ol>
<li>Azure Virtual Machines</li>
<li>On-premises virtual machines</li>
<li>Both</li>
</ol>
</li>
<li>To migrate a VM protected with <span>ASR</span> to the cloud, you must...
<ol>
<li>Replicate the VM</li>
<li>Perform failover</li>
<li>Start the VM in Azure</li>
</ol>
</li>
<li>To migrate a large amount of data to Azure, we must use...
<ol>
<li>AzCopy</li>
<li>PowerShell</li>
<li>Azure import/export job</li>
</ol>
</li>
</ol>


            </article>

            
        </section>
    </div>



  </body></html>