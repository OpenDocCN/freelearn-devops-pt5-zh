- en: Cloud Data Centers - The New Reality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last few years, there has been a shift toward cloud systems, which enable
    the companies to scale in an easy and cheap way depending on the needs. They also
    enable companies to take advantage of something called **Infrastructure as Code**
    (**IAC**), which basically allows you to treat your physical resources (servers
    and routers) that previously had to be bought according to the needs as code that
    you can review, run, and re-run to adapt the infrastructure to your requirements.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to walk through the main cloud providers, taking
    a look at their main strengths and weak points in order to form a clear picture
    of what they offer and how we can, as engineers, take advantage of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Out of all the providers in the market, we are going to focus on these two:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Web Services** (**AWS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud Platform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We are also going to talk a bit about these:'
  prefs: []
  type: TYPE_NORMAL
- en: Heroku
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DigitalOcean
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We should have an open minded attitude, as all of them can offer a different
    and valuable set of features, something that should not be overlooked.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to introduce **Kubernetes**, which is, in my humble opinion, the
    answer to many problems in the modern DevOps world.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Web Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Amazon is by far the biggest online retailer with an almost worldwide presence.
    Everyone has heard about Amazon and the possibilities that this type of store
    present to the busy society of the 21st century: they offer home delivery of pretty
    much anything that can be bought in a conventional store.'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon was founded in 1994 by Jeff Bezos, and since then, it has grown consistently
    every year, offering more and more products and services, but at some point, they
    got into the cloud computing business. It makes sense that a big company such
    as Amazon needs a lot of processing power, is reliable, and is able to adapt to
    the necessities of the business quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Initially, the cloud services were an internal solution to satisfy the high
    availability needs of the business as well as have the capacity to grow in a uniform
    way. This created a lot of expertise within the company in building a top notch
    **Infrastructure as a Service** (**IaaS**) that, at some point, they realized
    could be sold to customers.
  prefs: []
  type: TYPE_NORMAL
- en: By 2006, there was nothing in the market to compete with them, so they were
    in the sweet spot for a successful start.
  prefs: []
  type: TYPE_NORMAL
- en: I remember I was only in college when the first two services, EC2 and EC3, were
    introduced in a conference.
  prefs: []
  type: TYPE_NORMAL
- en: EC2 allowed you to create virtual machines on the cloud with an API that was
    manipulated through a command-line interface as well as a web interface that would
    act as a monitor of your resources.
  prefs: []
  type: TYPE_NORMAL
- en: S3 was a key value (kind of) storage that allowed you to store immense sets
    of data at a very low price manipulated through the command-line interface as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: 'It really was a revolution. It was a complete paradigm shift: now you could
    ask for more resources as you need. This was as simple as an API call, and there
    you go: three new machines ready to be used in 2 minutes. The following screenshot
    is a list of services on AWS:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/22f5e569-6fcb-44b2-ae21-31e98ce48d4b.png)'
  prefs: []
  type: TYPE_IMG
- en: Catalog of services in AWS at January 2017
  prefs: []
  type: TYPE_NORMAL
- en: In the last few years, Amazon has been adding services very often, up until
    a point where it is hard to keep up with the pace. In this chapter, we are going
    to walk through the main services (or what I consider the most useful), showing
    their features and areas of application.
  prefs: []
  type: TYPE_NORMAL
- en: EC2 - computing service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first element that a cloud system has to provide to the users is computing
    power. **EC2** stands for **Elastic Compute Cloud**, and it allows you to create
    machines on the cloud with a few clicks.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what the EC2 interface looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/42721bc2-6e22-4a08-8e95-062b2962f003.png)'
  prefs: []
  type: TYPE_IMG
- en: EC2 interface
  prefs: []
  type: TYPE_NORMAL
- en: EC2 was launched on August 25, 2006 (beta version), and it has evolved a lot
    since then. It provides the user with different sizes of machines and is available
    across the globe (11 different regions as of today). This means that the user
    can spin up machines in different parts of the globe for high availability and
    latency purposes, enabling the engineers of your company to build multi-zone applications
    without coordinating teams across the globe.
  prefs: []
  type: TYPE_NORMAL
- en: They also provide different types of instances optimized for different tasks
    so that the users can tailor the infrastructure to their needs. In total, there
    are 24 different type of instances, but they are also grouped by type, which we
    will walk through later on in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at an example of how to launch an instance.
  prefs: []
  type: TYPE_NORMAL
- en: Launching an instance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first thing you need to do is go to the AWS EC2 interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now click on the Launch Instance button, which will bring you to the following
    screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/aa358a37-cb82-4374-98ea-f7cfd1b594a3.png)'
  prefs: []
  type: TYPE_IMG
- en: This is where you can choose the image to run. As you can see, the image is
    the operating system that will run on top of the EC2 Instance. In Amazon jargon,
    this image is called **Amazon Machine Image** (**AMI**), and you can create your
    own ones and save them for later usage, allowing you to ship prebuilt software.
    For now, choose Ubuntu Server 16.04 by clicking on Select.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next screen is about the size of the image. AWS offers quite a big variety
    of sizes and types of images. This parameter drastically affects the performance
    of the application regarding the network, memory, and CPU performance as well
    as the I/O of the machine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s look at the different types:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **Type** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| Bursting instances | T2 are general-purpose instances for burst processing.
    They provide a baseline level of CPU for peaks of processing power, but these
    peaks are available on an accumulative basis: while idle, the CPU accumulates
    credits that can be used during high demand periods, but once these credits are
    used, the performance goes back to the baseline level. |'
  prefs: []
  type: TYPE_TB
- en: '| General purpose | M3 is a general-purpose instance with dedicated resources
    (no burst credits). It provides a good balance between CPU, memory, and network
    resources, and it is the minimum instance for production applications that need
    solid performance.M4 follows the same philosophy as M3 but with an updated hardware:
    **Amazon Elastic Block Store **(**Amazon ****EBS**) optimized and a better CPU
    as well as enhanced networking are the highlights of this instance type.  |'
  prefs: []
  type: TYPE_TB
- en: '|  Compute Optimized | The compute optimized instances in AWS are C3 and C4\.
    In the same way as the M instances, C4 is a hardware upgrade of the C3\. These
    types of instances are prepared for intensive CPU work, such as data processing
    and analysis or demanding servers. C4 also comes with an enhanced network system,
    which is very helpful for high networking traffic applications. |'
  prefs: []
  type: TYPE_TB
- en: '| Memory Optimized  | As you can guess, AWS also provides memory optimized
    instances that can be used for applications that need high memory usage. Applications
    based on Apache Spark (or big data in general), in memory databases and similar,
    benefit the most from these type of instances. In this case, the memory optimized
    instances are divided into two sub-families:X1: These are large scale enterprise
    grade instances. X1 can be used for the most demanding applications in the enterprise
    ecosystem and it is the flagship of the memory intensive instances and is only
    used for very large applications.R3/R4: Even though are more modest than X1, R
    instances are well capable of handling the majority of day-to-day memory intensive
    applications. Cache systems, in memory databases, and similar systems are the
    best use cases for X and R instances. |'
  prefs: []
  type: TYPE_TB
- en: '| Accelerated Computing Instances  | Some applications, such as **Artificial
    Intelligence** (**AI**), have specific computing requirements, such as **Graphical
    Processing Unit** (**GPU**) processing or reconfigurable hardware. These instances
    are divided into three families:P2: GPU compute instances. These are optimized
    to carry specific processing tasks, such as breaking passwords through brute force
    as well as machine learning applications (they usually rely on GPU power).G2:
    Graphical processing instances. Rendering videos as well as ray tracing or video
    streaming are the best use cases for these instances. |'
  prefs: []
  type: TYPE_TB
- en: 'As you can see, there is an instance for every necessity that the user can
    have. For now, we are going to choose a small instance first because we are just
    testing AWS and second because AWS has a free tier, which enables you to use the
    `t2.micro` instances for up to 1 year without any charge, as shown in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e706b488-60fb-4543-96de-1a646d92ca27.png)'
  prefs: []
  type: TYPE_IMG
- en: Now we have two options. Click on Review Instance Launch or Configure Instance
    Details. In this case, we are going to click on Review Instance Launch, but by
    clicking on Configure Instance Details, we can configure several elements of the
    instance, such as networking, storage, and so on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you click on Review Instance Launch, the review screen shows up. Click
    on Launch and you should get presented with something similar to what is shown
    in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/87e704de-af4a-4e2e-b252-d3cddee8cba3.png)'
  prefs: []
  type: TYPE_IMG
- en: Just assign a name to the key-pair name and click on the Download Key Pair button,
    which will download a `.pem` file that we will use later on to access via `ssh`
    to the instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have specified the key pair, click on Launch Instance, as shown in
    the preceding screenshot, and that's all. After a few checks, your image will
    be ready for installing the required software ( this usually takes a couple of
    minutes).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is the bare minimum needed to create a running instance in AWS. As you
    can see, the full process is very well explained on the screen and in general,
    if you know the basics of DevOps (`ssh`, networking, and device management), you
    don't really need much help creating instances.
  prefs: []
  type: TYPE_NORMAL
- en: Relational Database Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What we have shown in the previous section are EC2 machines that can be used
    to install the required software. There is another service that allows you to
    administer high availability databases (MySQL, PostgreSQL, Maria DB, and Aurora
    as well as Oracle and SQL Server) across regions. This service is called RDS and
    it stands for Relational Database Service.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the big headaches with relational databases is the high availability
    configuration: master-master configuration is something that is usually expensive
    and out of reach of small companies. AWS has raised the bar with RDS offering
    multi-region high availability databases with a few clicks.'
  prefs: []
  type: TYPE_NORMAL
- en: Networking in AWS and EC2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AWS provides fine-grain control at the networking level. As with any physical
    data center, you can define your own networks, but AWS has a higher-level abstraction
    concept: The Virtual Private Cloud.'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon **Virtual Private Cloud **(Amazon **VPC**) is a segment of the AWS cloud
    that allows you to group and segregate your resources in subnetworks to organize
    and plan your infrastructure matching your requirements. It also allows you to
    create a VPN between AWS and your physical data center to extend the latter one,
    adding more resources from AWS. Also, when you create a resource in EC2, you have
    the possibility of creating the resource in your custom defined subnet within
    your VPC.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before jumping into what a VPC looks like, let''s first explain how AWS works
    regarding the geographical distribution of resources. AWS provides you with different
    data centers in different regions such as Europe, Asia, and the US. As an example,
    let''s take EU West, which has three different availability zones:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/421b84ce-78c3-473c-8100-bc2170eee84d.png)'
  prefs: []
  type: TYPE_IMG
- en: The concept of region in AWS is basically a geographical area where the AWS
    data center lives. Knowing this information enables us to build global scale applications
    that serve the traffic from the closest data center in order to improve latency.
    Another very good reason for this geographical distribution is the data protection
    laws in several countries. By being able to choose where our data lives, we can
    enforce the compliance with the laws.
  prefs: []
  type: TYPE_NORMAL
- en: Inside of these geographical regions, sometimes, we can find availability zones.
    One availability zone is basically a physically separated data center that ensures
    the high availability of our system, as in the case of a catastrophe in one of
    the data centers, we can always fall back on the other availability zones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how the regions and availability zones look:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9a18dceb-63b1-4dca-9830-1b276a4e13ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we understand how AWS works from the geographical perspective, let's
    dig deeper into what a VPC is in terms of regions and availability zones.
  prefs: []
  type: TYPE_NORMAL
- en: 'A VPC is a logically separated segment of the AWS cloud that is private to
    the user, can hold resources, and spans across all the availability regions in
    an AWS zone. Inside of this VPC, we can define different subnets (public and privates
    in different availability zones) and define which machines are reachable from
    the Internet: AWS allows you to create routing tables, Internet gateways, and
    NAT gateways among other common networking resources that enable the user to build
    anything that they can build in a physical data center.'
  prefs: []
  type: TYPE_NORMAL
- en: It would take a full book just to talk about the networking in AWS. We will
    go deeper into some concepts in the rest of the chapters of this book, but if
    you really want to dive deep into the networking side of AWS, you can find more
    data and examples at [http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Introduction.html](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Introduction.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS also provides a very powerful element: **Elastic Load Balancing **(**ELB**).
    An ELB is a modern version of the classic hardware load balancer. It enables us
    to health-check resources and only get the healthy ones into the pool. Also, AWS
    comes in two flavors: classic load balancer and application load balancer. The
    first version is, as the name suggests, an application load balancer that distributes
    the traffic depending on health checks and does not understand the data being
    transmitted, whereas the application load balancer can route the traffic based
    on advanced policies dependent on the information of the request. ELBs can also
    handle the full HTTPS flow so that we can carry the SSL termination in the load
    balancer and allow our applications to offload the encryption/decryption to them.'
  prefs: []
  type: TYPE_NORMAL
- en: Storage in AWS and EC2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Up until now, we have exposed how to create machines and networking infrastructure
    in AWS. One important thing when building applications is the storage of the data.
    By default, when we launch a machine in EC2, there are two types of storage that
    can be associated with the machine in the root volume in order to run the operating
    system:'
  prefs: []
  type: TYPE_NORMAL
- en: Instance storage backed images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amazon Elastic Block Store **(**Amazon** **EBS**) storage backed images'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first one, instance storage backed images, relies on the storage associated
    with the image to mount and run the root volume. This means that the data stored
    in the image will be lost once the machine is terminated (these type of images
    do not support the stop action; they just support termination).
  prefs: []
  type: TYPE_NORMAL
- en: 'The second type of instances are the ones backed by EBS. Elastic Block Store
    is the name that AWS gives to its storage capabilities. With EBS, the user can
    create and destroy volumes (block devices) as needed as well as snapshots: we
    can create a copy of a running image before carrying a risky operation so we can
    restore it if something goes wrong.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The type of storage can vary depending on our needs: you can create things
    from magnetic block devices to SSD drives as well as general-purpose units that
    can cover a lot of the use cases in all the applications.'
  prefs: []
  type: TYPE_NORMAL
- en: In general, all the instances are backed by EBS as the fact that the storage
    is a logically segregated from compute enables us to do things such as resizing
    an instance (for example, creating a more powerful instance) without losing the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Several volumes can be mounted into the same EC2 instance that gets exposed
    to it as if a physical device were attached to it, so if we are using a Linux-based
    image (such as Ubuntu), we can use the mount command to mount the devices into
    folders.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon **Simple Storage Service **(Amazon **S3**) is, as described by its name,
    a simple way of storing a large amount of data on the cloud at a very low cost
    with a nice set of features. Unlike EC2 storage based on devices with predefined
    size, Amazon S3 is practically a key value storage that enables us to identify
    data with a key. Unlike other key value storage technologies, S3 is prepared to
    store from tiny to very large objects (up to 5 terabytes) with very low response
    times and that are accessible anywhere.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same way as EC2, Amazon S3 is a feature that has the concept of regions,
    but S3 does not understand availability zones: the S3 service itself manages to
    get the objects stored on different devices, so you don''t need to worry about
    it. The data is stored in an abstraction called buckets that, if we try to compare
    S3 with a filesystem, would be the equivalent to a folder but with one catch:
    the bucket name has to be unique across all the regions on your AWS account so
    we can''t create one bucket called `Documents` in two different regions.'
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of S3 is that AWS provides a REST API to access objects in
    a very simple way, which makes it fairly easy to use it as storage for the modern
    web.
  prefs: []
  type: TYPE_NORMAL
- en: One of the best use cases that I've come across in my professional life for
    S3 is the management of a large number of documents in a financial institution.
    Usually, when companies are dealing with money, they have to onboard the customers
    to a process called **Customer Due Diligence** (**CDD**). This process ensures
    that the customers are who they claim to be and that the money is coming from
    a valid source. The company also has to keep the documents for a minimum of 6
    years due to financial regulations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to carry on this investigation, the users need to send documents to
    the company, and Amazon S3 is the perfect match for it: the customer uploads the
    documents to the website of the company, which in reality is pushing the documents
    to S3 buckets (one per customer) and replicating them across regions with the
    Amazon S3 replication feature. Also, S3 provides another interesting feature for
    this model: links to objects that expire within a time frame. Basically, this
    enables you to create a link that is valid only for a period of time so that if
    the person reviewing documents exposes the link to a third party, S3 will reply
    with an error, making it really hard to leak documents accidentally (the user
    could always download it).'
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting feature of S3 is the possibility of integrating it with
    Amazon **Key Management System** (Amazon **KMS**), another feature provided by
    AWS), so all our objects in S3 are encrypted by a key stored in KMS that can be
    transparently rotated periodically.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon ECR and ECS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Containers are the new norm. Every single company that I''ve come across in
    the last few years is using or considering using containers for their software.
    This enables us to build software with the microservices principles in mind (small
    individual software components running independently) as it provides a decent
    level of abstraction from the configuration and deployment of different apps:
    basically, the entire configuration is stored in a container and we only need
    to worry about how to run it.'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon, as one of the pioneers of the microservices architectures, has created
    its own image registry and cluster (service).
  prefs: []
  type: TYPE_NORMAL
- en: 'As we will see in depth in [Chapter 3](fee45e6c-df39-48ae-ab43-a18911facbd8.xhtml),
    *Docker,* is built around two concepts: images and containers. An image is a definition
    of an application (configuration *+* software), whereas a container is an instance
    of the running image. The image is built through a Dockerfile (a description of
    the image with a very basic script language) and stored in a registry, in this
    case, Amazon **EC2 Container Registry **(**ECR**), our private registry in the
    AWS infrastructure. We don''t need to worry about availability or managing resources;
    we just choose the region where our containers are going to run and push our images
    into that repository.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, from our host running Docker, the image is pulled and the container is
    instantiated. This is simple and effective, but there are a few considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: What happens when our host does not have enough resources to run as many containers
    as we want?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What happens if we want to ensure the high availability of our containers?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we ensure that the containers are restarted when they fail (for some
    reason)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we add more hardware resources to our system without downtime?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All those questions were trickier a few years ago but are simple now: Amazon **EC2
    Container Service **(Amazon **ECS**) will take care of it for us. ECS is basically
    a cluster of resources (EC2 machines) that work together to provide a runtime
    for our containers to be executed.'
  prefs: []
  type: TYPE_NORMAL
- en: Within ECS, when creating a new service, we specify parameters such as how many
    replicas of our container should be running at the same time as well as what configuration
    (image) our container is supposed to use. Let's see how it works.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we are going to create a cluster in the AWS console and see how it works.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the Amazon ECS page and click on Get started button (the only button
    in the screen as you haven''t created any resources yet):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/bb1f951f-e6fe-43e7-9c58-08e68be6cb0f.png)'
  prefs: []
  type: TYPE_IMG
- en: Make sure that the two checkboxes are ticked before continuing. We want to deploy
    a sample application to ECS but also we want to store the images in ECR.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The next screen is key: this is where we define the repository of our image,
    which will determine the repository URI that will be used for pushing images from
    our local machine using Docker.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a3ce3b43-8026-4151-9ba7-6b8298935224.png)'
  prefs: []
  type: TYPE_IMG
- en: Just use `devops-test` as the repository name, and our repository URI will look
    very similar to the one shown in the preceding screenshot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Step number 2 (out of 6) is a series of commands provided by AWS to log in
    into ECR and push the images of our project. In this case, we are going to use
    a very simple application in `Node.js`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Save the code from earlier in a file called `index.js` within a folder called
    `devops-test` on your local machine. As we are using express, we need to install
    the required dependency. Just execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'After a few questions (just press Enter a few times and it should work), a
    file called `package.json` should be created. Now we need to install express for
    our program to run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'And voila! Our `package.json` file should have a line describing the required
    dependency:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This file allows us to reinstall the dependencies whenever required without
    having to do it manually; it also allows us to specify a command that will be
    run when we execute `npm start` (a standard way of running a Node app using npm).
    Add the line and highlight it, as shown in the preceding code, as we will need
    it later (don't forget the semicolon from the previous line).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now we need to write our Dockerfile. A Dockerfile, as we will see in [Chapter
    3](fee45e6c-df39-48ae-ab43-a18911facbd8.xhtml), *Docker, *is a file that describes
    what our Docker image looks like. In this case, we are going to reconstruct the
    steps needed to run the node application in a Docker container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Don''t try to understand the file; we will go deeper into this later on this
    book. Just save it with the name `Dockerfile` in the folder mentioned previously,
    `devops-test`. By now, your `devops-test` folder should look like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7513e983-3dc5-4e88-8ae6-b2e3332d865f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we are ready to follow step 2 in the ECS setup. Be aware that the following
    image is regarding my user in AWS; your user will have different parameters, so
    use yours instead of copying from the preceding screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/17a7cc60-606f-4234-ba23-a2ad9ee811fd.png)'
  prefs: []
  type: TYPE_IMG
- en: Once you finish it, a new version of the image with your app image should be
    installed in your private ECR.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step (step 3) is creating what AWS calls a task definition, which
    is basically the configuration for one instance of our containers: how much memory
    we are going to use, which image we are going to run, and what ports we are going
    to expose in the container. Just leave the default memory but change the port
    to `3000`, as it is the port that we used in the preceding example (the node application).
    This is typical docker parameter and we will learn more about it in the next chapter,
    where we will dive deeper into docker.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you are ready, click on next and we will be with step 4\. This step is
    where we are going to configure a service. By service, we mean the number of instances
    of our container are we going to keep alive and how are we going to expose them:
    using a load balancer or just in the EC2 instances that are part of the cluster.
    We will also be able to specify which IAM (AWS credential system) is going to
    be used for registering and deregistering running instances:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f53dfe50-15ed-465d-913c-a4bd3193f608.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We just leave everything by default except two parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The desired number of tasks: set to `2`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the ELB section, we just select sample-app: `80` (or the option that isn''t
    No ELB so AWS provisions an ELB for us)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Click on the Next step, where we are going to define what our cluster is going
    to look like:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The number of nodes
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The size of the nodes
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Once we are ready, just review and launch the instance. After a few minutes,
    our cluster should be up and running and ready to work with our deployed task.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can access the instance of the task that we created in the load balancer
    provisioned by the cluster itself on the port `3000`. As you can see, ECS makes
    the task of setting up a container cluster simple.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we are going to give special attention to Kubernetes and Docker
    Swarm mainly because they are platform agnostic technologies, but I believe that
    Amazon ECS is a very valid technology to be considered when building a new container-based
    system.
  prefs: []
  type: TYPE_NORMAL
- en: Other services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you can see, the list of services in AWS is pretty much endless. We have
    visited the ones that I consider the most important, and in the following chapters,
    we will visit some of them that are also interesting, but unfortunately, we cannot
    go in deep through all of them. However, AWS is pretty good in terms of the documentation,
    and every service always comes with quite a comprehensive explanation on how to
    use it.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we are going to touch base with some services that, even though
    are quite important, are not core to the development of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Route 53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Route 53 is the DNS service in AWS. It is a global and scalable DNS service
    that allows you to perform some advanced operations:'
  prefs: []
  type: TYPE_NORMAL
- en: Register domain names
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transfer domain names from other registrars
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create traffic routing policies (such as failovers across regions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitor the availability of your applications (and reroute the traffic to healthy
    instances).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With Route 53, we can link domain names to AWS resources, such as load balancers,
    S3 buckets, and other resources, enabling us to expose a human-readable name for
    our resources (mainly VMs) created within our AWS instance.
  prefs: []
  type: TYPE_NORMAL
- en: CloudFront
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CloudFront solves one of the biggest problems that low traffic websites experience
    when a spike in visits happens: it provides a cache in a way that makes us wonder
    whether AWS is the one that serves the data and not our server. Basically, CloudFront
    intercepts the request to our host, renders the page, and keeps it for up to 24
    hours so our site offloads the traffic to AWS. It is designed for serving static
    content, as the second time that the user hits the same URL, the cached version
    will be served instead of hitting your server again.'
  prefs: []
  type: TYPE_NORMAL
- en: It is highly recommended that you use CloudFront for the brochure site of your
    company so that you can serve all the traffic with a very small machine, saving
    some money in resources but also being able to improve your uptime when a traffic
    spike hits your site.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon ElasticCache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon ElasticCache, as the name suggests, is a distributed and scalable in-memory
    cache system that can be used to store cached data within our applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'It solves one of the biggest problems that we can face when building an application
    that relies on a cache for storing and retrieving data: high availability and
    a consistent temporary datastore.'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon RDS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**RDS** stands for **Relational Database Service**. With RDS, you can provision
    DB instances with a few clicks that could be used to store data: Oracle, MySQL,
    and MariaDB are some of the options that we have for RDS. It leverages the high
    availability to the underlying DB system, which might be a problem if we are looking
    to rely on AWS for it, but it is usually acceptable as high availability in SQL
    databases is a complicated subject.'
  prefs: []
  type: TYPE_NORMAL
- en: DynamoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DynamoDB is a fine piece of engineering. It is a NoSQL database that is fine-tuned
    down to the millisecond of latency at any scale. It stores objects instead of
    rows (SQL cannot be used) and is a good candidate for storing a big amount of
    data in a schema-less fashion. DynamoDB, in essence, is very similar to MongoDB,
    but there is a basic difference: DynamoDB is a service provided by AWS and can
    run only within AWS, whereas MongoDB is a software that can be installed anywhere,
    including AWS. From the functional point of view, the majority of use cases for
    MongoDB are valid for modeling DynamoDB databases.'
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google has always been at the top of the hill when it comes to technology. Surprisingly,
    Google didn't have a federated layer of services; instead, it offered every service
    separately, which was far from ideal in providing a solid platform for developers
    to build applications on top of it. In order to solve that, they released Google
    Cloud Platform, which is a collection of services (infrastructure as a service,
    platform as a service, containers and big data, as well as many other features)
    that enables developers and companies to build highly reliable and scalable systems
    with some of the most up-to-date features, such as Kubernetes and a set of unique
    machine learning APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The interface is also one of the main points in Google Cloud: it offers you
    a web console where you basically have an available `ssh` Terminal that is connected
    to all your services, and you can operate from there without the need for any
    configuration on your local machine. Another good point in the interface is the
    fact that they use the terminology in the traditional sysadmin world, making the
    learning curve easy for the majority of the services.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/96e99619-c350-4e5f-8124-7c271c72cfd3.png)'
  prefs: []
  type: TYPE_IMG
- en: In the same way as AWS, Google Cloud Platform allows engineers to create resources
    across the globe in regions and zones in order to ensure the high availability
    of our systems as well as the compliance with local laws.
  prefs: []
  type: TYPE_NORMAL
- en: 'But the real jewel in the crown is their container engine. I am a big fan of
    container orchestration. Nowadays, everyone is gravitating toward microservices-based
    systems, and it is not strange to see companies hitting the wall of the operational
    reality of a microservices-based system: this is impossible to manage without
    orchestration tools. From all the potential choices on the market (Amazon ECS,
    Docker Swarm, and DCOS), there is one in particular that has been a game changer
    in my life: Kubernetes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes is the answer to the question that I raised during the writing of
    my first book (*Developling Microservices with Node.js*): how can we efficiently
    automate the operations in a microservices environment by providing a common ground
    between development and operations? Kubernetes has incorporated all the expertise
    from working with containers that Google has accumulated through the years in
    order to create a product that provides all the necessary components for the efficient
    management of deployment pipelines.'
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we are going to place a special emphasis on Kubernetes, as in
    my opinion, it is the solution to many of the problems that teams have today when
    scaling up in members and resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to start working with GCP, Google offers a trial version of 300 USD
    credit or 60 days free of charge test, which is more than enough to get your head
    around the majority of the services and, of course, more than enough to follow
    the examples of this book and play around with the majority of the concepts that
    we are going to be exposing. I would recommend that you activate your trial period
    and start playing around: once the credit is used or the 60 days are over, Google
    requires explicit confirmation to activate the billing so there is not going to
    be any extra charge in your account (this is the case at the time of writing this).'
  prefs: []
  type: TYPE_NORMAL
- en: Google Compute Engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Google Compute Engine is the equivalent of EC2 in Amazon Web Services. It allows
    you to manage instances of machines, networks, and storage with a simplicity that
    I have never seen before. One of the downsides that I found when ramping up with
    AWS is the fact that they have created abstractions with names that are not very
    intuitive: Virtual Private Cloud, Elastic Block Storage, and many more. This is
    not a big deal as AWS is well known in the market, but Google got the message
    and has named its resources in a very intuitive way, facilitating the onboarding
    of new people into the platform with little to no effort.'
  prefs: []
  type: TYPE_NORMAL
- en: Regarding the machine types, Google Cloud Platform provides a simplified and
    limited set of machines when compared to AWS but enough variety to satisfy our
    needs. One of the features to keep in mind with Google Cloud Platform is the fact
    that the hardware improves with the size of the instance, which means that the
    64 cores machines get a better CPU than the two core machines.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Platform also provides a CLI tool to interact with the resources
    in GCP from a Terminal. In order to install it, just access this URL: [https://cloud.google.com/sdk/](https://cloud.google.com/sdk/).
  prefs: []
  type: TYPE_NORMAL
- en: Then, follow the instructions depending on your operating system.
  prefs: []
  type: TYPE_NORMAL
- en: Standard machine types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The standard machines are the most common to be used by any application. They
    offer a balance between CPU and memory that suits the majority of the tasks in
    all the projects that you can possibly imagine. These types of machines offer
    3.75 GB of RAM for every single virtual CPU. Let''s look at a few examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | CPUs | Memory |'
  prefs: []
  type: TYPE_TB
- en: '| `n1-standard-1` | 1 | 3.75 GB |'
  prefs: []
  type: TYPE_TB
- en: '| `n1-standard-2` | 2 | 7.50 GB |'
  prefs: []
  type: TYPE_TB
- en: '| `n1-standard-64` | 64 | 240 GB |'
  prefs: []
  type: TYPE_TB
- en: As you can see, the naming convention is fairly straightforward and is easy
    in order to guess the machine RAM and the number of CPUs out of the canonical
    name.
  prefs: []
  type: TYPE_NORMAL
- en: High-memory machine types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These machines are optimized for memory-intensive applications. They come with
    an extra amount of RAM for every virtual CPU that allows you to go the extra mile
    regarding memory power.
  prefs: []
  type: TYPE_NORMAL
- en: 'Every machine of the high-memory type comes with 6.5 GB of RAM for every single
    virtual CPU, and here are a few examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | CPUs | Memory |'
  prefs: []
  type: TYPE_TB
- en: '| `n1-highmem-2` | 2 | 13 |'
  prefs: []
  type: TYPE_TB
- en: '| `n1-highmem-8` | 8 | 52 |'
  prefs: []
  type: TYPE_TB
- en: '| `n1-highmem-64` | 64 | 416 |'
  prefs: []
  type: TYPE_TB
- en: These machines come with a massive amount of RAM and are well suited for distributed
    caches, databases, and many other types of applications that require a high memory
    consumption relative to the CPU power.
  prefs: []
  type: TYPE_NORMAL
- en: High-CPU machine types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As the name states, high-CPU machines are instances that hold a high CPU/memory
    ratio with only 0.9 GB of RAM for every virtual CPU, which indicates that they
    are well suited for saving some money on high-intensive CPU tasks (as we cut down
    on a lot of memory). Here are some examples of these machines:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | CPUs | Memory |'
  prefs: []
  type: TYPE_TB
- en: '| `n1-highcpu-2` | 2 | 1.8 GB |'
  prefs: []
  type: TYPE_TB
- en: '| `n1-highcpu-8` | 8 | 7.2 GB |'
  prefs: []
  type: TYPE_TB
- en: '| `n1-highcpu-64` | 64 | 57.6 GB |'
  prefs: []
  type: TYPE_TB
- en: As you can see, the only difference between the standard or high memory machines
    is that these machines are built with less amount of RAM, which allows us to save
    money on a resource that won't be used in some applications that are able to create
    machines with more CPUs at the same price. High-CPU machines are well suited for
    applications that require high CPU and low memory consumption, such as mathematical
    processing or other types of calculations.
  prefs: []
  type: TYPE_NORMAL
- en: Shared-core machine types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Sometimes, we really don''t need a dedicated machine for our process, so Google
    Cloud offers shared machines that you can use for it. In my opinion, the shared-core
    machines are not suited for production usage, but they could well serve a prototype
    or experimenting with different resources. Here are the two types of machines:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | CPUs | Memory |'
  prefs: []
  type: TYPE_TB
- en: '| `f1-micro` | 0.2 | 0.6 |'
  prefs: []
  type: TYPE_TB
- en: '| `g1-small` | 0.5 | 1.7 |'
  prefs: []
  type: TYPE_TB
- en: As you can see, there are only two options with different RAM and CPU power.
    I personally use these machines when I want to experiment with new software or
    new products of the Google Cloud Platform.
  prefs: []
  type: TYPE_NORMAL
- en: Don't forget that these are bursting machines that are only suited for short
    burst of intensive processing and not for sustained resource consumption as the
    CPU is shared across different applications.
  prefs: []
  type: TYPE_NORMAL
- en: Custom machines and GPU processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Sometimes, we need an extra amount of something on our machines, which is usually
    not in the predefined machine instances of other providers, but in this case,
    Google Cloud Platform comes to the rescue with an amazing feature: custom machine
    types.'
  prefs: []
  type: TYPE_NORMAL
- en: With custom machine types in Google Cloud Platform, we can get the benefit of
    the upgraded hardware of the large machines in a resource-modest machine or create
    specific configurations that suit our needs.
  prefs: []
  type: TYPE_NORMAL
- en: One of the best examples that we can find for custom machines is when we want
    to add some GPU processing to our mix. In Google Cloud, GPUs can be attached to
    any non-shared (`f1` or `g1`) machine on demand. With the ability to create our
    custom machine types, we can define how many GPUs we want to burst our processing
    power in.
  prefs: []
  type: TYPE_NORMAL
- en: In general, when I design a system, I try to stick to the standard types as
    much as possible in order to simplify my setup, but there is nothing wrong in
    creating custom machine types aside from the fact that we can easily fall in the
    premature optimization of our system, which is probably one of the biggest problems
    that you can find when working in IT.
  prefs: []
  type: TYPE_NORMAL
- en: Launching an instance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In Google Cloud Platform, everything is grouped in projects. In order to create
    resources, you need to associate them with projects, so the first step to launch
    an instance is to create a project. In order to do that, just select the new project
    button when entering the Google Cloud Platform interface the first time or in
    the drop-down in the top bar when you have already created one project:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the examples of this book, I am going to create a project called `Implementing
    Modern DevOps`, which I will to be using for running all the examples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2f4f4f93-736a-4c28-a06a-19f235a856f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once we have created our project, we proceed to create a new VM instance. Even
    though it is possible to create instances with more than 64 cores (with the custom
    machine types), we are going to stick to the standard ones in order to save costs.
    Proceed to create the instance with the default values (just change the name):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a83924d5-9f59-48a8-952c-f518bad5103e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are two details that I really like from Google Cloud Platform:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How easy they name their resources and make everything clear to understand
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: How transparent they are with the pricing
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While creating a virtual machine in Google Cloud Platform, these two characteristics
    are present: the form to create a machine has only a   few fields, and it gives
    you the cost of the machine per month (so there are no surprises).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the same way as AWS, Google Cloud Platform allows you to select the region
    and the zone (remember, a physically separated data center) where your instance
    is going to live in order to ensure the high availability of the overall system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Also, this (not in the preceding figure) allows you a couple of clicks in two
    checkboxes in order to allow the `http` and `https` traffic into the instance
    from the outer world. This is just as simple and effective.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can also configure other things, such as networking, ssh keys, and other
    parameters that we are going to skip for now. Just click on the Create button
    (at the bottom of the form) and wait until the machine is fully provisioned (it
    might take up to few minutes), and you should see something similar to what is
    shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/65df0081-936b-4bb2-9f9d-257c56928f01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'One of the most appealing features of Google Cloud Platform is how curated
    their usability is. In this case, you can see a column in your machine description
    called Connect that allows you to connect to the machine in a few different ways:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: SSH
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The `gcloud` command (a command-line tool from GCP)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Using another ssh client
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We are going to select SSH (the default one) and click on the SSH button. A
    popup should appear on the screen, and after a few seconds, we should see something
    similar to an `ssh` Terminal, which is a Terminal in our machine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7b23439c-d51b-45b2-a0fe-b55db8b59341.png)'
  prefs: []
  type: TYPE_IMG
- en: This is a very neat and useful feature that basically enables the engineer to
    avoid carrying a set of cryptographic keys that are always a risk as if they get
    leaked, your machines are exposed.
  prefs: []
  type: TYPE_NORMAL
- en: Networking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One thing I cannot stress enough about the Google Cloud Platform is how it
    simplifies the concepts and make them look similar to the real-world physical
    data center concepts. The case of the networking was not an exception: all the
    concepts and names can be mapped one to one to real world physical network concepts.'
  prefs: []
  type: TYPE_NORMAL
- en: In Google Cloud, we can implement any required design that follows the principles
    of the IP networking (the same as AWS) with pretty much a few clicks. Another
    interesting feature that Google Cloud offers (along with other providers such
    as AWS) is the possibility of extending your data center into the cloud with a
    VPN network taking the benefits of the cloud products but achieving the level
    of security required by the most sensitive data that you could imagine.
  prefs: []
  type: TYPE_NORMAL
- en: Google Container Engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Google Container Engine** (**GKE**) is a proposal from Google for the
    container orchestration making use of one of the most powerful container clusters
    available in the market: Kubernetes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we will discuss further in [Chapter 7](4e6a965e-c4bf-491d-9f60-c013269350c9.xhtml),
    *Docker Swarm and Kubernetes- Clustering Infrastructure, *Kubernetes is a feature-full
    cluster used for deploying and scaling container-based applications in a controlled
    manner, with a special emphasis on defining the common language between development
    and operations: a framework that blends development and operation concepts into
    a common ground: a YAML (or JSON) description of resources.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the big problems of Kubernetes is ensuring high availability. When you
    deploy a cluster on premises or in a cloud provider, making use of the computing
    power (EC2 in AWS or Compute Engine in GCP), you are responsible for upgrading
    the cluster version and evolving it with the new releases of Kubernetes. In this
    case, Google Cloud Platform, through the container engine, has solved the operational
    problem: GCP keeps the master and is responsible for keeping it up to date and
    the users upgrade the nodes when a new version of Kubernetes is released, which
    allows us to articulate different procedures for upgrading our cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 7](4e6a965e-c4bf-491d-9f60-c013269350c9.xhtml), *Docker Swarm and
    Kubernetes- Clustering Infrastructure, *you are going to learn how to operate
    Kubernetes, but it is worth teaching you how to set up a cluster in the GKE in
    this chapter in order to show how easy it is before diving deep into the core
    concepts of Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, go to Container Engine within Google Cloud Platform:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f77b6e67-5289-48f8-b288-2586a052b9e0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, there are no clusters set up, so we have two options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new container cluster
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Take the quickstart
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We are just going to click on Create a container cluster and follow up the
    onscreen instructions (a form) in order to set up our cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/075bff92-ef20-4785-9c1c-41191c88b23a.png)'
  prefs: []
  type: TYPE_IMG
- en: Ensure that Zone is the closest to your geographical area (even though right
    now it doesn't really matter) and the size is `3`. This parameter, the size, is
    going to ask GCP to create `3` instances in the Compute Engine in order to set
    up the cluster plus a master that is managed by GCP itself. Regarding the image,
    we have two options here, `gci` or `container-vm`. In this case, again, it doesn't
    really matter as it is just a test cluster, but just note that if you want to
    use NFS or any other advanced filesystem, you will need to use `container-vm.`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on Create, and after few minutes, you should see two things:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The cluster is created in the Google Container Engine section
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Three new VMs are provisioned in the Compute Engine section
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This is a very smart setup because with some commands using the google cloud
    platform command tool (`gcloud`), we can scale up or down or cluster as well as
    change the size of our instances in order to satisfy our needs. If you explore
    the cluster (by clicking on its name), you will find a Connect to the clusterlink,
    which leads to a screen with instructions to connect to the Kubernetes dashboard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0843b6c9-0cb4-4b10-9a88-08aadb91deb2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Sometimes, these instructions fail, and that is because `gcloud` is badly configured.
    If you find an error trying to configure the access to the cluster, run the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Then, follow the instructions. Assuming that you have already configured the
    Google Cloud SDK, everything should work fine, and after running the `kubectl
    proxy` command, you should be able to access the Kubernetes dashboard at `http://localhost:8001/ui`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In order to test whether everything works as expected, just run a simple image
    in Kubernetes (in this case, a `busybox` image):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If we refresh the dashboard (`http://localhost:8001/ui`) while running the
    Kubernetes proxy (as specified earlier), we should see something similar to what
    is shown in the following figure in the Deployments section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/86e9d64a-da62-4f42-95c6-3203f82a6ef3.png)'
  prefs: []
  type: TYPE_IMG
- en: This indicates that the deployment (a Kubernetes concept that we will explore
    in [Chapter 7](4e6a965e-c4bf-491d-9f60-c013269350c9.xhtml), *Docker Swarm and
    Kubernetes- Clustering Infrastructure*) was successful.
  prefs: []
  type: TYPE_NORMAL
- en: Other Google Cloud Platform products
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google Cloud platform is not only Compute Engine and Container Engine, but it
    is also a collection of services that are very interesting for different purposes.
    As things are limited in scope, we won't see the majority of them and will only
    focus on the ones that are more relevant to the DevOps world.
  prefs: []
  type: TYPE_NORMAL
- en: Google App Engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Up until now, we have been working with a side of DevOps called **IaaS**. Google
    Cloud platform also offers something called **Platform as a Service** (**PaaS**).
    In an IaaS model, we need not worry about the underlying infrastructure: provisioning
    machines, installing the software, patching the software. With **Google App Engine**
    (or any other major PaaS), we forget about the ops of our infrastructure and focus
    on the development of our application, leveraging the underlying infrastructure
    to Google. Instead of launching a machine and installing Java to run our Spring
    Boot-based application, we just specify that we want to run a Java application,
    and GCP takes care of everything else.'
  prefs: []
  type: TYPE_NORMAL
- en: This product, the Google App Engine, fits the necessity of the majority of the
    small to mid sized projects, but in this book, we are going to focus on the DevOps
    that maintaining an IaaS involves.
  prefs: []
  type: TYPE_NORMAL
- en: Google App Engine also provides us with features such as user management, which
    is a recurring problem in all the applications.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google has always been famous for its innovation across the technology products
    that it has released. It has changed how people use e-mail with Gmail and how
    people use phones with Android.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding **Machine Learning**, they are also shaking up the world with an innovative
    set of APIs that people can use to process images (with the vision APIs), translate
    documents (with the translations API), and analyze large amounts of text with
    the natural language API.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most amazing uses that I have seen of the vision API is a company
    that had to do some level of photo ID verification for its customers. There was
    a huge problem of people uploading invalid images (random images or even images
    with part of the face covered or similar), so we used the vision API to recognize
    images that contained a face without facial hair, hat, or any other accessories
    aside from glasses.
  prefs: []
  type: TYPE_NORMAL
- en: The result was that the people doing the ID verification focused just on valid
    images instead of having to classify them as valid or invalid before proceeding
    to the verification.
  prefs: []
  type: TYPE_NORMAL
- en: Big data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Big data is now a big thing. Everybody is trying to take the advantage of big
    data to explore new areas of business or unleash their potential in traditional
    businesses.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Platform offers a set of big data APIs that enable the users to
    carry on pretty much any task in large sets of data. With tools such as BigQuery,
    a data analyst can run queries on terabytes of information in seconds without
    setting up a massive scale infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, the big data APIs from Google are what is called no-ops tools in
    the DevOps world: they don''t require maintenance from users as they leverage
    it into Google. This means that if a big query requires a lot of processing power,
    Google is the one responsible for transparently offering this power to the user.'
  prefs: []
  type: TYPE_NORMAL
- en: Other cloud providers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unfortunately, there is a limit to the number of concepts we can develop in
    a book, and in this case, we are going to focus on AWS and GCP, as they are the
    most feature-full cloud providers in the market.
  prefs: []
  type: TYPE_NORMAL
- en: 'I always try to adopt an open mindset regarding technology, and there are three
    providers that I think you should know about:'
  prefs: []
  type: TYPE_NORMAL
- en: DigitalOcean
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heroku
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They have a lot to offer and they all are up to speed with the new trends of
    DevOps and security.
  prefs: []
  type: TYPE_NORMAL
- en: Heroku
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Heroku''s battle horse is this phrase: build apps, not infrastructure. That
    is a powerful message. Basically, Heroku is going full throttle with the **PaaS**
    concept **Platform as a Service**, allowing you to avoid maintaining the underlying
    infrastructure: just specify what you want to run (for example, a Node.js application)
    and the scale.'
  prefs: []
  type: TYPE_NORMAL
- en: With this powerful philosophy, Heroku allows you to easily deploy instances
    of your application, databases, or communication buses, such as Kafka, with a
    few clicks and without all the hassle of having to provision them with a DevOps
    tool, such as Ansible, Chef, or similar.
  prefs: []
  type: TYPE_NORMAL
- en: Heroku is one of the cloud providers preferred by start-ups as you can save
    a lot of time as opposed to using AWS or Google Cloud Platform, as you just need
    to focus on your applications, not the infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: DigitalOcean
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DigitalOcean is a provider that, even though not as well-known as AWS or GCP,
    offers a very interesting alternative to small to mid sized organizations to run
    their cloud systems. They have developed a very powerful concept: the droplet.'
  prefs: []
  type: TYPE_NORMAL
- en: Basically, a droplet is a component that can run your software and be connected
    to different networks (private or public) through some configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to assemble a droplet, we just need to define a few things:'
  prefs: []
  type: TYPE_NORMAL
- en: The image (the operating system or one-click images)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The region
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And once you have chosen your configuration, the droplet starts running. This
    is very simple and effective, which is usually what companies look for.
  prefs: []
  type: TYPE_NORMAL
- en: Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Azure is the Microsoft push for cloud systems and one of the providers that
    has grown the most in the last couple of years. As expected, Azure is a ;particularly
    good platform for running Windows-based applications, but that's not to say we
    can overlook its capability of running Linux applications as well.
  prefs: []
  type: TYPE_NORMAL
- en: The catalog of products is as complete as the catalog for AWS or Google Cloud
    Platform, and there is absolutely no reason not to choose Azure as a cloud provider
    for your systems.
  prefs: []
  type: TYPE_NORMAL
- en: Azure is also one of the newest providers (it became widely available in 2013)
    in the market, so it has the advantage of being able to solve problems that other
    providers have presented.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until now, we showcased the features of AWS and GCP and introduced some other
    providers that are very interesting choices when building our systems. One of
    the advantages of having a good number of competitors in the market is the fact
    that each one of them has their own strong points and we can combine them by making
    use of VPNs, creating a big and extended virtual data center across different
    providers.
  prefs: []
  type: TYPE_NORMAL
- en: Through the rest of the book, we are going to give special attention to AWS
    and GCP, as they have the most interesting characteristics for a DevOps book (not
    to overlook the rest of them, but remember, things are limited in terms of space).
  prefs: []
  type: TYPE_NORMAL
- en: We are also going to take a special interest in container clusters such as Kubernetes
    or Docker Swarm as they are, without any kind of doubt, the future.
  prefs: []
  type: TYPE_NORMAL
