- en: '*Chapter 4*: Scaling and Deploying Your Application'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第4章*：扩展和部署您的应用程序'
- en: In this chapter, we will learn about the higher-level Kubernetes resources that
    are used to run applications and control Pods. First, we'll cover the drawbacks
    of the Pod, before moving on to the simplest Pod controller, ReplicaSets. From
    there we will move on to Deployments, the most popular method for deploying applications
    to Kubernetes. Then we'll cover special resources to help you deploy specific
    types of applications – Horizontal Pod Autoscalers, DaemonSets, StatefulSets,
    and Jobs. Finally, we'll put it all together with a full example of how to run
    a complex application on Kubernetes.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将学习用于运行应用程序和控制 Pods 的高级 Kubernetes 资源。首先，我们将讨论 Pod 的缺点，然后介绍最简单的 Pod 控制器
    —— ReplicaSets。接下来，我们将介绍 Deployments，这是最流行的 Kubernetes 应用程序部署方法。然后，我们将介绍一些特殊资源，帮助您部署特定类型的应用程序
    —— 水平 Pod 自动扩展器、DaemonSets、StatefulSets 和 Jobs。最后，我们将通过一个完整的示例展示如何在 Kubernetes
    上运行一个复杂的应用程序。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding Pod drawbacks and their solutions
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 Pod 的缺点及其解决方案
- en: Using ReplicaSets
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 ReplicaSets
- en: Controlling Deployments
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制 Deployments
- en: Harnessing the Horizontal Pod Autoscaler
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用水平 Pod 自动扩展器
- en: Implementing DaemonSets
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现 DaemonSets
- en: Reviewing StatefulSets and Jobs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审查 StatefulSets 和 Jobs
- en: Putting it all together
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 综合应用
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In order to run the commands detailed in this chapter, you will need a computer
    that supports the `kubectl` command-line tool along with a working Kubernetes
    cluster. See [*Chapter 1*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016), *Communicating
    with Kubernetes*, for several methods to get up and running with Kubernetes quickly,
    and for instructions on how to install the `kubectl` tool.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行本章详细介绍的命令，您需要一台支持 `kubectl` 命令行工具的计算机，以及一个可工作的 Kubernetes 集群。请参阅[*第1章*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016)，*与
    Kubernetes 通信*，了解几种快速启动 Kubernetes 的方法，以及如何安装 `kubectl` 工具的说明。
- en: The code used in this chapter can be found in the book's GitHub repository at
    [https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter4](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter4).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的代码可以在本书的 GitHub 仓库中找到，地址是 [https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter4](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter4)。
- en: Understanding Pod drawbacks and their solutions
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 Pod 的缺点及其解决方案
- en: As we reviewed in the previous chapter, [*Chapter 3*](B14790_03_Final_PG_ePub.xhtml#_idTextAnchor091),
    *Running Application Containers on Kubernetes*, a Pod in Kubernetes is an instance
    of one or more application containers that run on a node. Creating just one Pod
    is enough to run an application the same way you would in any other container.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一章[*第3章*](B14790_03_Final_PG_ePub.xhtml#_idTextAnchor091)，*在 Kubernetes
    上运行应用程序容器*中回顾的那样，Kubernetes 中的 Pod 是在一个节点上运行的一个或多个应用容器的实例。创建一个 Pod 就足够了，这与在任何其他容器中运行应用程序的方式是一样的。
- en: That being said, using a single Pod to run an application ignores many of the
    benefits of running containers in the first place. Containers allow us to treat
    each instance of our application as a stateless item that can be scaled up or
    down to meet demand by spinning up new instances of the application.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，使用单个 Pod 来运行应用程序忽视了运行容器本身的许多优势。容器允许我们将应用程序的每个实例视为一个无状态的项目，可以通过启动新的应用实例来根据需求扩展或缩减。
- en: This has the benefits of both allowing us to scale our application easily and
    making our application more available by providing multiple instances of our application
    at a given time. If one of our instances crashes, the application will still continue
    to function, and will automatically scale to pre-crash levels. The way we do this
    on Kubernetes is by using a Pod controller resource.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这既能让我们轻松地扩展应用程序，又能通过在特定时间提供多个应用实例，使应用程序更加可用。如果其中一个实例崩溃，应用程序仍然会继续运行，并会自动扩展到崩溃前的状态。在
    Kubernetes 中，我们通过使用 Pod 控制器资源来实现这一点。
- en: Pod controllers
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pod 控制器
- en: Kubernetes provides several choices for Pod controllers out of the box. The
    simplest option is to use a ReplicaSet, which maintains a given number of Pod
    instances for a particular Pod. If one instance fails, the ReplicaSet will spin
    up a new instance to replace it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 提供了多种现成的 Pod 控制器选择。最简单的选择是使用 ReplicaSet，它为特定的 Pod 保持一定数量的 Pod 实例。如果某个实例失败，ReplicaSet
    会启动一个新的实例来替代它。
- en: Secondly, there are Deployments, which themselves control a ReplicaSet. Deployments
    are the most popular controller when it comes to running an application on Kubernetes,
    and they make it easy to upgrade applications using a rolling update across a
    ReplicaSet.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，Deployments 本身控制一个 ReplicaSet。Deployments 是 Kubernetes 中运行应用程序时最常见的控制器，它们使得通过对
    ReplicaSet 进行滚动更新轻松升级应用程序。
- en: Horizontal Pod Autoscalers take Deployments to the next level by allowing applications
    to autoscale to different numbers of instances based on performance metrics.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Horizontal Pod Autoscalers 通过允许应用程序根据性能指标自动扩展到不同数量的实例，将 Deployments 提升到一个新水平。
- en: 'Finally, there are a few specialty controllers that may be valuable in certain
    situations:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，存在一些特殊的控制器，在某些情况下可能非常有价值：
- en: DaemonSets, which run an instance of the application on each node and maintain
    them
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DaemonSets，运行应用程序的一个实例在每个节点上，并维护它们
- en: StatefulSets, where the Pod identity is kept static to assist in running stateful
    workloads
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: StatefulSets，用于保持 Pod 的身份静态，以帮助运行有状态的工作负载
- en: Jobs, which start, run to completion, and then shut down on a specified number
    of Pods
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jobs，启动后运行直到完成，然后在指定数量的 Pods 上关闭
- en: 'The actual behavior of a controller, be it a default Kubernetes controller
    like a ReplicaSet or a custom controller (for instance, the PostgreSQL Operator),
    should be easy to predict. A simplified view of the standard control loop looks
    something like the following diagram:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是像 ReplicaSet 这样的默认 Kubernetes 控制器，还是自定义控制器（例如，PostgreSQL Operator），控制器的实际行为应该是容易预测的。标准控制循环的简化视图大致如下图所示：
- en: '![Figure 4.1 – A basic control loop for a Kubernetes controller](img/B14790_04_001.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 – Kubernetes 控制器的基本控制循环](img/B14790_04_001.jpg)'
- en: Figure 4.1 – A basic control loop for a Kubernetes controller
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – Kubernetes 控制器的基本控制循环
- en: As you can see, the controller constantly checks the **Intended cluster state**
    (we want seven Pods of this app) against the **Current cluster state** (we have
    five Pods of this app running). When the intended state does not match the current
    state, the controller will take action via the API to correct the current state
    to match the intended state.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，控制器不断地检查**预期集群状态**（我们希望有七个此应用的 Pod）与**当前集群状态**（我们现在有五个此应用的 Pod 正在运行）之间的差异。当预期状态与当前状态不符时，控制器会通过
    API 采取行动，将当前状态修正为与预期状态一致。
- en: 'By now, you should understand why controllers are necessary on Kubernetes:
    the Pod itself is not a powerful enough primitive when it comes to delivering
    highly available applications. Let''s move on to the simplest such controller:
    the ReplicaSet.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该明白为什么在 Kubernetes 中控制器是必要的：单独的 Pod 并不是一个足够强大的基本元素，无法提供高度可用的应用程序。接下来我们将讨论最简单的这种控制器：ReplicaSet。
- en: Using ReplicaSets
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 ReplicaSets
- en: ReplicaSets are the simplest Kubernetes Pod controller resource. They replace
    the older ReplicationController resource.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet 是最简单的 Kubernetes Pod 控制器资源。它们替代了较旧的 ReplicationController 资源。
- en: The major difference between a ReplicaSet and a ReplicationController is that
    a ReplicationController uses a more basic type of *selector* – the filter that
    determines which Pods should be controlled.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet 和 ReplicationController 之间的主要区别在于，ReplicationController 使用一种更基础的*选择器*—决定哪些
    Pods 应该被控制的过滤器。
- en: While ReplicationControllers use simple equity-based (*key=value*) selectors,
    ReplicaSets use a selector with multiple possible formats, such as `matchLabels`
    and `matchExpressions`, which will be reviewed in this chapter.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 ReplicationController 使用基于简单等式的（*key=value*）选择器，ReplicaSet 使用具有多种可能格式的选择器，如
    `matchLabels` 和 `matchExpressions`，本章将讨论这些格式。
- en: Important note
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: There shouldn't be any reason to use a ReplicationController over a ReplicaSet
    – just stick with ReplicaSets unless you have a really good reason not to.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你有充分的理由，否则没有必要使用 ReplicationController，直接使用 ReplicaSet 即可。
- en: ReplicaSets allow us to inform Kubernetes to maintain a certain number of Pods
    for a particular Pod spec. The YAML for a ReplicaSet is very similar to that for
    a Pod. In fact, the entire Pod spec is nested in the ReplicaSet YAML, under the
    `template` key.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet 允许我们告知 Kubernetes 维护一个特定 Pod 规格的特定数量的 Pods。ReplicaSet 的 YAML 配置与
    Pod 的 YAML 非常相似。实际上，整个 Pod 规格嵌套在 ReplicaSet YAML 的 `template` 键下。
- en: 'There are also a few other key differences, which can be observed in the following
    code block:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他关键的区别，可以通过以下代码块观察到：
- en: replica-set.yaml
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: replica-set.yaml
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see, in addition to the `template` section, which is essentially
    a Pod definition, we have a `selector` key and a `replicas` key in our ReplicaSet
    spec. Let's start with `replicas`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，除了`template`部分（本质上是Pod定义）之外，我们的ReplicaSet spec中还有`selector`键和`replicas`键。让我们从`replicas`开始。
- en: Replicas
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 副本
- en: The `replicas` key specifies a replica count, which our ReplicaSet will ensure
    is always running at a given time. If a Pod dies or stops working, our ReplicaSet
    will create a new Pod to take its place. This makes the ReplicaSet a self-healing
    resource.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`replicas`键指定副本数，ReplicaSet将确保在任何给定时间都有正确数量的副本在运行。如果一个Pod崩溃或停止工作，ReplicaSet会创建一个新的Pod来替代它。这使得ReplicaSet成为一个自愈资源。'
- en: How does a ReplicaSet controller decide when a Pod stops working? It looks at
    the Pod's status. If the Pod's current status isn't "*Running*" or "*ContainerCreating*",
    the ReplicaSet will attempt to start a new Pod.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet控制器如何判断一个Pod何时停止工作？它会查看Pod的状态。如果Pod的当前状态不是“*Running*”或“*ContainerCreating*”，ReplicaSet将尝试启动一个新的Pod。
- en: As we discussed in [*Chapter 3*](B14790_03_Final_PG_ePub.xhtml#_idTextAnchor091),
    *Running Application Containers on Kubernetes*, the Pod's status after container
    creation is driven by the liveness, readiness, and startup probes, which can be
    configured specifically for a Pod. This means that you can set up application-specific
    ways to know whether a Pod is broken in some way, and your ReplicaSet can jump
    in and start a new one in its place.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[*第3章*](B14790_03_Final_PG_ePub.xhtml#_idTextAnchor091)中讨论的，*在Kubernetes上运行应用程序容器*，Pod在容器创建后的状态由活性、就绪性和启动探针控制，这些探针可以专门为Pod配置。这意味着你可以设置特定于应用程序的方式来判断Pod是否出现故障，而你的ReplicaSet可以介入并启动一个新的Pod替代它。
- en: Selector
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择器
- en: The `selector` key is important because of the way a ReplicaSet works – it is
    a controller that is implemented with the selector at its core. The ReplicaSet's
    job is to ensure that the number of running Pods that match its selector is correct.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`selector`键非常重要，因为ReplicaSet的工作方式依赖于它——它是一个核心实现为selector的控制器。ReplicaSet的任务是确保与其selector匹配的正在运行的Pod数量正确。'
- en: Let's say, for instance, that you have an existing Pod running your application,
    `MyApp`. This Pod is labeled with a `selector` key as `App=MyApp`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 假设，举个例子，你有一个正在运行你的应用程序`MyApp`的Pod。这个Pod使用`selector`键标记为`App=MyApp`。
- en: Now let's say you want to create a ReplicaSet with the same app, which will
    add an additional three instances of your application. You create a ReplicaSet
    with the same selector, and specify three replicas, with the intent of running
    four instances in total, since you already have one running.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设你想创建一个ReplicaSet来添加额外的三个实例，以扩展你现有的应用程序。你创建一个具有相同selector的ReplicaSet，并指定三个副本，计划总共运行四个实例，因为你已经有一个在运行。
- en: What will happen once you start the ReplicaSet? You'll find that the total number
    of Pods running that application will be three, not four. This is because a ReplicaSet
    has the ability to adopt orphaned Pods and bring them under its reign.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你启动ReplicaSet，会发生什么？你会发现运行该应用程序的Pod总数是三个，而不是四个。这是因为ReplicaSet具有接管孤立Pod并将其纳入控制的能力。
- en: When the ReplicaSet starts up, it sees that there is already an existing Pod
    matching its `selector` key. Depending on the number of replicas required, a ReplicaSet
    will shut down existing Pods or start new Pods that match the `selector` in order
    to create the correct number.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当ReplicaSet启动时，它会发现已经存在一个与其`selector`键匹配的Pod。根据需要的副本数量，ReplicaSet将关闭现有的Pod或启动新的与`selector`匹配的Pod，以确保正确的副本数。
- en: Template
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模板
- en: The `template` section contains the Pod and supports all the same fields as
    Pod YAMLs do, including the metadata section and the spec itself. Most other controllers
    follow this pattern – they allow you to define the Pod spec within the larger
    overall controller YAML.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`template`部分包含Pod，并支持与Pod YAML一样的所有字段，包括metadata部分和spec本身。大多数其他控制器遵循这种模式——它们允许你在更大的控制器YAML中定义Pod
    spec。'
- en: You should now understand the various parts of the ReplicaSet spec and what
    they do. Let's move on to actually running applications using our ReplicaSet.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该理解了ReplicaSet spec的各个部分及其作用。接下来，我们将实际使用我们的ReplicaSet来运行应用程序。
- en: Testing a ReplicaSet
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试ReplicaSet
- en: Now, let's deploy our ReplicaSet.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们部署我们的ReplicaSet。
- en: 'Copy the `replica-set.yaml` file listed previously and run it on your cluster
    using the following command in the same folder as your YAML file:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 复制之前列出的`replica-set.yaml`文件，并使用以下命令在与YAML文件相同的文件夹中运行它：
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To check that the ReplicaSet has been created properly, run `kubectl get pods`
    to fetch the Pods in the default namespace.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查 ReplicaSet 是否已正确创建，请运行 `kubectl get pods` 命令以获取默认命名空间中的 Pods。
- en: 'Since we haven''t specified a namespace for our ReplicaSet, it will be created
    by default. The `kubectl get pods` command should give you the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有为 ReplicaSet 指定命名空间，它将默认创建。`kubectl get pods` 命令应该返回如下内容：
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, try deleting one of the ReplicaSet Pods by using the following command:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，尝试使用以下命令删除一个 ReplicaSet 的 Pod：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: A ReplicaSet will always try to keep the specified number of replicas online.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet 总是会尝试保持指定数量的副本在线。
- en: 'Let''s use our `kubectl get` command to see our running pods again:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次使用 `kubectl get` 命令查看正在运行的 pods：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As you can see, our ReplicaSet controller is starting a new pod to keep our
    number of replicas at three.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们的 ReplicaSet 控制器正在启动一个新的 Pod，以保持副本数为三个。
- en: 'Finally, let''s delete our ReplicaSet using the following command:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们使用以下命令删除我们的 ReplicaSet：
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With our cluster a bit cleaner, let's move on to a more complex controller –
    Deployments.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在清理过集群后，我们来继续了解更复杂的控制器——Deployments。
- en: Controlling Deployments
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制 Deployments
- en: Though ReplicaSets contain much of the functionality you would want to run a
    high availability application, most of the time you will want to use Deployments
    to run applications on Kubernetes.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 ReplicaSet 包含了运行高可用性应用所需的大部分功能，但大多数情况下，你会想要使用 Deployments 来在 Kubernetes 上运行应用。
- en: Deployments have a few advantages over ReplicaSets, and they actually work by
    owning and controlling a ReplicaSet.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 与 ReplicaSets 相比，Deployments 有一些优势，并且它们实际上是通过拥有和控制 ReplicaSet 来工作的。
- en: The main advantage of a Deployment is that it allows you to specify a `rollout`
    procedure – that is, how an application upgrade is deployed to the various pods
    in the Deployment. This lets you easily configure controls to stop bad upgrades
    in their tracks.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment 的主要优势在于它允许你指定一个 `rollout` 程序——即应用升级是如何部署到 Deployment 中各个 pod 的。这使你可以轻松配置控制，以阻止错误的升级。
- en: 'Before we review how to do this, let''s look at the entire spec for a Deployment:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们复习如何执行此操作之前，先看一下 Deployment 的完整规格：
- en: deployment.yaml
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.yaml
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As you can see, this is very similar to the spec for a ReplicaSet. The difference
    we see here is a new key in the spec: `strategy`.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这与 ReplicaSet 的规格非常相似。我们在这里看到的区别是规格中出现了一个新键：`strategy`。
- en: Using the `strategy` setting, we can tell our Deployment which way to upgrade
    our application, either via a `RollingUpdate`, or `Recreate`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `strategy` 设置，我们可以告诉 Deployment 以何种方式升级应用，可以选择 `RollingUpdate` 或 `Recreate`。
- en: '`Recreate` is a very basic deployment method: all Pods in the Deployment will
    be deleted at the same time, and new Pods will be created with the new version.
    `Recreate` doesn''t give us much control against a bad Deployment – if the new
    Pods don''t start for some reason, we''re stuck with a completely non-functioning
    application.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`Recreate` 是一种非常基础的部署方法：Deployment 中的所有 Pods 会同时被删除，然后使用新版本创建新的 Pods。`Recreate`
    并未提供多少控制，以应对不良的部署——如果新 Pods 出现无法启动的情况，我们将面临一个完全无法工作的应用。'
- en: With `RollingUpdate` on the other hand, Deployments are slower but far more
    controlled. Firstly, the new application will be rolled out bit by bit, Pod by
    Pod. We can specify values for `maxSurge` and `maxUnavailable` to tune the strategy.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 而使用 `RollingUpdate`，Deployment 更新的速度较慢，但控制得更好。首先，新应用将逐步滚动发布，一次一个 Pod。我们可以为 `maxSurge`
    和 `maxUnavailable` 设置值来调优策略。
- en: A rolling update works like this – when the Deployment spec is updated with
    a new version of the Pod container, the Deployment will take down one Pod at a
    time, create a new Pod with the new application version, wait for the new Pod
    to register `Ready` as determined by the readiness check, and then move on to
    the next Pod.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动更新是这样工作的——当 Deployment 规格更新为新的 Pod 容器版本时，Deployment 会一次删除一个 Pod，创建一个带有新应用版本的新
    Pod，等待新 Pod 注册为 `Ready`（根据就绪检查确定），然后继续下一个 Pod。
- en: The `maxSurge` and `maxUnavailable` parameters allow you to speed up or slow
    down this process. `maxUnavailable` allows you to tune the maximum number of unavailable
    Pods during the rollout process. This can be either a percentage or a fixed number.
    `maxSurge` allows you to tune the maximum number of Pods over the Deployment replica
    number that can be created at any given time. Like with `maxUnavailable`, this
    can be a percentage or a fixed number.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`maxSurge` 和 `maxUnavailable` 参数允许你加快或减慢这一过程。`maxUnavailable` 让你可以调整在发布过程中不可用的
    Pod 的最大数量。它可以是百分比或固定数值。`maxSurge` 让你可以调整每次最多可以创建超过 Deployment 副本数的 Pod 数量。像 `maxUnavailable`
    一样，它可以是百分比或固定数值。'
- en: 'The following diagram shows the `RollingUpdate` procedure:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 `RollingUpdate` 过程：
- en: '![Figure 4.2 – RollingUpdate process for a Deployment](img/B14790_04_002.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – Deployment 的 RollingUpdate 过程](img/B14790_04_002.jpg)'
- en: Figure 4.2 – RollingUpdate process for a Deployment
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – Deployment 的 RollingUpdate 过程
- en: As you can see, the `RollingUpdate` procedure follows several key steps. The
    Deployment attempts to update Pods, one by one. Only after a Pod is successfully
    updated does the update proceed to the next Pod.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`RollingUpdate` 过程遵循几个关键步骤。Deployment 尝试逐个更新 Pods，只有一个 Pod 成功更新后，更新才会进行到下一个
    Pod。
- en: Controlling Deployments with imperative commands
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用命令式命令控制 Deployments
- en: As we've discussed, we can change our Deployment by simply updating its YAML
    using declarative methods. However, Kubernetes also gives us some special commands
    in `kubectl` for controlling several aspects of Deployments.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所讨论的，我们可以通过简单地更新 YAML 文件来改变 Deployment，使用声明式方法。然而，Kubernetes 还为我们提供了一些 `kubectl`
    中的特殊命令，用于控制 Deployment 的各个方面。
- en: First off, Kubernetes lets us manually scale a Deployment – that is, we can
    edit the amount of replicas that should be running.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，Kubernetes 允许我们手动缩放一个 Deployment——也就是说，我们可以编辑应该运行的副本数量。
- en: 'To scale our `myapp-deployment` up to five replicas, we can run the following:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 `myapp-deployment` 缩放到五个副本，我们可以运行以下命令：
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Similarly, we can roll back our `myapp-deployment` to an older version if required.
    To demonstrate this, first let''s manually edit our Deployment to use a new version
    of our container:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，如果需要，我们可以将`myapp-deployment`回滚到旧版本。为了演示这一点，首先让我们手动编辑我们的 Deployment，使用新版本的容器：
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This command tells Kubernetes to change the version of our container in our
    Deployment to 1.2\. Then, our Deployment will go through the steps in the preceding
    figure to roll out our change.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令告诉 Kubernetes 将我们 Deployment 中的容器版本更改为 1.2。然后，我们的 Deployment 将按照前述图示中的步骤滚动更新。
- en: 'Now, let''s say that we want to go back to our previous version before we updated
    the container image version. We can easily do this using the `rollout undo` command:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们想回到更新容器镜像版本之前的版本。我们可以使用 `rollout undo` 命令轻松实现：
- en: '[PRE9]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In our previous case, we only had two versions, the initial one and our version
    with the updated container, but if we had others, we could specify them in the
    `undo` command like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的案例中，我们只有两个版本，初始版本和更新容器的版本，但如果有其他版本，我们可以在 `undo` 命令中这样指定：
- en: '[PRE10]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This should give you a glimpse into why Deployments are so valuable – they give
    us fine-tuned control over rollout for new versions of our application. Next,
    we'll discuss a smart scaler for Kubernetes that works in concert with Deployments
    and ReplicaSets.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该能让你看出为什么 Deployments 如此有价值——它们让我们能够精确控制应用程序新版本的发布过程。接下来，我们将讨论一个与 Deployments
    和 ReplicaSets 协同工作的智能缩放器。
- en: Harnessing the Horizontal Pod Autoscaler
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用水平 Pod 自动缩放器
- en: As we've seen, Deployments and ReplicaSets allow you to specify a total number
    of replicas that should be available at a certain time. However, neither of these
    structures allow automatic scaling – they must be scaled manually.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，Deployments 和 ReplicaSets 允许你指定在某一时间点应该有多少个副本可用。然而，这两个结构都不支持自动缩放——它们必须手动进行缩放。
- en: '**Horizontal Pod Autoscalers** (**HPA**) provide this functionality by existing
    as a higher-level controller that can change the replica count of a Deployment
    or ReplicaSet based on metrics such as CPU and memory usage.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**水平 Pod 自动缩放器** (**HPA**) 通过作为一个更高级的控制器，提供这种功能，能够根据 CPU 和内存使用等指标来改变 Deployment
    或 ReplicaSet 的副本数。'
- en: By default, an HPA can autoscale based on CPU utilization, but by using custom
    metrics this functionality can be extended.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，HPA 可以基于 CPU 利用率进行自动缩放，但通过使用自定义指标，可以扩展这一功能。
- en: 'The YAML file for an HPA looks like this:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: HPA 的 YAML 文件如下所示：
- en: hpa.yaml
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: hpa.yaml
- en: '[PRE11]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the preceding spec, we have the `scaleTargetRef`, which specifies what should
    be autoscaled by the HPA, and the tuning parameters.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的规格中，我们有 `scaleTargetRef`，它指定了 HPA 应该自动扩展的对象，以及调优参数。
- en: The definition of `scaleTargetRef` can be a Deployment, ReplicaSet, or ReplicationController.
    In this case, we've defined the HPA to scale our previously created Deployment,
    `myapp-deployment`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`scaleTargetRef` 的定义可以是 Deployment、ReplicaSet 或 ReplicationController。在此案例中，我们已将
    HPA 定义为扩展我们之前创建的 Deployment，`myapp-deployment`。'
- en: For tuning parameters, we're using the default CPU utilization-based scaling,
    so we can use `targetCPUUtilizationPercentage` to define the intended CPU utilization
    of each Pod running our application. If the average CPU usage of our Pods increases
    past 70%, our HPA will scale the Deployment spec up, and if it drops below for
    long enough, it will scale the Deployment down.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于调优参数，我们使用基于默认 CPU 利用率的扩展，因此可以使用 `targetCPUUtilizationPercentage` 来定义每个运行我们应用程序的
    Pod 的目标 CPU 利用率。如果我们 Pod 的平均 CPU 使用率超过 70%，HPA 会扩展 Deployment 规格，如果使用率长时间低于该值，它会将
    Deployment 缩减。
- en: 'A typical scaling event looks like this:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的扩容事件如下所示：
- en: The average CPU usage of a Deployment exceeds 70% on three replicas.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个 Deployment 的平均 CPU 使用率超过了三个副本的 70%。
- en: The HPA control loop notices this increase in CPU utilization.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: HPA 控制循环会注意到 CPU 利用率的增加。
- en: The HPA edits the Deployment spec with a new replica count. This count is calculated
    based on CPU utilization, with the intent of a steady state per-node CPU usage
    under 70%.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: HPA 会通过新的副本数量来编辑 Deployment 规格。这个数量是根据 CPU 利用率计算的，目的是使每个节点的 CPU 使用率保持在 70% 以下的稳定状态。
- en: The Deployment controller spins up a new replica.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Deployment 控制器启动一个新的副本。
- en: This process repeats itself to scale the Deployment up or down.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该过程会重复，以便扩展或缩减 Deployment。
- en: In summary, the HPA keeps track of CPU and memory utilization and initiates
    a scaling event when boundaries are exceeded. Next, we will review DaemonSets,
    which provide a very specific type of Pod controller.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，HPA 会跟踪 CPU 和内存利用率，并在超出边界时启动扩容事件。接下来，我们将回顾 DaemonSets，它提供了一种非常特定类型的 Pod
    控制器。
- en: Implementing DaemonSets
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现 DaemonSets
- en: From now until the end of the chapter, we will be reviewing more niche options
    when it comes to running applications with specific requirements.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始直到本章结束，我们将回顾更多适用于具有特定要求的应用程序运行的细分选项。
- en: We'll start with DaemonSets, which are similar to ReplicaSets except that the
    number of replicas is fixed at one replica per node. This means that each node
    in the cluster will keep one replica of the application active at any time.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从 DaemonSets 开始，它类似于 ReplicaSets，区别在于每个节点的副本数固定为一个副本。这意味着集群中的每个节点在任何时候都会保持一个应用程序副本处于活动状态。
- en: Important note
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: It's important to keep in mind that this functionality will only create one
    replica per node in the absence of additional Pod placement controls, such as
    Taints or Node Selectors, which we will cover in greater detail in [*Chapter 8*](B14790_08_Final_PG_ePub.xhtml#_idTextAnchor186),
    *Pod Placement Controls*.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的是，在没有额外的 Pod 调度控制（如污点或节点选择器）的情况下，此功能仅会在每个节点上创建一个副本，后者我们将在[*第 8 章*](B14790_08_Final_PG_ePub.xhtml#_idTextAnchor186)中详细介绍，*Pod
    调度控制*。
- en: 'This ends up looking like the following diagram for a typical DaemonSet:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 对于典型的 DaemonSet，它最终呈现为如下图所示：
- en: '![Figure 4.3 – DaemonSet spread across three nodes](img/B14790_04_003.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3 – DaemonSet 分布在三个节点上](img/B14790_04_003.jpg)'
- en: Figure 4.3 – DaemonSet spread across three nodes
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – DaemonSet 分布在三个节点上
- en: As you can see in the preceding figure, each node (represented by a box) contains
    one Pod of the application, as controlled by the DaemonSet.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，集群中的每个节点（用方框表示）包含一个由 DaemonSet 控制的应用程序 Pod。
- en: 'This makes DaemonSets great for running applications that collect metrics at
    the node level or provide networking processes on a per-node basis. A DaemonSet
    spec looks like this:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得 DaemonSets 非常适合运行在节点级别收集指标或提供基于每个节点的网络进程的应用程序。一个 DaemonSet 规格如下所示：
- en: daemonset-1.yaml
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: daemonset-1.yaml
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As you can see, this is very similar to your typical ReplicaSet spec, except
    that we do not specify the number of replicas. This is because a DaemonSet will
    try to run a Pod on each node in your cluster.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这与典型的 ReplicaSet 规格非常相似，唯一不同的是我们没有指定副本数量。这是因为 DaemonSet 会尝试在集群中的每个节点上运行一个
    Pod。
- en: 'If you want to specify a subset of nodes to run your application, you can do
    this using a node selector as shown in the following file:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望指定一个子集的节点来运行你的应用程序，可以使用如下文件中的节点选择器来实现：
- en: daemonset-2.yaml
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: daemonset-2.yaml
- en: '[PRE13]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This YAML will restrict our DaemonSet to nodes that match the `type=bigger-node`
    selector in their labels. We will learn much more about Node Selectors in [*Chapter
    8*](B14790_08_Final_PG_ePub.xhtml#_idTextAnchor186), *Pod Placement Controls*.
    For now, let's discuss a type of controller well suited to running stateful applications
    such as databases – the StatefulSet.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 YAML 文件将限制我们的 DaemonSet 仅匹配标签中 `type=bigger-node` 选择器的节点。在[*第 8 章*](B14790_08_Final_PG_ePub.xhtml#_idTextAnchor186)中，我们将深入学习更多关于节点选择器的内容，*Pod
    放置控制*。现在，让我们讨论一种非常适合运行有状态应用程序（如数据库）的控制器——StatefulSet。
- en: Understanding StatefulSets
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 StatefulSets
- en: StatefulSets are very similar to ReplicaSets and Deployments, but with one key
    difference that makes them better for stateful workloads. StatefulSets maintain
    the order and identity of each Pod, even if the Pods are rescheduled onto new
    nodes.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSets 与 ReplicaSets 和 Deployments 非常相似，但有一个关键区别使它们更适合有状态工作负载。StatefulSets
    保持每个 Pod 的顺序和身份，即使这些 Pods 被重新调度到新的节点上。
- en: For instance, in a StatefulSet of 3 replicas, there will always be Pod 1, Pod
    2, and Pod 3, and those Pods will maintain their identity in Kubernetes and storage
    (which we'll get to in [*Chapter 7*](B14790_07_Final_PG_ePub.xhtml#_idTextAnchor166),
    *Storage on Kubernetes*), regardless of any rescheduling that happens.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在一个包含 3 个副本的 StatefulSet 中，Pod 1、Pod 2 和 Pod 3 会始终存在，并且这些 Pods 会在 Kubernetes
    和存储中保持其身份（我们将在[*第 7 章*](B14790_07_Final_PG_ePub.xhtml#_idTextAnchor166)中讨论 *Kubernetes
    存储*）。不管发生什么重新调度，它们的身份都会保持不变。
- en: 'Let''s take a look at a simple StatefulSet configuration:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下一个简单的 StatefulSet 配置：
- en: statefulset.yaml
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: statefulset.yaml
- en: '[PRE14]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This YAML will create a StatefulSet with five replicas of our app.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 YAML 文件将创建一个包含五个副本的 StatefulSet 来运行我们的应用程序。
- en: 'Let''s see how the StatefulSet maintains Pod identity differently than a typical
    Deployment or ReplicaSet. Let''s fetch all Pods using the command:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 StatefulSet 如何与典型的 Deployment 或 ReplicaSet 不同地维护 Pod 身份。我们可以使用以下命令获取所有
    Pods：
- en: '[PRE15]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output should look like the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '[PRE16]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you can see, in this example, we have our five StatefulSet Pods, each with
    a numeric indicator of their identity. This property is extremely useful for stateful
    applications such as a database cluster. In the case of running a database cluster
    on Kubernetes, the identity of the master versus replica Pods is important, and
    we can use StatefulSet identities to easily manage that.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在这个例子中，我们有五个 StatefulSet Pods，每个 Pod 都有一个数字标识符来表示其身份。这个特性对于有状态应用程序（如数据库集群）非常有用。在
    Kubernetes 上运行数据库集群时，主节点与副本节点的身份非常重要，我们可以使用 StatefulSet 身份来轻松管理这一点。
- en: Another point of interest is that you can see the final Pod is still starting
    up, and that the Pod ages increase as numeric identity increases. This is because
    StatefulSet Pods are created one at a time, in order.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得注意的地方是，你可以看到最后一个 Pod 仍在启动中，并且随着数字身份的增加，Pod 的年龄也会增加。这是因为 StatefulSet Pods
    是逐个顺序创建的。
- en: 'StatefulSets are valuable in concert with persistent Kubernetes storage in
    order to run stateful applications. We''ll learn more about this in [*Chapter
    7*](B14790_07_Final_PG_ePub.xhtml#_idTextAnchor166), *Storage On Kubernetes*,
    but for now, let''s discuss another controller with a very specific use: Jobs.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSets 与持久化的 Kubernetes 存储配合使用，以运行有状态应用程序。我们将在[*第 7 章*](B14790_07_Final_PG_ePub.xhtml#_idTextAnchor166)中了解更多关于这个内容，*Kubernetes
    存储*，但现在让我们讨论另一个有着非常特定用途的控制器：Jobs。
- en: Using Jobs
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Jobs
- en: The purpose of the Job resource in Kubernetes is to run tasks that can complete,
    which makes them not ideal for long-running applications, but great for batch
    jobs or similar tasks that can benefit from parallelism.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 中 Job 资源的目的是运行可以完成的任务，这使得它们不适合长期运行的应用程序，但非常适合批处理作业或类似任务，这些任务可以从并行化中受益。
- en: 'Here''s what a Job spec YAML looks like:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Job 规范 YAML 文件的样子：
- en: job-1.yaml
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: job-1.yaml
- en: '[PRE17]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This Job will start a single Pod, and run a command, `node job.js`, until it
    completes, at which point the Pod will shut down. In this and the future examples,
    we assume that the container image used has a file, `job.js`, that runs the job
    logic. The `node:lts-jessie` container image will not have this by default. This
    is an example of a Job that runs without parallelism. As you are likely aware
    from Docker usage, multiple command arguments must be passed as an array of strings.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Job 将启动一个 Pod，并运行命令 `node job.js`，直到它完成，此时 Pod 会关闭。在这个和未来的例子中，我们假设使用的容器镜像包含一个文件
    `job.js`，该文件运行作业逻辑。默认情况下，`node:lts-jessie` 容器镜像不会包含此文件。这是一个没有并行化的 Job 示例。如你所知，从
    Docker 使用中可以得知，多个命令参数必须作为字符串数组传递。
- en: In order to create a Job that can run with parallelism (that is to say, multiple
    replicas running the Job at the same time), you need to develop your application
    code in a way that it can tell that the Job is completed before ending the process.
    In order to do this, each instance of the Job needs to contain code that ensures
    it does the right part of the greater batch task and prevents duplicate work from
    occurring.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建一个可以并行运行的作业（也就是说，多个副本同时运行作业），你需要以一种能够在结束进程之前确定作业是否完成的方式开发应用代码。为了做到这一点，每个作业实例需要包含代码，确保它执行正确的批量任务部分，并防止重复工作。
- en: There are several application patterns that can enable this, including a mutex
    lock and a Work Queue. In addition, the code needs to check the status of the
    entire batch task, which could again be handled by updating a value in a database.
    Once the Job code sees that the greater task is complete, it should exit.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种应用模式可以启用此功能，包括互斥锁和工作队列。此外，代码需要检查整个批量任务的状态，这可以通过更新数据库中的一个值来处理。一旦作业代码发现大任务已完成，它应该退出。
- en: 'Once you''ve done that, you can add parallelism to your job code using the
    `parallelism` key. The following code block shows this:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 完成上述操作后，你可以使用`parallelism`键向作业代码中添加并行性。以下代码块展示了这一点：
- en: job-2.yaml
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: job-2.yaml
- en: '[PRE18]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see, we add the `parallelism` key with three replicas. Further, you
    can swap pure job parallelism for a specified number of completions, in which
    case Kubernetes can keep track of how many times the Job has been completed. You
    can still set parallelism for this case, but if you don't set it, it will default
    to 1.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们添加了`parallelism`键并设置为三份副本。此外，你可以将纯作业并行性替换为指定的完成次数，在这种情况下，Kubernetes会跟踪作业的完成次数。你仍然可以为这种情况设置并行性，但如果没有设置，它默认会是1。
- en: 'This next spec will run a Job `4` times to completion, with `2` iterations
    running at any given time:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这个规格将运行一个作业`4`次直到完成，每次运行时有`2`次迭代：
- en: job-3.yaml
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: job-3.yaml
- en: '[PRE19]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Jobs on Kubernetes provide a great way to abstract one-time processes, and many
    third-party applications link them into workflows. As you can see, they are very
    easy to use.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes中的作业为抽象一次性处理提供了很好的方式，许多第三方应用程序将其集成到工作流中。如你所见，它们非常易于使用。
- en: Next, let's look at a very similar resource, the CronJob.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来看一个非常相似的资源，CronJob。
- en: CronJobs
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CronJobs
- en: CronJobs are a Kubernetes resource for scheduled job execution. This works very
    similarly to CronJob implementations you may find in your favorite programming
    language or application framework, with one key difference. Kubernetes CronJobs
    trigger Kubernetes Jobs, which provide an additional layer of abstraction that
    can be used, for instance, to trigger batch Jobs at night, every night.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: CronJobs是Kubernetes中的一个资源，用于定时执行作业。这与您在最喜爱的编程语言或应用框架中可能找到的CronJob实现非常相似，唯一的关键区别是：Kubernetes的CronJob触发Kubernetes作业，它提供了一个额外的抽象层，可以用于触发例如每晚的批处理作业。
- en: 'CronJobs in Kubernetes are configured using a very typical cron notation. Let''s
    take a look at the full spec:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes中的CronJob使用非常典型的cron表示法进行配置。让我们来看一下完整的规格：
- en: cronjob-1.yaml
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: cronjob-1.yaml
- en: '[PRE20]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This CronJob will, at 1 a.m. every day, create a Job that is identical to our
    previous Job spec. For a quick review of cron time notation, which will explain
    the syntax of our 1 a.m. job, read on. For a comprehensive review of cron notation,
    check [http://man7.org/linux/man-pages/man5/crontab.5.html](http://man7.org/linux/man-pages/man5/crontab.5.html).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这个CronJob将在每天凌晨1点创建一个与我们之前的作业规格完全相同的作业。为了快速回顾cron时间表示法，了解我们凌晨1点作业的语法，继续阅读。如果需要更全面的cron表示法回顾，请查阅[http://man7.org/linux/man-pages/man5/crontab.5.html](http://man7.org/linux/man-pages/man5/crontab.5.html)。
- en: 'Cron notation consists of five values, separated by spaces. Each value can
    be a numeric integer, character, or combination. Each of the five values represents
    a time value with the following format, from left to right:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: cron表示法由五个值组成，用空格分隔。每个值可以是数字、字符或组合。每个值代表一个时间值，格式如下，从左到右：
- en: Minute
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分钟
- en: Hour
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小时
- en: Day of the month (such as `25`)
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每月的某一天（例如`25`）
- en: Month
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 月份
- en: Day of the week (where, for example, `3` = Wednesday)
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期几（例如，`3` = 星期三）
- en: 'The previous YAML assumes a non-parallel CronJob. If we wanted to increase
    the batch capacity of our CronJob, we could add parallelism as we did with our
    previous Job specs. The following code block shows this:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 上述YAML假设是一个非并行的CronJob。如果我们想增加CronJob的批量处理能力，可以像之前为作业规格设置并行性一样为CronJob添加并行性。以下代码块展示了这一点：
- en: cronjob-2.yaml
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: cronjob-2.yaml
- en: '[PRE21]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that for this to work, the code in your CronJob container needs to gracefully
    handle parallelism, which could be implemented using a work queue or other such
    pattern.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，为了使其正常工作，您在 CronJob 容器中的代码需要优雅地处理并行性，可以使用工作队列或其他类似模式来实现。
- en: We've now reviewed all the basic controllers that Kubernetes provides by default.
    Let's use our knowledge to run a more complex application example on Kubernetes
    in the next section.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经审查了 Kubernetes 默认提供的所有基本控制器。接下来，让我们利用我们的知识，在 Kubernetes 上运行一个更复杂的应用示例。
- en: Putting it all together
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将所有内容组合起来
- en: 'We now have a toolset for running applications on Kubernetes. Let''s look at
    a real-world example to see how this could all be combined to run an application
    with multiple tiers and functionality spread across Kubernetes resources:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有了一套在 Kubernetes 上运行应用程序的工具集。让我们看看一个现实世界的例子，看看这些如何结合起来，在 Kubernetes 资源上运行具有多个层和功能的应用程序：
- en: '![Figure 4.4 – Multi-tier application diagram](img/B14790_04_004.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4 – 多层应用程序架构](img/B14790_04_004.jpg)'
- en: Figure 4.4 – Multi-tier application diagram
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – 多层应用程序架构
- en: As you can see, our diagrammed application contains a web tier running a .NET
    Framework application, a mid-tier or service tier running Java, a database tier
    running Postgres, and finally a logging/monitoring tier.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们的应用程序架构包含一个运行 .NET Framework 应用程序的 Web 层，一个运行 Java 的中间层或服务层，一个运行 Postgres
    的数据库层，最后是一个日志/监控层。
- en: Our controller choices for each of these tiers are dependent on the applications
    we plan to run on each tier. For both the web tier and the mid-tier, we're running
    stateless applications and services, so we can effectively use Deployments to
    handle rolling out updates, blue/green deploys, and more.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为每个层选择的控制器取决于我们计划在每个层上运行的应用程序。对于 Web 层和中间层，我们运行的是无状态的应用和服务，因此我们可以有效地使用 Deployments
    来处理更新发布、蓝绿部署等。
- en: For the database tier, we need our database cluster to know which Pod is a replica
    and which is a master – so we use a StatefulSet. And finally, our log collector
    needs to run on every node, so we use a DaemonSet to run it.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据库层，我们需要数据库集群知道哪个 Pod 是副本，哪个是主节点——因此我们使用 StatefulSet。最后，我们的日志收集器需要在每个节点上运行，所以我们使用
    DaemonSet 来运行它。
- en: Now, let's go through example YAML specs for each of our tiers.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们逐一查看每个层的示例 YAML 规格。
- en: Let's start with our JavaScript-based web app. By hosting this application on
    Kubernetes, we can do canary tests and blue/green Deployments. As a note, some
    of the examples in this section use container image names that aren't publicly
    available in DockerHub. To use this pattern, adapt the examples to your own application
    containers, or just use busybox if you want to run it without actual application
    logic.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从基于 JavaScript 的 Web 应用程序开始。通过在 Kubernetes 上托管这个应用程序，我们可以进行金丝雀测试和蓝绿部署。需要注意的是，本节中的一些示例使用了在
    DockerHub 上不可公开访问的容器镜像名称。要使用此模式，您可以将示例适配到自己的应用容器，或者如果您想运行它而不涉及实际的应用逻辑，可以直接使用 busybox。
- en: 'The YAML file for the web tier could look like this:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Web 层的 YAML 文件可能如下所示：
- en: example-deployment-web.yaml
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: example-deployment-web.yaml
- en: '[PRE22]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In the preceding YAML, we're labeling our applications using the `tier` label
    and using that as our `matchLabels` selector.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的 YAML 中，我们使用 `tier` 标签来标记我们的应用程序，并将其作为我们的 `matchLabels` 选择器。
- en: 'Next up is the mid-tier service layer. Let''s take a look at the relevant YAML:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是中间层服务层。让我们来看一下相关的 YAML：
- en: example-deployment-mid.yaml
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: example-deployment-mid.yaml
- en: '[PRE23]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As you can see in the preceding code, our mid-tier application is pretty similar
    to the web tier setup, and we're using another Deployment.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在前面的代码中所见，我们的中间层应用程序与 Web 层设置非常相似，并且我们使用了另一个 Deployment。
- en: 'Now comes the interesting part – let''s look at the spec for our Postgres StatefulSet.
    We have truncated this code block somewhat in order to fit on the page, but you
    should be able to see the most important parts:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在进入有趣的部分——让我们来看一下 Postgres StatefulSet 的规格。为了适应页面，我们略微截断了这个代码块，但您应该能够看到最重要的部分：
- en: example-statefulset.yaml
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: example-statefulset.yaml
- en: '[PRE24]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the preceding YAML file, we can see some new concepts that we haven't reviewed
    yet – ConfigMaps and volumes. We'll get a much closer look at how these work in
    *Chapters 6*, *Kubernetes Application Configuration*, and [*Chapter 7*](B14790_07_Final_PG_ePub.xhtml#_idTextAnchor166),
    *Storage on Kubernetes*, respectively, but for now let's focus on the rest of
    the spec. We have our `postgres` container as well as a port set up on the default
    Postgres port of `5432`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s take a look at our DaemonSet for our logging app. Here''s a
    portion of the YAML file, which we''ve again truncated for length:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: example-daemonset.yaml
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In this DaemonSet, we're setting up FluentD (a popular open source log collector)
    to forward logs to Papertrail, a cloud-based log collector and search tool. Again,
    in this YAML file, we have some things we haven't reviewed before. For instance,
    the `tolerations` section for `node-role.kubernetes.io/master` will actually allow
    our DaemonSet to place Pods on master nodes, not just worker nodes. We'll review
    how this works in [*Chapter 8*](B14790_08_Final_PG_ePub.xhtml#_idTextAnchor186),
    *Pod Placement Controls*.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: We're also specifying environment variables directly in the Pod spec, which
    is fine for relatively basic configurations, but could be improved by using Secrets
    or ConfigMaps (which we'll review in [*Chapter 6*](B14790_06_Final_PG_ePub.xhtml#_idTextAnchor143),
    *Kubernetes Application Configuration*) to keep it out of our YAML code.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we reviewed some methods of running applications on Kubernetes.
    To start, we reviewed why Pods themselves are not enough to guarantee application
    availability and introduced controllers. We then reviewed some simple controllers,
    including ReplicaSets and Deployments, before moving on to controllers with more
    specific uses such as HPAs, Jobs, CronJobs, StatefulSets, and DaemonSets. Finally,
    we took all our learning and used it to implement a complex application running
    on Kubernetes.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll learn how to expose our applications (which are now
    running properly with high availability) to the world using Services and Ingress.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the difference between a ReplicaSet and a ReplicationController?
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the advantage of a Deployment over a ReplicaSet?
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a good use case for a Job?
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are StatefulSets better for stateful workloads?
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How might we support a canary release flow using Deployments?
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The official Kubernetes documentation: [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Documentation on the Kubernetes Job resource: [https://kubernetes.io/docs/concepts/workloads/controllers/job/](https://kubernetes.io/docs/concepts/workloads/controllers/job/)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Docs for FluentD DaemonSet installation: [https://github.com/fluent/fluentd-kubernetes-daemonset](https://github.com/fluent/fluentd-kubernetes-daemonset)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kubernetes The Hard Way*: [https://github.com/kelseyhightower/kubernetes-the-hard-way](https://github.com/kelseyhightower/kubernetes-the-hard-way)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kubernetes The Hard Way*: [https://github.com/kelseyhightower/kubernetes-the-hard-way](https://github.com/kelseyhightower/kubernetes-the-hard-way)'
