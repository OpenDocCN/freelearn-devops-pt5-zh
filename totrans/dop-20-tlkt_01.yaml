- en: Chapter 1. The DevOps Ideal
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章：DevOps 理想
- en: Working on small greenfield projects is great. The last one I was involved with
    was during the summer of 2015 and, even though it had its share of problems, it
    was a real pleasure. Working with a small and relatively new set of products allowed
    us to choose technologies, practices, and frameworks we liked. Shall we use microservices?
    Yes, why not. Shall we try Polymer and GoLang? Sure! Not having baggage that holds
    you down is a wonderful feeling. A wrong decision would put us back for a week,
    but it would not put in danger years of work someone else did before us. Simply
    put, there was no legacy system to think about and be afraid of.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 从事小型绿地项目是一件很棒的事。我参与的最后一个项目是在2015年夏天，尽管它有一些问题，但整体上还是非常愉快的。与一套小而相对新的产品合作使我们能够选择我们喜欢的技术、实践和框架。我们是否应该使用微服务？当然，为什么不呢？我们是否应该尝试
    Polymer 和 GoLang？没问题！没有那些束缚你的包袱是一种美妙的感觉。一个错误的决定可能让我们退步一周，但它不会危及到别人之前辛勤工作的几年时间。简单来说，我们不需要考虑并害怕遗留系统的影响。
- en: Most of my career was not like that. I had the opportunity, or a curse, to work
    on big inherited systems. I worked for companies that existed long before I joined
    them and, for better or worse, already had their systems in place. I had to balance
    the need for innovation and improvement with obvious requirement that existing
    business must continue operating uninterrupted. During all those years I was continuously
    trying to discover new ways to improve those systems. It pains me to admit, but
    many of those attempts were failures.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我的职业生涯大多数时间并不是这样的。我有机会，或者说是一种诅咒，参与到大型遗留系统的工作中。我曾为一些公司工作，这些公司在我加入之前就已存在，并且无论是好是坏，都已经有了自己的系统。我必须在创新和改进的需求与现有业务必须不间断运作之间找到平衡。在所有那些年里，我不断地尝试寻找新的方法来改进这些系统。虽然这很痛心，但我不得不承认，许多尝试都是失败的。
- en: We'll explore those failures in order to understand better the motivations that
    lead to the advancements we'll discuss throughout this books.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨这些失败，以便更好地理解推动我们在本书中讨论的进展的动机。
- en: Continuous Integration, Delivery, and Deployment
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续集成、持续交付与持续部署
- en: Discovering CI and, later on, CD, was one of the crucial points in my career.
    It all made perfect sense. The integration phase back in those days could last
    anything from days to weeks or even months. It was the period we all dreaded.
    After months of work performed by different teams working on different services
    or applications, the first day of the integration phase was the definition of
    hell on earth. If I didn't know better, I'd say that Dante was a developer and
    wrote Infierno during the integration phase.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 发现持续集成（CI）以及后来出现的持续交付（CD）是我职业生涯中的一个关键点。这一切都显得合情合理。在那个时候，集成阶段可能持续几天、几周，甚至几个月。这是我们都害怕的时期。在不同团队为不同服务或应用程序工作几个月后，集成阶段的第一天就是地狱的代名词。如果我不懂，我可能会说但丁是一个开发者，并且在集成阶段写了《地狱篇》。
- en: On the dreaded first day of the integration phase, we would all come to the
    office with grim faces. Only whispers could be heard while the integration engineer
    would announce that the whole system was set up, and the game could begin. He
    would turn it on and, sometimes, the result would be a blank screen. Months of
    work in isolation would prove, one more time, to be a disaster. Services and applications
    could not be integrated, and the long process of fixing problems would begin.
    In some cases, we would need to redo weeks of work. Requirements defined in advance
    were, as always, subject to different interpretations and those differences are
    nowhere more noticeable than in the integration phase.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在令人畏惧的集成阶段的第一天，我们都会带着严肃的面孔走进办公室。只能听到低声耳语，集成工程师宣布整个系统已搭建好，游戏可以开始了。他启动系统，有时，结果是一个空白屏幕。几个月的独立工作再次证明是灾难性的。服务和应用程序无法集成，修复问题的漫长过程就此开始。在某些情况下，我们可能需要重新做几周的工作。提前定义的需求，像往常一样，会有不同的解释，这种差异在集成阶段尤为明显。
- en: Then **eXtreme Programming** (**XP**) practices came into existence and, with
    them, **continuous integration** (**CI**). The idea that integration should be
    done continuously today sounds like something obvious. Duh! Of course, you should
    not wait until the last moment to integrate! Back then, in the waterfall era,
    such a thing was not so obvious as today. We implemented a continuous integration
    pipeline and started checking out every commit, running static analysis, unit
    and functional tests, packaging, deploying and running integration tests. If any
    of those phases failed, we would abandon what we were doing and made fixing the
    problem detected by the pipeline our priority. The pipeline itself was fast. Minutes
    after someone would make a commit to the repository we would get a notification
    if something failed. Later on, **continuous delivery** (**CD**) started to take
    ground, and we would have confidence that every commit that passed the whole pipeline
    could be deployed to production. We could do even better and not only attest that
    each build is production ready, but apply *continuous deployment* and deploy every
    build without waiting for (manual) confirmation from anyone. And the best part
    of all that was that everything was fully automated.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，**极限编程**（**XP**）实践诞生了，随之而来的是**持续集成**（**CI**）。今天，集成应该持续进行这个想法听起来似乎是显而易见的。嗯！当然，你不应该等到最后一刻才进行集成！但在当时的瀑布开发时代，这种做法并不如今天这样显而易见。我们实施了一个持续集成的流水线，并开始检查每一次提交，运行静态分析、单元测试、功能测试、打包、部署和集成测试。如果任何一个阶段失败，我们会放弃正在做的工作，并将修复流水线检测到的问题作为我们的首要任务。流水线本身非常快速。在有人提交代码到仓库后几分钟内，我们就会收到通知，若出现失败。后来，**持续交付**（**CD**）开始得到普及，我们可以确信每次通过整个流水线的提交都能部署到生产环境。我们甚至做得更好，不仅能验证每个构建是否准备好生产，而且可以应用*持续部署*，在不等待任何人（手动）确认的情况下，部署每个构建。所有这些最棒的一点是，一切都是全自动化的。
- en: It was a dream come true. Literally! It was a dream. It wasn't something we
    managed to turn into reality. Why was that? We made mistakes. We thought that
    CI/CD is a task for the operations department (today we'd call them *DevOps*).
    We thought that we could create a process that wraps around applications and services.
    We thought that CI tools and frameworks are ready. We thought that architecture,
    testing, business negotiations and other tasks were the job for someone else.
    We were wrong. I was wrong.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个梦想成真。字面意思！它是一个梦想。它不是我们设法变成现实的东西。那是为什么呢？我们犯了错误。我们认为 CI/CD 是运维部门的任务（今天我们称之为*DevOps*）。我们以为我们可以创建一个围绕应用程序和服务的流程。我们认为
    CI 工具和框架已经准备好。我们认为架构、测试、商业谈判以及其他任务是别人负责的事。我们错了。我错了。
- en: Today I know that successful CI/CD means that no stone can be left unturned.
    We need to influence everything; from architecture through testing, development
    and operations all the way until management and business expectations. But let
    us go back again. What went wrong in those failures of mine?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 今天我知道，成功的 CI/CD 意味着没有任何环节可以忽略。我们需要影响一切；从架构到测试，再到开发和运维，直到管理层和商业预期。但让我们再回到原点。那些失败中，究竟出了什么问题？
- en: Architecture
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构
- en: Trying to fit a monolithic application developed by many people throughout the
    years, without tests, with tight coupling and outdated technology is like an attempt
    to make an eighty-year-old lady look young again. We can improve her looks, but
    the best we can do is make her look a bit less old, not young. Some systems are,
    simply put, too old to be worth the *modernization* effort. I tried it, many times,
    and the result was never as expected. Sometimes, the effort in making it *young
    again* is not cost effective. On the other hand, I could not go to the client
    of, let's say, a bank, and say we're going to rewrite your whole system. Risks
    are too big to rewrite everything and, be it as it might, due to its tight coupling,
    age, and outdated technology, changing parts of it is not worth the effort. The
    commonly taken option was to start building the new system and, in parallel, maintain
    the old one until everything was done. That was always a disaster. It can take
    years to finish such a project, and we all know what happens with things planned
    for such a long term. That's not even the waterfall approach. That's like standing
    at the bottom of Niagara Falls wondering why you get wet. Even doing trivial things
    like updating the JDK was quite a feat. And those were the cases when I would
    consider myself lucky. What would you do with, for example, codebase done in Fortran
    or Cobol?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试调整一个由许多人多年来开发的单体应用，缺乏测试、耦合紧密且技术陈旧，就像试图让一个八十岁的老太太看起来年轻一样。我们可以改善她的外貌，但我们所能做的也就是让她看起来稍微不那么老，而不是年轻。简单来说，某些系统已经太老，不值得进行*现代化*努力。我尝试过，很多次，结果从未如预期。
    有时候，使其*恢复年轻*的努力是不划算的。另一方面，我无法去对银行之类的客户说：“我们将重写你们的整个系统。”重写一切的风险太大，而且由于其紧密耦合、老化和技术过时，改动其中的一部分也不值得投入太多精力。常见的做法是开始构建新系统，并在此期间维护旧系统，直到一切完成。这总是个灾难。完成这样一个项目可能需要好几年，而我们都知道长期规划的事情最终会怎么样。那甚至不是瀑布方法。那就像站在尼亚加拉大瀑布的底部，困惑自己为什么会被淋湿。即便是像更新
    JDK 这种琐事，也变得异常艰难。而那时候，我会觉得自己很幸运。那么，面对例如用 Fortran 或 Cobol 编写的代码库，你会怎么做呢？
- en: Then I heard about microservices. It was like music to my ears. The idea that
    we can build many small independent services that can be maintained by small teams,
    have codebase that can be understood in no time, being able to change framework,
    programming language or a database without affecting the rest of the system and
    being able to deploy it independently from the rest of the system was too good
    to be true. We could, finally, start taking parts of the monolithic application
    out without putting the whole system at (significant) risk. It sounded too good
    to be true. And it was. Benefits came with downsides. Deploying and maintaining
    a vast number of services turned out to be a heavy burden. We had to compromise
    and start standardizing services (killing innovation), we created shared libraries
    (coupling again), we were deploying them in groups (slowing everything), and so
    on. In other words, we had to remove the benefits microservices were supposed
    to bring. And let's not even speak of configurations and the mess they created
    inside servers. Those were the times I try to forget. We had enough problems like
    that with monoliths. Microservices only multiplied them. It was a failure. However,
    I was not yet ready to give up. Call me a masochist.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我听说了微服务。这对我来说简直是如同天籁之音。我们可以构建许多小的独立服务，由小团队维护，代码库可以很快理解，能够在不影响整个系统的情况下更换框架、编程语言或数据库，并且可以独立部署的想法实在太美好了，几乎不敢相信。我们终于可以开始从单体应用中剥离一些部分，而不至于让整个系统（遭受重大）风险。听起来太完美了，结果也确实如此。好处的背后也有缺点。部署和维护大量服务最终变成了一项沉重的负担。我们不得不做出妥协，开始标准化服务（扼杀创新），创建共享库（再次耦合），将它们分组部署（拖慢一切进度），诸如此类。换句话说，我们不得不去除微服务本应带来的好处。更不用提配置和它们在服务器内部制造的混乱了。这些是我尽量忘记的日子。我们已经有了足够多与单体系统相关的问题，微服务只是将它们放大了。这是一次失败。然而，我还没有准备好放弃。叫我一个受虐狂也罢。
- en: I had to face problems one at a time, and one of the crucial ones was deployments.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我不得不一次解决一个问题，其中一个关键问题就是部署。
- en: Deployments
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署
- en: You know the process. Assemble some artifacts (JAR, WAR, DLL, or whatever is
    the result of your programming language), deploy it to the server that is already
    polluted with... I cannot even finish the sentence because, in many cases, we
    did not even know what was on the servers. With enough time, any server maintained
    manually becomes full of things. Libraries, executables, configurations, gremlins
    and trolls. It would start to develop its own personality. Old and grumpy, fast
    but unreliable, demanding, and so on. The only thing all the servers had in common
    was that they were all different, and no one could be sure that software tested
    in, let's say, pre-production environment would behave the same when deployed
    to production. It was a lottery. You might get lucky, but most likely you won't.
    Hope dies last.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: You might, rightfully, wonder why we didn't use virtual machines in those days.
    Well, there are two answers to that question, and they depend on the definition
    of those days. One answer is that in those days we didn't have virtual machines,
    or they were so new that management was too scared to approve their usage. The
    other answer is that later on we did use VMs, and that was the real improvement.
    We could copy production environment and use it as, let's say testing environment.
    Except that there was still a lot of work to update configurations, networking,
    and so on.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Besides, we still did not know what was accumulated on those machines throughout
    the years. We just knew how to duplicate them. That still did not solve the problem
    that configurations were different from one VM to another as well as that a copy
    is the same as the original only for a short period. Do the deployment, change
    some configuration, bada bing, bada boom, you go back to the problem of testing
    something that is not the same as it will be in production. Differences accumulate
    with time unless you have a repeatable and reliable automated process instead
    of manual human interventions. If such a thing would exist, we could create immutable
    servers. Instead of deploying applications to existing servers and go down the
    path of accumulating differences, we could create a new VM as part of the CI/CD
    pipeline. So, instead of creating JARs, WAR, DLLs, and so on, we started creating
    VMs. Every time there was a new release it would come as a complete server built
    from scratch. That way we would know that what was tested is what goes into production.
    Create new VM with software deployed, test it and switch your production router
    to point from the old to the new one. It was awesome, except that it was slow
    and resource demanding. Having a separate VM for each service is overkill. Still,
    armed with patience, immutable servers were a good idea, but the way we used that
    approach and the tools required to support it were not good enough.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Orchestration
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The orchestration was the key. *Puppet* and *Chef* proved to be a big help.
    Programming everything related to servers setup and deployment was a huge improvement.
    Not only that the time needed to setup servers and deploy software dropped drastically,
    but we could, finally, accomplish a more reliable process. Having humans (read
    operations department) manually running those types of tasks was a recipe for
    disaster. Finally a story with a happy ending? Not really. You probably started
    noticing a pattern. As soon as one improvement was accomplished, it turned out
    that it, often, comes with a high price. Given enough time, Puppet and Chef scripts
    and configurations turn into an enormous pile of **** (I was told not to use certain
    words so please fill in the blanks with your imagination). Maintaining them tends
    to become a nightmare in itself. Still, with orchestration tools, we could drastically
    reduce the time it took to create immutable VMs. Something is better than nothing.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: The Light at the End of the Deployment pipeline
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I could go on and on describing problems we faced. Don't take me wrong. All
    those initiatives were improvements and have their place in software history.
    But history is the past, and we live in the present trying to look into the future.
    Many, if not all of the problems we had before are now solved. *Ansible* proved
    that orchestration does not need to be complicated to set up nor hard to maintain.
    With the appearance of *Docker*, containers are slowly replacing VMs as the preferable
    way to create immutable deployments. New operating systems are emerging and fully
    embracing containers as first class citizens. Tools for service discovery are
    showing us new horizons. *Swarm, Kubernetes and Mesos/DCOS* are opening doors
    into areas that were hard to imagine only a few years ago.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Microservices are slowly becoming the preferred way to build big, easy to maintain
    and highly scalable systems thanks to tools like *Docker, CoreOS, etcd, Consul,
    Fleet, Mesos, Rocket*, and others. The idea was always great, but we did not have
    the tools to make it work properly. Now we do! That does not mean that all our
    problems are gone. It means that when we solve one problem, the bar moves higher
    up, and new issues emerge.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: I started by complaining about the past. That will not happen again. This book
    is for readers who do not want to live in the past but present. This book is about
    preparations for the future. This book is about stepping through the looking glass,
    about venturing into new areas and about looking at things from a new angle.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '|   | *This is your last chance. After this, there is no turning back. You
    take the blue pill - the story ends, you wake up in your bed and believe whatever
    you want to believe. You take the red pill - you stay in Wonderland and I show
    you how deep the rabbit-hole goes.* |   |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
- en: '|   | --*Morpheus (Matrix)* |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: If you took the blue pill, I hope that you didn't buy this book and got this
    far by reading the free sample. There are no hard feelings. We all have different
    aspirations and goals. If, on the other hand, you chose the red one, you are in
    for a ride. It will be like a roller coaster, and we are yet to discover what
    awaits us at the end of the ride.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你选择了蓝色药丸，我希望你没有买这本书，而是通过阅读免费的样本来获取这些内容。没有任何不快。我们每个人都有不同的追求和目标。另一方面，如果你选择了红色药丸，你将会经历一场奇妙的旅程。这就像过山车一样，我们还未能预见到在这场旅程结束时将会有什么等着我们。
