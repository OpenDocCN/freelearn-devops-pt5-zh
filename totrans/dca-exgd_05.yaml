- en: Container Persistency and Networking
  prefs: []
  type: TYPE_NORMAL
- en: Containers are processes that run on a host. This seems very simple, but how
    will this work on a pool of nodes? If we are looking for high availability, being
    able to run our containers on any host from a pool will ensure execution everywhere.
    But this approach requires some special logic in our applications. Our applications
    must be completely portable and avoid friction and dependencies on any host. Applications
    with many dependencies are always less portable. We need to find a way to manage
    status data for containers. We will review different persistence strategies in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the aforementioned pool of hosts must be able to communicate
    with all containers. In this chapter, we will learn about basic standalone host
    networking and introduce advanced cluster-orchestrated networking concepts.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will cover the differences between stateless and stateful
    applications, how volumes work and how can we use them, and how the Docker daemon
    provides networking on standalone environments. We'll also consider interactions
    between containers and how to publish services provided by processes running within
    containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding stateless and stateful containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning about different persistence strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Networking in containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning about container interactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Publishing applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about Docker volumes and networking concepts.
    We''ll provide some labs at the end of this chapter that will help you understand
    and learn about the concepts shown. These labs can be run on your laptop or PC
    using the provided Vagrant standalone environment or any already deployed Docker
    host of your own. You can find additional information in this book''s GitHub repository:
    [https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git](https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '"[https://bit.ly/34DJ3V4](https://bit.ly/34DJ3V4)"'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding stateless and stateful containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Portability is key in modern applications because they should run in every environment
    (on-premises or the cloud). Containers are prepared for these situations. We will
    also seek the high availability of applications in production, and containers
    will help us here too.
  prefs: []
  type: TYPE_NORMAL
- en: Not all applications are ready for containers by default. Processes' states
    and their data are difficult to manage inside containers.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 1](c5ecd7bc-b7ed-4303-89a8-e487c6a220ed.xhtml), *Modern Infrastructures
    and Applications with Docker*, we learned that containers are not ephemeral. They
    live in our hosts. Containers are created, executed, and stopped or killed, but
    they will remain in our host until they are deleted. We can restart a previously
    stopped container. But this is only true in standalone environments because all
    information resides under the host data path-defined directory (`/var/lib/docker`
    and `C:\ProgramData\docker` by default on Linux and Windows, respectively). If
    we move our workloads (that is, our application components running as containers)
    to another host, we will not have their data and state there. What happens if
    we need to upgrade their image versions? In that case, we could run a new container
    and everything will be recreated again. We can launch a new container, but we
    need to maintain all application data.
  prefs: []
  type: TYPE_NORMAL
- en: Previously, we introduced volumes as a method used to bypass the internal filesystem
    of containers and their life cycles. Everything inside a volume is, in fact, outside
    of the container's filesystem. This will help us with application performance
    using direct access to a host's devices' but it will also keep data. Volumes will
    persist even when containers are removed (unless we use `--volumes` or `-v` on
    removal). Therefore, volumes will help us maintain application data locally, but
    how about execution on other Docker hosts? We can share images, but a container's
    associated data will not be there unless we can also share volumes between them.
  prefs: []
  type: TYPE_NORMAL
- en: Under these circumstances, stateless processes – those that do not require any
    kind of persistent data to work – are easier to manage. These processes are always
    candidates to run within containers.
  prefs: []
  type: TYPE_NORMAL
- en: And what about stateful processes – those using persistent data between executions?
    We have to take care in this case. We should provide external volumes or databases
    to store the process's state and its required data. These concepts are very important
    when we design microservice-based application architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Let's deep dive into how volumes work.
  prefs: []
  type: TYPE_NORMAL
- en: Learning how volumes work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Previously, we learned how to define volumes in images to simply bypass a container''s
    filesystem. Here is a simple Dockerfile definition showing a defined volume (this
    is an excerpt from the PostgreSQL database official image):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We have omitted many lines because we just want to review the `VOLUME` definition.
    In this case, all data stored under the `/var/lib/postgresql/data` directory will
    be outside of the container's filesystem. This is an **unnamed volume** definition
    and it will be identified in our system by a random ID when we run a container
    using this image. It was defined for bypassing copy-on-write filesystems. Every
    time we create or run a new container, a new random identifier volume will be
    created. These volumes should be removed manually or by using the `--volume` or
    `-v` options when we remove their associated containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, it is time to define the different volumes types we can have on Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unnamed volumes**: These are the volumes that are defined on images and therefore
    created using random identifiers. It is hard to track them on local filesystems
    because they are unnamed. As volumes can grow very fast, depending on your application,
    it is very important to check for volume definitions before running any image
    on your local system. Remember that unnamed volumes will grow under your Docker
    data root path, wherever it is.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Named volumes**: These are the volumes we create manually. As we learned
    in [*Chapter 1*](c5ecd7bc-b7ed-4303-89a8-e487c6a220ed.xhtml), *Modern Infrastructures
    and Applications with Docker*, volumes are Docker objects and we have some actions
    to control them. In this chapter, we will learn about their associated actions
    and how to use them. These volumes will be located under the data root path also,
    but we can use different plugins or drivers to create them. Drivers will allow
    local or remote volumes, via NFS for example. In these cases, what we will have
    under the data root path is a link to the real mounted remote filesystem. Consequently,
    these volumes will not consume local storage if they are remote.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Localhost directories or files**: In this case, we will use host directories
    and files inside containers. We usually refer to these volumes as **bind mounts**.
    We must take care of file and directory permissions because we can also use any
    special file inside containers (including devices). Adding permissions that are
    too open will give users access to your host''s devices. They will require appropriate
    process capabilities and permissions. It is important to understand that Docker
    does not care about how block devices, directories, and filesystems are mounted
    on the Docker host. They will be used always as if they were locally available.
    Bind mounts will not be listed as volumes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tmpfs volumes**: This kind of volume is temporal. They will only persist
    in the host memory. When the container stops, the volume will be removed. Files
    inside them will not persist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All kinds of volumes can be mounted in read-only mode inside containers. This
    is very important and useful when volume data shouldn't be modified by running
    processes, for example, when serving static web content. We can have containers
    that should be able to modify data and others that will only read and serve this
    modified data using read-only mode.
  prefs: []
  type: TYPE_NORMAL
- en: Named volumes or bind mounts will retain data. Unnamed volumes will be created
    with new containers. Keep this in mind. If we need to provide some data to an
    unnamed volume, it should be done when the container starts. We can also define
    a procedure in the image definition. This concept is very important as the position
    of the `VOLUME` definition in Dockerfiles matters. As we learned in [Chapter 2](3952ec16-ca49-4bc2-b7e6-d6f17fec3fab.xhtml),
    *Building Docker Images*, image creation is based on a sequence of container executions.
    If we add a volume for a specific path, all subsequent executions will not retain
    data in that directory. The building process will create a new unnamed volume
    on each new container and content will not be used between executions.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about volume object actions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Volumes can be created, used, and removed. We will also be able to inspect
    all their properties. The following table shows the actions that are allowed for
    volume objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Objects** | **Actions** |'
  prefs: []
  type: TYPE_TB
- en: '| `create` | We are able to create named volumes. We can add labels for filtering
    the listing output, as we learned in previous chapters. We can specify the driver
    to be used for creating a new volume. By default, volumes will use a local driver.
    This driver will create directories under the `volumes` directory. Each new volume
    will have its own directory containing the required meta-information and a **`_data`**subdirectory.
    This directory contains all files added to the volume. As we mentioned previously,
    some drivers will provide host external storage resources. Linked directories
    will provide connection information instead of their data.We will use `--driver`
    to specify a driver other than `local`. The `--opt` or `-o` arguments allow us
    to add required options for the specified driver. Each driver will have its own
    special options. |'
  prefs: []
  type: TYPE_TB
- en: '| `inspect` | All objects can be inspected. In this case, the `inspect` action
    will provide information about the object''s location, the driver used, and the
    labels provided. |'
  prefs: []
  type: TYPE_TB
- en: '| `ls` | We can list all volumes using the `ls` action. Almost all filtering
    and formatting options learned throughout this book can be applied. Formatting
    will also depend on a given volume''s properties. |'
  prefs: []
  type: TYPE_TB
- en: '| `prune` | The `prune` option will help us with volume housekeeping. It will
    remove all created volumes not used by any container. It will not delete any bind
    mount because they are not really treated as volumes. |'
  prefs: []
  type: TYPE_TB
- en: '| `rm` | We can remove volumes using the `rm` action. It is important to note
    that volumes attached to existing containers cannot be removed. Containers should
    be removed before volumes. Alternatively, you can use the `--volumes` option on
    container removal. |'
  prefs: []
  type: TYPE_TB
- en: Now, let's introduce how containers use volumes.
  prefs: []
  type: TYPE_NORMAL
- en: Using volumes in containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we will start with unnamed volumes. These are volumes defined in a container''s
    images. As we mentioned previously, always review images before execution. If
    we run an application that stores a huge amount of data on a predefined unnamed
    volume, our Docker host can run out of disk space. It is very important to review
    what image will run and what resources will be required. If we take a quick view
    of the `postgres:alpine` image (the PostgreSQL database image based on Alpine
    Linux), for example, we will find a volume definition (we first pull the `postgres:alpine`
    image from Docker Hub):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, `postgres:alpine` will define an unnamed volume to bypass the
    copy-on-write container filesystem to allow a process to write or modify any content
    under the `/var/lib/postgresql/data` directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a container named `mydb` using the `postgres:alpine` image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can inspect the `mydb` container, looking for its mount points (identifiers
    will be different in your system):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the obtained volume identifier, we can review its properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The output shows where this volume is mounted on our host (`/var/lib/docker/volumes/c888a831d6819aea6c6b4474f53b7d6c60e085efaa30d17db60334522281d76f/_data`)
    and what container is using it that it's mounted on (`/var/lib/postgresql/data`).
  prefs: []
  type: TYPE_NORMAL
- en: 'If we take a look at the `/var/lib/docker/volumes/c888a831d6819aea6c6b4474f53b7d6c60e085efaa30d17db60334522281d76f/_data`
    directory, we can list all PostgreSQL database data files (notice in the following
    log that the directory is owned by root, so root access will be required):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Notice that files and directories are owned by `userid` (`70`) and `groupid`
    (`70`). This is because the container's main process is not running under the
    root user and, as a result, all files created by the PostgreSQL process will be
    owned by an internal `postgres:postgres` user, whose ID may be different or even
    may not exist on our host. This is the ID used within the container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s stop the `mydb` container and check our volume. You will see that the
    volume is still in our system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Again, we can start our `mydb` container and it will reuse its volume data.
    If we had added data to this database, we would still be able to access it, because
    the volume persists our data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s remove the `mydb` container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can verify that the volume is still under `/var/lib/docker/volumes`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Volumes survive containers unless we use `--volume` to remove them with its
    associated container. We can also reuse volume content with other containers.
    But unnamed containers are not easy to manage because they are identified only
    by a digest. We will remove this volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s create a volume named `mydata`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we can create a new container using this volume and its content
    will be available for our new process.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand that the `VOLUME` definition in an image is not
    required to use volumes on containers. But they will help us understand what directories
    should be managed out of the container filesystem. Good container images will
    define the directories where persistent data should be stored.
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker containers can mount volumes using two different options in terms of
    container creation or execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `--volume` or `-v` | We will use this option with three arguments, separated
    by `:`. We will use the last argument to declare what type of access will be provided
    (read-only or read-write). The second argument will indicate the container''s
    directory or file where the volume will be mounted within the container. The first
    argument will be different, depending on what type of resource we are using. If
    we are using bind mounts, we will use them as a file or directory in the host.
    If we are using named volumes, this argument will declare which volume will be
    mounted inside the container. |'
  prefs: []
  type: TYPE_TB
- en: There are other options for the third argument when using the `--volume` option.
    In addition to read or write access, we can specify `z` or `Z` when we use SELinux.
    If the volume is going to be shared between multiple containers, we will use these
    options to declare the volume content as private and unshareable.
  prefs: []
  type: TYPE_NORMAL
- en: '| `--mount` | This notation allows more arguments than `--volume`. We will
    use the key/value format to declare multiple options. The available keys are as
    follows:**- type**: Values available are `bind`, `volume`, or `tmpfs`.**- source
    (or src)**: This will describe the volume or host path.**- destination (or dst
    or target)**: This describes the path where the volume content will be mounted.**-
    readonly**: This identifies the access type for the volume content. |'
  prefs: []
  type: TYPE_TB
- en: There is only one difference between using the `--volume` and `--mount` options.
    Using `--volume` will create the endpoint if we specify a path that does not exist
    in the Docker host when using bind mounts, while `--mount` will raise an error
    in this instance and it will not be created.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we''ll start an `alpine` container using the defined volume mounted in
    `/data`. We named it `c1` here. We will just touch a file under its `/data` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'After exiting the container, we can list the files under the `mydata` volume
    filesystem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can create a new container and reuse our previously created named volume,
    `mydata`. In this example, we will mount it under `/tmp`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, both containers, `c1` and `c2`, have mounted the `mydata` volume. Consequently,
    we can''t remove the `mydata` volume unless both are removed from the local system
    (even if we use `--force` for removal):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We will only be able to remove the `mydata` volume when both containers have
    been removed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's learn about some strategies and use cases for storing persistent
    data in containerized environments.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about different persistence strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we've already learned, there are different approaches to persistence in containers.
    Choosing the right solution will depend on the use case or requirements of the
    environment and our applications.
  prefs: []
  type: TYPE_NORMAL
- en: Local persistence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will use local directories or files whenever we are deploying applications
    on isolated and standalone Docker daemons. In this approach, you should take care
    of filesystem permissions and secure module configurations. This strategy is quite
    interesting for developers as they can run multi-container applications on their
    laptops using local source code files inside containers. Therefore, all changes
    made on their local files will be synced within the containers (in fact, they
    will not quite be synced; rather, they are the same files that are mounted inside
    the container filesystem as a bind mount volume). We will review some examples
    of this in the *Chapter labs* section. This solution will not provide high availability.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed or remote volumes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These are the preferred solutions for orchestrated environments. We should provide
    a pool of distributed or remote storage endpoints to allow applications to run
    everywhere within the cluster. Depending on your applications, volume speed could
    be key for deciding which driver to use. We will also have different choices regarding
    cloud providers. But for common use cases with static content, **Network File
    System** (**NFS**) will be fine. While it would not be enough for databases or
    high I/O application requirements, locking filesystem files is needed when we
    scale instances using shared resources. The Docker daemon will not manage these
    situations as they are out of Docker's scope. Volume I/O and file locking will
    really depend on the application logic and its architecture. Neither distributed
    nor remote volume solutions will provide high availability. In fact, Docker doesn't
    really know anything about storage. It just cares about volumes, no matter how
    storage was implemented on your host.
  prefs: []
  type: TYPE_NORMAL
- en: Volume drivers provide extensions to extend Docker's out-of-the-box features.
    The Docker plugin system changed in version 1.12 of Docker. Therefore, we refer
    to old plugins as *legacy plugins*, which are not managed using `docker plugin`
    actions. We can find a list of legacy volume plugins at [https://docs.docker.com/engine/extend/legacy_plugins/#volume-plugins](https://docs.docker.com/engine/extend/legacy_plugins/#volume-plugins).
    New plugins are always managed using `docker plugin` command-line actions. These
    plugins may require special capabilities because they should be able to execute
    privileged actions at the host system level. We will review a quick lab at the
    end of this chapter, where we'll use the `sshfs` plugin.
  prefs: []
  type: TYPE_NORMAL
- en: These described use cases are closer to data management. But what about the
    application state? This is usually managed using volumes, but it really depends
    on your application architecture. One recommendation for new application development
    projects is to track the application state out of containers or even volumes.
    This makes it easier to manage instance replication when we need to scale up or
    down some components. But remember, it should be managed at the application level.
    Docker will just manage how your containerized application components run; it
    will not manage their application states or dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to manage container data and their states using persistent
    volumes, let's get into networking features.
  prefs: []
  type: TYPE_NORMAL
- en: Networking in containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already learned that containers are processes that run isolated on top
    of host operating systems. This isolation is provided using different namespaces
    for users, processes trees, inter-process communications, and a set of complete
    network resources for each containerized process. Therefore, each container will
    have its own network interfaces. To be able to communicate with the world, by
    default, the Docker daemon will create a bridged interface called `docker0`. The
    Docker network plane has not changed too much in the latest releases. It can be
    extended using external tools and plugins and is based on bridged and virtual
    network interfaces that connect hosts and container resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, a fresh Docker installation will show three network objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As we have already learned, all objects are identified by their unique ID. The
    Docker network listing shows the network `NAME` (we can set our own network name),
    `DRIVER` (the network type), and `SCOPE` columns (indicating where this network
    will be available). There are different types of networks, according to which
    network driver containers will be used to attach to that network.
  prefs: []
  type: TYPE_NORMAL
- en: Besides all common object actions such as `create`, `list` (using `ls`), `inspect`,
    and `remove` (using `rm` or `prune`), networks also have `connect` and `disconnect`
    actions in order to attach or detach containers to/from them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s review some of the creation options before deep diving on each network
    type:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Option** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `--attachable` | This option enables manual container attachment. It is not
    required for locally scoped networks. |'
  prefs: []
  type: TYPE_TB
- en: '| `--aux-address` | Using `--aux-address`, we can add a host and its addresses
    to this network. For example, we can use `--aux-address="mygateway=192.168.1.10"`
    to set a specific host-to-IP mapping on the declared network. It is usually used
    on `macvlan` networks. |'
  prefs: []
  type: TYPE_TB
- en: '| `--config-from`and`--config-only` | We can create (or reuse previously created)
    network configurations. This is very useful for building configurations using
    automation tools, for example, on different hosts and being able to use them when
    needed. |'
  prefs: []
  type: TYPE_TB
- en: '| `--driver` or `-d`and`--opt` | This option allows us to specify which driver
    to use. By default, we can only use `macvlan`, `none`, `host`, and `bridge`. But
    we can extend Docker''s networking capabilities using other external plugins.
    We will use `--opt` to customize the applied driver. |'
  prefs: []
  type: TYPE_TB
- en: '| `--gateway` | We can overwrite the default gateway (the lower IP address
    of the defined subnet, by default) and specify another IP address for this purpose.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `--ingress` | This option will be used in cases where we want to create a
    special Swarm vxLan network for internal service management. |'
  prefs: []
  type: TYPE_TB
- en: '| `--internal` | This option is only available on overlay networks. We will
    only use it to define internal networks because, by default, all overlay networks
    will be attached to the `docker_gwbridge` bridge network (created automatically
    when operating on a Swarm) to provide external connectivity. |'
  prefs: []
  type: TYPE_TB
- en: '| `--ip-range` | Once we have configured a subnet, we can specify a range of
    IP addresses to be used for containers. |'
  prefs: []
  type: TYPE_TB
- en: '| `--ipam-driver`and`--ipam-opt` | With these options, we can use an external
    IP address management driver. |'
  prefs: []
  type: TYPE_TB
- en: '| `--ipv6` | We will use this option to enable IPv6 on this network. |'
  prefs: []
  type: TYPE_TB
- en: '| `--label` | With this, we can add metadata information to networks for better
    filtering. |'
  prefs: []
  type: TYPE_TB
- en: '| `--scope` | With this option, we declare the scope where the network will
    be created for local or Swarm usage. |'
  prefs: []
  type: TYPE_TB
- en: '| `--subnet` | This specifies a subnet in CIDR format that represents a network
    segment. |'
  prefs: []
  type: TYPE_TB
- en: Once created, network objects will exist until they are removed. But removal
    is only possible when no containers are attached to them. It is important to understand
    that dead containers will still have endpoints configured for existing networks
    and must, as a result, be deleted before network removal. On the other hand, the
    `prune` action will remove all unused networks.
  prefs: []
  type: TYPE_NORMAL
- en: Docker manipulates the `iptables` rules for you every time a network is created
    or some connection or container process publication must be implemented. You can
    avoid this feature, but we strongly recommend allowing the Docker daemon to manage
    these rules for you. It is not easy to track unexpected behaviors and there will
    be many rules to manage.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the basic `create` command options under our belts, let's look
    at the different standard networks we can create.
  prefs: []
  type: TYPE_NORMAL
- en: Using the default bridge network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bridge is the default network type for all containers. Any other network types
    must be declared on container creation or execution using the `--network` optional
    parameter.
  prefs: []
  type: TYPE_NORMAL
- en: In operating system terms, we use bridged interfaces to allow forwarded traffic
    from other virtual interfaces. All those virtual interfaces will use a physical
    interface, associated with the bridge, to talk to other network devices or connected
    hosts. In the world of containers, all container interfaces are virtual and they
    will be attached to these bridge interfaces at the host level. Therefore, all
    containers attached to the same bridge interface will see each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at a quick example of using a bridge network:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We just run two containers, `c1` and `c2`, attached to the default network
    (notice that we have not defined any network at all):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We find their IP addresses:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Consequently, we can ping each of them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s quickly review some of the `c1` container properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Each container will have its own IP address and `EndpointID`. Let''s inspect
    the bridge network''s configuration (created by Docker by default):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s talk about some of the most important sections in this output:'
  prefs: []
  type: TYPE_NORMAL
- en: This network is not using IPv6\. It's called `bridge`, was created using the
    `bridge` driver, and will only be available locally on this host.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It was created using the `172.17.0.0/16` subnet and consequently, all containers
    on this network will get an IP address on this segment range.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bridge interface has the IP address `172.17.0.1` and will be the default
    gateway for all containers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have two running containers on this network. They are both listed under the
    `Containers` section with their virtual MAC addresses, IP addresses, and associated
    endpoints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are a number of options that can be used during network creation that
    are of interest:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`com.docker.network.bridge.default_bridge: true`: This means that this is the
    default bridge when no network is defined.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`com.docker.network.bridge.enable_icc: true`: This parameter indicates that
    containers connected to this network can talk to each other. We can disable this
    feature on custom bridges, allowing just North-South traffic.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`com.docker.network.bridge.name: docker0`: This is the name of the associated
    host interface.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: When we refer to *North-South traffic*, we mean the type of communication that
    goes out of the Docker host to the containers and vice versa. On the other hand,
    *East-West traffic* is the traffic between different containers. These are references
    to well-known network terms that are applied to describe network traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding null networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Null or none networks are used when we need to deploy a container that should
    run without any network interface. Although it might sound useless, there are
    many situations where we may need to launch a task for executing a mathematical
    operation, compression, or many other examples that don''t require networking
    capabilities. In these cases, we just need to use volumes and we really do not
    need any network operation. Using a null network ensures that the task will only
    have access to its required resources. If it does not require network access,
    do not provide it. By default, the container will use a `bridge` network unless
    we specify `none`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Now that we understand that containers can have a null interface to avoid networking,
    we can look at the host's network namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the host network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Host networking is only available on Linux hosts. This is important because
    it is an important difference in Windows containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using host networking, the container shares the `host` networking namespace.
    Therefore, the container will get all host IP addresses, and every port that''s
    used at the container level will be set on the host. Consequently, no more than
    one container using a specific given port will be allowed to run at a time. But,
    on the other hand, network performance is better because container services are
    directly attached to host ports. There isn''t any NAT or firewall rule adaptation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Here, you can see that all host interfaces are listed because the container
    is using its network namespace.
  prefs: []
  type: TYPE_NORMAL
- en: This networking mode is risky because we are allowing any kind of communication
    on the containers. This should be used with care in **privileged mode**. It is
    very common in monitoring tools or when we run applications that require high
    levels of network interface performance.
  prefs: []
  type: TYPE_NORMAL
- en: We can define our own network interfaces. We'll create custom bridge networks
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating custom bridge networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we discussed in the default bridge network example, this networking type
    will be associated with host `bridge` interfaces. By default, it is attached to
    `docker0`, but every time we create a new bridge network, a new `bridge` interface
    will be created for us and all attached containers will have a virtual interface
    linked to this one.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few very important differences between a default bridge network
    and custom created ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Custom bridge isolation**: Each new custom bridge network created will have
    its own associated bridge with its own subnet and host `iptables`. This feature
    provides a higher level of isolation as only attached containers can talk to each
    other. All other containers running on the same host will not *see* these containers
    running on custom bridge networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Internal DNS**: The Docker daemon provides a custom DNS for each custom bridge
    network. This means that all containers running on the same network will know
    each other by name. This is a very important feature because your service discovery
    will not need any external source of knowledge. But remember that this is valid
    only for internal usage within the network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can provide this kind of DNS resolution on default bridge networks using
    the legacy `--link` functionality. This was the way of interconnecting containers
    on old Docker releases. Nowadays, using custom bridge networks is considered as
    providing better isolation.
  prefs: []
  type: TYPE_NORMAL
- en: '**On-the-fly container attachment**: In default bridge networks, we must provide
    connectivity in terms of container creation or execution. Imagine that we used
    a null or none network for a container and we want to attach it to a default bridge
    network later – this is not possible. Once a container is created, it can''t be
    attached to a default bridge network later. It must be recreated from the beginning
    with that network attachment. On the other hand, custom bridge networks are attachable,
    which means that we can consider a situation where our container was created without
    a specific attachment and can add it later. We can also run a container with multiple
    interfaces on different custom networks, with its name resolution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s review a quick example. We will provide more detailed examples in the
    *Chapter labs* section of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We review the created network properties (notice the defined subnet) and internal
    settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we create a container and test internet access:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Remember to use the *Ctrl* + *P* + *Q* shortcut to leave the `intc1` container
    running in the background.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may have noticed that we do not have any egress connectivity. Let''s review
    the internal connectivity with another container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: As shown in the preceding output, we have internal communication and DNS resolution,
    but we are unable to talk to any other external IP address.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we take a look at `iptables`, we can see that the creation of the internal
    network added some very interesting rules to our local firewall. Executing `iptables
    -L` and avoiding all non-Docker related rules, we can observe these rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: These are the rules that manage the internal network isolation we created previously.
  prefs: []
  type: TYPE_NORMAL
- en: We will examine some multi-interface examples toward the end of this chapter
    in the *Chapter labs* section.
  prefs: []
  type: TYPE_NORMAL
- en: The MacVLAN network – macvlan
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The MacVLAN driver assigns a virtual MAC address to each container interface.
    Consequently, a container will be able to manage its own IP address on the real
    network. To manage this type of network interface, we need to declare a host physical
    interface. As containers will get their own MACs, we can use VLANs on these interfaces
    to provide containers with access only to the defined VLAN. But note that in these
    cases, we will need to assign all required VLANs to the `macvlan` assigned host
    interface.
  prefs: []
  type: TYPE_NORMAL
- en: The `macvlan` driver will only work on Linux hosts (with a kernel version above
    3.9; 4.0 is recommended). This kind of interface is usually blocked on cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a result, we have described two different modes for `macvlan`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bridge mode**: In this case (the default one), traffic will go through the
    defined host physical interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**802.1q trunk bridge mode**: Traffic will go through an 802.1q VLAN interface,
    created by the Docker daemon on network creation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In these networks, we usually use `--aux-address` to add existing nodes or network
    devices to this newly created Docker network.
  prefs: []
  type: TYPE_NORMAL
- en: We have been reviewing different interfaces that are provided by Docker out
    of the box. Now, let's continue our journey and understand how these communications
    happen at the host level.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about container interactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two different types of communication in container environments:'
  prefs: []
  type: TYPE_NORMAL
- en: Communication with the external world
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inter-container communications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll take a look at both of these in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Communication with the external world
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two features at the host level that are required to allow containers
    to talk to the external world:'
  prefs: []
  type: TYPE_NORMAL
- en: IP forwarding is required to allow packets from container IP addresses to go
    outside the containerized environment. This is done at the kernel level and the
    Docker daemon will manage the required parameters (the `ip_forward` kernel parameter
    will be set to `1`) to allow this strategy. We can change this default behavior
    setting with `--ip-forward=false` in the daemon configuration. This forwarding
    is required for all kinds of communications between containers in general.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`iptables` will manage the required rules to strictly allow only required communications
    once forwarding is enabled. We can manually set `iptables` rules, instead of allowing
    the Docker daemon to take care of these settings, using the `--iptables=false`
    option in the daemon configuration. It is recommended to allow the Docker daemon
    to manage these rules unless you are sure of what changes to implement. Docker
    will only manage `DOCKER` and `DOCKER-ISOLATION` filter chains and we are able
    to manage custom rules in the `DOCKER-USER` chain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, Docker forwards all packets and permits all external source IP addresses.
    If we need to allow only required IP addresses, we can add custom rules to `DROP`
    all non-permitted communications.
  prefs: []
  type: TYPE_NORMAL
- en: Inter-container communications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can also manage inter-container communications with IP forwarding and `iptables`.
    As we've already learned, we can use `--internal` on network creation to only
    allow internal communications. Any other communication out of this defined subnet
    will be dropped.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, we can disallow any inter-container communication by applying
    `--icc=false`. This option manages the internal interaction within containers
    linked to the same bridge. If we set this parameter to `false`, no inter-container
    communication will be allowed, even if they are running on the same subnet. This
    is the most secure network configuration because we can still allow specific communications
    using the `--link` option. Container links will create special `iptables` rules
    to allow these specific communications.
  prefs: []
  type: TYPE_NORMAL
- en: DNS on custom bridge networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We've already learned that custom bridge networks own an internal DNS. This
    means that any container interaction can be managed using container names. This
    internal DNS will always run on `127.0.0.11`. We can modify some of its features,
    such as adding new hosts, for example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s review some of the common features that can easily be manipulated to
    improve application discovery and interactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Features** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `--network-alias=ALIAS` | This option allows us to add another internal DNS
    name to a container. |'
  prefs: []
  type: TYPE_TB
- en: '| `--link=CONTAINER_NAME:ALIAS` | We have been talking about the link option
    for legacy environments. It is also a way to allow specific communications when
    no container interaction is allowed by default. This option will also add an entry
    to the internal DNS to allow the resolution of `CONTAINER_NAME` as a defined `ALIAS`.
    This use case is different to `--network-alias` because it is used on different
    containers. |'
  prefs: []
  type: TYPE_TB
- en: '| `--dns`,`--dns-search`,and `--dns-option` | These options will manage forwarded
    DNS resolution in cases where an internal DNS cannot resolve a defined name. We
    can add a forwarder DNS, with its specific options to allow or disallow external
    searches for some containers. This will help us use different name resolutions
    to access internal or external applications. |'
  prefs: []
  type: TYPE_TB
- en: Now that we have learned about the different interfaces that are available and
    how communications work at the host system level, let's go ahead and learn how
    applications will be accessed from the client side. We have just introduced `iptables`
    as a mechanism to gain that access automatically when deploying containers on
    different networks. In the next section, we will deep dive into publishing application
    methods for standalone Docker hosts.
  prefs: []
  type: TYPE_NORMAL
- en: Publishing applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, all container processes are isolated from outside access. This means
    that although we had defined a port for the process service (using `EXPOSE` on
    images), it will not be accessible unless we declare it publicly available. This
    is a great security measure. No external communication will be allowed until it
    is specifically declared. Only containers attached to the same bridged network
    or host, using its host internal IP (attached to the bridge), will be able to
    use the process service.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s review a quick example using the `nginx:alpine` base image. We know
    that `nginx:alpine` exposes port `80`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Our host IP on the default bridge network is `172.17.0.1` in this case, and
    we can reach container port `80`, but no other host will be able to reach this
    port. It is exposed internally by a `webserver` container.
  prefs: []
  type: TYPE_NORMAL
- en: To publish a port exposed internally, we need to declare it during container
    creation or execution using the `--publish` or `-p` parameters.
  prefs: []
  type: TYPE_NORMAL
- en: We will use `--publish [HOST_IP:][HOST_PORT:]CONTAINER_PORT[/PROTOCOL]` for
    this. This means that the only required argument is the container port. By default,
    the TCP protocol and a random port between `32768` and `65000` will be used, and
    the port will be publicly published on all host IP addresses (`0.0.0.0`). We can
    also use `-P` to publish all ports exposed in a given container's image definition.
  prefs: []
  type: TYPE_NORMAL
- en: If we need to declare a UDP application publication, we need to specify this
    protocol.
  prefs: []
  type: TYPE_NORMAL
- en: Host mode networking does not require any publication of ports because any exposed
    container process will be accessible from outside.
  prefs: []
  type: TYPE_NORMAL
- en: We can declare a range of ports in the form `--publish StartPort-EndPort[/PROTOCOL]`
    to publish more than one port.
  prefs: []
  type: TYPE_NORMAL
- en: 'For security reasons, it is important to use a specific IP address on multi-homed
    hosts in order to only allow access to specified IP addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We will see more examples of this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter labs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter was dedicated to learning how to manage stateful environments and
    the magic behind container networking. Now, let's complete some labs to review
    what we've learned. For these labs, we will use a CentOS Linux host with a Docker
    engine installed.
  prefs: []
  type: TYPE_NORMAL
- en: Deploy `environments/standalone-environment` from this book's GitHub repository
    ([https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git](https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git))
    if you have not done so yet. You can use your own CentOS 7 server. Use `vagrant
    up` from the `environments/standalone-environment` folder to start your virtual
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using a standalone environment, wait until it is running. We can
    check the statuses of our nodes using `vagrant status`. Connect to your lab node
    using `vagrant ssh standalone`. `standalone` is the name of your node. You will
    be using the `vagrant` user with root privileges using `sudo`. You should have
    the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now connect to the standalone node using `vagrant ssh standalone`. This
    process may vary if you deployed a standalone virtual node previously and you
    just started it using `vagrant up`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are reusing your standalone environment, this means Docker Engine is
    installed. If you started a new instance, please execute the `/vagrant/install_requirements.sh`
    script so that you have all the required tools (Docker Engine and `docker-compose`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Now, you are ready to start the labs.
  prefs: []
  type: TYPE_NORMAL
- en: Using volumes to code on your laptop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this lab, we will run a container with our application code inside. As the
    application is created using an interpreted language, any change or code modification
    will be refreshed (we added debugging to reload the application on each change
    using `debug=True`):'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve created a simple Python Flask application for you. The following is
    the content of the `app.py` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We only require the `Flask` Python module, so we will only have one line in
    our `requirements.txt` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use a simple template HTML file under `templates/index.html` with this
    content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We will run this application inside a container. We will create a Dockerfile
    and build an image called `simpleapp`, with a tag of `v1.0`. This is the content
    of the Dockerfile:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s build our application image (`simpleapp:v1.0`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We can run this simple application by executing a detached container exposing
    port `5000`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can review the container''s IP address. We are running this container
    in a host, which means we can access the process port and defined IP address:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We can access our application as expected using the container''s defined IP
    and port:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'It is simple to change `index.html` if we get into the container. The problem
    is that when we run a new container, changes will not be stored and `index.html`
    will be lost. Every time, we will get `index.html` defined in the base image.
    As a result, if we want changes to persist, we need to use volumes. Let''s use
    a bind mount to change the `index.html` file while the container is running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now change `templates/index.html` because we have used `-v $(pwd)/templates:/app/templates`,
    assuming the current directory. Using the vi editor, we can modify the content
    of the `templates/index.html` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'We change the line containing the `Version` key and we access it again using
    `curl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The changes are reflected because we did them on our host filesystem and it
    is mounted inside our container. We can also change our application code by mounting
    `app.py`. Depending on what programming language we are using, we can change the
    application code on the fly. If changes must be persistent, we need to follow
    a versioning strategy. We will build a new image with the required changes.
  prefs: []
  type: TYPE_NORMAL
- en: Mounting SSHFS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this lab, we will install and use the `sshfs` volume plugin:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to install the `sshfs` plugin:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s review our host IP address and start the `sshd` or `ssh` daemons (depending
    on your system and whether it is already running):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s review the installed plugin:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Since plugins are objects, we can inspect installed plugins. We can review
    important aspects such as version, debug mode, or the type of mount points that
    will be managed with this plugin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will create a new volume named `sshvolume` (we assume that you have
    a valid SSH username and password here). Notice that we''re using `127.0.0.1`
    and the `/tmp` directory or filesystem for demo purposes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can easily run an `alpine` container by mounting previously created
    `sshvolume`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Let's continue with some network labs.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-homed containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now look at a quick lab on attaching containers to multiple networks.
    Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll create two different zones, `zone-a` and `zone-b`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can start a container named `cont1` on `zone-a`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we connect the `cont1` container to `zone-b` and review its IP addresses:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can run two containers with just one interface. One of them will run
    attached to `zone-a`, while the other one will just be attached to `zone-b`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s review the IP addresses and routes on both containers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want the `cont3` container to contact the `cont2` container, we should
    add a route through the `cont1` container, which contains both networks. In the
    `cont2` container, enter the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `cont3` container, enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember that we don''t have name resolution between different networks. Therefore,
    we cannot reach `cont2` using its name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: As we expected, name resolution within the `zone-a` network works fine. Any
    other container on another network will not be able to resolve containers by their
    names.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should be able to ping from `cont3` to `cont2` using its IP address:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: So, although we do not have name resolution, we can reach containers on other
    networks using a container gateway that has interfaces on all networks. For this
    to work, we added a route to each network container to route all other network
    traffic to the gateway container. We could have added aliases to reach other network
    containers by name. Try it yourself – it's easy!
  prefs: []
  type: TYPE_NORMAL
- en: Publishing applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this lab, we are going to deploy a simple three-layer application. In fact,
    it''s a two-layer application with the addition of a load balancer for our lab
    purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll create a bridge network named `simplenet`, where we will attach
    all application components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We will deploy a PostgreSQL database with `changeme` as the password for the
    root user. We created a simple database named `demo` with a `demo` user and a
    password of `d3m0` for this lab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we have not published any port for the database.
  prefs: []
  type: TYPE_NORMAL
- en: Never use environment variables for secure content. There are other mechanisms
    to manage this kind of data. Use the secrets functionality of Docker Swarm or
    Kubernetes to provide security for these keys.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to launch the backend application component, named `simpleapp`.
    Notice that in this case, we used many environment variables to configure the
    application side. We set the database host, database name, and the required credentials,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: We have not published the application. Therefore, it is only accessible locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s review the application component IP addresses deployed. We will inspect
    the containers attached to `simplenet`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'If we take a look at the exposed (not published) ports on each image definition,
    we will observe the following in the database component:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'In the application backend, we will observe the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have all the required information to test the connections to both components.
    We can even use the `curl` command to test whether the server is a database server.
    Let''s try the database with an IP address of `172.22.0.3` on port `5432`. We
    will use `curl -I` because we don''t really care about the response content. We
    just want to be able to connect to the exposed port:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, `Empty reply from server` is `OK` (it does not use the HTTP protocol).
    The database is listening on that IP-port combination. The same will happen on
    the application backend on IP address `172.22.0.4` and port `3000`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: In this situation, we will be able to open `http://172.22.0.4:3000` in the browser.
    The application will be visible, but it can only be consumed locally. It hasn't
    been published yet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s deploy the load balancer component. This component will publish a port
    on our host. Notice that we added two environment variables to allow the load
    balancer to connect to the backend application (we configured the load balancer
    on the fly with these variables because this image is modified for this behavior):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at our local `iptables`. The Docker daemon has added a NAT
    rule to guide traffic from port `8080` to port `80` on the load balancer component:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the load balancer will be available on all host IP addresses because
    we have not set any specific IP in the publish option.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, open `http://localhost:8080` in your web browser. You will be able to
    consume the deployed application. You will see the following GUI in your browser:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9f8bdd0c-3c63-488a-9b32-bad2d56a8754.png)'
  prefs: []
  type: TYPE_IMG
- en: This GUI is, in fact, the application backend's front page. As we mentioned
    previously, it is not a real three-layer application. We added a load balancer
    as a frontend just to be able to publish it and add some rules there.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure that the application only listens on the required interfaces, we can
    specify them to avoid unsecured ones. Always use a specific IP address with the
    `--publish` option (for example, `--listen MY_PUBLIC_IP_ONLY:8080:80`) to publish
    your application on a defined IP address.
  prefs: []
  type: TYPE_NORMAL
- en: In this lab, we published a simple application and ensured that only specific
    components are visible externally. Remember that it is possible to use container
    gateways and internal-only networks. These features will improve application security.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this chapter, we have reviewed how to manage data associated with
    containers. We took a look at different strategies to manage the data of processes
    and their statuses. We used host filesystems and unnamed and named volumes, and
    we learned how to extend the available Docker daemon volume management functionality
    by using plugins. We noticed that the Docker daemon will not take care of any
    application lock or even determine how storage resources are defined at the host
    level.
  prefs: []
  type: TYPE_NORMAL
- en: There are two different options for mounting volumes or bind mounts on containers
    using `--volume` or `--mount`. We also reviewed all the parameters required and
    the differences between them.
  prefs: []
  type: TYPE_NORMAL
- en: We talked about how to manage data and process states in high-availability environments.
    We haven't introduced any orchestration concepts yet, but it is important to understand
    that high availability or multiple instances of a process will require special
    application logic. Docker will not manage that logic and this is something you
    must be aware of.
  prefs: []
  type: TYPE_NORMAL
- en: We also introduced some basic networking concepts. We explained the different
    types of networks we can use out of the box on the Docker daemon and the special
    features of each one. We then reviewed the interactions between containers and
    how they can talk to external networks. Lastly, we finished this chapter by learning
    how to publish application processes running inside containers.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will introduce you to how to run applications on multiple containers.
    We will learn how an application's components run and interact.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we reviewed container persistency and networking in non-cluster
    environments. Let''s verify our understanding of these topics with some questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Which of the following statements is not true?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Containers are not ephemeral – once created, they will stay in the host unless
    they are removed.
  prefs: []
  type: TYPE_NORMAL
- en: b) We can run more than one container at a time using the same image.
  prefs: []
  type: TYPE_NORMAL
- en: c) Containers created from the same image share their filesystems.
  prefs: []
  type: TYPE_NORMAL
- en: d) All of these statements are false.
  prefs: []
  type: TYPE_NORMAL
- en: Which methods are allowed when creating a volume?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) We can manually create a volume using the `docker volume create` command
    for volume objects.
  prefs: []
  type: TYPE_NORMAL
- en: b) We can declare a `VOLUME` sentence in a Dockerfile to use a volume on containers
    created from a built image.
  prefs: []
  type: TYPE_NORMAL
- en: c) We can use Docker host filesystems inside containers as if they were Docker
    volumes.
  prefs: []
  type: TYPE_NORMAL
- en: d) Volume creation is only allowed in terms of container creation or execution.
  prefs: []
  type: TYPE_NORMAL
- en: When we remove a container, all associated volumes will be removed. Is this
    true?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) This is false. You need to use the `--force` or `-f` option on container
    removal.
  prefs: []
  type: TYPE_NORMAL
- en: b) This is false. You need to use the `--volumes` or `-v` options on container
    removal.
  prefs: []
  type: TYPE_NORMAL
- en: c) This is false. You need to use the `--volumes` or `-v` options on container
    removal, and only unnamed volumes are removed.
  prefs: []
  type: TYPE_NORMAL
- en: d) This is false. Volumes can only be removed manually using `docker volume
    rm` or `docker volume purge`.
  prefs: []
  type: TYPE_NORMAL
- en: Which of the following statements is not true regarding container networking?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) By default, all exposed container ports are accessible from the Docker host`
  prefs: []
  type: TYPE_NORMAL
- en: b) `docker network prune` will remove all unused networks`
  prefs: []
  type: TYPE_NORMAL
- en: c) By default, all bridge networks are attachable on the fly`
  prefs: []
  type: TYPE_NORMAL
- en: d) Docker provides an internal DNS for each custom bridge network`
  prefs: []
  type: TYPE_NORMAL
- en: Which of the following statements is true regarding a container publishing an
    Nginx web server with port `80` exposed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) If we use the host driver, we need to run this container with `NET_ADMIN`
    capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: b) If we use the `--publish-all` or `-P` options, a random port between `32768`
    and `65535` will be associated at the host level with each container port exposed.
    You need to add a NAT rule in `iptables` to allow requests to reach the container's
    internal port `80`.
  prefs: []
  type: TYPE_NORMAL
- en: c) Using `--publish 192.168.2.100:1080:80`, we will ensure that only requests
    to the host IP address `192.168.2.100` on port `1080` will be redirected to the
    internal web server container port. (We are assuming that IP address `192.168.2.100`
    is a host interface.)
  prefs: []
  type: TYPE_NORMAL
- en: d) If we use `--publish 80` or `-p 80`, a random port between `32768` and `65535`
    will be associated at the host level with port `80`, and a NAT rule will be added
    to `iptables`.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following links will help you learn more about volumes and networking concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using storage volumes: [https://docs.docker.com/storage/volumes/](https://docs.docker.com/storage/volumes/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Volume plugins: [https://docs.docker.com/engine/extend/legacy_plugins/](https://docs.docker.com/engine/extend/legacy_plugins/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Networking overview: [https://docs.docker.com/network/](https://docs.docker.com/network/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
