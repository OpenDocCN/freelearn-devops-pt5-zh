<html><head></head><body>
		<div><h1 id="_idParaDest-308"><em class="italic"><a id="_idTextAnchor329"/>Chapter 15</em>: Scanning, Monitoring, and Using Third-Party Tools</h1>
			<p>So far, we have explored how we can manually configure our Docker containers to ensure security is a priority. In this chapter, we will look at some of the tools available to automatically scan our images and monitor our production loads. This will provide a jumping off spot for you to expand your Docker-based projects further, based upon your cloud provider if you use one.</p>
			<p>We will start off by looking at DevOps solutions such as Anchore Engine for scanning images for security vulnerabilities, review <code>docker stats</code> and learn how it is useful, set up cAdvisor for local monitoring, and understand how Datadog can be used as a cloud-based solution for gathering container stats.</p>
			<p>This chapter will also briefly review AWS security options including GuardDuty for monitoring production environments and cover some of the features that Microsoft Azure offers. You'll gain an understanding of what tools are available to <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) users and deploy the Datadog Agent to your container environment.</p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Scanning and monitoring – cloud and DevOps security for containers</li>
				<li>Securing your containers using AWS</li>
				<li>Securing your containers using Azure</li>
				<li>Securing your containers using GCP</li>
			</ul>
			<p>Let's get started by looking at techniques for monitoring containers, scanning for security issues.</p>
			<h1 id="_idParaDest-309"><a id="_idTextAnchor330"/>Technical requirements</h1>
			<p>For this chapter, you will need to have access to a Linux machine running Docker. We recommend that you use the setup you have been using so far in this book.</p>
			<p>In addition to this, you will need an account on Docker Hub in order to access images located there. If you have not already set one up during previous chapters, you can do so via <a href="https://hub.docker.com:">https://hub.docker.com:</a></p>
			<p>In order to use many of the programs explored in this chapter, you will need to download them from the web. We'll provide links in each section where relevant so you know where to get them from. In some instances, you may need to set up an account in order to use a service or download a tool.</p>
			<p>Check out the following video to see the Code in Action:</p>
			<p><a href="https://bit.ly/30VfWu8">https://bit.ly/30VfWu8</a></p>
			<h1 id="_idParaDest-310"><a id="_idTextAnchor331"/>Scanning and monitoring – cloud and DevOps security for containers</h1>
			<p>Before we begin to look at specific tools for monitoring and scanning your containers, we shall first define exactly what we mean by the term monitoring in a security context.</p>
			<p>As you have seen <a id="_idIndexMarker1095"/>throughout this book, containers provide a mechanism to serve up applications in small self-contained environments. However, we need to ensure that released software does not suffer from performance degradation while running. For example, we need to know if a container is consuming a lot of resources and thereby impacting the overall performance of our environment. You may already have some understanding of this concept from <a href="B11641_10_Final_AM_ePub.xhtml#_idTextAnchor226"><em class="italic">Chapter 10</em></a>, <em class="italic">Monitoring Docker Using Prometheus, Grafana, and Jaeger</em>.</p>
			<p>Additionally, monitoring<a id="_idIndexMarker1096"/> allows us to look for anomalies that may indicate that the system is under attack or has been compromised in some fashion. While elsewhere in this book monitoring has been focused on ensuring system stability and performance, we will use those concepts from a security angle. Security scanning applications are an important part of any tool chain, but may not pick up every issue, especially newer exploits. Therefore, looking for negative side effects of a malicious software's presence is an important defense mechanism. As such, combining scanning prior to release, monitoring post release, and incident response are important parts of running a production container system.</p>
			<p class="callout-heading">A note on sandbox environments</p>
			<p class="callout">One concept that may also be useful to understand is a <a id="_idIndexMarker1097"/>sandbox environment. A sandbox provides an environment for isolating and testing untrusted code. These environments are useful for reviewing containers you believe may be infected with malware without risking impacting live systems or development environments your team uses. </p>
			<p>In this chapter, we are going to start by looking at the scanning stage in the CI/CD (DevOps) pipeline, before investigating how monitoring tools can be used in conjunction with them to protect our systems. Let's get started with Anchore Engine for scanning our containers.</p>
			<h2 id="_idParaDest-311"><a id="_idTextAnchor332"/>Scanning using Anchore Engine</h2>
			<p>When building out a <a id="_idIndexMarker1098"/>DevOps pipeline, scanning our <a id="_idIndexMarker1099"/>containers for security issues is an important consideration. One of the final steps in a typical CI process is to build the container itself, having tested the software we intend to deploy to it. As you have seen throughout this book, we have experimented with a number of technologies deployed within containers. While there are many security tools for each language, whether it be JavaScript or PHP (which are sadly out of scope for this book), we shouldn't fail to lessen our manual security burden at the container level by using automated tools. </p>
			<p>While we have seen the importance of pulling down signed images, it certainly doesn't hurt to scan them. As the saying goes, <em class="italic">better safe than sorry!</em> </p>
			<p>If we discover that an image we have included in our build is compromised or a tag violates an internal work security policy or compliance, we know that the whole build is thus vulnerable to attack and can in turn prevent it from reaching our production environment.</p>
			<p>Therefore, we can think of the security scanning process as the following two interrelated steps:</p>
			<ol>
				<li value="1">Looking at the image we are including in the <code>Dockerfile</code>, and also the configuration in the <code>Dockerfile</code> itself.</li>
				<li>Ensuring that the container matches any internal requirements that we may have such as not using blacklisted images. In this case, the image may have not been blacklisted purely for security reasons, but also for performance.</li>
			</ol>
			<p>In order to accommodate these two factors, we need a container scanning tool that allows us the flexibility of defining our own policies on top of standard security considerations.</p>
			<p>One of the most popular <a id="_idIndexMarker1100"/>open source tools on the market that <a id="_idIndexMarker1101"/>allows us to meet both these goals is Anchore Engine. You can find the <a id="_idIndexMarker1102"/>official website at:  <a href="https://anchore.com/engine/">https://anchore.com/engine/</a>.</p>
			<p>In addition to a large number of features we will shortly investigate, it is also an open source project. So, if you wish to contribute to it, make sure to check out the GitHub repository at <a href="https://github.com/anchore/anchore-engine">https://github.com/anchore/anchore-engine</a>.</p>
			<p>At its heart, Anchore is an engine for scanning containers for security issues. It can easily be hooked into your CI pipeline to provide vulnerability and policy scanning prior to deployment. Let's take a look at getting it installed and running a basic scan against the latest Alpine image.</p>
			<h3>Installing Anchore Engine</h3>
			<p>Installing <a id="_idIndexMarker1103"/>Anchore Engine is straightforward. First, we need to start with the engine portion of the product. Let's create and navigate into a new directory called <code>aevolume</code>:</p>
			<pre>$ mkdir ~/aevolume
$ cd ~/aevolume</pre>
			<p>Next, pull down the latest version of Anchore Engine:</p>
			<pre>$ docker pull docker.io/anchore/anchore-engine:latest</pre>
			<p>We can now run Docker's <code>create</code> command:</p>
			<pre>$ docker create --name ae docker.io/anchore/anchore-engine:latest</pre>
			<p class="callout-heading">Use curl to grab the docker-compose.yaml</p>
			<p class="callout">You can also copy the <code>docker-compose.yaml</code> via curl using: <code>curl </code><a href="https://docs.anchore.com/current/docs/engine/quickstart/docker-compose.yaml">https://docs.anchore.com/current/docs/engine/quickstart/docker-compose.yaml</a><code> &gt; docker-compose.yaml</code></p>
			<p>Copy over the <code>docker-compose</code> file to your current directory and then remove the <code>ae</code> folder that was created:</p>
			<pre>$ docker cp ae:/docker-compose.yaml ~/aevolume/docker-compose.yaml
$ docker rm ae</pre>
			<p>Finally, run the <code>pull</code> and <code>up</code> commands as follows:</p>
			<pre>$ docker-compose pull
$ docker-compose up -d</pre>
			<p>Next, we need to install the CLI that can interact with the engine. You have several options here, including the Docker container:</p>
			<pre>$ docker pull anchore/engine-cli:latest</pre>
			<p>You can also <a id="_idIndexMarker1104"/>use one of the methods listed here, which will install the CLI locally onto your machine: <a href="https://github.com/anchore/anchore-cli">https://github.com/anchore/anchore-cli</a>. </p>
			<p>The Python version of the CLI can be installed using the following commands:</p>
			<pre>apt-get update 
apt-get install python-pip 
pip install anchorecli</pre>
			<p>If you have pulled the container image and wish to use the default credentials, run the following command to be dropped into the CLI shell:</p>
			<pre>$ docker run  -it anchore/engine-cli</pre>
			<p>In the following section will be use the Python command line version of the CLI to interact with the engine.</p>
			<p>You can now execute the CLI commands against the engine from within the container shell, or from the CLI if you've installed it manually. The following example demonstrates calling the endpoint via the CLI, passing in the credentials and endpoint, and requesting the system status information:</p>
			<pre>$ anchore-cli --u admin --p foobar --url http://localhost:8228/v1/ system status</pre>
			<p>You should now see<a id="_idIndexMarker1105"/> some status results in your console indicating the engines are up:</p>
			<pre>Service analyzer (anchore-quickstart, http://engine-analyzer:8228): up
Service simplequeue (anchore-quickstart, http://engine-simpleq:8228): up
Service policy_engine (anchore-quickstart, http://engine-policy-engine:8228): up
Service apiext (anchore-quickstart, http://engine-api:8228): up
Service catalog (anchore-quickstart, http://engine-catalog:8228): up
Engine DB Version: 0.0.12
Engine Code Version: 0.6.1</pre>
			<p>Now let's review the scanning step.</p>
			<h3>Adding and scanning images</h3>
			<p>Let's try out Anchore Engine<a id="_idIndexMarker1106"/> by running a scan on the latest Alpine container. You'll remember that Alpine is the base operating system that our <code>shipitclicker</code> image version 0.1 has been using so far. Therefore, confirming this is free of issues is a good first step.</p>
			<p>When we run a scan, it checks the image against what is known as a set of <strong class="bold">policies</strong>. Policies in Anchore are collections of whitelists and checks that the image must pass.</p>
			<p>The process to kick off a scan is as follows:</p>
			<ol>
				<li value="1">Let's add the Alpine image using the CLI command by executing the following:<pre><strong class="bold">$ anchore-cli --u admin --p foobar --url http://localhost:8228/v1/ image add alpine:latest</strong></pre></li>
				<li>When this completes <a id="_idIndexMarker1107"/>successfully, you should see something similar to the following. This tells us the image was added:<pre><strong class="bold">Image Digest: sha256:ddba4d27a7ffc3f86dd6c2f92041af252a1 f23a8e742c90e6e1297bfa1bc0c45</strong>
<strong class="bold">Parent Digest: sha256:ab00606a42621fb68f2ed6ad3c88be54397f 981a7b70a79db3d1172b11c4367d</strong>
<strong class="bold">Analysis Status: not_analyzed</strong>
<strong class="bold">Image Type: docker</strong>
<strong class="bold">Analyzed At: None</strong>
<strong class="bold">Image ID: e7d92cdc71feacf90708cb59182d0df1b911f8ae022d29 e8e95d75ca6a99776a</strong>
<strong class="bold">Dockerfile Mode: None</strong>
<strong class="bold">Distro: None</strong>
<strong class="bold">Distro Version: None</strong>
<strong class="bold">Size: None</strong>
<strong class="bold">Architecture: None</strong>
<strong class="bold">Layer Count: None</strong> 
<strong class="bold">Full Tag: docker.io/alpine:latest</strong>
<strong class="bold">Tag Detected At: 2020-02-04T16:22:19Z</strong> </pre></li>
				<li>Our image hasn't been analyzed by Anchore yet. This is where we extract and classify metadata. So, let's move the image into this state as follows:<pre><strong class="bold">$ anchore-cli --u admin --p foobar --url http://localhost:8228/v1/ image wait alpine:latest</strong></pre></li>
				<li>Once complete, we can now run a vulnerability scan on the Alpine image using this command. Here, we are checking for operating-system-level package vulnerabilities using the <code>os</code> property. In addition to <code>os</code>, we have the option of checking for <code>non-os</code> (this includes language-specific packages such as Python PIP and Ruby GEM types) and <code>all</code>:<pre><strong class="bold">$ anchore-cli --u admin --p foobar --url http://localhost:8228/v1/ image vuln alpine:latest os</strong></pre><p>If everything is successful and the image passes, you will not see any vulnerabilities <a id="_idIndexMarker1108"/>displayed on the screen.</p><p>If a vulnerability is found, it will come back in the following format:</p><pre><strong class="bold">Vulnerability ID  Package      Severity   Fix     Vulnerability URL </strong>
<strong class="bold">CVE-1111-1111     package.zip  Negligible None https://somewebsite</strong></pre></li>
			</ol>
			<p>By default, the basic Anchore installation policy will scan for CVE issues and Dockerfile problems, such as those we have explored in the previous few chapters.</p>
			<p>Now you have the scanning engine in place, you can begin to build out your own policies and scan against them. For more information, refer <a id="_idIndexMarker1109"/>to the Anchor policy documentation:</p>
			<p><a href="https://docs.anchore.com/current/docs/using/cli_usage/policies/">https://docs.anchore.com/current/docs/using/cli_usage/policies/</a></p>
			<p>Also, to see examples of policies you can copy and modify, check <a id="_idIndexMarker1110"/>out the Anchore Hub page on GitHub:</p>
			<p><a href="https://github.com/anchore/hub">https://github.com/anchore/hub</a></p>
			<p>Whether defining custom policies or reusing others, these JSON files can be added using the CLI:</p>
			<pre>$ anchore-cli policy add /path/to/image/policy/bundle.json</pre>
			<p>Once added, they can then be activated using the <code>activate</code> command:</p>
			<pre>$ anchore-cli policy activate &lt;Policy ID&gt;</pre>
			<p>If you need to know a policy ID, you can use the <code>policy list</code> command from the CLI:</p>
			<pre>anchore-cli --u admin --p foobar policy list</pre>
			<p>As an experiment, you might like to run the default or your own policies against the other images in the Docker for Developers Docker Hub repository:</p>
			<p><a href="https://hub.docker.com/r/dockerfordevelopers/shipitclicker/tags">https://hub.docker.com/r/dockerfordevelopers/shipitclicker/tags</a></p>
			<p>This covers the basics of <a id="_idIndexMarker1111"/>getting up and running. If you wish to add scanning to your DevOps pipeline, Anchore integrates with a number of CI/CD systems, including the following:</p>
			<ul>
				<li>CloudBees</li>
				<li>GitHub</li>
				<li>GitLab</li>
				<li>CircleCI</li>
				<li>Codefresh</li>
			</ul>
			<p>Integration instructions for each platform<a id="_idIndexMarker1112"/> can be found on the Anchore website:</p>
			<p><a href="https://docs.anchore.com/current/docs/using/integration/ci_cd/">https://docs.anchore.com/current/docs/using/integration/ci_cd/</a></p>
			<p>Anchore also includes a plugin for Jenkins, so you can experiment with integrating it with the Jenkins setup we completed earlier in this book:</p>
			<p><a href="https://plugins.jenkins.io/anchore-container-scanner/">https://plugins.jenkins.io/anchore-container-scanner/</a></p>
			<p>Let's quickly mention another tool before we move on to looking at monitoring tools.</p>
			<h2 id="_idParaDest-312"><a id="_idTextAnchor333"/>A brief mention of Chef InSpec</h2>
			<p>Another tool you may be interested in reviewing when considering scanning container infrastructure is <a id="_idIndexMarker1113"/>Chef InSpec.</p>
			<p>Chef InSpec is an open source framework like Anchore but geared toward testing and auditing all of your applications and infrastructure. This includes running auditing tests against Docker. If you are looking for an all-in-one solution for infrastructure beyond just your container environment, this may meet your needs.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">A complete walk-through of InSpec is out of scope of this book, however, if you would like to read more about it, you can find further information in the <a id="_idIndexMarker1114"/>document portal at the InSpec website: <a href="https://www.inspec.io/docs/">https://www.inspec.io/docs/</a>.</p>
			<p>In summary, we can scan our containers before deploying them to check if they are secure. Let's now move on and look at Docker stats for container monitoring.</p>
			<h2 id="_idParaDest-313"><a id="_idTextAnchor334"/>Native monitoring locally using Docker stats</h2>
			<p>Now we have deployed <a id="_idIndexMarker1115"/>our containers and believe that they are secure, we should consider using monitoring tools to review performance and help investigate problems when they arise.</p>
			<p>Before exploring some of the complex and comprehensive tools available in the cloud, we can use Docker's native stats tool to get a quick overview of the container's health. This can be useful if you are quickly testing a container in an isolated sandbox environment due to a suspicion that some software on it may be using up resources in an anomalous fashion – for example, if you suspect a web application may be infected by a coin miner that wasn't picked up at the CI stage.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Running a container in a VM sandbox, as well as allowing you to probe performance metrics, allows you to safely scan it for security issues without risking infecting the underlying machine.</p>
			<p>To access data on your container's performance, you can execute the following command:</p>
			<pre>$ docker stats &lt;container id&gt;</pre>
			<p>For each container, you will see CPU usage, memory usage, the memory limit (<code>MEM</code>), <code>% NET I/O</code>, and finally, <code>BLOCK I/O</code>. The following example demonstrates a typical output:</p>
			<pre>CONTAINER CPU % MEM USAGE/LIMIT MEM % NET I/O  BLOCK I/O
ebb12326ae94 1% 73.63 MiB/490 MiB 15.02% 90.2 MB/275.5 MB 26.8 MB/873.7 MB</pre>
			<p>While the <code>stats</code> command is useful when doing local development or if you wish to get a quick snapshot of how a system is performing, it would be nice to gather a more comprehensive set of metrics. One<a id="_idIndexMarker1116"/> method of achieving this is to use the Stats API. We'll now briefly look at this and also consider some of the security implications around it.</p>
			<h3>Using the Stats API</h3>
			<p>The<a id="_idIndexMarker1117"/> Stats API is a more comprehensive set of results, returned in JSON format, and is available on the Docker socket:</p>
			<pre>$ /var/run/docker.sock</pre>
			<p>You'll remember from the <em class="italic">Securing the Daemon Socket</em> section in <a href="B11641_12_Final_NM_ePub.xhtml#_idTextAnchor278"><em class="italic">Chapter 12</em></a>, <em class="italic">Introduction to Container Security</em>, that we need to ensure an attacker cannot compromise the socket and then use it to gain root access to the underlying host. We can do this by encrypting the traffic using TLS. Refer back to this chapter if you need help in getting this set up.</p>
			<p>The Stats API<a id="_idIndexMarker1118"/> operates using a REST architecture and thus takes HTTP requests as queries. You can see examples on the official documentation site at <a href="https://docs.docker.com/engine/api/latest/">https://docs.docker.com/engine/api/latest/</a>.</p>
			<p>Requests to the API can be made from the command line using netcat or <code>curl</code>, with a third-party tool such as Postman, or you can write your own script using Python, Bash, or similar, to hit the endpoint.</p>
			<p>Using <code>curl</code> as an example, you can replace the value in this command with your own and execute it:</p>
			<pre>$ curl -sk &lt;options&gt; https://&lt;ip&gt;:&lt;port&gt;/&lt;rest endpoint&gt;  --cert &lt;path/to/cert.pem&gt; --key &lt;path/to/key.pem -cacert &lt;path/to/ca.pem&gt;</pre>
			<p>You should see a JSON object returned with the results. These are more comprehensive than using the Docker command, and may be more useful if you wish to save them as JSON files for further analysis, for example, if gathering data on a container you may believe is compromised. </p>
			<p>In addition to the native<a id="_idIndexMarker1119"/> Docker tools, Google provides <strong class="bold">Container Advisor</strong> (<strong class="bold">cAdvisor</strong>) for gathering metrics on your container. We will now briefly take a look at this, as a third option for local monitoring.</p>
			<h3>cAdvisor for container monitoring </h3>
			<p>cAdvisor is a <a id="_idIndexMarker1120"/>Google-managed software project for providing container insights into container performance and resource usage. The source code for cAdvisor<a id="_idIndexMarker1121"/> is available on GitHub at the following URL:</p>
			<p><a href="https://github.com/google/cadvisor">https://github.com/google/cadvisor</a></p>
			<p>To test it out, you can use the standard demo container provided by Google. Simply run the following command to pull it down from Google Container Registry and start it up:</p>
			<pre>$ sudo docker run \
    --volume=/:/rootfs:ro \
    --volume=/var/run:/var/run:ro \
    --volume=/sys:/sys:ro \
    --volume=/var/lib/docker/:/var/lib/docker:ro \
    --volume=/dev/disk/:/dev/disk:ro \
    --publish=8080:8080 \
    --detach=true \
    --name=cadvisor \
    gcr.io/google-containers/cadvisor:latest</pre>
			<p>You can now access cAdvisor's web portal on port <code>8080</code> of <code>localhost</code>. If you have other services running on this port, such as Jenkins, you can change the cAdvisor port in the preceding command.</p>
			<p>Try accessing <code>http://localhost:8080/containers/</code> and you should see the dashboard shown in the following screenshot:</p>
			<div><div><img src="img/B11641_15_001.jpg" alt="Figure 15.1 – cAdvisor dashboard"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.1 – cAdvisor dashboard</p>
			<p>From this dashboard, you<a id="_idIndexMarker1122"/> can explore a variety of metrics ranging from filesystem and memory to CPU and processes. Monitoring these for poor performance can be a useful tool to monitor security issues as we have noted elsewhere.</p>
			<p>For example, if resource usage seems to be abnormally high, this can be an indication of software that it isn't functioning properly, or a potential security issue, such as malware running on the container.</p>
			<p>All of this is very useful for small local systems and perhaps a quick investigation of a potentially compromised container, but what about monitoring our containers in a production environment and gathering actionable data if we believe a security issue may exist? Well, we can look at one of the many third-party tools that exist that allow us to gather metrics and build comprehensive dashboard and alerting systems.</p>
			<p>To demonstrate this, we are going to look at one of the most popular tools on the market for gathering monitoring data for Kubernetes and Docker environments, Datadog.</p>
			<h2 id="_idParaDest-314"><a id="_idTextAnchor335"/>Aggregating monitoring data in the cloud with Datadog </h2>
			<p>For commercial <a id="_idIndexMarker1123"/>projects where environments are deployed to a cloud environment or on your own data center, we need a platform that is capable of aggregating data from a variety of inputs and then presenting it in a fashion you can work with.</p>
			<p>Datadog is one such product capable of achieving this and provides plugins for both simple Docker and advanced Kubernetes-based environments. It is also supported on a number of platforms, including major cloud providers such as AWS. Datadog (<a href="https://www.datadoghq.com/">https://www.datadoghq.com/</a>) offers a <a id="_idIndexMarker1124"/>free 14-day trial so you can experiment with their container features and decide if they meet your needs. You'll find this a worthy rival to some of the tools explored in earlier chapters.</p>
			<p>So, now let's take a look at the agents you can run for Kubernetes and Docker on your nodes to start sending data back to Datadog.</p>
			<h3>Datadog agents for Docker and Kubernetes </h3>
			<p>Once you have an <a id="_idIndexMarker1125"/>account set up at <a href="https://www.datadoghq.com/">https://www.datadoghq.com/</a>, you can<a id="_idIndexMarker1126"/> install the Datadog Agent on a test node to monitor performance.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">We'd recommend starting with a test environment before trying to deploy the production.  We also recommend that, before deploying to your production environment, you familiarize yourself with the Docker and Kubernetes agent documentation at: <a href="https://docs.datadoghq.com/agent/docker/?tab=standard">https://docs.datadoghq.com/agent/docker/?tab=standard</a>.</p>
			<p>The following examples will cover installing Docker Agent and also the Kubernetes agent. Each example uses a cluster with only a single node for demonstration purposes. You are welcome to reuse the Docker container from <a href="B11641_12_Final_NM_ePub.xhtml#_idTextAnchor278"><em class="italic">Chapter 12</em></a>, <em class="italic">Introduction to Container Security</em>, or one of the other containers used elsewhere in this book.</p>
			<h4>Installing and monitoring Docker Agent</h4>
			<p>Your first task is to install the <a id="_idIndexMarker1127"/>Docker Agent on the host. The Datadog Docker Agent is responsible for collecting the metrics and passing them back to your account dashboard.</p>
			<p>Installing the agent is now incredibly easy. From within your host, execute the following Docker command to include the Datadog Agent:</p>
			<pre>$ docker run -d --name dd-agent \
    -v /var/run/docker.sock:/var/run/docker.sock:ro \
    -v /proc/:/host/proc/:ro \
    -v /path/to/cgroup/:/host/sys/fs/cgroup:ro \
    -e DD_API_KEY={API_KEY} \
    datadog/docker-dd-agent:latest</pre>
			<p>Based upon your OS version, and <a id="_idIndexMarker1128"/>the version of the agent you have installed, you can then confirm it is running by checking the list of commands here:</p>
			<p>https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6v7#agent-status-and-information</p>
			<p>From the Datadog dashboard you should now see data being returned. You can now begin to explore the metrics that come back from your containers, and set alerts when issues arise:</p>
			<div><div><img src="img/B11641_15_002.jpg" alt="Figure 15.2 – Example of the Datadog dashboard showing metrics"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.2 – Example of the Datadog dashboard showing metrics</p>
			<p>The next area you may <a id="_idIndexMarker1129"/>be interested in exploring is the <strong class="bold">Security</strong> option in the menu. Select this and follow the wizard to set up security monitoring. Once complete, you can enable and disable security <strong class="bold">Detection Rules</strong>, as the following screenshot demonstrates:</p>
			<div><div><img src="img/B11641_15_003.jpg" alt="Figure 15.3 – Detection rules in Datadog"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.3 – Detection rules in Datadog</p>
			<p>For more on setting monitors and <a id="_idIndexMarker1130"/>alerts for containers in Datadog, please refer to the documentation here:</p>
			<p><a href="https://docs.datadoghq.com/monitors/">https://docs.datadoghq.com/monitors/</a></p>
			<p>Let's now look at the Kubernetes agent equivalent.</p>
			<h4>Installing and monitoring the Kubernetes agent</h4>
			<p>As with our previous <a id="_idIndexMarker1131"/>Docker example, we need to install the agent first. To do this, we <a id="_idIndexMarker1132"/>can deploy a DaemonSet via Helm. The following instructions use Helm version 3.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Remember to run add <code>helm repo add stable, </code><a href="https://kubernetes-charts.storage.googleapis.com">https://kubernetes-charts.storage.googleapis.com</a>, if you haven't already, to add stable to your repositories.</p>
			<p>You can download the official Helm file (<code>values.yaml</code>) containing the configuration from GitHub at (<a href="https://github.com/helm/charts/blob/master/stable/datadog/values.yaml">https://github.com/helm/charts/blob/master/stable/datadog/values.yaml</a>).</p>
			<p>Next, you will need to grab your API key from your account. With the API key, we can now complete the installation process. In the following command, replace <code>{API_KEY}</code> with your own:</p>
			<pre>helm install datadog-agent -f values.yaml  --set datadog.apiKey={API KEY} stable/datadog</pre>
			<p>You should see a confirmation in your terminal that the deployment was successful:</p>
			<div><div><img src="img/B11641_15_004.jpg" alt="Figure 15.4 – Datadog Agent deployment "/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.4 – Datadog Agent deployment</p>
			<p>Now you have <a id="_idIndexMarker1133"/>deployed the agent, it will start to collect metrics from <a id="_idIndexMarker1134"/>Kubernetes:</p>
			<div><div><img src="img/B11641_15_005.jpg" alt="Figure 15.5 – Example dashboard metrics"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.5 – Example dashboard metrics</p>
			<p>As part of this installation process, the <code>kube-state-metrics</code> Helm chart is also included. This Helm chart<a id="_idIndexMarker1135"/> installs the <code>kube-state-metrics</code> service (<a href="https://github.com/kubernetes/kube-state-metrics">https://github.com/kubernetes/kube-state-metrics</a>).</p>
			<p>A variety of data is collected by this service and you can view the exposed metrics at <a href="https://github.com/kubernetes/kube-state-metrics/tree/master/docs">https://github.com/kubernetes/kube-state-metrics/tree/master/docs</a>.</p>
			<p>For example, you may be interested in the metrics around secrets, so you can see what data is being gathered by reviewing the Kubernetes log collection document. You can also enable log collection via Helm. To do this, update the <code>datadog-values.yaml</code> file to set the <code>enabled</code> and <code>containerCollectAll</code> key-value pairs both to <code>true</code>. Once you have done this, run <code>helm upgrade</code> to update your Datadog Helm chart. </p>
			<p>With the metrics from your nodes being sent back to the Datadog default Kubernetes dashboard, you can start to configure alerting and monitoring and explore the many features Datadog offers. </p>
			<p>For example, you can create a <a id="_idIndexMarker1136"/>custom dashboard that displays the number of security <a id="_idIndexMarker1137"/>signals discovered:</p>
			<div><div><img src="img/B11641_15_006.jpg" alt=""/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.6 – Dashboard list</p>
			<p>We've briefly seen how we can use third-party tools to monitor our containers in a security context. This can help to alert us about security issues that may manifest their symptoms as performance problems.</p>
			<p>Let's now look at some of the tools provided by the major cloud platforms out there. Both Datadog and the CI/CD scanning pipeline we discussed can be integrated with the providers listed in the following sections, to provide an even more comprehensive security posture.</p>
			<h1 id="_idParaDest-315"><a id="_idTextAnchor336"/>Securing your containers using AWS</h1>
			<p>There are a<a id="_idIndexMarker1138"/> number <a id="_idIndexMarker1139"/>of approaches we can take to securing containers in the cloud. We will start by looking at <strong class="bold">Amazon Web Services</strong>, commonly known as <strong class="bold">AWS</strong>. This section of the book assumes you are already familiar with working in AWS for hosting container-based projects. If you use a different service, such as Azure or GCP, then please feel free to skip <a id="_idIndexMarker1140"/>ahead to the <em class="italic">Azure container security</em> and <em class="italic">Google container security options</em> sections respectively. The <a id="_idIndexMarker1141"/>topic of AWS and container hosting is also discussed in <a href="B11641_05_Final_NM_ePub.xhtml#_idTextAnchor080"><em class="italic">Chapter 5</em></a>, <em class="italic">Alternatives for Deploying and Running Containers in Production</em>, and <a href="B11641_08_Final_AM_ePub.xhtml#_idTextAnchor157"><em class="italic">Chapter 8</em></a>, <em class="italic">Deploying Docker Apps to Kubernetes</em>. Let's take a look at the tools used for monitoring in AWS.</p>
			<h2 id="_idParaDest-316"><a id="_idTextAnchor337"/>Security alerts for AWS with GuardDuty </h2>
			<p>A number of tools exist<a id="_idIndexMarker1142"/> either in AWS or as third-party plugins that can be used to monitor your Amazon environment hosting your container infrastructure.</p>
			<p>Amazon's major tool for monitoring security issues within a <a id="_idIndexMarker1143"/>VPC is GuardDuty (<a href="https://aws.amazon.com/guardduty/">https://aws.amazon.com/guardduty/</a>).</p>
			<p>We've seen how we can monitor container health with Datadog, but also saw how important it is to monitor the environment that supports our infrastructure. Complex production instances<a id="_idIndexMarker1144"/> often use AWS services that sit outside of <strong class="bold">Elastic Kubernetes Service</strong> (<strong class="bold">EKS</strong>), <strong class="bold">Elastic Container Service</strong> (<strong class="bold">ECS</strong>), and <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>). Examples include the<a id="_idIndexMarker1145"/> IAM roles you might have used to<a id="_idIndexMarker1146"/> set up CloudWatch metrics or S3 buckets earlier in this book.</p>
			<p>AWS GuardDuty provides a mechanism to monitor our cloud-based environment to ensure that any attacks within the VPC that hosts our containers can be tracked down. This is achieved by being integrated with CloudWatch, which allows us to trigger certain security actions based upon the type of alert we see, such as triggering a lambda function, or sending the events on to a third-party application or an S3 bucket for storage.</p>
			<p>If you wish to enable GuardDuty, you will need a VPC setup hosting your containers, such as the one configured in <a href="B11641_08_Final_AM_ePub.xhtml#_idTextAnchor157"><em class="italic">Chapter 8</em></a>, <em class="italic">Deploying Docker Apps to Kubernetes</em>. </p>
			<p>With this in place, you can now create a rule to allow CloudWatch to send events for anything that GuardDuty discovers. This is especially useful for spotting whether containers are generating suspicious network traffic in your VPC.</p>
			<p>Using the AWS CLI, we can now enable CloudWatch to start sending the previously mentioned events. To do this, execute the following command:</p>
			<pre>$ aws events put-rule --name PacktContainerSecurity --event-pattern "{\"source\":[\"aws.guardduty\"]}"</pre>
			<p>With these events enabled, you have a number of options for next steps. You could, for example, attach a lambda function that will handle events that are triggered and act on them, or integrate CloudWatch <a id="_idIndexMarker1147"/>GuardDuty events with your Datadog setup, as outlined here:</p>
			<p><a href="https://github.com/DataDog/datadog-serverless-functions/tree/master/aws/logs_monitoring">https://github.com/DataDog/datadog-serverless-functions/tree/master/aws/logs_monitoring</a></p>
			<p>If you wish to write the results of CloudWatch GuardDuty events to the S3 bucket created in <a href="B11641_10_Final_AM_ePub.xhtml#_idTextAnchor226"><em class="italic">Chapter 10</em></a>, <em class="italic">Monitoring Docker Using Prometheus, Grafana, and Jaeger</em>, in the <em class="italic">Storing logs for the long term with AWS S3</em> section, then you can attach the lambda function as an event rule:</p>
			<pre>$ aws events put-targets --rule PacktContainerSecurity --targets Id=1,Arn=arn:aws:lambda:&lt;zone&gt;:&lt;ARN digits&gt;:function:&lt;function&gt;</pre>
			<p>An example of a lambda function that can be used to write to the S3 bucket is provided by AWS at the following link:</p>
			<p><a href="https://aws.amazon.com/blogs/database/monitoring-your-security-with-guardduty-in-real-time-with-amazon-elasticsearch-service/">https://aws.amazon.com/blogs/database/monitoring-your-security-with-guardduty-in-real-time-with-amazon-elasticsearch-service/</a></p>
			<p>Once you have modified this lambda to your needs and added it between the <code>&lt;</code> and <code>&gt; </code>brackets, you can include the required permissions  by running the following command:</p>
			<pre>$ aws lambda add-permission --function-name &lt;function&gt; --statement-id 1 --action 'lambda:InvokeFunction' --principal events.amazonaws.com</pre>
			<p>This should act as a jumping-off point for you to explore GuardDuty in more detail and expand upon the setup you have created over the course of this book.</p>
			<p class="callout-heading">Another way to store findings to S3</p>
			<p class="callout">You can also use the steps provided by AWS here for exporting GuardDuty findings to an S3 bucket: <a href="https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_exportfindings.html">https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_exportfindings.html</a></p>
			<p>Other security features in AWS you may be interested in checking out include the following:</p>
			<ul>
				<li>Amazon Inspector for<a id="_idIndexMarker1148"/> analyzing application security: <a href="https://aws.amazon.com/inspector/">https://aws.amazon.com/inspector/</a></li>
				<li>AWS Security Hub for <a id="_idIndexMarker1149"/>creating a unified central security center: <a href="https://aws.amazon.com/security-hub/">https://aws.amazon.com/security-hub/</a></li>
				<li>Amazon Detective<a id="_idIndexMarker1150"/> for detecting potential security issues: <a href="https://aws.amazon.com/detective/">https://aws.amazon.com/detective/</a></li>
			</ul>
			<p>Each of these services can be enabled through your AWS web console. Let's now move on and take a look at some of the options available in Microsoft Azure.</p>
			<h1 id="_idParaDest-317"><a id="_idTextAnchor338"/>Securing your containers using Azure</h1>
			<p>Azure is<a id="_idIndexMarker1151"/> Microsoft's flagship cloud service and provides a number of <a id="_idIndexMarker1152"/>tools you can use to deploy and monitor Docker containers. This section assumes some familiarity with both Azure and the Log Analytics service.</p>
			<h2 id="_idParaDest-318"><a id="_idTextAnchor339"/>Container monitoring in Azure</h2>
			<p>Microsoft's Container Monitoring<a id="_idIndexMarker1153"/> solution provides a mechanism to manage Docker and <a id="_idIndexMarker1154"/>Windows hosts from a single place and supports Kubernetes and Docker Swarm, both of which have been discussed in this book.</p>
			<p>If you are already using Microsoft's AKS service, you may be familiar with the monitoring services available on the AKS page, however, it is also possible to monitor containers across your whole Microsoft infrastructure in Azure.</p>
			<p>To enable the monitoring of your containers, you will need to start by enabling the feature by adding it to Log Analytics. You can do this by clicking the <strong class="bold">GET IT NOW</strong> button on the Azure Marketplace website:</p>
			<p><a href="https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft.containersoms?tab=overview">https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft.containersoms?tab=overview</a></p>
			<p>Once this is complete, you can create a new Log Analytics workspace. From this new workspace, record the name you chose, and also obtain the workspace ID and key. These are available under the <strong class="bold">Advanced settings</strong> of your workspace and can be found under the <strong class="bold">Connected Sources </strong>| <strong class="bold">Linux Servers</strong> options.</p>
			<p>For the purpose of this overview, we are going to assume an environment of a single host as we did for Datadog running on Linux. In this scenario, you will need to install the Log Analytics agent as follows:</p>
			<pre>$ wget https://raw.githubusercontent.com/Microsoft/OMS-Agent-for-Linux/master/installer/scripts/onboard_agent.sh &amp;&amp; sh onboard_agent.sh -w &lt;workspace_id&gt; -s &lt;workspace_key&gt;</pre>
			<p>You can now restart the agent<a id="_idIndexMarker1155"/> using the following command:</p>
			<pre>$ sudo /opt/microsoft/omsagent/bin/service_control restart [&lt;workspace_id&gt;]</pre>
			<p>Now let's try running the monitor <a id="_idIndexMarker1156"/>against the container as follows:</p>
			<pre>$ sudo docker run --privileged -d -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/containers:/var/lib/docker/containers -e WSID="&lt;workspace_id&gt;" -e KEY="&lt;workspace_key&gt;" -h=`hostname` -p 127.0.0.1:25225:25225 --name="omsagent" --restart=always microsoft/oms</pre>
			<p>We can modify the event data we collect under the <strong class="bold">Data</strong> option of the Log Analytics workspace. From here, we can add syslog and also enable the Linux Performance Counters.</p>
			<p>Once the solution is enabled, you will see the <strong class="bold">Container</strong> tile appear. You can then drill into the <strong class="bold">Container</strong> dashboard to gather metrics.</p>
			<p>Now we have some monitoring in place, let's look at some security features that are available in Azure for container-based platforms. </p>
			<h2 id="_idParaDest-319"><a id="_idTextAnchor340"/>Using Security Center to secure your containers in Azure</h2>
			<p>With monitoring in place, you<a id="_idIndexMarker1157"/> can now move on to looking at Microsoft's container security tools. The recommended native tool for achieving this in Azure is the Security Center service.</p>
			<p>You can sign up to add it to your Azure account by clicking the <strong class="bold">Turn on Security Center</strong> button at <a href="https://azure.microsoft.com/en-us/services/security-center/">https://azure.microsoft.com/en-us/services/security-center/</a> and sign up for an Azure account at the same time if you wish.</p>
			<p>Once you have the feature enabled, you will see that Security Center provides a number of features, including the following:</p>
			<ul>
				<li>Container runtime protection</li>
				<li>Vulnerability management</li>
				<li>Environment hardening</li>
			</ul>
			<p>We'll take a look at each of these briefly.</p>
			<h3>Container runtime protection</h3>
			<p>Security Center's <a id="_idIndexMarker1158"/>runtime protection for container environments allows you to generate real-time threat metrics that can be used to plan remediation efforts. The threat detection mechanism is broken down into two core areas:</p>
			<ul>
				<li><strong class="bold">At the host level</strong>: At this level, we can monitor for containers acting in a malicious or suspicious fashion, including an exposed Docker daemon or a privileged command run within the container.</li>
				<li><strong class="bold">At the AKS cluster level</strong>: AKS cluster-level threat detection analyzes the Kubernetes audit logs for suspicious activity such as highly privileged role creation or a coin miner being detected.</li>
			</ul>
			<p>These two features combined can help to look at the layers of your container stack and detect suspicious activity.</p>
			<h3>Vulnerability management</h3>
			<p>Here, you can use the Container <a id="_idIndexMarker1159"/>Registries bundle to scan new images when they are pushed. Security Center integration with third-party security provider Qualys scans the container for some of the vulnerabilities we've discussed in this book.</p>
			<p>When an issue is detected, it will be logged on the dashboard with a recommended remediation step.</p>
			<h3>Environment hardening</h3>
			<p>Security Center<a id="_idIndexMarker1160"/> provides a variety of tools for monitoring the security of your container environment. One of the most important features is running bench mark tests, such as the CIS Docker Benchmark, to alert you if your environment's configuration is weakened. An example of a CIS control is checking whether containers have unrestricted network traffic being exchanged between each other.</p>
			<p>You can download a copy of the CIS Docker Benchmark<a id="_idIndexMarker1161"/> for free from the CIS website:</p>
			<p><a href="https://learn.cisecurity.org/benchmarks">https://learn.cisecurity.org/benchmarks</a></p>
			<p class="callout-heading">Note</p>
			<p class="callout">InSpec users may be interested in <a id="_idIndexMarker1162"/>downloading the InSpec profile for CIS Docker Benchmarking at <a href="https://github.com/dev-sec/cis-docker-benchmark">https://github.com/dev-sec/cis-docker-benchmark</a>.</p>
			<p>When Security Center spots a problem with your environment, it will flag it on the <strong class="bold">Recommendations</strong> page of the dashboard for you, so you can start remediating the issue.</p>
			<p>We've briefly looked at what is available in Azure. Let's wrap up with a quick tour of some of GCP's features.</p>
			<h1 id="_idParaDest-320"><a id="_idTextAnchor341"/>Securing your containers using GCP</h1>
			<p>Google <a id="_idIndexMarker1163"/>offers a number of tools for monitoring containers in both <a id="_idIndexMarker1164"/>Anthos and <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>).</p>
			<p>For those unfamiliar with Google's offerings, Anthos is a platform that is designed for hybrid and multi-cloud deployment and allows you, among other features, to deploy container-oriented platforms such as Kubernetes. GKE is Google's enterprise-grade Kubernetes platform offered via <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) and can be thought of as a rival to Amazon's EKS. Googles Container Registry is a platform for storing images that can be reused across your projects.</p>
			<p>For the following sections, it is assumed that you have some prior knowledge of GCP. If you would like to <a id="_idIndexMarker1165"/>know more about getting started with GCP, please visit the following link:</p>
			<p><a href="https://cloud.google.com/gcp/getting-started">https://cloud.google.com/gcp/getting-started</a></p>
			<p>Let's start by looking at container security in GCP.</p>
			<h2 id="_idParaDest-321"><a id="_idTextAnchor342"/>Container Analysis and Binary Authorization in GCP</h2>
			<p>A useful feature that Google offers is <a id="_idIndexMarker1166"/>the <strong class="bold">Container Analysis</strong> scanner for Container Registry. This feature allows you to scan images for security issues and exposes an API for your use to pull down the metadata results. If you enable this feature on your account, it will scan all new images that are pushed to the registry, however, for existing images you will need to re-push them to trigger the scan.</p>
			<p>The two core features of <a id="_idIndexMarker1167"/>Container Analysis are the following:</p>
			<ul>
				<li><strong class="bold">Incremental scans</strong>: This handles the scanning of new images and generates the metadata related to them.</li>
				<li><strong class="bold">Continuous monitoring</strong>: The metadata generated by incremental scans is continuously analyzed to see if it matches new sets of security vulnerabilities.</li>
			</ul>
			<p>When running scans, a severity level for effective severity (the level defined by the Linux distribution owner) and <strong class="bold">Common Vulnerability Scoring System</strong> (<strong class="bold">CVSS</strong>) score is assigned to a <a id="_idIndexMarker1168"/>matching issue.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you would like to know<a id="_idIndexMarker1169"/> more about CVSS, please visit the CVSS website: <a href="https://www.first.org/cvss/specification-document">https://www.first.org/cvss/specification-document</a>.</p>
			<p>Severity levels are categorized as follows:</p>
			<ul>
				<li>Critical</li>
				<li>High</li>
				<li>Medium</li>
				<li>Low</li>
				<li>Minimal</li>
			</ul>
			<p>These results are stored within your <a id="_idIndexMarker1170"/>Container Registry account and can be viewed from there. Additionally, they can be retrieved by the RESTful API. For an overview of the REST commands available, please refer to the Container Analysis API documentation:</p>
			<p><a href="https://cloud.google.com/container-registry/docs/reference/rest">https://cloud.google.com/container-registry/docs/reference/rest</a></p>
			<p>To explore Container Analysis further, you can enable it within your account and test it out by pushing an existing image to the registry. For example, you could use one of the <code>shipitclicker</code> projects we have used throughout this book. To do this, remember to tag the image first:</p>
			<pre>$ docker tag &lt;source_image&gt; &lt;hostname&gt;/&lt;project_id&gt;/&lt;image&gt;:&lt;tag&gt;</pre>
			<p>The hostname will be one of the four following storage regions:</p>
			<ul>
				<li><a href="http://gcr.io">gcr.io</a> (US)</li>
				<li><a href="http://us.gcr.io">us.gcr.io</a> (US)</li>
				<li><a href="http://eu.gcr.io">eu.gcr.io</a> (EU)</li>
				<li><a href="http://asia.gcr.io">asia.gcr.io</a> (Asia)</li>
			</ul>
			<p>Then, to push to the registry, use the <code>docker push</code> command in the following format:</p>
			<pre>$ docker push &lt;hostname&gt;/&lt;project_id&gt;/&lt;image&gt;:&lt;tag&gt;</pre>
			<p>It's as simple as that, you can then pull the container image as and when you need to and use the Container Analysis service. In addition to conducting analysis on containers, we can enforce rule<a id="_idTextAnchor343"/>s around using signed images to complement this. </p>
			<p>Google have built a <a id="_idIndexMarker1171"/>deploy-time security feature geared toward preventing untrusted container images from making it into GKE. This is <a id="_idIndexMarker1172"/>called <strong class="bold">Binary Authorization</strong> (<a href="https://cloud.google.com/binary-authorization">https://cloud.google.com/binary-authorization</a>). </p>
			<p>Binary Authorization is built around <strong class="bold">Kritis</strong>, which defines<a id="_idIndexMarker1173"/> a specification for the deployment authorization of Kubernetes applications. You can read more about it here on GitHub:</p>
			<p><a href="https://github.com/grafeas/kritis/blob/master/docs/binary-authorization.md">https://github.com/grafeas/kritis/blob/master/docs/binary-authorization.md</a> </p>
			<p>Using this service will allow you to enforce rules around requiring Docker images to be signed by trusted authorities. This involves a process known as attestations. Effectively, each container image has a unique hash (called a digest), which is signed by the signer. You might remember we saw how digests can be used earlier in this book, in <a href="B11641_13_Final_NM_ePub.xhtml#_idTextAnchor299"><em class="italic">Chapter 13</em></a>, <em class="italic">Docker Security Fundamentals and Best Practices</em>.</p>
			<p>When a digest is signed, this is known as an attestation. When we come to deploy a container image, we can use a Binary Authorization attestor to verify the attestation. This allows us to prevent unauthorized – that is, unsigned – container images being used.</p>
			<p>If you are interested in learning more, to set up Binary Analysis you can follow the simple steps documented here:</p>
			<p><a href="https://cloud.google.com/binary-authorization/docs/quickstart">https://cloud.google.com/binary-authorization/docs/quickstart</a></p>
			<p>Let's now take a look at another feature of GCP, Security Command Center.</p>
			<h2 id="_idParaDest-322"><a id="_idTextAnchor344"/>Understanding your attack surface with Security Command Center</h2>
			<p>The final tool we will quickly take a<a id="_idIndexMarker1174"/> look at is Google's Security <a id="_idIndexMarker1175"/>Command Center. For this, you will need to have set up an organization and project in GCP to work with. If not, please refer back to the preceding section for a link to Google's own quick-start guide.</p>
			<p>To enable Security Command Center for this new organization and project, follow these steps:</p>
			<ol>
				<li value="1">Log into Cloud Console at <a href="https://console.cloud.google.com">https://console.cloud.google.com</a>.</li>
				<li>Add the following two roles via <code>organizationAdmin</code> (<code>roles/resourcemanager.organizationAdmin</code>) from <code>securitycenter.admin</code> (<code>roles/securitycenter.admin</code>) from <strong class="bold">Security Center</strong> | <strong class="bold">Security Center Admin</strong>.</li>
				<li>Save the changes and navigate to the Security Command Center page in the web console.</li>
				<li>Select the organization you added in step 2 from the drop-down list called <strong class="bold">Organization</strong>.</li>
				<li>You will now be<a id="_idIndexMarker1176"/> presented with the <strong class="bold">Enable asset discovery</strong> page.</li>
				<li>Enable the <strong class="bold">All current and future projects</strong> option.</li>
				<li>Asset discovery will now begin.</li>
			</ol>
			<p>Once Security <a id="_idIndexMarker1177"/>Command Center has finished scanning your resources, you will be able to see the results on the dashboard. By default, anomaly detection is enabled, however, Google provides a number of security sources you can integrate, or you can plug in container-specific third-party services.</p>
			<p>A full list of the potential sources you can integrate can be found here:</p>
			<p><a href="https://cloud.google.com/security-command-center/docs/how-to-security-sources">https://cloud.google.com/security-command-center/docs/how-to-security-sources</a></p>
			<p>With these two basic services set up, you are now free to explore integrating other third-party providers such as Twistlock or experiment with these services to get comfortable rolling them out to a production environment.</p>
			<p>That concludes our whistle-stop tour of a few of the major cloud providers' offerings. Let's summarize what we have looked at.</p>
			<h1 id="_idParaDest-323"><a id="_idTextAnchor345"/>Summary</h1>
			<p>In this chapter, we've provided you with some pointers for where you can take your cloud skills to next. This has included looking at scanning tools such as Anchore, reviewing metric-gathering platforms such as Datadog, and looking briefly at some of the features offered by the major cloud providers.</p>
			<p>These cloud platforms included AWS, Microsoft Azure, and GCP. Each of these companies also provide a number of other cloud-based container infrastructure products you may wish to explore further.</p>
			<p>We hope this high-level overview has provided you with some thoughtful insights on how to apply these skills to your own projects. Each topic in this chapter should act as a jumping-off point to explore each tool further, or provide you with the basics to start experimenting with monitoring in a cloud-based container environment. For those of you working with local projects, tools such as Docker stats and cAdvisor will provide a handy mechanism for monitoring container performance.</p>
			<p>Now we will move on to the final chapter, where we shall recap what we have studied throughout the book and leave you with some takeaway points for where to take your learning to next.</p>
			<h1 id="_idParaDest-324"><a id="_idTextAnchor346"/>Further reading</h1>
			<p>Don't forget you can visit each provider's website for a list of these further features:</p>
			<ul>
				<li>Containers on AWS: <a href="https://aws.amazon.com/containers/services/">https://aws.amazon.com/containers/services/</a></li>
				<li>Container services in Azure: <a href="https://azure.microsoft.com/en-us/product-categories/containers/">https://azure.microsoft.com/en-us/product-categories/containers/</a></li>
				<li>Container options in GCP: <a href="https://cloud.google.com/container-options">https://cloud.google.com/container-options</a></li>
			</ul>
		</div>
	</body></html>