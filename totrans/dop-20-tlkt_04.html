<html><head></head><body><div class="chapter" title="Chapter&#xA0;4.&#xA0;Setting Up the Development Environment with Vagrant and Docker"><div class="titlepage"><div><div><h1 class="title"><a id="ch04"/>Chapter 4. Setting Up the Development Environment with Vagrant and Docker</h1></div></div></div><p>The development environment is often the first thing newcomers to the project need to face. While each project is different, is it not uncommon for them to spend a whole day setting up the environment, and many more days trying to understand how the application works.</p><p>How much time it takes to, for example, install JDK, setup local instance of JBoss server, do all the configuration and all other, often complicated, things required for the back-end part of the application. On top of that, add the time to do the same for the front-end when it is separated from the back-end. How much time does it take to, for example, understand inner workings of some monolithic application that has thousands, tens of thousands or even millions of lines of code split into layers upon layers of what was initially thought as a good idea but with time ended up as something that adds more complexity than benefits?</p><p>Development environment setup and simplicity are some of the areas where <span class="strong"><strong>containers</strong></span> and <span class="strong"><strong>microservices</strong></span> can help a lot. Microservices are, by definition, small. How much time does it take to understand a thousand (or less) lines of code? Even if you never programmed in the language used in the microservice in front of you, it should not take a lot of time to understand what it does. Containers, on the other hand, especially when combined with Vagrant, can make the development environment setup feel like a breeze. Not only that the setup process can be painless and fast, but the result can be as close as one can get to the production environment. Actually, with the exception of hardware, it can be the same.</p><p>Before we start working on such an environment, let us discuss the technology behind the service we are building.</p><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note01"/>Note</h3><p>Please note that the code that will be used throughout this book might change and, therefore, might not fully reflect snippets from this book. While this might create occasional confusion, I thought you might benefit from bug fixes (every code has them) and well as updates. Technology stack we'll use is so new that changes and improvements are coming on a daily basis, and I'll try to include them in the code even after this book has been released.</p></div></div><div class="section" title="Combining Microservice Architecture and Container Technology"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec13"/>Combining Microservice Architecture and Container Technology</h1></div></div></div><p>The books microservice (<code class="literal">books-ms</code>) that we'll use throughout this book was created in a bit different <a class="indexterm" id="id172"/>way than most microservices proponents tend to recommend.</p><p>Apart from<a class="indexterm" id="id173"/> things we <a class="indexterm" id="id174"/>already discussed the need for a service to be small, limited to a well-defined bounded context, and so on, it is important to notice that most microservices are created only for the back-end part of the system. Microservices proponents would split monolithic back-end into a lot of small microservices but would often leave the front-end untouched. The result in those cases is an overall architecture with monolithic front-end and back-end split into microservices. Why is that? I think that the answer lies in technologies we're using. The way we are developing front-end is not designed to be split into smaller pieces.</p><p>Server-side rendering is becoming history. While enterprise might not agree with that statement and continues pushing for server-side frameworks that "magically" transform, for example, Java objects to HTML and JavaScript, client-side frameworks will continue to increase in popularity slowly sending the server-side page rendering into oblivion. That leaves us with client-side frameworks. Single-page applications are what we tend to use today. AngularJS, React, ExtJS, ember.js and others proved to be the next step in the evolution of front-end development. However, single-page applications or not, most of them are promoting the monolithic approach to front-end architecture.</p><p>With back-end being split into microservices and front-end being monolithic, services we are building do not truly adhere to the idea that each should provide a full functionality. We are supposed to apply vertical decomposition and create small loosely coupled applications. However, in most cases we're missing visual aspect inside those services.</p><p>All front-end functionality (authentication, inventory, shopping cart, and so on) is part of a single application and communicates with back-end (most of the time through HTTP) that is split into microservices. This approach is a big advancement when compared with a single monolithic application. By keeping back-end services small, loosely coupled, designed for a single purpose and easy to scale, some of the problems we had with monoliths become mitigated. While nothing is ideal, and microservices have their set of problems, finding production bugs, testing, understanding the code, changing framework or even language, isolation, responsibility and other things became easier to handle. The price we had to pay was deployment, but that was significantly improved with containers (Docker) and the concept of immutable servers.</p><p>If we see the benefits microservices are providing with the back-end, wouldn't it be a step forward if we could apply those benefits to the front-end as well and design microservices to be complete with not only back-end logic but also visible parts of our applications? Wouldn't it be beneficial if a developer or a team could fully develop a feature and let someone else just import it into the application? If we could do business in that way, front-end (SPA or not) would be reduced to a scaffold that is in charge only of routing and deciding which services to import.</p><p>I'm not trying<a class="indexterm" id="id175"/> to say that <a class="indexterm" id="id176"/>no one is developing microservices in such a way that both front-end and back-end are part of it. I know that there are projects that do just that. However, I was not convinced that benefits of splitting the front-end into parts and packing them together with back-end outweigh downsides of such an approach. That is, until web components came into being.</p><p>I won't go into details how web components work since one of the goals of this book is to be language-agnostic (as much as that is possible). If you're interested to know more about the <a class="indexterm" id="id177"/>subject, please visit the <a class="ulink" href="https://technologyconversations.com/2015/08/09/including-front-end-web-components-into-microservices/">https://technologyconversations.com/2015/08/09/including-front-end-web-components-into-microservices/</a> article.</p><p>For now, the important thing to note is that the <code class="literal">books-ms</code> that we are about to start using has both the front-end web components and the back-end API packed into a single microservice. That allows us to keep the full functionality in one place and use it as we see fit. Someone might invoke the service API while someone else might decide to import web components into their Web site. As the authors of the service, we should not care much who is using it but only that it provides all the functionality potential users might require.</p><p>The service itself is coded using Scala with Spray that serves API requests and static front-end files. Web components are done with Polymer. Everything is coded using test-driven development approach that produced both unit and functional/integration tests. The source <a class="indexterm" id="id178"/>code is located in the <a class="ulink" href="https://github.com/vfarcic/books-ms">https://github.com/vfarcic/books-ms</a> GitHub repository.</p><p>Don't worry if you never worked with Scala or Polymer. We won't be going into more details nor are we going to develop this application further. We'll use it to demonstrate concepts and to practice. For now, we'll use this service to setup the development environment. Before we do that, let us briefly go through the tools we'll use for this task.</p><div class="section" title="Vagrant and Docker"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec30"/>Vagrant and Docker</h2></div></div></div><p>We'll set up our development environment using <span class="strong"><strong>Vagrant</strong></span> and <span class="strong"><strong>Docker</strong></span>.</p><p>Vagrant is<a class="indexterm" id="id179"/> a command-line tool for <a class="indexterm" id="id180"/>creating and managing <a class="indexterm" id="id181"/>virtual machines through a hypervisor<a class="indexterm" id="id182"/> like VirtualBox or VMWare. Vagrant isn't a hypervisor, just a driver that provides a consistent interface. With a single Vagrantfile, we can specify everything Vagrant needs to know to create, through VirtualBox or VMWare, as many VMs as needed. Since all it needs is a single configuration file, it can be kept in the repository together with the application code. It is very lightweight and portable and allows us to create reproducible environments no matter the underlying OS. While containers make the usage of VMs partly obsolete, Vagrant shines when we need a development environment. It's been used, and battle tested, for years.</p><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note02"/>Note</h3><p>Please make sure that your Vagrant version is at least 1.8. Some of the readers experienced problems on older versions.</p><p>Please note that containers do not always replace VMs. Virtual machines provide an additional layer of isolation (security). They, also, allow more permutations than containers. With VMs, you could run Android if you wanted to. VMs are complimentary to containers. As Kelsey Hightower (formerly CoreOS, now Google) says <span class="emphasis"><em>If you replace all your VMs with containers, I look forward to seeing how your site was hacked on the front page of HackerNews</em></span>. That being said, containers reduce the usage of VMs. While it is still debatable whether we should run containers on "bare metal" or inside VMs, there is no need anymore to waste resources by creating one VM per application or service.</p></div></div><p>Docker containers allow us to wrap up some software in a complete filesystem. They can contain everything that software needs to run with complete autonomy; code, runtime libraries, database, application server, and so on. Since everything is packed together, containers will run the same no matter the environment. Containers share the kernel of the host OS making them more lightweight than virtual machines since they require a fully operational operating system. One single server can host many more containers than VMs. Another noticeable feature is that they provide process isolation. That isolation is not as solid as the one offered by virtual machines. However, VMs are much heavier than containers, and it would be very inefficient to pack each microservice into a separate VM. Containers, on the other hand, are a perfect fit for that task. We can pack each service into a separate container, deploy them directly on top of OS (without VMs in between) and still maintain the isolation between them. Apart from the kernel, nothing is shared (unless we choose to) and each container is a world in itself. At the same time, unlike VMs, containers are immutable. Each is a set of unchangeable images, and the only way to deploy a new release is to build a new container and replace the running instance of the old release. Later on, we'll discuss strategies for blue-green deployment that will run both releases in parallel, but that is the subject of one of the next chapters. As you will soon discover, containers can have a much broader usage than running production software.</p><p>Just like Vagrantfile that defines everything needed for Vagrant to create a virtual machine, Docker has <span class="emphasis"><em>Dockerfile</em></span> that contains instructions how to build a container.</p><p>At this point, you might be asking why do we need Vagrant if Docker does the same and more? We'll use it to bring up a virtual machine with Ubuntu OS. I could not be sure which <a class="indexterm" id="id183"/>operating system you are <a class="indexterm" id="id184"/>using. You might be a Windows <a class="indexterm" id="id185"/>user or an OS X fan. You might <a class="indexterm" id="id186"/>prefer one of Linux distributions. This book, for example, is written on Ubuntu as it is my OS of choice. The decision was made to use VMs to ensure that all the commands and tools throughout this book work on your computer no matter the underlying OS. Right now we are about to start one as an example of setting up the development environment. Later on, we'll create many more. They will simulate testing, staging, production, and other types of environments. We'll use Ubuntu and a few more operating systems. That does not mean that you should use Vagrant VMs as presented in this book when you try to apply what you learned. While they are useful for development scenarios and for trying new things, you should reconsider deploying containers directly on top an of OS installed on "bare metal" or to a production ready VM.</p><p>The time has come to stop talking and move towards more practical parts. Throughout the rest of this book, I will assume that Git and Vagrant are installed on your computer. There will be no other requirement. Everything else you might need will be provided through instructions and scripts.</p><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="tip02"/>Tip</h3><p>If you are using Windows, please make sure that Git is configured to use <code class="literal">Checkout as-is</code>. That can be accomplished during the setup by selecting the second or third options from the screen depicted in the Figure 4-1. Also, if you do not have SSH installed, please make sure that <code class="literal">[PATH_TO_GIT]\bin</code> is added to your PATH:</p></div></div><div class="mediaobject"><img alt="Vagrant and Docker" src="graphics/B05848_04_01.jpg"/><div class="caption"><p>Figure 4-1 – On Windows, Checkout as-is option should be selected during the Git setup</p></div></div></div></div></div>
<div class="section" title="Development Environment Setup"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec14"/>Development Environment Setup</h1></div></div></div><p>Let us start by <a class="indexterm" id="id187"/>cloning the code from the <code class="literal">books-ms</code> GitHub repository:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>git clone https://github.com/vfarcic/books-ms.git</strong></span>
<span class="strong"><strong>cd books-ms</strong></span>
</pre></div><p>With the code downloaded we can proceed and create the development environment.</p><div class="section" title="Vagrant"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl3sec03"/>Vagrant</h2></div></div></div><p>Creating <a class="indexterm" id="id188"/>a Vagrant virtual machine<a class="indexterm" id="id189"/> is easy:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>vagrant plugin install vagrant-cachier</strong></span>
<span class="strong"><strong>vagrant up dev</strong></span>
</pre></div><p>The first command is not mandatory, but it will help speeding up the creation of new VMs. It caches all packages that are being used so that the next time we need them, they are obtained from the local HD instead being downloaded. The second command does the "real" work. It brings up the VM called dev. The first attempt might take some time since everything, starting with the base box, needs to be downloaded. Bringing up this VM will be much faster each consecutive time. Bringing up any other Vagrant VM based on the same box (in this case <code class="literal">ubuntu/trusty64</code>) will be fast.</p><p>Please <a class="indexterm" id="id190"/>note that some of the commands<a class="indexterm" id="id191"/> we'll be executing throughout the book might require a substantial time to finish. As a general rule, feel free to continue reading while commands are running (at least until you are asked to run a new command). Let us use the time needed to bring up the VM to go through the Vagrantfile located in the root of the code we just cloned. It contains all the information Vagrant needs to create the development environment VM. The contents are as follows:</p><div class="informalexample"><pre class="programlisting">Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  config.vm.box = "ubuntu/trusty64"
  config.vm.synced_folder ".", "/vagrant"
  config.vm.provider "virtualbox" do |v|
    v.memory = 2048
  end
  config.vm.define :dev do |dev|
    dev.vm.network "private_network", ip: "10.100.199.200"
    dev.vm.provision :shell, path: "bootstrap.sh"
    dev.vm.provision :shell,
      inline: 'PYTHONUNBUFFERED=1 ansible-playbook \/vagrant/ansible/dev.yml -c local'
  end
  if Vagrant.has_plugin?("vagrant-cachier")
    config.cache.scope = :box
  end
end</pre></div><p>For those unfamiliar with Ruby, the syntax might look a bit cryptic but after a very short practice, you'll notice that it is very easy and straightforward to define one or more VMs with Vagrant. In our case, we started by specifying the box to be <code class="literal">ubuntu/trusty64</code>.</p><p>Vagrant boxes are the package format for Vagrant environments. Anyone can use a box, on any platform supported by Vagrant, to bring up an identical working environment.</p><p>In other words, the box is (a kind of) a VM on top of which we can add things we require. You can browse available boxes from <code class="literal">Atlas</code> or <code class="literal">create your own</code>.</p><p>After the box, comes the specification that local directory should be synced with VM. In our case, we set that the current directory (<code class="literal">.</code>) should be synced with the <code class="literal">/vagrant</code> directory inside the VM. This way, all the files from the current directory will be freely available within the virtual machine.</p><p>Moving on, we specified that the VM should have 2 GB of RAM and defined one VM called <a class="indexterm" id="id192"/>
<span class="emphasis"><em>dev</em></span>. Further on, throughout the book, we'll see how we can specify multiple virtual <a class="indexterm" id="id193"/>machines within the same <span class="emphasis"><em>Vagrantfile</em></span>.</p><p>Inside the definition of the dev VM, we set the IP that Vagrant will expose and that it should run the Ansible playbook <code class="literal">dev.yml</code>. We won't go into more details regarding Ansible since that is reserved for one of the next chapters. Suffice to say that Ansible will make sure<a class="indexterm" id="id194"/> that <a class="indexterm" id="id195"/>
<span class="strong"><strong>Docker</strong></span> and <span class="strong"><strong>Docker Compose</strong></span> are up and running.</p><p>We'll use <a class="indexterm" id="id196"/>Vagrant on many occasions <a class="indexterm" id="id197"/>throughout this book so you'll have plenty of opportunities to learn more about it. However, this book does not provide detailed guidelines and documentation. For more information and the complete documentation, please<a class="indexterm" id="id198"/> visit the <a class="ulink" href="https://www.vagrantup.com/">https://www.vagrantup.com/</a>.</p><p>Hopefully, you have a fast internet connection and by this time, execution of <code class="literal">vagrant up</code> probably finished. If not, grab a coffee and have a short break.</p><p>Let us enter the VM we just created and take a look what's inside:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>vagrant ssh dev</strong></span>
<span class="strong"><strong>ansible --version</strong></span>
<span class="strong"><strong>docker --version</strong></span>
<span class="strong"><strong>docker-compose --version</strong></span>
<span class="strong"><strong>cd /vagrant</strong></span>
<span class="strong"><strong>ll</strong></span>
</pre></div><p>The first command allows us to enter inside the dev VM. You will be greeted with Ubuntu's welcome message. The next three are just demonstrations that Ansible, Docker and Docker Compose are installed. Finally, we're entering the /vagrant directory and listing its content. You'll notice that it is the same as the host directory where we cloned the GitHub repository. Both of them are synchronized.</p><p>Now that we have the VM with all the software up and running, let us take a look at our second star of this chapter.</p></div><div class="section" title="Docker"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl3sec04"/>Docker</h2></div></div></div><p>We already<a class="indexterm" id="id199"/> had a short discussion about Docker<a class="indexterm" id="id200"/> and containers in general. Never the less, we might want to explore the subject a bit more. There were very few technologies that experienced such a fast adoption. What makes Docker so popular?</p><p>VM hypervisors are all based on emulating virtual hardware. A huge percentage of resources VMs use is spent on that emulation. The exact percentage depends on specific configurations of each VM, but it is not uncommon to spend 50% or more of hardware resources on hardware virtualization. What that means in practical terms is that they are very demanding on resources.</p><p>Docker, on the <a class="indexterm" id="id201"/>other hand, uses shared OS. That<a class="indexterm" id="id202"/> feature alone makes it much more efficient. With well-defined containers, we can easily have 5 times more applications running than when they are deployed to separate virtual machines. By using the host kernel, containers manage to maintain almost the same separation between processes without the hardware virtualization. Even if Docker does not bring anything else to the table, that would be enough for many to start using it.</p><p>Curious thing is that many think that containers are something new that came into being with Docker. The reality is that they've been in use at least from the year 2000. Oracle Solaris Zones, LXC and OpenVZ are few of the examples. Google is one of the companies that started using containers long time before Docker emerged. The question you might ask is what makes Docker so special if containers existed long before its first release. Docker made it easy for us to use containers and is built on top of LXC. It made useful technology simple to use and built a very powerful ecosystem around it.</p><p>Docker company quickly become the partner with almost all software industry leaders (Canonical, RedHat, Google, Microsoft, and so on) and managed to standardize containers. This partnership also brought containers to almost all operating systems. At the time of this writing, Windows Server 2016 technical preview was released featuring Docker engine running natively.</p><p>Developers and DevOps love it since it provides them with a very easy and reliable way to pack, ship and run self-sufficient applications that can be deployed virtually anywhere. Another important Docker tool is the Hub that contains official, unofficial and private containers. Whatever you need, be it an application, server, database or anything in between, chances are you will be able to find it in the Docker Hub and have it up and running with a single command in a matter of minutes.</p><p>There's much more to Docker (and containers in general) than what we discussed and you'll see throughout this book many different usages and test cases. For now, let's see how we can utilize Docker to help us with the development environment.</p></div><div class="section" title="Development Environment Usage"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec32"/>Development Environment Usage</h2></div></div></div><p>At this moment, we <a class="indexterm" id="id203"/>won't go into details how to write Dockerfile, build containers, and push them to the public or a private registry. Those will be the subjects of following chapters. At the moment, we'll focus on running pre-made containers. In particular, <code class="literal">vfarcic/books-ms-tests</code> container. It contains everything developers might need in order to work with the books-ms service that we cloned.</p><p>The container itself contains MongoDB, NodeJS, NPM, Git, Java, Scala, SBT, FireFox, Chrome and Gulp. It has all the Java and JavaScript libraries required by the project, configurations properly set, and so on. If you happen to work with all those languages and frameworks, you probably already have them installed on your computer. However, the chances are that you work only with some of them and lack the others. Even if you have everything already installed, you'd need to download Scala and JavaScript dependencies, fiddle with some configurations, run your instance of MongoDB, and so on. Instructions for<a class="indexterm" id="id204"/> this single microservice could be imposing. Now, multiply that with tens, hundreds or even thousands of microservices your enterprise might need. Even if you work only on one or very few of them, you would probably need to run some done by others. For example, your service might need to communicate with services done by some other team. While I am a strong believer that those cases should be solved with well-defined mocks, sooner or later you'll run into a situation when mocks are just not good enough.</p><p>There are different types of development tasks that we might need to perform with the <code class="literal">books-ms</code> service. Remember, it contains both the back-end (Scala with Spray) and front-end (JavaScript/HTML/CSS with PolymerJS).</p><p>We can, for example, execute <a class="indexterm" id="id205"/>
<span class="strong"><strong>Gulp</strong></span> watcher that will run all front-end tests every time there is any change in client's source code. Getting continuous feedback of the correctness of your code is especially useful if you are practicing test-driven development. For more information regarding the way front-end was developed, please <a class="indexterm" id="id206"/>consult the <a class="ulink" href="https://technologyconversations.com/2015/08/09/developing-front-end-microservices-with-polymer-web-components-and-test-driven-development-part-15-the-first-component/">https://technologyconversations.com/2015/08/09/developing-front-end-microservices-with-polymer-web-components-and-test-driven-development-part-15-the-first-component/</a> article series.</p><p>The following command runs the watcher:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>sudo docker run -it --rm \</strong></span>
<span class="strong"><strong>    -v $PWD/client/components:/source/client/components \</strong></span>
<span class="strong"><strong>    -v $PWD/client/test:/source/client/test \</strong></span>
<span class="strong"><strong>    -v $PWD/src:/source/src \</strong></span>
<span class="strong"><strong>    -v $PWD/target:/source/target \</strong></span>
<span class="strong"><strong>    -p 8080:8080 \</strong></span>
<span class="strong"><strong>    --env TEST_TYPE=watch-front \</strong></span>
<span class="strong"><strong>    vfarcic/books-ms-tests</strong></span>
</pre></div><p>A couple of readers commented that in rare occasions the tests fail (probably due to concurrency). If such a thing happens to you, please rerun tests.</p><p>A lot of layers need to be downloaded before this container is run. The container occupies around 2.5GB of virtual space (the actual physical size is much smaller). Unlike production containers that should be as small as possible, those used in development tend to be much bigger. For example, only NodeJS modules occupy almost 500MB, and those are just the front-end development dependencies. Add Scala libraries, runtime executables, browsers, and so on. Things sum up pretty quickly. Hopefully, you have a fast internet connection, and it won't take long until all the layers are pulled. Feel free to continue reading until the download is done or until you reach the instruction to run another command.</p><p>Parts of the output <a class="indexterm" id="id207"/>should be as follows (timestamps are removed for brevity):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>MongoDB starting : pid=6 port=27017 dbpath=/data/db/ 64-bit host=072ec2400bf0</strong></span>
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>allocating new datafile /data/db/local.ns, filling with zeroes...</strong></span>
<span class="strong"><strong>creating directory /data/db/_tmp</strong></span>
<span class="strong"><strong>done allocating datafile /data/db/local.ns, size: 16MB,  took 0 secs</strong></span>
<span class="strong"><strong>allocating new datafile /data/db/local.0, filling with zeroes...</strong></span>
<span class="strong"><strong>done allocating datafile /data/db/local.0, size: 64MB,  took 0 secs</strong></span>
<span class="strong"><strong>waiting for connections on port 27017</strong></span>
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>firefox 43                Tests passed</strong></span>
<span class="strong"><strong>Test run ended with great success</strong></span>
<span class="strong"><strong>firefox 43 (93/0/0)</strong></span>
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>connection accepted from 127.0.0.1:46599 #1 (1 connection now open)</strong></span>
<span class="strong"><strong>[akka://routingSystem/user/IO-HTTP/listener-0] Bound to /0.0.0.0:8080</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>We just run <code class="literal">93 tests</code> using Firefox, run the MongoDB and started the Web server with Scala and Spray. All Java and JavaScript dependencies, runtime executables, browser, MongoDB, JDK, Scala, sbt, npm, bower, gulp and everything else we might need are inside this container. All that was accomplished with a single command. Go ahead and change the client source code located in the <code class="literal">client/components</code> directory or tests in the <code class="literal">client/test</code>. You'll see that as soon as you save changes, tests will run again. Personally, I tend to keep my screen split in two. The first half with the code and the other half with the terminal when those tests are running in. We got a continuous feedback with a single command and no installations or setup of any kind.</p><p>As mentioned above, it's not only front-end tests that we are running with this command but also the Web server and MongoDB. With those two we can see the result of our work by opening the <a class="ulink" href="http://10.100.199.200:8080/components/tc-books/demo/index.html">http://10.100.199.200:8080/components/tc-books/demo/index.html</a> in your favorite browser. What you see is a demo of Web components that we are going to use later on.</p><p>We won't go into details of what each argument in the command we just run means. That is reserved for one of the next chapters when we'll explore Docker CLI in more depth. The important thing to notice is that we run the container that was downloaded from the Docker Hub. Later on, we'll install our own registry where we'll store our containers. Another important thing is that a few local directories are mounted as container volumes allowing us to change the source code files locally and use them inside the container.</p><p>The major problem <a class="indexterm" id="id208"/>with the command above is its length. I, for one, am not capable remembering such a long command, and we cannot expect all developers to know it either. While what we did by now is by far easier than alternative methods for setting up the development environment, this command in itself clashes with the simplicity we're trying to accomplish. Much better way to run Docker commands is <a class="indexterm" id="id209"/>through <span class="strong"><strong>Docker Compose</strong></span>. Again, we'll reserve deeper explanation for one of the next chapter. For now, let us just get a taste of it. Please stop the container that is currently running by pressing <span class="emphasis"><em>Ctrl</em></span> + <span class="emphasis"><em>C</em></span> and run the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>sudo docker-compose -f docker-compose-dev.yml run feTestsLocal</strong></span>
</pre></div><p>As you can see the result is the same but the command is this time much shorter. All the arguments needed for this container to run are stored in the <code class="literal">docker-compose-dev.yml</code> file under <a class="indexterm" id="id210"/>the target <code class="literal">feTestsLocal</code>. The configuration file is using <span class="strong"><strong>Yet Another Markup Language</strong></span> (<span class="strong"><strong>YAML</strong></span>) format that is very easy to write and read for those who are familiar with Docker.</p><p>That was only one of many usages of this container. Another one, out of many more, is to run all tests once (both back-end and front-end), compile Scala code and minify and prepare JavaScript and HTML files for the distribution.</p><p>Before proceeding, please stop the container that is currently running by pressing <span class="emphasis"><em>Ctrl</em></span> + <span class="emphasis"><em>C</em></span> and run the following.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>sudo docker-compose -f docker-compose-dev.yml run testsLocal</strong></span>
</pre></div><p>This time, we did even more. We started MongoDB, run back-end functional and unit tests, stopped the DB, run all front-end tests and, finally, created the JAR file that will be used later on to create the distribution that will, ultimately, be deployed to the production (or, in our case, imitation of the production) node. Later on, we'll use the same container when we start working on our continuous deployment pipeline.</p><p>We won't need the development environment anymore, so let's stop the VM:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>exit</strong></span>
<span class="strong"><strong>vagrant halt dev</strong></span>
</pre></div><p>That was another one of the advantages of Vagrant. VMs can be started, stopped or destroyed with a single command. However, even if you choose the latter option, a new one can be as easily recreated from scratch. Right now, the VM is stopped. We might need it later and next time it won't take that long to start it. With the <code class="literal">vagrant up dev</code>, it will be up and running in a matter of seconds.</p><p>This chapter served two purposes. First one was to show you that, with Vagrant and Docker, we can setup development environment in a much easier and faster way than with the more traditional approaches. The second purpose was to give you a taste of what is to come. Soon we'll explore Docker and Docker Compose in more depth and start building, testing<a class="indexterm" id="id211"/> and running containers. Our goal will be to start working on the deployment pipeline. We'll begin by running commands manually. Next chapter with deal with basics and from there on we'll slowly progress towards more advanced techniques.</p></div></div></body></html>