<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch02"/>Chapter 2. Launching Applications Using Docker</h1></div></div></div><p>In this chapter, we are going to be looking at launching more than just a simple web server using our local Docker installation. We will look at the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Using Docker on the command-line to launch applications</li><li class="listitem" style="list-style-type: disc">How to use the Docker <code class="literal">build</code> command</li><li class="listitem" style="list-style-type: disc">Using Docker Compose to make multi-container applications easier to launch</li></ul></div><p>We will then look at using all the techniques above to launch a WordPress and Drupal application stack.</p><div><div><div><div><h1 class="title"><a id="ch02lvl1sec12"/>Docker terminology</h1></div></div></div><p>Before we start learning how to launch containers, we should quickly discuss some of the more common terminology we are going to be using in this chapter.</p><div><div><h3 class="title"><a id="tip04"/>Tip</h3><p>Please note, the Docker commands in this chapter have been written for use with Docker 1.13 and later. Trying to run commands such as <code class="literal">docker image pull nginx</code> in older versions will fail with an error. Please refer to <a class="link" href="ch01.html" title="Chapter 1. Installing Docker Locally">Chapter 1</a>,<em> Installing Docker Locally</em> for details on how to install the latest version of Docker.</p></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec09"/>Docker images</h2></div></div></div><p>A <strong>Docker image</strong>
<a id="id40" class="indexterm"/> is a collection of all the files that make up an executable software application. This collection includes the application plus all the libraries, binaries, and other dependencies such as deployment descriptors and so on. just needed just to run the application everywhere without any hitch or hurdle. These files in the Docker image are read-only and hence the content of the image cannot be altered. If you choose to alter the content of your image, the only option Docker allows is to add another layer with the new changes. In other words, a Docker image is made up of layers which you can review using <code class="literal">docker image history</code> subcommand.</p><p>The <a id="id41" class="indexterm"/>Docker image architecture effectively leverages this layering concept to seamlessly add additional capabilities to the existing images to meet the varying business requirements and increase the reuse of images. In other words, capabilities can be added to existing images by adding additional layers on top of that image and deriving a new image. The Docker images have a parent/child relationship and the bottom-most image is called<a id="id42" class="indexterm"/> the <strong>base image</strong>. The base image is the special image that doesn't have any parent:</p><div><img src="img/B06455_02_01A.jpg" alt="Docker images"/></div><p>In the previous diagram, Ubuntu is a base image and it does not have any parent image.</p><div><div><h3 class="title"><a id="note07"/>Note</h3><p>The Ubuntu Docker image<a id="id43" class="indexterm"/> is a minimalist bundle of software libraries and binaries that are critical to run an application. It does not include Linux Kernel, Diver Drivers, and various other services a full-fledged Ubuntu operating system would provide.</p></div></div><div><img src="img/B06455_02_01B.jpg" alt="Docker images"/></div><p>As you can see in the above diagram, everything starts with a base image and here in this example, it is Ubuntu. Further on, the <code class="literal">wget</code> capability is added to the image as a layer and the <code class="literal">wget</code> image is referencing Ubuntu image as its parent. And in the next layer, an instance of Tomcat application server is added and it refers the <code class="literal">wget</code> image as its parent. Each addition that is made to the original base image is stored in a separate layer (a kind of hierarchy gets generated here to retain the original identity).</p><p>Precisely speaking, any <a id="id44" class="indexterm"/>Docker image has to originate from a base image and an image gets continuously enriched in its functionality by getting fresh modules and this is accomplished by adding an additional module as a new layer on the existing Docker image one by one as vividly illustrated in the above diagram.</p><p>The Docker platform provides a simple way of building new images or extending existing images. You can also download the Docker images that the other people have already created and deposited in Docker image repositories (private or public).</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec10"/>Docker Registry</h2></div></div></div><p>A <strong>Docker Registry</strong>
<a id="id45" class="indexterm"/> is a place where Docker images can be stored in order to be publicly or privately found, accessed, and used by worldwide software developers for quickly crafting fresh and composite applications without any risks. Because, all the stored images will have gone through multiple validations, verifications, and refinements, the quality of those images are really high.</p><p>Using the <code class="literal">dockerimage push</code> subcommand, you can dispatch your Docker image to the registry so that it is registered and deposited. Using the <code class="literal">dockerimage pull</code> subcommand, you can download a Docker image from the registry.</p><p>A Docker Registry<a id="id46" class="indexterm"/> could <a id="id47" class="indexterm"/>be hosted by a<a id="id48" class="indexterm"/> third party as a public or private registry, such as one of the<a id="id49" class="indexterm"/> following<a id="id50" class="indexterm"/> registries:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Docker Hub (<a class="ulink" href="https://hub.docker.com">https://hub.docker.com</a>)</li><li class="listitem" style="list-style-type: disc">Quay (<a class="ulink" href="https://quay.io/">https://quay.io/</a>)</li><li class="listitem" style="list-style-type: disc">Google Container Registry (<a class="ulink" href="https://cloud.google.com/container-registry">https://cloud.google.com/container-registry</a>)</li><li class="listitem" style="list-style-type: disc">AWS Container Registry (<a class="ulink" href="https://aws.amazon.com/ecr/">https://aws.amazon.com/ecr/</a>)</li></ul></div><p>Every institution, innovator and individual can have their own Docker Registry to stock up their images for internal and/or external access and usage.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec11"/>Docker Hub</h2></div></div></div><p>In the previous chapter, when you <a id="id51" class="indexterm"/>ran the <code class="literal">dockerimage pull</code> subcommand, the <code class="literal">nginx</code> image got downloaded mysteriously. In this section, let's unravel the mystery around the <code class="literal">docker image pull</code> subcommand and how the Docker Hub immensely contributed toward this unintended success.</p><p>The good folks in the Docker community have built a repository of images and they have made it publicly available at a default location, <code class="literal">index.docker.io</code>. This default location is called the Docker Hub. The <code class="literal">docker image pull</code> subcommand is programmed to look for the images at this location. Thus, when you <code class="literal">pull</code> a <code class="literal">nginx</code> image, it is effortlessly downloaded from the default registry. This mechanism helps in speeding up the spinning of the Docker containers.</p><p>The Docker Hub is the official repository that contains all the painstakingly curated images that are created and deposited by the worldwide Docker development community. This so-called cure is enacted for ensuring that all the images stored in the Docker Hub are secure and safe through a host of quarantine tasks. There are additional mechanisms such as creating the image digest and having content trust that gives you the ability to verify both the integrity and the publisher of all the data received from a registry over any channel.</p><p>There are<a id="id52" class="indexterm"/> proven verification and validation methods for cleaning up any knowingly or unknowingly introduced malware, adware, viruses, and so on, from these Docker images.</p><div><div><h3 class="title"><a id="note08"/>Note</h3><p>The digital signature is a prominent mechanism of the utmost integrity of the Docker images. Nonetheless, if the official image has been either corrupted, or tampered with, then the Docker engine will issue a warning and then continue to run the image.</p></div></div><p>In addition to the official repository, the Docker Hub Registry also provides a platform for thethird-party developers and providers for sharing their images for general consumption. The third-party images are prefixed by the user ID of their developers or depositors.</p><p>For example, <code class="literal">russmckendrick/cluster</code>is a third-party image, wherein <code class="literal">russmckendrick</code> is the user ID and <code class="literal">cluster</code> is the image repository name. You can download any third-party image by using the <code class="literal">docker image pull</code> subcommand, as shown here:</p><div><pre class="programlisting">
<strong>docker image pull russmckendrick/cluster</strong>
</pre></div><p>Apart from the <a id="id53" class="indexterm"/>preceding repository, the Docker ecosystem also provides a mechanism for leveraging the images from any third-party repository hub other than the Docker Hub Registry, and it also provides the images hosted by the local repository hubs. As mentioned earlier, the Docker engine has been programmed to look for images at <code class="literal">index.docker.io</code> by default, whereas in the case of the third-party or the local repository hub, we must manually specify the path from where the image should be pulled.</p><p>A manual repository path is similar to a URL without a protocol specifier, such as <code class="literal">https://</code>, <code class="literal">http://</code>and <code class="literal">ftp://</code>.</p><p>Following is an example of pulling an image from a third-party repository hub:</p><div><pre class="programlisting">
<strong>docker image pull registry.domain.com/myapp</strong>
</pre></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec13"/>Controlling Docker containers</h1></div></div></div><p>The Docker engine enables<a id="id54" class="indexterm"/> you to <code class="literal">start</code>, <code class="literal">stop</code>, and <code class="literal">restart</code> a container with a set of <code class="literal">docker</code> subcommands. Let's begin with the <code class="literal">docker container stop</code> subcommand, which stops a running container. When a user issues this command, the Docker engine sends <code class="literal">SIGTERM (-15)</code> to the main process, which is running inside the container. The<a id="id55" class="indexterm"/> <strong>SIGTERM</strong> signal requests the process to terminate itself gracefully.</p><p>Most of the processes would handle this signal and facilitate a graceful exit. However, if this process fails to do so, then the Docker engine will wait for a grace period. Even after the grace period, if the process has not been terminated, then the Docker engine will forcefully terminate the process. The forceful termination is achieved by sending <code class="literal">SIGKILL (-9)</code>.</p><p>The <strong>SIGKILL</strong> signal<a id="id56" class="indexterm"/> cannot be caught or ignored and hence, it will result in an abrupt termination of the process without a proper cleanup.</p><p>Now, let's launch our <a id="id57" class="indexterm"/>container and experiment with the <code class="literal">docker container stop</code> subcommand, as shown here:</p><div><pre class="programlisting">
<strong>dockercontainer run -i -t ubuntu:16.04 /bin/bash</strong>
</pre></div><div><img src="img/B06455_02_01.jpg" alt="Controlling Docker containers"/></div><p>Having launched the container, let's run the <code class="literal">docker container stop</code> subcommand on this container by using the container <code class="literal">ID</code> that was taken from the prompt. Of course, we have to use a second screen/terminal to run this command, and the command will always echo back to the container <code class="literal">ID</code>, as shown here:</p><div><pre class="programlisting">
<strong>docker  container stop 3 de97cc32051</strong>
</pre></div><div><img src="img/B06455_02_02.jpg" alt="Controlling Docker containers"/></div><p>Now, if you switch to the screen/terminal where you were running the container, you will notice that the container is being terminated. If you observe a little more keenly, then you will also notice the text <code class="literal">exit</code> next to the container prompt. This happened due to the SIGTERM handling mechanism of the bash shell, as shown here:</p><div><img src="img/B06455_02_03.jpg" alt="Controlling Docker containers"/></div><p>If we take it one step further and run the <code class="literal">docker container ps</code> subcommand, then we will not find this container anywhere in the list. The fact is that the <code class="literal">docker container ps</code> subcommand, by default, always lists the container that is in the running state. Since our container is in the stopped state, it was comfortably left out of the list. Now, you might ask, how do we see the container that is in the stopped state? Well, the <code class="literal">docker container ps</code> subcommand takes an additional argument <code class="literal">-a</code>, which will list all the containers in that Docker host irrespective of its status.</p><p>This can be done by running the following command:</p><div><pre class="programlisting">
<strong>docker container ps -a</strong>
</pre></div><div><img src="img/B06455_02_04.jpg" alt="Controlling Docker containers"/></div><p>Next, let's look at <a id="id58" class="indexterm"/>the <code class="literal">docker container start</code> subcommand, which is used for starting one or more stopped containers. A container could be moved to the stopped state either by the <code class="literal">docker container stop</code> subcommand or by terminating the main process in the container either normally or abnormally. On a running container, this subcommand has no effect.</p><p>Let's start the previously stopped container by using the <code class="literal">docker container start</code> subcommand, as follows:</p><div><pre class="programlisting">
<strong>docker start 3de97cc32051</strong>
</pre></div><p>By default, the <code class="literal">docker container start</code> subcommand will not attach to the container. You can attach it to the container either by using the <code class="literal">-a</code> option in the <code class="literal">docker container start</code> subcommand or by explicitly using the <code class="literal">docker container attach</code> subcommand, as shown here:</p><div><pre class="programlisting">
<strong>docker container attach 3de97cc32051</strong>
</pre></div><div><img src="img/B06455_02_05.jpg" alt="Controlling Docker containers"/></div><p>Now, let's run the <code class="literal">docker containerps</code> command and verify the container's running status, as shown here:</p><div><pre class="programlisting">
<strong>docker container ps</strong>
</pre></div><div><img src="img/B06455_02_06.jpg" alt="Controlling Docker containers"/></div><p>The <code class="literal">restart</code> command is a combination of the <code class="literal">stop</code> and the <code class="literal">start</code> functionality. In other words, the <code class="literal">restart</code> command will <code class="literal">stop</code> a running container by following the precise steps followed by the <code class="literal">docker conatiner stop</code> subcommand and then it will initiate the <code class="literal">start</code> process. This functionality will be executed by default through the <code class="literal">docker conatiner restart</code> subcommand.</p><p>The next important set of container controlling subcommands are the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">docker container pause</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">docker container unpause</code></li></ul></div><p>The <code class="literal">docker container pause</code> subcommands will essentially freeze the execution of all the processes within that container. Conversely, the <code class="literal">docker container unpause</code> subcommand will unfreeze the execution of all the processes within that container and resume the execution from the point where it was frozen.</p><p>Having seen the <a id="id59" class="indexterm"/>technical explanation of <code class="literal">pause</code>/<code class="literal">unpause</code>, let's see a detailed example for illustrating how this feature works. We have used two screen/terminal scenarios. On one terminal, we have launched our container and used an infinite while loop for displaying the date and time, sleeping for 5 seconds, and then continuing the loop. We will run the following commands:</p><div><pre class="programlisting">
<strong>docker container run -i -t ubuntu:16.04 /bin/bash</strong>
</pre></div><p>Once you are within the container, run the following:</p><div><pre class="programlisting">
<strong>while true; do date; sleep 5; done</strong>
</pre></div><p>Our little script has very faithfully printed the date and time every <code class="literal">5</code> seconds apart from when it was paused:</p><div><img src="img/B06455_02_07.jpg" alt="Controlling Docker containers"/></div><p>As you can see from the terminal output above, we encountered a delay of around 30 seconds, because this is when we initiated the <code class="literal">docker container pause</code> subcommand on our container on the second terminal screen, as shown here:</p><div><pre class="programlisting">
<strong>docker container pause 9724f4e0e444</strong>
</pre></div><p>When we paused<a id="id60" class="indexterm"/> our container, we looked at the process status by using the <code class="literal">docker containerps</code> subcommand on our container, which was on the same screen, and it clearly indicated that the container had been paused, as shown in this command result:</p><div><pre class="programlisting">
<strong>docker container ps</strong>
</pre></div><p>We continued onto issuing the <code class="literal">docker conatiner unpause</code> subcommand, which unfroze our container, continued its execution, and then started printing the date and time, as we saw in the preceding command, shown here:</p><div><pre class="programlisting">
<strong>docker container unpause 9724f4e0e444</strong>
</pre></div><p>We explained the <code class="literal">pause</code> and the <code class="literal">unpause</code> commands at the beginning of this section.</p><p>Lastly, the container and the script running within it had been stopped by using the <code class="literal">docker container stop</code> subcommand, as shown here:</p><div><pre class="programlisting">
<strong>docker container stop 9724f4e0e444</strong>
</pre></div><p>You can see everything we ran in our second terminal below:</p><div><img src="img/B06455_02_10.jpg" alt="Controlling Docker containers"/></div><p>Let's look at doing <a id="id61" class="indexterm"/>something a little more complex now.</p></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec14"/>Running a WordPress container</h1></div></div></div><p>Almost everyone at <a id="id62" class="indexterm"/>some point will have installed, used, or read about WordPress, so for our next example, we will be using the official WordPress container<a id="id63" class="indexterm"/> from the Docker Hub. You <a id="id64" class="indexterm"/>can find details on the <a id="id65" class="indexterm"/>container at <a class="ulink" href="https://hub.docker.com/_/wordpress/">https://hub.docker.com/_/wordpress/</a>.</p><div><div><h3 class="title"><a id="note09"/>Note</h3><p>WordPress is web software that you can use to create a beautiful website, blog, or app. We like to say that WordPress is both free and priceless at the same time. For more information, check out <a class="ulink" href="https://wordpress.org/">https://wordpress.org/</a>.</p></div></div><p>To launch WordPress, you will need to download and run two containers, the first of which is the database container, for this I recommend using the official MySQL container<a id="id66" class="indexterm"/> which you can find at <a class="ulink" href="https://hub.docker.com/_/mysql/">https://hub.docker.com/_/mysql/</a>.</p><p>To download the latest MySQL container image run the following command on your Mac, Windows or Linux machine:</p><div><pre class="programlisting">
<strong>docker image pull mysql</strong>
</pre></div><p>Now that you have the pulled a copy of the image you can launch MySQL by running the following command:</p><div><pre class="programlisting">
<strong>docker container run -d \</strong>
<strong>    --name mysql \</strong>
<strong>    -e MYSQL_ROOT_PASSWORD=wordpress \</strong>
<strong>    -e MYSQL_DATABASE=wordpress \</strong>
<strong>    mysql</strong>
</pre></div><p>The command above launches (<code class="literal">docker container run</code>) the MySQL in a detached state (using <code class="literal">-d</code>), meaning that it is running in the background, we are calling the container <code class="literal">mysql</code> (<code class="literal">--namewordpress</code>) and we are using two different environment variables (using <code class="literal">-e</code>) to set the MySQL root password to <code class="literal">wordpress (-e MYSQL_ROOT_PASSWORD=wordpress</code>) and to create a database called <code class="literal">wordpress</code> (<code class="literal">-e MYSQL_DATABASE=wordpress</code>).</p><p>Once launched, you should receive the container ID. You can check the container is running as expected by using the following command:</p><div><pre class="programlisting">
<strong>docker container ps</strong>
</pre></div><p>Now, at this point, although the <a id="id67" class="indexterm"/>container is running that doesn't really mean that MySQL is ready. If you were to launch your WordPress container now, you might find that it runs for a short while and then stops.</p><p>Don't worry, this is expected. As there is no MySQL data within the container it takes a little while to get itself into a state where it is available to accept incoming connections.</p><p>To check the status of your MySQL container you can run the following command:</p><div><pre class="programlisting">
<strong>docker container logs mysql</strong>
</pre></div><div><img src="img/B06455_02_11.jpg" alt="Running a WordPress container"/></div><p>Once you see the message <strong>mysqld: ready for connections</strong>, you are good to launch your WordPress container; you may find yourself having to check the logs a few times.</p><p>Next up, we to down the WordPress container image; to do this, run the following command:</p><div><pre class="programlisting">
<strong>docker image pull wordpress</strong>
</pre></div><p>Once downloaded run the following command to launch the WordPress container:</p><div><pre class="programlisting">
<strong>docker container run -d \</strong>
<strong>    --name wordpress \</strong>
<strong>--link mysql:mysql\</strong>
<strong>    -p 8080:80 \</strong>
<strong>    -e WORDPRESS_DB_PASSWORD=wordpress \</strong>
<strong>    wordpress</strong>
</pre></div><p>Again, we are launching the container in the background (using <code class="literal">-d</code>), calling the container the <code class="literal">wordpress</code> (with <code class="literal">--name wordpress</code>). This is where things differ slightly between the MySQL and WordPress containers, we need to let the WordPress container know where our MySQL <a id="id68" class="indexterm"/>container is accessible, to do this are using the link flag (in our case by running <code class="literal">--link mysql:mysql</code>) this will create an alias within the WordPress container pointing it at the IP address of the MySQL container.</p><p>Next up we are opening port <code class="literal">8080</code> on our machine and mapping it to port <code class="literal">80</code> on the container (using <code class="literal">-p 8080:80</code>) and then letting WordPress know what the password is (with <code class="literal">-e WORDPRESS_DB_PASSWORD=wordpress</code>).</p><p>Check the running containers using the following command:</p><div><pre class="programlisting">
<strong>docker container ps</strong>
</pre></div><p>Should show you that you now have two running containers, MySQL and WordPress:</p><div><img src="img/B06455_02_12.jpg" alt="Running a WordPress container"/></div><p>Unlike the MySQL container, there isn't much the WordPress container needs to do before it is accessible, you can check the logs by running the following command:</p><div><pre class="programlisting">
<strong>docker container logs wordpress</strong>
</pre></div><div><img src="img/B06455_02_13.jpg" alt="Running a WordPress container"/></div><p>If you open your browser and go to <code class="literal">http://localhost:8080/</code> you should see your WordPress installation sitting at an installation prompt like the following:</p><div><img src="img/B06455_02_14.jpg" alt="Running a WordPress container"/></div><p>If you like, you can work through the installation and get WordPress up and running by clicking on <strong>Continue</strong> and following the onscreen prompts; however, the next set of commands we will be running will destroy our two containers.</p><p>To remove <a id="id69" class="indexterm"/>everything we have just launched ahead of the next exercise, run the following commands:</p><div><pre class="programlisting">
<strong>docker container stop wordpressmysql</strong>
<strong>docker container rmwordpressmysql</strong>
<strong>docker image rm wordpress mysql</strong>
</pre></div><p>So far we have used the Docker client to easily launch, stop, start, pause, unpause and remove containers as well as downloading and removing container images from the Docker Hub, while this is great to quickly launch a few containers it can get complicated to manage once you have more than a few containers running at once, this is where the next tool we are going to look at comes in.</p></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec15"/>Docker Compose</h1></div></div></div><p>If you were following<a id="id70" class="indexterm"/> along with the Linux installation in <a class="link" href="ch01.html" title="Chapter 1. Installing Docker Locally">Chapter 1</a>,<em> Installing Docker Locally</em> then you should have already installed Docker Compose manually, for those of you that skipped that part then you will glad to know that Docker Compose is installed and maintained as part of Docker for Mac and Windows.</p><p>I am sure that you will agree that so far Docker has proved to be quite intuitive, Docker Compose is no different. It started off life as third-party <a id="id71" class="indexterm"/>software called Fig<a id="id72" class="indexterm"/> and was written by Orchard Labs (the project's original website is still available at <a class="ulink" href="http://fig.sh/">http://fig.sh/</a>).</p><p>The original project's goal was the following:</p><div><blockquote class="blockquote"><p>"Provide fast, isolated development environments using Docker"</p></blockquote></div><p>Since Orchard Labs became part of Docker, they haven't strayed too far from the original projects <a id="id73" class="indexterm"/>goal:</p><div><blockquote class="blockquote"><p>"Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a Compose file to configure your application's services.Then, using a single command, you create and start all the services from your configuration."</p></blockquote></div><p>Before we start looking at <a id="id74" class="indexterm"/>Compose files and start containers up, let's think of why a tool such as Compose is useful.</p><div><div><div><div><h2 class="title"><a id="ch02lvl2sec12"/>Why Compose?</h2></div></div></div><p>Launching <a id="id75" class="indexterm"/>individual containers is as simple as running the following command: </p><div><pre class="programlisting">
<strong>docker container run -i -t ubuntu:16.04 /bin/bash</strong>
</pre></div><p>This will launch and then attach to an Ubuntu container. As we have already touched upon, there is a little more to it than just launching simple containers though. Docker is not here to replace virtual machines, it is here to run a single application.</p><p>This means that you shouldn't really run an entire LAMP stack in single container, instead, you should look at running Apache and PHP in one container, which is then linked with a second container running MySQL.</p><p>You could take this further, running NGINX container, a PHP-FPM container, and a MySQL container. This is where it gets complicated. All of sudden, your simple single command for launching a container is now several lines, all of which must executed in the correct order with the correct flags to expose ports, link them together and configure the services using environment variables.</p><p>This is exactly the problem Docker Compose tries to fix. Rather than several long commands, you can define your containers using a YAML file. This means that you will be able to launch your application with a single command and leave the logic of the order in which the containers will be launched to Compose.</p><div><div><h3 class="title"><a id="note10"/>Note</h3><p><strong>YAML Ain't Markup Language</strong> (<strong>YAML</strong>) is a <a id="id76" class="indexterm"/>human-friendly data serialization standard for all programming languages.</p></div></div><p>It also means that you can ship your application's Compose file with your code base or directly to another developer/administrator and they will be able to launch your application exactly how you intended it be executed.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec13"/>Compose files</h2></div></div></div><p>Let's start by getting a <a id="id77" class="indexterm"/>launching WordPress again. First of all, if you haven't already clone the GitHub repository which accompanies this book. You can find it at the following URL: <a class="ulink" href="https://github.com/russmckendrick/bootcamp">https://github.com/russmckendrick/bootcamp</a></p><p>For more information on how to clone the repository please see the introduction. Once you have repo cloned run the following commands from the top level of the repo:</p><div><pre class="programlisting">
<strong>cd chapter2/compose-wordpress</strong>
</pre></div><p>The <code class="literal">compose-wordpress</code> folder contains the following <code class="literal">docker-compose.yml</code> file:</p><div><pre class="programlisting">version: "3" 

services:
mysql:
     image: mysql
     volumes:
       - db_data:/var/lib/mysql
     restart: always
     environment:
       MYSQL_ROOT_PASSWORD: wordpress
       MYSQL_DATABASE: wordpress
wordpress:
depends_on:
       - mysql
     image: wordpress
     ports:
       - "8080:80"
     restart: always
     environment:
       WORDPRESS_DB_PASSWORD: wordpress

volumes:
db_data:</pre></div><p>As you can see, the <code class="literal">docker-compose.yml</code> file is easy to follow; our initial <code class="literal">docker-compose.yml</code> file is split into three sections:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Version</strong>: This <a id="id78" class="indexterm"/>tells Docker Compose which file format we are using; the current version is 3</li><li class="listitem" style="list-style-type: disc"><strong>Services</strong>: These<a id="id79" class="indexterm"/> are where our containers are defined, you can define several containers here</li><li class="listitem" style="list-style-type: disc"><strong>Volumes</strong>: Any <a id="id80" class="indexterm"/>volumes for persistent storage are defined here, we will go into this in more detail in later chapters</li></ul></div><p>For the most part, the syntax is pretty similar to that we used to launch our WordPress containers using the Docker command-line client. There are, however a few changes:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">volumes</code>: In the <code class="literal">mysql</code> container we are taking a volume called <code class="literal">db_data</code> and mounting it to <code class="literal">/var/lib/mysql</code> within the container</li><li class="listitem" style="list-style-type: disc"><code class="literal">restart</code>: This is set to <code class="literal">always,</code> meaning that if our containers stop responding any reason, like the <code class="literal">wordpress</code> container will do until the <code class="literal">mysql</code> container is accepting connections, then it will be restarted automatically meaning we don't have to manually intervene</li><li class="listitem" style="list-style-type: disc"><code class="literal">depends_on</code>: Here <a id="id81" class="indexterm"/>we are telling the <code class="literal">wordpress</code> container not to start until the <code class="literal">mysql</code> container is running</li></ul></div><p>You may notice that we are not linking our containers, this is because Docker Compose automatically creates a network to launch the services in, each container within the network created by Docker Compose automatically has its host file updated to include aliases for each of the containers within the service, meaning that our WordPress container will be able to connect to our MySQL container using the default host of <code class="literal">mysql</code>.</p><p>To launch our WordPress installation, all we need to do is run the following commands:</p><div><pre class="programlisting">
<strong>docker-compose pull</strong>
<strong>docker-compose up -d</strong>
</pre></div><p>Using the <code class="literal">-d</code> flag at the end of the command launches the containers in detached mode, this means that they will run in the background.</p><p>If we didn't use the <code class="literal">-d</code> flag, then our containers would have launched in the foreground and we would not have been able to carry on using the same terminal session without stopping the running containers.</p><p>You will see something like the following output:</p><div><img src="img/B06455_02_15.jpg" alt="Compose files"/></div><p>While the containers are up and running, which you can see by running the follow:</p><div><pre class="programlisting">
<strong>docker-compose ps</strong>
<strong>docker container ps</strong>
</pre></div><p>It will take a short while for the MySQL container to be ready to accept connections, you may find running:</p><div><pre class="programlisting">
<strong>docker-compose logs</strong>
</pre></div><p>Show you connection <a id="id82" class="indexterm"/>errors like the ones below:</p><div><img src="img/B06455_02_16.jpg" alt="Compose files"/></div><p>Don't worry, you should soon see something like the following:</p><div><img src="img/B06455_02_17.jpg" alt="Compose files"/></div><p>Again, opening <code class="literal">http://localhost:8080/</code> in your browser should show you the installation <a id="id83" class="indexterm"/>screen:</p><div><img src="img/B06455_02_19.jpg" alt="Compose files"/></div><p>The process above works on Docker for Mac and on Linux; however for Docker for Windows you should add<code class="literal">.exe</code> to your Docker Compose commands:</p><div><pre class="programlisting">
<strong>cd .\chapter02\wordpress-compose</strong>
<strong>docker-compose.exe pull</strong>
<strong>docker-compose.exe up -d</strong>
<strong>docker container ps</strong>
</pre></div><p>This will give you something like the following output:</p><div><img src="img/B06455_02_20.jpg" alt="Compose files"/></div><p>Again, opening your <a id="id84" class="indexterm"/>browser and going to <code class="literal">http://localhost:8080/</code> should show you the installation screen:</p><div><img src="img/B06455_02_21.jpg" alt="Compose files"/></div><p>Before we move into the next section, let's stop and remove our WordPress containers by running the following commands:</p><div><pre class="programlisting">
<strong>docker-compose stop</strong>
<strong>docker-compose rm</strong>
</pre></div><p>Or if you are following using Docker for Windows:</p><div><pre class="programlisting">
<strong>docker-compose.exestop</strong>
<strong>docker-compose.exe rm</strong>
</pre></div><p>So far, we have been using images from the Docker Hub, next we will are going to take a look at customizing images.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec16"/>Docker Build</h1></div></div></div><p>Docker images are the <a id="id85" class="indexterm"/>fundamental building blocks of containers. These images could be very basic operating environments such, as <code class="literal">alpine</code> or <code class="literal">Ubuntu</code>. Or, the images could craft advanced application stacks for the enterprise and cloud IT environments. An automated approach of crafting Docker images is using a <code class="literal">Dockerfile</code>.</p><p>A <code class="literal">Dockerfile</code> is a text-based build script that contains special instructions in a sequence for building the right and the relevant images from the base images. The sequential instructions inside the <code class="literal">Dockerfile</code> can include the base image selection, installing the required application, adding the configuration and the data files, and automatically running the services as well as exposing those services to the external world. Thus, a Dockerfile-based automated build system has remarkably simplified the image-building process. It also offers a great deal of flexibility in the way in which the build instructions are organized and in the way in which they visualize the complete build process.</p><p>The Docker engine tightly integrates this build process with the help of the <code class="literal">docker build</code> subcommand. In the client-server paradigm of Docker, the Docker server (or daemon) is responsible for the complete build process and the Docker command line interface is responsible for transferring the build context, including transferring <code class="literal">Dockerfile</code> to the daemon.</p><p>To have a sneak peek into the <code class="literal">Dockerfile</code> integrated build system in this section, we introduce you to a basic <code class="literal">Dockerfile</code>. Then, we explain the steps for converting that <code class="literal">Dockerfile</code> into an image, and then launching a container from that image.</p><p>Our <code class="literal">Dockerfile</code> is made up of two instructions, as shown here (there is also a copy in the GitHub repo in the <code class="literal">chapter02/build_basic</code> folder):</p><div><pre class="programlisting">FROM alpine:latest
CMD echo Hello World!!</pre></div><p>In the following, we cover/discuss the two instructions mentioned earlier:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The first instruction is for choosing the base image selection. In this example, we select the <code class="literal">apline:latest</code> image.</li><li class="listitem" style="list-style-type: disc">The second instruction is for carrying out the command <code class="literal">CMD</code>, that instructs the container to <code class="literal">echo Hello World!!</code>.</li></ul></div><p>Now, let's proceed towards generating a Docker image by using the preceding <code class="literal">Dockerfile</code> by calling <code class="literal">dockerimagebuild</code> along with the path of the <code class="literal">Dockerfile</code>. In our example, we will invoke the <code class="literal">dockerimagebuild</code> subcommand from the directory where we have stored the <code class="literal">Dockerfile,</code> and the path will be specified by the following command:</p><div><pre class="programlisting">
<strong>dockerimagebuild</strong>
</pre></div><p>After issuing <a id="id86" class="indexterm"/>the preceding command, the <code class="literal">build</code> process will begin by sending build context to the daemon and then display the text shown here:</p><p><strong>Sending build context to Docker daemon 2.048 kB</strong></p><p><strong>Step 1/2 : FROM alpine:latest</strong></p><p>The build process will continue and after completing itself, it will display the following:</p><p><strong>Successfully built 0080692cf8db</strong></p><p>In the preceding example, the image was built with <code class="literal">IMAGE ID0a2abe57c325</code>. Let's use this image to launch a container by using the <code class="literal">docker container run</code> subcommand as follows:</p><div><pre class="programlisting">
<strong>docker container run 0080692cf8db</strong>
</pre></div><p>Cool, isn't it? With very little effort, we have been able to craft an image with <code class="literal">alpine</code> as the base image, and we have been able to extend that image to produce <code class="literal">Hello World!!</code>.</p><p>This is a simple application, but the enterprise-scale images can also be realized by using the same methodology.</p><p>Now, let's look at the image details by using the <code class="literal">dockerimage ls</code> subcommand. Here, you may be surprised to see that the <code class="literal">IMAGE</code> (<code class="literal">REPOSITORY</code>) and <code class="literal">TAG</code> name have been listed as <code class="literal">&lt;none&gt;</code>. This is because we did not specify any image or any <code class="literal">TAG</code> name when we built this image. You could specify an <code class="literal">IMAGE</code> name and optionally a <code class="literal">TAG</code> name by using the <code class="literal">docker image tag</code> subcommand, as shown here:</p><div><pre class="programlisting">
<strong>docker image tag 0080692cf8dbbasicbuild</strong>
</pre></div><p>The alternative approach is to build the image with an image name during the <code class="literal">build</code> time by using the <code class="literal">-t</code> option for the <code class="literal">docker image build</code> subcommand, as shown here:</p><div><pre class="programlisting">
<strong>docker image build -t basicbuild</strong>
</pre></div><p>Since there is no change in the instructions in <code class="literal">Dockerfile</code>, the Docker engine will efficiently reuse the old image that has <code class="literal">ID0a2abe57c325</code> and update the image name to <code class="literal">basicbuild</code>. By default, the build system would apply <code class="literal">latest</code> as the <code class="literal">TAG</code> name. This behavior can be modified by specifying the <code class="literal">TAG</code> name after the <code class="literal">IMAGE</code> name by having a <code class="literal">:</code> separator placed in between them. That is, <code class="literal">&lt;image name&gt;:&lt;tag name&gt;</code> is the correct syntax for modifying behaviors, wherein <code class="literal">&lt;image name&gt;</code> is the name of the image and <code class="literal">&lt;tag name&gt;</code> is the name of the tag.</p><p>Once again, let's look at the image details by using the <code class="literal">docker image ls</code> subcommand, and you will notice that the image (Repository) name is <code class="literal">basicimage</code> and the tag name is <code class="literal">latest</code>. Building images with an image name is always recommended as the best practice.</p><p>Having experienced <a id="id87" class="indexterm"/>the magic of <code class="literal">Dockerfile</code>, in the subsequent sections, we will introduce you to the syntax or the format of <code class="literal">Dockerfile</code> and explain a dozen <code class="literal">Dockerfile</code> instructions.</p><div><div><h3 class="title"><a id="note11"/>Note</h3><p>By default <code class="literal">docker image build</code> subcommand uses the <code class="literal">Dockerfile</code> located at the build context. However <code class="literal">–f</code> option <code class="literal">docker image build</code> subcommand let's to specify an alternate <code class="literal">Dockerfile</code> in a different path or name.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec17"/>A quick overview of the Dockerfile's syntax</h1></div></div></div><p>In this section, we explain <a id="id88" class="indexterm"/>the syntax or the format of <code class="literal">Dockerfile</code>. A <code class="literal">Dockerfile</code> is made up of instructions, comments, parser directives and empty lines, as shown here:</p><div><pre class="programlisting"># Comment

INSTRUCTION arguments</pre></div><p>The instruction line of <code class="literal">Dockerfile</code> is made up of two components, where the instruction line begins with the instruction itself, which is followed by the arguments for the instruction. The instruction could be written in any case, in other words, it is case-insensitive. However, the standard practice or the convention is to use <em>uppercase</em> to differentiate it from the arguments. Let's take a relook at the content of <code class="literal">Dockerfile</code> in our previous example:</p><div><pre class="programlisting">FROM apline:latest
CMD echo Hello World!!</pre></div><p>Here, <code class="literal">FROM</code> is an instruction which has taken <code class="literal">apline:latest</code> as an argument, and <code class="literal">CMD</code> is an instruction which has taken <code class="literal">echo Hello World!!</code> as an argument.</p><div><div><div><div><h2 class="title"><a id="ch02lvl2sec14"/>The comment line</h2></div></div></div><p>The comment line<a id="id89" class="indexterm"/> in <code class="literal">Dockerfile</code> must begin with the <code class="literal">#</code> symbol. The <code class="literal">#</code> symbol after an instruction is considered as an argument. If the <code class="literal">#</code> symbol is preceded by a whitespace, then the <code class="literal">docker image build</code> system would consider that as an unknown instruction and skip the line. Now, let's understand the preceding cases with the help of an example to get a better understanding of the comment line:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A valid <code class="literal">Dockerfile</code> comment line always begins with a <code class="literal">#</code> symbol as the first character of the line:<div><pre class="programlisting"># This is my first Dockerfile comment</pre></div></li><li class="listitem" style="list-style-type: disc">The <code class="literal">#</code> symbol can be a part of an argument:<div><pre class="programlisting">CMD echo ### Welcome to Docker ###</pre></div></li><li class="listitem" style="list-style-type: disc">If the <code class="literal">#</code> symbol is preceded by a whitespace, then it is considered as an unknown instruction by the build system:<div><pre class="programlisting"># this is an invalid comment line</pre></div></li></ul></div><p>A <a id="id90" class="indexterm"/>sample <code class="literal">Dockerfile</code> can be found at <code class="literal">/chapter02/build_basic/</code> in the repo:</p><div><pre class="programlisting"># Example of a really bsaicDockerfile

FROM alpine:latest
CMD echo Hello World!!</pre></div><p>The <code class="literal">docker image build</code> system ignores any empty line in the <code class="literal">Dockerfile</code> and hence, the author of <code class="literal">Dockerfile</code> is encouraged to add comments and empty lines to substantially improve the readability of <code class="literal">Dockerfile</code>.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec15"/>The parser directives</h2></div></div></div><p>As the name<a id="id91" class="indexterm"/> implies, the parser directives instruct the <code class="literal">Dockerfile</code> parser to handle the content of the <code class="literal">Dockerfile</code> as specified in the directives. The parser directives are optional and they must be at the very top of a <code class="literal">Dockerfile</code>. Currently escape is the only supported directive.</p><p>We use escape character to escape characters in a line or to extend a single line to multiple lines. On a UNIX like platform, <code class="literal">\</code> is the escape character whereas on windows \ is a directory path separator and <code class="literal">'</code> is the escape character. By default, <code class="literal">Dockerfile</code> parser considers <code class="literal">\</code> as the escape character and you could override this on windows using the escape parser directive as shown below:</p><div><pre class="programlisting"># escape='</pre></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec18"/>The Dockerfile build instructions</h1></div></div></div><p>So far, we have looked at the<a id="id92" class="indexterm"/> integrated build system, the <code class="literal">Dockerfile</code> syntax and a sample lifecycle, wherein how a sample <code class="literal">Dockerfile</code> is leveraged for generating an image and how a container gets spun off from that image was discussed. In this section, we will introduce the <code class="literal">Dockerfile</code> instructions, their syntax, and a few befitting examples.</p><div><div><div><div><h2 class="title"><a id="ch02lvl2sec16"/>The FROM instruction</h2></div></div></div><p>The <code class="literal">FROM</code> instruction is<a id="id93" class="indexterm"/> the most important one and it is the<a id="id94" class="indexterm"/> first valid instruction of a <code class="literal">Dockerfile</code>. It sets the base image for the build process. The subsequent instructions will use this base image and build on top of it. The Docker build system lets you flexibly use the images built by anyone. You can also extend them by adding more precise and practical features to them. By default, the Docker build system looks in the Docker host for the images. </p><p>However, if the image is not found in the Docker host, then the Docker build system will pull the image from the publicly available Docker Hub Registry. The Docker build system will return an error if it cannot find the specified image in the Docker host and the Docker Hub Registry.</p><p>The <code class="literal">FROM</code> instruction has the following syntax:</p><div><pre class="programlisting">FROM &lt;image&gt;[:&lt;tag&gt;|@&lt;digest&gt;]</pre></div><p>In the preceding code statement, note the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;image&gt;</code>: This is the name of the image which will be used as the base image.</li><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;tag&gt;</code> or<code class="literal">&lt;digest&gt;</code>: Both tag and digest are optional attributes and you could qualify a particular Docker image version using either a tag or a digest. Tag <code class="literal">latest</code> is assumed by default if both tag and digest are not present.</li></ul></div><p>Here is an example of the <code class="literal">FROM</code> instruction with the image name <code class="literal">centos</code>:</p><div><pre class="programlisting">FROM centos</pre></div><p>In the above example, the Docker build system would implicitly default to tag <code class="literal">latest</code> because neither a tag nor a digest is explicitly added to the image name.</p><p>You should be strongly discouraged from using multiple <code class="literal">FROM</code> instructions in a single <code class="literal">Dockerfile</code>, as damaging conflicts could arise.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec17"/>The MAINTAINER instruction</h2></div></div></div><p>All the <code class="literal">MAINTAINER</code> instruction does is<a id="id95" class="indexterm"/> enables<a id="id96" class="indexterm"/> the authors' details to set the in an image. Docker does not place any restrictions on placing the <code class="literal">MAINTAINER</code> instruction in a <code class="literal">Dockerfile</code>. However, it is strongly recommended that you should place it after the <code class="literal">FROM</code> instruction.</p><p>The following is the syntax of the <code class="literal">MAINTAINER</code> instruction, where <code class="literal">&lt;author's detail&gt;</code> can be in any text. However, it is strongly recommended that you should use the image, author's name and the e-mail address as shown in this code syntax:</p><div><pre class="programlisting">MAINTAINER &lt;author's detail&gt;</pre></div><p>There is an<a id="id97" class="indexterm"/> example of the <code class="literal">MAINTAINER</code> instruction<a id="id98" class="indexterm"/> with the author name, and the e-mail address at <code class="literal">/chapter02/build_01_maintainer/</code> in the repo:</p><div><pre class="programlisting"># Example Dockerfile showing MAINTAINER

FROM alpine:latest
MAINTAINER Russ McKendrick&lt;russ@mckendrick.io&gt;</pre></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec18"/>The RUN instruction</h2></div></div></div><p>The <code class="literal">RUN</code> instruction<a id="id99" class="indexterm"/> is the real workhorse during the <a id="id100" class="indexterm"/>build time, and it can run any command. The general recommendation is to execute the multiple commands by using one <code class="literal">RUN</code> instruction. This reduces the layers in the resulting Docker image because the Docker system inherently creates a layer for each time an instruction is called in <code class="literal">Dockerfile</code>.</p><p>The <code class="literal">RUN</code> instruction has two types of syntax:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The first is the shell type, as shown here:<div><pre class="programlisting">RUN &lt;command&gt;</pre></div><p>Here, the <code class="literal">&lt;command&gt;</code> is the shell command that has to be executed during the build time. If this type of syntax is to be used, then the command is always executed by using <code class="literal">/bin/sh -c</code>.</p></li><li class="listitem" style="list-style-type: disc">The second syntax type is either exec or the JSON array, as shown here:<div><pre class="programlisting">RUN ["&lt;exec&gt;", "&lt;arg-1&gt;", ..., "&lt;arg-n&gt;"]</pre></div><p>Wherein, the code terms mean the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;exec&gt;</code>: This is the executable to run during the build time.</li><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;arg-1&gt;, ..., &lt;arg-n&gt;</code>: These are the variables (zero or more) number of the arguments for the executable.</li></ul></div></li></ul></div><p>Unlike the first type of syntax, this type does not invoke <code class="literal">/bin/sh -c</code>. Hence, the types of shell processing, such as the variable substitution (<code class="literal">$USER</code>) and the wild card substitution (<code class="literal">*</code>, <code class="literal">?</code>), do not happen in this type. If shell processing is critical for you, then you are encouraged to use the shell type. However, if you still prefer the exec (JSON array type) type, then use your preferred shell as the executable and supply the command as an argument.</p><p>For example, <code class="literal">RUN ["bash", "-c", "rm", "-rf", "/tmp/abc"]</code>.</p><p>Let's add a few <code class="literal">RUN</code> instructions to our <code class="literal">Dockerfile</code> to install NGINX using <code class="literal">apk</code> and then set some permissions:</p><div><pre class="programlisting"># Example Dockerfile showing RUN

FROM alpine:latest
MAINTAINER Russ McKendrick&lt;russ@mckendrick.io&gt;

RUN apk add --update supervisor nginx&amp;&amp;rm -rf /var/cache/apk/*</pre></div><p>As you can see, we <a id="id101" class="indexterm"/>are installing NGINX and<a id="id102" class="indexterm"/> Supervisor. The <code class="literal">&amp;&amp;</code> has been added so that we can string several commands together on a single line, as each line within the <code class="literal">Dockerfile</code> creates a layer within the image stringing commands together like this streamlines your image file.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec19"/>The COPY instruction</h2></div></div></div><p>The <code class="literal">COPY</code> instruction<a id="id103" class="indexterm"/> enables you to copy the files from your <a id="id104" class="indexterm"/>Docker host to the filesystem of the image you are building. The following is the syntax of the <code class="literal">COPY</code> instruction:</p><div><pre class="programlisting">COPY &lt;src&gt; ... &lt;dst&gt;</pre></div><p>The preceding code terms bear the explanations shown here:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;src&gt;</code>: This is the source directory, the file in the build context, or the directory from where the <code class="literal">docker build</code> subcommand was invoked.</li><li class="listitem" style="list-style-type: disc"><code class="literal">...</code>: This indicates that multiple source files can either be specified directly or be specified by wildcards.</li><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;dst&gt;</code>: This is the destination path for the new image into which the source file or directory will get copied. If multiple files have been specified, then the destination path must be a directory and it must end with a slash <code class="literal">/</code>.</li></ul></div><p>Using an absolute path for the destination directory or a file has been recommended. In the absence of an absolute path, the <code class="literal">COPY</code> instruction will assume that the destination path will start from root <code class="literal">/</code>. The <code class="literal">COPY</code> instruction is powerful enough for creating a new directory and for overwriting the filesystem in the newly created image.</p><p>An example of the <code class="literal">copy</code> command can be found in the repo (<a class="ulink" href="https://github.com/russmckendrick/bootcamp">https://github.com/russmckendrick/bootcamp</a>) at <code class="literal">/chapter02/build_03_copy/</code>:</p><div><pre class="programlisting"># Example Dockerfile showing COPY

FROM alpine:latest
MAINTAINER Russ McKendrick&lt;russ@mckendrick.io&gt;

RUN apk add --update supervisor nginx&amp;&amp;rm -rf /var/cache/apk/*

COPY start.sh /script/
COPY files/default.conf /etc/nginx/conf.d/
COPY files/nginx.conf /etc/nginx/nginx.conf
COPY files/supervisord.conf /etc/supervisord.conf</pre></div><p>This copies the <code class="literal">start.sh</code> file to the folder in the Docker image at<code class="literal">/script/</code>and the configuration file from the <code class="literal">files</code> folder to in place on the image.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec20"/>The ADD instruction</h2></div></div></div><p>The <code class="literal">ADD</code> instruction<a id="id105" class="indexterm"/> is like the <code class="literal">COPY</code> instruction. However, in <a id="id106" class="indexterm"/>addition to the functionality supported by the <code class="literal">COPY</code> instruction, the <code class="literal">ADD</code> instruction can handle the TAR files and the remote URLs. We can annotate the <code class="literal">ADD</code> instruction as <code class="literal">COPY</code> on steroids.</p><p>The following is the syntax of the <code class="literal">ADD</code> instruction:</p><div><pre class="programlisting">ADD &lt;src&gt; ... &lt;dst&gt;</pre></div><p>The arguments of the <code class="literal">ADD</code> instruction are very similar to those of the <code class="literal">COPY</code> instruction, as shown here:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;src&gt;</code>: This is either the source directory or the file that is in the build context or in the directory from where the <code class="literal">docker build</code> subcommand will be invoked. However, the noteworthy difference is that the source can either be a <code class="literal">tar</code> file stored in the build context or be a remote URL.</li><li class="listitem" style="list-style-type: disc"><code class="literal">...</code>: This indicates that the multiple source files can either be specified directly or be specified by using wildcards.</li><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;dst&gt;</code>: This is the destination path for the new image into which the source file or directory will be copied.</li></ul></div><p>Here is an example for demonstrating the procedure for copying multiple source files to the various destination directories in the target image filesystem. In this example, we have taken a TAR file (<code class="literal">webroot.tar</code>) in the source build context with the <code class="literal">http</code> daemon configuration file and the files for the web pages are stored in the appropriate directory structure, as shown here:</p><div><img src="img/B06455_02_25.jpg" alt="The ADD instruction"/></div><p>The next line in the <code class="literal">Dockerfile</code> content has an <code class="literal">ADD</code> instruction for copying the TAR file (<code class="literal">webroot.tar</code>) to<a id="id107" class="indexterm"/> the target image and extracting the TAR file from the root directory (<code class="literal">/</code>) of the target image, as shown here in the example you can find in the repo at <code class="literal">/chapter02/build_04_add/</code>:</p><div><pre class="programlisting"># Example Dockerfile showing ADD

FROM alpine:latest
MAINTAINER Russ McKendrick&lt;russ@mckendrick.io&gt;

RUN apk add --update supervisor nginx&amp;&amp;rm -rf /var/cache/apk/*

COPY start.sh /script/
COPY files/default.conf /etc/nginx/conf.d/
COPY files/nginx.conf /etc/nginx/nginx.conf
COPY files/supervisord.conf /etc/supervisord.conf

ADD webroot.tar /
RUN chown -R nginx:nginx /var/www/html</pre></div><p>Thus, the TAR <a id="id108" class="indexterm"/>option of the <code class="literal">ADD</code> instruction can be used for copying multiples files to the target image, also note we have added a second <code class="literal">RUN</code> instruction to set the permissions on the folder we have just created using <code class="literal">ADD</code>.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec21"/>The EXPOSE instruction</h2></div></div></div><p>The <code class="literal">EXPOSE</code> instruction<a id="id109" class="indexterm"/> opens up a container network <a id="id110" class="indexterm"/>port for communicating between the container and the rest of the network.</p><p>The syntax of the <code class="literal">EXPOSE</code> instruction is as follows:</p><div><pre class="programlisting">EXPOSE &lt;port&gt;[/&lt;proto&gt;] [&lt;port&gt;[/&lt;proto&gt;]...]</pre></div><p>Here, the code terms mean the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;port&gt;</code>: This is the network port that has to be exposed to the outside world.</li><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;proto&gt;</code>: This is an optional field provided for a specific transport protocol, such as TCP and UDP. If no transport protocol has been specified, then TCP is assumed to be the transport protocol.</li></ul></div><p>The <code class="literal">EXPOSE</code> instruction allows you to specify multiple ports in a single line.</p><p>The following is an<a id="id111" class="indexterm"/> example of the <code class="literal">EXPOSE</code> instruction <a id="id112" class="indexterm"/>inside a <code class="literal">Dockerfile</code> exposing port <code class="literal">80</code>:</p><div><pre class="programlisting"># Example Dockerfile showing EXPOSE

FROM alpine:latest
MAINTAINER Russ McKendrick&lt;russ@mckendrick.io&gt;

RUN apk add --update supervisor nginx&amp;&amp;rm -rf /var/cache/apk/*

COPY start.sh /script/
COPY files/default.conf /etc/nginx/conf.d/
COPY files/nginx.conf /etc/nginx/nginx.conf
COPY files/supervisord.conf /etc/supervisord.conf

ADD webroot.tar /

RUN chown -R nginx:nginx /var/www/html

EXPOSE 80/tcp</pre></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec22"/>The ENTRYPOINT instruction</h2></div></div></div><p>The <code class="literal">ENTRYPOINT</code> instruction will <a id="id113" class="indexterm"/>help in crafting<a id="id114" class="indexterm"/> an image for running an application (entry point) during the complete lifecycle of the container, which would have been spun out of the image. When the entry point application is terminated, the container would also be terminated along with the application and vice versa.</p><p>Thus, the <code class="literal">ENTRYPOINT</code> instruction would make the container function like an executable. Functionally, <code class="literal">ENTRYPOINT</code> is akin to the <code class="literal">CMD</code> instruction which we will look at next, but the major difference between the two is that the entry point application is launched by using the <code class="literal">ENTRYPOINT</code> instruction, which cannot be overridden by using the <code class="literal">docker run</code> subcommand arguments.</p><p>However, these <code class="literal">docker container run</code> subcommand arguments will be passed as additional arguments to the entry point application. Having said this, Docker provides a mechanism for overriding the entry point application through the <code class="literal">--entrypoint</code> option in the <code class="literal">docker container run</code> subcommand. The <code class="literal">--entrypoint</code> option can accept only word as its argument and hence, it has limited functionality.</p><p>Syntactically, the <code class="literal">ENTRYPOINT</code> instruction is very similar to the <code class="literal">RUN</code>, and the <code class="literal">CMD</code> instructions, and it has two types of syntax, as shown here:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The first type of syntax is the shell type, as shown here:<div><pre class="programlisting">ENTRYPOINT &lt;command&gt;</pre></div><p>Here, <code class="literal">&lt;command&gt;</code> is the shell command, which is executed during the launch of the container. If this type of syntax is used, then the command is always executed by using <code class="literal">/bin/sh -c</code>.</p></li><li class="listitem" style="list-style-type: disc">The second type of syntax is <code class="literal">exec</code> or the JSON array, as shown here:<div><pre class="programlisting">ENTRYPOINT ["&lt;exec&gt;", "&lt;arg-1&gt;", ..., "&lt;arg-n&gt;"]</pre></div><p>Wherein, the code terms mean the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;exec&gt;</code>: This is the executable, which has to be run during the container launch time.</li><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;arg-1&gt;, ..., &lt;arg-n&gt;</code>: These are the variable (zero or more) number of arguments for the executable.</li></ul></div></li></ul></div><p>Syntactically, you can have more than one <code class="literal">ENTRYPOINT</code> instruction in a <code class="literal">Dockerfile</code>. However, the build system will ignore all the <code class="literal">ENTRYPOINT</code> instructions except the last one. In other words, in the case of multiple <code class="literal">ENTRYPOINT</code> instructions, only the last <code class="literal">ENTRYPOINT</code> instruction be effective.</p><p>As you may <a id="id115" class="indexterm"/>recall from when we covered the <code class="literal">RUN</code> instruction<a id="id116" class="indexterm"/> we installed a service called <code class="literal">supervisord</code>, we will be using this for the entry point in our image meaning that our <code class="literal">Dockerfile</code> now looks like the following:</p><div><pre class="programlisting"># Example Dockerfile showing ENTRYPOINT

FROM alpine:latest
MAINTAINER Russ McKendrick&lt;russ@mckendrick.io&gt;

RUN apk add --update supervisor nginx&amp;&amp;rm -rf /var/cache/apk/*

COPY start.sh /script/
COPY files/default.conf /etc/nginx/conf.d/
COPY files/nginx.conf /etc/nginx/nginx.conf
COPY files/supervisord.conf /etc/supervisord.conf

ADD webroot.tar /

RUN chown -R nginx:nginx /var/www/html

EXPOSE 80/tcp

ENTRYPOINT ["supervisord"]</pre></div><p>Now we could <a id="id117" class="indexterm"/>leave it here and the image <a id="id118" class="indexterm"/>would be functional, however there is one instruction we should pass to our image.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec23"/>The CMD instruction</h2></div></div></div><p>The <code class="literal">CMD</code> instruction can<a id="id119" class="indexterm"/> run any command (or application), which <a id="id120" class="indexterm"/>is similar to the <code class="literal">RUN</code> instruction. However, the major difference between those two is the time of execution. The command supplied through the <code class="literal">RUN</code> instruction is executed during the build time, whereas the command specified through the <code class="literal">CMD</code> instruction is executed when the container is launched from the newly created image. Thus, the <code class="literal">CMD</code> instruction provides a default execution for this container. However, it can be overridden by the <code class="literal">docker run</code> subcommand arguments. When the application terminates, the container will also terminate along with the application and vice versa.</p><p>On the face of it the <code class="literal">CMD</code> instruction is very similar to the <code class="literal">RUN</code> instruction in that it can run any command passed to it, however there is a major difference between the two instructions.</p><p>The command passed to the <code class="literal">RUN</code> instruction is executed at build time and commands passed using the <code class="literal">CMD</code> instruction are executed at run time meaning you can define the default execution for the container. This means if no command is passed during the <code class="literal">docker container run</code> command then the CMD will executed.</p><p>The <code class="literal">CMD</code> instruction has three types of syntax, as shown here:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The first syntax type is the shell type, as shown here:<div><pre class="programlisting">
<strong>CMD &lt;command&gt;</strong>
</pre></div><p>Wherein, the <code class="literal">&lt;command&gt;</code> is the shell command, which has to be executed during the launch of the container. If this type of syntax is used, then the command is always executed by using <code class="literal">/bin/sh -c</code>.</p></li><li class="listitem" style="list-style-type: disc">The second type of syntax is exec or the JSON array, as shown here:<div><pre class="programlisting">
<strong>CMD ["&lt;exec&gt;", "&lt;arg-1&gt;", ..., "&lt;arg-n&gt;"]</strong>
</pre></div><p>Wherein, the code terms mean the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;exec&gt;</code>: This is the executable, which is to be run during the container launch time</li><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;arg-1&gt;, ..., &lt;arg-n&gt;</code>: These are the variable (zero or more) number of the arguments for the executable</li></ul></div></li><li class="listitem" style="list-style-type: disc">The third type of syntax is also exec or the JSON array, which is similar to the previous type. However, this type is used for setting the default parameters to the <code class="literal">ENTRYPOINT</code> instruction, as shown here:<div><pre class="programlisting">
<strong>CMD ["&lt;arg-1&gt;", ..., "&lt;arg-n&gt;"]</strong>
</pre></div><p>Wherein, the code terms mean the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">&lt;arg-1&gt;, ..., &lt;arg-n&gt;</code>: These are the variables (zero or more) number of the arguments for the <code class="literal">ENTRYPOINT</code> instruction, which will be explained in the next section.</li></ul></div></li></ul></div><p>Syntactically, you <a id="id121" class="indexterm"/>can add more than one <code class="literal">CMD</code> instruction<a id="id122" class="indexterm"/> in <code class="literal">Dockerfile</code>. However the build system would ignore all the <code class="literal">CMD</code> instructions except for the last one. In other words, in the case of multiple <code class="literal">CMD</code> instructions, only the last <code class="literal">CMD</code> instruction would be effective.</p><p>As mentioned in the previous section, our <code class="literal">Dockerfile</code> could have been run with just the <code class="literal">ENTRYPOINT</code> instruction defined, however that would give a non-breaking error when <code class="literal">supervisiord</code> starts up so let's pass a flag which defines where our supervisor configuration file is using the <code class="literal">CMD</code> instruction:</p><div><pre class="programlisting"># Example Dockerfile showing CMD

FROM alpine:latest
MAINTAINER Russ McKendrick&lt;russ@mckendrick.io&gt;

RUN apk add --update supervisor nginx&amp;&amp;rm -rf /var/cache/apk/*

COPY start.sh /script/
COPY files/default.conf /etc/nginx/conf.d/
COPY files/nginx.conf /etc/nginx/nginx.conf
COPY files/supervisord.conf /etc/supervisord.conf

ADD webroot.tar /

RUN chown -R nginx:nginx /var/www/html

EXPOSE 80/tcp

ENTRYPOINT ["supervisord"]
CMD ["-c","/etc/supervisord.conf"]</pre></div><p>We are now in a <a id="id123" class="indexterm"/>position where we can build our image, you <a id="id124" class="indexterm"/>can find our completed <code class="literal">Dockerfile</code> in the <code class="literal">/chapter02/</code>
<code class="literal">build_07_cmd/</code> folder in the repo, to build the image simple run the following command:</p><div><pre class="programlisting">
<strong>docker image build -t cluster</strong>
</pre></div><p>This will kick of the build, as you can see from the following terminal:</p><div><img src="img/B06455_02_26.jpg" alt="The CMD instruction"/></div><p>There are 12 steps in the build, it will take a minute or two, but once compete you should see something like the following terminal output:</p><div><img src="img/B06455_02_27.jpg" alt="The CMD instruction"/></div><p>Once you have your image built, you can check and then run it by using the following commands:</p><div><pre class="programlisting">
<strong>docker image ls</strong>
<strong>docker container run -d -p 8080:80 cluster</strong>
</pre></div><div><img src="img/B06455_02_28.jpg" alt="The CMD instruction"/></div><p>Now the container is <a id="id125" class="indexterm"/>running, opening your browser and <a id="id126" class="indexterm"/>going <code class="literal">http://localho</code>
<code class="literal">st:8080/</code> should show you something like the following page:</p><div><img src="img/B06455_02_29.jpg" alt="The CMD instruction"/></div><p>There you have it, we have created an image:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Using the Alpine Linux base (<code class="literal">FROM</code>)</li><li class="listitem" style="list-style-type: disc">Installed <code class="literal">NGINX</code> and <code class="literal">supervisord</code> using <code class="literal">apk</code> (<code class="literal">RUN</code>)</li><li class="listitem" style="list-style-type: disc">Copied the configuration from our Docker host to the image (<code class="literal">COPY</code>)</li><li class="listitem" style="list-style-type: disc">Uploaded and extracting our web root (<code class="literal">ADD</code>)</li><li class="listitem" style="list-style-type: disc">Set the correct ownership of our web root (<code class="literal">RUN</code>)</li><li class="listitem" style="list-style-type: disc">Ensured that port <code class="literal">80</code> on the container is open (<code class="literal">EXPOSE</code>)</li><li class="listitem" style="list-style-type: disc">Made sure that <code class="literal">supervisord</code> is the default process (<code class="literal">ENTRYPOINT</code>)</li><li class="listitem" style="list-style-type: disc">Passed the configuration file flag to <code class="literal">supervisord</code> (<code class="literal">CMD</code>)</li></ul></div><p>Before moving onto the next section you can stop and remove the container by running the following command making sure you replace the container ID with that of yours:</p><div><pre class="programlisting">
<strong>docker container ps</strong>
<strong>docker container stop de9a26a1d149</strong>
<strong>docker container rm de9a26a1d149</strong>
</pre></div><p>Then remove the<a id="id127" class="indexterm"/> image we created by running:</p><div><pre class="programlisting">
<strong>docker image rm cluster</strong>
</pre></div><p>Next, we are going to go<a id="id128" class="indexterm"/> back to our WordPress image and customize it.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec19"/>Customizing existing images</h1></div></div></div><p>While the official images <a id="id129" class="indexterm"/>should provide you with a fully functioning usable image you may sometimes need to install additional software, in this case we are going to look at installing<a id="id130" class="indexterm"/> WordPress CLI using the official WordPress image.</p><div><div><h3 class="title"><a id="note12"/>Note</h3><p>WordPress CLI<a id="id131" class="indexterm"/> is a set of command line tools which allow you to manage your WordPress configuration and installation; for more information, see <a class="ulink" href="http://wp-cli.org/">http://wp-cli.org/</a>.</p></div></div><p>You can find a copy of the <code class="literal">Dockerfile</code> below in the <code class="literal">/chapter02/wordpress-custom/</code> folder in the repo, as you can see we are just running <code class="literal">RUN</code> and <code class="literal">COPY</code>instructions:</p><div><pre class="programlisting"># Adds wp-cli to the offical WordPress image
FROM wordpress:latest
MAINTAINER Russ McKendrick&lt;russ@mckendrick.io&gt;

# Install the packages we need to run wp-cli
RUN apt-get update &amp;&amp;\
apt-get install -y sudo less mysql-client &amp;&amp;\
curl -o /bin/wp-cli.pharhttps://raw.githubusercontent.com/wp-cli/builds/gh-pages/phar/wp-cli.phar

# Copy the wrapper for wp-cli and set the correct execute permissions
COPY wp /bin/wp
RUN chmod 755 /bin/wp-cli.phar /bin/wp

# Clean up the installation files
RUN apt-get clean &amp;&amp;rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/</pre></div><p>You can build the image using the following command:</p><div><pre class="programlisting">
<strong>docker image build -t wordpress-custom .</strong>
</pre></div><p>Once it has finished<a id="id132" class="indexterm"/> building use the following command to check the image:</p><div><pre class="programlisting">
<strong>docker image ls</strong>
</pre></div><p>However, as we discovered earlier in this chapter it is easier to launch WordPress using Docker Compose, before we do lets remove the image we just built by running:</p><div><pre class="programlisting">
<strong>docker image rm wordpress-custom</strong>
</pre></div><p>Docker Compose can also trigger builds. Our updated <code class="literal">docker-compose.yml</code> file can be found in the <code class="literal">/chapter02/wordpress-custom/</code> folder and below:</p><div><pre class="programlisting">version: "3"

services:
mysql:
     image: mysql
     volumes:
       - db_data:/var/lib/mysql
     restart: always
     environment:
       MYSQL_ROOT_PASSWORD: wordpress
       MYSQL_DATABASE: wordpress
wordpress:
depends_on:
       - mysql
     build: ./
     ports:
       - "8080:80"
     restart: always
     environment:
       WORDPRESS_DB_PASSWORD: wordpress

volumes:
db_data:</pre></div><p>As you can see, it is almost exactly the same as our original <code class="literal">docker-compose.yml </code>apart from now we have a line that says <code class="literal">build: ./</code>" rather than <code class="literal">image: wordpress</code>".</p><p>To launch our WordPress installation, we simply need to run the following command:</p><div><pre class="programlisting">
<strong>docker-compose up -d</strong>
</pre></div><p>This will pull and build<a id="id133" class="indexterm"/> the container images, once complete you should see something like the following in your terminal:</p><div><img src="img/B06455_02_32.jpg" alt="Customizing existing images"/></div><p>Going to <code class="literal">http://localhost:8080/</code> should show you the installation screen, however, we are going to typing a few commands to configure WordPress using the WordPress CLI.</p><p>First, let's check the version of WordPress we are working with by running:</p><div><pre class="programlisting">
<strong>docker-compose exec wordpress wp core version</strong>
</pre></div><p>This will connect to the WordPress service and run the <code class="literal">wp core version</code> command, then return the output:</p><div><img src="img/B06455_02_33.jpg" alt="Customizing existing images"/></div><p>Next, we are going to install WordPress using the <code class="literal">wp core install</code> command, change the <code class="literal">title</code>, <code class="literal">admin_user</code>, <code class="literal">admin_password</code> and <code class="literal">admin_email</code> values as you like:</p><div><pre class="programlisting">
<strong>docker-compose exec wordpress wp core install --url=http://localhost:8080/ --title=Testing --admin_user=admin --admin_password=adminpasswIt ord --admin_email=russ@mckendrick.io</strong>
</pre></div><p>Once the command has finished running you should receive a message saying <strong>Success: WordPress installed successfully</strong>:</p><div><img src="img/B06455_02_34.jpg" alt="Customizing existing images"/></div><p>Going <a id="id134" class="indexterm"/>to <code class="literal">http://localhost:8080/</code> should show you a WordPress site rather than an installation prompt:</p><div><img src="img/B06455_02_35.jpg" alt="Customizing existing images"/></div><p>Once you have finished with your WordPress installation you can stop and remove it by running:</p><div><pre class="programlisting">
<strong>docker-compose stop</strong>
<strong>docker-compose rm</strong>
</pre></div><p>Now we know how to build an image we are going to look at a few different ways to share them.</p></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec20"/>Sharing your images</h1></div></div></div><p>The Docker <a id="id135" class="indexterm"/>Hub is a central place used for keeping the Docker images either in a public or private repository.</p><p>The Docker Hub provides features, such as a repository for Docker images, user authentications, automated image builds, integration with GitHub or Bitbucket, and managing organizations and groups. The Docker Registry component of the Docker Hub manages the repository.</p><p>To work with the Docker Hub, you <a id="id136" class="indexterm"/>must register an account using the link at <a class="ulink" href="https://hub.docker.com/">https://hub.docker.com/</a>.You can update the <strong>Docker Hub ID</strong>, <strong>Email Address</strong> and <strong>Password</strong> as shown in the following screenshot:</p><div><img src="img/B06455_02_37.jpg" alt="Sharing your images"/></div><p>After completing the <strong>Sign Up</strong> process, you need to complete the verification received in an e-mail. After the e-mail verification is completed, you will see something similar to the following screenshot, when you login to the Docker Hub:</p><div><img src="img/B06455_02_38.jpg" alt="Sharing your images"/></div><p>As you can see, I already<a id="id137" class="indexterm"/> have a few automated builds configured, we will get to these later on, for now we are going to look at pushing an image from our local Docker host.</p><p>First, we need to login to the Docker Hub using the Docker client on the command line, to do this simply use the following command:</p><div><pre class="programlisting">
<strong>docker login</strong>
</pre></div><p>You should be prompted for your Docker Hub username and password:</p><div><img src="img/B06455_02_39.jpg" alt="Sharing your images"/></div><p>Now we are ready to start committing and pushing images to the Docker Hub.</p><p>We'll again create an image using the <code class="literal">Dockerfile</code> we created earlier in the chapter. So, let's create the Docker image using the <code class="literal">Dockerfile</code> in <code class="literal">/chapter02/build_07_cmd</code>and push the resulting image to the Docker Hub.</p><p>Now we build the image locally using the following command making sure to use your own Docker Hub username in place of mine:</p><div><pre class="programlisting">
<strong>docker image build -t russmckendrick/exampleimage .</strong>
</pre></div><p>Once built, you can <a id="id138" class="indexterm"/>check the image is there by using:</p><div><pre class="programlisting">
<strong>docker image ls</strong>
</pre></div><div><img src="img/B06455_02_40.jpg" alt="Sharing your images"/></div><p>As we are already logged in all we need to do to push the newly create image is run the following command:</p><div><pre class="programlisting">
<strong>docker image push russmckendrick/exampleimage</strong>
</pre></div><div><img src="img/B06455_02_41.jpg" alt="Sharing your images"/></div><p>Finally, we can verify the availability of the image on the Docker Hub:</p><div><img src="img/B06455_02_42.jpg" alt="Sharing your images"/></div><p>This is where I should probably issue a warning: as you have just experienced it is very easy to publish images to the Docker Hub using the <code class="literal">docker image push</code> command; however, it is very easy to accidentally push content you maybe wouldn't want to be publicly available. For example, with a simple <code class="literal">COPY</code> or <code class="literal">ADD</code> instruction in your <code class="literal">Dockerfile</code> it is easy<a id="id139" class="indexterm"/> to bake sensitive information such as password credentials, certificates keys and non-publicly available code to a publicly accessible Docker Image repository.</p><p>It is this reason why I prefer to share a <code class="literal">Dockerfile</code> or <code class="literal">docker-compose.yml</code> files with my colleagues using private Git repositories and a good set of instructions . A also, it allows then to check what it is they are going to be running as they are able to review the<code class="literal">Dockerfile</code> and <code class="literal">docker-compose.yml</code> files; in fact, they can make changes and share them with me.</p></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec21"/>Summary</h1></div></div></div><p>We have covered a lot in this chapter. We have used the Docker command line client to launch and interact with containers. We also used Docker Compose to define multiple container based application, namely WordPress and created and published our own Docker images on the Docker Hub. Finally, we customized the official WordPress Docker image adding additional functionality.</p><p>I am sure you will agree that so far using Docker has felt quite intuitive; in our next chapter we will move off our local Docker host and interact with Docker installations on remote hosts.</p></div></body></html>