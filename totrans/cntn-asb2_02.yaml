- en: Working with Ansible Container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw in [Chapter 1](61a61ca8-60d4-48a0-8987-6f719d6a2c36.xhtml), *Building
    Containers with Docker*, containerization is changing the way critical IT infrastructure
    is maintained and deployed. As DevOps methodologies and mindsets evolve across
    organizations, the lines between development and operations roles are becoming
    blurred. While tools such as Docker continue to grow and evolve, tools need to
    be developed to leverage the ever-increasing need to scale and deploy containerized
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible is a unique framework for automation, as we saw in [Chapter 1](61a61ca8-60d4-48a0-8987-6f719d6a2c36.xhtml)*,
    Building Containers with Docker, *as it relies on an agent-less architecture,
    bringing servers and virtualized applications into the desired state from a centralized
    location over the SSH protocol. Compared to the other core automation tools discussed,
    Ansible brings a different approach from other configuration management tools,
    such as Chef and Puppet, which rely on agents and centralized servers to store
    and maintain configuration states.
  prefs: []
  type: TYPE_NORMAL
- en: The Ansible Container project was launched to address the need to bring critical
    configuration management techniques to the currently manual process of building
    and deploying Docker container images with the standard Docker toolchain. Currently,
    Docker and Docker tools are built with an emphasis on deploying containers to
    Docker native environments using Swarm and Docker Compose. Ansible Container is
    a wrapper around many of the standard Docker tools, and provides the functionality
    to deploy your projects to various cloud providers, Kubernetes, and OpenShift.
    At the time of writing other container orchestration tools such as Docker Swarm
    and Apache Mesos are not currently supported. If Dockerfiles are akin to shell
    scripts during the era of monolithic application deployments, then Ansible Container
    is a solution for bringing automation and repeatability to the container ecosystem.
    As Ansible Core uses playbooks and SSH as an interface for bringing about desired
    states, Ansible Container can use your same playbooks and native container APIs
    to build and deploy containers.
  prefs: []
  type: TYPE_NORMAL
- en: If you or your organization is already using Ansible roles for customized deployments
    of applications and services, these same roles can be leveraged to turn these
    applications and services into containers, helping to streamline your container
    build pipeline. When making the leap from bare-metal and virtualized deployments,
    you can be confident that your customized configurations and settings will be
    preserved when building your containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter we will learn:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to Ansible Container and the microservice architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A quick introduction to Docker Compose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ansible Container workflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ansible Container quick start
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to Ansible Container and the microservice architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While using Ansible Container has a great number of benefits in reusing existing
    Ansible artifacts, modules, and playbooks, careful consideration has to be given
    to any changes required in porting over your existing services. Ansible gives
    you a large amount of freedom in the way you write playbooks and roles to suite
    the uniqueness of your organization''s architecture and resource constraints.
    A typical web application, for example, may have three distinct layers of functionality:
    a web server, which provides your end users with a website; a database for storing
    data; and a cache, providing the web server with commonly accessed data from the
    database. Depending on the architecture and any resource constraints, these services
    might be implemented in any number of ways. You may have your web server, caching
    layer, and database on three separate and distinct clusters of servers. You could
    opt to deploy the web server and caching layer on the same cluster, and the database
    on a secondary cluster. Or all three layers might be deployed on the same bare-metal
    or virtualized server cluster, with a load balancer providing redundancy as necessary.
    Your infrastructure is a unique snowflake that Ansible gives you the freedom to
    write and deploy playbook roles in almost any configuration that fits your needs.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Microservice architecture* is a term used to describe the independent and
    modular breakout of application services to distinct and deployable units. In
    the world of containers, you want each of your containers to conform to the microservice
    architecture, creating each service as a separate container that can be deployed
    and scaled independently of the other services. While it is possible to deploy
    multiple services in the same container, it is generally a bad idea, as each service
    adds layers to your containers, creating unnecessary overhead when building and
    deploying new containers.'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, each of the core services (web server, cache, and
    database) will be a separate microservice you want to isolate and encapsulate
    into containers. Having the flexibility to dynamically deploy more cache or database
    containers on demand creates a huge advantage if your web application goes into
    production and you realize that the projected traffic is much higher than originally
    anticipated and database queries are becoming a bottleneck. Having a microservice-oriented
    design to your containers will allow your infrastructure to be simplified, more
    easily deployed, and more quickly scaled to meet the needs of demanding users.
  prefs: []
  type: TYPE_NORMAL
- en: The key takes-away when thinking about porting existing Ansible roles into Ansible
    Container projects is to think through how tightly integrated your roles currently
    are. Ideally, Ansible roles should be able to be standalone, with little to no
    reliance on other environmental characteristics. Isn't this starting to sound
    a lot like the containerized microservices we described before? This is what makes
    Ansible Container a unique platform among other configuration management tools.
    Ansible primitives are already designed to fit nicely into a containerized ecosystem.
    Even if you are not currently using Ansible as your configuration management tool,
    Ansible Container is still a fantastic tool for building, maintaining, and deploying
    containers, from development all the way through to production.
  prefs: []
  type: TYPE_NORMAL
- en: A quick introduction to Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker Compose is one of the Docker workflow tools that allow you to easily
    build and run multiple containers at once. It is important to have a basic understanding
    of how Docker Compose works before we start working with Ansible Container since
    a lot of Ansible Container's core functionality is wrapped around Docker Compose.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, I illustrated an example in which three Apache web
    server containers were created to demonstrate running multiple containers simultaneously
    leveraging the same container base image. With Docker Compose, instead of providing
    three separate docker `run` commands, one can simply provide a `YAML` definition
    file that describes the containers you want to run, any docker `run` parameters
    you want the containers to run with (ports, volumes, and so on), and any links
    or dependencies you want to create for the containers prior to running them. When
    Docker Compose is executed, it will automatically try to bring up the containers
    described in the `YAML` file. If the images are not yet cached locally, it will
    try to download them from the internet or will build the container images if the
    Dockerfiles are provided. Let's do a quick exercise to get a feel for how Docker
    Compose works.
  prefs: []
  type: TYPE_NORMAL
- en: If you are not using the provided Vagrant lab environment, as discussed in [Chapter
    1](61a61ca8-60d4-48a0-8987-6f719d6a2c36.xhtml)*,* *Building Containers with Docker,*
    you will first need to download Docker Compose using the following command. The
    steps provided assume you have Docker Engine already installed and running on
    a Linux or macOS machine. Make sure you install Docker Compose with the same version
    number as the Docker Engine you already have running to ensure maximum compatibility.
    Execute the following commands to download the Docker Compose executable and copy
    it to `/usr/local/bin` with `execute` privileges.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The most up-to-date installation documentation can be found at [https://docs.docker.com/compose/install](https://docs.docker.com/compose/install).
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, Docker Compose looks for a file in your current working directory
    called `docker-compose.yml`. I have provided a sample `docker-compose.yml` file
    as an example. On your workstation, create a directory called `docker-compose`
    and create a blank `docker-compose.yml` file in that directory. Paste in the following
    content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s look at this file line by line:'
  prefs: []
  type: TYPE_NORMAL
- en: '`version`: This line indicates which version of the Docker Compose API to use.
    In this case, we are using version 2\. At the time of writing, there is also version
    3 of the API, which provides some new features. For our purposes, however, we
    are content to use version 2\. The version parameter usually starts a Docker Compose
    file and has no indentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`services`: The `services` line starts the section of your `docker-compose.yml`
    file that lists each service container you are going to create. In this particular
    Docker Compose file, we are going to create a service called `Cache_Server`, which
    spins up a single `memcached` container. Each service you specify should be indented
    two spaces under the `services` declarative. It should also be noted that the
    service names are user-defined and are used to generate the container name. When
    creating multi-container Docker Compose files, Docker provides simple DNS resolution
    between containers, based on the service names. More on this in [Chapter 8](f734178a-8a55-4fc5-9961-13e8182fdda7.xhtml),* Building
    and Deploying Multi-Container Projects.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image`: `image` is used to specify the container image you want your container
    to be based on. For this example, we are using the official `memcached` image
    from Docker Hub, specifying version 1.4.36\. We could also have used the latest
    keyword in place of the version number if we had wanted to always have the latest
    version of the image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ports`: The `ports` parameter indicate which ports on the host you want to
    be forwarded to the container. In this case, we will forward port `11211` to the
    exposed container port `11211`. Similar to `docker run`, ports must be specified
    in the format `host:container`. This is a `YAML` list, so each port must be indented
    and prefixed with a hyphen (`-`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`volumes`: This parameter specifies any directories or storage volumes on the
    Docker host you would like to make accessible to the container. This is useful
    if there is data in the container you may want to back up, export, or otherwise
    share with the container. This volume mounting merely serves as an example of
    the syntax. Similar to the `ports` parameter, `volumes` takes a list in the form
    of `hostDirectory:containerDirectory`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To start our container using Docker Compose, you simply execute the command `docker-compose
    up`. This will, by default, start all of the containers in the Docker Compose
    file one by one, unless container dependencies are specified. Containers started
    using `docker-compose` will be started in `attached` mode, meaning that the container
    process will run, taking over the Terminal you are using. Similar to `docker run`,
    we can supply the `-d` flag to run the containers in `detached` mode, so we can
    run some validations in the same Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You will observe that, similarly to `docker run`, Docker Compose automatically
    determines that the container image is not present on the Docker host and successfully
    downloads the image and corresponding layers from the internet.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Running `docker ps -a` will reveal that Docker Compose was able to successfully
    create the running container with the properly exposed ports and volume mounts
    listed in our `docker-compose.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use `telnet` to ensure the `memcached` application is functioning and
    forwarded through the host networking. Using `telnet`, we can store and retrieve
    data from `Memcached` directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Running the `stats slabs` command lets us know that `memcached` has been deployed
    and is functioning as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have had a brief introduction to Docker and Docker Compose, we have
    acquired the basic skills needed to start working with Ansible Container.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible Container workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to other orchestration and automation tools, Ansible Container contains
    a set of utilities that constitute a containerized workflow. Using Ansible Container,
    you can create, build, run, and deploy containers, from development all the way
    through to production, using the suite of tools included with Ansible Container
    out of the box. Ansible Core''s *batteries-included* methodology carries over
    to Ansible Container to provide developers and system administrators with a complete
    containerized workflow solution. The following is an overview of the primary Ansible
    Container functions and how they correspond to the typical lifecycle of a containerized
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ansible-container init`: Used to initially start an Ansible Container project.
    `init` builds and creates the directory scaffolding and base files that are required
    to start an Ansible Container project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ansible-container build`: Similar to what the name suggests, `build` will
    parse the primary files in your project and attempt to build the containers described.
    Ansible Container is able to do this by first creating what is known as a `conductor`
    container. The `conductor` container is a master container that is created during
    the build phase of your project and contains a running copy of Ansible. Once the
    other containers launch, the `conductor` container is responsible for running
    the Ansible roles and playbooks against them to bring the containers into the
    desired state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ansible-container run`: `run` works in a very similar way to `docker run`
    in the respect that, when executed, `run` takes the built containers and attempts
    to run them in the container engine on the host. By default, the `run` command
    takes into consideration any development options listed in the `container.yml`
    file, unless the `-- production` flag is passed in at runtime.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ansible-container destroy`: Stops any running containers and also removes
    any built image files. This command is useful when testing an end-to-end deployment
    from scratch.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ansible-container push`: This command pushes the container images you built
    with Ansible Container to a container registry of your choice, such as Docker
    Hub, Quay, or GCR. This command is similar to `docker push`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ansible-container deploy`: `deploy` (formerly `ShipIt`) takes your current
    project and generates a customized Ansible playbook and role to deploy your container
    to a cloud service provider. At the time of writing, `deploy` supports only OpenShift
    and Kubernetes. Running this playbook using the `ansible-playbook` command, will
    deploy your containers to the specified provider.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, Ansible Container comes prebuilt with an end-to-end lifecycle
    management system that allows you to manage containers from development through
    to production. Ansible Container leverages the powerful and customizable Ansible
    configuration management system to allow containers to be created and deployed
    similarly to bare-metal or virtual nodes.
  prefs: []
  type: TYPE_NORMAL
- en: All Ansible Container subcommands can be found by running `ansible-container
    --help`.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible Container quick-start
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This portion of the chapter is going to focus on getting started with Ansible
    Container, initializing a base project, and recreating the `memcached` example
    from earlier. If you are not following along with the Vagrant lab provided on
    GitHub, the first step is to install Ansible Container using the `python-pip`
    package manager. The following steps will install Ansible Container with support
    for Docker on a Debian-based distribution of Linux:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Ansible Container init
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You should now have Ansible Container installed and ready to run in your environment.
    The first command that''s required to start a new Ansible Container project is
    the `ansible-container init` command. After logging in to your vagrant VM, create
    an empty directory in the `/vagrant` directory and type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: It is important to note that the final lab exercise can be found in the official
    book GitHub repository, in the directory: `AnsibleContainer/demo`.
  prefs: []
  type: TYPE_NORMAL
- en: When Ansible Container has successfully created a new project, it will return
    the response `Ansible Container initialized`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As discussed previously, `init` creates the basic directory structure and layout
    required to start building Ansible Container projects. Navigating to that directory
    and looking at the directory listing will give you an idea of what an Ansible
    Container project looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s look at these files individually to understand their purpose in an Ansible
    Container project:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ansible.cfg`: The primary configuration file for the Ansible engine. Any settings
    you want the Ansible `conductor` container to leverage will go in this file. If
    you''re familiar with using Ansible for configuration management tasks, you will
    already have a basic familiarity with the `ansible.cfg` file. For the most part,
    you can safely leave this file alone, unless there is a specific way Ansible needs
    to run during the container build process. More information about Ansible configuration
    options can be found in the Ansible documentation at [https://docs.ansible.com.](https://docs.ansible.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ansible-requirements.txt`: The `ansible-requirements.txt` file is used to
    specify any Python pip dependencies that your playbooks may need to run successfully.
    Ansible Engine is built on a series of modules that perform the tasks described
    in the playbooks. Any additional Python packages that are required to run the
    Ansible roles are listed in this file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`container.yml`: Describes the state of your containers, including base images,
    exposed ports, and volume mounts. The syntax for `container.yml` is similar to
    the Docker Compose format, with a few differences we will look at throughout this
    book.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`meta.yml`: The `meta.yml` file includes any metadata about your container
    project, including the name of the author, version information, software licensing
    details, and tags. This information makes it easy for other users to find your
    project should you choose to share it on Ansible Galaxy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`requirements.yml`: Defines any Ansible Galaxy roles and version information
    your container project will use. In this file, you can describe the exact roles
    and role versions your project requires. Ansible Container will download these
    roles from Ansible Galaxy prior to building your container project. By specifying
    your roles in the `requirements.yml` file, you can be sure that your projects
    consistently use the same roles to build the base container images. It is important
    to keep in mind the distinction between `ansible-requirements.yml` and `requirements.yml`.
    `requirements.yml` is used to manage the Ansible roles your project depends on,
    whereas `ansible-requirements.yml` is used to manage the Python pip packages those
    roles may require.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that we have a feel for what an Ansible Container project looks like, we
    can dive in and start experimenting with creating a simple Ansible Container project.
    Remember our Docker Compose project we created earlier? Let''s use that as a starting
    point and port this project to Ansible Container by editing the `container.yml`
    file. In a text editor, open the `container.yml` file. By default `container.yml`
    comes with a prepopulated structure, which in many ways resembles a Docker Compose
    file. Your `container.yml` file should resemble the following. To conserve space,
    I have removed many of the comments and example data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Each of these sections has a particular purpose for structuring your Ansible
    Container project. It is important to understand what each of these `YAML` definitions
    is used to describe. The comments that come in the file by default show examples
    of the various settings each of these sections uses. The following is a list of
    the key sections of the `container.yml` file and how to use these sections in
    your Ansible Container project:'
  prefs: []
  type: TYPE_NORMAL
- en: '`version`: The `version` section signifies which version of the Docker Compose
    API to use. As we discussed before, Ansible Container is a wrapper around many
    of the Docker Compose services. Here, we can specify which version of the Docker
    Compose API we want our containers to use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`settings`: The `settings` section is used to specify additional integrations
    or modify any default behaviors of our Ansible Container project. By default,
    there is one setting enabled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`conductor_base`:  This indicates which base image we want our project to use.
    The `conductor` container is responsible for creating a Python environment used
    for running Ansible playbooks and roles. The `conductor` image will connect to
    the other containers that it creates, providing access to its own Python environment
    during the build process. Therefore, it is very important to use the same base
    container operating system as the container images you plan on building. This
    will ensure complete compatibility in terms of Python and Ansible. Think of the
    conductor image as a container that works in a similar way to the Ansible controller
    node in a standard Ansible implementation. This container will reach out to the
    other nodes (containers), leveraging the Docker API directly to bring our other
    containers into the desired state. Once we are done building our containers, the
    `conductor` container deletes itself by default, unless you instruct Ansible Container
    to retain the conductor image for debugging purposes. As well as specifying our
    conductor image, we can also specify other integrations in the settings section,
    such as Kubernetes credentials or OpenShift endpoints. We will dig deeper into
    these in later chapters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`services`: The `services` section is almost identical to the `services` section
    in our Docker Compose file. In this section, we will provide our `YAML` definitions,
    which describe the running state of our containers: which base image we will use,
    the container name, exposed ports, volumes, and more. Each container described
    in the services section is a *node* that will be configured by our conductor image
    running Ansible. By default the `services` section is disabled with two curly
    braces next to the `YAML` definition: `{}`. Before adding container definitions,
    delete the curly braces so that Ansible Container can access the child data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`registries`: The final section of our `container.yml` file is the `registries`
    section. It is here that you can specify container registries, from which Ansible
    container will pull images. By default, Ansible Container uses Docker Hub, but
    you may also specify other registries, such as Quay, `gcr.io`, or locally hosted
    container registries. This section is also used in conjunction with the `ansible-container`
    push command to push your built containers to the registry service of your choice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ansible Container build
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The second part of our Ansible Container workflow is the build process. Now
    that we have our first project initialized, we can explore how the `ansible-container
    build` function works even though we do not have any services or roles defined.
    From the `demo` directory, run the `ansible-container build` command. You should
    see output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Running Ansible Container build for the first time on your local workstation
    might take a few minutes to complete, as it needs to build the `conductor` container
    before it can start. Keeping in mind that the conductor container is responsible
    for connecting to the service containers using the Docker API and executing Ansible
    playbooks and roles on them. Since this is a basic example of the `ansible-container
    build` command, there are no Ansible playbooks to run on the containers we are
    creating. Later in the book we will write our own roles to really explore how
    the conductor container functions. The below illustration demonstrates the how
    the conductor container connects to the service containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9fa32db1-533e-4304-b32b-d598665972b4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Conductor container bringing the service containers into the desired
    state'
  prefs: []
  type: TYPE_NORMAL
- en: However, in this example, Ansible Container will first connects to the Docker
    API on the localhost to determine the build context, download the required image
    dependencies, and execute the build of the `conductor` container. You can see
    in the preceding output that our `conductor` container was successfully built
    for our project, `demo`. It also lists the return code, which confirms that our
    image was successfully built, as well as an internal conductor ID, which Ansible
    Container generates.
  prefs: []
  type: TYPE_NORMAL
- en: If we execute the command `docker ps -a`, we will see that no containers are
    currently running or exited. This is expected since we have not yet defined any
    containers in the `services `section of our `container.yml` file. You may also
    see that, since we did not pass in any arguments or configuration to instruct
    Ansible Container to save our `conductor` container, Ansible Container deleted
    the conductor after it had finished running.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: However, if we take a look at our `docker images` output, you will find that
    the `conductor` image we built is cached, as well as the base image used to create
    it. Note that the conductor image is prefixed with `demo-*`. Ansible Container
    automatically names container images based on the `project-service` nomenclature.
    This ensures that, if you are building and running multiple container projects
    at once, it is easy to tell which containers belong to which projects.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, our project is called, `demo `and the service we are building
    is `conductor`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also build our project by passing in the `--save-conductor-container`
    flag to keep our `conductor` container after the `ansible-container build` process
    finishes. This is useful for debugging failed builds by having the ability to
    view our containers from the context that Ansible is running from. Let''s try
    rebuilding our `demo` project, this time saving the `conductor` container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, you will see the output reflect a slight difference: `Conductor
    terminated. Preserving as requested`, in addition to the output we observed earlier.
    This indicates that, while the conductor has stopped due to it having finished
    its job, the container, `demo_conductor`, remains for us to look at with `docker
    ps -a`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: With a firm understanding of how the Ansible Container build process works,
    as well as how Ansible Container builds the conductor image, we can use this knowledge
    to recreate the Docker Compose project we introduced at the beginning of this
    chapter. We can use Ansible Container to spin up the `memcached` server container
    we created before.
  prefs: []
  type: TYPE_NORMAL
- en: 'In your text editor, open the `conductor.yml` document we looked at earlier.
    Delete the curly braces after our `services: {}` declaration, and add the following
    beneath it, indented two spaces as per the `YAML` syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the syntax we are using to specify our service is remarkably
    similar to the Docker Compose syntax we created earlier. For the purposes of this
    demonstration, we are going to use the same parameters for `ports` and `volume` that
    we used with Docker Compose earlier, so that the reader may easily see the slight
    differences in the syntax. You will note that the `container.yml` syntax and Docker
    Compose syntax have many similarities, but the primary differences allow Ansible
    Container to be more flexible with how container services are built and deployed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Save and close the file. If you execute the `ansible-container build` command
    again, you should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: After Ansible Container has built our conductor image, we can observe from this
    output that Ansible Container now recognizes that we have a service called `AC_Cache_Server`
    enabled and it is attempting to build it. However, we do not have any Ansible
    roles associated with this service, so it returns the message `Nothing to do`.
    This would usually be the step in the process during which our playbooks would
    be executed to build the services we are creating. Since we do not have any roles
    defined, Ansible Container is going to skip this step and terminate the `conductor`
    container as usual.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible Container run
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have a service defined, we can use the `ansible-container run`
    command to start our service. The run command quickly generates a small Ansible
    playbook that is responsible for starting the containers specified in the `container.yml`
    file. This playbook leverages the `docker_service` Ansible module for starting,
    stopping, restarting, and destroying containers. The `docker_service` module is
    also useful for interfacing with the Docker daemon installed on the host OS to
    pull and delete images from the Docker image cache. While it''s not super important
    to understand the implementation details behind the module at this point, it is
    helpful to understand how Ansible Container is working behind the scenes to run
    containers. Executing the `ansible-container run` command will display the stages
    of the playbook run, as well as `play recap`, similar to the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see by reading through the playbook run output, you can easily follow
    the key highlights of our project as we bring it into a running state:'
  prefs: []
  type: TYPE_NORMAL
- en: Our project cannot find the `memcached` image we specified, so Ansible Container
    pulls it from the default repository (Docker Hub)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A single change has been made on our host to bring our container into a running
    state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: None of our plays failed; one task succeeded (bringing up our container), and
    this successful task made a change on our host in order to bring up the container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The conductor service was terminated
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the highlights from the Ansible Container playbook is critical
    to seeing how Ansible orchestration deploys and maintains our applications. As
    we discussed previously, the Ansible team works very hard to ensure that Ansible
    playbook execution is very simple to understand and easy to debug. By displaying
    all of the steps required to bring up container projects, it is very easy to debug
    failures and see potential areas for improvement as we move forward into developing
    more complex projects. The playbook that was just executed is generated on-the-fly
    when `ansible-container run` is executed, and is located in the `ansible-deployment`
    directory. Leveraging Ansible Container to run projects takes away much of the
    complexity of deploying and maintaining projects since all of the deployment complexity
    is abstracted away. From the perspective of the user, you are concerned with ensuring
    the containers run and are built properly. Ansible Container becomes an end-to-end
    lifecycle management tool that enables containers to be built consistently and
    to run in an expected state every time. As we will see later in the book, having
    Ansible Container streamline the deployment complexity is especially useful in
    environments that leverage Kubernetes or OpenShift.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that our container run has completed, let''s take a look to see what containers
    are running on our host using the `docker ps -a` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: As expected, it is easy to see that our `memcached` container (version 1.4.36)
    is in a running state. Also, note that the `conductor` container is not running
    or showing up in our `docker ps` output. Ansible Container only runs the containers
    defined in the `container.yml` file as the *desired state*, unless you choose
    to keep the `conductor` container for debugging purposes. The name of the container,
    as we specified in our `container.yml` file, is `demo_AC_Cache_Server_1`. You
    may ask yourself why this is the case, as we observed when we created the `container.yml`
    file that we had specifically named our container `AC_Cache_Server`. One of the
    great features of Ansible Container is that it understands that, as developers,
    we might be running and testing multiple versions of our projects at once on the
    same host or group of hosts. By default, when Ansible Container starts containers,
    it automatically appends the name of our project (`demo` in this case) to the
    front of the name of the running container, and a number indicating the instance
    ID of the running container.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, since we have one instance of this container running, Ansible
    Container automatically appended `demo_` and `_1` to the beginning and end of
    our container name so that it would not conflict if we were testing multiple versions
    of this container on the same host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we are recreating the exercise we started at the beginning of the chapter
    on this host, let''s run the same `telnet` test using the `stats slabs` command
    we executed earlier to see if our `memcached` container is running and responding
    as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: It appears that our containerized service is running and properly accepting
    requests, listening on the network interfaces of our Docker host. Keep in mind,
    we specified in our `container.yml` file that our localhost port (`11211`) should
    be forwarded to the container's listening port (also `11211`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a quick peek at the image cache on the Docker host. We can do this
    by executing the `docker images` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on this output, we can understand more clearly how Ansible Container
    is working on the backend. In order to bring up our `demo` project, Ansible Container
    had to leverage three images: `CentOS 7`, `memcached`, and `demo-conductor`. The
    container image named `demo-conductor` is the conductor image that was created
    during the build process. To build the conductor image, Ansible Container had
    to download and cache the `CentOS 7` base image also seen in this output. Finally,
    `memcached` is the container that Ansible had to pull from the image repository,
    as it was specified in the `services` section of our `container.yml` file. The
    reader may also note that the conductor image is prefaced with the name of our
    project `demo`, similarly to the running state of our service container in the
    preceding output. This is again to avoid name conflicts and to have the flexibility
    to run multiple container projects at once on the same host.'
  prefs: []
  type: TYPE_NORMAL
- en: Ansible Container destroy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you have finished experimenting with the `demo` project, we can use the
    `ansible-container destroy` command to stop all running instances of our container
    and remove all traces of it from our system. `destroy` is useful for cleaning
    up existing deployments and testing our containers by rebuilding them from scratch.
    To destroy a container, simply run `ansible-container destroy` in your project
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to the `run` command seen earlier, destroy executes the same playbook
    that was autogenerated by the `run` process. However, this time, it stops and
    deletes the containers specified in the `container.yml` file. You may find that
    the `docker ps -a` output now displays no running containers on our host:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, the `destroy` function has wiped out the `conductor` container image,
    as well as the service container images on the Docker host. We can validate this
    with the `docker images` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Note that the only container left on the system is the base `CentOS` container.
    This can be manually deleted but, by default, Ansible Container leaves this on
    the system to speed up the process of destroying and rebuilding projects.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the course of this chapter, we have learned some fundamental concepts about
    how Ansible Container works, how it leverages the Docker Compose APIs, as well
    as basic lifecycle management tools built-in to Ansible Container, including `init`,
    `build`, `run`, and `destroy`. Having a firm grasp and understanding of what these
    features do and how they work is foundational when it comes to going forward and
    digging deeper into more complex projects we will create in Ansible Container.
    Although this example is included in the official Git repository of the book,
    feel free to recreate and tweak these examples to experiment further with how
    Ansible Container works. In the next chapter, we will learn how to use Ansible
    Container with existing roles, leveraging those roles to create reusable container
    artifacts.
  prefs: []
  type: TYPE_NORMAL
