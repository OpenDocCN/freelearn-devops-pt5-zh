- en: '*Chapter 8*: Deploying Docker Apps to Kubernetes'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recently, lots of container orchestrators have sprung up like mushrooms after
    a rainstorm, but one orchestrator is poised to dominate the market: Kubernetes,
    from the Cloud Native Computing Foundation. Google originally released Kubernetes
    with the intention of bringing the same level of sophistication to the world of
    open source container runtimes as it has been doing for years internally with
    the Borg clustering system.'
  prefs: []
  type: TYPE_NORMAL
- en: We will begin by learning more about different Kubernetes distributions and
    why you might want to use each one. We will start with using Kubernetes on a local
    development workstation, and then install a sample application locally.
  prefs: []
  type: TYPE_NORMAL
- en: As we progress through the chapter, you will learn how to create a Kubernetes
    cluster on **Amazon Web Services** (**AWS**) through **Elastic Kubernetes Service**
    (**EKS**), and deploy your application to a cluster running on multiple **Elastic
    Compute Cloud** (**EC2**) nodes. We will use AWS CloudFormation, an infrastructure-as-code
    system, to deploy the EKS cluster. Once we have deployed the cluster to AWS, we
    will learn about using labels and namespaces to organize our applications.
  prefs: []
  type: TYPE_NORMAL
- en: Running a Kubernetes cluster is more complex than the alternatives presented
    so far, but it opens up a huge universe of tools and techniques for running clustered
    applications with a vendor-neutral, cloud-native approach. Kubernetes is useful
    not only for cloud deployments, but also for on-premises deployments and local
    development.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Options for Kubernetes local installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a sample application – ShipIt Clicker v4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a Kubernetes distribution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting familiar with Kubernetes concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spinning up AWS EKS with CloudFormation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying an application with resource limits to Kubernetes on AWS EKS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using AWS Elastic Container Registry with AWS EKS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using labels and namespaces to segregate environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started by getting Kubernetes running on our local workstation. Then,
    we will look at the various Kubernetes distributions available.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this chapter, you will need to set up Kubernetes on your local workstation,
    either through Docker Desktop or by installing a Kubernetes distribution, such
    as Minikube. In addition, to deploy your containers to AWS, you will need an account
    set up in advance.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can sign up for an AWS account at the following URL if you haven''t already
    done so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/](https://aws.amazon.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: The code files for this chapter can be downloaded from the `chapter8` directory
    at [https://github.com/PacktPublishing/Docker-for-Developers/](https://github.com/PacktPublishing/Docker-for-Developers/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://bit.ly/3fXO5xy](https://bit.ly/3fXO5xy)'
  prefs: []
  type: TYPE_NORMAL
- en: Options for Kubernetes local installation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You need to set up a local Kubernetes installation in order to build, package,
    and test your Docker application in preparation for deploying it to a production
    installation in the cloud. Please review the Kubernetes *Getting Started* documentation
    ([https://kubernetes.io/docs/setup/](https://kubernetes.io/docs/setup/)). This
    documentation calls this local environment a **learning environment**. Think of
    the local environment as a way to learn about and test your application before
    you take the application to production with Kubernetes in the cloud. Let's continue
    by weighing up the options, starting with Docker Desktop's Kubernetes support.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Desktop with Kubernetes
  prefs: []
  type: TYPE_NORMAL
- en: For most people, this is the easiest way to start experimenting with Kubernetes.
    You don't have to set up cloud accounts or do a complicated installation to get
    started if you choose to do this. To install Docker Desktop, follow the download
    links at [https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop).
  prefs: []
  type: TYPE_NORMAL
- en: 'With recent versions of Docker Desktop, you can enable Kubernetes support and
    run and develop Kubernetes applications on your workstation. Open the Docker Desktop
    application on your workstation and go to the **Preferences** menu to open the
    **Settings** dialog. Tick the **Enable Kubernetes** box and hit the **Apply &
    Restart** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B11641_08_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Example of enabling Kubernete
  prefs: []
  type: TYPE_NORMAL
- en: This will activate a single-node Kubernetes cluster on your local workstation.
    Once you have enabled Kubernetes, you are ready to verify that your local installation
    works. See the following section to find out how to do this.
  prefs: []
  type: TYPE_NORMAL
- en: Minikube
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you don't want to run Kubernetes through Docker Desktop, you should probably
    use Minikube to set up a local Kubernetes single-node cluster environment. This
    is available on Windows, Macintosh, and a wide variety of Linux operating system
    distributions.
  prefs: []
  type: TYPE_NORMAL
- en: To install Minikube, follow the directions for your operating system found at
    [https://kubernetes.io/docs/tasks/tools/install-minikube/](https://kubernetes.io/docs/tasks/tools/install-minikube/),
    and then follow the instructions in the following section to verify that your
    Minikube installation works.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying that your Kubernetes installation works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Interacting with Kubernetes is done mostly through the **command-line interface**
    (**CLI**). You can issue the following command to see whether your environment
    is functional; it will show all the running pods, including the system pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Output of kubectl get pods'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B11641_08_002.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 – Output of kubectl get pods
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have Kubernetes running on your local workstation, you can develop
    and deploy applications using Kubernetes. Applications you develop and package
    with Kubernetes can be deployed with the same tools that you use locally – but
    at a much larger scale in the cloud. Before we deploy an application to the cloud,
    though, we should show that we can deploy a packaged application locally.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a sample application – ShipIt Clicker v4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's imagine that the ShipIt Clicker application introduced in previous chapters
    has been shipped to production and the team responsible for operations is nervous
    about the limits of scaling this application since it is only deployed on one
    server. In order to scale out this Docker application to multiple servers, the
    team has decided to migrate to Kubernetes and package the software for Kubernetes
    using the Helm package manager. To proceed, let's install Helm and test it out.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Helm
  prefs: []
  type: TYPE_NORMAL
- en: Helm is to Kubernetes what a package manager is to a modern operating system.
    It allows developers to specify how their application is packaged and deployed
    in a Kubernetes cluster. Helm is not only a package manager, but also a templating
    system for generating Kubernetes configurations and applying those configurations
    in a controlled way. Helm allows developers to define the entire set of containers
    and their interrelated Kubernetes configurations. Once you have defined an application
    in Helm, it becomes simple to install and update that application.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can install this on macOS easily with Homebrew using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: For other operating systems, follow the Helm installation instructions at [https://helm.sh/docs/intro/install/](https://helm.sh/docs/intro/install/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have installed Helm, use it to install the stable Helm repository
    (so that we can install other software packages that Helm supports, such as the
    NGINX Ingress Controller) with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Once you have installed this, you can use Helm to install applications from
    the catalog to your local Kubernetes instance. You can also use Helm to install
    applications defined in local Helm charts. We will use Helm to deploy ShipIt Clicker
    to Kubernetes, in conjunction with another Helm package, the NGINX Ingress Controller.
    In this chapter, we will first deploy the ShipIt Clicker application to the local
    learning environment Kubernetes cluster, and later, we will deploy ShipIt Clicker
    to the cloud on Amazon EKS.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the NGINX Ingress Controller and ShipIt Clicker locally
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s use Helm to install a packaged application, the NGINX Ingress Controller,
    and then use it to install ShipIt Clicker. An Ingress Controller is a Kubernetes
    networking proxy that allows requests from the outside to reach applications deployed
    to Kubernetes, with well-defined interfaces to help wire together the applications.
    The stable Helm repository contains the NGINX Ingress Controller. Install it as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Later in the chapter, we will explore Ingress Controller in more detail. Know
    for now that this simple installation is sufficient to expose services inside
    the Kubernetes cluster with the right configurations to `localhost` so that you
    can test them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will build the ShipIt Clicker Docker container, tag it, and push it
    to Docker Hub. Kubernetes relies on pulling Docker images from a Docker image
    registry, so it is insufficient to only have the container on your local system.
    Issue these commands, replacing `dockerfordevelopers` with your Docker Hub username:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Edit the `shipitclicker/values.yaml` file and replace `dockerfordevelopers`
    with your Docker Hub username in this stanza:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, deploy ShipIt Clicker to the Kubernetes local environment. In this case,
    we will use a local Helm Chart instead of one from a network Helm Chart repository.
    The Helm Chart for ShipIt Clicker is in the GitHub repository, in the `chapter8/shipitclicker`
    directory. Install it with Helm, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Visit `http://localhost/` to view the ShipIt Clicker application. You should
    see the running application splash screen.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting local installation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you can't reach the application at `http://localhost/`, you might have another
    web server running on port `80`, such as Apache 2.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are running this on Kubernetes, you need to use Kubernetes commands
    to connect to services that are on the inside of the cluster and not exposed through
    the Ingress Controller.
  prefs: []
  type: TYPE_NORMAL
- en: 'To expose the Redis port from the Kubernetes cluster for testing, use the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now that you have deployed the ShipIt Clicker application to a local Kubernetes
    installation, you can proceed with deploying it to a larger cloud environment
    and configuring it for production readiness.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a Kubernetes distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, how do we host Kubernetes beyond installing it on our workstations? When
    it comes to choosing a Kubernetes distribution, you are presented with a plethora
    of options, as we saw in [*Chapter 5*](B11641_05_Final_NM_ePub.xhtml#_idTextAnchor080),
    *Alternatives for Deploying and Running Containers in Production*. We are now
    going to revisit some of the most popular options to help you gain an understanding
    of the choices available based on your cloud provider or bare-metal data center
    setup, as well as see why we are choosing to use EKS to demonstrate the migration
    of the ShipIt Clicker sample application to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Google Kubernetes Engine
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Google Kubernetes Engine** (**GKE**) is Google''s key service for hosting
    containers in a Kubernetes-based environment. GKE (formerly known as Google Container
    Engine) was released in an Alpha state in November 2014 and went live in August
    2015 for general usage.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It currently offers one of the most mature Kubernetes services offered by cloud
    providers, including the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: A single cluster quick start option for trialing the service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container vulnerability scanning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Built-in data encryption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple channels for upgrading, repairing, and releasing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration with Google monitoring services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic scaling and load balancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google-managed underlying hardware
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further documentation for interested readers can be found at the GKE website
    at [https://cloud.google.com/kubernetes-engine/docs](https://cloud.google.com/kubernetes-engine/docs).
  prefs: []
  type: TYPE_NORMAL
- en: Let's now compare this with Amazon's offerings.
  prefs: []
  type: TYPE_NORMAL
- en: AWS EKS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon's answer to serving and managing containers in the cloud is its EKS service.
    As with GKE, Amazon's Kubernetes services, EKS, offers a managed service. Unlike
    Google's offering, it came to the market later, not being available until early
    2018\. However, what EKS loses in maturity, it makes up for in features.
  prefs: []
  type: TYPE_NORMAL
- en: 'These features include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Serverless hosting via AWS Fargate ([https://aws.amazon.com/fargate/](https://aws.amazon.com/fargate/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Server deployment options on EC2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero-downtime upgrades and patching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Auto-detection of unhealthy nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hybrid hosting solutions with AWS Outposts ([https://aws.amazon.com/outposts/](https://aws.amazon.com/outposts/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Jobs for batch processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can read more about EKS on the official website at [https://aws.amazon.com/eks/features/](https://aws.amazon.com/eks/features/).
  prefs: []
  type: TYPE_NORMAL
- en: We'll be exploring EKS in more detail throughout this chapter and in subsequent
    chapters, mostly since it is the managed Kubernetes offering from the dominant
    cloud vendor. Other distributions have their merits, however, so we will also
    examine some of the other options out there. Next is Red Hat OpenShift.
  prefs: []
  type: TYPE_NORMAL
- en: Red Hat OpenShift
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift is a collection of software developed by Red Hat geared toward containerized
    application architectures. Like GKE and EKS, OpenShift is Kubernetes-focused;
    however, where it diverges is with its focus on build-related artifacts and a
    native image repository.
  prefs: []
  type: TYPE_NORMAL
- en: Having used Jenkins in the projects presented in this book, you will now be
    familiar with `kubectl`commands to include mechanisms that replicate the sort
    of CI/CD functionality that you might otherwise have to use software such as Jenkins
    or Spinnaker to get. This includes the ability to create builds, test runs, and
    deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some other key features that also make OpenShift a desirable option:'
  prefs: []
  type: TYPE_NORMAL
- en: Automated upgrades and life cycle management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Open source code base available on GitHub ([https://github.com/openshift](https://github.com/openshift))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy in any cloud, in a data center, or on-premises
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An image registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring and log aggregation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For further information on Red Hat OpenShift, make sure to check out the documentation
    on GitHub ([https://github.com/openshift/openshift-docs](https://github.com/openshift/openshift-docs))
    or on the official website ([https://www.openshift.com/](https://www.openshift.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Azure Kubernetes Service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We've looked at the major players so far, but of course, couldn't go any further
    without mentioning Microsoft's contribution to the Kubernetes ecosystem. For users
    of Microsoft cloud products, **Azure Kubernetes Service** (**AKS**) provides a
    mechanism to serve Docker containers in a Kubernetes-based environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a brief tour of what AKS offers:'
  prefs: []
  type: TYPE_NORMAL
- en: The elastic provisioning of services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration with the Azure DevOps and Monitor services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identity and access management with Active Directory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Failure detection and container health monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canary deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log aggregation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, for Azure users, it has a comparable set of features to those
    available in EKS and GKE. If you would like to learn more, please refer to the
    AKS documentation ([https://docs.microsoft.com/en-us/azure/aks/](https://docs.microsoft.com/en-us/azure/aks/)).
    Here, you will also find a quick start guide for getting a taste of what the service
    has to offer.
  prefs: []
  type: TYPE_NORMAL
- en: Before running through the components that form the basis of Kubernetes, let's
    briefly review the other options available.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing other relevant options
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: EKS, OpenShift, GKE, and AKS represent the most popular Kubernetes services
    on the market. However, they are not alone. Digital Ocean offers an option for
    those wishing to get a taste of a managed service outside of deploying your own
    RedShift infrastructure or signing up to the big cloud providers. You can read
    more about it at [https://www.digitalocean.com/products/kubernetes/](https://www.digitalocean.com/products/kubernetes/).
  prefs: []
  type: TYPE_NORMAL
- en: Many readers will be familiar with IBM, and they too offer cloud-hosting services.
    If you want to try out Kubernetes in their cloud environment, you can find details
    on their website, including how to set up a free cluster ([https://www.ibm.com/cloud/container-service/](https://www.ibm.com/cloud/container-service/)).
  prefs: []
  type: TYPE_NORMAL
- en: Anyone familiar with VMware might wish to explore their Kubernetes offering
    as well –VMware Tanzu Kubernetes Grid – which has strengths in building hybrid
    clouds ([https://tanzu.vmware.com/kubernetes-grid](https://tanzu.vmware.com/kubernetes-grid)).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, those looking for a fully managed Kubernetes service or those who are
    already customers of Rackspace have the option of checking out their **Kubernetes
    as a Service** (**KaaS**) offerings ([https://www.rackspace.com/managed-kubernetes](https://www.rackspace.com/managed-kubernetes)).
  prefs: []
  type: TYPE_NORMAL
- en: That wraps up our whistle-stop tour of the hosting platforms available for deploying
    your containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the remainder of this chapter, we will be using Amazon''s EKS service.
    If you haven''t created an account, we recommend you sign up for one here now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/](https://aws.amazon.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Users of other cloud providers may find that they can adapt the following sections
    to their own services if they wish.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now dig into the core concepts of Kubernetes, including pods, nodes, and
    namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: Getting familiar with Kubernetes concepts
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you know where you can deploy Kubernetes, let''s dive into some of
    the key concepts (including objects, ConfigMaps, pods, nodes, services, Ingress
    Controllers, secrets, and namespaces) and how they work. Let''s start by examining
    an architecture diagram that shows the relationship between the various components
    of the system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Kubernetes architecture diagram'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B11641_08_003.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.3 – Kubernetes architecture diagram
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.3 – Kubernetes architecture diagram
  prefs: []
  type: TYPE_NORMAL
- en: With Kubernetes, the cluster consists of a control plane that manages all aspects
    of the Kubernetes cluster (including the interface with the cloud provider) and
    a set of workers for the cluster, known as nodes, where the applications hosted
    by the cluster live. Developers and cluster operators interact with Kubernetes
    via the control plane through an API. The processes in the control plane communicate
    with the processes running on the individual worker nodes via the `kubelet` process,
    and the processes on the worker nodes are organized as pods that communicate with
    one another via the `kube-proxy` process that runs on each node.
  prefs: []
  type: TYPE_NORMAL
- en: Objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most fundamental concept in Kubernetes is an `kubectl` utility to create,
    query, and modify all the different types of Kubernetes objects, as well as to
    configure the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The `kubectl` command-line utility can take YAML format files that describe
    the objects and use them to create and update the state of the system. This is
    the most basic way of defining, installing, and upgrading Kubernetes applications.
    The Helm tool we used to install applications takes this a step further by providing
    templating and life cycle capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: We recommend configuring your application through Helm Charts. You briefly saw
    how to use Helm at the beginning of this chapter. A Helm Chart is simply a set
    of YAML configuration files that contain information about your containerized
    application.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create a new Helm Chart using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This sets up a Helm Chart structure with template files that are ready for customization.
  prefs: []
  type: TYPE_NORMAL
- en: ConfigMaps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes handles application configuration with a concept known as a ConfigMap.
    Then, we need to define the configuration for the container itself. This is handled
    through a ConfigMap.
  prefs: []
  type: TYPE_NORMAL
- en: The key idea behind ConfigMaps is that you can separate the important configuration
    from the content of the images themselves. This is done in order to provide better
    portability of your microservices and applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'ConfigMaps can be created directly through `kubectl` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'A ConfigMap will contain information used by your application, and other key-value
    pairs, such as the namespace. The following example illustrates how an application''s
    ConfigMap might look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: A ConfigMap such as the one we just demonstrated would then be stored inside
    your Helm Chart directory in the templates folder – for example, `shipitclicker/templates/configmap.yaml`.
  prefs: []
  type: TYPE_NORMAL
- en: With this basic setup in place, you can then install your configuration through
    the `helm install` command. We will be exploring configuration in both its ConfigMap
    and Helm Chart formats in further detail throughout this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Pods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pods in Kubernetes serve the purpose of grouping together *1* to *n* containerized
    components, which are then run in a shared context. They also include shared resources,
    such as IP addresses, storage, and definitions on how containers should be run.
    Multiple containers running together in a pod can communicate with each other
    on fixed ports on `localhost`, simplifying application configuration significantly.
  prefs: []
  type: TYPE_NORMAL
- en: When defining what should be run in a pod, the best approach is to think of
    it as holding all the necessary containers for a system or application. Multiple
    pods can then be added to Kubernetes to scale your application out horizontally.
    This allows you to create redundancy and helps cope with increases in traffic
    and load.
  prefs: []
  type: TYPE_NORMAL
- en: The shared context that the pods use is implemented through Linux concepts such
    as cgroups and namespaces. In [*Chapter 12*](B11641_12_Final_NM_ePub.xhtml#_idTextAnchor278),
    *Introduction to Container Security*, we will explore some of these concepts in
    depth in relation to container security.
  prefs: []
  type: TYPE_NORMAL
- en: Nodes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Machines that host Docker containers in Kubernetes' ecosystem are known as **nodes**,
    though you may also encounter the terms *minions* or *workers* – they all mean
    the same thing, but node is the official term. Kubernetes supports nodes that
    are either physical or virtual machines. Services such as Amazon's EKS provide
    the mechanisms for deploying node infrastructure. You deploy Kubernetes pods on
    nodes; the pods include both containers and shared resources.
  prefs: []
  type: TYPE_NORMAL
- en: In the learning environment that we are using, our local development workstation
    is the sole node in the cluster. Later in this chapter, we will be creating a
    Kubernetes cluster with nodes managed by EKS on AWS EC2\. Kubernetes nodes run
    containers through pods and other Kubernetes objects, such as DaemonSets.
  prefs: []
  type: TYPE_NORMAL
- en: Alternative container runtimes
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes nodes could potentially run different container runtimes. Kubernetes
    not only supports Docker containers, but also other container technologies, including
    containerd, CRI-O, and Frakti. Since this book is about Docker, we will exclusively
    use the Docker runtime in our examples.
  prefs: []
  type: TYPE_NORMAL
- en: Services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A Kubernetes service is a way of declaring how your application exposes its
    interfaces to the world. It typically defines a network port that other Kubernetes
    pods can use to communicate with your application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Helm Chart for ShipIt Clicker emits a service template that defines a `ClusterIP`
    service definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This declaration describes the fact that ShipIt Clicker exposes HTTP on port
    `8008` as a service on each pod. This lets other Kubernetes services discover
    and make connections to it.
  prefs: []
  type: TYPE_NORMAL
- en: Ingress Controllers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes manages an internal network where the applications in a cluster can
    communicate with one another via a private network. By default, there is no way
    to reach applications running on the inside of a Kubernetes cluster from the outside.
    The Ingress Controller plays the role of a proxy and connection broker. Depending
    on whether you are deploying on-premises or in the cloud, different types of Ingress
    Controller have different uses. For example, earlier in this chapter, we installed
    the `nginx-ingress` Ingress Controller to allow us to reach applications running
    on our local Kubernetes installation. That controller is also useful when you
    want a vendor-neutral way of granting access to Kubernetes applications.
  prefs: []
  type: TYPE_NORMAL
- en: Other Ingress Controllers allow Kubernetes to work smoothly with different types
    of external load balancers, such as `aws-alb-ingress-controller`, which enables
    the use of an `k8s-bigip-ctlr`, which enables the use of F5 BIG-IP load balancers,
    which are found in many data centers.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use Ingress Controllers to map domain names and HTTP paths to Kubernetes
    services. This makes it really easy to expose different services at different
    URLs. If you had a fleet of microservices, you could expose them at different
    API endpoints using this pattern. You can take advantage of Ingress Controllers
    by declaring an ingress object for your application that advertises how to connect
    your service to the outside world. For the ShipIt Clicker example, we use the
    following to map the service to `localhost` in the default namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The Kubernetes system handles connections to applications hosted inside the
    cluster from the outside using this Ingress Controllers definition. This means
    that when you are first developing your application, you do not need to worry
    about how it is connected to the outside world. The Kubernetes configurations
    that enable Ingress Controllers can all be managed with Helm Charts, too.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will examine how Kubernetes deals with sensitive information – using
    secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Secrets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every application has values that need to be protected, from database passwords
    to API keys, so having a mechanism to store and retrieve them securely is an important
    function. In Kubernetes, this is handled with a mechanism called secrets. You
    can use a combination of configuration files and `kubectl` commands for sharing
    and modifying information that needs to be protected with your pods and their
    running containers. Once you have created a secret, you can use it in your application
    through a variety of mechanisms, including exposing a secret as an environment
    variable or creating a file that containers running in a pod can retrieve.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key operations in Kubernetes related to secrets are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a secret
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describing a secret
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrieving a secret
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Editing a secret
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's explore these four concepts, starting with creating a secret.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a secret
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can use several procedures to create a secret. This could be done by adding
    it manually on the command line or storing it in a YAML template file and using
    it from there.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add a secret stored in a text document via the command line, we can use
    the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: If we do this, `kubectl` will take care of encoding the secret for us using
    Base64 encoding.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s prepare a secret another way, with a configuration file. In order to
    prepare a text secret for this file, it must be Base64-encoded. You can do that
    from the command line in macOS or Linux with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'If we wanted to instead store the secret in a configuration file, and use `kubectl`
    to add it to Kubernetes, we could create the following `secret-api-token.yaml`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, using the `kubectl apply` command-line option, we can create the secret:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: You will notice that the configuration file format for the secret is very similar
    to the example ConfigMap we examined.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because `shipitclicker` uses Helm to manage its Kubernetes objects, it has
    support for secrets built into its templates. The one secret it references in
    the code in this chapter is related to a Node.js server-side framework setting
    for the Express framework used by the sample application that deals with server
    sessions. This secret is called `SESSION_SECRET`, and it is stored in the `chapter8/shipitclicker/templates/secrets.yaml`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Notice that this uses template expressions for `name` and `namespace` in order
    to align with the other templates that Helm transforms.
  prefs: []
  type: TYPE_NORMAL
- en: We created this secret when we installed the `shipitclicker` Helm template earlier
    in the chapter when we used the `helm install` command. That is how you create
    secrets when you use a Helm template.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen several ways of creating secrets, we will show how we
    ask Kubernetes what secrets it knows about.
  prefs: []
  type: TYPE_NORMAL
- en: Describing a secret
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once a secret has been created, you can list it using the `kubectl get secrets`command.
    This will list the secrets in a similar way to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B11641_08_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – List of secrets
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn more about the secret, use the `kubectl describe` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Output of the kubectl describe command showing the secret''s
    metadata'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B11641_08_005.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.5 – Output of the kubectl describe command showing the secret's metadata
  prefs: []
  type: TYPE_NORMAL
- en: You will see metadata about your secret displayed, including the key of the
    secret – in this case, `SESSION_SECRET`. It will not show the value of the secret,
    though.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving a secret
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A typical way for a Kubernetes application to retrieve a simple secret is to
    define it as an environment variable passed to the container referencing the secret.
    See this excerpt from the rendered Helm chart templates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the environment variables mapped to the deployment for the
    `shipitclicker` container reference both the `configMapKeyRef` and `secretKeyRef`
    entries.
  prefs: []
  type: TYPE_NORMAL
- en: To deal with more complex secrets that are complete files, such as SSH private
    keys, the mechanism is similar. See the Kubernetes secrets documentation for more
    scenarios at [https://kubernetes.io/docs/concepts/configuration/secret/](https://kubernetes.io/docs/concepts/configuration/secret/).
  prefs: []
  type: TYPE_NORMAL
- en: 'For troubleshooting purposes, we can retrieve a secret from Kubernetes from
    the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have seen how to retrieve a secret, we will examine how to edit
    secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Editing secrets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you wish to edit the secret after creating it, use the `kubectl edit` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This will open your default editor (by default, vi) and you can edit the secret.
    You will have to have the Base64-encoded replacement value ready. It will look
    something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: You can edit secrets directly this way. You might need to redeploy your application
    after updating a secret, depending on how it uses that secret. Having to manage
    this by hand can get complicated, which is one of the reasons why we use Helm
    to package applications.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the ShipIt Clicker session secret
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For applications deployed with Helm, it is usual practice to make changes through
    the Helm templates instead of using raw `kubectl` commands. Now, we will change
    the ShipIt Clicker `SESSION_SECRET` key using Helm by following this procedure:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a Base64-encoded secret with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Edit the template `chapter8/shipitclicker/templates/secrets.yaml` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the value outputted by the `openssl` command for the new `SESSION_SECRET`
    value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Edit the `chapter8/shipitclicker/Chart.yaml` file and increment the chart's
    `version` number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You have to do this every time you update a Helm Chart. Then, update the template
    with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, the basic commands to add and edit secrets are very simple.
    Using them in our application is slightly more complex. This should give you a
    taste of how to create a secret value and retrieve information on it to explore
    the feature.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For further information on secrets, you can check out the latest Kubernetes
    documentation at [https://kubernetes.io/docs/concepts/configuration/secret/](https://kubernetes.io/docs/concepts/configuration/secret/).
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 14*](B11641_14_Final_NM_ePub.xhtml#_idTextAnchor316), *Advanced
    Docker Security – Secrets, Secret Commands, Tagging, and Labels*, we look into
    secret storage and usage in relation to Docker Swarm. While Docker Swarm is falling
    out of favor, with many teams switching to Kubernetes, it is important to understand
    these concepts when maintaining legacy systems. Additionally, you may find yourself
    in a position where you have to migrate systems from Docker Swarm to Kubernetes.
    The information provided in this chapter and [*Chapter 14*](B11641_14_Final_NM_ePub.xhtml#_idTextAnchor316),
    *Advanced Docker Security – Secrets, Secret Commands, Tagging, and Labels*, should
    help you map concepts from one technology to the other.
  prefs: []
  type: TYPE_NORMAL
- en: Namespaces
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to partition resources within Kubernetes, we can use a concept called
    namespaces. Namespaces provide a mechanism to group container resources into non-overlapping
    sets, which then allows you to subdivide your Kubernetes resources, based on your
    business needs, within the same cluster. This could include everything from environments
    (development, staging, and production) to groups of microservices. One important
    factor you should consider is that applications in the same namespace can read
    any secret in that namespace, so it represents a security boundary as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is tempting, once you learn of this feature, to want to use it everywhere,
    but the Kubernetes documentation cautions against this. The main namespaces content
    page ([https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/))
    states the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '"*For clusters with a few to tens of users, you should not need to create or
    think about namespaces at all*."'
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind, though, that different teams might want to segregate applications
    from one another, and namespaces are a good way to do that as they provide a security
    boundary. Later in this chapter, in the *Using labels and namespaces to segregate
    environments* section, we will explore using this concept to deploy our application
    to both a staging and production environment in AWS.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's set up AWS EKS with CloudFormation in order to deploy our application
    to the public cloud using Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Spinning up AWS EKS with CloudFormation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have walked through a local installation of Kubernetes and explored
    some of the cloud vendor options, we are going to try deploying containers to
    an AWS-hosted Kubernetes environment. This will be the EKS service we briefly
    introduced in the previous section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In order to achieve this, we will describe how to create and manage an EKS cluster
    using AWS CloudFormation, their infrastructure-as-code service. For more information
    on CloudFormation, be sure to check out the AWS guides and documentation at [https://docs.aws.amazon.com/cloudformation/](https://docs.aws.amazon.com/cloudformation/).
  prefs: []
  type: TYPE_NORMAL
- en: Assuming you have previously created an AWS account or followed the instructions
    under the *Technical requirements* section of this chapter, load up the AWS cloud
    console.
  prefs: []
  type: TYPE_NORMAL
- en: 'To proceed, we need to set up EKS. There are many ways to get a working EKS
    cluster that require varying amounts of work:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up everything by hand, step by step through the AWS console. We *do not
    recommend* this approach as it requires deep AWS knowledge to carry out correctly,
    and will lead to a hard-to-replicate environment with poor controls.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write infrastructure-as-code templates from scratch in either AWS CloudFormation
    or Terraform to control all the resources needed. This is an approach that might
    work for you if you are an expert in either CloudFormation or Terraform and have
    an existing investment in CloudFormation or Terraform tooling, but we *do not
    recommend this for beginners*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the `eksctl` tool (see [https://eksctl.io](https://eksctl.io)) to create
    a cluster with a simple CLI tool. This could work well if you are already familiar
    with AWS and want to put your cluster in a specific region and tweak more of the
    parameters of your cluster. We *only recommend this if you are familiar with AWS
    and EKS already*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Research and adopt infrastructure-as-code templates that someone else has already
    written. Both AWS and many other people have created CloudFormation and Terraform
    templates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are going to follow this last approach and use the AWS Quick Start CloudFormation
    templates for EKS to create our first cloud Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the AWS EKS Quick Start CloudFormation templates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon provides a handy set of CloudFormation templates called Quick Starts,
    built by their expert cloud architects to quickly get you up and running for a
    wide selection of AWS services and scenarios ([https://aws.amazon.com/quickstart/](https://aws.amazon.com/quickstart/)).
  prefs: []
  type: TYPE_NORMAL
- en: We will be using an AWS EKS Quick Start template for the next section of this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: However, before you deploy the EKS Quick Start CloudFormation templates, please
    take a moment to prepare your AWS account for deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing an AWS account
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are just starting to use AWS, there are a few critical things to take
    care of before you proceed in order to protect your account. These precautions
    and preparations also apply if you choose a method other than using the AWS Quick
    Start CloudFormation templates to create your EKS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: If you are already an experienced AWS user and have an AWS `us-east-2` region,
    and you know your public IPv4 address, you can skip ahead to the *Launching the
    AWS EKS Quick Start CloudFormation templates* section. Avoid using an assumed
    IAM role with administrative privileges to create the CloudFormation template,
    though – that can cause some of the child templates to enter an `UPDATE_ROLLBACK_FAILED`
    state, which is difficult to recover from.
  prefs: []
  type: TYPE_NORMAL
- en: Using an IAM administrator user and not the root account user
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First of all, ensure that you are not using the AWS console as the root account
    user. This is a major security risk. You will need an AWS IAM user account with
    administrative privileges. If you have just created your AWS root account, you
    can set one up by following the AWS instructions at [https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_create-admin-group.html](https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_create-admin-group.html).
  prefs: []
  type: TYPE_NORMAL
- en: Once you have set up this user and enabled billing access for the IAM user as
    per instructions, go to the [https://console.aws.amazon.com/iam/home#/home](https://console.aws.amazon.com/iam/home#/home)
    page and copy the IAM user's sign-in link to the clipboard. Edit your web browser
    bookmarks and use this URL to create an **AWS IAM Login** item. You will want
    to use this to sign in to your AWS account with your administrator account instead
    of using the root account.
  prefs: []
  type: TYPE_NORMAL
- en: 'On your local system, create an `eks-notes.txt` file and record the sign-in
    link there. Also, record the **User ARN** value of the administrator user from
    the [https://console.aws.amazon.com/iam/home?region=us-east-2#/users/Administrator](https://console.aws.amazon.com/iam/home?region=us-east-2#/users/Administrator)
    URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – AWS IAM user summary for the administrative user'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B11641_08_006.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.6 – AWS IAM user summary for the administrative user
  prefs: []
  type: TYPE_NORMAL
- en: This **Amazon Resource Name** (**ARN**) user is a string, much like a web **Uniform
    Resource Identifier** (**URI**), but it is Amazon-specific. Now that we have set
    up an administrative user, let's set up **multi-factor authentication** (**MFA**)
    to protect both the root account and the administrator user.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up MFA
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We recommend that you protect both the root account and every IAM user account
    with administrative privileges using MFA. If someone compromises your root account,
    they could create huge bills by launching expensive cloud resources, steal your
    information, or even delete all your data. When you are getting started, we recommend
    that you use MFA with a virtual MFA device and supporting software such as Google
    Authenticator, Authy, or 1Password.
  prefs: []
  type: TYPE_NORMAL
- en: 'For added security, you have the option of using one of the supported hardware
    token solutions, but virtual MFA works fine. Please see the AWS MFA documentation
    for more details on setting up MFA:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/iam/features/mfa/](https://aws.amazon.com/iam/features/mfa/)'
  prefs: []
  type: TYPE_NORMAL
- en: Signing in to the AWS console with the IAM user account
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ensure you have signed out of the root account. Then, use the sign-in URL from
    your `eks-notes.txt` document to sign in to the AWS console with your administrator
    IAM user account before proceeding.
  prefs: []
  type: TYPE_NORMAL
- en: Creating access keys for the IAM administrator user
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to use the AWS command-line tools, you will need to generate AWS access
    keys. You can read more about access keys and other types of AWS credentials at
    [https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html](https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the AWS console, go to the IAM service and look in the **Users** section
    for the administrator user you just created. Then, navigate to the **Security
    credentials** tab and create new access keys by pressing the **Create access key**
    button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B11641_08_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7– AWS IAM user summary for an administrative user
  prefs: []
  type: TYPE_NORMAL
- en: Download these access keys as a CSV file to your local system. You will need
    to open that file and examine the keys in order to configure the AWS CLI, which
    we will do next.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the AWS CLI on your local workstation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You are going to need a working AWS CLI installation on your local workstation
    to complete the configuration of the EKS cluster. If you don't already have this
    installed, follow the instructions to install it at [https://aws.amazon.com/cli/](https://aws.amazon.com/cli/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once it is installed, issue the `aws configure` command and use the access
    ID and secret key from the access key''s CSV file you saved in the previous section
    to configure the CLI to use the administrator user. Verify that it works with
    the `aws sts get-caller-identity` command. Inspect the output to make sure that
    it does not show an error message, and then verify that the ARN that this command
    emits for the active user is the same one as for the administrator user shown
    in the IAM web console. The output should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – Output of aws sts get-caller-identity'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B11641_08_008.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.8 – Output of aws sts get-caller-identity
  prefs: []
  type: TYPE_NORMAL
- en: You will need this set up when you configure the cluster for the ALB Ingress
    Controller later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an EC2 key pair for the EKS cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In order to perform the initial configuration of the EKS cluster, you will
    need to SSH to an EC2 virtual server that the CloudFormation template sets up,
    known as the bastion host. A `us-east-2` region. Signed in as your IAM administrator
    user, go to [https://console.aws.amazon.com/ec2](https://console.aws.amazon.com/ec2),
    and then make sure you switch your region to **us-east-2** from the region picker:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9 – Switching your AWS region'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B11641_08_009.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.9 – Switching your AWS region
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, find and click on the key pairs link in the menu on the left, create
    a new key pair called `ec2-eks`, and download it. You will need this key pair
    when you configure the EKS cluster. To prepare for that, copy this key pair to
    the `.ssh` directory under your local user home directory and set its permissions
    so that SSH will allow its use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: You will need this key to connect to the bastion host for your EKS cluster later.
    Next, make sure you know your public IP address.
  prefs: []
  type: TYPE_NORMAL
- en: Recording your public IP address in CIDR notation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We are going to restrict access from the internet to the Kubernetes cluster
    by restricting it to just the pubic IPv4 address you are currently using. This
    will keep malicious hackers and people who attack internet hosts from scanning
    your system. To do this, go to [https://whatismyip.com/](https://whatismyip.com/)
    and copy your public IPv4 address in CIDR format, which is the raw numerical address
    with `/32` appended. For example, if it was `192.2.0.15`, the CIDR form of your
    IPv4 address would be `192.2.0.15/32`. On your local system, open your `eks-notes.txt`
    file and record the CIDR address there.
  prefs: []
  type: TYPE_NORMAL
- en: Launching the AWS EKS Quick Start CloudFormation templates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can find the documentation on the AWS EKS Quick Start CloudFormation templates
    at [https://aws.amazon.com/quickstart/architecture/amazon-eks/](https://aws.amazon.com/quickstart/architecture/amazon-eks/).
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a complete picture of what this offers, read the deployment guide that
    AWS offers related to this quick start:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.aws.amazon.com/quickstart/latest/amazon-eks-architecture/welcome.html](https://docs.aws.amazon.com/quickstart/latest/amazon-eks-architecture/welcome.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'At a minimum, review the outline on that page. When you want to proceed with
    deployment, click on the **How to Deploy** section. You will see that you have
    two options when deploying the CloudFormation templates, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Deploy to a new VPC** ([https://fwd.aws/6dEQ7](https://fwd.aws/6dEQ7))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deploy to an existing VPC** ([https://fwd.aws/e37MA](https://fwd.aws/e37MA))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before you begin, sign out of the AWS console if you are still signed in with
    the root account user, and sign in as a administrator user using the IAM sign-in
    URL you recorded in the `eks-notes.txt` file.
  prefs: []
  type: TYPE_NORMAL
- en: We recommend that you start by deploying this infrastructure to a new **Virtual
    Private Cloud** (**VPC**). Click on that link or use the preceding URL to go to
    the CloudFormation stack creation forms. Most of the items in these forms can
    be left at their defaults, but some must be filled out both to complete initial
    cluster configuration and to ensure that you do not accidentally create an unsecure
    configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Guidance for EKS Quick Start CloudFormation creation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Creating the CloudFormation stack will require you to fill out a four-page
    CloudFormation parameters form by following the **Deploy into a new VPC** link
    in the previous section. This is the first page of that form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.10 – CloudFormation form, page 1 of 4: Prepare template'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B11641_08_010.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.10 – CloudFormation form, page 1 of 4: Prepare template'
  prefs: []
  type: TYPE_NORMAL
- en: This guidance will allow you to complete the items to get a working EKS cluster
    in about 30 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: Create Stack – Prerequisite – Prepare Template
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Leave all the items on this form at their defaults and hit the **Next** button.
    This will take you to the **Specify Stack Details** screen.
  prefs: []
  type: TYPE_NORMAL
- en: Specify Stack Details
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You can leave almost all of these items at their defaults, but specify items
    for the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`us-east-2a`, `us-east-2b`, and `us-east-2c`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`192.2.0.15/32`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**EKS cluster name**: Choose a short cluster name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`8`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eks-ec2`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Additional EKS admin ARN (IAM Role)**: Leave this blank, unless you have
    another AWS IAM role in your account that you want to give access to.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Additional EKS admin ARN (IAM User)**: Leave this blank, unless you have
    another AWS IAM user in your account that you want to give access to.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kubernetes Version**: 1.15.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do not use 1.16 or higher if you want to experiment with Spinnaker as described
    in [*Chapter 9*](B11641_09_Final_NM_ePub.xhtml#_idTextAnchor191), *Cloud-Native
    Continous Deployment Using Spinnaker*, as Spinnaker is not compatible with higher
    versions
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**EKS Public Access Endpoint**: Enabled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`192.2.0.15/32`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ALB Ingress Controller**: Enabled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster Autoscaler**: Enabled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**EFS Storage Class**: Enabled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring Stack**: Prometheus and Grafana.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting these options will ultimately allow you to manage the EKS cluster
    from your local workstation using the `kubectl`, `helm`, and `eksctl` tools. Once
    these are specified, press the **Next** button at the bottom of the form. This
    will take you to the **Configure Stack Options** screen.
  prefs: []
  type: TYPE_NORMAL
- en: Configure Stack Options
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Leave all of these at their defaults. Press the **Next** button at the bottom
    of the form. This will take you to the **Review** screen.
  prefs: []
  type: TYPE_NORMAL
- en: Review
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Scroll to the bottom of the form and check both of the checkboxes acknowledging
    that this might create IAM resources with custom names and that it might require
    the `CAPABILITY_AUTO_EXPAND` capability. Press the **Next** button at the bottom
    of the form to create the CloudFormation template. Wait about 30 minutes and review
    the creation status of the template in the CloudFormation console—it should complete
    without issue. Check that all the CloudFormation templates reach the completed
    state before proceeding. It should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.11 – The CloudFormation console with the CREATE_COMPLETE status'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B11641_08_011.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.11 – The CloudFormation console with the CREATE_COMPLETE status
  prefs: []
  type: TYPE_NORMAL
- en: Now, your EKS cluster is ready for its initial configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the EKS cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Having deployed the CloudFormation template, you will have an environment that
    contains the following AWS services:'
  prefs: []
  type: TYPE_NORMAL
- en: A VPC that serves as networking infrastructure for the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An EKS Kubernetes control plane managed by AWS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An EC2 bastion host used to configure the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes infrastructure, including three EC2 instances serving as nodes deployed
    across three AWS availability zones
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An ALB Ingress Controller that will allow outside access to cluster services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To gain initial access to the cluster, view the CloudFormation outputs for
    the stack and note the IPv4 address marked `BastionIP`. Then, SSH to the host
    with that address, replacing `192.2.10` with that IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the deployment is complete, follow the AWS deployment guide to validate
    the cluster state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.aws.amazon.com/quickstart/latest/amazon-eks-architecture/step-3.html](https://docs.aws.amazon.com/quickstart/latest/amazon-eks-architecture/step-3.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Use some of the commands you have learned about, such as `kubectl get all -A`,
    `kubectl get nodes`, and `kubectl describe service/kubernetes`, to explore the
    cluster configuration from the bastion host.
  prefs: []
  type: TYPE_NORMAL
- en: The bastion node already has `kubectl`, `helm`, and `git` installed, so you
    have the option of using it to perform some cluster maintenance chores. The Helm
    installation even has the stable charts repository already installed, which you
    can verify with the `helm repo list` command.
  prefs: []
  type: TYPE_NORMAL
- en: Keep an eye on AWS costs
  prefs: []
  type: TYPE_NORMAL
- en: Once you have deployed the EKS infrastructure, AWS will start charging you by
    the hour while it is running. You will be responsible for all charges incurred
    while the EKS cluster and EC2 servers are running. Keeping this EKS cluster running
    might cost up to **$10-20 per day**. Please visit the **Billing & Cost Management**
    dashboard at [https://console.aws.amazon.com/billing/home?#/](https://console.aws.amazon.com/billing/home?#/)
    in order to see your month-to-date and projected costs. We recommend that you
    have AWS generate cost and usage reports on a regular basis to help you track
    your spending. Information on enabling this can be found at [https://docs.aws.amazon.com/cur/latest/userguide/cur-create.html](https://docs.aws.amazon.com/cur/latest/userguide/cur-create.html).
  prefs: []
  type: TYPE_NORMAL
- en: Verifying that the ALB Ingress Controller is working
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Because we enabled the ALB Ingress Controller optional add-in when we created
    the EKS cluster, we can skip the detailed directions in the ALB user guide ([https://docs.aws.amazon.com/eks/latest/userguide/alb-ingress.html](https://docs.aws.amazon.com/eks/latest/userguide/alb-ingress.html))
    to set up an ALB Ingress Controller for EKS. Since the ALB Ingress Controller
    is already set up, the cluster will automatically be able to create new Ingress
    Controllers and application load balancers when it finds a correctly annotated
    ingress object.
  prefs: []
  type: TYPE_NORMAL
- en: As an exercise, you can deploy the 2048 game described in the last section of
    the user guide to validate that the ALB works as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying an application with resource limits to Kubernetes on AWS EKS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Kubernetes, we can set resource limits on an application in order to prevent
    it from consuming all the available CPU and memory resources in the cluster. This
    is desirable to protect the system from resource exhaustion, and to ensure that
    an application that has a memory leak or a bug that causes it to consume more
    CPU than expected does not bring down the entire cluster.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate setting resource limits, we are going to deploy the ShipIt Clicker
    Docker container and Helm charts we deployed to our local Kubernetes installation
    in the *Deploying a sample application* section earlier in this chapter to the
    EKS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate setting resource limits, we will now look at deploying the ShipIt
    Clicker application to Kubernetes, managed by the AWS EKS service, with CPU and
    memory limits enabled. We will also expose this application to the world using
    an Ingress Controller.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring resource limits to guard against memory leaks and runaway CPU usage
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are deploying to EKS, we want to be sure that our pod's containers
    are good citizens in the cluster. To do this, we will specify both resource requests
    and limits. Requests give Kubernetes guidance about how much of each resource
    it will initially allocate to the application, and will guide the orchestrator
    when it places the containers and pods on the nodes. Kubernetes will only schedule
    a pod on a node if it has adequate headroom to support a request. Limits give
    the orchestrator hard-maximum limits on how much CPU or memory to allocate. If
    a container exceeds its memory limit, its process will be killed with an **out-of-memory**
    (**OOM**) error.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to use the Helm templates at `chapter8/shipitclicker-eks/` in order
    to make the first set of changes versus the basic Helm template we installed on
    our local system.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `chapter8/shipitclicker-eks/values.yaml`, we are now specifying the CPU
    and memory requests and limits for the containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: These apply both to the Redis and the ShipIt Clicker containers.
  prefs: []
  type: TYPE_NORMAL
- en: Annotating ShipIt Clicker to use the ALB Ingress Controller
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some changes are required for the `chapter8/shipitclicker-eks/values.yaml`
    file to make sure that the Ingress Controller annotations are compatible with
    the EKS setup. We need to switch up the annotations so that they are targeted
    toward EKS. Also, we will remove the host restriction and make sure that the configuration
    for paths has a wildcard in it. Since we use a `ClusterIP` service point, we also
    need to use the `ip` target type for the ALB Ingress Controller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Without these annotations, the ALB Ingress Controller would have trouble connecting
    to the services.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying an EKS-ready ShipIt Clicker to EKS
  prefs: []
  type: TYPE_NORMAL
- en: 'SSH to the bastion host, clone the repository, and deploy the software with
    Helm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Check in the AWS EC2 console for evidence that an elastic load balancer is getting
    created. It may take a few minutes to become available. When it does, enter its
    DNS name in a browser and you should see the ShipIt Clicker game.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you don''t see it, troubleshoot by looking at the Ingress Controller logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have the ShipIt Clicker application deployed to EKS and exposed
    to the world with an ALB Ingress Controller, let's examine how we can segregate
    environments so that different Docker containers can run without interfering with
    each other.
  prefs: []
  type: TYPE_NORMAL
- en: Using AWS Elastic Container Registry with AWS EKS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using public images stored in Docker Hub is fine for some applications, but
    for more sensitive applications, you might want to store your Docker containers
    in a private Docker registry. AWS provides just such a registry: **Elastic Container
    Registry** (**ECR**). You can read more about the basics of ECR on the main product
    website at [https://aws.amazon.com/ecr/](https://aws.amazon.com/ecr/).'
  prefs: []
  type: TYPE_NORMAL
- en: In order to get a Kubernetes cluster to use images from a private repository,
    you must configure the cluster with the right credentials so that it can pull
    images from the repository. The process for most repositories is in the Kubernetes
    documentation at [https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/](https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/).
  prefs: []
  type: TYPE_NORMAL
- en: However, AWS ECR uses an enhanced security system that relies on AWS IAM to
    grant temporary access tokens that are used to authenticate with ECR. Kubernetes
    has built-in support for this authentication process, as described in the documentation
    on images regarding using a private registry ([https://kubernetes.io/docs/concepts/containers/images/#using-aws-ec2-container-registry](https://kubernetes.io/docs/concepts/containers/images/#using-aws-ec2-container-registry)).
  prefs: []
  type: TYPE_NORMAL
- en: 'When using ECR with Kubernetes, you use an ECR identifier in the specification
    for the images used in pod configurations or their Helm templates. Instead of
    using the default Docker Hub image specifications, you can specify images using
    the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ACCOUNT.dkr.ecr.REGION.amazonaws.com/imagename:tag`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The AWS documentation on EKS explains that the worker nodes that run the pods
    must have the correct IAM policies applied via IAM roles in order to get authentication
    tokens and retrieve the images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.aws.amazon.com/AmazonECR/latest/userguide/ECR_on_EKS.html](https://docs.aws.amazon.com/AmazonECR/latest/userguide/ECR_on_EKS.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, the AWS CloudFormation templates we used to set up the EKS cluster
    produce worker nodes that already have the correct permissions applied, as do
    all clusters set up using the `eksctl` tool, if you set up your cluster with that
    alternative path. The access control rules described in ECR on the preceding EKS
    web page will grant EKS nodes permission to read any images stored in any ECR
    repository on the account.
  prefs: []
  type: TYPE_NORMAL
- en: So, to use ECR with EKS, all we should have to do is make sure our containers
    are pushed to an ECR repository in the same account with the EKS cluster, and
    that we use the ECR-style repository URIs as the identifiers for the containers
    that run in our Kubernetes pods.
  prefs: []
  type: TYPE_NORMAL
- en: Next up, let's create an ECR repository so that we can prepare for integrating
    ECR and EKS.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an ECR repository
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a web browser, log in to the AWS console. Make sure you switch to the `us-east-2`
    region (the same region where your EKS cluster lives), and then click on the **Services**
    link and choose **Elastic Container Registry**. If you don't have any registries
    created yet, click on the **Get Started** button. The AWS console will prompt
    you for a namespace and repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, visit the following URL to start the creation process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://console.aws.amazon.com/ecr/create-repository?region=us-east-2](https://console.aws.amazon.com/ecr/create-repository?region=us-east-2)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Either way, you will see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.12 – The ECR Create repository form'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B11641_08_012.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.12 – The ECR Create repository form
  prefs: []
  type: TYPE_NORMAL
- en: 'Leave the other settings at their defaults. After you create the repository,
    note the URI for your repository; you will need it in order to push containers
    to the registry. You will see the URI on a screen that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13 – The ECR Repositories page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B11641_08_013.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.13 – The ECR Repositories page
  prefs: []
  type: TYPE_NORMAL
- en: Then, click on the **View push commands** button. This will give you detailed
    instructions on how to use the AWS CLI to get temporary credentials that you can
    use to accomplish a Docker push to the ECR repository.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise – pushing ShipIt Clicker to the ECR repository
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Follow the instructions shown after clicking on the `REPO` value with the hostname
    of your ECR registry from the URI generated in the **Create** form):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'If this succeeds, you will see an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.14 – A Docker push to ECR'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B11641_08_014.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.14 – A Docker push to ECR
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to use ECR to store Docker images that we
    build through Jenkins and deploy using Spinnaker and Helm.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen how we might store Docker container images in an ECR repository,
    we will examine how we can segregate environments using labels and namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: Using labels and namespaces to segregate environments
  prefs: []
  type: TYPE_NORMAL
- en: We learned earlier in this chapter what a namespace is. Now, we will explore
    how we can use both namespaces and labels to create separate environments in both
    a local environment and in an EKS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Local example – labeled environments in the default namespace
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's imagine you are developing the ShipIt Clicker application and want to
    keep a working stable environment deployed so that you can demonstrate it to others
    and compare new behaviors in code that you are changing to stable behavior. While
    you could use namespaces to segregate the application, it would be simpler to
    just deploy the Helm Chart again with deployments that have different labels.
    You can use multiple deployments with distinct labels, along with some template
    overrides, to accomplish this with Helm, without having to deal with the complexity
    of multiple namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, we need to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Define a hostname to use to reach the service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure the Ingress Controller for ShipIt Clicker to use that hostname.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure and bump the chart version in `chapter8/shipitclicker/Chart.yaml`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the Helm Chart with a different name from the one already deployed, for
    example `shipit-stable`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test that we can reach the alternative environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's go through each of these steps in order to set up this stable environment
    using namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: Adding multiple hostnames to the local environment
  prefs: []
  type: TYPE_NORMAL
- en: The time-tested way to add alternative names for your local environment is to
    edit your operating system hosts file – this is `/etc/hosts` on UNIX-inspired
    systems, such as Linux and macOS, or `C:\Windows\System32\Drivers\etc\hosts` on
    Windows systems. You must do so as a user with administrative privileges, though.
    You might add an entry such as `127.0.0.1 shipit-stable.internal.` to your `hosts`
    file, following some of the guidance at [https://tools.ietf.org/html/rfc6762#appendix-G](https://tools.ietf.org/html/rfc6762#appendix-G)
    to pick a TLD that is unlikely to cause operational problems.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is an easier way to do this now. You can use a hostname of the
    `name.A.B.C.D.nip.io` form and it will map to whatever IP address you give, thanks
    to the free [https://nip.io/](https://nip.io/) service. This enables the easy
    creation of `localhost` aliases as we can use `shipit-stable.127.0.0.1.nip.io`
    and similar names for local development.
  prefs: []
  type: TYPE_NORMAL
- en: Temporarily configuring the Helm Chart for the shipit-stable environment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Edit the `chapter8/shipitclicker/values.yaml` file to switch up the host so
    that it matches `shipit-stable.127.0.0.1.nip.io`, and bump the chart version.
    Then, use Helm to deploy the app using the command `helm install shipit-stable
    shipitclicker/`. You should then be able to see the application in your web browser
    by going to http://shipit-stable.127.0.0.1.[nip.io/](http://nip.io/).
  prefs: []
  type: TYPE_NORMAL
- en: Staged environments – Dev, QA, staging, and production
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the EKS environment, you could also get a pretty good separation of environments
    just by deploying labeled stacks. You could label the stacks with a prefix or
    suffix name that indicates what environment they are. With ALB support, each separate
    service that is exposed to the world will get its own distinct load balancer,
    whether they are in different namespaces or not.
  prefs: []
  type: TYPE_NORMAL
- en: But there are some cases where you would want to use namespaces. For example,
    if you host both production and non-production resources in the cluster, you could
    make it so that the namespaces for the non-production resources use quotes. Refer
    to [https://kubernetes.io/docs/concepts/policy/resource-quotas/](https://kubernetes.io/docs/concepts/policy/resource-quotas/)
    for more information on quotas.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs: []
  type: TYPE_NORMAL
- en: Create a `qa` namespace with `kubectl` and use Helm to deploy ShipIt Clicker
    to that namespace. Then, set a memory quota on that namespace so that it never
    uses more than 1 GB of RAM.
  prefs: []
  type: TYPE_NORMAL
- en: For even more advanced practices regarding namespaces, you should consult the
    best practices documentation at [https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-organizing-with-namespaces](https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-organizing-with-namespaces).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have set up a separate environment that is segregated using namespaces,
    we have more flexibility in how we might deploy and manage our applications. Next,
    let's review what we have learned in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned all about Kubernetes and options for hosting it
    in the cloud. We walked through some of the cloud-hosting platforms on the market
    and then completed a quick overview of the key components of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Following this, we developed a process for deploying our Docker containers to
    AWS EKS, using AWS ECR as a Docker container registry. Here, you also got the
    chance to experiment with Amazon's CloudFormation technology, a platform for developing
    infrastructure as code.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we studied Helm and Helm Charts and built on the ShipIt Clicker application.
    This was stood up in AWS with resource limits.
  prefs: []
  type: TYPE_NORMAL
- en: You should now feel comfortable with repeating this process for another project
    if you wish!
  prefs: []
  type: TYPE_NORMAL
- en: Now that our basic Kubernetes setup is ready to go, what other concerns do we
    need to address before we can use it for a scalable production project? We have
    seen how we can use Jenkins for continuous deployment, but it would be tedious
    to write all the scripts required to get the basic Jenkins system to manage a
    complex Kubernetes cluster and deploy applications to it reliably.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter has presented a simplified set of Helm Charts that generate Kubernetes
    configurations that result in a running application, but there are some refinements
    we must make in order to make the application production-ready, just as we did
    in previous chapters with Docker Compose.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to introduce Spinnaker as a cloud-native CI/CD
    platform that will help us facilitate CI/CD for a Kubernetes for this exact task.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs: []
  type: TYPE_NORMAL
- en: 'These articles may help you get a better handle on some of the essential Kubernetes
    concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A gentle illustrated introduction to Kubernetes concepts through this tongue-in-cheek
    guide: [https://www.cncf.io/the-childrens-illustrated-guide-to-kubernetes/](https://www.cncf.io/the-childrens-illustrated-guide-to-kubernetes/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Another Cloud Native Computing Foundation illustrated guide to Kubernetes concepts
    featuring Phippy: [https://www.cncf.io/phippy-goes-to-the-zoo-book/](https://www.cncf.io/phippy-goes-to-the-zoo-book/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Why is Kubernetes getting so popular? See this blog article: [https://stackoverflow.blog/2020/05/29/why-kubernetes-getting-so-popular/](https://stackoverflow.blog/2020/05/29/why-kubernetes-getting-so-popular/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Many applications require you to use private Docker image registries, whether
    that is Docker Hub, AWS ECR, or something else. Read this to find out how to integrate
    registry secrets into your Kubernetes configuration files: [https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/](https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While this is targeted at customers of Digital Ocean using their Kubernetes
    service, it does an excellent job of explaining NGINX Ingress Controllers: [https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nginx-ingress-on-digitalocean-kubernetes-using-helm](https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nginx-ingress-on-digitalocean-kubernetes-using-helm)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The user guide for EKS. This is chock full of super-detailed information about
    running EKS: [https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html](https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deploy the Kubernetes dashboard. This is optional but will give you a nice
    web user interface to see more information about the cluster: [https://docs.aws.amazon.com/eks/latest/userguide/dashboard-tutorial.html](https://docs.aws.amazon.com/eks/latest/userguide/dashboard-tutorial.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An example of an advanced configuration using Kubernetes namespaces might involve
    using the Kubernetes **role-based access control** (**RBAC**) system to further
    restrict how applications in different namespaces interact: [https://kubernetes.io/docs/reference/access-authn-authz/rbac/](https://kubernetes.io/docs/reference/access-authn-authz/rbac/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Learn more about the options for EKS installations, including Terraform, using
    a hybrid strategy that mixes NGINX and ALB Ingress Controller, and more: [https://medium.com/](https://medium.com/)@dmaas/setting-up-amazon-eks-what-you-must-know-9b9c39627fbc'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
