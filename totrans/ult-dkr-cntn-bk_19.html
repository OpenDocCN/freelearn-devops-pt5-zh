<html><head></head><body>
<div><div><h1 class="chapter-number" id="_idParaDest-411"><a id="_idTextAnchor412"/>19</h1>
<h1 id="_idParaDest-412"><a id="_idTextAnchor413"/>Monitoring and Troubleshooting an Application Running in Production</h1>
<p>In the previous chapter, we got an overview of the three most popular ways of running containerized applications in the cloud – AWS EKS, Azure AKS, and Google GKE. We then explored each of the hosted solutions and discussed their pros and cons.</p>
<p>This chapter looks at different techniques used to instrument and monitor an individual service or a whole distributed application running on a Kubernetes cluster. You will be introduced to the concept of alerting based on key metrics. The chapter also shows how one can troubleshoot an application service that is running in production without altering the cluster or the cluster nodes on which the service is running.</p>
<p>Here is a list of topics we are going to discuss in this chapter:</p>
<ul>
<li>Monitoring an individual service</li>
<li>Using OpenTracing for distributed tracing</li>
<li>Leveraging Prometheus and Grafana to monitor a distributed application</li>
<li>Defining alerts based on key metrics</li>
<li>Troubleshooting a service running in production</li>
</ul>
<p>After reading this chapter and following the exercises carefully, you will have acquired the following skills:</p>
<ul>
<li>Instrumenting your services with OpenTracing</li>
<li>Configuring application-level monitoring for a service</li>
<li>Using Prometheus to collect and centrally aggregate relevant application metrics</li>
<li>Using Grafana to monitor the application</li>
<li>Defining and wiring alerts triggered based on rules defined for key metrics</li>
<li>Troubleshooting a service running in production using a special tools container</li>
</ul>
<p>Without further ado, let’s dive into the chapter.</p>
<h1 id="_idParaDest-413"><a id="_idTextAnchor414"/>Technical requirements</h1>
<p>We are going to use Docker Desktop and its single-node Kubernetes cluster in this chapter. Make sure you have Docker Desktop installed and properly configured as described in <a href="B19199_02.xhtml#_idTextAnchor027"><em class="italic">Chapter 2</em></a>, <em class="italic">Setting Up a </em><em class="italic">Working Environment</em>.</p>
<p>We’ll also use the files in the <code>~/The-Ultimate-Docker-Container-Book/sample-solutions/ch19</code> folder of our labs repository from GitHub, at <a href="https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch19">https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/tree/main/sample-solutions/ch19</a>.</p>
<h1 id="_idParaDest-414"><a id="_idTextAnchor415"/>Monitoring an individual service</h1>
<p>Effective monitoring of distributed, mission-critical applications is crucial, akin to the instrumentation in a <a id="_idIndexMarker1616"/>nuclear power plant or airplane cockpit. Our application services and infrastructure need “sensors” that collect important data, functioning similarly to the sensors monitoring the temperature or flow rate in complex systems.</p>
<p>These “sensors” collect values – or metrics – to provide insight into our application’s performance. Metrics can be both functional, which provide business-relevant data, and non-functional, which give <a id="_idIndexMarker1617"/>insight into system performance irrespective of the application’s business type.</p>
<p>Functional metrics might include the rate of checkouts per minute on an e-commerce platform or the five <a id="_idIndexMarker1618"/>most streamed songs in the last 24 hours for a music streaming service. Non-functional metrics could show the average latency of a web request, the number of 4xx status codes returned, or resource usage such as RAM or CPU cycles.</p>
<p>In a distributed system, a centralized service is needed to aggregate these metrics. This is similar to how an airplane cockpit consolidates all necessary readings, eliminating the need for pilots to inspect each part of the plane during a flight.</p>
<p>Prometheus, an open source <a id="_idIndexMarker1619"/>project donated to the <strong class="bold">Cloud Native Computing Foundation</strong> (<strong class="bold">CNCF</strong>), is a popular service for metrics exposure, collection, and <a id="_idIndexMarker1620"/>storage. It integrates well with Docker <a id="_idIndexMarker1621"/>containers, Kubernetes, and many other systems. We will use Prometheus to demonstrate metric instrumentation for a service in this chapter.</p>
<h1 id="_idParaDest-415"><a id="_idTextAnchor416"/>Using OpenTracing for distributed tracing</h1>
<p>OpenTracing is an open <a id="_idIndexMarker1622"/>standard for distributed tracing that provides a <a id="_idIndexMarker1623"/>vendor-neutral API and instrumentation for <a id="_idIndexMarker1624"/>distributed systems. In OpenTracing, a trace tells the story of a transaction or workflow as it propagates through a distributed system. The concept of the trace borrows a tool from the scientific community called a <strong class="bold">directed acyclic graph</strong> (<strong class="bold">DAG</strong>), which stages the parts of a process from <a id="_idIndexMarker1625"/>a clear start to a clear end.</p>
<p><strong class="bold">Distributed tracing</strong> is a way to track a single request and log a single request as it crosses through all of the<a id="_idIndexMarker1626"/> services in our infrastructure. It can help us understand how long each service takes to process the request and identify bottlenecks in our system. It can also help us identify which service is causing an issue when something goes wrong.</p>
<p>Using OpenTracing for distributed tracing can help us gain visibility into our distributed system and understand how requests are flowing through it. It can also help us identify performance issues and troubleshoot problems more quickly.</p>
<h2 id="_idParaDest-416"><a id="_idTextAnchor417"/>A Java example</h2>
<p>Let’s create the<a id="_idIndexMarker1627"/> simplest possible Java example with a Spring Boot <a id="_idIndexMarker1628"/>example that uses OpenTracing:</p>
<ol>
<li>Start by navigating to your source code folder:<pre class="source-code">
$ cd ~/The-Ultimate-Docker-Container-Book</pre></li> <li>Then create a subfolder, <code>ch19</code>, and navigate to it:<pre class="source-code">
$ mkdir ch19 &amp;&amp; cd ch19</pre></li> <li>Go to <a href="https://start.spring.io/">https://start.spring.io/</a> to create a <code>SpringBoot</code> application.</li>
<li>Use <code>Gradle – Groovy</code> as the project and <code>Java</code> as the language.</li>
<li>Leave all<a id="_idIndexMarker1629"/> the other defaults.</li>
<li>Create the <a id="_idIndexMarker1630"/>application and download the ZIP file.</li>
<li>Extract it into the <code>ch19/java</code> subfolder.</li>
<li>Modify your <code>build.gradle</code> file such that it looks like this one:</li>
</ol>
<div><div><img alt="Figure 19.1 – build.gradle file when using OpenTracing" height="779" src="img/Figure_19.01_B19199.jpg" width="980"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.1 – build.gradle file when using OpenTracing</p>
<ol>
<li value="9">Modify your <code>DemoApplication.java</code> file such that it looks like this:</li>
</ol>
<div><div><img alt="Figure 19.2 – DemoApplication.java file demoing OpenTracing" height="928" src="img/Figure_19.02_B19199.jpg" width="880"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.2 – DemoApplication.java file demoing OpenTracing</p>
<ol>
<li value="10">Run the <a id="_idIndexMarker1631"/>application by clicking on <a id="_idIndexMarker1632"/>the <code>main</code> method of the <code>DemoApplication</code> class.</li>
<li>In a terminal window, use <code>curl</code> to hit the http://localhost:8080 endpoint. The response should be <code>Hello, World!</code>.</li>
<li>Observe the output in the Terminal window of VS Code. You should see something like this:</li>
</ol>
<div><div><img alt="Figure 19.3 – OpenTracing used in a simple Java and Spring Boot application" height="124" src="img/Figure_19.03_B19199.jpg" width="1101"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.3 – OpenTracing used in a simple Java and Spring Boot application</p>
<p>This shows <a id="_idIndexMarker1633"/>that a span has been created <a id="_idIndexMarker1634"/>and reported.</p>
<p>Next, let’s see how we can instrument a Node.js service.</p>
<h2 id="_idParaDest-417"><a id="_idTextAnchor418"/>Instrumenting a Node.js-based service</h2>
<p>In this section, we <a id="_idIndexMarker1635"/>will learn how to instrument a microservice authored in Node.js by following these steps:</p>
<ol>
<li>Navigate to your source code folder:<pre class="source-code">
$ cd ~/The-Ultimate-Docker-Container-Book/ch19</pre></li> <li>Create a new folder called <code>node</code> and navigate to it:<pre class="source-code">
$ mkdir node &amp;&amp; cd node</pre></li> <li>Run <code>npm init</code> in this folder, and accept all defaults except the entry point, which you change from the <code>index.js</code> default to <code>server.js</code>.</li>
<li>We need to add <code>express</code> to our project with the following:<pre class="source-code">
$ npm install --save express</pre></li> </ol>
<p class="callout-heading">Note</p>
<p class="callout">As of npm 5.0.0, you no longer need to use this option. Now, npm saves all installed packages as dependencies by default.</p>
<ol>
<li value="5">Now we need to install the Prometheus adapter for Node Express with the following:<pre class="source-code">
$ npm install --save prom-client</pre></li> <li>Add a file called <code>server.js</code> to the folder with this content:<pre class="source-code">
const app = require("express")();app.get('/hello', (req, res) =&gt; {    const { name = 'World' } = req.query;    res.json({ message: `Hello, ${name}!` });});app.listen(port=3000, () =&gt; {    console.log('Example api is listening on http://localhost:3000');});</pre></li> </ol>
<p>This is a very <a id="_idIndexMarker1636"/>simple Node Express app with a single endpoint – <code>/</code><code>hello</code>.</p>
<ol>
<li value="7">To the preceding code, after line 1, add the following snippet to initialize the Prometheus client:<pre class="source-code">
const client = require("prom-client");const register = client.register;const collectDefaultMetrics =    client.collectDefaultMetrics;collectDefaultMetrics({ register });</pre></li> <li>Next, add an endpoint to expose the metrics. You can add it right after the definition of the <code>/</code><code>hello</code> endpoint:<pre class="source-code">
app.get('/metrics', (req, res) =&gt; {    res.set('Content-Type', register.contentType);    res.end(register.metrics());});</pre></li> <li>Now let’s run this sample microservice:<pre class="source-code">
$ npm start</pre></li> </ol>
<p>You should see an output similar to this:</p>
<pre class="source-code">
&gt; node@1.0.0 start&gt; node server.js
Example api is listening on http://localhost:3000</pre>
<p>We can see <a id="_idIndexMarker1637"/>in the preceding output that the service is listening on port <code>3000</code>.</p>
<ol>
<li value="10">Let’s now try to access the metrics at the <code>/metrics</code> endpoint, as we defined in the code. For this, open a new terminal window and use this command:<pre class="source-code">
$ curl localhost:3000/metrics</pre></li> </ol>
<p>You should see output similar to this:</p>
<pre class="source-code">
# HELP process_cpu_user_seconds_total Total user CPU time spent in seconds.# TYPE process_cpu_user_seconds_total counter
process_cpu_user_seconds_total 0.081801
# HELP process_cpu_system_seconds_total Total system CPU time spent in seconds.
# TYPE process_cpu_system_seconds_total counter
process_cpu_system_seconds_total 0.02082
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 0.102621
…</pre>
<p>Note that the preceding output has been shortened for readability. What we get as output is a pretty long list of metrics, ready for consumption by a Prometheus server.</p>
<p>This was pretty easy, wasn’t it? By adding a Node package and adding a few trivial lines of code to our <a id="_idIndexMarker1638"/>application startup, we have gained access to a plethora of system metrics.</p>
<p>Now let’s define our own custom metric. We will make it a <code>counter</code> object:</p>
<ol>
<li>Add the following code snippet to <code>server.js</code> to define a custom counter called <code>my_hello_counter</code>:<pre class="source-code">
const helloCounter = new client.Counter({    name: 'my_hello_counter',    help: 'Counts the number of hello requests',});</pre></li> <li>To our existing <code>/hello</code> endpoint, add code to increase the counter. The modified endpoint should look like this:<pre class="source-code">
app.get('/hello', (req, res) =&gt; {    helloCounter.inc();    const name = req.query.name || 'World';    res.json({ message: `Hello, ${name}!` });});</pre></li> <li>Rerun the application with <code>npm start</code>.</li>
<li>To test the new counter, let’s access our <code>/hello</code> endpoint twice:<pre class="source-code">
$ curl localhost:3000/hello?name=Sue$ curl localhost:3000/hello?name=Marc</pre></li> <li>We will get this output when accessing the <code>/</code><code>metrics</code> endpoint:<pre class="source-code">
$ curl localhost:3000/metrics</pre></li> </ol>
<p>Analyze the output generated by the preceding command and look for something like this toward the end of the output:</p>
<pre class="source-code">
…# HELP my_hello_counter Counts the number of hello requests
# TYPE my_hello_counter counter
my_hello_counter 2
...</pre>
<p>The counter we <a id="_idIndexMarker1639"/>defined in the code clearly works and is output with the <code>HELP</code> text we added.</p>
<p>Now that we know how to instrument a Node Express application, let’s do the same for a .NET-based microservice.</p>
<h2 id="_idParaDest-418"><a id="_idTextAnchor419"/>Instrumenting a .NET service</h2>
<p>Let’s start by <a id="_idIndexMarker1640"/>creating a simple .NET microservice based on the Web API template:</p>
<ol>
<li>Navigate to your source code folder:<pre class="source-code">
$ cd ~/The-Ultimate-Docker-Container-Book/ch19</pre></li> <li>Create a new <code>dotnet</code> folder, and navigate to it:<pre class="source-code">
$ mkdir dotnet &amp;&amp; cd dotnet</pre></li> <li>Use the <code>dotnet</code> tool to scaffold a new microservice called <code>sample-api</code>:<pre class="source-code">
$ dotnet new webapi --output sample-api</pre></li> <li>We will use the Prometheus adapter for .NET, which is available to us as a NuGet package called <code>prometheus-net.AspNetCore</code>. Add this package to the <code>sample-api</code> project with the following command:<pre class="source-code">
$ dotnet add sample-api package prometheus-net.AspNetCore</pre></li> <li>Open the project in your favorite code editor; for example, when using VS Code, execute the following:<pre class="source-code">
$ code .</pre></li> <li>Locate the <code>Program.cs</code> file, and open it. At the beginning of the file, add a <code>using</code> statement:<pre class="source-code">
using Prometheus;</pre></li> <li>Then, in the <a id="_idIndexMarker1641"/>code of the file, right after the <code>app.MapControllers()</code> command, add the <code>app.MapMetrics()</code> command. Your code should look as follows:<pre class="source-code">
…app.UseAuthorization();app.MapControllers();app.MapMetrics();app.Run();</pre></li> </ol>
<p>Note that the preceding is valid for version 7.x of .NET or newer. If you’re on an earlier version, the configuration might look slightly different. Consult the repo for more details, at <a href="https://github.com/prometheus-net/prometheus-net">https://github.com/prometheus-net/prometheus-net</a>.</p>
<ol>
<li value="8">With this, the Prometheus component will start publishing the request metrics of ASP.NET. Let’s try it. First, start the application with the following:<pre class="source-code">
$ dotnet run --project sample-api</pre></li> </ol>
<p>The output of the preceding command should look like this:</p>
<pre class="source-code">
Building...info: Microsoft.Hosting.Lifetime[14]
      Now listening on:
info: Microsoft.Hosting.Lifetime[0]
      Application started. Press Ctrl+C to shut down.
info: Microsoft.Hosting.Lifetime[0]
      Hosting environment: Development
info: Microsoft.Hosting.Lifetime[0]
      Content root path: /Users/.../ch19/dotnet/sample-api
...</pre>
<p>The preceding output tells us that the microservice is listening at http://localhost:5204.</p>
<ol>
<li value="9">We can now use <code>curl</code> to call the metrics endpoint of the service:<pre class="source-code">
$ curl http://localhost:5204/metrics</pre></li> </ol>
<p>The (shortened) output <a id="_idIndexMarker1642"/>of the preceding command looks similar to this:</p>
<pre class="source-code">
# HELP process_private_memory_bytes Process private memory size# TYPE process_private_memory_bytes gauge
process_private_memory_bytes 55619584
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 2221930053632
# HELP process_working_set_bytes Process working set
# TYPE process_working_set_bytes gauge
process_working_set_bytes 105537536
…
prometheus_net_metric_families{metric_type="histogram"} 0
prometheus_net_metric_families{metric_type="summary"} 0
prometheus_net_metric_families{metric_type="counter"} 3
prometheus_net_metric_families{metric_type="gauge"} 12</pre>
<p>What we get is a list of system metrics for our microservice. That was easy: we only needed to add a NuGet package and a single line of code to get our service instrumented!</p>
<p>What if we want <a id="_idIndexMarker1643"/>to add our own (functional) metrics? This is equally straightforward. Assume we want to measure the number of concurrent accesses to the <code>/weatherforecast</code> endpoint that .NET scaffolding created for us. To do this, we define a gauge and use it to wrap the logic in the appropriate endpoint with this gauge.</p>
<p class="callout-heading">Metric types</p>
<p class="callout">Prometheus supports four types of metrics:</p>
<ul>
<li class="callout"><strong class="bold">Counter</strong>: A cumulative metric that represents a single monotonically increasing counter whose <a id="_idIndexMarker1644"/>value can only increase or be reset to zero on restart.</li>
<li class="callout"><strong class="bold">Gauge</strong>: A metric that <a id="_idIndexMarker1645"/>represents a single numerical value that can arbitrarily go up and down. Gauges are typically used for measured values such as temperatures or current memory usage.</li>
<li class="callout"><strong class="bold">Histogram</strong>: A metric that <a id="_idIndexMarker1646"/>samples observations (usually things such as request durations or response sizes) and counts them in configurable buckets. It also provides a sum of all observed values.</li>
<li class="callout"><strong class="bold">Summary</strong>: Similar to a histogram, a summary samples observations. While it also provides a total count of observations and a sum of all observed values, it calculates configurable quantiles over a sliding time window.</li>
</ul>
<p>We can define our own gauge by following these steps:</p>
<ol>
<li>Locate the <code>WeatherForecastController.cs</code> class in the <code>Controllers</code> folder.</li>
<li>Add <code>using Prometheus;</code> to the top of the file.</li>
<li>Define a private instance <code>callsInProgress</code> variable of the <code>Gauge</code> type in the <code>WeatherForecastController</code> class:<pre class="source-code">
private static readonly Gauge callsInProgress = Metrics    .CreateGauge("myapp_calls_in_progress",    "Number of weather forecast operations ongoing.");</pre></li> <li>Wrap the logic <a id="_idIndexMarker1647"/>of the <code>Get</code> method with a <code>using</code> statement:<pre class="source-code">
[HttpGet]public IEnumerable&lt;WeatherForecast&gt; Get(){    using(callsInProgress.TrackInProgress())    {        // code of the Get method    }}</pre></li> <li>Restart the microservice.</li>
<li>Call the <code>/weatherforecast</code> endpoint a couple of times using <code>curl</code>:<pre class="source-code">
$ curl http://localhost:5204/weatherforecast</pre></li> <li>Use <code>curl</code> to get the metrics, as done earlier in this section:<pre class="source-code">
$ curl http://localhost:5204/metrics</pre></li> </ol>
<p>You should see an output similar to the following one (shortened):</p>
<pre class="source-code">
...# HELP myapp_calls_in_progress Number of weather forecast operations ongoing.
# TYPE myapp_calls_in_progress gauge
myapp_weather_forecasts_in_progress 0
...</pre>
<p>You will notice that there is now a new metric called <code>myapp_weather_forecasts_in_progress</code> available in the list. Its value will be zero since, currently, you are not running any requests against the tracked endpoint, and a gauge-type metric only measures the number of ongoing requests.</p>
<p>Congratulations, you have just defined your first functional metric! This is only a start; many more sophisticated possibilities are readily available to you.</p>
<p>Node.js- or .NET-based application services are by no means special. It is just as straightforward and easy to <a id="_idIndexMarker1648"/>instrument services written in other languages, such as Kotlin, Python, or Go.</p>
<p>Having learned how to instrument an application service so that it exposes important metrics, let’s now have a look at how we can use Prometheus to collect and aggregate those values to allow us to monitor a distributed application.</p>
<h1 id="_idParaDest-419"><a id="_idTextAnchor420"/>Leveraging Prometheus and Grafana to monitor a distributed application</h1>
<p>Now that we have <a id="_idIndexMarker1649"/>learned how to <a id="_idIndexMarker1650"/>instrument an application service to expose Prometheus metrics, it’s time to show how we can collect the metrics and forward them to a Prometheus server where all metrics will be aggregated and stored. We can then either use the (simple) web UI of Prometheus or a more sophisticated solution such as Grafana to display important metrics on a dashboard.</p>
<p>Unlike most other tools that are used to collect metrics from application services and infrastructure <a id="_idIndexMarker1651"/>components, the <a id="_idIndexMarker1652"/>Prometheus server takes the load of work and periodically scrapes all the defined targets. This way, applications and services don’t need to worry about forwarding data. You can also describe this as pulling metrics, versus pushing them.</p>
<p>This makes Prometheus servers an excellent fit for our case. We will now discuss how to deploy Prometheus to Kubernetes, followed by our two sample application services. Finally, we will deploy Grafana to the cluster, and use it to display our custom metrics on a dashboard.</p>
<h2 id="_idParaDest-420"><a id="_idTextAnchor421"/>Architecture</h2>
<p>Let’s have a quick overview of the architecture of the planned system. As mentioned before, we have <a id="_idIndexMarker1653"/>our microservices, the Prometheus server, and Grafana. Furthermore, everything will be deployed to Kubernetes. The following diagram shows the relationships:</p>
<div><div><img alt="Figure 19.4 – High-level overview of an application using Prometheus and Grafana for monitoring" height="400" src="img/Figure_19.04_B19199.jpg" width="656"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.4 – High-level overview of an application using Prometheus and Grafana for monitoring</p>
<p>At the top center of the diagram, we have Prometheus, which periodically scrapes metrics from Kubernetes, shown on the left. It also periodically scrapes metrics from the services, in our case <a id="_idIndexMarker1654"/>from the Node.js and .NET sample services we created and instrumented in the previous section. Finally, on the right-hand side of the diagram, we have Grafana, which pulls data periodically from Prometheus to then display it on graphical dashboards.</p>
<h2 id="_idParaDest-421"><a id="_idTextAnchor422"/>Deploying Prometheus to Kubernetes</h2>
<p>As indicated, we start by deploying Prometheus to Kubernetes. Let’s first define the Kubernetes YAML <a id="_idIndexMarker1655"/>file that we can use to do so. First, we <a id="_idIndexMarker1656"/>need to define a Kubernetes Deployment that will create a ReplicaSet of Prometheus server instances, and then we will define a Kubernetes service to expose Prometheus to us, so that we can access it from within a browser tab, or so that Grafana can access it. Let’s do it:</p>
<ol>
<li>Navigate to the source folder:<pre class="source-code">
$ cd ~/The-Ultimate-Docker-Container-Book/ch19</pre></li> <li>Create a <code>kube</code> folder, and navigate to it:<pre class="source-code">
$ mkdir -p ch19/kube &amp;&amp; cd ch19/kube</pre></li> <li>Add a file called <code>prometheus.yaml</code> to this folder.</li>
<li>Add the following code snippet to this file; it defines a Deployment for Prometheus:</li>
</ol>
<div><div><img alt="Figure 19.5 – Deployment for Prometheus" height="969" src="img/Figure_19.05_B19199.jpg" width="675"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.5 – Deployment for Prometheus</p>
<p>We are <a id="_idIndexMarker1657"/>defining a ReplicaSet with two instances <a id="_idIndexMarker1658"/>of Prometheus. Each instance is assigned two labels, <code>app: prometheus</code> and <code>purpose: monitoring-demo</code>, for identification purposes. The interesting part is in the <code>volumeMounts</code> section of the container spec. There, we mount a Kubernetes <code>ConfigMap</code> object called <code>prometheus-cm</code>, containing the Prometheus configuration, in the container at the location where Prometheus expects its configuration file(s) to be. The volume of the <code>ConfigMap</code> type is defined in the last four lines of the preceding code snippet.</p>
<p>Note that we <a id="_idIndexMarker1659"/>will define the ConfigMap <a id="_idIndexMarker1660"/>later on.</p>
<ol>
<li value="5">Now let’s define the Kubernetes service for Prometheus. Append this snippet to the previous file:</li>
</ol>
<div><div><img alt="Figure 19.6 – Service for Prometheus" height="658" src="img/Figure_19.06_B19199.jpg" width="558"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.6 – Service for Prometheus</p>
<p>Please note the three dashes (<code>---</code>) at the beginning of the snippet are needed to separate individual object definitions in our YAML file.</p>
<p>We call our service <code>prometheus-svc</code> and make it <code>NodePort</code> (and not just a service of the <code>ClusterIP</code> type) to be able to access the Prometheus web UI from the host.</p>
<ol>
<li value="6">Now we can <a id="_idIndexMarker1661"/>define a simple configuration <a id="_idIndexMarker1662"/>file for Prometheus. This file basically instructs the Prometheus server which services to scrape metrics from and how often to do so. First, create a <code>ch19/kube/config</code> subfolder:<pre class="source-code">
$ mkdir config</pre></li> <li>Add a file called <code>prometheus.yml</code> to the <code>config</code> folder, and add the following content to it:</li>
</ol>
<div><div><img alt="Figure 19.7 – Prometheus configuration" height="665" src="img/Figure_19.07_B19199.jpg" width="683"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.7 – Prometheus configuration</p>
<p>In the preceding <a id="_idIndexMarker1663"/>file, we define three jobs <a id="_idIndexMarker1664"/>for Prometheus:</p>
<ul>
<li>The first one, called <code>prometheus</code>, scrapes metrics every five seconds from the Prometheus server itself. It finds those metrics at the <code>localhost:9090</code> target. Note that, by default, the metrics should be exposed on the <code>/</code><code>metrics</code> endpoint.</li>
<li>The second job, called <code>dotnet</code>, scrapes metrics from a service found at <code>dotnet-api-svc:80</code>, which will be our .NET Core service that we defined and instrumented previously.</li>
<li>Finally, the third job does the same for our Node service. Note that we have also added a group <code>'production'</code> label to this job. This allows further grouping of jobs or tasks.</li>
</ul>
<ol>
<li value="8">Now we can <a id="_idIndexMarker1665"/>define the <code>ConfigMap</code> object in <a id="_idIndexMarker1666"/>our Kubernetes cluster with the next command. From within the <code>ch19/kube</code> folder, execute the following:<pre class="source-code">
$ kubectl create configmap prometheus-cm \--from-file config/prometheus.yml</pre></li> </ol>
<p class="callout-heading">What is a Kubernetes ConfigMap?</p>
<p class="callout">A Kubernetes ConfigMap is an API object used to store non-confidential configuration data in key-value pairs. This can <a id="_idIndexMarker1667"/>include settings such as environment-specific URLs, command-line arguments, or any other parameters your applications need to run.</p>
<p class="callout">The main advantage of ConfigMaps is that they allow you to decouple configuration details from your application<a id="_idIndexMarker1668"/> code. This can help make your applications more portable and easier to scale.</p>
<p class="callout">ConfigMaps can be consumed by Pods in a variety of ways: as environment variables, as command-line arguments for a container, or as configuration files in a volume. This flexibility allows developers to choose the most suitable method for their use case.</p>
<ol>
<li value="9">We can now deploy Prometheus to our Kubernetes server with the following:<pre class="source-code">
$ kubectl apply -f prometheus.yaml</pre></li> </ol>
<p>This gives this response:</p>
<pre class="source-code">
deployment.apps/prometheus-deployment createdservice/prometheus-svc created</pre>
<ol>
<li value="10">Let’s double-check that the deployment succeeded:<pre class="source-code">
$ kubectl get all</pre></li> </ol>
<p>Here is the output of the preceding command:</p>
<div><div><img alt="Figure 19.8 – The Prometheus resources created on the Kubernetes cluster" height="323" src="img/Figure_19.08_B19199.jpg" width="991"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.8 – The Prometheus resources created on the Kubernetes cluster</p>
<p>Keep a close <a id="_idIndexMarker1669"/>eye on the list of Pods, and <a id="_idIndexMarker1670"/>make sure they are all up and running. Please also note the port mapping of the <code>prometheus-svc</code> object. In the author’s case, the <code>9090</code> port is mapped to the <code>31421</code> host port. In your case, the latter may be different, but it will also be in the 3xxxx range.</p>
<ol>
<li value="11">We can now access the web UI of Prometheus. Open a new browser tab, and navigate to <code>http://localhost:&lt;port&gt;/targets</code> where <code>&lt;port&gt;</code> in the author’s case is <code>31421</code>. You should see something like this:</li>
</ol>
<div><div><img alt="Figure 19.9 – Prometheus web UI showing the configured targets" height="636" src="img/Figure_19.09_B19199.jpg" width="1007"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.9 – Prometheus web UI showing the configured targets</p>
<p>In the previous screenshot, we can see that we defined three targets for Prometheus. Only <a id="_idIndexMarker1671"/>the third one in the list is up and <a id="_idIndexMarker1672"/>accessible by Prometheus. It is the endpoint we defined in the configuration file for the job that scrapes metrics from Prometheus itself. The other two services are not running at this time, and thus their state is down.</p>
<ol>
<li value="12">Now navigate to <strong class="bold">Graph</strong> by clicking on the respective link in the top menu of the UI.</li>
<li>Start typing in the search box and a list of known metrics will appear in a list. Inspect all the listed metrics that Prometheus found. In this case, it is only the list of metrics defined by the Prometheus server itself:</li>
</ol>
<div><div><img alt="Figure 19.10 – Prometheus web UI showing available metrics" height="557" src="img/Figure_19.10_B19199.jpg" width="1004"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.10 – Prometheus web UI showing available metrics</p>
<p>With that, we <a id="_idIndexMarker1673"/>are ready to deploy the .NET and Node <a id="_idIndexMarker1674"/>sample services we created earlier to Kubernetes.</p>
<h2 id="_idParaDest-422"><a id="_idTextAnchor423"/>Deploying our application services to Kubernetes</h2>
<p>Before we can use the sample services we created earlier and deploy them to Kubernetes, we <a id="_idIndexMarker1675"/>must create Docker images <a id="_idIndexMarker1676"/>for them and push them to a container registry. In our case, we will just push them to Docker Hub.</p>
<p>Let’s start with the .NET Core sample:</p>
<ol>
<li>Add a Dockerfile with the following content to the <code>ch19/dotnet/sample-api</code> project folder:<pre class="source-code">
FROM mcr.microsoft.com/dotnet/sdk:7.0 AS build-envWORKDIR /appCOPY *.csproj ./RUN dotnet restoreCOPY . ./RUN dotnet publish -c Release -o outFROM mcr.microsoft.com/dotnet/aspnet:7.0WORKDIR /appCOPY --from=build-env /app/out .ENTRYPOINT ["dotnet", "sample-api.dll"]</pre></li> <li>Create a Docker image by using this command from within the <code>dotnet/sample-api</code> project folder:<pre class="source-code">
$ docker image build -t fundamentalsofdocker/ch19-dotnet-api:2.0 .</pre></li> </ol>
<p>Note that you may want to replace <code>fundamentalsofdocker</code> with your own Docker Hub username in the preceding and subsequent commands.</p>
<ol>
<li value="3">Make <a id="_idIndexMarker1677"/>sure you are logged in to <a id="_idIndexMarker1678"/>Docker. If not, use this command to do so:<pre class="source-code">
$ docker login</pre></li> <li>Push the image to Docker Hub:<pre class="source-code">
$ docker image push fundamentalsofdocker/ch19-dotnet-api:2.0</pre></li> </ol>
<p>Now we do the same with the Node sample API:</p>
<ol>
<li>Add a Dockerfile with the following content to the <code>ch19/node</code> project folder:<pre class="source-code">
FROM node:ltsWORKDIR /appCOPY package.json ./RUN npm ci --only=productionCOPY . .EXPOSE 3000CMD ["node", "server.js"]</pre></li> <li>Create a Docker image by using this command from within the <code>ch19/node</code> project folder:<pre class="source-code">
$ docker image build -t fundamentalsofdocker/ch19-node-api:2.0 .</pre></li> </ol>
<p>Note once again that you may want to replace <code>fundamentalsofdocker</code> with your own Docker Hub username in the preceding and subsequent commands.</p>
<ol>
<li value="3">Push the image to Docker Hub:<pre class="source-code">
$ docker image push fundamentalsofdocker/ch19-node-api:2.0</pre></li> </ol>
<p>With this, we are <a id="_idIndexMarker1679"/>ready to define the necessary Kubernetes <a id="_idIndexMarker1680"/>objects for the deployment of the two services. The definition is somewhat lengthy and can be found in the <code>sample-solutions/ch19/kube/app-services.yaml</code> file in the repository.</p>
<p>Please open that file and analyze its content.</p>
<p>Let’s use this file to deploy the services:</p>
<ol>
<li>Make sure you are in the <code>kube</code> subfolder.</li>
<li>Use the following command to deploy the two services:<pre class="source-code">
$ kubectl apply -f app-services.yaml</pre></li> </ol>
<p>This is the output:</p>
<pre class="source-code">
deployment.apps/dotnet-api-deployment createdservice/dotnet-api-svc created
deployment.apps/node-api-deployment created
service/node-api-svc created</pre>
<ol>
<li value="3">Double-check that the services are up and running using the <code>kubectl get all</code> command. Make sure all the Pods of the Node and .NET sample API services are up and running.</li>
<li>List all <a id="_idIndexMarker1681"/>Kubernetes services to find out<a id="_idIndexMarker1682"/> the host ports for each application service:<pre class="source-code">
$ kubectl get services</pre></li> </ol>
<p>The output looks like this:</p>
<div><div><img alt="Figure 19.11 – Output of kubectl get services" height="155" src="img/Figure_19.11_B19199.jpg" width="923"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.11 – Output of kubectl get services</p>
<p>In the author’s case, the .NET API is mapped to port <code>30211</code>, and the Node API to port <code>30663</code>. Your ports may differ.</p>
<ol>
<li value="5">Use <code>curl</code> to access the <code>/metrics</code> endpoint for the .NET service:<pre class="source-code">
$ curl localhost:30211/metrics</pre></li> </ol>
<p>The output should look like this:</p>
<pre class="source-code">
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 0.4
# HELP prometheus_net_meteradapter_instruments_connected Number of instruments that are currently connected to the adapter.
# TYPE prometheus_net_meteradapter_instruments_connected gauge
prometheus_net_meteradapter_instruments_connected 0
# HELP prometheus_net_exemplars_recorded_total Number of exemplars that were accepted into in-memory storage in the prometheus-net SDK.
# TYPE prometheus_net_exemplars_recorded_total counter
prometheus_net_exemplars_recorded_total 0
...</pre>
<ol>
<li value="6">Now do the <a id="_idIndexMarker1683"/>same for the Node <a id="_idIndexMarker1684"/>service:<pre class="source-code">
$ curl localhost:30663/metrics</pre></li> </ol>
<p>This time, the output looks like this:</p>
<pre class="source-code">
# HELP process_cpu_user_seconds_total Total user CPU time spent in seconds.# TYPE process_cpu_user_seconds_total counter
process_cpu_user_seconds_total 1.0394399999999997 1578294999302
# HELP process_cpu_system_seconds_total Total system CPU time spent in seconds.
# TYPE process_cpu_system_seconds_total counter
process_cpu_system_seconds_total 0.3370890000000001 1578294999302
...</pre>
<ol>
<li value="7">Double-check the <code>/targets</code> endpoint in Prometheus to make sure the two microservices are now reachable:</li>
</ol>
<div><div><img alt="Figure 19.12 – Prometheus showing all targets are up and running" height="625" src="img/Figure_19.12_B19199.jpg" width="1004"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.12 – Prometheus showing all targets are up and running</p>
<ol>
<li value="8">To make <a id="_idIndexMarker1685"/>sure the custom metrics we <a id="_idIndexMarker1686"/>defined for our Node.js and .NET services are defined and exposed, we need to access each service at least once. Thus use <code>curl</code> to access the respective endpoints a few times:<pre class="source-code">
# access the /weatherforecast endpoint in the .NET service$ curl localhost:30211/weatherforecast# and access the /hello endpoint in the Node service$ curl localhost:30663/hello</pre></li> <li>We can also see the two metrics in the Prometheus Graph view:</li>
</ol>
<div><div><img alt="Figure 19.13 – Custom metrics in Prometheus" height="387" src="img/Figure_19.13_B19199.jpg" width="1003"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.13 – Custom metrics in Prometheus</p>
<p>The last step is <a id="_idIndexMarker1687"/>to deploy Grafana to Kubernetes so that <a id="_idIndexMarker1688"/>we have the ability to create sophisticated and graphically appealing dashboards displaying key metrics of our application services and/or infrastructure components.</p>
<h2 id="_idParaDest-423"><a id="_idTextAnchor424"/>Deploying Grafana to Kubernetes</h2>
<p>Now let’s also <a id="_idIndexMarker1689"/>deploy Grafana to our Kubernetes <a id="_idIndexMarker1690"/>cluster, so that we can manage this tool the same way as all the other components of our distributed application. As the tool that allows us to create dashboards for monitoring the application, Grafana can be considered mission-critical and thus warrants this treatment.</p>
<p>Deploying Grafana to the cluster is pretty straightforward. Let’s do it as follows:</p>
<ol>
<li>Add a new file called <code>grafana.yaml</code> to the <code>ch19/kube</code> folder.</li>
<li>To this file, add the definition for a Kubernetes Deployment for Grafana:</li>
</ol>
<div><div><img alt="Figure 19.14 – The content of the grafana.yaml file" height="907" src="img/Figure_19.14_B19199.jpg" width="616"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.14 – The content of the grafana.yaml file</p>
<p>If you prefer not to type the code yourself, then the file can be found in the <code>sample-solutions/ch19/kube</code> subfolder of your repo.</p>
<p>There are no <a id="_idIndexMarker1691"/>surprises in that definition. In this <a id="_idIndexMarker1692"/>example, we are running a single instance of Grafana, and it uses the <code>app</code> and <code>purpose</code> labels for identification, similar to what we used for Prometheus. No special volume mapping is needed this time since we are only working with defaults.</p>
<ol>
<li value="3">We also need to expose Grafana, and thus append the following snippet to the preceding file to define a service for Grafana:</li>
</ol>
<div><div><img alt="Figure 19.15 – The Kubernetes service for Grafana" height="664" src="img/Figure_19.15_B19199.jpg" width="564"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.15 – The Kubernetes service for Grafana</p>
<p>Once again, we <a id="_idIndexMarker1693"/>are using a service of the <code>NodePort</code> type <a id="_idIndexMarker1694"/>to be able to access the Grafana UI from our host.</p>
<ol>
<li value="4">We can now deploy Grafana with this command:<pre class="source-code">
$ kubectl apply -f grafana.yaml</pre></li> </ol>
<p>This results in this output:</p>
<pre class="source-code">
deployment.apps/grafana-deployment createdservice/grafana-svc created</pre>
<ol>
<li value="5">Let’s find out what the port number will be, over which we can access Grafana:<pre class="source-code">
$ kubectl get services/grafana-svc</pre></li> </ol>
<p>This gives <a id="_idIndexMarker1695"/>us this:</p>
<div><div><img alt="Figure 19.16 – Get details of the Grafana service" height="88" src="img/Figure_19.16_B19199.jpg" width="846"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.16 – Get details of the Grafana service</p>
<ol>
<li value="6">Open a new browser <a id="_idIndexMarker1696"/>tab and navigate to <code>http://localhost:&lt;port&gt;</code>, where <code>&lt;port&gt;</code> is the port you identified in the previous step, and in my case is <code>32736</code>. You should see something like this:</li>
</ol>
<div><div><img alt="Figure 19.17 – Login screen of Grafana" height="724" src="img/Figure_19.17_B19199.jpg" width="968"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.17 – Login screen of Grafana</p>
<ol>
<li value="7">Log in with the default username <code>admin</code>, and the password is also <code>admin</code>. When asked to change the password, click the <strong class="bold">Skip</strong> link for now. You will be redirected to the <strong class="bold">Home</strong> dashboard.</li>
<li>On the <strong class="bold">Home</strong> dashboard, <a id="_idIndexMarker1697"/>click on <strong class="bold">Create your first data source</strong>, and <a id="_idIndexMarker1698"/>select <strong class="bold">Prometheus</strong> from the list of data sources.</li>
<li>Add <code>http://prometheus-svc:9090</code> for the URL to Prometheus, and click the green <strong class="bold">Save &amp; </strong><strong class="bold">Test</strong> button.</li>
<li>In Grafana, navigate back to the <strong class="bold">Home</strong> dashboard, and then select the <strong class="bold">New </strong><strong class="bold">dashboard</strong> link.</li>
<li>Click <strong class="bold">Add query</strong>, and then from the <strong class="bold">Metrics</strong> drop-down menu, select the custom metric we defined in the .NET sample service:</li>
</ol>
<div><div><img alt="Figure 19.18 – Selecting the .NET custom metric in Grafana" height="447" src="img/Figure_19.18_B19199.jpg" width="1101"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.18 – Selecting the .NET custom metric in Grafana</p>
<ol>
<li value="12">Change the <a id="_idIndexMarker1699"/>value of <strong class="bold">Relative time</strong> from <strong class="bold">1h</strong> to <strong class="bold">5m</strong> (5 minutes).</li>
<li>Change the <a id="_idIndexMarker1700"/>dashboard refresh rate, found in the upper-right corner of the view, to <strong class="bold">5s</strong> (5 seconds).</li>
<li>Repeat the same for the custom metric defined in the Node sample service, so that you will have two panels on your new dashboard.</li>
<li>Modify the dashboard and its panels to your liking by consulting the documentation at <a href="https://grafana.com/docs/grafana/latest/guides/getting_started/">https://grafana.com/docs/grafana/latest/guides/getting_started/</a>.</li>
<li>Use <code>curl</code> to access the two endpoints of the sample services, and observe the dashboard. It may look like this:</li>
</ol>
<div><div><img alt="Figure 19.19 – Grafana dashboard with our two custom metrics" height="393" src="img/Figure_19.19_B19199.jpg" width="1187"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.19 – Grafana dashboard with our two custom metrics</p>
<p>To summarize, we can say that Prometheus is a good fit to monitor our microservices because we just <a id="_idIndexMarker1701"/>need to expose a metrics port, and thus don’t <a id="_idIndexMarker1702"/>need to add too much complexity or run additional services. Prometheus then is in charge of periodically scraping the configured targets, so that our services don’t need to worry about emitting them.</p>
<h1 id="_idParaDest-424"><a id="_idTextAnchor425"/>Defining alerts based on key metrics</h1>
<p>You will be let down if you believe that gathering logs and metrics and showing them in attractive <a id="_idIndexMarker1703"/>dashboards is sufficient. If we just use dashboards, some support staff will need to be stationed in front of a large number of monitors constantly, round the clock, every day of the year, just in case. To put it mildly, this job is tedious. What happens if the person nods off? We must adjust our approach. Let’s start by defining what metrics are.</p>
<h2 id="_idParaDest-425"><a id="_idTextAnchor426"/>Metrics</h2>
<p>Metrics are used as input values in the rules on which alerts are based. Critical metrics must be identified, and if they <a id="_idIndexMarker1704"/>surpass a predetermined value repeatedly or for an extended period of time, an alert is required. For illustration, consider CPU usage.</p>
<p>Defining alerts based on key metrics is an important part of monitoring and maintaining the health of our Docker and Kubernetes systems. Alerts allow us to define conditions based on metrics and to send notifications when those conditions are met, allowing us to quickly respond to potential issues.</p>
<p>In Kubernetes, we can use tools such as Prometheus to define alerting rules based on PromQL expressions. These rules allow us to specify conditions based on metrics collected from our cluster and send notifications to an external service when those conditions are met. For example, we could define an alert that triggers when CPU or memory utilization on cluster nodes exceeds a certain threshold.</p>
<p>In Docker, we can use tools such as cAdvisor or Docker stats to collect metrics from our containers, and then <a id="_idIndexMarker1705"/>use a monitoring and alerting tool to define alerts based on those metrics. For example, we could define an alert that triggers when the number of running containers exceeds a certain threshold.</p>
<p>When defining alerts, it’s important for us to follow best practices to ensure that our alerts are effective and actionable. Some best practices for alerting on Kubernetes include the following:</p>
<ul>
<li><strong class="bold">Alerting on symptoms</strong>: Alerts should be based on symptoms that have a noticeable <a id="_idIndexMarker1706"/>impact, rather than unexpected values in metrics</li>
<li><strong class="bold">Alerting on the host or Kubernetes node layer</strong>: Monitor the health of your hosts and nodes to ensure that your cluster is running smoothly</li>
<li><strong class="bold">Alerting on the Kubernetes infrastructure</strong>: Monitor the health of the Kubernetes control plane and other internal services</li>
<li><strong class="bold">Alerting on services running on Kubernetes</strong>: Monitor the health of your applications running on Kubernetes</li>
<li><strong class="bold">Alerting on application layer metrics</strong>: Monitor application-specific metrics to ensure that your applications are running smoothly</li>
</ul>
<p>Now let’s talk about alerting when an exceptional situation occurs.</p>
<h2 id="_idParaDest-426"><a id="_idTextAnchor427"/>Alerts</h2>
<p>Let’s define alerts, which are <a id="_idIndexMarker1707"/>sent out when something unusual occurs. We may alert in different ways. If you are on duty, it may be a pager message, a text message, an email, or even the activation of an alarm sound and some blinking alert lights. Everything hinges on the use case. Let’s just state that the author has contributed to several programs that have employed all of the aforementioned methods of alerting users.</p>
<p>For illustration, consider CPU use. When a Kubernetes cluster node’s CPU use exceeds 95% for a period of more than a minute, the <strong class="bold">System Reliability Engineer</strong> (<strong class="bold">SRE</strong>) needs <a id="_idIndexMarker1708"/>to be notified.</p>
<p>But who must establish <a id="_idIndexMarker1709"/>the guidelines, you might wonder? Operations – or, more precisely, the SREs – are responsible for determining what non-functional metrics are significant and when they wish to be notified, even in the middle of the night. The company must specify the functional metrics as well as the tolerance levels or other criteria that will cause an alert for each measure.</p>
<h2 id="_idParaDest-427"><a id="_idTextAnchor428"/>Defining alerts</h2>
<p>It is not sufficient <a id="_idIndexMarker1710"/>to merely gather and display metrics, whether they <a id="_idIndexMarker1711"/>pertain to infrastructure or the business. In order to develop <strong class="bold">Service-Level Objectives</strong> (<strong class="bold">SLOs</strong>) and <strong class="bold">Service-Level Agreements</strong> (<strong class="bold">SLAs</strong>) for those <a id="_idIndexMarker1712"/>metrics, we must first determine the crucial indicators that truly define the state of the system. Following that, we establish guidelines for how frequently and for how long a measured metric may exceed the appropriate SLO or SLA. We send out an alert if one of these rules is broken.</p>
<p>Let’s define a few potential alert candidates to get a sense of this. The first sample is a system-level statistic, whereas the second is a functional, or business-relevant, metric. Can you distinguish between them?</p>
<ul>
<li>We define the percentage of the total CPU utilized in a banking application as a statistic. <em class="italic">The proportion should not exceed 99%</em> could be the SLO. The rule might be that an alert should be sent out if the CPU percentage rises above 99% for more than 50% of a minute.</li>
<li>We may designate the amount of time it takes to generate a quote for a customer interested in a quote as a critical statistic in an application providing life insurance. The SLA for this metric may then be that 99% of all quote requests must be processed within 50 milliseconds. No request can take more than 1,000 milliseconds. If the SLA is breached more than three times in a single hour, an alert should be sent, according to a rule for alerts.</li>
</ul>
<p>The former is a infrastructure metric, whereas the latter is an commercial metric.</p>
<p>The chosen target <a id="_idIndexMarker1713"/>individuals, such as SREs or developers, can then get alerts via a variety of channels, including email, text messages, automated phone calls, Slack messages, audio alarms, optical alarms, and others.</p>
<p>Service employees can now conduct other activities instead of actively monitoring the system once we have created and wired such alarms. They are guaranteed to be informed if anything significant or unusual occurs to which they must respond.</p>
<h2 id="_idParaDest-428"><a id="_idTextAnchor429"/>Runbooks</h2>
<p>Say that an alert has been raised. What follows? Runbooks can help in this situation. A runbook outlines for <a id="_idIndexMarker1714"/>each alert who must be notified, what this person must do to remedy the underlying problem, and to whom the problem must be escalated if it cannot be resolved. Runbook creation is a difficult process that shouldn’t be taken lightly. However, they are a crucial tool for businesses. An SRE is only capable of so much. Some production problems are so serious that the C-level management must be notified. Imagine, for instance, that you run an online store and that there are no payments coming in because your <strong class="bold">Payment Service Provider</strong> (<strong class="bold">PSP</strong>) is down, making it impossible to <a id="_idIndexMarker1715"/>process payments on your platform. This indicates that your application is now devoid of a crucial requirement. In essence, you are unable to conduct business until the problem is fixed; don’t you think your CTO should be aware of this?</p>
<p>Let’s talk about a current hot topic: problems occurring with a production system. We need to swiftly identify the underlying cause of the problem.</p>
<h1 id="_idParaDest-429"><a id="_idTextAnchor430"/>Troubleshooting a service running in production</h1>
<p>It is a recommended best practice to create minimal images for production that don’t contain anything <a id="_idIndexMarker1716"/>that is not absolutely needed. This includes common tools that are usually used to debug and troubleshoot an application, such as <code>netcat</code>, <code>iostat</code>, <code>ip</code>, and others. Ideally, a production system only has container orchestration software such as Kubernetes installed on a cluster node with a minimal OS, such as CoreOS. The application container in turn ideally only contains the binaries absolutely necessary to run. This minimizes the attack surface and the risk of having to deal with vulnerabilities. Furthermore, a small image has the advantage of being downloaded quickly, using less space on disk and in memory, and showing faster startup times.</p>
<p>But this can be a problem if one of the application services running on our Kubernetes cluster shows unexpected behavior and maybe even crashes. Sometimes we are not able to find the root cause of the problem just from the logs generated and collected, so we might need to troubleshoot the component on the cluster node itself.</p>
<p>We may be tempted to SSH into the given cluster node and run some diagnostic tools. But this is not possible since the cluster node only runs a minimal Linux distro with no such tools installed. As a developer, we could now just ask the cluster administrator to install all the Linux diagnostic tools we intend to use. But that is not a good idea. First of all, this would open the door for potentially vulnerable software now residing on the cluster node, endangering all the other pods that run on that node, and would also open a door to the cluster itself, which could be exploited by hackers. Furthermore, it is always a bad idea to give developers direct access to nodes of a production cluster, no matter how much you trust them. Only a limited number of cluster administrators should ever be able to do so.</p>
<p>A better solution is to <a id="_idIndexMarker1717"/>have the cluster admin run a so-called bastion container on behalf of the developers. This bastion or troubleshooting container has all the tools installed that we need to pinpoint the root cause of the bug in the application service. It is also possible to run the bastion container in the host’s network namespace; thus, it will have full access to all the network traffic of the container host.</p>
<h2 id="_idParaDest-430"><a id="_idTextAnchor431"/>The netshoot container</h2>
<p>Nicola Kabar, a former Docker employee, created a handy Docker image called <code>nicolaka/netshoot</code> that field <a id="_idIndexMarker1718"/>engineers at Docker use all the time to troubleshoot applications running in production on Kubernetes or Docker Swarm. The purpose of this <a id="_idIndexMarker1719"/>container, in the words of the creator, is as follows:</p>
<p class="author-quote">“Purpose: Docker and Kubernetes network troubleshooting can become complex. With proper understanding of how Docker and Kubernetes networking works and the right set of tools, you can troubleshoot and resolve these networking issues. The netshoot container has a set of powerful networking troubleshooting tools that can be used to troubleshoot Docker networking issues.”</p>
<p class="author-quote">- Nicola Kabar</p>
<p>To use this container <a id="_idIndexMarker1720"/>for debugging purposes, we can proceed as follows:</p>
<ol>
<li>Spin up a throwaway bastion container for debugging on Kubernetes, using the following command:<pre class="source-code">
$ kubectl run tmp-shell --rm -i --tty \    --image nicolaka/netshoot</pre></li> </ol>
<p>You will be greeted by this prompt:</p>
<pre class="source-code">
bash-5.0#</pre> <ol>
<li value="2">You can now use tools such as <code>ip</code> from within this container:<pre class="source-code">
bash-5.0# ip a</pre></li> </ol>
<p>On my machine, this results in an output similar to the following if the pod is run on Docker Desktop:</p>
<div><div><img alt="Figure 19.20 – Output of the ip a command using the netshoot container" height="607" src="img/Figure_19.20_B19199.jpg" width="1091"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 19.20 – Output of the ip a command using the netshoot container</p>
<ol>
<li value="3">To leave this troubleshooting container, just press <em class="italic">Ctrl</em> + <em class="italic">D</em> or type <code>exit</code> and then hit <em class="italic">Enter</em>.</li>
<li>If we need to dig a bit deeper and run the container in the same network namespace as the Kubernetes host, then we can use this command instead:<pre class="source-code">
$ kubectl run tmp-shell --rm -i --tty \    --overrides='{"spec": {"hostNetwork": true}}' \    --image nicolaka/netshoot</pre></li> <li>If we run <code>ip</code> again <a id="_idIndexMarker1721"/>in this container, we will see everything that the container host sees too, for example, all the <code>veth</code> endpoints.</li>
</ol>
<p>The <code>netshoot</code> container has all the usual tools installed that an engineer ever needs to troubleshoot network-related problems. Some of the more familiar ones are <code>ctop</code>, <code>curl</code>, <code>dhcping</code>, <code>drill</code>, <code>ethtool</code>, <code>iftop</code>, <code>iperf</code>, and <code>iproute2</code>.</p>
<h1 id="_idParaDest-431"><a id="_idTextAnchor432"/>Summary</h1>
<p>In this last chapter of the book, we have looked at different techniques used to instrument and monitor an individual service or a whole distributed application running on a Kubernetes cluster. You have been introduced to the concept of alerting based on key metrics. Furthermore, you have been shown how one can troubleshoot an application service that is running in production without altering the cluster or the cluster nodes on which the service is running.</p>
<p>As we come to the end of this book, we would like to thank you for your interest and for persisting till the end. We hope that the information and examples provided have been helpful in deepening your understanding of Docker and Kubernetes. These technologies are powerful tools for building and deploying modern applications, and we hope that this book has given you the knowledge and confidence to use them effectively. Thank you again for reading, and we wish you all the best in your future endeavors!</p>
<h1 id="_idParaDest-432"><a id="_idTextAnchor433"/>Questions</h1>
<p>To assess your learning progress, please answer the following questions:</p>
<ol>
<li>Why is it important to instrument your application services?</li>
<li>Can you describe to an interested layperson what Prometheus is?</li>
<li>Exporting Prometheus metrics is easy. Can you describe in simple words how you can do this for a Node.js application?</li>
<li>You need to debug a service running on Kubernetes in production. Unfortunately, the logs produced by this service alone don’t give enough information to pinpoint the root cause. You decide to troubleshoot the service directly on the respective Kubernetes cluster node. How do you proceed?</li>
</ol>
<h1 id="_idParaDest-433"><a id="_idTextAnchor434"/>Answers</h1>
<p>Here are sample answers to the preceding questions:</p>
<ol>
<li>We cannot do any live debugging on a production system for performance and security reasons. This includes interactive or remote debugging. Yet application services can show unexpected behavior in response to code defects or other infrastructure-related issues such as network glitches or external services that are not available. To quickly pinpoint the reason for the misbehavior or failure of a service, we need as much logging information as possible. This information should give us a clue about, and guide us to, the root cause of the error. When we instrument a service, we do exactly this – we produce as much information as is reasonable in the form of log entries and published metrics.</li>
<li>Prometheus is a service that is used to collect functional or non-functional metrics that are provided by other infrastructure services and, most importantly, by application services. Since Prometheus itself pulls those metrics periodically from all configured services, the services themselves do not have to worry about sending data. Prometheus also defines the format in which the metrics are to be presented by the producers.</li>
<li>To instrument a Node.js-based application service, we need to take the following four steps:<ol><li>Add a Prometheus adapter to the project. The maintainers of Prometheus recommend a library called <code>siimon/prom-client</code>.</li><li>Configure the Prometheus client during the startup of the application. This includes the definition of a metrics registry.</li><li>Expose an HTTP GET endpoint/metrics where we return the collection of metrics defined in the metrics registry.</li><li>Finally, define custom metrics of the counter, gauge, or histogram type, and use them in our code; for example, we increase a metric of the counter type each time a certain endpoint is called.</li></ol></li>
<li>Normally, in production, a Kubernetes cluster node only contains a minimal OS to keep its attack surface as limited as possible and to not waste precious resources. Thus, we cannot assume that the tools typically used to troubleshoot applications or processes are available on the respective host. A powerful and recommended way to troubleshoot is to run a special tool or troubleshoot container as part of an ad hoc pod. This container can then be used as a bastion from which we can investigate network and other issues with the troubled service. A container that has been successfully used by many Docker field engineers at their customers’ sites is <code>nicolaka/netshoot</code>.</li>
</ol>
</div>
</div></body></html>