<html><head></head><body><div class="chapter" title="Chapter&#xA0;6.&#xA0;Orchestrating SDN Controllers Using Ansible"><div class="titlepage"><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Orchestrating SDN Controllers Using Ansible</h1></div></div></div><p>This chapter will focus on SDN controllers and the ways they can enable network teams to simplify their daily tasks.</p><p>We will look at why SDN Controllers have been adopted and highlight some of the immediate business benefits they will bring if utilized correctly. It will focus on ways in which network operations need to be divided so network operations can scale, by utilizing automation.</p><p>This chapter will discuss the benefits of utilizing software-defined networking and look at practical configuration management processes that can be used to orchestrate SDN Controller APIs and object models. Finally, we will look at how Ansible can be used to execute and wrap some of these configuration management processes, using Nuage VSP as a practical example.</p><p>In this chapter, the following topics will be covered:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Arguments against software defined networking</li><li class="listitem" style="list-style-type: disc">Why would a company utilize SDN?</li><li class="listitem" style="list-style-type: disc">Splitting up network operations</li><li class="listitem" style="list-style-type: disc">Immutable networking</li><li class="listitem" style="list-style-type: disc">Using Ansible to orchestrate SDN controllers</li></ul></div><div class="section" title="Arguments against software-defined networking"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec34"/>Arguments against software-defined networking</h1></div></div></div><p>With the emergence of public clouds such as AWS, Microsoft Azure, and Google Cloud, networking is now <a id="id501" class="indexterm"/>being treated more like a commodity and has moved from silicon to software. This has allowed developers the ability to mutate the network to best serve the applications, rather than retrofit applications into an aging network,  that is probably not optimized for modern microservice applications.</p><p>It would therefore seem <a id="id502" class="indexterm"/>nonsensical if any business would want to treat their internal data center networking any differently. However, like all new ideas, before acceptance and adoption comes fear and uncertainty, inherently co-related with the new or different ways of working.</p><p>Common arguments against using a clos Leaf-Spine architecture and SDN controllers center around one common theme, that it requires change and change is hard. We then harp back to the mythical 8th layer of the OSI model, and that is the <span class="strong"><strong>User</strong></span> layer:</p><div class="mediaobject"><img src="graphics/B05559_06_01.jpg" alt="Arguments against software-defined networking"/></div><p>The network operators have to feel comfortable with any solution that is implemented. This is very important, but by the same <a id="id503" class="indexterm"/>token, the <span class="strong"><strong>User</strong></span> layer is equally important as it is the networking service provided by the network team to end users. So ease of use is important on two levels, both network operations and the self-service operations provided to the consumers of the network.</p><p>Before a company considers putting in software-defined networking, they need to be doing it for the correct reasons and make it requirements-based. Simply implementing a new tool, in this case an SDN Controller, will not solve operational issues alone.</p><p>Organizations need to work out what the new operational model should be and utilize software-defined networking as a facilitator for those new business processes, focusing on speed of operations with the <a id="id504" class="indexterm"/>aim of removing networking as the bottleneck for application delivery. In short, network operations need to be DevOps friendly or they will inhibit software delivery and slow down the whole application lifecycle.</p><div class="section" title="Added network complexity"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec71"/>Added network complexity</h2></div></div></div><p>Some of the arguments used against using overlay networks are that they are more complex than traditional layer 2 networks, with many more moving parts that could cause a bigger variety of failures.</p><p>Although the constructs of an <a id="id505" class="indexterm"/>overlay and underlay network may be different, it is fair to say software-defined networking is still a relatively new concept and a lot of people fear change. As long as the base requirements in terms of network availability, redundancy, performance, and speed of change are met, then there should be no reason not to implement software-defined networking.</p><p>The fear of software-defined overlay networks can be likened to operations staff's initial skepticism towards server virtualization when they initially argued against the introduction of hypervisors. These new concepts were initially viewed as an added layer of complexity and added abstraction layer that would probably not be as performant.</p><p>However, the portability and opportunities introduced by running a hypervisor greatly outweighed any performance implications for the vast majority of application use cases. The benefits included increased portability, flexibility, and speed of operations.</p><p>There are of course edge cases and some applications that don't fit into the virtualized model, but the benefits that virtualization brings for 99 percent of the data center mean that as a business solution it can't really be ignored.</p><p>Overlay networks give the same benefits to networking as hypervisors did to servers. Of course, when implementing a software-defined overlay network, the underlay should be built for redundancy, so that if a failure occurs, it occurs on the underlay and does not impact the overlay.</p><p>The underlay network should be horizontally scaleable and simple, in the case of a Leaf-Spine architecture, which has a series of Spine switches connected to Leaf switches that sit on top of each rack. The introduction of more racks paired with Leaf switches, or even a new Spine to prevent over-subscription of links, allow horizontal scalability.</p><p>On the topic of overlay networks adding complexity, Any systems reliability engineer or network engineer that has spent hours debugging an ill-performing link in a layer 2 Spanning Tree network will testify that Spanning Tree networks are themselves very complex by nature. The systems reliability engineer or network engineer will also probably be able to show you the network <a id="id506" class="indexterm"/>diagram they had to draw in an attempt to solve the issue as evidence of the complexity.</p><p>So networks are complex beasts at the best of times; however, when utilizing underlay and overlay networks, the main focus on the underlay network should be horizontal scalability and performance. It should ensure that network operators can easily scale out the network based on demand.</p><p>Alternatively, the focus of the overlay network is simplicity, so it should have easy-to-understand software constructs while at the same time ensure that the API endpoints can cope with the desired number of concurrent requests from consumers.</p><p>If implemented correctly, networks should be componentized into two distinct sections. The overlay user friendly software, much like AWS, Microsoft Azure, Google Cloud, or OpenStack, and the underlay is the gritty, hardcore, networking that needs to be well designed by a network architect and built for scale.</p></div><div class="section" title="Lack of software-defined networking skills"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec72"/>Lack of software-defined networking skills</h2></div></div></div><p>Another argument against not implementing a software-defined network is lack of skills in the industry currently; with any <a id="id507" class="indexterm"/>new technology there is initially a lack of skilled people to support it. One viewpoint is that companies will have to hire completely new staff to implement software defined networking.</p><p>However, this can be offset by partnering with an SDN vendor or utilizing provided training programs for staff. It is a business transformation and as such, network staff will need to build new skills over a period of time.</p><p>But networking staff will need to evolve with the changes software-defined networking bring and build new skills like other teams in IT. Implementing software defined networking is a big change at first, but good networking staff should be excited and embrace these changes. The efficiency and benefits that can be had from implementing software-defined networking are undeniable.</p><p>Change can be daunting at first and can seem like a monumental cultural shift or effort at times. To initiate successful change in large or even small companies it usually has to come with top-down sponsorship or backing.</p><p>Adopting software-defined networking will mean changing the business's operational model and automation will need to be embraced at every level; network tasks in the overlay simply can't be manual when using an SDN controller. An organization implementing software-defined networking also needs to look at ways of automating the underlay. In this book we have already looked at ways in which APIs can be utilized to configure network devices, so really, both the underlay and overlay need to be automated.</p><p>The term software-defined data center is somewhat overused by vendors, but the principles behind it can't be ignored if a network team wants to provide a great user experience <a id="id508" class="indexterm"/>to the rest of the business. If a company puts in a software-defined networking solution as a standalone initiative, then it will add no true value if automation isn't written to speed up network operations utilizing the rich set of APIs that are provided. If companies are going to put in a software-defined network and have network engineers manually enter commands on network devices or use a GUI, the company may as well not bother, as they can do that with any out-of-the-box switch or router; they are wasting the opportunity a software-defined overlay network offers.</p><p>Just putting in the software-defined networking solution and still having developers raise network tickets will give zero business value; it will not increase efficiency, time to market, or the reliability of changes. To ensure organizations extract the significant business benefits out of software-defined networking, you need an all-or-nothing approach; network operations are either completely automated or over time become fragmented and broken.</p><p>If network engineers persist with doing manual updates outside the automated workflows, then it has the opportunity to break the whole operational mode. It changes the desired state of the network, and it could break the automation completely.</p><p>When putting in software-defined networking, automate all the common operations first and allow developers to serve themselves and make it immutable if possible. Being able to rebuild the network from source control management systems should be the aim as it acts as a record of change.</p><p>In <a class="link" href="ch03.html" title="Chapter 3. Bringing DevOps to Network Operations">Chapter 3</a>, <span class="emphasis"><em>Bringing DevOps to Network Operations,</em></span> we looked at ways of initiating cultural change. Humans are creatures of habit, they tend to stick with what they know; network engineers have spent years gathering networking certifications on ways to configure Spanning Tree algorithms and layer 2 networks, so this is a huge cultural shift.</p></div><div class="section" title="Stateful firewalling to support regularity requirements"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec73"/>Stateful firewalling to support regularity requirements</h2></div></div></div><p>One of the main issues highlighted with software-defined networking has been the lack of stateful <a id="id509" class="indexterm"/>firewalling, due to Open vSwitch being based on flow data and being traditionally stateless. Until recently, reflexive rules were utilized to emulate stateful firewalling at the kernel user space level.</p><p>However, recent feature developments with Open vSwitch has allowed stateful firewalling to be <a id="id510" class="indexterm"/>implemented. So the lack of stateful firewalling is no longer an issue with Open vSwitch. <span class="strong"><strong>Connection tracking</strong></span> (<span class="strong"><strong>conntrack</strong></span>), previously only available as part of iptables, has now been decoupled from iptables, meaning that it is now possible to match on connections as well as flow data.</p><p>The Nuage VSP platform has introduced stateful firewalling as part of its 4.x release. The Nuage VSP <a id="id511" class="indexterm"/>platform has replaced reflexive rules for stateful rules, to govern all ICMP and TCP ACL rules on the Nuage VRS (Nuage's customized version of Open vSwitch):</p><div class="mediaobject"><img src="graphics/B05559_06_02.jpg" alt="Stateful firewalling to support regularity requirements"/></div></div></div></div>
<div class="section" title="Why would organizations need software-defined networking?"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec35"/>Why would organizations need software-defined networking?</h1></div></div></div><p>Any good enterprise networks <a id="id512" class="indexterm"/>should be built with the following goals in mind:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Performance</li><li class="listitem" style="list-style-type: disc">Scalability</li><li class="listitem" style="list-style-type: disc">Redundancy</li></ul></div><p>The network, first and foremost, needs to be <span class="emphasis"><em>performant </em></span>to meet customer needs. Customers can be end users in the data center or end users of the application in the public domain. With Continuous Delivery and deployment, if networking blocks a developer in a test environment, it is hampering <a id="id513" class="indexterm"/>a potential <a id="id514" class="indexterm"/>feature or bug fix reaching production, so it is not acceptable to have sub-standard pre-production networks and they should be designed as scaled-down functional replicas of production.</p><p>
<span class="emphasis"><em>Scalability</em></span> focuses on the ability to scale out the network to support company growth and demand. As more applications are added, how does the network horizontally scale? Is it cost effective? Can it <a id="id515" class="indexterm"/>easily be adapted to cater for new services such as third-party VPN access or point-to-point network integration? All these points need to be given proper consideration when creating a flexible and robust network design.</p><p>
<span class="emphasis"><em>Redundancy</em></span> is built on <a id="id516" class="indexterm"/>the concept that any enterprise network should have no single points of failure. This is so that the network can recover from a switch failure or an issue with a core router and not cause outages to customers. Every part of the network should be set up to maximize uptime.</p><p>These three points seem to have been the staple on which good networks were designed and built in the past. However, as applications have moved from monoliths to microservices, additional requirements are necessary for successful network operations.</p><p>Traditionally, monolithic applications have tended to have one setup operation and then remained fairly static, while microservice applications on the other hand have required more dynamic networks that are subject to greater variance of change.</p><p>The needs of the modern network have evolved and networks need to be updated rapidly to deal with the requirements of microservice architectures, without having to wait on a network engineer to process a ticket. With Continuous Delivery forming feedback loops, it is imperative that the process is quick and lean, and issues can be fixed quickly otherwise the whole process will break down and grind to a stand-still.</p><div class="section" title="Software-defined networking adds agility and precision"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec74"/>Software-defined networking adds agility and precision</h2></div></div></div><p>Software-defined <a id="id517" class="indexterm"/>networking or in particular overlay<a id="id518" class="indexterm"/> networking, still focuses on <span class="emphasis"><em>performance</em></span>, <span class="emphasis"><em>scalability,</em></span> and <span class="emphasis"><em>redundancy</em></span>; they should never be compromised, but also introduces the following benefits:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Agility</li><li class="listitem" style="list-style-type: disc">Mean time to recover</li><li class="listitem" style="list-style-type: disc">Precision and repeatability</li></ul></div><p>Software-defined networking puts the network into a software overlay network with associated object model, which allows the network to be programmable by exposing a rich set of APIs. This means that workflows can be used to set up network functions, the same way infrastructure can be controlled in a cloud or virtualization environment.</p><p>As the network is programmable, requesting a new subnet or making an ACL change can be done as quickly as spinning up a virtual machine on a hypervisor. Software-defined networking removes the traditional blockers or operational inhibitors. These have often included being required to raise a ticket to a network operation team to mutate the network, which was <a id="id519" class="indexterm"/>subject to a lengthy change control process. Instead, when utilizing software-defined networking, a developer can control a subnet of network operations via an API call so changes can be carried out at pace.</p><p>
<span class="emphasis"><em>Mean time to recover</em></span> has also improved when utilizing software-defined networking because <a id="id520" class="indexterm"/>network changes are programmable, so network inventory can be stored in source control management systems. This versions the network so any change is delivered via source control management and allows network changes to be modular, auditable, and easy to track.</p><p>If a breaking <a id="id521" class="indexterm"/>change has occurred to the overlay network, a version tree in the source control management system can be used to see what has changed since the network's last working release. The same programmable script can then be used to quickly roll back the network change back to the previous version and remove the issue. This is, of course, the beauty of implementing an immutable network rather than static networks, where the state is always as clean as the day one network and can be rolled forward or back on demand.</p><p>
<span class="emphasis"><em>Repeatability</em></span> in software-defined networking is catered for using programmatic operational <a id="id522" class="indexterm"/>workflows, so that all network changes are carried out in an identical way by all users. These operations can be executed using the API workflows approved by the network team against the overlay network.</p><p>The use of programmatic workflows means that network changes can be integrated into application deployment processes such as Continuous Delivery. This means network changes, like code, will be checked into source control management systems, pushed to a test environment using programmatic workflow actions (to manage the desired state of the network), tested and verified, and only then promoted onto the next test environment or production.</p><p>This repeatability of using an overlay network ensures all the constructs of a quality assurance test environment can be the same as a production environment, as all networking constructs are described in software and are easy to reproduce.</p></div><div class="section" title="A good understanding of Continuous Delivery is key"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec75"/>A good understanding of Continuous Delivery is key</h2></div></div></div><p>Organizations looking to utilize software-defined networking should ideally already have a well-established <a id="id523" class="indexterm"/>Continuous Delivery model for code and infrastructure before tackling network operations. Companies committed to investing in a DevOps transformation would also benefit greatly from designing their new operational model around a software-defined network.</p><p>Companies which have mandated their business functions to automate all IT operations, inclusive of networking functions, would receive immeasurable quantifiable benefits from using an SDN controller to help their teams automate the network. Companies with an inherit <a id="id524" class="indexterm"/>understanding of DevOps, <span class="strong"><strong>continuous integration</strong></span>, and <span class="strong"><strong>Continuous Delivery</strong></span> are more likely to utilize SDN controllers to their full capabilities <a id="id525" class="indexterm"/>and drive innovation.</p><p>To emphasize the point, if overlay networks are modified by network engineers by hand rather than programmatically, it will bring no business value and the company will have missed the point.</p><p>Operational models need to change when implementing software-defined networking and if an issue occurs it needs to be built back into the automation to fix the issue so it doesn't re-occur. Any complex process, when initially automated, will probably hit some unexpected edge cases and fail under unexpected conditions. As a result, it is important that automated processes are continually iterated and improved on. Having teams adopt a continuous improvement methodology will ensure that automated processes are iterated and improved so they become more and more robust over time.</p><p>It is important to appreciate that edge cases will occur and to not panic when they do; fixing a problem with the automation fixes it for all users, but by the same token a problem with the automation can cause multiple users to be impacted, so it is a double-edged sword. Creating sufficient testing when creating automated processes to try and catch these edge cases in test environments becomes vitally important.</p><p>One of the benefits automation brings is that that all changes can be carried out with the precision of a highly skilled network engineer who can supply all their knowledge to automation. This means that every automated network change is done with the same care and precision as the best network engineer in the company.</p><p>The pre-approved and well-defined changes to automated workflows can be carried out by anyone in the company, not just the best engineer, if they are automated, so the bottleneck is removed from the network team freeing them up to work on more interesting tasks <a id="id526" class="indexterm"/>than the mundane repeatable <span class="strong"><strong>Business as Usual</strong></span> (<span class="strong"><strong>BAU</strong></span>) tasks that are more accurately done using automation.</p></div><div class="section" title="Simplifying complex networks"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec76"/>Simplifying complex networks</h2></div></div></div><p>Organizations that have very complex legacy networks would also be a prime candidate for benefiting from software-defined networking instead of fixing the existing network, which may not be possible <a id="id527" class="indexterm"/>due to having to adhere to 99 percent uptime targets. Instead, a new green-field network could be created in parallel with the existing network.</p><p>This will allow application workloads to be migrated to the new network over time and simplify the complexity of the existing network in the process. During the period of migration where both the new green-field network and old legacy network co-exist, the SDN overlay network can be used to route back to the legacy network for application dependencies that have yet to be migrated.</p><p>Another benefit of software-defined networking is that it allows private cloud solutions to run at increased scale. If private clouds are running more than 100 hypervisors, this is a scale at which an SDN solution would be of benefit, such as extending OpenStack Neutron capabilities to allow companies to run OpenStack at scale, as opposed to deploying multiple smaller OpenStack clouds to cope with bottlenecks.</p></div><div class="section" title="Splitting up network operations"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec77"/>Splitting up network operations</h2></div></div></div><p>With the introduction of software-defined networking in a company or business there has to be a shift in <a id="id528" class="indexterm"/>operational responsibilities. If an organization runs multiple microservice applications, a fairly typical situation is that a company has 100 developers that develop those 200 microservices. </p><p>Each of those 200 microservices are combined together to deploy the company's customer facing website.</p><p>The company may use agile software development so each of the 100 developers are split into a set of delivery teams that contain 10 or so developers, each forming scrum teams, and each delivery team looks after a set amount of microservices relative to their complexity.</p><p>The company has 10 network engineers that are required to serve the networking needs of the 100 developers, as well as maintaining uptime of the network.</p><p>However, in this model, if all network operations are done manually, then the network engineers will not be able to keep up with the necessary change requests, so they will either have to work late nights and subsequently become burned out, so their productivity will drop. In this model, they are in reactive firefighting mode.</p><p>In this model, the productivity of the developers will probably be impacted too as the network engineers will become the bottleneck for throughput. The model described will simply not scale, so operational change is required.</p><p>In the scenario described, one network engineer will be required for every ten developers, and in future as the company expands it will want to invest in development staff to create more products. It is undoubtedly a harder sell for organizations to scale up their network teams to support those network operations, so network automation becomes a must in this scenario and the network team needs to work smarter.</p><p>Introducing new <a id="id529" class="indexterm"/>products and developers without changing the way a networking team operates can lead to burnout, so a network engineer will be able to support ten developers but not 20 when doing all network operations manually. Therefore, considering the developer to network engineer ratio is important when making the case for automation, as shown:</p><div class="mediaobject"><img src="graphics/B05559_06_03.jpg" alt="Splitting up network operations"/></div><p>The business may then look at software-defined networking as the solution to solve their scaling problems, with the mindset of simplifying the network. This means that network engineers can carry out network changes more quickly to support developer demand.</p><p>But simply putting in a software defined networking solution such as CISCO ACI, Juniper Contrail, VMware NSX, or Nuage Networks will not help the situation unless processes are automated and the inefficient business processes are addressed.</p><div class="section" title="New responsibilities in API-driven networking"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec02"/>New responsibilities in API-driven networking</h3></div></div></div><p>The role of a network engineer in a software-defined network therefore has to evolve; they have to devolve <a id="id530" class="indexterm"/>some power to the developers like operations staff were required to for the creation of the infrastructure. But software-defined networking shouldn't mean giving complete, open access of the API to developer. This is also a recipe for disaster. Efficient controls need to be put in place that act as a quality gate, not as an inhibitor of productivity.</p><p>Some operational workflows in an overlay network should still be controlled by a qualified network engineer and governed by security, but not to the detriment of developer's productivity and requirements.</p><p>It wouldn't be fair to <a id="id531" class="indexterm"/>expect a developer to be well versed enough in networking to log onto a router and set up their routing requirements for their application unaided, so there has to be some middleground.</p><p>Allowing a developer access to network devices in an uncontrolled manner poses the risk of a network outage, which goes against one of the three main networking principles and compromises redundancy, and network engineers have a responsibility for uptime of the system.</p></div><div class="section" title="Overlay architecture setup"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec03"/>Overlay architecture setup</h3></div></div></div><p>When setting up an overlay network, it will normally be built in a green-field environment <a id="id532" class="indexterm"/>as part of an application migration program and target environment for a legacy network. The application migration could either be done in a piecemeal format or done in one step, where everything is migrated, then switched on as part of a migration big bang, go live activity.</p><p>Regardless of the application migration approach, it is very important that the overlay network is set up to achieve the following goals:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Agility</li><li class="listitem" style="list-style-type: disc">Minimize mean time to recover</li><li class="listitem" style="list-style-type: disc">Repeatability</li><li class="listitem" style="list-style-type: disc">Scalability</li></ul></div><p>The performance of the network will be determined by the underlay components and silicon used, but the definition of the overlay network in terms of constructs and workflow of the SDN object model need to be correct to make sure that any operation can easily be carried out quickly, is repeatable, and that the design scales and can support roll-back. The SDN before implementation should be performance tested to make sure the virtualization overhead does not impact performance.</p><p>So, let's quickly <a id="id533" class="indexterm"/>recap on the Nuage VSP object model that was covered in <a class="link" href="ch02.html" title="Chapter 2. The Emergence of Software-defined Networking">Chapter 2</a>, <span class="emphasis"><em>The Emergence of Software-defined Networking</em></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Organization</strong></span>: Governs all layer 3 domains<div class="mediaobject"><img src="graphics/B05559_06_04.jpg" alt="Overlay architecture setup"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Layer 3 domain template</strong></span>: A <span class="strong"><strong>Company L3 Domain Template</strong></span> is required before child layer 3 domains are created. The <span class="strong"><strong>Company L3 Domain Template</strong></span> is used to govern overarching default policies that will be propagated to <a id="id534" class="indexterm"/>all child layer 3 domains. If a <span class="strong"><strong>Company L3 Domain Template</strong></span> is updated at template level, then the update will be implemented on all layer 3 domains that have been created underneath it, immediately.<div class="mediaobject"><img src="graphics/B05559_06_05.jpg" alt="Overlay architecture setup"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Layer 3 domain</strong></span>: Can be used to segment different environments so users cannot hop from subnets deployed in a layer 3 <span class="strong"><strong>Test</strong></span> domain to a layer 3 <span class="strong"><strong>Production</strong></span> domain.<div class="mediaobject"><img src="graphics/B05559_06_06.jpg" alt="Overlay architecture setup"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Zones</strong></span>: A zone segment's firewall policies are at application level, so each micro-service application can have its own zone and associated Ingress and Egress policy per layer 3 domain.<div class="mediaobject"><img src="graphics/B05559_06_07.jpg" alt="Overlay architecture setup"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Layer 3 Subnet</strong></span>: This is where VMs or bare-metal servers are deployed. In this example, we see <span class="strong"><strong>Subnet Application1</strong></span> and <span class="strong"><strong>Subnet Application2:</strong></span><div class="mediaobject"><img src="graphics/B05559_06_08.jpg" alt="Overlay architecture setup"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Application Specific Egress Policy</strong></span>: Unique application policies for Egress rules that can be <a id="id535" class="indexterm"/>used to view each individual application's connectivity rules:<div class="mediaobject"><img src="graphics/B05559_06_09.jpg" alt="Overlay architecture setup"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Application Specific Ingress Policy</strong></span>: Unique application policies for ingress rules that can be used to view each individual application's connectivity rules:<div class="mediaobject"><img src="graphics/B05559_06_10.jpg" alt="Overlay architecture setup"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Leaking Domain</strong></span>: This is used to leak routes into the overlay network via a layer 3 subnet to bridge connectivity between the green-field network and a legacy network:<div class="mediaobject"><img src="graphics/B05559_06_11.jpg" alt="Overlay architecture setup"/></div><p>So, utilizing Nuage VSP as an example, we had an organization with two layer 3 <a id="id536" class="indexterm"/>domains dictating Test and Production, with a zone for each micro-service application encapsulating its unique micro-subnets and virtual machines:</p><div class="mediaobject"><img src="graphics/B05559_06_12.jpg" alt="Overlay architecture setup"/></div><p>In terms of network setup, automation could be used by the network team <a id="id537" class="indexterm"/>and they would be in control of the following constructs in the overlay network:</p></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Organization</strong></span>: Governs all layer 3 domains:<div class="mediaobject"><img src="graphics/B05559_06_13.jpg" alt="Overlay architecture setup"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Layer 3 domain template</strong></span>: Used to govern default policies:<div class="mediaobject"><img src="graphics/B05559_06_14.jpg" alt="Overlay architecture setup"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Layer 3 domain</strong></span>: Used to separate responsibilities between environments such as development and production:<div class="mediaobject"><img src="graphics/B05559_06_15.jpg" alt="Overlay architecture setup"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Leaking Domain</strong></span>: Used to make the legacy network accessible from the overlay network:<div class="mediaobject"><img src="graphics/B05559_06_16.jpg" alt="Overlay architecture setup"/></div></li></ul></div><p>The organization is most likely a <span class="emphasis"><em>day-one</em></span> setup activity, while the domain template policies can be defined and dictated by the network and security team. Any security policies applied across all networks, regardless of the domain they are deployed in, are governed <a id="id538" class="indexterm"/>by the domain template. So test environments will have identical template policies to production and meet all security, governance, and regularity requirements.</p><p>Development teams then have the ability to create unique test environments under the <span class="strong"><strong>Test</strong></span> layer 3 domain with the same subsequent policies, without the need for the network team to audit each and every one. The application security rules that developers use can then be agreed between security and development teams without network teams having to become involved directly unless they are asked to advise on particular best practice ways of setting up ACL rules.</p><p>The other <span class="emphasis"><em>day-one</em></span> setup activity will probably be setting up access to a legacy network that teams will be migrating applications from for a time, so they will still have dependent applications residing in that network.</p><p>Nuage VSG, which is a hardware gateway device that connects external networks to the Nuage VSP platform and its associated leaking domain, can be used to do this. The Nuage VSG leaks routes from external networks into the overlay network and into specific layer 3 domains.</p><p>The Nuage VSP Platform allows network teams to define the <span class="strong"><strong>GRThubDomain</strong></span> leaking domain in software that utilizes VSG. In this example, a leaking domain is set as IP host interfaces are connected into the <span class="strong"><strong>Front End</strong></span>, <span class="strong"><strong>Business Logic</strong></span> and <span class="strong"><strong>Back End</strong></span> routers in the legacy network:</p><div class="mediaobject"><img src="graphics/B05559_06_17.jpg" alt="Overlay architecture setup"/></div><p>The Nuage VSP platform then allows the newly-created <span class="strong"><strong>GRThubDomain</strong></span> to be associated with the <span class="strong"><strong>Production</strong></span> or <span class="strong"><strong>Test</strong></span> layer 3 domains by associating a leaking domain against them.</p><p>In the following <a id="id539" class="indexterm"/>example, the <span class="strong"><strong>GRThubDomain</strong></span> leaking domain is associated with the <span class="strong"><strong>Production</strong></span> layer 3 domain to allow legacy network routes to be accessible from zones and subnets residing under the <span class="strong"><strong>Production</strong></span> layer 3 domain:</p><div class="mediaobject"><img src="graphics/B05559_06_18.jpg" alt="Overlay architecture setup"/></div><p>The network team will also be responsible for monitoring the network underlay and making sure that it is scaled out appropriately as more compute is introduced, so Leaf switches will be introduced and ordered as and when new racks are scaled out, while new Spine switches are introduced to avoid the saturation of links.</p></div><div class="section" title="Self-service networking"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec04"/>Self-service networking</h3></div></div></div><p>It is important to focus on the network operations that developers typically require network tickets <a id="id540" class="indexterm"/>for as a start point. These are the common pain points for developers that prove to be blockers to productivity. Network operations can be effectively separated by looking at the common themes on network ticketing systems that have been raised by development teams.</p><p>These are the more mundane BAU operations that network operators should make self-service:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Opening firewall ports</li><li class="listitem" style="list-style-type: disc">Creation of new development environments</li><li class="listitem" style="list-style-type: disc">Connectivity to other applications</li></ul></div><p>These operations should be set up as self-service operations in a software-defined network.</p><p>In terms of the <a id="id541" class="indexterm"/>Nuage VSP object model, network operators should allow developers the ability to control the following object model entities:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Zones</strong></span>: They encapsulate a microservice application:<div class="mediaobject"><img src="graphics/B05559_06_19.jpg" alt="Self-service networking"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Layer 3 Subnet</strong></span>: These define the IP range available to a microservice application<div class="mediaobject"><img src="graphics/B05559_06_20.jpg" alt="Self-service networking"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Application Specific Egress Policy</strong></span>: This defines the Egress ACL policies for the microservice application:<div class="mediaobject"><img src="graphics/B05559_06_21.jpg" alt="Self-service networking"/></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Application Specific Ingress Policy</strong></span>: This defines the Ingress ACL policies <a id="id542" class="indexterm"/>for the microservice application:<div class="mediaobject"><img src="graphics/B05559_06_22.jpg" alt="Self-service networking"/></div></li></ul></div><p>This will allow the network operations team to provide development teams with the organization, layer 3 domains, and the layer 3 domain template.</p><p>Underneath either the <span class="strong"><strong>Test</strong></span> or <span class="strong"><strong>Production</strong></span> layer 3 domains, development teams have the flexibility to create new zones unique to each microservice application, then any associated subnets and virtual machines that they need to provision.</p><p>The subnets will be micro subnets, so something akin to a <code class="literal">/26</code>, <code class="literal">/27</code>, or <code class="literal">/28</code> may be acceptable. The <a id="id543" class="indexterm"/>network team will provide the subnet schema and a booking system where teams can reserve the address space in an IPAM solution if they are on-boarding an application or creating a new application, to prevent clashes with other teams.</p><p>As long as each delivery team follows those constructs, the networking team does not need to be involved in the provisioning of new applications or onboarding, it will become self-service, like AWS, Microsoft Azure, or Google Cloud.</p><p>However, in order to properly facilitate development teams, the network team should ideally create the self-service automation that the development teams can use to carry out the following in Nuage VSP along with the operations team:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Creation of zones</li><li class="listitem" style="list-style-type: disc">Deletion of zones</li><li class="listitem" style="list-style-type: disc">Creation of subnets</li><li class="listitem" style="list-style-type: disc">Deletion of subnets</li><li class="listitem" style="list-style-type: disc">Creation of Ingress rules</li><li class="listitem" style="list-style-type: disc">Deletion of Ingress rules</li><li class="listitem" style="list-style-type: disc">Creation of Egress rules</li><li class="listitem" style="list-style-type: disc">Deletion of Egress rules</li><li class="listitem" style="list-style-type: disc">Creation of network macros (external subnets)</li><li class="listitem" style="list-style-type: disc">Deletion of network macros (external subnets)</li></ul></div><p>No matter the SDN solution implemented, the self-service constructs required will be similar, in order to scale network operations, a lot of the operations have to be automated and made self-service.</p><p>Ideally, these self-service workflow actions could be added to Ansible playbooks or roles and included in the deployment pipelines to provision the networking along with the infrastructure.</p></div></div><div class="section" title="Immutable networking"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec78"/>Immutable networking</h2></div></div></div><p>To fully take advantage of the benefits of software-defined networking, utilizing immutable networking <a id="id544" class="indexterm"/>brings multiple benefits over static networking. Like infrastructure as code before it, networking as code and the utilization of immutable networking means that every time an application is deployed, its networking is freshly deployed from a source control management system that describes the desired state of the network. This means that network configurations don't drift over time.</p><p>Using a networking as code model to drive immutable networking allows application connectivity to be tested prior to production. Test environments mirroring production should be used to check application connectivity prior to releasing any network changes to production.</p><p>Implementing network changes as part of a Continuous Delivery model means that if application connectivity is proven to be wrong when it is tested in a test environment, then the application connectivity will be wrong in production environments. As a result, wrong connectivity changes should never reach production and should be caught prior to production by creating feedback loops that alert teams that the network change is not fit for purpose. Catching such issues will prevent outages and application downtime.</p><div class="section" title="A/B immutable networking"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec05"/>A/B immutable networking</h3></div></div></div><p>Networking, as a result, should ideally be integrated and become part of the application release <a id="id545" class="indexterm"/>cycle, with networks being built from scratch every single release and loaded from the source control management system. Networks can be deployed using immutable A/B networking.</p><p>Using the Nuage VSP integrated with OpenStack as an example:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A network will reside under a layer 3 domain</li><li class="listitem" style="list-style-type: disc">Each zone will be unique to a particular microservice application</li><li class="listitem" style="list-style-type: disc">Underneath the zone, a subnet will be created in both Nuage and OpenStack</li><li class="listitem" style="list-style-type: disc">Virtual machines for each release will be created in OpenStack and associated with the Nuage subnet</li></ul></div><p>The first release of <span class="strong"><strong>Application1</strong></span> version 1.1 is deployed to the <span class="strong"><strong>Test</strong></span> layer 3 domain, deploying two virtual machines on <span class="strong"><strong>Subnet A Application1</strong></span>, sitting under the <span class="strong"><strong>Application1</strong></span> zone:</p><div class="mediaobject"><img src="graphics/B05559_06_23.jpg" alt="A/B immutable networking"/></div><p>The second release of application version 1.2 is deployed to the <span class="strong"><strong>Test</strong></span> layer 3 domain, scaling down the release and deploying one virtual machine on <span class="strong"><strong>Subnet B Application1</strong></span>, sitting under the <span class="strong"><strong>Application1</strong></span> zone:</p><div class="mediaobject"><img src="graphics/B05559_06_24.jpg" alt="A/B immutable networking"/></div><p>Once release 1.2 has been put into service on the load balancer, doing a rolling deployment, <a id="id546" class="indexterm"/>the new virtual machine on <span class="strong"><strong>Subnet B Application1</strong></span> will be in service, <span class="strong"><strong>Subnet A Application1</strong></span> can then be destroyed along with its virtual machines as part of the deployment clean-up phase:</p><div class="mediaobject"><img src="graphics/B05559_06_25.jpg" alt="A/B immutable networking"/></div><p>The next release of <span class="strong"><strong>Application1</strong></span>, release 1.3, will then be deployed into <span class="strong"><strong>Subnet A Application1</strong></span>, and scaled up again to two virtual machines:</p><div class="mediaobject"><img src="graphics/B05559_06_26.jpg" alt="A/B immutable networking"/></div><p>Once release 1.2 has been put into service on the load balancer, doing a rolling deployment, <a id="id547" class="indexterm"/>the new virtual machines on <span class="strong"><strong>Subnet A Application1</strong></span> will be in service, <span class="strong"><strong>Subnet B Application1</strong></span> can then be destroyed along with its associated virtual machine as part of the deployment clean-up phase:</p><div class="mediaobject"><img src="graphics/B05559_06_27.jpg" alt="A/B immutable networking"/></div><p>Releases will alternate between <span class="strong"><strong>Subnet A Application1</strong></span> and <span class="strong"><strong>Subnet B Application1</strong></span> for every release, building the network from source control each time and cleaning up the previous release each time.</p></div><div class="section" title="The clean-up of redundant firewall rules"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec06"/>The clean-up of redundant firewall rules</h3></div></div></div><p>One of the major tech debt issues with firewalls is that over time they accumulate lots of out of date ACL rules as applications are retired or network connectivity changes. It is often a <a id="id548" class="indexterm"/>risk to do clean-up as network engineers are scared that they will potentially cause an outage. As a result, manual clean-up of firewall rules is required by the network team.</p><p>When utilizing A/B immutable network deployments, egress and ingress policies are associated with subnets, meaning that in Nuage VSP when a subnet is deleted, all ACL policies associated with that subnet will be automatically cleaned up too as part of the release process.</p><p>In the following example, <span class="strong"><strong>Subnet A Application1</strong></span> has the following connectivity, so when the subnet is deleted as part of the release process, all these subnet-specific ACL rules will be cleaned up:</p><div class="mediaobject"><img src="graphics/B05559_06_28.jpg" alt="The clean-up of redundant firewall rules"/></div><p>It is important to note that as ACL rules exist subnet to zone for application dependencies, <a id="id549" class="indexterm"/>if the A subnet deployment is in service, then the B subnet deployment will be brought up in parallel with its associated ACL Ingress and Egress rules to replace the A deployment.</p><p>All applications dependent on <span class="strong"><strong>Application1</strong></span> will be required to have an ACL rule pointing at the zone rather than the subnet, this means they will not lose connectivity to the application as their rules will be zone-dependent rather than subnet-dependent. Having subnet to subnet rules would not work in an immutable subnet model.</p><p>To illustrate this, in the following example, currently deployed subnet <span class="strong"><strong>Application1</strong></span> has a subnet to zone ACL rule to connect to <span class="strong"><strong>Application2</strong></span>. So, despite <span class="strong"><strong>Application2</strong></span> Egress and Ingress policies alternating between A and B deployments each time it is released as shown in the following diagram:</p><div class="mediaobject"><img src="graphics/B05559_06_29.jpg" alt="The clean-up of redundant firewall rules"/></div><p>The required <a id="id550" class="indexterm"/>ACL rules are always available for <span class="strong"><strong>Application1</strong></span> as a dependency as it subscribes to connectivity at the zone level as opposed to the subnet level:</p><div class="mediaobject"><img src="graphics/B05559_06_30.jpg" alt="The clean-up of redundant firewall rules"/></div></div><div class="section" title="Application decommissioning"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec07"/>Application decommissioning</h3></div></div></div><p>The use of immutable subnets makes the decommissioning of applications easy when they are no <a id="id551" class="indexterm"/>longer required. The clean-up logic already exists for subnets and associated ACL rules so that already-created automation can be re-used to do a full clean-up of the microservice application when it needs to be retired.</p><p>A clean-up pipeline can easily be provided by the operations and networking team for development teams to clean up applications that are no longer required. Their allocated subnet ranges can then be released by the IPAM solution so they are available to new microservice applications that need to be on-boarded onto the platform.</p></div></div><div class="section" title="Using Ansible to orchestrate SDN controllers"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec79"/>Using Ansible to orchestrate SDN controllers</h2></div></div></div><p>Ansible, as discussed in <a class="link" href="ch05.html" title="Chapter 5. Orchestrating Load Balancers Using Ansible">Chapter 5</a>, <span class="emphasis"><em>Orchestrating Load Balancers Using Ansible</em></span>, can be used to issue and <a id="id552" class="indexterm"/>configure <a id="id553" class="indexterm"/>servers as well as issue commands directly to an <span class="strong"><strong>SDK </strong></span>or<span class="strong"><strong> REST</strong></span> <span class="strong"><strong>API</strong></span>:</p><div class="mediaobject"><img src="graphics/B05559_06_38.jpg" alt="Using Ansible to orchestrate SDN controllers"/></div><p>This is very useful when orchestrating SDN controllers that provide Restful API endpoints and an <a id="id554" class="indexterm"/>array of SDKs to control software-<a id="id555" class="indexterm"/>defined object models that allow network operators to automate all network operations.</p><p>In terms of the Nuage VSP platform, the VSD component, which builds the overlay network, is all REST API calls behind the scenes, so all operations can be orchestrated using the Nuage Java or Python SDK, which wrap REST API calls.</p><p>The Nuage VSPK SDK would simply need to be installed on the Ansible control host, and then it can be used to orchestrate Nuage. As Ansible is written in Python, modules can be easily created to orchestrate each object model in the Nuage entity tree.</p><p>Using the Nuage VSPK modules could alternately be written in any programming language that is available, such as Java, but Ansible's boilerplate for Python is probably the simplest way of creating modules.</p><p>The Nuage VSPK object model has parent and child relationships between entities, so lookups need to be done on parent objects to return the child entities using the unique identifier associated with the entity.</p><p>The following example <a id="id556" class="indexterm"/>highlights the list of operations required to build the Nuage VSPK object tree:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">A new Nuage <code class="literal">session</code> is started.</li><li class="listitem">A <code class="literal">user</code> is used to create a child <code class="literal">enterprises</code>.</li><li class="listitem">A <code class="literal">domain_templates</code> is <a id="id557" class="indexterm"/>created as a child of the enterprise.</li><li class="listitem">A <code class="literal">domains</code> is an <a id="id558" class="indexterm"/>instantiated as child of the domain template.</li><li class="listitem">A child <code class="literal">zone</code> is created against the domain.</li><li class="listitem">A child <code class="literal">subnet</code> is created against the zone.<div class="mediaobject"><img src="graphics/B05559_06_32.jpg" alt="Using Ansible to orchestrate SDN controllers"/></div></li></ol></div><div class="section" title="Using SDN for disaster recovery"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec08"/>Using SDN for disaster recovery</h3></div></div></div><p>One of the main benefits of using Ansible for orchestration is that it can be used to create a set of day one playbooks to <a id="id559" class="indexterm"/>build out the initial network prior to it being used for self-service by developers. So the initial setup of the Nuage <span class="strong"><strong>organization</strong></span>, <span class="strong"><strong>Company L3 Domain Template</strong></span>, and layer 3 domains can be created among any other necessary operations as a day one playbook or role.</p><p>The Nuage Python VSPK can be utilized to easily create the organization called <span class="strong"><strong>Company</strong></span>, layer 3 domain template called <span class="strong"><strong>L3 Domain Template</strong></span>, and two layer 3 domains called <span class="strong"><strong>Test</strong></span> and <span class="strong"><strong>Prod</strong></span> as per the Nuage VSPK object model, as shown in the  following screenshot:</p><div class="mediaobject"><img src="graphics/B05559_06_33.jpg" alt="Using SDN for disaster recovery"/></div><p>Each of these Python commands can easily be wrapped in Ansible to create a set of modules to create a day one playbook utilizing <code class="literal">delegate_to</code> localhost. which will execute each module on the Ansible control host and then connect to the Nuage APIs.</p><p>Each module, by <a id="id560" class="indexterm"/>default, should be written so that it is idempotent and detects if the entity exists, before issuing a <code class="literal">Create</code> command. If the entity already exists, then it shouldn't issue a <code class="literal">Create</code> command if the overlay network is already in the desired state.</p><p>The day one playbook can be used to build the whole network from scratch in the event of a disaster if the whole network needs to be restored. The day one playbook should be stored in source control. While each deployment pipeline will build the application zones, subnets, and virtual machines under the initially defined structure.</p><p>A leaking domain governing legacy network connectivity and leaking domain association can also be added to the day one playbook if required.</p></div><div class="section" title="Storing A/B subnets and ACL rules in YAML files"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec09"/>Storing A/B subnets and ACL rules in YAML files</h3></div></div></div><p>Ansible can also be utilized to store self-service subnet and ACL rule information in <code class="literal">var</code> files that will be <a id="id561" class="indexterm"/>called from a set of self-service <a id="id562" class="indexterm"/>playbooks as part of each development <a id="id563" class="indexterm"/>team's deployment pipelines. Each application environment can be stored in a set of <code class="literal">var</code> files defining each of the A/B subnets.</p><p>A playbook to create <a id="id564" class="indexterm"/>A or B subnets would be used to run <code class="literal">delegate_to</code> localhost to carry out the creation actions against the Nuage VSD API.</p><p>The playbook would be set up to do the following things:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create the zone, if one has not already been created.</li><li class="listitem">Create the subnet in Nuage mapped to OpenStack using a subnet YAML file.</li><li class="listitem">Apply ACL policies for Ingress and Egress rules to the policies applying them directly to the subnet.</li></ol></div><p>As with the day one playbook, unique modules can be written for each of the VSPK commands; in this example, the Python VSPK creates a zone called <span class="strong"><strong>Application1</strong></span> and a subnet called <span class="strong"><strong>Subnet A Application1</strong></span>:</p><div class="mediaobject"><img src="graphics/B05559_06_34.jpg" alt="Storing A/B subnets and ACL rules in YAML files"/></div><p>So these commands can also be wrapped in Ansible modules, should be completely idempotent, and the <a id="id565" class="indexterm"/>desired state of the network <a id="id566" class="indexterm"/>is determined by the <code class="literal">var</code> files that are stored in source control.</p><p>The logic in the <a id="id567" class="indexterm"/>playbook would load the <code class="literal">var</code> files by pulling <a id="id568" class="indexterm"/>them from source control at deployment time. The playbook would then use the Jinja2 filter conditions to detect if either the A or B subnet or neither was present using the when conditions.</p><p>If neither subnet was present, subnet A would be created, or if subnet A was present, then subnet B would be created.</p><p>The playbook could read this information from the environment specific <code class="literal">var</code> file that is specified in the following screenshot. As it is idempotent, it will run over the zone, creating it if it doesn't already exist, and use the jinja2 playbook when conditions to either create subnet A or B:</p><div class="mediaobject"><img src="graphics/B05559_06_35.jpg" alt="Storing A/B subnets and ACL rules in YAML files"/></div><p>A unique set of A and B subnets would be checked into source control as a prerequisite for every required environment, with one or more environments per layer 3 domain.</p><p>ACL rules should ideally be consistent across all environments encapsulated in a layer 3 domain, so an explicit set of ACL rules would be created and assigned to the application's unique policy for Ingress and Egress rules that would span all environments.</p><p>Each environment could have its own unique policy for Egress and Ingress per layer 3 subnet. The <a id="id569" class="indexterm"/>Ansible playbook could then <a id="id570" class="indexterm"/>append a unique identifier for the environment to the policy name if multiple environments existed under the <span class="strong"><strong>Test</strong></span> layer 3 domain to <a id="id571" class="indexterm"/>server integration, UAT, or other test environments.</p><p>The unique <a id="id572" class="indexterm"/>ACL rules for an application can be filled in by development teams as part of the on-boarding to the new platform based on the minimum connectivity required to make the application function, with a deny all applied to the layer 3 domain template.</p><p>The ACL rules should always be subnet to zone for inter-dependencies and each ACL rule will be created with the subnet as the source, so that when subnets are destroyed, the ACL rules will automatically be cleaned up.</p><p>An example of how the self-service ACL rules file would look is displayed as follows It would create two ingress rules and one Egress rule against the <span class="strong"><strong>Application1</strong></span> policy:</p><div class="mediaobject"><img src="graphics/B05559_06_36.jpg" alt="Storing A/B subnets and ACL rules in YAML files"/></div><p>The self-service playbook could be provided to development teams so that they always have a <a id="id573" class="indexterm"/>standard way to create zones and <a id="id574" class="indexterm"/>subnets. The YAML structure of the <code class="literal">var</code> files will <a id="id575" class="indexterm"/>also provide templates of what the desired state of the network should be. This means that <a id="id576" class="indexterm"/>pointing the automated pipelines at another Nuage endpoint would mean the whole network could be built out programmatically from source control.</p></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec36"/>Summary</h1></div></div></div><p>In this chapter, we have looked at different networking operations that SDN controllers can help automate, and sought to debunk some of the common misconceptions associated with software-defined networking.</p><p>We then looked at ways in which companies can benefit from using software-defined networking and looked at ways in which SDN solutions can help solve some of the challenges associated with network operations.</p><p>The chapter then focused on ways that network operations need to adapt and embrace automation so development teams can self-serve a subset of different networking tasks, and ways in which networking can be divided and responsibilities shared. We then focused on the benefits of immutable A/B networking and how it can help simplify the network and build consistent programmatically controlled networks while keeping firewall rules clean.</p><p>In this chapter, you should have learned why software-defined networking is important to organizations looking to scale network operations. We have also covered ways in which overlay network object models can be utilized by microservice applications and the benefits of immutable networking and A/B subnets.</p><p>Key takeaways from this chapter also include different ways that SDN controllers can help network operators to build out day one networks, which pieces of network operations can be made self-service, and the ways in which Ansible can be used to programmatically control network operations using Rest API calls or an SDK.</p><p>In the next chapter, we will look at continuous integration and how network operations can take some of the best practices from development teams and apply them to networking operations, so that networking is versioned properly and can be used to roll forward and roll back changes.</p><p>Once we have established a basis for continuous integration, we will move onto chapters that cover network testing and Continuous Delivery, which will outline a set of best practices that should allow network teams to integrate network automation into deployment pipelines.</p></div></body></html>