- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing Applications Running in Containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we have learned how we can containerize our applications
    written in any language, such as Node.js, Python, Java, C#, and .NET. We all know
    that just writing code and then shipping it to production is not enough. We also
    need to guarantee that the code is error-free and that it does what it is supposed
    to do. This is commonly subsumed under the term **quality assurance**, or **QA**
    for short.
  prefs: []
  type: TYPE_NORMAL
- en: It has been proven in practice over and over again that fixing a bug in an application
    that has been discovered in production as opposed to during development is very
    costly. We want to avoid this. The most cost-effective way to do so is to have
    the developer who writes the code also write automated tests that make sure the
    new or changed code is of high quality and performs exactly as specified in the
    acceptance criteria of the business requirement or feature specification.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a list of the topics we are going to discuss in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The benefits of testing applications running in containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different types of testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Commonly used tools and technologies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practices for setting up a testing environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tips for debugging and troubleshooting issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Challenges and considerations when testing applications running in containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Case studies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After reading this chapter, you will be able to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Explain the benefits of testing applications running in containers to an interested
    layperson
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up a productive environment that allows you to write and execute tests for
    applications or services running in containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Develop unit and integration tests for code running in a container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run your unit and integration tests in a container with the application code
    under test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run a dedicated container with functional tests that act on your application
    as a black box
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manage application dependencies and create test data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you need Docker Desktop, a terminal, and VS Code installed
    on your Mac, Windows, or Linux machine. As we will work with code, you should
    prepare a chapter folder in the code repository you cloned from GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the folder to which you cloned the GitHub repository accompanying
    this book. Normally, you do this as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a chapter folder in this directory and navigate to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As always, you can find complete sample solutions for all the exercises we will
    do in this chapter in the `sample-solutions/ch07` subfolder.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of testing applications in containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are discussing the benefits of testing applications in containers,
    including the ability to replicate production environments, ease of configuration
    and setup, and faster test execution.
  prefs: []
  type: TYPE_NORMAL
- en: But before we start, let’s pause for a second and ask ourselves, why do we care
    to test at all?
  prefs: []
  type: TYPE_NORMAL
- en: Why do we test?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every person working in any role in software development is aware that one needs
    to implement and ship new or changed application features at a fast cadence. There
    is constant pressure to implement new code and ship it as quickly as possible
    to production. But business analysts that write the feature specifications and
    software engineers that write the actual code implementing the specifications
    are just human beings. Human beings working under a lot of pressure tend to make
    mistakes. These mistakes can be subtle, or they can be quite substantial. Those
    mistakes will manifest themselves in the application running in production. Our
    customers will discover them, and this will have consequences.
  prefs: []
  type: TYPE_NORMAL
- en: Manual versus automated testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most companies that write commercial applications will have a team of manual
    software testers. These people will take the newest version of the application
    that product engineering has prepared for them and execute a suite of manual regression
    tests against this application. If a manual tester discovers a bug, they will
    report it in a tool such as Jira as a bug ticket, where they will ideally write
    down all the necessary details that matter for the developer who will have to
    fix the bug. This includes the exact version of the application tested, the steps
    that the tester took before the bug was detected, and some evidence of the bug,
    such as screenshots, error messages, stack traces, and log entries. These tickets
    written by manual testers will become part of the backlog of product engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Product engineering will then, together with the testers, triage all the new
    bug tickets on a regular basis, say daily, and decide how quickly a particular
    bug needs to be addressed. Usually, the classification of P1, P2, P3, and P4 is
    used, where P1 is a defect of the highest severity that needs to be fixed immediately,
    and P4 is a bug that is of low priority and can be dealt with whenever the team
    has time.
  prefs: []
  type: TYPE_NORMAL
- en: If the application is a typical enterprise application consisting of many services
    all running in the cloud, then the testers need a special environment where they
    can perform their regression testing. This environment is often called **user
    acceptance testing**, or **UAT** for short. A full test suite for such an enterprise
    application usually consists of several hundred test cases. To perform a single
    test case takes a manual tester a considerable amount of time. It is not unheard
    of that a team of dedicated manual testers needs a couple of weeks to perform
    a full test run. During this time, the UAT environment is blocked. No new version
    can be deployed to this environment, because otherwise the testers would have
    to restart their regression testing. Each change in the application can introduce
    new bugs, and we can only be certain to catch them all if we execute the whole
    suite of regression tests on each new version.
  prefs: []
  type: TYPE_NORMAL
- en: Only after the manual testers have run through all regression tests, and only
    if no more severe bugs have been discovered, can the current version of the application
    be shipped to production.
  prefs: []
  type: TYPE_NORMAL
- en: I bet you can imagine that having UAT blocked for several weeks at a time can
    introduce some significant problems in the software development process. Your
    many product engineering teams will have accumulated a lot of new code in the
    form of new features and bug fixes that are blocked from being shipped to production
    since the manual testers are still testing the previous version. But accumulating
    a lot of code changes does, at the same time, increase risk. To ship a piece of
    software that has undergone many changes is riskier than if we continuously ship
    new versions with minimal changes to production.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only real solution to this problem is to shorten the regression test cycle.
    We need to shorten it from weeks to minutes or a small number of hours. This way,
    we can test and ship small batches of changes in a continuous fashion. But no
    human being is able to test so fast. The solution is to exclusively use automated
    testing. And yes, I mean it: we should rely exclusively on automated regression
    and acceptance testing.'
  prefs: []
  type: TYPE_NORMAL
- en: What did we learn? Manual testing is not scalable, it is super boring, since
    the testers have to repeat the same tests over and over again, and it is error
    prone, since everything humans do is not automated and thus not exactly repeatable
    every time.
  prefs: []
  type: TYPE_NORMAL
- en: Does this mean we have to fire all manual testers? Not necessarily. Manual testers
    should not perform acceptance and regression tests but rather exploratory tests.
    Manual testers are human beings, and they should leverage that fact and their
    creativity to discover yet undiscovered potential defects in the application.
    As the term *exploratory testing* implies, these tests are not following a particular
    script, but are rather random and only guided by the professional experience of
    the tester and their understanding of the business domain for which the application
    has been written. If the tester discovers a bug, they write a ticket for it, which
    then will be triaged and flown into the backlog of the development teams.
  prefs: []
  type: TYPE_NORMAL
- en: Why do we test in containers?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several reasons why it is often useful to run tests in containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Isolation**: Running tests in containers can provide a level of isolation
    between the test environment and the host system, which can be useful for ensuring
    that the test results are consistent and repeatable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Environment consistency**: Containers allow you to package the entire test
    environment (including dependencies, libraries, and configuration) in a self-contained
    unit, which can help to ensure that the test environment is consistent across
    different development environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ease of use**: Containers can make it easier to set up and run tests, as
    you don’t have to manually install and configure all of the required dependencies
    and libraries on the host system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Portability**: Containers can be easily moved between different environments,
    which can be useful for running tests in different environments or on different
    platforms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: Containers can make it easier to scale up your test infrastructure
    by allowing you to run tests in parallel or on multiple machines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, running tests in containers can help to improve the reliability, consistency,
    and scalability of the testing process and can make it easier to set up and maintain
    a testing environment that is isolated from the host system.
  prefs: []
  type: TYPE_NORMAL
- en: Different types of testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section gives an overview of different types of testing that can be performed
    on applications running in containers, including unit tests, integration tests,
    and acceptance tests.
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A unit test’s primary objective is to validate the functionality of a *unit*,
    or tiny, isolated portion of code. In order to check that the code is accurate
    and operates as expected, developers frequently build unit tests as they create
    or modify the code. These tests are then routinely executed as part of the development
    process.
  prefs: []
  type: TYPE_NORMAL
- en: With no reliance on other resources or components, unit tests are made to test
    distinct pieces of code in isolation. This enables developers to find and quickly
    solve bugs in their code and makes them quick and simple to run.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, tools and testing frameworks that facilitate the creation, running,
    and reporting of unit tests are used to generate unit tests. These tools frequently
    offer capabilities such as automatic test discovery, test execution, and test
    results reporting, and they enable developers to create unit tests using a particular
    syntax or structure.
  prefs: []
  type: TYPE_NORMAL
- en: A thorough testing approach should include unit tests, since they enable developers
    to verify that their code is valid and works as intended at the most granular
    level. Normally, they are executed as a part of a **continuous integration** (**CI**)
    process, which is a workflow in which code changes are automatically executed
    each time they are committed to a version control system.
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Software testing called *integration testing* examines how well various systems
    or components function together as a whole. It usually follows unit testing and
    entails examining how various parts of an application or system interact with
    one another.
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests are created to examine how well various units or components
    interact together. They are frequently used to confirm that an application’s or
    system’s various components can function as intended. Testing the integration
    of several software components or the integration of a software program with external
    resources such as databases or APIs are examples of this.
  prefs: []
  type: TYPE_NORMAL
- en: As many components or systems need to be set up and configured in order to execute
    the tests, integration tests are typically more complicated and time-consuming
    than unit tests. In order to enable the execution and reporting of the tests,
    they could also call for the employment of specialist testing tools and frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests, like unit tests, are a crucial component of a thorough testing
    approach, because they enable developers to confirm that several systems or components
    can function together as intended.
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Software testing of this kind, known as *acceptance testing*, ensures that a
    system or application is suitable for its intended use and that it satisfies all
    of the requirements. It usually comes after all other types of testing (such as
    unit testing and integration testing) and is the last step in the testing procedure.
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance tests are typically developed and carried out by a different team
    or group of testers who are tasked with assessing the system or application from
    the viewpoint of the end user. These tests are intended to make sure that the
    system or program is simple to use, fits the demands of the intended users, and
    is user-friendly.
  prefs: []
  type: TYPE_NORMAL
- en: Functional testing (to ensure that the application or system performs the required
    functions correctly), usability testing (to make sure that the application or
    system is easy to use), and performance testing are just a few examples of the
    different types of testing that may be included in acceptance tests (to verify
    that the application or system performs well under different load conditions).
  prefs: []
  type: TYPE_NORMAL
- en: Acceptance testing is a crucial step in the software development process, since
    it enables developers to confirm that the system or application is ready for deployment
    and satisfies the needs of the intended customers. Although it is highly recommended
    to employ automated acceptance testing technologies to assist the testing process,
    it is often carried out manually by testers.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will look at a special type of acceptance test called *black
    box tests*. The main differentiator compared to unit and integration tests is
    that these black box tests look at the system under tests from a decidedly business-oriented
    perspective. Ideally, acceptance tests, and with it black box tests, reflect the
    acceptance criteria to be found in the feature specifications written by business
    analysts or product owners. Most often, acceptance tests are written in a way
    that they look at the component to be tested as a black box. The internals of
    this component do not and should not matter. The test code only ever accesses
    the component or system under test via its public interfaces. Typically, public
    interfaces are APIs or messages that the component consumes or produces.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – Acceptance test interacting with the system under test](img/B19199_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Acceptance test interacting with the system under test
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding figure, we can see how the test code is structured in the popular
    format of **Arrange-Act-Assert**, or **AAA**. First, we set up the boundary conditions
    (arrange). Next, we specify the action to exercise on the system under test (act).
    Finally, we verify that the outcome of the action is as expected (assert). The
    **system under test** (**SUT**) is the component that has a public interface in
    the form of either a REST API and/or messages that it consumes from a message
    bus. The SUT, in most cases, also has a database where it stores it state.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will present tools and technologies used for testing.
  prefs: []
  type: TYPE_NORMAL
- en: Commonly used tools and technologies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s now discuss the tools and technologies that are commonly used for testing
    applications running in containers, such as Docker, Kubernetes, and **continuous
    integration and delivery** (**CI/CD**) platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a sample component
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we want to implement a sample component that we are later going
    to use to demonstrate how we can write and execute tests for, and, specifically,
    how we can combine the advantage of automated tests and the use of Docker containers.
    We will implement the sample component using recent versions of Java and Spring
    Boot.
  prefs: []
  type: TYPE_NORMAL
- en: 'This sample component represents a simple REST API with some CRUD logic behind
    it. The tasks of creating and managing lists of animal species and associated
    races are simple enough to not warrant more complicated modeling. For simplicity,
    we are working with the in-memory database H2\. This means that upon each restart
    of the component, the previous data is wiped out. If you want to change this,
    you can configure H2 to use a backing file for persistence instead:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the **spring initializr** page at [https://start.spring.io](https://start.spring.io)
    to bootstrap the Java project. After configuring everything, the page should look
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Bootstrapping the library project](img/B19199_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Bootstrapping the library project
  prefs: []
  type: TYPE_NORMAL
- en: Note how we have added the four dependencies listed on the right-hand side of
    the preceding figure.
  prefs: []
  type: TYPE_NORMAL
- en: Download the bootstrap code and unzip the file into the chapter folder, `.../ch07`.
    You should now have a subfolder called `library` containing the code we can use
    as a starting point to implement our API.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the project in VS Code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Locate the `LibraryApplication.java` file in the `src/main/java/com/example/library`
    folder. It’s the typical start class containing the `main` function for a Spring
    Boot-based Java application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inside this folder, create three subfolders called `controllers`, `models`,
    and `repositories`, respectively. They will contain the logic for our library.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Project structure of the library API](img/B19199_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Project structure of the library API
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first define the models we’re using in our application. To the `models`
    folder, add the following simple data classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To a file called `Race.java`, add the following content:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.4 – The Race data class](img/B19199_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – The Race data class
  prefs: []
  type: TYPE_NORMAL
- en: 'To a file called `Species.java`, add this content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.5 – The Species data class](img/B19199_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 – The Species data class
  prefs: []
  type: TYPE_NORMAL
- en: Note how we use the `@Entity` annotation to mark these classes as (database)
    entities, and we decorate their respective `id` properties with the `@Id` annotation
    to tell Spring Boot that this property represents the unique ID of each entity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we are going to implement the repositories we’re going to use to persist
    data to and retrieve data from our database. To the `repositories` folder, add
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A file called `RaceRepository.java` with this content:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.6 – Code for the race repository](img/B19199_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 – Code for the race repository
  prefs: []
  type: TYPE_NORMAL
- en: Note how on line 10, we add a custom `findBySpeciesId` method, which will allow
    us to retrieve all races assigned to a given `speciesId`.
  prefs: []
  type: TYPE_NORMAL
- en: 'A file called `SpeciesRepository.java` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.7 – Code for the species repository](img/B19199_07_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 – Code for the species repository
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we define the two REST controllers through which we can interact with
    the application. To the `controllers` folder, add the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A file called `RacesController.java` with this content:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.8 – Code for the races controller](img/B19199_07_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 – Code for the races controller
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the full code here: [https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/blob/main/sample-solutions/ch07/library/src/main/java/com/example/library/controllers/RacesController.java](https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/blob/main/sample-solutions/ch07/library/src/main/java/com/example/library/controllers/RacesController.java).'
  prefs: []
  type: TYPE_NORMAL
- en: 'A file called `SpeciesController.java` with this code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.9 – Code for the species controller](img/B19199_07_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 – Code for the species controller
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the full code here: [https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/blob/main/sample-solutions/ch07/library/src/main/java/com/example/library/controllers/SpeciesController.java](https://github.com/PacktPublishing/The-Ultimate-Docker-Container-Book/blob/main/sample-solutions/ch07/library/src/main/java/com/example/library/controllers/SpeciesController.java).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we need to do some application configuration. We can do so in the
    `application.properties` file, which you can find in the `src/main/resources`
    folder. Add this content to it, which configures the database we are going to
    use for this example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.10 – Application configuration](img/B19199_07_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.10 – Application configuration
  prefs: []
  type: TYPE_NORMAL
- en: We are using the H2 in-memory database with a username of `sa` and no password.
    We are also making sure to enable the H2 console in our application to have an
    easy way to inspect the data from our browser (line 6).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now open the `LibraryApplication` class and click the **Run** link above the
    main method to start the application. Observe the output generated in the terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.11 – Logging the output of the running library application](img/B19199_07_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 – Logging the output of the running library application
  prefs: []
  type: TYPE_NORMAL
- en: Read through the log output and try to make sense of each line. The second-to-last
    line of the preceding output is telling us that the application can be accessed
    at port `8080`, which is the default for Spring Boot applications. Also note the
    line where it says `H2 console available at ‘/h2-console’. Database available
    at ‘jdbc:h2:mem:inventory’`. This indicates that we can now open a browser at
    `localhost:8080/h2-console` to open the H2 console and, through it, access our
    in-memory database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the Thunder client in VS Code, Postman, or the `curl` command in the terminal
    to add a species to the database. Here we are using `curl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The response should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Use `curl` (or any other tool) again to list the species stored in the system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: It is a JSON array with exactly one element.
  prefs: []
  type: TYPE_NORMAL
- en: Try all the other `REST` calls that the two controllers we implemented support,
    such as `PUT` to update an existing species and `GET`, `POST`, and `PUT` for the
    `/``races` endpoint.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When done, make sure to stop the application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we need to package the application into a container and run it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a Dockerfile to the root of the library project with this content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.12 – Dockerfile for the library component](img/B19199_07_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.12 – Dockerfile for the library component
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Docker image using this Dockerfile with this command executed from
    within the `ch07` folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run a container with this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Test that the component now running inside a container still works as expected
    by using the same commands as in the previous section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When done, stop the container with the library component. We suggest that you
    use the Docker plugin of VS Code to do so or the dashboard of Docker Desktop.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have a working example application, we can continue and discuss
    how we can test this REST API using unit, integration, and black box tests. Let’s
    start with the unit and/or integration tests.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing and running unit and integration tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have a working component, it is time to write some tests for it.
    In this section, we concentrate on unit and integration tests. Spring Boot makes
    it really simple to get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To the `src/test/java/com/example/library` folder, add a `LibraryUnitTests.java`
    file with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.13 – Sample unit test written for the library project](img/B19199_07_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.13 – Sample unit test written for the library project
  prefs: []
  type: TYPE_NORMAL
- en: Note how we have added a private `Calculator` class to our `Test` class. This
    is for demonstration purposes only and makes it easier to show how to write a
    unit test. Normally, one would test classes and their methods that are part of
    the code base.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: It is a good idea to always structure your tests in a similar way and make it
    easier for others (and yourself) to read and comprehend those tests. In this case,
    we have chosen the triple-A (AAA) syntax consisting of Arrange, Act, and Assert.
    Alternatively, you could use the Given-When-Then syntax.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have the **Test Runner for Java** extension installed on your VS Code
    editor, you should now see a green triangle next to the test method (line 19 in
    the preceding figure). Click it to run the test. As a result, you should see something
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.14 – Results of a first test run](img/B19199_07_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.14 – Results of a first test run
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, you can run the tests from the command line with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`$ ./``mvnw test`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s add a sample integration test. For this, add a file called `LibraryIntegrationTests.java`
    in the same folder as where you have put the unit tests. We will implement a test
    using the `MockMvc` helper class provided by Spring Boot to simulate that our
    application runs on a web server and we’re accessing it through its REST endpoints.
    Add the following content to the test class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.15 – Sample Integration Test written for the library project](img/B19199_07_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.15 – Sample Integration Test written for the library project
  prefs: []
  type: TYPE_NORMAL
- en: Run the preceding test the same way as you did with the unit test. Make sure
    the test passes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We have finished our preparation and are now ready to package the component
    into a container and run the unit and integration tests inside the same container.
    To do this, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s add a Dockerfile with the following content to the root of our library
    project. The content is the same that we already used in the previous Java example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.16 – Dockerfile for the library project](img/B19199_07_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.16 – Dockerfile for the library project
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, let’s build an image using this Dockerfile:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the tests in the container with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note the volume mapping we are using. We are sharing our local Maven repository
    at `$HOME/.m2` with the container, so when building the application, Maven does
    not have to download all dependencies first as they are already in our local cache.
    This improves the overall experience massively.
  prefs: []
  type: TYPE_NORMAL
- en: Also note how we override the `CMD` command in our Dockerfile (line 8 in the
    preceding figure) with `./mvnw test` to run the tests instead of running the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Observe the output generated. The last few lines of the output should look
    like this, indicating that tests were run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.17 – Output of a test run inside the container](img/B19199_07_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.17 – Output of a test run inside the container
  prefs: []
  type: TYPE_NORMAL
- en: In the same way that you have now run the unit and integration tests inside
    a container locally on your laptop, you can also run it during the CI phase of
    your CI/CD pipeline. A simple shell script is enough to automate what you just
    did manually.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing and running black box tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since black box tests have to deal with the SUT as a closed system, the tests
    should not run inside the same container as the component itself. It is instead
    recommended to run the test code in its own dedicated test container.
  prefs: []
  type: TYPE_NORMAL
- en: It is also recommended to not intermingle the code of black box tests and the
    component but to keep them strictly separate. We will demonstrate this by writing
    the tests in a different language than the component. This time, we will use C#.
    Any language will do such as Kotlin, Node.js, or Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we will use .NET and C# to implement the component tests:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From within the `ch07` folder, execute the following command to create a test
    project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will create a test project in the `library-component-tests` subfolder using
    the popular `xunit` test library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Try to run the tests with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The (shortened) output should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This indicates that all tests passed. Of course, by default, there exists only
    an empty sample test in the project at this time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open this project in VS Code with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Locate the `UnitTest1.cs` file and open it. At the top of the file, add this
    statement:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Right after the `namespace` declaration, add this record definition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now add a new method called `can_add_species`, looking like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.18 – Component test to add a species](img/B19199_07_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.18 – Component test to add a species
  prefs: []
  type: TYPE_NORMAL
- en: Here we are using the `HttpClient` class to post a data object of type `Species`
    to the `/species` endpoint. We are then asserting that the HTTP response code
    for the operation is `OK (200)`. Note how we are using the AAA convention to structure
    our test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add another method called `can_get_a_species_by_id` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.19 – Component test to read a species by ID](img/B19199_07_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.19 – Component test to read a species by ID
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you proceed and run the tests, make sure the `library` component is
    running and listening at port `8080`. Otherwise, the tests will fail, since nobody
    is listening at the expected endpoints. Use this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the tests with this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Make sure the two tests pass.
  prefs: []
  type: TYPE_NORMAL
- en: '`library` component.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When done, stop the `library` component.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we are going to show how we can run the tests in a container:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a Dockerfile with the following content to the root of the .NET test project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.20 – Dockerfile for the component tests](img/B19199_07_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.20 – Dockerfile for the component tests
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an image with this Dockerfile. From within the `ch07` folder, use this
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Double-check that we already have a Docker image created for the library component.
    If not, use this command to do so from within the `ch07` folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that we have a Docker image for the library component and one for the component
    tests, we need to run a container of each:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To run the library component, use this:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To run the component tests, use this command:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Observe that the tests are executed and are all passing.
  prefs: []
  type: TYPE_NORMAL
- en: When done, remove the two containers. Use your Docker plugin in VS Code or the
    dashboard of Docker Desktop to do so.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Well, that was quite a run. We have shown how to write unit and integration
    tests for a component written in Java and using Spring Boot 3\. We ran the tests
    natively on our laptop and also inside a container. Then we showed how to create
    some black box tests in .NET 7, C# and ran them against our library component.
    We did this again natively on our laptop and then ran the component and the black
    box tests each in their own container.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we are going to discuss how to best set up a testing environment.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for setting up a testing environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we want to list a few best practices for setting up a testing
    environment for applications running in containers, including considerations for
    network isolation, data management, and resource constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use a separate testing environment**: It is generally a good idea to use
    a separate testing environment for running tests in containers rather than running
    tests on the same host as your production environment. This can help to prevent
    any potential issues or disruptions from affecting your production environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Isolate the testing network**: To ensure that your testing environment is
    isolated from your production environment, it is a good idea to use a separate
    network for testing. This can be achieved by using a separate virtual network
    or by using network namespaces or overlays in your container runtime.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manage test data carefully**: When testing applications in containers, it
    is important to manage test data carefully to ensure that your tests are reliable
    and repeatable. This can involve using test data generation tools, snapshotting
    the test data, or using a separate test database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use resource constraints**: To ensure that your tests are reliable and consistent,
    it is a good idea to use resource constraints (e.g., CPU, memory) to limit the
    resources available to your containers. This can help to prevent resource contention
    and ensure that your tests are not impacted by external factors such as the load
    on the host system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use a container orchestration tool**: To manage a large number of containers
    and ensure that they are deployed and scaled consistently, it is a good idea to
    use a container orchestration tool such as Kubernetes or Docker Swarm. These tools
    can help to automate the process of deploying and scaling containers and can provide
    features such as automatic rollbacks and self-healing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitor the testing environment**: To ensure that your testing environment
    is running smoothly and to identify any issues that may arise, it is a good idea
    to use monitoring tools to track the performance and resource usage of your containers.
    This can help you to identify and fix any issues that may affect the reliability
    of your tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now when testing, you may face some troubles and hard-to-explain test failures.
    In the next section, we’re going to provide a few tips about what you can do in
    such a situation.
  prefs: []
  type: TYPE_NORMAL
- en: Tips for debugging and troubleshooting issues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we are running automated tests in our containerized environments, we may
    from time to time face seemingly weird behaviors and mysteriously failing tests.
    Here are some tips for debugging and troubleshooting issues that may arise when
    testing applications in containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker container logs` to view the logs for a specific container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use a debugger**: If the error message or log output is not sufficient to
    diagnose the problem, you can use a debugger to inspect the state of the application
    at runtime. Many IDEs, such as VS Code, which we use all the time, Visual Studio,
    and IntelliJ, have built-in support for debugging applications running in containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker container exec` to run commands inside the container and inspect its
    environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use a container runtime debugger**: Some container runtimes, such as Docker,
    provide tools for debugging issues with the container itself (e.g., resource usage
    and networking issues). These tools can be helpful for diagnosing issues that
    are specific to the container runtime.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use a containerized debugging environment**: If you are having difficulty
    reproducing the issue in a local development environment, you can use a containerized
    debugging environment (e.g., a debugger container) to replicate the production
    environment more closely.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Check for known issues**: If you are using third-party libraries or dependencies
    in your application, it is worth checking whether there are any known issues or
    bugs that could be causing the problem. Many libraries and dependencies maintain
    lists of known issues and workarounds on their website or in their documentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Get help**: If you are unable to diagnose the issue on your own, don’t hesitate
    to seek help from the community, for example, from Stack Overflow or the maintainers
    of the libraries and tools you are using. There are many resources available online.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s discuss a few challenges that may occur during testing and what we
    should consider when testing.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges and considerations when testing applications running in containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next to all the many advantages that testing applications running in containers
    brings to the table, we need to also have a brief discussion of the challenges
    and considerations involved in this type of testing, such as dealing with dependencies
    and managing test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Isolation**: Testing applications in containers can provide a level of isolation
    between the test environment and the host system, which can be useful for ensuring
    that the test results are consistent and repeatable. However, this isolation can
    also make it more difficult to debug issues and identify the root cause of problems,
    as you may not have access to the host system and its resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Environment consistency**: Ensuring that the test environment is consistent
    across different development environments can be a challenge when using containers.
    Differences in the host system, container runtime, and network configuration can
    all impact the behavior of the application and the test results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data management**: Managing test data in a containerized environment can
    be challenging, as you may need to ensure that the test data is consistent and
    available to all containers, or that it is properly isolated and not shared between
    tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource constraints**: Testing applications in containers can be resource-intensive,
    as you may need to run multiple containers in parallel to test different scenarios.
    This can lead to resource contention and may require careful resource management
    to ensure that your tests are reliable and consistent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration testing**: Testing the integration between multiple containers
    can be challenging, as you may need to coordinate the startup and shutdown of
    multiple containers and ensure that they can communicate with each other.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance testing**: Testing the performance of applications running in
    containers can be difficult, as the performance may be impacted by the host system,
    the container runtime, and the network configuration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, testing applications running in containers requires careful planning
    and consideration to ensure that the test environment is consistent and reliable,
    and to ensure that the test results are meaningful and actionable.
  prefs: []
  type: TYPE_NORMAL
- en: Before we end this chapter, let’s look at a few case studies where companies
    are using containerized tests.
  prefs: []
  type: TYPE_NORMAL
- en: Case studies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this last section of the chapter, we present a few case studies and examples
    of organizations that have successfully implemented testing strategies for applications
    running in containers:'
  prefs: []
  type: TYPE_NORMAL
- en: An automated testing technique was introduced by a well-known online shop to
    boost the effectiveness and efficiency of its software development process. The
    company was able to considerably reduce the time and effort needed to test its
    applications by automating the execution of functional, integration, and acceptance
    tests. As a result, it was able to provide customers with new features and upgrades
    more rapidly and reliably.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Automated testing was used by a financial services company to enhance the dependability
    and stability of their trading platform. The business was able to find and fix
    problems early in the development process by automating the execution of unit,
    integration, and acceptance tests, minimizing the risk of downtime and enhancing
    customer satisfaction.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Automated testing was used by a healthcare organization to guarantee the precision
    and dependability of its **electronic medical record** (**EMR**) system. The business
    was able to swiftly identify and address problems by automating the execution
    of functional and acceptability tests, increasing the EMR system’s dependability
    and trustworthiness, and lowering the risk of mistakes and patient harm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The advantages of automated testing, such as better quality, quicker development
    and deployment cycles, increased reliability, and higher customer happiness, are
    illustrated by these case studies.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the benefits of testing applications running
    in containers, discussed the different types of testing, presented some of the
    tools and technologies commonly used for testing, as well as best practices for
    setting up a testing environment. We also presented a list of tips for debugging
    and troubleshooting issues, talked about challenges and considerations when testing
    applications running in containers, and concluded the chapter with a list of case
    studies.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will introduce miscellaneous tips, tricks, and concepts
    useful when containerizing complex distributed applications or when using Docker
    to automate sophisticated tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To assess your learning, please try to answer the following questions before
    you proceed to the next chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: How do we run unit tests for an application inside a container?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Should the Docker images that we use in production contain test code? Justify
    your answer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Where do we typically run unit and integration tests that run inside a container?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List a few advantages of running unit and integration tests in containers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are a few challenges you may face if running tests in containers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are sample answers to the questions of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have learned how to run an application in a container. We have seen examples
    written in Node.js, Python, Java, and .NET C#. We have learned how the Dockerfile
    must look to create an image. Specifically, we have learned how to define the
    startup command to execute when a container is created from such an image. In
    the case of a Java application, this could be as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For a Node.js application, it could be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: To run the unit tests for the application, we just have to use a different startup
    command.
  prefs: []
  type: TYPE_NORMAL
- en: 'We strongly advise against shipping test code to a production environment.
    Tests bloat the Docker image, which has several negative side effects, such as
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Providing a bigger surface for hacker attacks
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Longer startup times for the container since it takes longer to load an image
    from storage into the memory of the container host
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Longer download times and higher network usage due to the increased size of
    the image
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit and integration tests are typically run on the developer’s local machine
    before they push code to a code repository such as GitHub. Once the code is pushed
    to GitHub or any other remote code repository, usually the CI/CD pipeline kicks
    in and the CI stage is executed. Part of this stage is the execution of all unit
    and integration tests against the application. Usually, this is performed on a
    so-called build agent. In many cases, this is a sandbox environment where Docker
    containers can be run. Thus, the CI stage uses the same technique to run the tests
    in the build agent as a developer would do locally. It is important to note that
    tests other than some special smoke tests are never run in a production environment,
    since this could have undesired side effects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: One of the most important advantages of running tests in containers is the isolation
    aspect. We can run the tests on any environment able to run containers and do
    not have to worry about installing frameworks or libraries on the hosting machine
    first.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Another important advantage is that running tests in containers makes them repeatable
    out of the box. Each time a container containing the application code and the
    tests are started, the boundary conditions are the same. With this, we guarantee
    consistency in the test execution. Were we to run the tests natively on the host,
    we would have a harder time guaranteeing this consistency.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some challenges we may face when running our tests inside containers are as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It may be harder to troubleshoot and debug failing tests
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration testing can be more challenging when several containers are involved
    in the necessary setup
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Resources such as CPU, RAM, and network bandwidth can be limited in a containerized
    environment (via cgroup settings) and thus negatively impact your test runs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
