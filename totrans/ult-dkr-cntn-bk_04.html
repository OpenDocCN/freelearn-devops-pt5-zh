<html><head></head><body>
<div><div><h1 class="chapter-number" id="_idParaDest-86"><a id="_idTextAnchor083"/>4</h1>
<h1 id="_idParaDest-87"><a id="_idTextAnchor084"/>Creating and Managing Container Images</h1>
<p>In the previous chapter, we learned what containers are and how to run, stop, remove, list, and inspect them. We extracted the logging information of some containers, ran other processes inside an already running container, and finally, we dived deep into the anatomy of containers. Whenever we ran a container, we created it using a container image. In this chapter, we will familiarize ourselves with these container images. We will learn what they are, how to create them, and how to distribute them.</p>
<p>This chapter will cover the following topics:</p>
<ul>
<li>What are images?</li>
<li>Creating images</li>
<li>Lift and shift – containerizing a legacy app</li>
<li>Sharing or shipping images</li>
</ul>
<p>After completing this chapter, you will be able to do the following:</p>
<ul>
<li>Name three of the most important characteristics of a container image</li>
<li>Create a custom image by interactively changing the container layer and committing it</li>
<li>Author a simple Dockerfile to generate a custom image</li>
<li>Export an existing image using <code>docker image save</code> and import it into another Docker host using <code>docker </code><code>image load</code></li>
<li>Write a two-step Dockerfile that minimizes the size of the resulting image by only including the resulting artifacts in the final image</li>
</ul>
<h1 id="_idParaDest-88"><a id="_idTextAnchor085"/>What are images?</h1>
<p>In Linux, everything<a id="_idIndexMarker223"/> is a file. The whole operating system is a filesystem with files and folders stored on the local disk. This is an important fact to remember when looking at what container images are. As we will see, an image is a big tarball containing a filesystem. More specifically, it contains a layered filesystem.</p>
<p class="callout-heading">Tarball</p>
<p class="callout">A tarball (also known as a <code>.tar</code> archive) is a<a id="_idIndexMarker224"/> single file <a id="_idIndexMarker225"/>that contains multiple files or<a id="_idIndexMarker226"/> directories. It is a common archive format that is used to distribute software packages and other collections of files. The <code>.tar</code> archive is usually compressed using gzip or another compression format to reduce its size. Tarballs are commonly used in Unix-like operating systems, including Linux and macOS, and can be unpacked using the <code>tar</code> command.</p>
<h2 id="_idParaDest-89"><a id="_idTextAnchor086"/>The layered filesystem</h2>
<p>Container<a id="_idIndexMarker227"/> images are templates from which containers are<a id="_idIndexMarker228"/> created. These images are not made up of just one monolithic block but are composed of many layers. The first layer in the image is also <a id="_idIndexMarker229"/>called the <strong class="bold">base layer</strong>. We can see this in the following figure:</p>
<div><div><img alt="Figure 4.1 – The image as a stack of layers" height="261" src="img/B19199_04_01.jpg" width="201"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – The image as a stack of layers</p>
<p>Each layer contains files and folders. Each layer only contains the changes to the filesystem concerning the underlying layers. Docker uses a Union filesystem – as discussed in <a href="B19199_03.xhtml#_idTextAnchor057"><em class="italic">Chapter 3</em></a>, <em class="italic">Mastering Containers</em> – to create a virtual filesystem out of the set of layers. A storage driver handles the details regarding the way these layers interact with each other. Different storage drivers are available that have advantages and disadvantages in different situations.</p>
<p>The layers of a container image are all immutable. Immutable means that once generated, the layer cannot ever be changed. The only possible operation affecting the layer is its physical deletion. This immutability of layers is important because it opens up a tremendous number of opportunities, as we will see.</p>
<p>In the following figure, we can see what a custom image for a web application, using Nginx <a id="_idIndexMarker230"/>as a <a id="_idIndexMarker231"/>web server, could look like:</p>
<div><div><img alt="Figure 4.2 – A sample custom image based on Alpine and Nginx" height="111" src="img/B19199_04_02.jpg" width="301"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – A sample custom image based on Alpine and Nginx</p>
<p>Our base layer here consists of the Alpine Linux distribution. Then, on top of that, we have an <strong class="bold">Add Nginx</strong> layer where Nginx is added on top of Alpine. Finally, the third layer contains all the files that make up the web application, such as HTML, CSS, and JavaScript files.</p>
<p>As has been said previously, each image starts with a base image. Typically, this base image is one of the official images found on Docker Hub, such as a Linux distro, Alpine, Ubuntu, or CentOS. However, it is also possible to create an image from scratch.</p>
<p class="callout-heading">Note</p>
<p class="callout">Docker Hub is a public registry for container images. It is a central hub ideally suited for sharing public container images. The registry can be found here: <a href="https://hub.docker.com/">https://hub.docker.com/</a>.</p>
<p>Each layer only contains the delta of changes regarding the previous set of layers. The content of each layer is mapped to a special folder on the host system, which is usually a subfolder of <code>/var/lib/docker/</code>.</p>
<p>Since <a id="_idIndexMarker232"/>layers <a id="_idIndexMarker233"/>are immutable, they can be cached without ever becoming stale. This is a big advantage, as we will see.</p>
<h2 id="_idParaDest-90"><a id="_idTextAnchor087"/>The writable container layer</h2>
<p>As we have <a id="_idIndexMarker234"/>discussed, a container image is<a id="_idIndexMarker235"/> made of a stack of immutable or read-only layers. When Docker Engine creates a container from such an image, it adds a writable container layer on top of this stack of immutable layers. Our stack now looks as follows:</p>
<p class="IMG---Figure"><img alt="Figure 4.3 – The writable container layer" height="171" src="img/B19199_04_03.png" width="301"/></p>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.3 – The writable container layer</p>
<p>The container layer is <a id="_idIndexMarker236"/>marked as <strong class="bold">read/write</strong> (<strong class="bold">r/w</strong>). Another advantage of the immutability of image layers is that they can be shared among many containers created from this image. All that is needed is a thin, writable container layer for each container, as shown in the following figure:</p>
<div><div><img alt="Figure 4.4 – Multiple containers sharing the same image layers" height="332" src="img/B19199_04_04.jpg" width="482"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.4 – Multiple containers sharing the same image layers</p>
<p>This technique, of course, results in a tremendous reduction in the resources that are consumed. Furthermore, this helps decrease the loading time of a container since only a thin<a id="_idIndexMarker237"/> container<a id="_idIndexMarker238"/> layer has to be created once the image layers have been loaded into memory, which only happens for the first container.</p>
<h2 id="_idParaDest-91"><a id="_idTextAnchor088"/>Copy-on-write</h2>
<p>Docker uses <a id="_idIndexMarker239"/>the <a id="_idIndexMarker240"/>copy-on-write technique when dealing with images. Copy-on-write is a strategy for sharing and copying files for maximum efficiency. If a layer uses a file or folder that is available in one of the low-lying layers, then it just uses it. If, on the other hand, a layer wants to modify, say, a file from a low-lying layer, then it first copies this file up to the target layer and then modifies it. In the following figure, we can see what this means:</p>
<div><div><img alt="Figure 4.5 – Docker image using copy-on-write" height="202" src="img/B19199_04_05.jpg" width="512"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.5 – Docker image using copy-on-write</p>
<p>The second layer wants to modify <strong class="bold">File 2</strong>, which is present in the base layer. Thus, it copies it up and then modifies it. Now, let’s say that we’re sitting in the top layer of the preceding<a id="_idIndexMarker241"/> graphic. This <a id="_idIndexMarker242"/>layer will use <strong class="bold">File 1</strong> from the base layer and <strong class="bold">File 2</strong> and <strong class="bold">File 3</strong> from the second layer.</p>
<h2 id="_idParaDest-92"><a id="_idTextAnchor089"/>Graph drivers</h2>
<p>Graph drivers <a id="_idIndexMarker243"/>are what enable the Union filesystem. Graph<a id="_idIndexMarker244"/> drivers are also called storage drivers and are used when dealing with layered container images. A graph driver consolidates multiple image layers into a root filesystem for the mount namespace of the container. Or, put differently, the driver controls how images and containers are stored and managed on the Docker host.</p>
<p>Docker supports several different graph drivers using a pluggable architecture. The preferred driver is <strong class="bold">overlay2,</strong> followed by <strong class="bold">overlay.</strong></p>
<p>Now that we understand what images are, we will learn how we can create a Docker image ourselves.</p>
<h1 id="_idParaDest-93"><a id="_idTextAnchor090"/>Creating Docker images</h1>
<p>There are three <a id="_idIndexMarker245"/>ways to create a new container image on your system. The first one is by interactively building a container that contains all the additions and changes you desire, and then committing those changes into a new image. The second, and most important, way is to use a Dockerfile to describe what’s in the new image, and then build the image using that Dockerfile as a manifest. Finally, the third way of<a id="_idIndexMarker246"/> creating an image is by importing it into the system from a tarball.</p>
<p>Now, let’s look at these three ways in detail.</p>
<h2 id="_idParaDest-94"><a id="_idTextAnchor091"/>Interactive image creation</h2>
<p>The first way we<a id="_idIndexMarker247"/> can create a custom image is by interactively building a container. That is, we start with a base image that we want to use as a template and run a container of it interactively. Let’s say that this is the Alpine image:</p>
<ol>
<li>The command to run the container would be as follows:<pre class="console">
$ docker container run -it \    --name sample \    alpine:3.17 /bin/sh</pre></li> </ol>
<p>The preceding command runs a container based on the <code>alpine:3.17</code> image.</p>
<ol>
<li value="2">We run the container interactively with an<a id="_idIndexMarker248"/> attached <code>-it</code> parameter, name it <code>sample</code> with the <code>--name</code> parameter, and finally run a shell inside the container using <code>/bin/sh</code>.</li>
</ol>
<p>In the Terminal window where you ran the preceding command, you should see something like this:</p>
<div><div><img alt="Figure 4.6 – Alpine container in interactive mode" height="293" src="img/B19199_04_06.jpg" width="1119"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.6 – Alpine container in interactive mode</p>
<p>By default, the Alpine container does not have the <code>curl</code> tool installed. Let’s assume we want to create a new custom image that has <code>curl</code> installed.</p>
<ol>
<li value="3">Inside the container, we can then run the following command:<pre class="console">
/ # apk update &amp;&amp; apk add curl</pre></li> </ol>
<p>The preceding command first updates the Alpine package manager, <code>apk</code>, and then it installs the <code>curl</code> tool. The output of the preceding command should look<a id="_idIndexMarker249"/> approximately like this:</p>
<div><div><img alt="Figure 4.7 – Installing curl on Alpine" height="450" src="img/B19199_04_07.jpg" width="1191"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.7 – Installing curl on Alpine</p>
<ol>
<li value="4">Now, we can indeed use <code>curl</code>, as the following code snippet shows:</li>
</ol>
<div><div><img alt="Figure 4.8 – Using curl from within the container" height="365" src="img/B19199_04_08.jpg" width="1099"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.8 – Using curl from within the container</p>
<p>With the preceding command, we have contacted the Google home page, and with the <code>-I</code> parameter, we have told <code>curl</code> to only output the response headers.</p>
<ol>
<li value="5">Once we have finished our customization, we can quit the container by typing <code>exit</code> at the prompt or hitting Ctrl + D.</li>
<li>Now, if we list all containers with the <code>docker container ls -a</code> command, we will see that our sample container has a status of <code>Exited</code>, but still exists on the system, as shown in the following code block:<pre class="console">
$ docker container ls -a | grep sample</pre></li> <li>This should<a id="_idIndexMarker250"/> output something similar to this:<pre class="console">
5266d7da377c   alpine:3.17    "/bin/sh"                2 hours ago      Exited (0) 48 seconds ago</pre></li> <li>If we want to see what has changed in our container concerning the base image, we can use the <code>docker container diff</code> command, as follows:<pre class="console">
$ docker container diff sample</pre></li> <li>The output should present a list of all modifications done on the filesystem of the container, as follows:</li>
</ol>
<div><div><img alt="Figure 4.9 – Output of the docker diff command (truncated)" height="697" src="img/B19199_04_09.jpg" width="1079"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.9 – Output of the docker diff command (truncated)</p>
<p>We have <a id="_idIndexMarker251"/>shortened the preceding output for better readability. In the list, <code>A</code> stands for added, and <code>C</code> stands for changed. If we had any deleted files, then those would be prefixed with <code>D</code>.</p>
<ol>
<li value="10">We can now use the <code>docker container commit</code> command to persist our modifications and create a new image from them, like this:<pre class="console">
$ docker container commit sample my-alpine</pre></li> </ol>
<p>The output generated by the preceding command on the author’s computer is as follows:</p>
<pre class="console">
sha256:5287bccbb3012ded35e7e992a5ba2ded9b8b5d0...</pre> <p>With the preceding command, we have specified that the new image will be called <code>my-alpine</code>. The output generated by the preceding command corresponds to the ID of the newly generated image.</p>
<ol>
<li value="11">We can verify this by listing all the images on our system, as follows:<pre class="console">
$ docker image ls</pre></li> </ol>
<p>We can see this image ID as follows:</p>
<div><div><img alt="Figure 4.10 – Listing all Docker images" height="275" src="img/B19199_04_10.jpg" width="1175"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.10 – Listing all Docker images</p>
<p>We can see that the image named <code>my-alpine</code> has the expected ID of <code>5287bccbb301</code> (corresponding to the first part of the full hash code) and automatically<a id="_idIndexMarker252"/> got a tag of <code>latest</code> assigned. This happened since we did not explicitly define a tag ourselves. In this case, Docker always defaults to the <code>latest</code> tag.</p>
<ol>
<li value="12">If we want to see how our custom image has been built, we can use the <code>history</code> command, as follows:<pre class="console">
$ docker image history my-alipine</pre></li> </ol>
<p>This will print a list of the layers our image consists of, as follows:</p>
<div><div><img alt="Figure 4.11 – History of the my-alpine Docker image" height="124" src="img/B19199_04_11.jpg" width="1102"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.11 – History of the my-alpine Docker image</p>
<p>The top layer – marked in red – in the preceding output is the one that we just created by adding the <code>curl</code> package. The other two lines stem from the original build of the Alpine 3.17 Docker image. It was created and uploaded 4 days ago.</p>
<p>Now that we have seen how we can interactively create a Docker image, let’s look into how we can do the same declaratively using a Dockerfile.</p>
<h2 id="_idParaDest-95"><a id="_idTextAnchor092"/>Using Dockerfiles</h2>
<p>Manually creating<a id="_idIndexMarker253"/> custom images, as shown in the previous<a id="_idIndexMarker254"/> section of this chapter, is very helpful when doing exploration, creating prototypes, or authoring feasibility studies. But it has a serious drawback: it is a manual process and thus is not repeatable or scalable. It is also error-prone, just like any other task executed manually by humans. There must be a better way.</p>
<p>This is where the so-called Dockerfile comes into play. A <code>Dockerfile</code> is a text file that, by default, is called <code>Dockerfile</code>. It contains instructions on how to build a custom container image. It is a declarative way of building images.</p>
<p class="callout-heading">Declarative versus imperative</p>
<p class="callout">In computer science in general, and with Docker specifically, you often use a declarative way of defining a task. You describe the expected outcome and let the system figure out how to achieve this goal, rather than giving step-by-step instructions to the system on how to achieve this desired outcome. The latter is an imperative approach.</p>
<p>Let’s look at a sample Dockerfile, as follows:</p>
<pre class="source-code">
FROM python:3.12RUN mkdir -p /app
WORKDIR /app
COPY ./requirements.txt /app/
RUN pip install -r requirements.txt
CMD ["python", "main.py"]</pre>
<p>This is a Dockerfile as it is used to containerize a Python 3.12 application. As we can see, the file has six lines, each starting with a keyword such as <code>FROM</code>, <code>RUN</code>, or <code>COPY</code>.</p>
<p class="callout-heading">Note</p>
<p class="callout">It is a convention to write the keywords in all caps, but that is not a must.</p>
<p>Each line of the Dockerfile results in a layer in the resulting image. In the following figure, the image is drawn upside down compared to the previous figures in this chapter, showing an image as a stack of layers. Here, the base layer is shown on top. Don’t let yourself be confused by this. In reality, the base layer is always the lowest in the stack:</p>
<div><div><img alt="Figure 4.12 – The relationship between a Dockerfile and the layers in an image" height="311" src="img/B19199_04_12.jpg" width="661"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.12 – The relationship between a Dockerfile and the layers in an image</p>
<p>Now, let’s<a id="_idIndexMarker255"/> look<a id="_idIndexMarker256"/> at the individual keywords in more detail.</p>
<h3>The FROM keyword</h3>
<p>Every <a id="_idIndexMarker257"/>Dockerfile starts with the <code>FROM</code> keyword. With it, we define <a id="_idIndexMarker258"/>which base image we want to start building our custom image from. If we want to build starting with CentOS 7, for example, we would have the following line in the Dockerfile:</p>
<pre class="source-code">
FROM centos:7</pre> <p>On Docker Hub, there are curated or official images for all major Linux distros, as well as for all important development frameworks or languages, such as Python, Node.js, Ruby, Go, and many more. Depending on our needs, we should select the most appropriate base image.</p>
<p>For example, if I want to containerize a Python 3.12 application, I might want to select the relevant official <code>python:3.12</code> image.</p>
<p>If we want to start from scratch, we can also use the following statement:</p>
<pre class="source-code">
FROM scratch</pre> <p>This is useful in the context of building super-minimal images that only – for example – contain a single binary: the actual statically linked executable, such as <code>Hello-World</code>. The scratch image is an empty base image.</p>
<p><code>FROM scratch</code>, in<a id="_idIndexMarker259"/> reality, is <a id="_idIndexMarker260"/>a no-op in the Dockerfile, and as such does not generate a layer in the resulting container image.</p>
<h3>The RUN keyword</h3>
<p>The next <a id="_idIndexMarker261"/>important keyword is <code>RUN</code>. The argument for <code>RUN</code> is any <a id="_idIndexMarker262"/>valid Linux command, such as the following:</p>
<pre class="source-code">
RUN yum install -y wget</pre> <p>The preceding command is using the <code>yum</code> CentOS package manager to install the <code>wget</code> package into the running container. This assumes that our base image is CentOS or <strong class="bold">Red Hat Enterprise Linux</strong> (<strong class="bold">RHEL</strong>). If we<a id="_idIndexMarker263"/> had Ubuntu as our base image, then the command would look similar to the following:</p>
<pre class="source-code">
RUN apt-get update &amp;&amp; apt-get install -y wget</pre> <p>It would look like this because Ubuntu uses <code>apt-get</code> as a package manager. Similarly, we could define a line with <code>RUN</code>, like this:</p>
<pre class="source-code">
RUN mkdir -p /app &amp;&amp; cd /app</pre> <p>We could also do this:</p>
<pre class="source-code">
RUN tar -xJC /usr/src/python --strip-components=1 -f python.tar.xz</pre> <p>Here, the former creates an <code>/app</code> folder in the container and navigates to it, and the latter un-tars a file to a given location. It is completely fine, and even recommended, for you to format a Linux command using more than one physical line, such as this:</p>
<pre class="source-code">
RUN apt-get update \  &amp;&amp; apt-get install -y --no-install-recommends \
    ca-certificates \
    libexpat1 \
    libffi6 \
    libgdbm3 \
    libreadline7 \
    libsqlite3-0 \
   libssl1.1 \
  &amp;&amp; rm -rf /var/lib/apt/lists/*</pre>
<p>If we use more than one line, we need to put a backslash (<code>\</code>) at the end of the lines to indicate to <a id="_idIndexMarker264"/>the<a id="_idIndexMarker265"/> shell that the command continues on the next line.</p>
<p class="callout-heading">Tip</p>
<p class="callout">Try to find out what the preceding command does.</p>
<h3>The COPY and ADD keywords</h3>
<p>The <code>COPY</code> and <code>ADD</code> keywords <a id="_idIndexMarker266"/>are <a id="_idIndexMarker267"/>very<a id="_idIndexMarker268"/> important<a id="_idIndexMarker269"/> since, in the end, we want to add some content to an existing base image to make it a custom image. Most of the time, these are a few source files of – say – a web application, or a few binaries of a compiled application.</p>
<p>These two keywords are used to copy files and folders from the host into the image that we’re building. The two keywords are very similar, with the exception that the <code>ADD</code> keyword also lets us copy and unpack <code>TAR</code> files, as well as provide an URI as a source for the files and folders to copy.</p>
<p>Let’s look at a few examples of how these two keywords can be used, as follows:</p>
<pre class="source-code">
COPY . /appCOPY ./web /app/web
COPY sample.txt /data/my-sample.txt
ADD sample.tar /app/bin/
ADD http://example.com/sample.txt /data/</pre>
<p>In the preceding lines of code, the following applies:</p>
<ul>
<li>The first line copies all files and folders from the current directory recursively to the <code>app</code> folder inside the container image</li>
<li>The second line copies everything in the <code>web</code> subfolder to the target folder, <code>/app/web</code></li>
<li>The third line copies a single file, <code>sample.txt</code>, into the target folder, <code>/data</code>, and at the same time, renames it <code>my-sample.txt</code></li>
<li>The fourth statement unpacks the <code>sample.tar</code> file into the target folder, <code>/app/bin</code></li>
<li>Finally, the last statement copies the remote file, <code>sample.txt</code>, into the target file, <code>/data</code></li>
</ul>
<p>Wildcards are allowed in the source path. For example, the following statement copies all files starting with <code>sample</code> to the <code>mydir</code> folder inside the image:</p>
<pre class="source-code">
COPY ./sample* /mydir/</pre> <p>From a <a id="_idIndexMarker270"/>security <a id="_idIndexMarker271"/>perspective, it<a id="_idIndexMarker272"/> is <a id="_idIndexMarker273"/>important to know that, by default, all files and folders inside the image will have a <code>ADD</code> and <code>COPY</code>, we can change the ownership that the files will have inside the image using the optional <code>--chown</code> flag, as follows:</p>
<pre class="source-code">
ADD --chown=11:22 ./data/web* /app/data/</pre> <p>The preceding statement will copy all files starting with <code>web</code> and put them into the <code>/app/data</code> folder in the image, and at the same time assign user 11 and group 22 to these files.</p>
<p>Instead of numbers, we could also use names for the user and group, but then these entities would have to be already defined in the root filesystem of the image at <code>/etc/passwd</code> and <code>/etc/group</code>, respectively; otherwise, the build of the image would fail.</p>
<h3>The WORKDIR keyword</h3>
<p>The <code>WORKDIR</code> keyword <a id="_idIndexMarker274"/>defines the working directory or<a id="_idIndexMarker275"/> context that is used when a container is run from our custom image. So, if I want to set the context to the <code>/app/bin</code> folder inside the image, my expression in the Dockerfile would have to look as follows:</p>
<pre class="source-code">
WORKDIR /app/bin</pre> <p>All activity that happens inside the image after the preceding line will use this directory as the working directory. It is very important to note that the following two snippets from a Dockerfile are not the same:</p>
<pre class="source-code">
RUN cd /app/binRUN touch sample.txt</pre>
<p>Compare the preceding code with the following code:</p>
<pre class="source-code">
WORKDIR /app/binRUN touch sample.txt</pre>
<p>The former will create the file in the root of the image filesystem, while the latter will create the file at the expected location in the <code>/app/bin</code> folder. Only the <code>WORKDIR</code> keyword sets the context across the layers of the image. The <code>cd</code> command alone is not persisted across layers.</p>
<p class="callout-heading">Note</p>
<p class="callout">It is completely fine to change the current working directory multiple times in a Dockerfile.</p>
<h3>The CMD and ENTRYPOINT keywords</h3>
<p>The <code>CMD</code> and <code>ENTRYPOINT</code> keywords<a id="_idIndexMarker276"/> are special. While all<a id="_idIndexMarker277"/> other <a id="_idIndexMarker278"/>keywords <a id="_idIndexMarker279"/>defined for a Dockerfile are executed at the time the image is built by the Docker builder, these two are definitions of what will happen when a container is started from the image we define. When the container runtime starts a container, it needs to know what the process or application will be that has to run inside that container. That is exactly what <code>CMD</code> and <code>ENTRYPOINT</code> are used for – to tell Docker what the start process is and how to start that process.</p>
<p>Now, the differences between <code>CMD</code> and <code>ENTRYPOINT</code> are subtle, and honestly, most users don’t fully understand them or use them in the intended way. Luckily, in most cases, this is not a problem and the container will run anyway; it’s just handling it that is not as straightforward as it could be.</p>
<p>To better understand how to use these two keywords, let’s analyze what a typical Linux command or expression looks like. Let’s take the <code>ping</code> utility as an example, as follows:</p>
<pre class="source-code">
$ ping -c 3 8.8.8.8</pre> <p>In the preceding expression, <code>ping</code> is the command, and <code>-c 3 8.8.8.8</code> are the parameters of this com<a href="http://example.com/downloads/script.sh">mand. Let’s look at another expression</a> here:</p>
<pre class="source-code">
$ wget -O - http://example.com/downloads/script.sh</pre> <p>Again, in the preceding expression, <code>wget</code> is the command, and <code>-O - http://example.com/downloads/script.sh</code> are the parameters.</p>
<p>Now that <a id="_idIndexMarker280"/>we <a id="_idIndexMarker281"/>have <a id="_idIndexMarker282"/>dealt<a id="_idIndexMarker283"/> with this, we can get back to <code>CMD</code> and <code>ENTRYPOINT</code>. <code>ENTRYPOINT</code> is used to define the command of the expression, while <code>CMD</code> is used to define the parameters for the command. Thus, a Dockerfile using Alpine as the base image and defining <code>ping</code> as the process to run in the container could look like this:</p>
<pre class="source-code">
FROM alpine:3.17ENTRYPOINT [ "ping" ]
CMD [ "-c", "3", "8.8.8.8" ]</pre>
<p>For both <code>ENTRYPOINT</code> and <code>CMD</code>, the values are formatted as a JSON array of strings, where the individual items correspond to the tokens of the expression that are separated by whitespace. This is the preferred way of defining <code>CMD</code> and <code>ENTRYPOINT</code>. It is also called the exec form.</p>
<p>Alternatively, we can use what’s called the shell form, as shown here:</p>
<pre class="source-code">
CMD command param1 param2</pre> <p>We can now build an image called <code>pinger</code> from the preceding Dockerfile, as follows:</p>
<pre class="source-code">
$ docker image build -t pinger .</pre> <p>Here is the output generated by the preceeding command:</p>
<div><div><img alt="Figure 4.13 – Building the pinger Docker image" height="277" src="img/B19199_04_13.jpg" width="1101"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.13 – Building the pinger Docker image</p>
<p>Then, we can run a container from the pinger image we just created, like this:</p>
<pre class="source-code">
$ docker container run --rm -it pinger</pre> <div><div><img alt="Figure 4.14 – Output of the pinger container" height="274" src="img/B19199_04_14.jpg" width="864"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.14 – Output of the pinger container</p>
<p>In<a id="_idIndexMarker284"/> the <a id="_idIndexMarker285"/>preceding <a id="_idIndexMarker286"/>command, we <a id="_idIndexMarker287"/>are using the <code>--rm</code> parameter, which defines that the container is automatically removed once the applications inside the container end.</p>
<p>The beauty of this is that I can now override the CMD part that I have defined in the Dockerfile (remember, it was <code>["-c", "3","8.8.8.8"]</code>) when I create a new container by adding the new values at the end of the <code>docker container run</code> expression, like this:</p>
<pre class="source-code">
$ docker container run --rm -it pinger -w 5 127.0.0.1</pre> <p>This will cause the container to ping the loopback IP address (<code>127.0.0.1</code>) for 5 seconds.</p>
<p>If we want to override what’s defined in <code>ENTRYPOINT</code> in the Dockerfile, we need to use the <code>--entrypoint</code> parameter in the <code>docker container run</code> expression. Let’s say we want to execute a shell in the container instead of the <code>ping</code> command. We could do so by using the following command:</p>
<pre class="source-code">
$ docker container run --rm -it --entrypoint /bin/sh pinger</pre> <p>We will then find ourselves inside the container. Type <code>exit</code> or press <em class="italic">Ctrl + D</em> to leave the container.</p>
<p>As I already mentioned, we do not necessarily have to follow best practices and define the command through <code>ENTRYPOINT</code> and the parameters through <code>CMD</code>; instead, we can enter the whole expression as a value of <code>CMD</code> and it will work, as shown in the following code block:</p>
<pre class="source-code">
FROM alpine:3.17CMD wget -O - http://www.google.com</pre>
<p>Here, I have even used the shell form to define CMD. But what happens in this situation if <code>ENTRYPOINT</code> is undefined? If you leave <code>ENTRYPOINT</code> undefined, then it will have the default value of <code>/bin/sh -c</code>, and whatever the value of <code>CMD</code> is will be passed as a string to the shell command. The preceding definition would thereby result in <a id="_idIndexMarker288"/>entering<a id="_idIndexMarker289"/> the<a id="_idIndexMarker290"/> following<a id="_idIndexMarker291"/> code to run the process inside the container:</p>
<pre class="source-code">
/bin/sh -c "wget -O - http://www.google.com"</pre> <p>Consequently, <code>/bin/sh</code> is the main process running inside the container, and it will start a new child process to run the <code>wget</code> utility.</p>
<h3>A complex Dockerfile</h3>
<p>So far, we have<a id="_idIndexMarker292"/> discussed the most important keywords commonly used in Dockerfiles. Now, let’s look at a realistic and somewhat complex example of a Dockerfile. Those of you who are interested might note that it looks very similar to the first Dockerfile that we presented in this chapter. Here is its content:</p>
<pre class="source-code">
FROM node:19-buster-slimRUN mkdir -p /app
WORKDIR /app
COPY package.json /app/
RUN npm install
COPY . /app
ENTRYPOINT ["npm"]
CMD ["start"]</pre>
<p>OK; so, what is happening here? This is a Dockerfile that is used to build an image for a Node.js application; we can deduce this from the fact that the <code>node:19-buster-slim</code> base image is used. Then, the second line is an instruction to create an <code>/app</code> folder in the filesystem of the image. The third line defines the working directory or context in the image to be this new <code>/app</code> folder. Then, on line four, we copy a <code>package.json</code> file into the <code>/app</code> folder inside the image. After this, on line five, we execute the <code>npm install</code> command inside the container; remember, our context is the <code>/app</code> folder, so <code>npm</code> will find the <code>package.json</code> file there that we copied on line four.</p>
<p>Once all the Node.js dependencies have been installed, we copy the rest of the application files from the current folder of the host into the <code>/app</code> folder of the image.</p>
<p>Finally, in the<a id="_idIndexMarker293"/> last two lines, we define what the startup command will be when a container is run from this image. In our case, it is <code>npm start</code>, which will start the Node.js application.</p>
<h3>Building an image</h3>
<p>Let’s look at a<a id="_idIndexMarker294"/> concrete example and build a simple Docker image, as follows:</p>
<ol>
<li>Navigate to the sample code repository. Normally, this should be located in your home folder:<pre class="console">
$ cd ~/The-Ultimate-Docker-Container-Book</pre></li> <li>Create a new subfolder for <a href="B19199_04.xhtml#_idTextAnchor083"><em class="italic">Chapter 4</em></a> and navigate to it:<pre class="console">
$ mkdir ch04 &amp;&amp; cd ch04</pre></li> <li>In the preceding folder, create a <code>sample1</code> subfolder and navigate to it, like this:<pre class="console">
$ mkdir sample1 &amp;&amp; cd sample1</pre></li> <li>Use your favorite editor to create a file called <code>Dockerfile</code> inside this sample folder, with the following content:<pre class="console">
FROM centos:7RUN yum install -y wget</pre></li> <li>Save the file and exit your editor.</li>
<li>Back in the Terminal window, we can now build a new container image using the preceding Dockerfile as a manifest or construction plan, like this:<pre class="console">
$ docker image build -t my-centos .</pre></li> </ol>
<p>Please <a id="_idIndexMarker295"/>note that there is a period (<code>.</code>) at the end of the preceding command:</p>
<div><div><img alt="Figure 4.15 – Building our first custom image from CentOS" height="604" src="img/B19199_04_15.jpg" width="1342"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.15 – Building our first custom image from CentOS</p>
<p>The previous command means that the Docker builder creates a new image called <code>my-centos</code> using the Dockerfile that is present in the current directory. Here, the period at the end of the command specifies the current directory. We could also write the preceding command as follows, with the same result:</p>
<pre class="console">
$ docker image build -t my-centos -f Dockerfile .</pre> <p>Here, we can omit the <code>-f</code> parameter since the builder assumes that the Dockerfile is called <code>Dockerfile</code>. We only ever need the <code>-f</code> parameter if our Dockerfile has a different name or is not located in the current directory.</p>
<p>Let’s analyze the output shown in <em class="italic">Figure 4</em><em class="italic">.15</em>. This output is created by the Docker build kit:</p>
<ol>
<li>First, we have the following line:<pre class="console">
[+] Building 21.7s (7/7) FINISHED</pre></li> </ol>
<p>This line is generated at the end of the build process, although it appears as the first line. It tells us that the building took approximately 22 seconds and was executed in 7 steps.</p>
<ol>
<li value="2">Now, let’s skip the next few lines until we reach this one:<pre class="console">
=&gt; [1/2] FROM docker.io/library/centos:7@sha256:c73f51...</pre></li> </ol>
<p>This line tells<a id="_idIndexMarker296"/> us which line of the Dockerfile the builder is currently executing (1 of 2). We can see that this is the <code>FROM centos:7</code> statement in our Dockerfile. This is the declaration of the base image, on top of which we want to build our custom image. What the builder then does is pull this image from Docker Hub, if it is not already available in the local cache.</p>
<ol>
<li value="3">Now, follow the next step. I have shortened it even more than the preceding one to concentrate on the essential part:<pre class="console">
=&gt; [2/2] RUN yum install -y wget</pre></li> </ol>
<p>This is our second line in the Dockerfile, where we want to use the <code>yum</code> package manager to install the <code>wget</code> utility.</p>
<ol>
<li value="4">The last few lines are as follows:<pre class="console">
=&gt; exporting to image                              0.1s=&gt; =&gt; exporting layers                             0.1s=&gt; =&gt; writing image sha256:8eb6daefac9659b05b17740...=&gt; =&gt; naming to docker.io/library/my-centos</pre></li> </ol>
<p>Here, the builder finalizes building the image and provides the image with the <code>sha256</code> code of <code>8eb6daefac9...</code>.</p>
<p>This tells us that the resulting custom image has been given an ID of <code>8eb6daefac9...</code> and has been tagged with <code>my-centos:latest</code>.</p>
<p>Now that we <a id="_idIndexMarker297"/>have analyzed how the build process of a Docker image works and what steps are involved, let’s talk about how to further improve this by introducing multi-step builds.</p>
<h3>Multi-step builds</h3>
<p>To demonstrate<a id="_idIndexMarker298"/> why a Dockerfile with multiple build steps is useful, let’s make an example Dockerfile. Let’s take a Hello World application written in C:</p>
<ol>
<li>Open a new Terminal window and navigate to this chapter’s folder:<pre class="console">
$ cd The-Ultimate-Docker-Container-Book/ch04</pre></li> <li>Create a new folder called <code>multi-step-build</code> in your chapter folder:<pre class="console">
$ mkdir multi-step-build</pre></li> <li>Open VS Code for this folder:<pre class="console">
$ code multi-step-build</pre></li> <li>Create a file called <code>hello.c</code> in this folder and add the following code to it:<pre class="console">
#include &lt;stdio.h&gt;int main (void){    printf ("Hello, world!\n");    return 0;}</pre></li> <li>Now, we want to containerize this application and write a Dockerfile with this content:<pre class="console">
FROM alpine:3.12RUN apk update &amp;&amp; \    apk add --update alpine-sdkRUN mkdir /appWORKDIR /appCOPY . /appRUN mkdir binRUN gcc -Wall hello.c -o bin/helloCMD /app/bin/hello</pre></li> <li>Next, let’s build this image:<pre class="console">
<code>$ docker image build -t hello-world .</code></pre></li> </ol>
<p>This gives <a id="_idIndexMarker299"/>us a fairly long output since the builder has to install the <a id="_idIndexMarker300"/>Alpine <strong class="bold">Software Development Kit</strong> (<strong class="bold">SDK</strong>), which, among other tools, contains the C++ compiler we need to build the application.</p>
<ol>
<li value="7">Once the build is done, we can list the image and see the size that’s been shown, as follows:<pre class="console">
$ docker image ls | grep hello-world</pre></li> </ol>
<p>In the author’s case, the output is as follows:</p>
<pre class="console">
hello-world   latest   42c0c7086fbf   2 minutes ago   215MB</pre> <p>With a size of 215 MB, the resulting image is way too big. In the end, it is just a Hello World application. The reason for it being so big is that the image not only contains the Hello World binary but also all the tools to compile and link the application from the source code. But this is not desirable when running the application, say, in production. Ideally, we only want to have the resulting binary in the image and not a whole SDK.</p>
<p>It is precisely for this reason that we should define Dockerfiles as multi-stage. We have some stages that are used to build the final artifacts, and then a final stage, where we use the minimal necessary base image and copy the artifacts into it. This results in very small Docker images. Let’s do this:</p>
<ol>
<li>Create a new Dockerfile to your folder called <code>Dockerfile.multi-step</code> with this<a id="_idIndexMarker301"/> content:<pre class="console">
FROM alpine:3.12 AS buildRUN apk update &amp;&amp; \    apk add --update alpine-sdkRUN mkdir /appWORKDIR /appCOPY . /appRUN mkdir binRUN gcc hello.c -o bin/helloFROM alpine:3.12COPY --from=build /app/bin/hello /app/helloCMD /app/hello</pre></li> </ol>
<p>Here, we have the first stage with an alias called <code>build</code>, which is used to compile the application; then, the second stage uses the same <code>alpine:3.12</code> base image but does not install the SDK, and only copies the binary from the <code>build</code> stage, using the <code>--from</code> parameter, into this final image.</p>
<ol>
<li value="2">Let’s build the image again, as follows:<pre class="console">
$ docker image build -t hello-world-small \    -f Dockerfile.multi-step .</pre></li> <li>Let’s compare the sizes of the images with this command:<pre class="console">
$ docker image ls | grep hello-world</pre></li> </ol>
<p>Here, we get the following output:</p>
<pre class="console">
hello-world-small latest 72c... 20 seconds ago 5.34MBhello-world latest 42c... 10 minutes ago 215</pre>
<p>We have been able to reduce the size from 215 MB down to 5.34 MB. This is a reduction in size by a factor of approximately 40. A smaller image has many advantages, such as a smaller attack surface area for hackers, reduced memory and disk consumption, faster startup times<a id="_idIndexMarker302"/> for the corresponding containers, and a reduction of the bandwidth needed to download the image from a registry, such as Docker Hub.</p>
<h3>Dockerfile best practices</h3>
<p>There are a <a id="_idIndexMarker303"/>few recommended best practices to consider when authoring a Dockerfile, which are as follows:</p>
<ul>
<li>First and foremost, we need to consider that containers are meant to be ephemeral. By ephemeral, we mean that a container can be stopped and destroyed, and a new one built and put in place with the absolute minimum setup and configuration. That means that we should try hard to keep the time that is needed to initialize the application running inside the container at a minimum, as well as the time needed to terminate or clean up the application.</li>
<li>The next best practice tells us that we should order the individual commands in the Dockerfile so that we leverage caching as much as possible. Building a layer of an image can take a considerable amount of time – sometimes many seconds, or even minutes. While developing an application, we will have to build the container image for our application multiple times. We want to keep the build times at a minimum.</li>
</ul>
<p>When we’re rebuilding a previously built image, the only layers that are rebuilt are the ones that have changed, but if one layer needs to be rebuilt, all subsequent layers also need to be rebuilt. This is very important to remember. Consider the following example:</p>
<pre class="source-code">
FROM node:19RUN mkdir -p /app
WORKIR /app
COPY . /app
RUN npm install
CMD ["npm", "start"]</pre>
<p>In this example, the <code>npm install</code> command on line five of the Dockerfile usually takes the longest. A classical Node.js application has many external dependencies, and those are all downloaded and installed in this step. It can take minutes until it is done. Therefore, we want to avoid running <code>npm install</code> each time we rebuild the image, but a developer changes their source code all the time during the development of an application. That means that line four, the result of the <code>COPY</code> command, changes every time, and thus this layer has to be rebuilt. But as we discussed previously, that also means that all subsequent layers have to be rebuilt, which – in this case – includes the <code>npm install</code> command. To<a id="_idIndexMarker304"/> avoid this, we can slightly modify the Dockerfile and have the following:</p>
<pre class="source-code">
FROM node:19RUN mkdir -p /app
WORKIR /app
COPY package.json /app/
RUN npm install
COPY . /app
CMD ["npm", "start"]</pre>
<p>Here, on line four, we only copied the single file that the <code>npm install</code> command needs as a source, which is the <code>package.json</code> file. This file rarely changes in a typical development process. As a consequence, the <code>npm install</code> command also has to be executed only when the <code>package.json</code> file changes. All the remaining frequently changed content is added to the image after the <code>npm </code><code>install</code> command.</p>
<p>A further best practice is to keep the number of layers that make up your image relatively small. The more layers an image has, the more the graph driver needs to work to consolidate the layers into a single root filesystem for the corresponding container. Of course, this takes time, and thus the fewer layers an image has, the faster the startup time for the container can be.</p>
<p>But how can we keep our number of layers low? Remember that in a Dockerfile, each line that starts with a keyword such as <code>FROM</code>, <code>COPY</code>, or <code>RUN</code> creates a new layer. The easiest way to reduce the number of layers is to combine multiple individual <code>RUN</code> commands into a single one. For example, say that we had the following in a Dockerfile:</p>
<pre class="source-code">
...RUN apt-get update
RUN apt-get install -y ca-certificates
RUN rm -rf /var/lib/apt/lists/*
...</pre>
<p>We could combine<a id="_idIndexMarker305"/> these into a single concatenated expression, as follows:</p>
<pre class="source-code">
...RUN apt-get update \
    &amp;&amp; apt-get install -y ca-certificates \
    &amp;&amp; rm -rf /var/lib/apt/lists/*
...</pre>
<p>The former will generate three layers in the resulting image, while the latter will only create a single layer.</p>
<p>The next three best practices all result in smaller images. Why is this important? Smaller images reduce the time and bandwidth needed to download the image from a registry. They also reduce the amount of disk space needed to store a copy locally on the Docker host and the memory needed to load the image. Finally, smaller images also mean a smaller attack surface for hackers. Here are the best practices mentioned:</p>
<ul>
<li>The first best practice that helps reduce the image size is to use a <code>.dockerignore</code> file. We want to avoid copying unnecessary files and folders into an image, to keep it as lean as possible. A <code>.dockerignore</code> file works in the same way as a <code>.gitignore</code> file, for those who are familiar with Git. In a <code>.dockerignore</code> file, we can configure patterns to exclude certain files or folders from being included in the context when building the image.</li>
<li>The next best practice is to avoid installing unnecessary packages into the filesystem of the image. Once again, this is to keep the image as lean as possible.</li>
<li>Last but not least, it is recommended that you use multi-stage builds so that the resulting image is as small as possible and only contains the absolute minimum needed to<a id="_idIndexMarker306"/> run your application or application service.</li>
</ul>
<p>In the next section, we are going to learn how to create a Docker image from a previously saved image. In fact, it may look like restoring an image.</p>
<h2 id="_idParaDest-96"><a id="_idTextAnchor093"/>Saving and loading images</h2>
<p>The third way to <a id="_idIndexMarker307"/>create a new container image is by importing or loading it from a file. A container image is nothing more than a tarball. To demonstrate this, we can use the <code>docker image save</code> command to export an existing image to a tarball, like this:</p>
<pre class="source-code">
$ mkdir backup$ docker image save -o ./backup/my-alpine.tar my-alpine</pre>
<p>The preceding command takes our <code>my-alpine</code> image that we previously built and exports it into a file called <code>./backup/my-alpine.tar</code>:</p>
<div><div><img alt="Figure 4.16 – Exporting an image as a tarball" height="213" src="img/B19199_04_16.jpg" width="1054"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.16 – Exporting an image as a tarball</p>
<p>If, on the other hand, we have an existing tarball and want to import it as an image into our system, we can use the <code>docker image load</code> command, as follows:</p>
<pre class="source-code">
$ docker image load -i ./backup/my-alpine.tar</pre> <p>The output of the preceding command should be as follows:</p>
<pre class="source-code">
Loaded image: my-alpine:latest</pre> <p>With this, we have learned how to build a Docker image in three different ways. We can do so interactively, by <a id="_idIndexMarker308"/>defining a Dockerfile, or by importing it into our system from a tarball.</p>
<p>In the next section, we will discuss how we can create Docker images for existing legacy applications, and thus run them in a container and profit from this.</p>
<h1 id="_idParaDest-97"><a id="_idTextAnchor094"/>Lift and shift – containerizing a legacy app</h1>
<p>We can’t always<a id="_idIndexMarker309"/> start from scratch and develop a brand-new application. More often than not, we find ourselves with a huge portfolio of traditional applications that are up and running in production and provide mission-critical value to the company or the customers of the company. Often, those applications are organically grown and very complex. Documentation is sparse, and nobody wants to touch such an application. Often, the saying “<em class="italic">Never touch a running system”</em> applies. Yet, the market needs change, and with that arises the need to update or rewrite those apps. Often, a complete rewrite is not possible due to the lack of resources and time, or due to the excessive cost. What are we going to do about those applications? Could we possibly Dockerize them and profit from the benefits introduced by containers?</p>
<p>It turns out we can. In 2017, Docker introduced a program called <strong class="bold">Modernize Traditional Apps</strong> (<strong class="bold">MTA</strong>) to <a id="_idIndexMarker310"/>their enterprise customers, which in essence promised to help those customers take their existing or traditional Java and .NET applications and containerize them, without the need to change a single line of code. The focus of MTA was on Java and .NET applications since those made up the lion’s share of the traditional applications in a typical enterprise. But it can also be used for any application that was written in – say – C, C++, Python, Node.js, Ruby, PHP, or Go, to name just a few other languages and platforms.</p>
<p>Let’s imagine such a legacy application for a moment. Let’s assume we have an old Java application that was written 10 years ago and that was continuously updated during the following 5 years. The application is based on Java SE 6, which came out in December 2006. It uses environment variables and property files for configuration. Secrets such as usernames and passwords used in the database connection strings are pulled from a secrets<a id="_idIndexMarker311"/> keystore, such as HashiCorp Vault.</p>
<p>Now, let’s describe each of the required steps to lift and shift a legacy application in more detail.</p>
<h2 id="_idParaDest-98"><a id="_idTextAnchor095"/>Analyzing external dependencies</h2>
<p>One of the first steps in<a id="_idIndexMarker312"/> the modernization process is to discover and list all external dependencies of the legacy application:</p>
<ul>
<li>Does it use a database? If so, which one? What does the connection string look like?</li>
<li>Does it use external APIs such as credit card approval or geo-mapping APIs? What are the API keys and key secrets?</li>
<li>Is it consuming from or<a id="_idIndexMarker313"/> publishing to an <strong class="bold">Enterprise Service </strong><strong class="bold">Bus</strong> (<strong class="bold">ESB</strong>)?</li>
</ul>
<p>These are just a few possible dependencies that come to mind. Many more exist. These are the seams of the application to the outer world, and we need to be aware of them and create an inventory.</p>
<h2 id="_idParaDest-99"><a id="_idTextAnchor096"/>Source code and build instructions</h2>
<p>The next step<a id="_idIndexMarker314"/> is to locate all the source code and other assets, such <a id="_idIndexMarker315"/>as images and CSS and HTML files that are part of the application. Ideally, they should be located in a single folder. This folder will be the root of our project and can have as many subfolders as needed. This project root folder will be the context during the build of the container image we want to create for our legacy application. Remember, the Docker builder only includes files in the build that are part of that context; in our case, that is the root project folder.</p>
<p>There is, though, an option to download or copy files during the build from different locations, using the <code>COPY</code> or <code>ADD</code> commands. Please refer to the online documentation for the exact details on how to use these two commands. This option is useful if the sources for your legacy application cannot be easily contained in a single, local folder.</p>
<p>Once we are aware of all the parts that contribute to the final application, we need to investigate how the application is built and packaged. In our case, this is most probably done by using <code>make</code> would<a id="_idIndexMarker317"/> most likely be used.</p>
<p>Once again, let’s extend our inventory and write down the exact build commands used. We will need this information later on when authoring the Dockerfile.</p>
<h2 id="_idParaDest-100"><a id="_idTextAnchor097"/>Configuration</h2>
<p>Applications need to<a id="_idIndexMarker318"/> be configured. Information provided during configuration could be – for example – the type of application logging to use, connection strings to databases, and hostnames to services such as ESBs or URIs to external APIs, to name just a few.</p>
<p>We can differentiate a few types of configurations, as follows:</p>
<ul>
<li><strong class="bold">Build time</strong>: This is the information needed during the build of the application and/or its Docker image. It needs to be available when we create the Docker images.</li>
<li><code>DEVELOPMENT</code> versus <code>STAGING</code> or <code>PRODUCTION</code>. This kind of configuration is applied to the application when a container with the app starts – for example, in production.</li>
<li><strong class="bold">Runtime</strong>: This is information that the application retrieves during runtime, such as secrets to access an external API.</li>
</ul>
<h2 id="_idParaDest-101"><a id="_idTextAnchor098"/>Secrets</h2>
<p>Every mission-critical <a id="_idIndexMarker319"/>enterprise application needs to deal with secrets in some form or another. The most familiar secrets are part of the connection information needed to access databases that are used to persist the data produced by or used by the application. Other secrets include the credentials needed to access external APIs, such as a credit score lookup API. It is important to note that, here, we are talking about secrets that have to be provided by the application itself to the service providers the application uses or depends on, and not secrets provided by the users of the application. The actor here is our application, which needs to be authenticated and authorized by external authorities and service providers.</p>
<p>There are various ways traditional applications got their secrets. The worst and most insecure way of providing secrets is by hardcoding them or reading them from configuration files or environment variables, where they are available in cleartext. A much better way is to read the secrets during runtime from a special secret store that persists the secrets encrypted and provides them to the application over a secure connection, such <a id="_idIndexMarker320"/>as <strong class="bold">Transport Layer </strong><strong class="bold">Security</strong> (<strong class="bold">TLS</strong>).</p>
<p>Once again, we need to create an inventory of all the secrets that our application uses and the way it procures them. Thus, we need to ask ourselves where we can get our secrets from: is it through <a id="_idIndexMarker321"/>environment variables or configuration files, or is it by accessing an external keystore, such as HashiCorp Vault, AWS Secrets Manager, or Azure Key Vault?</p>
<h2 id="_idParaDest-102"><a id="_idTextAnchor099"/>Authoring the Dockerfile</h2>
<p>Once we have a <a id="_idIndexMarker322"/>complete inventory of all the items we discussed in the previous few sections, we are ready to author our Dockerfile. But I want to warn you: don’t expect this to be a one-shot-and-go task. You may need several iterations until you have crafted your final Dockerfile. The Dockerfile may be rather long and ugly-looking, but that’s not a problem, so long as we get a working Docker image. We can always fine-tune the Dockerfile once we have a working version.</p>
<h3>The base image</h3>
<p>Let’s start by<a id="_idIndexMarker323"/> identifying the base image we want to use and build our image from. Is there an official Java image available that is compatible with our requirements? Remember that our application is based on Java SE 6. If such a base image is available, then we should use that one. Otherwise, we will want to start with a Linux distro such as Red Hat, Oracle, or Ubuntu. In the latter case, we will use the appropriate package manager of the distro (<code>yum</code>, <code>apt</code>, or another) to install the desired versions of Java and Maven. For this, we can use the <code>RUN</code> keyword in the Dockerfile. Remember, <code>RUN</code> allows us to execute any valid Linux command in the image during <a id="_idIndexMarker324"/>the build process.</p>
<h3>Assembling the sources</h3>
<p>In this step, we <a id="_idIndexMarker325"/>make sure all the source files and other artifacts needed to successfully build the application are part of the image. Here, we mainly use the two keywords of the Dockerfile: <code>COPY</code> and <code>ADD</code>. Initially, the structure of the source inside the image should look the same as on the host, to avoid any build problems. Ideally, you would have a single <code>COPY</code> command that copies all of the root project folders from the host into the image. The corresponding Dockerfile snippet could then look as simple as this:</p>
<pre class="source-code">
WORKDIR /appCOPY . .</pre>
<p class="callout-heading">Note</p>
<p class="callout">Don’t forget to also provide a <code>.dockerignore</code> file, which is located in the project root folder, which lists all the files and (sub)folders of the project root folder that should not be part of the build context.</p>
<p>As mentioned earlier, you can also use the <code>ADD</code> keyword to download sources and other artifacts into the Docker image that are not located in the build context but somewhere reachable by a URI, as shown here:</p>
<pre class="source-code">
ADD http://example.com/foobar ./</pre> <p>This would create a <code>foobar</code> folder in the image’s working folder and copy all the contents from the URI.</p>
<h3>Building the application</h3>
<p>In this step, we<a id="_idIndexMarker326"/> make sure to create the final artifacts that make up our executable legacy application. Often, this is a <code>JAR</code> or <code>WAR</code> file, with or without some satellite JARs. This part of the Dockerfile should mimic the way you traditionally used to build an application before containerizing it. Thus, if you’re using Maven as your build automation tool, the corresponding snippet of the Dockerfile could look as simple as this:</p>
<pre class="source-code">
RUN mvn --clean install</pre> <p>In this step, we may also want to list the environment variables the application uses and provide sensible defaults. But never provide default values for environment variables that provide secrets to the application, such as the database connection string! Use the <code>ENV</code> keyword to define your variables, like this:</p>
<pre class="source-code">
ENV foo=barENV baz=123</pre>
<p>Also, declare all ports that the application is listening on and that need to be accessible from outside of <a id="_idIndexMarker327"/>the container via the <code>EXPOSE</code> keyword, like this:</p>
<pre class="source-code">
EXPOSE 5000EXPOSE 15672/tcp</pre>
<p>Next, we will explain the <code>start</code> command.</p>
<h3>Defining the start command</h3>
<p>Usually, a Java<a id="_idIndexMarker328"/> application is <a id="_idIndexMarker329"/>started with a command such as <code>java -jar &lt;mainapplication jar&gt;</code> if it is a standalone application. If it is a WAR file, then the <code>start</code> command may look a bit different. Therefore, we can either define <code>ENTRYPOINT</code> or <code>CMD</code> to use this command. Thus, the final statement in our Dockerfile could look like this:</p>
<pre class="source-code">
ENTRYPOINT java -jar pet-shop.war</pre> <p>Often, though, this is too simplistic, and we need to execute a few pre-run tasks. In this case, we can craft a script file that contains the series of commands that need to be executed to prepare the environment and run the application. Such a file is often called <code>docker-entrypoint</code><code>.sh</code>, but you are free to name it however you want. Make sure the file is executable – for example, run the following command on the host:</p>
<pre class="source-code">
chmod +x ./docker-entrypoint.sh</pre> <p>The last line of the Dockerfile would then look like this:</p>
<pre class="source-code">
ENTRYPOINT ./docker-entrypoint.sh</pre> <p>Now that you<a id="_idIndexMarker330"/> have been given hints on how to containerize a legacy application, it is time to recap and ask ourselves, is it worth the effort?</p>
<h2 id="_idParaDest-103"><a id="_idTextAnchor100"/>Why bother?</h2>
<p>At this point, I can<a id="_idIndexMarker331"/> see you scratching your head and asking yourself: why bother? Why should you take on this seemingly huge effort just to containerize a legacy application? What are the benefits?</p>
<p>It turns out that <a id="_idIndexMarker332"/>the <strong class="bold">return on investment</strong> (<strong class="bold">ROI</strong>) is huge. Enterprise customers of Docker have publicly disclosed at conferences such as DockerCon 2018 and 2019 that they are seeing these two main benefits of Dockerizing traditional applications:</p>
<ul>
<li>More than a 50% saving in maintenance costs</li>
<li>Up to a 90% reduction in the time between the deployments of new releases</li>
</ul>
<p>The costs saved by reducing the maintenance overhead can be directly reinvested and used to develop new features and products. The time saved during new releases of traditional applications makes a business more agile and able to react to changing customer or market needs more quickly.</p>
<p>Now that we have discussed how to build Docker images at length, it is time to learn how we can ship those images through the various stages of the software delivery pipeline.</p>
<h1 id="_idParaDest-104"><a id="_idTextAnchor101"/>Sharing or shipping images</h1>
<p>To be able to<a id="_idIndexMarker333"/> ship our custom image to other environments, we need to give it a globally unique name. This action is often<a id="_idIndexMarker334"/> called <strong class="bold">tagging an image</strong>. We then need to publish the image to a central location from which other interested or entitled parties can pull it. These central<a id="_idIndexMarker335"/> locations<a id="_idIndexMarker336"/> are called <strong class="bold">image registries</strong>.</p>
<p>In the following sections, we will describe how this works in more detail.</p>
<h2 id="_idParaDest-105"><a id="_idTextAnchor102"/>Tagging an image</h2>
<p>Each image has <a id="_idIndexMarker337"/>a so-called tag. A tag is often used to version images, but it has a broader reach than just being a version number. If we do not explicitly specify a tag when working with images, then Docker automatically assumes we’re referring to the latest tag. This is relevant when pulling an image from Docker Hub, as shown in the following example:</p>
<pre class="source-code">
$ docker image pull alpine</pre> <p>The preceding command will pull the <code>alpine:latest</code> image from Docker Hub. If we want to explicitly specify a tag, we can do so like this:</p>
<pre class="source-code">
$ docker image pull alpine:3.5</pre> <p>This will pull the Alpine image that has been tagged with <code>3.5</code>.</p>
<h2 id="_idParaDest-106"><a id="_idTextAnchor103"/>Demystifying image namespaces</h2>
<p>So far, we have<a id="_idIndexMarker338"/> pulled various images and haven’t worried so much about where those images originated from. Your Docker environment is configured so that, by default, all images are pulled from Docker Hub. We also only pulled so-called official images from Docker Hub, such as <code>alpine</code> or <code>busybox</code>.</p>
<p>Now, it is time to widen our horizons a bit and learn about how images are namespaced. The most generic way to define an image is by its fully qualified name, which looks as follows:</p>
<pre class="source-code">
&lt;registry URL&gt;/&lt;User or Org&gt;/&lt;name&gt;:&lt;tag&gt;</pre> <p>Let’s look at this in a bit more detail:</p>
<table class="No-Table-Style" id="table001-2">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold">Namespace part</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Description</strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><code>&lt;</code><code>registry URL&gt;</code></p>
</td>
<td class="No-Table-Style">
<p>This is the URL to the registry from which we want to pull the image. By default, this is <code>docker.io</code>. More generally, this could be <a href="https://registry.acme.com">https://registry.acme.com</a>.</p>
<p>Other than Docker Hub, there are quite a few public registries out there that you could pull images from. The following is a list of some of them, in no particular order:</p>
<ul>
<li>Google, at <a href="https://cloud.google.com/container-registry">https://cloud.google.com/container-registry</a></li>
<li>Amazon AWS Amazon <strong class="bold">Elastic Container Registry </strong>(<strong class="bold">ECR</strong>), at <a href="https://aws.amazon.com/ecr/">https://aws.amazon.com/ecr/</a></li>
<li>Microsoft Azure, at <a href="https://azure.microsoft.com/en-us/services/container-registry/">https://azure.microsoft.com/en-us/services/container-registry/</a></li>
<li>Red Hat, at <a href="https://access.redhat.com/containers/">https://access.redhat.com/containers/</a></li>
<li>Artifactory, at <a href="https://jfrog.com/integration/artifactorydocker-registry/">https://jfrog.com/integration/artifactorydocker-registry/</a></li>
</ul>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><code>&lt;User&gt;</code> or <code>&lt;Org&gt;</code></p>
</td>
<td class="No-Table-Style">
<p>This is the private Docker ID of either an individual or an organization defined on Docker Hub – or any other registry, for that matter, such as <code>microsoft</code> or <code>oracle</code>.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><code>&lt;</code><code>name&gt;</code></p>
</td>
<td class="No-Table-Style">
<p>This is the name of the image, which is often also called a repository.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><code>&lt;</code><code>tag&gt;</code></p>
</td>
<td class="No-Table-Style">
<p>This is the tag of the image.</p>
</td>
</tr>
</tbody>
</table>
<p>Let’s<a id="_idIndexMarker339"/> look <a id="_idIndexMarker340"/>at an example, as follows:</p>
<pre class="source-code">
https://registry.acme.com/engineering/web-app:1.0</pre> <p>Here, we have an image, <code>web-app</code>, that is tagged with version <code>1.0</code> and belongs to the <code>engineering</code> organization on the private registry at <code>https://registry.acme.com</code>.</p>
<p>Now, there are some special conventions:</p>
<ul>
<li>If we omit the registry URL, then Docker Hub is automatically taken</li>
<li>If we omit the tag, then the <code>latest</code> tag is taken</li>
<li>If it is an official image on Docker Hub, then no user or organization namespace is needed</li>
</ul>
<p>Here are a few samples in tabular form:</p>
<table class="No-Table-Style" id="table002-1">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold">Image</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Description</strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><code>alpine</code></p>
</td>
<td class="No-Table-Style">
<p>The official <code>alpine</code> image on Docker Hub with the <code>latest</code> tag.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><code>ubuntu:22.04</code></p>
</td>
<td class="No-Table-Style">
<p>The official <code>ubuntu</code> image on Docker Hub with the <code>22.04</code> tag or version.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><code>hashicorp/vault</code></p>
</td>
<td class="No-Table-Style">
<p>The <code>vault</code> image of an organization called <code>hashicorp</code> on Docker Hub with the <code>latest</code> tag.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><code>acme/web-api:12.0</code></p>
</td>
<td class="No-Table-Style">
<p>The <code>web-api</code> image version of <code>12.0</code> that’s associated with the <code>acme</code> org. The image is on Docker Hub.</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><code>gcr.io/jdoe/sample-app:1.1</code></p>
</td>
<td class="No-Table-Style">
<p>The <code>sample-app</code> image with the <code>1.1</code> tag belonging to an individual with the <code>jdoe</code> ID in Google’s container registry.</p>
</td>
</tr>
</tbody>
</table>
<p>Now that <a id="_idIndexMarker341"/>we know how the fully qualified name of a Docker image is defined and what its parts are, let’s talk about some special images we can find on Docker Hub.</p>
<h2 id="_idParaDest-107"><a id="_idTextAnchor104"/>Explaining official images</h2>
<p>In the<a id="_idIndexMarker342"/> preceding table, we mentioned “official image” a few times. This needs an explanation.</p>
<p>Images are stored in repositories on the Docker Hub registry. Official repositories are a set of repositories hosted on Docker Hub that are curated by individuals or organizations that are also responsible for the software packaged inside the image. Let’s look at an example of what that means. There is an official organization behind the Ubuntu Linux distro. This team also provides official versions of Docker images that contain their Ubuntu distros.</p>
<p>Official images are meant to provide essential base OS repositories, images for popular programming language runtimes, frequently used data storage, and other important services.</p>
<p>Docker sponsors a<a id="_idIndexMarker343"/> team whose task is to review and publish all those curated images in public repositories on Docker Hub. Furthermore, Docker scans all official images for vulnerabilities.</p>
<h2 id="_idParaDest-108"><a id="_idTextAnchor105"/>Pushing images to a registry</h2>
<p>Creating custom <a id="_idIndexMarker344"/>images is all well and good, but at some point, we want to share or ship our images to a target environment, such as a test, <strong class="bold">quality assurance</strong> (<strong class="bold">QA</strong>), or <a id="_idIndexMarker345"/>production system. For this, we typically use a container registry. One of the most popular public registries out there is Docker Hub. It is configured as a default registry in your Docker environment, and it is the registry from which we have pulled all our images so far.</p>
<p>In a registry, we can usually create personal or organizational accounts. For example, the author’s account at Docker Hub is <code>gnschenker</code>. Personal accounts are good for personal use. If we want to use the registry professionally, then we’ll probably want to create an organizational account, such as <code>acme</code>, on Docker Hub. The advantage of the latter is that organizations can have multiple teams. Teams can have differing permissions.</p>
<p>To be able to push an image to my account on Docker Hub, I need to tag it accordingly. Let’s say I want to push the latest version of the Alpine image to my account and give it a tag of <code>1.0</code>. I can do this in the following way:</p>
<ol>
<li>Tag the existing image, <code>alpine:latest</code>, with this command:<pre class="console">
$ docker image tag alpine:latest gnschenker/alpine:1.0</pre></li> </ol>
<p>Here, Docker does not create a new image but creates a new reference to the existing image, <code>alpine:latest</code>, and names it <code>gnschenker/alpine:1.0</code>.</p>
<ol>
<li value="2">Now, to be able to push the image, I have to log in to my account, as follows:<pre class="console">
$ docker login -u gnschenker -p &lt;my secret password&gt;</pre></li> <li>Make sure to replace <code>gnschenker</code> with your own Docker Hub username and <code>&lt;my secret password&gt;</code> with your password.</li>
<li>After a successful login, I can then push the image, like this:<pre class="console">
$ docker image push gnschenker/alpine:1.0</pre></li> </ol>
<p>I will see something similar to this in the Terminal window:</p>
<pre class="console">
The push refers to repository [docker.io/gnschenker/alpine]04a094fe844e: Mounted from library/alpine
1.0: digest: sha256:5cb04fce... size: 528</pre>
<p>For each image that we push to Docker Hub, we automatically create a repository. A repository can be private or public. Everyone can pull an image from a public repository. From a private<a id="_idIndexMarker346"/> repository, an image can only be pulled if you are logged in to the registry and have the necessary permissions configured.</p>
<h1 id="_idParaDest-109"><a id="_idTextAnchor106"/>Summary</h1>
<p>In this chapter, we discussed what container images are and how we can build and ship them. As we have seen, there are three different ways that an image can be created – either manually, automatically, or by importing a tarball into the system. We also learned some of the best practices commonly used when building custom images. Finally, we got a quick introduction to how to share or ship custom images by uploading them to a container image registry such as Docker Hub.</p>
<p>In the next chapter, we’re going to introduce Docker volumes, which can be used to persist the state of a container. We’ll also show you how to define individual environment variables for the application running inside the container, as well as how to use files containing whole sets of configuration settings.</p>
<h1 id="_idParaDest-110"><a id="_idTextAnchor107"/>Questions</h1>
<p>Please try to answer the following questions to assess your learning progress:</p>
<ol>
<li>How would you create a Dockerfile that inherits from Ubuntu version 22.04, and that installs <code>ping</code> and runs <code>ping</code> when a container starts? The default address used to ping should be <code>127.0.0.1</code>.</li>
<li>How would you create a new container image that uses <code>alpine:latest</code> as a base image and installs <code>curl</code> on top of it? Name the new image <code>my-alpine:1.0</code>.</li>
<li>Create a Dockerfile that uses multiple steps to create an image of a Hello World app of minimal size, written in C or Go.</li>
<li>Name three essential characteristics of a Docker container image.</li>
<li>You want to push an image named <code>foo:1.0</code> to your <code>jdoe</code> personal account on Docker Hub. Which of the following is the right solution?<ol><li><code>$ docker container </code><code>push foo:1.0</code></li><li><code>$ docker image tag </code><code>foo:1.0 jdoe/foo:1.0</code></li><li><code>$ docker image </code><code>push jdoe/foo:1.0</code></li><li><code>$ docker login -u jdoe -p &lt;</code><code>your password&gt;</code></li><li><code>$ docker image tag </code><code>foo:1.0 jdoe/foo:1.0</code></li><li><code>$ docker image </code><code>push jdoe/foo:1.0</code></li><li><code>$ docker login -u jdoe -p &lt;</code><code>your password&gt;</code></li><li><code>$ docker container tag </code><code>foo:1.0 jdoe/foo:1.0</code></li><li><code>$ docker container </code><code>push jdoe/foo:1.0</code></li><li><code>$ docker login -u jdoe -p &lt;</code><code>your password&gt;</code></li><li><code>$ docker image push </code><code>foo:1.0 jdoe/foo:1.0</code></li></ol></li>
</ol>
<h1 id="_idParaDest-111"><a id="_idTextAnchor108"/>Answers</h1>
<p>Here are possible answers to this chapter’s questions:</p>
<ol>
<li>The Dockerfile could look like this:<pre class="console">
FROM ubuntu:22.04RUN apt-get update &amp;&amp; \apt-get install -y iputils-pingCMD ping 127.0.0.1</pre></li> </ol>
<p>Note that in Ubuntu, the <code>ping</code> tool is part of the <code>iputils-ping</code> package. You can build the image called pinger – for example – with the following command:</p>
<pre class="console">
$ docker image build -t mypinger .</pre> <ol>
<li value="2">The Dockerfile could look like this:<pre class="console">
FROM alpine:latestRUN apk update &amp;&amp; \apk add curl</pre></li> </ol>
<p>Build the image with the following command:</p>
<pre class="console">
$ docker image build -t my-alpine:1.0 .</pre> <ol>
<li value="3">The Dockerfile for a Go application could look like this:<pre class="console">
FROM golang:alpineWORKDIR /appADD . /appRUN go env -w GO111MODULE=offRUN cd /app &amp;&amp; go build -o goappENTRYPOINT ./goapp</pre></li> </ol>
<p>You can find the full solution in the <code>~/The-Ultimate-Docker-Container-Book/sample-solutions/ch04/answer03</code> folder.</p>
<ol>
<li value="4">A Docker image has the following characteristics:<ul><li>It is immutable</li><li>It consists of one-to-many layers</li><li>It contains the files and folders needed for the packaged application to run</li></ul></li>
<li>The correct answer is <em class="italic">C</em>. First, you need to log in to Docker Hub; then, you must tag your image correctly with the username. Finally, you must push the image.</li>
</ol>
</div>
</div></body></html>