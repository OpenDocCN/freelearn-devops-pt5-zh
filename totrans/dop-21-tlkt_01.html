<html><head></head><body>
        <section>

            <header>
                <h1 class="header-title">Continuous Integration with Docker Containers</h1>
            </header>

            <article>
                
<div class="packt_quote">It is paradoxical, yet true, to say, that the more we know, the more ignorant we become in the absolute sense, for it is only through enlightenment that we become conscious of our limitations. Precisely one of the most gratifying results of intellectual evolution is the continuous opening up of new and greater prospects.<br/>
                                                                                                                       —Nikola Tesla</div>
<p>To fully understand the challenges and benefits that Docker Swarm brings, we need to start from the beginning. We need to go back to a code repository and decide how are we going to build, test, run, update, and monitor the services we're developing. Even though the objective is to implement continuous deployment to a Swarm cluster, we need to step back and explore <strong>Continuous Integration</strong> (<strong>CI</strong><em>)</em> first. The steps we'll define for the CI process will dictate how we proceed towards <strong>Continuous Delivery</strong> (<strong>CD</strong><em>)</em>, from there towards <strong>Continuous Deployment</strong> (<strong>CDP</strong><em>)</em>, and, finally, how we ensure that our services are monitored and able to self-heal. This chapter explores Continuous Integration as a prerequisite for the more advanced processes.</p>
<div class="packt_tip"><strong>A note to The DevOps 2.0 Toolkit readers<br/></strong>The text that follows is identical to the one published in <em>The DevOps 2.0 Toolkit</em>. If it is still fresh in your mind, feel free to jump to the sub-section <em>Defining a fully Dockerized manual Continuous Integration flow</em> . Since I wrote the <em>2.0</em>, I discovered a few better ways to implement CI processes. I hope you'll benefit from this chapter even if you consider yourself a veteran CI practitioner.</div>
<p>To understand Continuous Deployment we should first define its predecessors, Continuous Integration and Continuous Delivery.<br/>
Integration phase of a project development tended to be one of the most painful stages of <strong>Software Development Life Cycle </strong>(<strong>SDLC</strong>). We would spend weeks, months or even years working in separate teams dedicated to separate applications and services. Each of those teams would have their set of requirements and tried their best to meet them. While it wasn't hard to periodically verify each of those applications and services in isolation, we all dreaded the moment when team leads would decide that the time has come to integrate them into a unique delivery. Armed with the experience from previous projects, we knew that integration would be problematic. We knew that we would discover problems, unmet dependencies, interfaces that do not communicate with each other correctly and that managers will get disappointed, frustrated, and nervous. It was not uncommon to spend weeks or even months in this phase. The worse part of all that was that a bug found during the integration phase could mean going back and redoing days or weeks worth of work. If someone asked me how I felt about integration back then, I'd say that it was closest I could get to becoming permanently depressed. Those were different times. We thought that was the <em>right</em> way to develop applications.</p>
<p>A lot changed since then. <strong>Extreme Programming</strong> (<strong>XP</strong>) and other agile methodologies became familiar, automated testing became frequent, and Continuous Integration started to take ground. Today we know that the way we developed software back then was wrong. The industry moved a long way since those days.</p>
<p>Continuous Integration usually refers to integrating, building, and testing code within the development environment. It requires developers to integrate code into a shared repository often. How often is often can be interpreted in many ways and it depends on the size of the team, the size of the project and the number of hours we dedicate to coding. In most cases, it means that coders either push directly to the shared repository or merge their code with it. No matter whether we're pushing or merging, those actions should, in most cases, be done at least a couple of times a day. Getting code to the shared repository is not enough, and we need to have a pipeline that, as a minimum, checks out the code and runs all the tests related, directly or indirectly, to the code corresponding to the repository. The result of the execution of the pipeline can be either <em>red</em> or <em>green</em>. Something failed, or everything was run without any problems. In the former case, minimum action would be to notify the person who committed the code.</p>
<p>The Continuous Integration pipeline should run on every commit or push. Unlike Continuous Delivery, Continuous Integration does not have a clearly defined goal of that pipeline. Saying that one application integrates with others does not tell us a lot about its production readiness. We do not know how much more work is required to get to the stage when the code can be delivered to production. All we are striving for is the knowledge that a commit did not break any of the existing tests. Nevertheless, CI is a vast improvement when done right. In many cases, it is a very hard practice to implement, but once everyone is comfortable with it, the results are often very impressive.</p>
<p>Integration tests need to be committed together with the implementation code, if not before. To gain maximum benefits, we should write tests in <strong>Test-Driven Development</strong> (<strong>TDD</strong>) fashion. That way, not only that tests are ready for commit together with implementation, but we know that they are not faulty and would not pass no matter what we do. There are many other benefits TDD brings to the table and, if you haven't already, I strongly recommend to adopt it. You might want to consult the <em>Test-Driven Development</em> (<a href="http://technologyconversations.com/category/test-driven-development/">http://technologyconversations.com/category/test-driven-development/</a>) section of the <em>Technology Conversations</em> (<a href="http://technologyconversations.com/">http://technologyconversations.com/</a>) blog.</p>
<p>Tests are not the only CI prerequisite. One of the most important rules is that when the pipeline fails, fixing the problem has higher priority than any other task. If this action is postponed, next executions of the pipeline will fail as well. People will start ignoring the failure notifications and, slowly, CI process will begin losing its purpose. The sooner we fix the problem discovered during the execution of the CI pipeline, the better we are. If corrective action is taken immediately, knowledge about the potential cause of the problem is still fresh (after all, it's been only a few minutes between the commit and the failure notification) and fixing it should be trivial.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Defining a fully Dockerized manual Continuous Integration flow</h1>
            </header>

            <article>
                
<p>Every Continuous Integration process starts with a code that is checked out from a repository. We'll use the GitHub repository <kbd>vfarcic/go-demo</kbd> (<a href="https://github.com/vfarcic/go-demo">https://github.com/vfarcic/go-demo</a>) throughout the book. It contains the code of the service we'll use throughout the book. The service is written in <em>Go</em> (<a href="https://golang.org/">https://golang.org/</a>). Fear not! Even though I consider it one of the best currently available languages, you will not be required to learn Go. We'll use the go-demo service only as a demonstration of the processes explained throughout the book. Even though I strongly recommend learning Go, the book does not assume any knowledge of the language. All the examples will be programming language agnostic.</p>
<div class="packt_infobox">All the commands from this chapter are available in the <kbd>01-continuous-integration.sh</kbd> (<a href="https://gist.github.com/vfarcic/886ae97fe7a98864239e9c61929a3c7c">https://gist.github.com/vfarcic/886ae97fe7a98864239e9c61929a3c7c</a>) Gist.</div>
<div class="packt_tip"><strong>A note to Windows users</strong><br/>
Please make sure that your Git client is configured to check out the code <em>AS-IS</em>. Otherwise, Windows might change carriage returns to the Windows format.</div>
<p>Let's get going and check out the <kbd>go-demo</kbd> code:</p>
<pre>
<strong>git clone https://github.com/vfarcic/go-demo.git</strong><br/><br/><strong>cd go-demo</strong>
</pre>
<p>Some of the files will be shared between the host file system and Docker Machines we'll start creating soon. Docker Machine makes the whole directory that belongs to the current user available inside the VM. Therefore, please make sure that the code is checked out inside one of the user's sub-folders.</p>
<p>Now that we have the code checked out from the repository, we need a server that we'll use to build and run tests. For now, we'll use Docker Machine, since it provides an easy way to create a "Docker ready" VMs on our laptops.</p>
<p>The <em>Docker Machine</em> (<a href="https://docs.docker.com/machine/overview/">https://docs.docker.com/machine/overview/</a>) is a tool that lets you install Docker Engine on virtual hosts, and manage the hosts with the <kbd>docker-machine</kbd> commands. You can use Machine to create Docker hosts on your local Mac or Windows box, on your company network, in your data center, or on cloud providers like AWS or DigitalOcean.</p>
<p>Using <kbd>docker-machine</kbd> commands, you can start, inspect, stop, and restart a managed host, upgrade the Docker client and daemon, and configure a Docker client to talk to your host.</p>
<p>Machine was the only way to run Docker on Mac or Windows previous to <em>Docker v1.12.</em> Starting with the beta program and <em>Docker v1.12</em>, Docker for Mac and Docker for Windows are available as native apps and the better choice for this use case on newer desktops and laptops. I encourage you to try out these new apps. The installers for Docker for Mac and Docker for Windows include Docker Machine, along with Docker Compose.</p>
<div class="packt_infobox">The examples that follow assume that you have <em>Docker Machine version v0.9</em> (<a href="https://www.docker.com/products/docker-machine">https://www.docker.com/products/docker-machine</a>) that includes <em>Docker Engine v1.13+</em> (<a href="https://www.docker.com/products/docker-engine">https://www.docker.com/products/docker-engine</a>). The installation instructions can be found in the <em>Install Docker Machine</em> (<a href="https://docs.docker.com/machine/install-machine/">https://docs.docker.com/machine/install-machine/</a>) page.</div>
<div class="packt_tip"><strong>A note to Windows users</strong><br/>
The recommendation is to run all the examples from <em>Git Bash</em> (installed through <em>Docker Toolbox</em> as well as Git). That way the commands you'll see throughout the book will be same as those that should be executed on <em>OS X</em> or any <em>Linux</em> distribution.</div>
<div class="packt_tip"><strong>A note to Linux users</strong><br/>
Docker Machine on Linux might not be able to mount a host volume inside VMs. The problem is related to the fact that both host and Docker Machine OSes use <kbd>/home</kbd> directory. Mounting <kbd>/home</kbd> from the host would overwrite some of the required files. If you experience problems with mounting of the host volume, please export the <kbd>VIRTUALBOX_SHARE_FOLDER</kbd> variable:<br/>
<kbd>export VIRTUALBOX_SHARE_FOLDER="$PWD:$PWD"</kbd><br/>
If machines are already created, you'll have to destroy them and create them again.<br/>
Please note that this problem should be fixed in newer Docker Machine versions so use this workaround only if you notice that the volume is not mounted (files from the host are not available inside VMs).</div>
<p>Let's create our first server called <kbd>go-demo</kbd> use the following command:</p>
<pre>
<strong>docker-machine create <span class="hljs-operator">-d</span> virtualbox go-demo</strong>
</pre>
<div class="packt_tip"><strong>A note to Windows users</strong><br/>
If you're using <em>Docker for Windows</em> instead of <em>Docker Toolbox</em>, you will need to change the driver from virtualbox to Hyper-V. The problem is that Hyper-V does not allow mounting host volumes, so it is still highly recommended to use <em>Docker Toolbox</em> when working with <em>Docker Machine</em>. The reason behind the choice of running <em>Docker</em> inside <em>Docker Machines</em> instead natively on the host lies in the need to run a cluster (coming in the next chapter). <em>Docker Machine</em> is the easiest way to simulate a multi-node cluster.</div>
<p>The command should be self-explanatory. We specified virtualbox as the driver (or Hyper-V if you're running <em>Docker for Windows</em>) and named the machine <kbd>go-demo</kbd>:</p>
<div class="packt_tip"><strong>A note to Windows users</strong><br/>
In some cases, Git Bash might think that it is still running as BAT. If you experience a problem with the <kbd>docker-machine env</kbd> commands, please export the <kbd>SHELL</kbd> variable:<br/>
<kbd>export SHELL=bash</kbd></div>
<p>Now that the machine is running, we should instruct our local Docker Engine to use it, use the following command:</p>
<pre>
<strong>docker-machine env go-demo</strong>
</pre>
<p>The <kbd>docker-machine env go-demo</kbd> command outputs environment variables required for the local engine to find the server we'd like to use. In this case, the remote engine is inside the VM we created with the <kbd>docker-machine create</kbd> command.</p>
<p>The output is as follows:</p>
<pre>
<strong><span class="hljs-keyword">export</span> DOCKER_TLS_VERIFY=<span class="hljs-string">"1"</span><br/><span class="hljs-keyword">export</span> DOCKER_HOST=<span class="hljs-string">"tcp://192.168.99.100:2376"</span><br/><span class="hljs-keyword">export</span> DOCKER_CERT_PATH=<span class="hljs-string">"/Users/vfarcic/.docker/machine/machines/go-demo"</span><br/><span class="hljs-keyword">export</span> DOCKER_MACHINE_NAME=<span class="hljs-string">"go-demo"</span></strong>
</pre>
<p>We can envelop the <kbd>env</kbd> command into an <kbd>eval</kbd> that will evaluate the output and, in this case, create the environment variables using the following command:</p>
<pre>
<strong><span class="hljs-built_in">eval</span> $(docker-machine env go-demo)</strong>
</pre>
<p>From now on, all the Docker commands we execute locally will be channeled to the engine running inside the <kbd>go-demo</kbd> machine.</p>
<p>Now we are ready to run the first two steps in the CI flow. We'll execute unit tests and build the service binary.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Running unit tests and building service binary</h1>
            </header>

            <article>
                
<p>We'll use Docker Compose for the CI flow. As you will see soon, Docker Compose has little, if any, value when operating the cluster. However, for operations that should be performed on a single machine, Docker Compose is still the easiest and the most reliable way to go.</p>
<p>Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a Compose file to configure your application's services. Then, using a single command, you create and start all the services from your configuration. Compose is great for development, testing, and staging environments, as well as CI workflows.</p>
<p>The repository that we cloned earlier, already has all the services we'll need defined inside the <kbd>docker-compose-test-local.yml</kbd> (<a href="https://github.com/vfarcic/go-demo/blob/master/docker-compose-test-loc">https://github.com/vfarcic/go-demo/blob/master/docker-compose-test-loc</a>) file.</p>
<p>Let's take a look at the content of the <kbd>docker-compose-test-local.yml</kbd> (<a href="https://github.com/vfarcic/go-demo/blob/master/docker-compose-test-local.yml">https://github.com/vfarcic/go-demo/blob/master/docker-compose-test-local.yml</a>) file:</p>
<pre>
<strong>cat docker-compose-test-local.yml</strong>
</pre>
<p>The service we'll use for our unit tests is called <kbd>unit</kbd>. It is as follows:</p>
<pre>
<strong><span class="hljs-symbol">unit:</span><br/><span class="hljs-symbol">    image:</span> <span class="hljs-symbol">golang:</span><span class="hljs-number">1.6</span><br/><span class="hljs-symbol">    volumes:</span><br/>      - .<span class="hljs-symbol">:/usr/src/myapp</span><br/>      - <span class="hljs-regexp">/tmp/go</span><span class="hljs-symbol">:/go</span><br/><span class="hljs-symbol">    working_dir:</span> /usr/src/myapp<br/><span class="hljs-symbol">    command:</span> bash -c <span class="hljs-string">"go get -d -v -t &amp;&amp; go test --cover -v \<br/>./... &amp;&amp; go build -v-o go-demo"</span></strong>
</pre>
<p>It is a relatively simple definition. Since the service is written in <em>Go</em>, we are using the <kbd>golang:1.6</kbd> image.</p>
<p>Next, we are exposing a few volumes. Volumes are directories that are, in this case, mounted on the host. They are defined with two arguments. The first argument is the path to the host directory while the second represents a directory inside the container. Any file already inside the host directory will be available inside the container and vice versa.</p>
<p>The first volume is used for the source files. We are sharing the current host directory <kbd>.</kbd> with the container directory <kbd>/usr/src/myapp</kbd>. The second volume is used for <em>Go</em> libraries. Since we want to avoid downloading all the dependencies every time we run unit tests, they will be stored inside the host directory <kbd>/tmp/go</kbd>. That way, dependencies will be downloaded only the first time we run the service.</p>
<p>Volumes are followed with the <kbd>working_dir</kbd> instruction. When the container is run, it will use the specified value as the starting directory.</p>
<p>Finally, we are specifying the command we want to run inside the container. I won't go into details since they are specific to <em>Go</em>. In short, we download all the dependencies <kbd>go get -d -v -t</kbd>, run <kbd>unit</kbd> tests <kbd>go test --cover -v ./...</kbd>, and build the go-demo binary <kbd>go build -v -o go-demo</kbd>. Since the directory with the source code is mounted as a volume, the binary will be stored on the host and available for later use.</p>
<p>With this single Compose service, we defined two steps of the CI flow. It contains unit tests and build of the binary.</p>
<p>Please note that even though we run the service called <kbd>unit</kbd>, the real purpose of this CI step is to run any type of tests that do not require deployment. Those are the tests we can execute before we build the binary and, later on, Docker images.</p>
<p>Let's run the following code:</p>
<pre>
<strong>docker-compose \ <br/><span class="hljs-operator">    -f</span> docker-compose-test-local.yml \ <br/>    run --rm unit</strong>
</pre>
<div class="packt_tip"><strong>A note to Windows users</strong>  <br/>
You might experience a problem with volumes not being mapped correctly. If you see an <kbd>Invalid volume specification error</kbd>, please export the environment variable <kbd>COMPOSE_CONVERT_WINDOWS_PATHS set</kbd> to  <kbd>0</kbd>:<br/>
<kbd>export COMPOSE_CONVERT_WINDOWS_PATHS=0</kbd><br/>
If that fixed the problem with volumes, please make sure that the variable is exported every time you run <kbd>docker-compose</kbd>.</div>
<p>We specified that Compose should use <kbd>docker-compose-test-local.yml</kbd> file (default is <kbd>docker-compose.yml</kbd>) and run the service called <kbd>unit</kbd>. The <kbd>--rm</kbd> argument means that the container should be removed once it stops. The run command should be used for services that are not meant to run forever. It is perfect for batch jobs and, as in this case, for running tests.</p>
<p>As you can see from the output, we pulled the <kbd>golang</kbd> image, downloaded service dependencies, successfully ran the tests, and built the binary.</p>
<p>We can confirm that the binary is indeed built and available on the host by listing the files in the current directory using the following command. For brevity, we'll filter the result:</p>
<pre>
<strong>ls <span class="hljs-operator">-l</span> *go-demo*</strong>
</pre>
<p>Now that we passed the first round of tests and have the binary, we can proceed and build the Docker images.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Building service images</h1>
            </header>

            <article>
                
<p>Docker images are built through a definition stored in a Dockerfile. With few exceptions, it takes a similar approach as if we would define a simple script. We will not explore all the options we can use when defining a Dockerfile, but only those used for the <kbd>go-demo</kbd> service. Please consult the <em>Dockerfile reference</em> (<a href="https://docs.docker.com/engine/reference/builder/">https://docs.docker.com/engine/reference/builder/</a>) page for more info.<br/>
The <a href="https://github.com/vfarcic/go-demo/blob/master/Dockerfile"><kbd>go-demo</kbd></a> Dockerfile is as follows:</p>
<pre>
<strong>FROM alpine:<span class="hljs-number">3.4</span><br/>MAINTAINER Viktor Farcic &lt;viktor<span class="hljs-variable">@farcic</span>.com&gt;<br/><br/>RUN <span class="hljs-keyword">mkdir</span> /lib64 &amp;&amp; ln -<span class="hljs-keyword">s</span> /lib/libc.musl-x86_64.so.<span class="hljs-number">1</span> /lib64/ld-linux-x86-<span class="hljs-number">64</span>.so.<span class="hljs-number">2</span><br/><br/>EXPOSE <span class="hljs-number">8080</span><br/>ENV DB db<br/>CMD [<span class="hljs-string">"go-demo"</span>]<br/>HEALTHCHECK --interval=<span class="hljs-number">10</span><span class="hljs-keyword">s</span> CMD wget -qO- localhost:<span class="hljs-number">8080</span>/demo/hello<br/><br/>COPY go-demo /usr/<span class="hljs-keyword">local</span>/bin/go-demo<br/>RUN <span class="hljs-keyword">chmod</span> +<span class="hljs-keyword">x</span> /usr/<span class="hljs-keyword">local</span>/bin/go-demo</strong>
</pre>
<p>Each of the statements will be built as a separate image. A container is a collection of images stacked one on top of the other.</p>
<p>Every Dockerfile starts with the <kbd>FROM</kbd> statement. It defines the base image that should be used. In most cases, my preference is to use <kbd>alpine</kbd> Linux. With its size being around 2MB it is probably the smallest distribution we can use. That is aligned with the idea that containers should have only things that are needed and avoid any extra overhead.</p>
<p><kbd>MAINTAINER</kbd> is for informational purposes only.</p>
<p>The <kbd>RUN</kbd> statement executes any command set as its argument. I won't explain this one since it is very specific to the service we're building.</p>
<p>The <kbd>EXPOSE</kbd> statement defines the port the service will be listening to. It is followed by the definition of the environment variable <kbd>DB</kbd> that tells the service the address of the database. The default value is <kbd>db</kbd> and, as you'll see soon, it can be changed at runtime. The <kbd>CMD</kbd> statement represents the command that will be run when containers start.</p>
<p>The <kbd>HEALTHCHECK</kbd> instruction tells Docker how to test a container to check that it is still working. This can detect cases such as a web server that is stuck in an infinite loop and unable to handle new connections, even though the server process is still running. When a container has a healthcheck specified, it has a health status in addition to its normal status. This status is initially starting. Whenever a health check passes, it becomes healthy (from whatever state it was previously in). After a certain number of consecutive failures, it becomes unhealthy.<br/>
In our case, the healthcheck will be executed every ten seconds. The command sends a simple request to one of the API endpoints. If the service responds with status <kbd>200</kbd>, the <kbd>wget</kbd> command will return <kbd>0</kbd> and Docker will consider the service healthy. Any other response will be considered as unhealthy and Docker Engine will perform certain actions to fix the situation.</p>
<p>Finally, we copy the <kbd>go-demo</kbd> binary from the host to the <kbd>/usr/local/bin/</kbd> directory inside the image and give it executable permissions with the <kbd>chmod</kbd> command.</p>
<p>To some, the order of the statements might not look logical. However, there is a good reason behind such declarations and their order. Those that are less likely to change are defined before those that are prone to changes. Since <kbd>go-demo</kbd> will be a new binary every time we build the images, it is defined last.</p>
<p>The reasons behind such order lie in the way Docker Engine creates images. It starts from the top-most definition and checks whether it changed since the last time the build was run. If it didn't, it moves to the next statement. As soon as it finds a statement that would produce a new image, it, and all the statements following it are built into Docker images. By placing those that are less likely to change closer to the top, we can reduce the build time, disk usage, and bandwidth.</p>
<p>Now that we understand the Dockerfile behind the <kbd>go-demo</kbd> service, we can build the images.</p>
<p>The command is very straightforward and is as follows:</p>
<pre>
<strong>docker build -t go-demo .</strong>
</pre>
<p>As an alternative, we can define build arguments inside a Docker Compose file. The service defined in <kbd>docker-compose-test-local.yml</kbd> (<a href="https://github.com/vfarcic/go-demo/blob/master/docker-compose-test-local.yml">https://github.com/vfarcic/go-demo/blob/master/docker-compose-test-local.yml</a>) file is as follows:</p>
<pre>
<strong>  app:<br/>    build: .<br/><span class="hljs-keyword">    image</span>: go-demo</strong>
</pre>
<p>In both cases, we specified that the current directory should be used for the build process <kbd>.</kbd> and that the name of the image is <kbd>go-demo</kbd>.</p>
<p>We can run the build through Docker compose with the command that is as follows:</p>
<pre>
<strong>docker-compose \ <br/><span class="hljs-operator">    -f</span> docker-compose-test-local.yml \ <br/>    build app</strong>
</pre>
<p>We'll use the latter method throughout the rest of the book.</p>
<p>We can confirm that the image was indeed built, by executing the <kbd>docker images</kbd> command as follows:</p>
<pre>
<strong>docker images</strong>
</pre>
<p>The output is as follows:</p>
<pre>
<strong>REPOSITORY <span class="hljs-built_in">TAG</span>    IMAGE ID     CREATED        SIZE<br/>go<span class="hljs-attribute">-demo</span>    latest <span class="hljs-number">5e90126</span>bebf1 <span class="hljs-number">49</span> seconds ago <span class="hljs-number">23.61</span> MB<br/>golang     <span class="hljs-number">1.6</span>    <span class="hljs-number">08</span>a89f0a4ee5 <span class="hljs-number">11</span> hours ago   <span class="hljs-number">744.2</span> MB<br/>alpine     latest <span class="hljs-number">4e38</span>e38c8ce0 <span class="hljs-number">9</span> weeks ago    <span class="hljs-number">4.799</span> MB</strong>
</pre>
<p>As you can see, <kbd>go-demo</kbd> is one of the images we have inside the server.</p>
<p>Now that the images are built, we can run staging tests that depend on the service and its dependencies to be deployed on a server.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Running staging tests</h1>
            </header>

            <article>
                
<p>Please note that the real purpose of this step in the CI flow is to run the tests that require the service and its dependencies to be running. Those are still not integration tests that require production or production-like environment. The idea behind those tests is to run the service together with its direct dependencies, run the tests, and, once they're finished, remove everything and free the resources for some other task. Since these are still not integration tests, some, if not all, dependencies can be mocks.</p>
<p>Due to the nature of these tests, we need to split the task into three actions:</p>
<ol>
<li>Run the service and all the dependencies.</li>
<li>Run the tests.</li>
<li>Destroy the service and all the dependencies.</li>
</ol>
<p>The dependencies are defined as the <kbd>staging-dep</kbd> service inside the <kbd>docker-compose-test-local.yml</kbd> (<a href="https://github.com/vfarcic/go-demo/blob/master/docker-compose-test-local.yml">https://github.com/vfarcic/go-demo/blob/master/docker-compose-test-local.yml</a>) file. The definition is as follows:</p>
<pre>
<strong>  staging-dep:<br/>    image: go-demo<br/>    ports:<br/>      -<span class="ruby"> <span class="hljs-number">8080</span><span class="hljs-symbol">:</span><span class="hljs-number">8080</span><br/></span>    depends_on:<br/>      -<span class="ruby"> db<br/></span><br/>  db:<br/>    image: mongo:3.2.10</strong>
</pre>
<p>The image is <kbd>go-demo</kbd>, and it exposes the port <kbd>8080</kbd> (both on the host and inside the container). It depends on the service <kbd>db</kbd> which is a <kbd>mongo</kbd> image. Services defined as <kbd>depends_on</kbd> will be run before the service that defines the dependency. In other words, if we run the <kbd>staging-dep</kbd> target, Compose will run the <kbd>db</kbd> first.</p>
<p>Let's run the dependencies as shown in the following code:</p>
<pre>
<strong>docker-compose \ <br/><span class="hljs-operator">    -f</span> docker-compose-test-local.yml \<br/>    up <span class="hljs-operator">-d</span> staging-dep</strong>
</pre>
<p>Once the command is finished, we will have two containers running (<kbd>go-demo</kbd> and <kbd>db</kbd>). We can confirm that by listing all the processes:</p>
<pre>
<strong>docker-compose \ <br/><span class="hljs-operator">    -f</span> docker-compose-test-local.yml \<br/>    ps</strong>
</pre>
<p>The output is as follows:</p>
<pre>
<strong><span class="hljs-header">Name                 Command               State Ports<br/>---------------------------------------------------------------------</span><br/>godemo<span class="hljs-emphasis">_db_</span>1          /entrypoint.sh mongod Up    27017/tcp<br/>godemo<span class="hljs-emphasis">_staging-dep_</span>1 go-demo               Up    0.0.0.0:8080-&gt;8080/tcp</strong>
</pre>
<p>Now that the service and the database it depends on are running, we can execute the tests. They are defined as the service staging. The definition is as follows:</p>
<pre>
<strong>  staging:<br/>    extends:<br/>      service: unit<br/>    environment:<br/>      - HOST_IP=localhost:<span class="hljs-number">8080</span><br/>    network_mode: host<br/><span class="hljs-command"><span class="hljs-keyword">command</span>: <span class="hljs-title">bash</span> -<span class="hljs-title">c</span> <span class="hljs-string">"go get -d -v -t &amp;&amp; go test --tags integration -v"</span></span></strong>
</pre>
<p>Since the definition of the staging tests is very similar to those we run as unit tests, the staging service extends unit. By extending a service, we inherit its full definition. Further on, we defined an environment variable <kbd>HOST_IP</kbd>. The tests code uses that variable to determine the location of the service under test. In this case, since the <kbd>go-demo</kbd> service is running on the same server as tests, the IP is server's localhost. Since, by default, localhost inside a container is not the same as the one on the host, we had to define <kbd>network_mode</kbd> as <kbd>host</kbd>. Finally, we defined the command that should be executed. It will download tests dependencies <kbd>go get -d -v -t</kbd> and run the tests <kbd>go test --tags integration -v</kbd>.</p>
<p>Let's run the following commands:</p>
<pre>
<strong>docker-compose \ <br/><span class="hljs-operator">    -f</span> docker-compose-test-local.yml \ <br/>    run --rm staging</strong>
</pre>
<p>All the tests passed, and we are one step closer to the goal of having full confidence that the service is indeed safe to be deployed to production.</p>
<p>We don't have any use for keeping the service and the database running so let's remove them and free the resources for some other task:</p>
<pre>
<strong>docker-compose \ <br/><span class="hljs-operator">    -f</span> docker-compose-test-local.yml \ <br/>    down</strong>
</pre>
<p>The <kbd>down</kbd> command stops and removes all services defined in that Compose file. We can verify that by running the following  <kbd>ps</kbd> command:</p>
<pre>
<strong>docker-compose \ <br/><span class="hljs-operator">    -f</span> docker-compose-test-local.yml \ <br/>    ps</strong>
</pre>
<p>The output is as follows:</p>
<pre>
<strong><span class="hljs-header">Name   Command   State   Ports<br/>------------------------------</span></strong>
</pre>
<p>There is only one thing missing for the CI flow to be complete. At this moment we have the <kbd>go-demo</kbd> image that is usable only inside the go-demo server. We should store it in a registry so that it can be accessed from other servers as well.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Pushing images to the registry</h1>
            </header>

            <article>
                
<p>Before we push our <kbd>go-demo</kbd> image, we need a place to push to. Docker offers multiple solutions that act as a registry. We can use <em>Docker Hub</em> (<a href="https://hub.docker.com/">https://hub.docker.com/</a>), <em>Docker Registry</em> (<a href="https://docs.docker.com/registry/">https://docs.docker.com/registry/</a>), and <em>Docker Trusted Registry</em> (<a href="https://docs.docker.com/docker-trusted-registry/">https://docs.docker.com/docker-trusted-registry/</a>). On top of those, there are many other solutions from third party vendors.</p>
<p>Which registry should we use? Docker Hub requires a username and password, and I do not trust you enough to provide my own. One of the goals I defined before I started working on the book is to use only open source tools so Docker Trusted Registry, while being an excellent choice under different circumstances, is also not suitable. The only option left (excluding third party solutions), is <em>Docker Registry</em> (<a href="https://docs.docker.com/registry/">https://docs.docker.com/registry/</a>).</p>
<p>The registry is defined as one of the services inside the <kbd>docker-compose-local.yml</kbd> (<a href="https://github.com/vfarcic/go-demo/blob/master/docker-compose-local.yml">https://github.com/vfarcic/go-demo/blob/master/docker-compose-local.yml</a>) Compose file. The definition is as follows:</p>
<pre>
<strong>  registry:<br/>    container_name: registry<br/>    image: registry:2.5.0<br/>    ports:<br/>      -<span class="ruby"> <span class="hljs-number">5000</span><span class="hljs-symbol">:</span><span class="hljs-number">5000</span><br/></span>    volumes:<br/>      -<span class="ruby"> .<span class="hljs-symbol">:/var/lib/registry</span><br/></span>    restart: always</strong>
</pre>
<p>We set registry as an explicit container name, specified the image, and opened the port <kbd>5000</kbd> (both on the host and inside the container).</p>
<p>Registry stores the images inside the <kbd>/var/lib/registry</kbd> directory, so we mounted it as a volume on the host. That way, data will not be lost if the container fails. Since this is a production service that could be used by many, we defined that it should always be restarted on failure.</p>
<p>Let's run the following commands:</p>
<pre>
<strong>docker-compose \ <br/><span class="hljs-operator">    -f</span> docker-compose-local.yml \ <br/>    up <span class="hljs-operator">-d</span> registry</strong>
</pre>
<p>Now that we have the registry, we can do a dry-run. Let's confirm that we can pull and <kbd>push</kbd> images to it:</p>
<pre>
<strong>docker pull alpine<br/><br/>docker tag alpine localhost:<span class="hljs-number">5000</span>/alpine<br/><br/>docker push localhost:<span class="hljs-number">5000</span>/alpine</strong>
</pre>
<p>Docker uses a naming convention to decide where to pull and push images from. If the name is prefixed with an address, the engine will use it to determine the location of the registry. Otherwise, it assumes that we want to use Docker Hub. Therefore, the first command pulled the alpine image from Docker Hub.</p>
<p>The second command created a tag of the alpine image. The tag is a combination of the address of our registry <kbd>localhost:5000</kbd> and the name of the image. Finally, we pushed the <kbd>alpine</kbd> image to the registry running on the same server.</p>
<p>Before we start using the registry in a more serious fashion, let's confirm that the images are indeed persisted on the host:</p>
<pre>
<strong>ls -<span class="hljs-number">1</span> docker/registry/v2/repositories/alpine/</strong>
</pre>
<p>The output is as follows:</p>
<pre>
<strong>_layers<br/>_manifests<br/>_uploads</strong>
</pre>
<p>I won't go into details what each of those sub-directories contains. The important thing to note is that registry persists the images on the host so no data will be lost if it fails or, in this case, even if we destroy the VM since that Machine directory is mapped to the same directory on our laptop.</p>
<p>We were a bit hasty when we declared that this registry should be used in production. Even though data is persisted, if the whole VM crashes, there would be a downtime until someone brings it up again or creates a new one. Since one of the goals is to avoid downtime whenever possible, later on, we should look for a more reliable solution. The current setup should do for now.</p>
<p>Now we are ready to push the <kbd>go-demo</kbd> image to the registry:</p>
<pre>
<strong>docker tag go-demo localhost:<span class="hljs-number">5000</span>/go-demo:<span class="hljs-number">1.0</span><br/><br/>docker push localhost:<span class="hljs-number">5000</span>/go-demo:<span class="hljs-number">1.0</span></strong>
</pre>
<p>As with the Alpine example, we tagged the image with the registry prefix and pushed it to the registry. We also added a version number <kbd>1.0</kbd>.</p>
<p>The push was the last step in the CI flow. We run unit tests, built the binary, built the Docker image, ran staging tests, and pushed the image to the registry. Even though we did all those things, we are not yet confident that the service is ready for production. We never tested how it would behave when deployed to a production (or production-like) cluster. We did a lot, but not enough.</p>
<p>If CI were our final objective, this would be the moment when manual validations should occur. While there is a lot of value in manual labor that requires creativity and critical thinking, we cannot say the same for repetitive tasks. Tasks required for converting this Continuous Integration flow into Continuous Delivery and, later on, deployment are, indeed repetitive.</p>
<p>We have the CI process done, and it is time to do the extra mile and convert it into Continuous Delivery.</p>
<p>Before we move into the steps required for the Continuous Integration process to become Continuous Delivery, we need to take a step back and explore cluster management. After all, in most cases, there is no production environment without a cluster.</p>
<p>We'll destroy the VMs at the end of each chapter. That way, you can come back to any of part of the book and do the exercises without the fear that you might need to do some steps from one of the earlier chapters. Also, such a procedure will force us to repeat a few things. Practice makes perfect. To reduce your waiting times, I did my best to keep things as small as possible and keep download times to a minimum. Execute the following command:</p>
<pre>
<strong>docker-machine rm <span class="hljs-operator">-f</span> go-demo</strong>
</pre>
<p>The next chapter is dedicated to the setup and operation of a Swarm cluster.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </body></html>