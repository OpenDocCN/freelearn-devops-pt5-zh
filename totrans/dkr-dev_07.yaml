- en: '*Chapter 5*: Alternatives for Deploying and Running Containers in Production'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As container technology and cloud computing mature, the number of ways in which
    you can deploy your Docker containers has exploded. Some of the options are as
    simple as running Docker on a single host, and others feature advanced features
    such as autoscaling, multi-cloud support, and more. You could even run your Docker
    containers on-premises on bare-metal servers or adopt a hybrid cloud solution.
  prefs: []
  type: TYPE_NORMAL
- en: After reading this chapter, you will understand that the many choices available
    offer different trade-offs. You will learn how to build the smallest viable production
    environment. You will be able to choose between different cloud providers and
    their managed container runtimes, as well as articulate the benefits of running
    Docker either on-premises or in a hybrid cloud. Most importantly, you will be
    able to make an informed decision about choosing a production path for deploying
    Docker containers given competing objectives.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the spectrum of choices will help guide you toward making better
    decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Running Docker in production – many paths, choose wisely
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the minimum realistic production environment?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managed cloud services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running your own Kubernetes cluster – from bare-metal servers to OpenStack
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deciding on the right Docker production setup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To complete the exercises in this chapter, you'll need Git and Docker on your
    local workstation. For Mac and Windows users, please install Docker Desktop ([https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop))
    as this is how most people using Docker use it on their local workstations. You
    need to learn more about the options before you choose a production deployment
    tool.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on what avenues you explore, you may also want to establish accounts
    with Amazon Web Services, Google Cloud, Microsoft Azure, or Digital Ocean. Most
    of these services have fairly generous free tiers that may allow you to experiment
    without spending much money, especially if you only use the services for a short
    duration. When considering what sort of environment might be suitable for your
    application, it helps to have multiple options. If you do create resources in
    the cloud, don't forget to terminate resources that you are done with or are not
    planning to keep, or you could receive a nasty surprise when you see the bill.
    Most cloud providers have a billing alert system. Please consider setting up an
    alarm that will notify you if your spending exceeds your budget.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to explore hosting a more complex on-premises setup, or use a bare-metal
    hosting service such as Packet ([https://www.packet.com/](https://www.packet.com/)),
    you may need one or more server computers that meet the specifications for running
    Docker or OpenStack on bare-metal computer hardware.
  prefs: []
  type: TYPE_NORMAL
- en: The GitHub repository for this chapter is [https://github.com/Packt-Publishing/Docker-for-Developers](https://github.com/Packt-Publishing/Docker-for-Developers)
    – please see the `chapter5` folder inside.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://bit.ly/2DYMria](https://bit.ly/2DYMria)'
  prefs: []
  type: TYPE_NORMAL
- en: Example application – ShipIt Clicker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The linked GitHub repository for this chapter has code for a prototype for an
    online game – called ShipIt Clicker. In this game, a fedora-clad squirrel urges
    you to deploy containers to production; the faster you click, the faster you accumulate
    `docker-compose` to run multiple containers. The game features communications
    between a web browser game client, a Node.js server using Express and a Swagger-driven
    API, and a Redis NoSQL database used to track scores and other game information.
  prefs: []
  type: TYPE_NORMAL
- en: You can experiment with ShipIt Clicker to get familiar with more elaborate applications
    than previous chapters explored. Feel free to adapt and improve both the configuration
    files and the code in conjunction with a variety of tools and services in order
    to learn more about deploying to production. In subsequent chapters, we will learn
    how to deploy this application to production in several different ways, each offering
    progressively more capabilities, but different trade-offs in terms of cost, complexity,
    and availability. Before we do that, let's learn more about these alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: Running Docker in production – many paths, choose wisely
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you thought running Docker on your local workstation offered many choices,
    buckle up as the variety available to developers and system administrators in
    deploying an application built using Docker in a robust way makes the local development
    environment look simple by comparison. Some of the largest information technology
    companies in the world use Docker (or equivalent container technologies) to run
    at a massive scale, and container orchestration makes that possible. The promise
    of having a self-healing cluster that can continue to run applications in the
    face of network partitions and hardware failure has lured many into the Docker
    arena. Many people see their enthusiasm wane when the complexity of running a
    fault-tolerant cluster becomes evident.
  prefs: []
  type: TYPE_NORMAL
- en: However, you don't have to do it all yourself. Multiple cloud providers offer
    services that make running applications with Docker more manageable. The solution
    larger organizations are gravitating toward is Kubernetes, a project sponsored
    by Google as a public and community-supported alternative to proprietary container
    orchestration tools. Kubernetes takes the lessons that Google learned from building
    and operating Borg, their internal container orchestration tool, and makes them
    available to the public.
  prefs: []
  type: TYPE_NORMAL
- en: Or maybe you just need to run a simple dynamic website on as small a setup as
    possible – you don't have to learn cloud orchestration to do that if you have
    access to an internet-connected server that itself can run Docker.
  prefs: []
  type: TYPE_NORMAL
- en: What is the minimum realistic production environment?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Docker can run on a wide variety of hardware and software, but the level of
    support you will receive from either Docker itself or from a third party, such
    as an operating system distribution that bundles Docker, may vary significantly.
    Docker can run on a wide variety of operating systems: Linux, Apple macOS, Microsoft
    Windows, and even IBM S/390x.'
  prefs: []
  type: TYPE_NORMAL
- en: Bare minimum – run Docker and Docker Compose on one host
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given the wide distribution of Docker on different environments, the minimum
    production environment for a Docker-hosted application is a single host, whether
    it is physical or virtual, running an operating system that supports Docker and
    Docker Compose. Many popular mainstream operating systems and distributions have
    some version of Docker built in, including the current **Long-Term Support** (**LTS**)
    versions of Ubuntu (16.04, 18.04, and 20.04) and CentOS (7 and 8). Other more
    specialized operating systems, such as CoreOS and Container Linux, focus exclusively
    on running containers and may be good choices, albeit with a learning curve for
    people used to more mainstream systems.
  prefs: []
  type: TYPE_NORMAL
- en: You could even run Docker on Windows or macOS for a production system. You might
    be more comfortable running Docker on a platform that has support, depending on
    your risk tolerance and needs. Trade-offs abound!
  prefs: []
  type: TYPE_NORMAL
- en: Docker support
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The community edition of Docker receives support from the parent company for
    a very limited time – the developer-focused Docker Inc. company ([https://www.docker.com](https://www.docker.com))
    produces quarterly releases of the **Community Edition** (**CE**) Docker toolchain
    with a 4-month rolling support window. As of November 13, 2019, the **Enterprise
    Edition** (**EE**) of Docker is a Mirantis product; see [https://www.mirantis.com/company/press-center/company-news/mirantis-acquires-docker-enterprise/](https://www.mirantis.com/company/press-center/company-news/mirantis-acquires-docker-enterprise/)
    for more details. The EE version of Docker features longer support horizons; support
    for a variety of Linux, Windows, and macOS operating systems; and an expanded
    set of supported orchestration systems; see [https://docs.docker.com/ee/](https://docs.docker.com/ee/)
    for more information on Docker EE. Mirantis announced that it would end support
    for the  Docker Swarm container orchestrator, a part of Docker EE, in November
    2021, but retracted the retirement announcement in February 2020\. See [https://devclass.com/2020/02/25/mirantis-to-keep-docker-swarm-buzzing-around-pledges-new-features/](https://github.com/PacktPublishing/Docker-for-Developers)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes appears to be the winner of the Docker container orchestration wars,
    given this news, although Mirantis is still supporting Docker Swarm.
  prefs: []
  type: TYPE_NORMAL
- en: Problems with single-host deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Running Docker on a single host has major drawbacks, however. If that host suffers
    a major hardware or software failure or has impaired internet connectivity, your
    application will suffer decreased availability. Computers are fundamentally unreliable
    and even systems that have enterprise availability features, such as redundant
    disks, power supplies, and cooling features, can suffer failures due to environmental
    factors. If you do go down this route, it would be prudent to add some sort of
    external monitoring and ensure you have a reliable backup and restore routine
    to mitigate these risks. In order to avoid these risks, we need to consider more
    sophisticated approaches, such as relying on more container orchestration systems
    that a third party runs.
  prefs: []
  type: TYPE_NORMAL
- en: Managed cloud services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to overcome the limitations of deploying applications on a single
    host, the easiest option to choose is to consider running your application using
    a managed cloud service that provides a container orchestration solution. Some
    of the most popular solutions include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Google Kubernetes Engine** (**GKE**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Web Services **Elastic Beanstalk** (**EB**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Web Services **Elastic Container Service** (**ECS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Web Services **Elastic Kubernetes Service** (**EKS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft **Azure Kubernetes Service** (**AKS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DigitalOcean Docker Swarm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most of these services support running a set of Docker containers through Kubernetes
    ([https://kubernetes.io/](https://kubernetes.io/)), a project initiated by Google.
    For many years, Google has run a container orchestration system called Borg ([https://ai.google/research/pubs/pub43438](https://ai.google/research/pubs/pub43438)),
    and Google used that as inspiration to create a container orchestration system
    suitable for external use, which got named Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Some managed cloud services support Docker Swarm, while others (including AWS
    Elastic Beanstalk and AWS ECS) have their own custom orchestration systems.
  prefs: []
  type: TYPE_NORMAL
- en: All of the container orchestration systems allow software developers and system
    administrators to run a fleet of servers that execute multiple containers simultaneously,
    with policy-based mechanisms for distributing multiple container instances among
    the cluster. The container orchestrators are responsible for starting, monitoring,
    and moving container workloads from host to host as health checks and scaling
    constraints dictate. Since Google popularized running these container orchestration
    systems, many vendors have devised managed service offerings, including Google,
    Microsoft, Amazon Web Services, Digital Ocean, and others, as we will discuss
    in the following subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Google Kubernetes Engine
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Google offers a system called **Google Kubernetes Engine** (**GKE**) ([https://cloud.google.com/kubernetes-engine/](https://cloud.google.com/kubernetes-engine/)),
    which offers a supported Kubernetes cluster running within the Google Cloud. If
    you use this service, you don't have to operate and upgrade the Kubernetes cluster
    master nodes yourself; you won't see the master nodes in the cloud console at
    all, as Google operates them directly. Furthermore, Google does not charge customers
    for running those Kubernetes master nodes. This option is appealing to developers
    because it has a way to run low-cost Kubernetes clusters. Having the support directly
    from Google to run Kubernetes workloads gives some customers additional confidence
    with this system.
  prefs: []
  type: TYPE_NORMAL
- en: However, Google Cloud is not the first or even the second biggest cloud provider,
    and the rest of the services available from Google Cloud are not as varied as
    the services that Azure, AWS, or other cloud providers such as AliBaba offer.
  prefs: []
  type: TYPE_NORMAL
- en: If you are invested in Google Cloud, or you want a low-cost environment to experiment
    with Kubernetes or take it to production and you are not tied to cloud services
    from other providers, evaluate GKE for running Docker and Kubernetes loads.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Elastic Beanstalk
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon Web Services offers a way to run Docker applications through its platform-as-a-service
    offering, Elastic Beanstalk ([https://aws.amazon.com/elasticbeanstalk/](https://aws.amazon.com/elasticbeanstalk/)).
    You can run either single Docker containers or a setup that supports multiple
    Docker containers. Under the covers, Elastic Beanstalk uses ECS if you select
    multiple containers. With Elastic Beanstalk, developers use a command-line interface
    tool that simplifies deployment to multiple environments, in conjunction with
    some concise configuration files that hide some of the complexity of running an
    autoscaling cluster.
  prefs: []
  type: TYPE_NORMAL
- en: It is easier to set up Elastic Beanstalk than it is to set up either ECS or
    EKS, and developers needing an easy on-ramp to get to production with low overhead
    and minimal setup might consider using Elastic Beanstalk.
  prefs: []
  type: TYPE_NORMAL
- en: AWS ECS and Fargate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'AWS also offers a container orchestration system called ECS ([https://aws.amazon.com/ecs/](https://aws.amazon.com/ecs/)).
    ECS has two basic modalities: one where containers run on a fleet of EC2 instances
    managed directly by the account owner, and one where AWS manages the nodes that
    containers run on, called Fargate ([https://aws.amazon.com/fargate/](https://aws.amazon.com/fargate/)).'
  prefs: []
  type: TYPE_NORMAL
- en: Using ECS with either EC2 or Fargate can make sense if you are invested in AWS.
    While this path allows you to deploy containers without having to deal with Kubernetes
    or Docker Swarm, however, it is a proprietary system that only AWS supports, so
    you would have to do extra work to move your systems away from it compared to
    using Kubernetes or Docker Swarm as an orchestrator. It has its own learning curve
    and requires that you commit to running your Docker workloads on AWS because these
    interfaces are AWS-specific.
  prefs: []
  type: TYPE_NORMAL
- en: AWS EKS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon Web Services (AWS) offers EKS, a managed Kubernetes service that offloads
    the maintenance and configuration of the Kubernetes master servers to AWS. EKS
    is the AWS equivalent of Google's GKE. It offers robust integration with the rest
    of the AWS services, and even though it is not as economical as the GKE service
    with respect to running the Kubernetes masters, the baseline costs are modest
    compared with the cost of running a busy application. AWS has generally had support
    available for Kubernetes through EKS since 2018 and has fixed enough of the initial
    rough spots that surfaced after its launch (such as a lack of support for some
    common autoscaling strategies) to make EKS a formidable Kubernetes distribution.
    In December 2019, AWS announced support for running Kubernetes containers managed
    by EKS through Fargate, melding the support AWS has for EKS with the managed container
    runtime and elastic and transparent provisioning that AWS provides.
  prefs: []
  type: TYPE_NORMAL
- en: AWS has the largest and most comprehensive set of services available from a
    cloud provider as of early 2020\. If you have an investment in AWS, and you want
    a well-trod path that many people have traveled, consider using AWS EKS as your
    Kubernetes master environment.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Azure Kubernetes Service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Microsoft Azure provides a robust container deployment service in **Azure Kubernetes
    Service** (**AKS**). This option may be particularly appealing if you or your
    company have a large investment in Microsoft platform tooling, including Windows,
    Visual Studio Code, or Active Directory. Microsoft claims to have robust support
    for all these concerns. The developer tooling from Microsoft also tends to have
    a gentler learning curve than the tools from some other organizations. However,
    if you rely really heavily on elements of the Microsoft stack, it may be more
    difficult to migrate to other solutions.
  prefs: []
  type: TYPE_NORMAL
- en: If you are working for a Microsoft shop, or you want an easy on-ramp to Kubernetes
    that is tightly integrated into Visual Studio Code, consider AKS.
  prefs: []
  type: TYPE_NORMAL
- en: Digital Ocean Docker Swarm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Digital Ocean provides support for running a fleet of containers using Docker
    Swarm, a relatively simple container orchestration system. This technology has
    a reputation for being easier to deploy than deploying containers on Kubernetes
    or even AWS ECS. The Docker tooling has support for deploying to Docker Swarm
    out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: However, after the Mirantis acquisition, Docker Swarm's support status was deprecated
    and then revived after customers demanded continuing support. Given the wavering
    commitment from the main vendor supporting it, you should carefully consider whether
    you should field new applications using Docker Swarm.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen what the alternatives entail for running Docker applications
    in production, let's examine the set of alternatives for running applications
    using Docker and Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Running your own Kubernetes cluster – from bare metal to OpenStack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you must run your application on-premises, in a data center, or if you have
    the need to run across multiple cloud computing providers, you may need to run
    your own Kubernetes cluster. Once you learn more about the benefits and drawbacks
    of running Docker and Kubernetes either on-premises or in a hybrid cloud, you
    should be able to know when it is an appropriate solution. While these scenarios
    are more complex than using one of the managed services, they can provide different
    benefits, listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading cluster software (or not) on your own schedule, with full control
    of what versions you run today and tomorrow. Cloud vendors may lag in what versions
    are supported, or deprecate versions in ways that can impose operational risk.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using one of the many mature Kubernetes provisioning solutions, such as Kops,
    that  facilitate setting up k8s clusters on AWS EC2.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operating a hybrid cloud solution across a mixture of data center and cloud
    computing environments. While some cloud provider solutions, such as Google Cloud
    Anthos or Azure Arc, can support hybrid environments, many do not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running high-performance Kubernetes clusters on bare metal, without the overhead
    of a hypervisor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running on platforms not supported by major cloud vendors, such as running Docker
    and Kubernetes on a cluster of Raspberry Pi computers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having complete control over the supporting infrastructure of your cluster integrating
    with a platform that uses Kubernetes as a starting point, such as the OpenShift
    platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running on a private cloud solution, such as OpenStack or VMware Tanzu (formerly
    known as VMware Enterprise PKS).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Docker containers as part of a comprehensive computing platform that
    has other major features and capabilities beyond vanilla Kubernetes, such as Red
    Hat OpenShift or Rancher.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In practice, running any of these solutions is more complex than relying on
    either a single-host deployment of Docker or a vendor-managed software-as-a-service
    Kubernetes clustering solution.
  prefs: []
  type: TYPE_NORMAL
- en: Deciding on the right Docker production setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Because of the bewildering number of choices, picking the right path to deploy
    your application in production is daunting. You may need to weigh many factors,
    including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Setup**: How hard is it to go from local development to production?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Features**: Deployment, testing, monitoring, alerting, and cost reporting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost**: Initial and ongoing monthly charges.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Support**: Is support easily available either from vendors or from the community?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Elasticity**: Can it scale out as the load increases, with automatic or manual
    controls?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Availability**: Can the setup survive the loss of services, hosts, and networks?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stickiness**: How hard will it be to change the deployment strategy?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Docker on a single host is inexpensive and easy to set up but has poor
    scaling and availability characteristics. All the major cloud orchestration services
    that support Kubernetes are well-balanced in terms of features and scaling and
    availability characteristics, but they are more complex to set up and operate.
    The non-Kubernetes options are stickier than the Kubernetes options. Running your
    own clusters either in the cloud, on bare-metal servers, or in a hybrid cloud
    gives you enormous flexibility at the cost of increased complexity and support
    burden.
  prefs: []
  type: TYPE_NORMAL
- en: Learning the relative strengths and weaknesses of these systems will help you
    judge the right set of technologies to use to deploy your applications. The following
    matrix shows my snap judgements on a scale of 1 to 5, where 5 is the best, of
    how well the different technology options compare.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B11641_Table_5.1.jpg)![](img/B11641_Table_5.1a.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You can use this matrix to help rank alternative solutions. By comparing two
    or more of the choices, you can get a better idea of what sort of solution would
    be appropriate. In order to evaluate this matrix, you could build an evaluation
    table where you compare alternatives. If you rank the priorities with a number,
    where 5 is the highest priority and 1 is the lowest priority, you can multiply
    the priority by the scores in Table 1 in order to get a scaled score.
  prefs: []
  type: TYPE_NORMAL
- en: The following example matrix has priorities that emphasize ease of setup, minimization
    of cost, and minimization of stickiness, while disregarding robustness in the
    form of high availability or elasticity under load. That set of priorities matches
    up with the priorities many real-world applications have when they first launch
    – the struggle developers face is often to get things up and running quickly,
    and it is OK to compromise on the other factors. The scaled scores in the Alternative
    columns represent the result of multiplying the priority versus the Production
    Alternatives Rank table for each alternative.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B11641_Table_5.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In this case, alternative 1, Docker on a single host, has the highest-ranked
    scaled score, 78 versus 74\. The factors that are important, setup, cost, and
    stickiness, combine with the weights to push it above the other alternative. Given
    this score, you should consider using that deployment alternative. Consider though
    that if the availability or elasticity priority was even one notch higher, the
    other alternative, Google Cloud GKE, would have been the higher-ranking service.
  prefs: []
  type: TYPE_NORMAL
- en: You may find that your needs are served by a hybrid solution also, where more
    than one of the solutions is appropriate and necessary to solve your problems.
    For example, you might find that your everyday demands tilt toward an on-premises
    cluster, but peak demand might require scaling out into the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise – join the ShipIt Clicker team
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's pretend that you have just joined the ShipIt Clicker development team.
    Other people on the team have created the basic design for the game (see the game
    design document in [https://github.com/PacktPublishing/Docker-for-Developers/blob/master/chapter5/ShipIt_Clicker-spec.md](https://github.com/PacktPublishing/Docker-for-Developers/blob/master/chapter5/ShipIt_Clicker-spec.md))
    and written a prototype that has only the bare minimum required functionality
    to build, test, and package the application with Docker.
  prefs: []
  type: TYPE_NORMAL
- en: The rest of the team might be experts in design, or frontend or backend development,
    but they are not sure how they should proceed regarding deploying to production.
    At this point, you have more experience using Docker than any of the other developers
    on the team. The Dockerfile and `docker-compose.yml` files they have produced
    are functioning.
  prefs: []
  type: TYPE_NORMAL
- en: Get the ShipIt Clicker—the version made for this chapter—running on your local
    workstation to better understand how it is put together.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run `docker-compose up` in order to start the containers on your local machine.
    This will allow you to evaluate the deployment alternatives and experiment with
    changes that will prepare the application for production use. You will see output
    similar to the following; we will explain in detail what each group of lines in
    the output means:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The preceding output shows Docker using the `ubuntu:bionic` image, and then
    the installation of the operating system packages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Steps 3-5 of the Dockerfile prepare the container image for the application
    installation by creating essential directories and copying the package configuration
    file for node modules into place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, the Dockerfile installs the node modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'After this, the Dockerfile copies more configuration files into the container
    image, as well as copying the sources for the application itself into place within
    the container under `/app`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the Dockerfile tells Docker what port to expose and how to run the
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, the Docker container is built, and Docker applies the `latest`
    tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The power of using `docker-compose up` is on display next, as the one command
    we ran at the beginning not only builds the Docker container for our application,
    but it also starts all the containers together. When it starts the containers,
    it starts both the application container, and the Redis container. The Redis container
    emits some detailed output as part of its startup. The output of our `docker-compose
    up` command continues with container startup messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that Redis is not entirely happy being run as part of a Docker container
    that uses a Linux kernel that is not tuned explicitly for it. This is an example
    where using Docker might not yield optimal results, but results that are good
    enough anyway:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that Redis is now ready to go. Next, `docker-compose` starts up
    the ShipIt Clicker container, using the command given in the preceding `ENTRYPOINT
    DEBUG` output (`''shipit-clicker:*'' npm run dev`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have done this, you can play the game by going to `http://localhost:3005/`
    in a web browser. In the following figure, we see the output of the main menu
    of the game, with a link to the API documentation at `http://localhost:3005/api-explorer/`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – ShipIt Clicker game main menu](img/B11641_05_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – ShipIt Clicker game main menu
  prefs: []
  type: TYPE_NORMAL
- en: Once you have the application running and have explored it, you can learn how
    to deploy it in different ways.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise – choosing from reasonable deployment alternatives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The setup in this chapter works to get the game running on a local development
    environment. However, the setup has some issues that might cause problems for
    a production deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The initial audiences for the game in this prototype stage are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Your fellow game developers and the management team of the company
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A globally distributed team of enthusiasts who signed up for an Alpha program
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A professional cadre of testers twelve time zones away from where you live
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Management wants to get the prototype available for the alpha tester volunteers
    and the professional testers as soon as possible, but wants to know what the options
    and costs will be to support a more robust deployment environment that can scale
    if the game goes viral or the investors approve an ad campaign to boost subscribers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your tasks, given what you know about Docker and the alternatives for deploying
    to production, are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Advise management on what the first production deployment should be, after constructing
    a *Production Decision Alternatives* table.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advise management on what one or more reasonable alternatives to the first deployment
    would be, which would increase elasticity and availability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build a spreadsheet model of the one-time and recurring costs incurred over
    the first year for each option, after consulting current price lists from vendors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Compare your decision matrix to the preceding example in the *Deciding on the
    right Docker production setup* section and see whether your result differs. Show
    the spreadsheet model of costs and your decision matrix to a colleague and ask
    them what they might choose and whether they agree with your decision.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise – Dockerfile and docker-compose.yml evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Management wants you to stretch a little and help smooth the way for a production
    deployment. They want you to identify areas for improvement:'
  prefs: []
  type: TYPE_NORMAL
- en: Are the choices made in the Dockerfile and `docker-compose.yml` files reasonable
    for this application?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What choices could be made to better prepare the application for a production
    deployment?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What effect does the choice of a commodity operating system distribution have
    when choosing a container base to use in `FROM`?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Look at the versions of the Dockerfile and `docker-compose.yml` files in [https://github.com/PacktPublishing/Docker-for-Developers/tree/master/chapter6](https://github.com/PacktPublishing/Docker-for-Developers/tree/master/chapter6)
    and see how your recommendations line up. We will explore this in more detail
    in [*Chapter 6*](B11641_06_Final_NM_ePub.xhtml#_idTextAnchor102), *Deploying Applications
    with Docker Compose*.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have learned more about the alternatives for deploying Docker containers
    into production, and done some practical exercises, let's review what we have
    learned.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the alternatives for deploying your Docker-based
    application to production. We learned that the many choices involve trade-offs,
    and how to build the smallest viable production environment. We learned how to
    choose between different cloud providers and their managed container runtimes,
    and how to articulate the benefits of running Docker either on-premises or in
    a hybrid cloud. We also learned how to decide on a production path for deploying
    Docker containers given competing objectives.
  prefs: []
  type: TYPE_NORMAL
- en: Given these lessons, you can apply what you have learned to create a real production
    deployment. Having enough context about the technology alternatives is very important
    – because different strategies offer different advantages and disadvantages. Your
    company might need a super-robust autoscaling deployment in the future but might
    only need something that works today.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will show how you can create a robust single-host Docker
    production deployment while maintaining the ability to develop locally.
  prefs: []
  type: TYPE_NORMAL
