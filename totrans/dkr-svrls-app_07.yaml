- en: Operating FaaS Clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the hardest things about having a system up and running is administering
    and maintaining our own clusters. Although serverless is a paradigm aimed at solving
    this problem entirely, in reality, there are some situations where we still need
    to provision and take care of servers by ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind serverless and Docker is to have a balance between reducing
    cluster maintenance and administration, and having full control of the cluster.
    Using Docker is a great way to help balance this.
  prefs: []
  type: TYPE_NORMAL
- en: Along with this balance, the most attractive driving factor for serverless is
    the *price model*. However, we have found that using Docker on EC2 Spot instances,
    given the competitive price, is sometimes even cheaper than AWS Lambda or other
    cloud functions. So with Spot instances, we will get the cheaper price, while
    our functions will not hit any limitation found in AWS Lambda or others.
  prefs: []
  type: TYPE_NORMAL
- en: Operating Docker-based FaaS clusters uses the same techniques as operating Docker
    clusters. We need to mix the techniques of running standalone Docker together
    with the techniques to utilize the Docker Swarm mode. This chapter focuses on
    *configuration stabilization*, how to prepare the new ingress layer, how to use
    a network plugin, how to set up the logging system, and how to operate the cluster
    using Golang scripting.
  prefs: []
  type: TYPE_NORMAL
- en: Stabilizing the configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start by carefully stabilizing the cluster configuration. At the time
    of writing, a Docker cluster works best with the following configuration. *Figure:
    7.1* illustrated in this section depicts it well:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ubuntu Server 16.04.3 LTS**: Although Red Hat Linux or CentOS may work best
    for you, Ubuntu Server is easy to handle. We are constantly informed that Docker
    has been really well tested with Ubuntu Server. If you choose to use Red Hat or
    CentOS, please go with version 7.4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Linux Kernel 4.4 LTS**: The 4.4 kernel is an LTS and it''s great for Docker.
    You can also use kernel 4.9 but the kernel, like 4.13, is still too new for Docker.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overlay2** **as the Docker storage driver**: Although the **advanced multi-layered
    unification filesystem** (**AUFS**) has worked well for Docker for quite a long
    time, overlay2 should be the new default storage driver for Docker running on
    the 4.4+ kernel. If you get a chance to run a production cluster on CentOS or
    RHEL 7.4, overlay2 is also a good option on these distributions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Docker CE 17.06.2** **or 17.09.1**: Docker EE 17.06 is also a great option,
    if you can afford the enterprise edition:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/43707075-e64a-4bdb-93a6-63f8b53205c4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.1: A stabilized Docker Swarm stack with Træfik and WeaveWorks network
    plugin'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the right network plugin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a long time, people have said that the default Docker overlay network is
    not great for production. Although the quality of the overlay network driver is
    getting better and better, we may look at some other network plugins for optimum
    results. We can replace the default overlay driver with other plugins, for example,
    WeaveWorks or Contiv. We use WeaveWorks network plugin version 2 in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '*Why WeaveWorks?*'
  prefs: []
  type: TYPE_NORMAL
- en: The WeaveWorks network plugin for Docker uses the same underlying network implementation
    as those of Kubernetes CNI. It has also been battle tested by its development
    team, WeaveWorks Inc. Additionally, it has been working really great so far, on
    my production clusters.
  prefs: []
  type: TYPE_NORMAL
- en: WeaveWorks network plugin version 2.1.3, in order to avoid disconnection bugs
    found in the current version of the overlay network driver, it is recommended
    entirely removing the default ingress network, which is based on the default overlay
    network driver, in production. A question may be raised here. If the ingress network
    is removed, we will lose the whole routing mesh, so then how can we route traffic
    into the cluster? The answer is in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: New ingress and routing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As previously mentioned, we will not use the default Docker *ingress network*
    for *routing requests* to the running container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98d729e9-1aa1-4d8b-8e19-a99df09ecaa6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.2: The new ingress layer built on top of Træfik, connected to underlying
    Swarm tasks to form a routing mesh'
  prefs: []
  type: TYPE_NORMAL
- en: 'Yes, we will lose the routing mesh, but we will build our own instead. As shown
    in the previous figure, we will replace the default routing mesh with a new ingress
    layer built on top of an L7 load balancer, **Træfik**. You can choose one from
    the following list of stable versions:'
  prefs: []
  type: TYPE_NORMAL
- en: Træfik v1.4.5 (`traefik@sha256:9c299d9613`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Træfik v1.4.6 (`traefik@sha256:89cb51b507`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The advantage of using Træfik is that the newly built ingress layer is better
    stabilized. Each service is automatically resolved to be a list of IP addresses
    by Træfik. So you can choose to use either an IPVS-based load balancer offered
    by Docker Swarm, or the built-in mechanism offered by Træfik itself.
  prefs: []
  type: TYPE_NORMAL
- en: As Træfik works with the L7 layer, we are additionally allowed to match services
    with the hostname, and forward the request to a certain task of the matched service.
    Also, with this new implementation, we could flexibly restart or re-configure
    the ingress layer on-the-fly without touching the running services. This has been
    a weak point of the Docker's ingress layer for a very long time.
  prefs: []
  type: TYPE_NORMAL
- en: Tracing component
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the architecture proposed in this book, we use Envoy as a sidecar proxy
    for every deployed function. With Envoy, it allows distributed trace calling between
    functions, as in illustrated in the following figure, even if they are prepared
    by or deployed to different FaaS platforms. This is really an important step for
    avoiding vendor lock-in. Envoy is compiled and pushed to Docker hub incrementally.
    We have picked a certain version of Envoy for this book: **E****nvoyProxy**, `envoyproxy/envoy:29989a38c017d3be5aa3c735a797fcf58b754fe5`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b96914b6-55b6-460b-bed4-f0241670efac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.3: A block diagram showing the distributed tracing mechanism with
    Envoy'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows two levels of implementation for the sidecar proxy
    pattern. First, we directly tweak the `Dockerfile` of a function or a service
    by embedding the **EnvoyProxy** binary into the Docker image. This technique yields
    the best performance because **EnvoyProxy** talks to the function program through
    the **loopback** interface inside the container. But when we need to change the
    configuration of Envoy, such as *retry* or *circuit breaker*, we need to restart
    the **EnvoyProxy** together with the function instance, shown as the first (**1**)
    configuration in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9ed59fa0-2acc-46b3-8d8a-1cc2742e5095.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4: Two configurations to implement Envoy as (1) sidecar proxy and
    (2) edge proxy'
  prefs: []
  type: TYPE_NORMAL
- en: So the better configuration when it comes to flexibility and management is the
    second (**2**) configuration, where we separate **EnvoyProxy**, as an edge proxy,
    out of the function container. The trade-off here is the network overheads between
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Retry and circuit breaker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we discuss one of the most interesting topics to date: the
    retry and circuit breaker pattern. It would be great to get familiar with this
    concept before proceeding to implementing a production cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: Retry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The problem solved by retry and circuit breaker stems from cascade failures
    caused by a service or a function inside a chain of calling becoming unavailable.
    In the following figure, we assume that five different functions or services have
    99% availability, so they will fail once every 100 calls. The client observing
    this service''s chain will experience the availability of **A** at only **95.09%**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf31eea3-05e5-4a42-8990-4654a64e0bc7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.5: A chain of functions or microservices would make their overall
    availability lower'
  prefs: []
  type: TYPE_NORMAL
- en: What does this imply? It means that when this chain becomes eight functions
    long, the availability will become 92.27%, and if it's 20 functions long, this
    figure will decrease to 81.79%. To reduce the failure rate, we should retry calling
    to another instance of function or service when an error, such as HTTP 500, occurs.
  prefs: []
  type: TYPE_NORMAL
- en: But a simple or constant-rate retry is not enough. If we use a simple strategy,
    our retry calls would increase unnecessary loads to the already broken service.
    This would cause more problems than it would solve.
  prefs: []
  type: TYPE_NORMAL
- en: Circuit breaker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To resolve this problem, many retry pattern implementations usually come with
    **Exponential Back-off Retry**. With the exponential back-off strategy, we gradually
    increase the delay between each retry. For example, we may retry the second call
    to the service 3 seconds after the fault occurs. If the service still returns
    an error, we increase the delay to 9 seconds and 27 seconds, for the third and
    fourth calls respectively. This strategy leaves some room for the service to recover
    from transient faults. The difference between two kinds of retry strategies is
    shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0abeef59-8c82-41bf-9643-5f04d99e7d9a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.6: The difference between the constant-rate retry and exponential
    back-off retry strategies'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing a production cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will discuss how to prepare a production Docker Swarm cluster
    to run FaaS platforms at the cheapest rate possible on AWS Spot instances. The
    cost of deploying a Docker cluster would be as cheap as running codes on AWS Lambda,
    but it allows us to control almost everything in our cluster. If the deployment
    policy is cost-driven, this is the best way to go.
  prefs: []
  type: TYPE_NORMAL
- en: Cost savings with Spot instances
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we are talking about the cloud, its on-demand instances are actually cheap
    already. However, in the long run, the price of using cloud instances will be
    similar to buying real machines. To solve this pricing problem, major cloud providers,
    such as Amazon EC2, and Google Cloud Platform, provide a new instance type, collectively
    called a **Spot instance** in this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/18255aa6-7399-4cf8-83df-42ed2065c696.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.7: Comparison of shutdown signals of a Spot instance on AWS versus
    Google Cloud'
  prefs: []
  type: TYPE_NORMAL
- en: Spot instances are far cheaper than on-demand instances. However, their weak
    point is the short life cycle and unexpected termination. That is, a Spot instance
    could be terminated at any time. When it is gone, you have a choice as to whether
    to preserve or completely discard the volumes. On AWS, the instance will get the
    notification around 120 seconds before termination via remote metadata, while
    on Google Cloud, the notification will be sent via an ACPI signal 30 seconds before
    the machine stops. The rough comparison is shown in the previous figure.
  prefs: []
  type: TYPE_NORMAL
- en: We could put stateless computing to run on these kinds of instances. Both microservices
    and functions are naturally stateless, so Spot instances fit with the deployment
    of microservices and functions nicely.
  prefs: []
  type: TYPE_NORMAL
- en: With this kind of infrastructure on cheap instances, its cost will be comparable
    to AWS Lambda or Google Cloud Functions, but we are more in control of the overall
    system, meaning no invocation timeout for functions on this kind of infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Using EC2 Spot instances
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'On Amazon EC2, go to [https://aws.amazon.com/ec2/spot/](https://aws.amazon.com/ec2/spot/) and
    we will find the page as shown in the following screenshot. Log onto the AWS Console
    for Spot instances to set up some of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0db6a15c-462f-4395-8ee5-28d1bf12fe96.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.8: The landing page of AWS Spot instances'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the navigation bar, we see Spot Requests. Click it to go to the Spot Requests
    screen as shown in the following screenshot. On this screen, clicking Request
    Spot Instances starts the request process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e688906e-192c-4731-a8c2-881348b7bc76.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.9: The Spot Requests screen on AWS displaying a request with its associated
    instances'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three models for requesting Spot instances:'
  prefs: []
  type: TYPE_NORMAL
- en: One-time request. This is one time only, so when the instance is gone, we need
    to do another request.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Request a fleet of instances and let AWS maintain the number of target instances.
    When some instances are terminated, AWS will try its best, depending on our maximum
    bidding price, to allocate instances to meet the target numbers of each fleet.
    We have opted for this request model in this chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Request instances for a fixed period of time. A fixed period is called a **Spot
    block**, which is between 1 and 6 hours. We will pay more if we set the longer
    period.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows what the cluster in preparation will look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e5d916bd-1965-4eec-b6cb-fe704ca74c96.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.10: A Docker cluster forming on Spot instances using an automatic
    operator to take care of it'
  prefs: []
  type: TYPE_NORMAL
- en: Assume that we already have three boxes provisioned to be managers. To get the
    cheapest rate possible, it is recommended using three on-demand EC2 nodes as Docker
    managers, and N-3 Spot instances as Docker workers. We start small with three
    Spot workers.
  prefs: []
  type: TYPE_NORMAL
- en: If possible, choose a cloud provider that allows you to create a private network
    and floating IPs. We will form a Docker cluster on the private network. Most cloud
    providers allow this, so do not worry.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, SSH into a node we would like to be the first manager, install Docker,
    and run the `docker swarm init` command on it. The `eth0` is the private network
    interface provided by the cloud provider. Check yours using the `ip addr` command
    before proceeding. If you know which interface is the private one, initialize
    the cluster using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, SSH into the other two nodes. Install Docker and join the cluster using
    the `docker swarm join` command. Do not forget that we need to use the join token
    for the *manager*, not for the worker. The token in the following example is the
    manager token. Please note that my first manager''s IP is `172.31.4.52` during
    this setup. Replace it with your IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: For these first three nodes, do not forget to label them as managers to help
    you remember.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, please make sure that `docker info` shows the list of managers, containing
    all their private IP addresses. We use `grep -A3` to see the next three lines
    after the target:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, if you are familiar with the `jq` command, try the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `docker info` command also accepts `--format` to let us customize the output.
    In the previous example, we used the JSON method provided by the template to generate
    JSON output. Then we used `jq` to query the IP addresses of all the Swarm managers.
    The combination of JSON templating and `jq` will be a great tool to build our
    own set of Docker-based scripts for operating clusters in the long term.
  prefs: []
  type: TYPE_NORMAL
- en: Workers on Spot instances
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Then, we will provision another three nodes as a fleet of Spot instances. Here,
    in the following screenshot, it shows the setup to request a fleet of three Spot
    instances. Choose the Request and Maintain option, then set the Target capacity
    to `3` instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/69a23956-d79a-4188-964d-65b163e10155.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.11: Requesting and maintaining a fleet of 3 instances'
  prefs: []
  type: TYPE_NORMAL
- en: 'We configure the setup script to install Docker, join the node to the cluster,
    and set up the network driver upon the instance creation. The setup must be put
    into the User data section of the fleet setup, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3c4f9f38-655a-441b-bbdd-8119fd64fc6d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.12: Putting join instructions into the request''s user data'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the script used in the User data section. Please replace `$TOKEN` with
    your worker''s token, and `$MANAGER_IP` with one of your manager''s private IP
    addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now, we wait until the fleet request is fulfilled.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we get into the first manager, we could check the current nodes in the cluster
    with the `docker node ls` command. If everything is OK, we should have six nodes
    in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: With this technique, we can easily scale the cluster by simply adjusting the
    number of Spot instances.
  prefs: []
  type: TYPE_NORMAL
- en: Working with the network plugin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we can see in the User data section in the fleet setup, there will be a line
    of the script that installs the network plugin for us. It is the WeaveWorks network
    plugin. The WeaveWorks network plugin uses the information from the `docker info` command
    to list the IP addresses of all the Swarm managers. The plugin then uses these
    IP addresses to bootstrap the network mesh.
  prefs: []
  type: TYPE_NORMAL
- en: The WeaveWorks network plugin must be installed only after you successfully
    form the set of managers in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: We use WeaveWorks network plugin 2.1.3\. This is the most stable version of
    it at the time of writing. It is also recommended upgrading to the next minor
    versions of this plugin, if available.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install the network plugin, we use the `docker plugin install` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We use `--grant-all-permissions` just to automate the installation step. Without
    this parameter, we must manually grant the permissions required by each plugin.
  prefs: []
  type: TYPE_NORMAL
- en: We need to install a plugin for every single node in the cluster, which means
    we need to do this six times for our six boxes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could check to see whether the network plugin is installed correctly using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ENABLED` status of the plugin will be `true`, meaning that it is currently
    active. To check the status of the WeaveWork plugin and its network mesh, the
    plain text status could be CURLed from `localhost:6782/status`. The following
    status information was obtained from a worker node. We can check the number of
    connections between peers, or a number of peers, for example, from that URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The previous example shows us having six peers with five connections each. The
    IP range and the default subnet are important information for us to use when we
    create Docker networks. The IP range is `10.32.0.0/12`, so if we create a network
    with subnet `10.32.0.0/24`, it will be valid, while `10.0.0.0/24` will be invalid,
    for example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure illustrates our WeaveWorks network topology. Each node
    has five connections to another five nodes, as shown by solid lines from an **mg**
    node pointing to others. To make the diagram comprehensible, it shows only an
    **mg** node and another **wk** node connecting their five lines to the rest of
    the peers in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d482584-1a08-4c7e-959a-f6fc0d0c7337.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.13: Swarm nodes connecting together via a WeaveWorks full-mesh network'
  prefs: []
  type: TYPE_NORMAL
- en: 'For advanced troubleshooting, we could check the plugin''s running process,
    `weaver`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from grepping the output of `ps`, the final parts of the command
    are the list of Swarm manager IP addresses. If it looks like this, our networking
    layer is good to go. But if you do not see the list of manager IP addresses here,
    remove the plugin and start over again.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we prepare a network with the WeaveWorks driver, please keep in mind that
    we always need to specify the `--subnet` and `--gateway` parameters as we do not
    use the default subnet value provided by the Docker's libnetwork. We need to make
    a network attachable, with `--attachable`, to allow containers started using `docker
    run` command attach to the network. Without this option, only Swarm services,
    started by `docker service create`, are allowed to join the network.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we can create a *class C* network using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Creating an operational control plane
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An operational control plane is where we deploy operator containers to help
    operate the cluster. It is a concept that stems from the CoreOS's operator pattern,
    [https://coreos.com/blog/operators](https://coreos.com/blog/operators).
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, we create the control network to allow operator agents connecting
    to the manager nodes. Just name it `control`. We create this network to be a size
    of *class C*. So please be careful that the number of operator containers does
    not go beyond `255`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Operators in the `control` plane usually require access to Docker APIs to observe
    the cluster's state, to decide what to do, and to make changes back to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: To make the Docker API accessible via every operator inside the same control
    network, we deploy the `docker-api` service in the control plane.
  prefs: []
  type: TYPE_NORMAL
- en: We use `rancher/socat-docker` as the image of the `docker-api `service for the
    control plane because it is widely used and has proven stable for production.
    The `docker-api` will be deployed globally on every manager, using `node.role==manager`.
    The endpoint's mode will be set to `dnsrr` as each `docker-api` instance is stateless
    and the Docker managers are already taking care of the whole cluster state. So
    the `vip` endpoint mode is not necessary here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each `docker-api` instance binds to `/var/run/docker.sock` on their Docker
    host to connect to their local manager:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We will run an operator container called **service balancer** as an example
    of using the operator pattern in production.
  prefs: []
  type: TYPE_NORMAL
- en: Service balancer operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Service rebalancing has been one of the requested features for Docker. However,
    it is better to have this feature running outside the orchestrator and to run
    it as an operator container.
  prefs: []
  type: TYPE_NORMAL
- en: The problem is that after a new node joins the cluster, we usually rebalance
    the running services to spread loads across the cluster. The main reason this
    feature is not built into the orchestrator is because it is application-specific.
    Also, if the cluster keeps rebalancing everything when nodes dynamically come
    and go, running services may be broken all the time, and not in a good enough
    condition to serve requests.
  prefs: []
  type: TYPE_NORMAL
- en: However, if we implement this kind of feature as an operator container, we can
    optionally disable it when necessary as it is running outside the orchestrator.
    Also, we can selectively pick only particular services to be rebalanced.
  prefs: []
  type: TYPE_NORMAL
- en: 'The service balancer is currently available as `chanwit/service-balancer` on
    Docker''s hub. We will be running only one instance of service balancer on any
    manager:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Something to consider when using the auto-rebalancer is that `--update-delay`
    must be set to greater than the startup time of each task. This is really important,
    especially for Java-based services. This delay should be large enough, at least
    larger than the interval used by the health checking mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Also, for the safest result, the value of `--update-parallelism` should start
    at `1`, and gradually increase when the system can stably serve the requests.
  prefs: []
  type: TYPE_NORMAL
- en: To allow a service to automatically rebalance, the service balancer operator
    checks the service's label `rebalance.on.node.create=true`. If this label is present
    on the service, it will be rebalanced every time a new node is added to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to logging, one popular solution is to set up an Elasticsearch
    stack. The natural combination could be **Elasticsearch**-**Logstash**-**Kibana** (**ELK**).
  prefs: []
  type: TYPE_NORMAL
- en: We use an ELK stack from [https://github.com/deviantony/docker-elk](https://github.com/deviantony/docker-elk)
    with modification to improve it by adding Docker Swarm configs, and to deploy
    each of them independently. The original Docker Compose file, `docker-compose.yml`,
    are split into three YML files, each for **Elasticsearch**, **Kibana**, and **Logstash**,
    respectively**. **Services must be deployed this way because we do not want to
    bring the whole logging system down when we change each service's configs. The
    fork used in this chapter is available at [https://github.com/chanwit/docker-elk](https://github.com/chanwit/docker-elk).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows what the stack will look like. All ELK components
    will be in **elk_net**. The **Logstash** instance will be exposed on port **5000**.
    On each Docker host, its local **Logspout** agent will forward log messages from
    the Docker host to the **Logstash** instance. **Logstash** will then transform
    each message and store them in **ElasticSearch**. Finally, a user can access **Kibana**
    via port **5601** to visualize all the logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9d8fb58e-8213-4753-80eb-d8ca97450c92.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.14: An ELK stack block diagram for cluster-wide logging'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with the preparation of a dedicated network for our ELK stack. We
    name this network `elk_net` and use it for all ELK components:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the source of `elasticsearch.yml`. We use Docker compose YAML
    specification version 3.3 throughout the chapter. This is the minimum requirement,
    as we will use Docker Swarm configs to manage all configuration files for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: It is the requirement that `docker stack` needs the image name to be specified
    before it can be deployed. So, we need to build the container image using `docker-compose`
    first.
  prefs: []
  type: TYPE_NORMAL
- en: We use `docker-compose` only for building images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s do it! We use `docker-compose` build to prepare images defined in the
    YML file. The `docker-compose` command also tags images for us too. As we have
    a separate YML file each service, we use `-f` to tell `docker-compose` to build
    the correct file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'When the image is ready, we can simply deploy the stack, `es`, using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Next, we move to the preparation and deployment of Kibana.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the stack YML file for Kibana. We have `kibana_config` pointing to
    our Kibana configuration. The Kibana port `5601` is published using Swarm''s host
    mode to bypass the ingress layer. Please remember that we do not really have the
    default ingress layer in our cluster. As previously mentioned, we use Træfik as
    our new ingress:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to Elasticsearch, now the Kibana image can be prepared using the `docker-compose
    build` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we deploy Kibana with the stack name `kb`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'With Logstash, there are two configuration files to consider. The most important
    one is the pipeline config, `logstash_pipeline_config`. We need to add custom
    rules to this file for log message transformation. It keeps changing, unlike the
    first two components of ELK. Logstash listens to port `5000`, both for TCP and
    UDP, inside `elk_net`. We will later plug Logspout into this network to convey
    log messages from Docker daemons to this Logstash service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The next steps are to build and deploy, similar to the first two components:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We started these three components as separate stacks linked together via `elk_net`.
    To check if all components are running, simply check this using `docker stack
    ls`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can redirect all logs from each Docker daemon to the ELK stack,
    the central service, using Logspout. This can be done by attaching each local
    `logspout` container to the `elk_net` so that they will all be able to connect
    to a Logstash instance inside the network. We start each Logspout using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We are now able to log all messages via Logspout to Logstash, storing them in
    Elasticsearch, and visualizing them with Kibana.
  prefs: []
  type: TYPE_NORMAL
- en: Scripting Docker with Golang
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to operating and administrating Docker, we could do everything
    by controlling the cluster via the `docker` CLI using the `jq` command. Another
    powerful and very flexible way is to control the cluster via scripting. The most
    suitable programming language for scripting Docker cluster is, of course, Golang.
  prefs: []
  type: TYPE_NORMAL
- en: Why not Python? How could Golang, a statically compiled language, come to fit
    scripting?
  prefs: []
  type: TYPE_NORMAL
- en: First, Go is the language that Docker is written in. The Docker library written
    in the Go language is the same piece of codes used by Docker itself. So, the scripts
    written using this library will be naturally in high quality and greatly reliable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, the language constructs and the idioms fit the way Docker works. For
    example, the Go programming language has the channel construct and it fits nicely
    for processing event messages emitted by the Docker cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Third, the Go compiler is incredibly fast. Also, once all related libraries
    get compiled, the compilation time is greatly reduced. We can normally use it
    to run scripts just like other scripting language interpreters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we will discuss how to use scripts written in Golang to control
    Docker directly via its API. This will become a powerful tool for taking care
    of running the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the tool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Installing the Go compiler and making it ready to use is sometimes tricky. However, **Golang
    Version Manager** (**GVM**), is a tool that helps with installing and uninstalling
    different Go versions on the same machine. It also helps manage `GOPATH` effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'What is GOPATH? It is defined as follows in Wikipedia:'
  prefs: []
  type: TYPE_NORMAL
- en: '"The GOPATH environment variable is used to specify directories outside of
    $GOROOT that contain the source for Go projects and their binaries."'
  prefs: []
  type: TYPE_NORMAL
- en: 'To start using GVM, we first install the `gvm` command using the snippet provided
    on [https://github.com/moovweb/gvm](https://github.com/moovweb/gvm). It can be
    installed with a single command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Now we have GVM installed already, and we continue by installing Go.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is great to use Go''s most recent version-1.9.3\. The command to install
    is, of course, `gvm install`. We pass the `-B` parameter to the `install` command,
    so that it will download and use only the binary of the Go distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, if we choose to go with Go v1.9.3 when taking care of our cluster, we
    should make it the default version. Issue the `gvm use` command with the `--default`
    parameter to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Making Go scriptable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, prepare the next tool, `gorun`, to make a Go program scriptable. With
    `gorun`, you can add a shebang to the first line of the script, as shown in the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The normal Go program will then be allowed to execute directly from the shell.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install `gorun`, just do `go get`. The `gorun` binary will now be available
    under the path provided by the current `go1.9.3` managed by GVM. Please note that
    if you switch Go version with GVM, you need to do `go get` again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We could install all necessary libraries for controlling Docker programmatically
    by installing the Docker client library itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: If nothing goes wrong, we will be ready to start writing a Golang script.
  prefs: []
  type: TYPE_NORMAL
- en: Simple Docker script
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s write a simple script that interacts with Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: First, the script must have the first line with shebang and `gorun`. Second,
    import a line with Docker's client library, `github.com/docker/docker/client`.
    Although, Docker has been moved to `github.com/moby/moby`, but we still need to
    import all related library using the `docker/docker` repository name. Just `go
    get github.com/docker/docker/client` and everything is still working fine for
    us.
  prefs: []
  type: TYPE_NORMAL
- en: Then we start programming our cluster by creating a client while also setting
    the API version to 1.30\. This script then calls `cli.Info(ctx)` to obtain the
    engine's information from the Docker daemon, as the `info` variable. It simply
    prints out the version of the Docker daemon we're talking to. The version information
    is stored in `info.ServerVersion`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Save the script to a file named `server-version`. We can now run it as a normal
    shell script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Script reacting to Docker events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, we will write a script to monitor changes in the Docker cluster and then
    do a print out when a node is updated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This is also a script executed by `gorun`. The script starts by creating a Docker
    client CLI pointing to the local socket, `/var/run/docker.sock`.
  prefs: []
  type: TYPE_NORMAL
- en: Then it creates a filter, the `filter` variable. This filter makes the event
    emitter select only the type of events we are interested in, in this case, when
    the `type` of events is `node`. This is equivalent to passing `--filter type=node`
    to the command line. The `cli.Events` method will return a Go channel for retrieving
    messages. A message is then retrieved inside the `for` loop. The program will
    be automatically blocked if the message is not available in the channel. So the
    script just becomes a single-thread style and easy to program.
  prefs: []
  type: TYPE_NORMAL
- en: Inside the loop, we can manipulate information inside the message, for example,
    checking the action of a certain event. Normally, most types of event contain
    three possible actions, `create`, `update`, and `remove`. For a node, `create`
    means there is a new node added to the cluster. The `update` action means something
    has changed on a certain node. The `remove` action means the node is removed from
    the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Just save this script to `./node-event`, then `chmod +x` it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The `chmod` command will change executable bits of the script. With these bits,
    the Linux system will be able to detect that the file should be executed. Then,
    it will tell `gorun` to take care of that execution.
  prefs: []
  type: TYPE_NORMAL
- en: Try changing some properties of the current working node. We may observe that
    the text `- Node updated.` will be printed out.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please try to answer the following questions without going back to read the
    chapter''s content:'
  prefs: []
  type: TYPE_NORMAL
- en: List at least three components described in the stable cluster configuration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are retry and circuit breaker important?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we replace the default ingress layer with the new one?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we install the network plugin?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the most frontal part of the ELK stack?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is the Go language suitable for scripting the Docker system?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we listen to Docker events of a certain type?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we set up a control plane?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the operator pattern? Why is it important?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the characteristic of Spot instances that makes them cheaper than normal
    instances?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter discussed various topics on how to prepare and operate a Docker
    cluster with a stable configuration. We introduced a low-cost alternative to Lambda
    by deploying a Docker cluster on Spot instances. This chapter also introduced
    the concept of CoreOS's operator pattern, and how to use it practically to auto-balance
    the tasks of our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to logging, the ELK stack is usually the first choice. This chapter
    also discussed how to efficiently prepare ELK on Docker Swarm and it ended with
    how to operate a cluster with Golang scripts, the scripting technique that can
    fully leverage Docker and its ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will put all FaaS platforms into the same cluster and
    make them work together to demonstrate a use case of event-driven FaaS systems
    over a Docker cluster.
  prefs: []
  type: TYPE_NORMAL
