<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch03"/>Chapter 3. Volume Plugins</h1></div></div></div><p>In this chapter, you will get an overview of both first and third-party volume plugins. We will be discussing<a id="id87" class="indexterm"/> installing, configuring, and using the following storage plugins:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Docker Volumes</strong>: <a class="ulink" href="https://docs.docker.com/engine/userguide/containers/dockervolumes/">https://docs.docker.com/engine/userguide/containers/dockervolumes/</a></li><li class="listitem" style="list-style-type: disc"><strong>Convoy</strong>: <a class="ulink" href="https://github.com/rancher/convoy/">https://github.com/rancher/convoy/</a></li><li class="listitem" style="list-style-type: disc"><strong>REX-Ray</strong>: <a class="ulink" href="https://github.com/emccode/rexray/">https://github.com/emccode/rexray/</a></li><li class="listitem" style="list-style-type: disc"><strong>Flocker</strong>: <a class="ulink" href="https://clusterhq.com/flocker/introduction/">https://clusterhq.com/flocker/introduction/</a></li></ul></div><p>You will <a id="id88" class="indexterm"/>also<a id="id89" class="indexterm"/> get an understanding<a id="id90" class="indexterm"/> of how to interact with Docker plugins and how they both differ and work with the supporting tools that we covered in <a class="link" href="ch02.html" title="Chapter 2. Introducing First-party Tools">Chapter 2</a>, <em>Introducing First-party Tools</em>.</p><div><div><h3 class="title"><a id="note09"/>Note</h3><p>This chapter assumes that you are using Docker 1.10+. Note that some commands may not work in previous versions.</p></div></div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec18"/>Zero volumes</h1></div></div></div><p>Before <a id="id91" class="indexterm"/>we look at volumes, let's look at what happens when you do not use any volumes at all and store everything directly on the containers.</p><p>To start with, let's create a new Docker instance called <code class="literal">chapter03</code> locally using Docker Machine:</p><div><pre class="programlisting">
<strong>docker-machine create chapter03 --driver=virtualbox</strong>
<strong>eval $(docker-machine env chapter03)</strong>
</pre></div><div><img src="img/B05468_03_01.jpg" alt="Zero volumes"/></div><p>Now that we <a id="id92" class="indexterm"/>have our machine, we can use Docker Compose to run through a scenario with WordPress. First of all, we will need to launch our WordPress containers, we are using the official WordPress and MySQL images from the Docker Hub as we did earlier, our <code class="literal">docker-compose.yml</code> file looks similar to the following code:</p><div><pre class="programlisting">version: '2'
services:
  wordpress:
    container_name: my-wordpress-app
    image: wordpress
    ports: 
      - "80:80"
    links:
      - mysql
    environment:
      WORDPRESS_DB_HOST: "mysql:3306"
      WORDPRESS_DB_PASSWORD: "password"
  mysql:
    container_name: my-wordpress-database
    image: mysql
    environment:
      MYSQL_ROOT_PASSWORD: "password"</pre></div><p>As you can see, there is nothing special about the compose file. You can launch it by running the following command:</p><div><pre class="programlisting">
<strong>docker-compose up -d</strong>
</pre></div><p>Once you<a id="id93" class="indexterm"/> have launched the containers, check their status by running the following command:</p><div><pre class="programlisting">
<strong>docker-compose ps</strong>
</pre></div><p>If they both have state of <code class="literal">Up</code>, you can go to the WordPress installation screen by running the following command:</p><div><pre class="programlisting">
<strong>open http://$(docker-machine ip chapter03)/</strong>
</pre></div><p>This will open your browser and go to the IP address of your Docker instance. In my case, this is <code class="literal">http://192.168.99.100/</code>. You should see the following screen:</p><div><img src="img/B05468_03_02.jpg" alt="Zero volumes"/></div><p>Let's click on <strong>Continue</strong> button and install WordPress:</p><div><img src="img/B05468_03_03.jpg" alt="Zero volumes"/></div><p>Once the<a id="id94" class="indexterm"/> information has been filled in, click on Install WordPress to complete the installation. When you do, the MySQL database will be updated with your settings and the test posts and comments will also be added. When this is completed, you will be shown a success screen:</p><div><img src="img/B05468_03_04.jpg" alt="Zero volumes"/></div><p>You should now be able to rerun the following command:</p><div><pre class="programlisting">
<strong>open http://$(docker-machine ip chapter03)</strong>
</pre></div><p>This will take you to your very empty WordPress site:</p><div><img src="img/B05468_03_05.jpg" alt="Zero volumes"/></div><p>Your <a id="id95" class="indexterm"/>command line history should look something similar to the following terminal output:</p><div><img src="img/B05468_03_06.jpg" alt="Zero volumes"/></div><p>Now that we have our WordPress site installed, let's destroy the containers by running the following command:</p><div><pre class="programlisting">
<strong>docker-compose stop &amp;&amp; docker-compose rm</strong>
</pre></div><p>Make sure you type <code class="literal">y</code> when prompted. You will then receive a confirmation message that your two containers have been removed:</p><div><img src="img/B05468_03_07.jpg" alt="Zero volumes"/></div><p>Now that <a id="id96" class="indexterm"/>we have removed our containers, let's recreate them by running through the commands again:</p><div><pre class="programlisting">
<strong>docker-compose up -d</strong>
<strong>docker-compose ps</strong>
<strong>open http://$(docker-machine ip chapter03)/</strong>
</pre></div><p>As you can see, you are presented with an installation screen again, which is to be expected as the MySQL database was stored on the <code class="literal">mysql</code> container that we removed.</p><p>Before we move onto looking at what ships with Docker, let's do some housekeeping and remove the containers:</p><div><pre class="programlisting">
<strong>docker-compose stop &amp;&amp; docker-compose rm</strong>
</pre></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec19"/>The default volume driver</h1></div></div></div><p>Before<a id="id97" class="indexterm"/> we start using the third-party volume plugins, we should take a look at what ships with Docker and how volumes solve the scenario we just worked through. Again, we will be using a <code class="literal">docker-compose.yml</code> file; however, this time, we will add a few lines to create and mount volumes:</p><div><pre class="programlisting">version: '2'
services:
  wordpress:
    container_name: my-wordpress-app
    image: wordpress
    ports: 
      - "80:80"
    links:
      - mysql
    environment:
      WORDPRESS_DB_HOST: "mysql:3306"
      WORDPRESS_DB_PASSWORD: "password"
<strong>    volumes:</strong>
<strong>      - "uploads:/var/www/html/wp-content/uploads/"</strong>
  mysql:
    container_name: my-wordpress-database
    image: mysql
    environment:
      MYSQL_ROOT_PASSWORD: "password"
    volumes:
      - "database:/var/lib/mysql"
<strong>volumes:</strong>
<strong>  uploads:</strong>
<strong>    driver: local</strong>
<strong>  database:</strong>
<strong>    driver: local</strong>
</pre></div><p>As you <a id="id98" class="indexterm"/>can see, here we are creating two volumes, one called <code class="literal">uploads</code>, which is being mounted to the WordPress uploads folder on the WordPress container. The second volume called <code class="literal">database</code>, which is being mounted in <code class="literal">/var/lib/mysql</code> on our MySQL container.</p><p>You can launch the containers and open WordPress, using the following commands:</p><div><pre class="programlisting">
<strong>docker-compose up -d</strong>
<strong>docker-compose ps</strong>
<strong>open http://$(docker-machine ip chapter03)/</strong>
</pre></div><p>Before we complete the WordPress installation in the browser, we should make sure that the <code class="literal">uploads</code> folder has the right permissions by running <code class="literal">docker exec</code>:</p><div><pre class="programlisting">
<strong>docker exec -d my-wordpress-app chmod 777 /var/www/html/wp-content/uploads/</strong>
</pre></div><p>Now that the permissions are correctly set on the <code class="literal">uploads</code> folder, we can go through the WordPress installation as per the previous test.</p><p>As WordPress creates a <code class="literal">Hello World!</code> test post as part of the installation, we should go and edit the post. To do this, log in to WordPress using the credentials that you entered during the installation. Once logged in, go to <strong>Posts</strong> | <strong>Hello World</strong> and then upload a featured image by clicking on <strong>Set featured image</strong> button. Your edit should look similar to the following screenshot once you have uploaded the featured image:</p><div><img src="img/B05468_03_08.jpg" alt="The default volume driver"/></div><p>Once<a id="id99" class="indexterm"/> your image has been uploaded, click on <strong>Update</strong> button and then go to your WordPress homepage by clicking on the title on the top left-hand side of the screen. Once the home page opens, you should see your featured image:</p><div><img src="img/B05468_03_09.jpg" alt="The default volume driver"/></div><p>Before <a id="id100" class="indexterm"/>we remove our containers, you can run the following command to show all the volumes that have been created in Docker:</p><div><pre class="programlisting">
<strong>docker volume ls</strong>
</pre></div><p>When running the command, you should the two volumes that we defined in our <code class="literal">docker-compose.yml</code> file:</p><div><img src="img/B05468_03_10.jpg" alt="The default volume driver"/></div><p>Remember, as <a id="id101" class="indexterm"/>we discussed in the previous chapter, Docker Compose will prefix names with the project title (which is the name of the folder that <code class="literal">docker-compose.yml</code> is in), in this case, the project is called <code class="literal">wordpress-vol</code> and as <code class="literal">-</code> is not allow in names, it has been stripped out, leaving <code class="literal">wordpressvol</code>.</p><p>Now that we have the basic WordPress installation with updated content, let's remove the containers as we did before:</p><div><pre class="programlisting">
<strong>docker-compose stop &amp;&amp; docker-compose rm</strong>
<strong>docker-compose ps</strong>
</pre></div><div><img src="img/B05468_03_11.jpg" alt="The default volume driver"/></div><p>At this stage, you can probably guess what is going to happen next, let's relaunch our containers and open the WordPress site in our browser:</p><div><pre class="programlisting">
<strong>docker-compose up -d</strong>
<strong>open http://$(docker-machine ip chapter03)/</strong>
</pre></div><p>It may take a few seconds for everything to start up, so if you don't see your WordPress when the<a id="id102" class="indexterm"/> browser opens, refresh the page. If everything goes as planned, you should be presented with your edited <code class="literal">Hello World!</code> post:</p><div><img src="img/B05468_03_12.jpg" alt="The default volume driver"/></div><p>While it looks like the same screenshot as earlier, you will notice that you have been logged out of WordPress. This is because, by default, WordPress stores its sessions on the filesystem, and as they are not stored in the uploads directory, the session files were lost when we removed the containers.</p><p>Volumes can also be shared between containers, if we add the following to our <code class="literal">docker-compose.yml</code> file anywhere in the <code class="literal">Services</code> section:</p><div><pre class="programlisting">  wordpress8080:
    container_name: my-wordpress-app-8080
    image: wordpress
    ports: 
      - "8080:80"
    links:
      - mysql
    environment:
      WORDPRESS_DB_HOST: "mysql:3306"
      WORDPRESS_DB_PASSWORD: "password"
    volumes:
      - "uploads:/var/www/html/wp-content/uploads/"</pre></div><p>You<a id="id103" class="indexterm"/> can launch a second container with WordPress running on <code class="literal">port 8080</code> and access the file we uploaded at <code class="literal">http://192.168.99.100:8080/wp-content/uploads/2016/02/containers-1024x512.png</code>.</p><p>Note that the preceding URL will differ for your installation as the IP address may be different, along with the upload date and file name.</p><p>You can get more information on a volume by running the following command:</p><div><pre class="programlisting">
<strong>docker volume inspect &lt;your_volume_name&gt;</strong>
</pre></div><p>In our case, this returns the following information:</p><div><img src="img/B05468_03_13.jpg" alt="The default volume driver"/></div><p>You will have noticed that we have been using the <code class="literal">local</code> driver for our two volumes, this creates the volume on our Docker instance and mounts a folder from host machine, which is the Docker Machine host running under VirtualBox in this case.</p><p>You can view the contents on the folder by SSHing into the host machine and going to the folder listed under the mount point returned by the <code class="literal">docker volume inspect</code> command. To SSH into the host and change to the root user, run the following commands:</p><div><pre class="programlisting">
<strong>docker-machine ssh chapter03</strong>
<strong>sudo su -</strong>
</pre></div><p>You will <a id="id104" class="indexterm"/>then be able to change to the folder containing the volume, the reason for changing to the root user is to make sure that you have permissions to see the contents on the folder:</p><div><img src="img/B05468_03_14.jpg" alt="The default volume driver"/></div><p>As you can see from the preceding terminal output, the files are owned by an unknown user with a user ID and group ID of 32, in the container, this is the Apache user. Be careful if you add files directly or make any changes, as you may find yourself causing all sorts of permission errors when it comes to your containers accessing the files you have added/changed.</p><p>So far so good, but what are the limits? The biggest one is that your data is tied to a single instance. In the last chapter, we looked at clustering Docker using Swarm, we discussed that the containers launched with Docker Compose are tied to a single instance, which is great for development, but not so hot for production, where we may have several host instances that we want to start spreading our containers across, this is where third-party volume drivers come into play.</p><div><div><div><div><h2 class="title"><a id="ch03lvl2sec22"/>Third-party volume drivers</h2></div></div></div><p>There <a id="id105" class="indexterm"/>are several third-party volume drivers available, they all bring different functionality to the table. To start with, we are going to be looking at Convoy by Rancher.</p><p>Before we look at installing Convoy, we should look at launching a Docker instance somewhere in the cloud. As we already have launched Docker instance in both DigitalOcean and Amazon Web Services, we should terminate our local <code class="literal">chapter03</code> instance and relaunch it in one of these providers, I am going to be using DigitalOcean:</p><div><pre class="programlisting">
<strong>docker-machine stop chapter03 &amp;&amp; docker-machine rm chapter03</strong>
<strong>docker-machine create \</strong>
<strong>    --driver digitalocean \</strong>
<strong>    --digitalocean-access-token sdnjkjdfgkjb345kjdgljknqwetkjwhgoih314rjkwergoiyu34rjkherglkhrg0\</strong>
<strong>    --digitalocean-region lon1 \</strong>
<strong>    --digitalocean-size 1gb \</strong>
<strong>    chapter03</strong>
<strong>eval "$(docker-machine env chapter03)"</strong>
</pre></div><div><img src="img/B05468_03_15.jpg" alt="Third-party volume drivers"/></div><p>One of the reasons that we have launched the instance in a cloud provider is that we need a full underlying <a id="id106" class="indexterm"/>operating system to be able install and use Convoy, while the image provided by Boot2Docker is good, it is a little too lightweight for our requirement.</p><div><div><h3 class="title"><a id="tip06"/>Tip</h3><p>Before we do anything further, I would recommend you to attach a floating IP address to your DigitalOcean droplet. The reason for this is that, in this section of the chapter, we are going to be installing WordPress and then moving the installation to a new machine. Without a floating IP address, your WordPress installation may appear broken. You can find more details on floating IPs on the <a id="id107" class="indexterm"/>DigitalOcean website at <a class="ulink" href="https://www.digitalocean.com/community/tutorials/how-to-use-floating-ips-on-digitalocean">https://www.digitalocean.com/community/tutorials/how-to-use-floating-ips-on-digitalocean</a>.</p></div></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec03"/>Installing Convoy</h3></div></div></div><p>As already<a id="id108" class="indexterm"/> mentioned, we need to install Convoy on our underlying Docker hosts operating system. To do this, you should first SSH onto your Docker host:</p><div><pre class="programlisting">
<strong>docker-machine ssh chapter03</strong>
</pre></div><div><div><h3 class="title"><a id="tip07"/>Tip</h3><p>As the machine has been launched in DigitalOcean, we have connected as the root user; this means that we don't have to use <code class="literal">sudo</code> in front of the commands, however, as you could have launched the instance in another provider, I will keep them there so that you don't end up getting permission errors if you are not the root user.</p></div></div><p>Now that you have used <code class="literal">ssh</code> command to get into our Docker host, we can install and start Convoy. Convoy is written in Go and ships as a static binary. This means that we don't have to compile it manually; instead, we just need to grab the binary and copy it into place:</p><div><pre class="programlisting">
<strong>wget https://github.com/rancher/convoy/releases/download/v0.4.3/convoy.tar.gz</strong>
<strong>tar xvf convoy.tar.gz</strong>
<strong>sudo cp convoy/convoy convoy/convoy-pdata_tools /usr/local/bin/</strong>
</pre></div><p>There are later versions of Convoy available at <a class="ulink" href="https://github.com/rancher/convoy/releases">https://github.com/rancher/convoy/releases</a>; however, these are flagged for use with Rancher only. We will be looking at Rancher in detail in a later chapter.</p><p>Now that we have our binary in place, we need to set up our Docker installation so that it loads the plugin:</p><div><pre class="programlisting">
<strong>sudo mkdir -p /etc/docker/plugins/</strong>
<strong>sudo bash -c 'echo "unix:///var/run/convoy/convoy.sock" &gt; /etc/docker/plugins/convoy.spec'</strong>
</pre></div><p>The <code class="literal">convoy.spec</code> file tells Docker where it can access Convoy; for more details on how plugins work refer to <a class="link" href="ch05.html" title="Chapter 5. Building Your Own Plugin">Chapter 5</a>, <em>Building Your Own Plugin</em>.</p><p>Convoy is<a id="id109" class="indexterm"/> installed and ready to go, now we just have to add some storage. For testing purposes, we are going to be creating and using a loopback device; however, do not do this in production!</p><div><div><h3 class="title"><a id="note10"/>Note</h3><p>A Loopback Device is <a id="id110" class="indexterm"/>a mechanism used to interpret files as real devices. The main advantage of this method is that all tools used on real disks can be used with a loopback<a id="id111" class="indexterm"/> device. Refer to <a class="ulink" href="http://wiki.osdev.org/Loopback_Device">http://wiki.osdev.org/Loopback_Device</a>.</p></div></div><p>To create the loopback device and mount it, run the following commands:</p><div><pre class="programlisting">
<strong>truncate -s 4G data.vol</strong>
<strong>truncate -s 1G metadata.vol</strong>
<strong>sudo losetup /dev/loop5 data.vol</strong>
<strong>sudo losetup /dev/loop6 metadata.vol</strong>
</pre></div><p>Now that we have our storage ready, we can start Convoy by running the following command:</p><div><pre class="programlisting">
<strong>sudo convoy daemon --drivers devicemapper --driver-opts dm.datadev=/dev/loop5 --driver-opts dm.metadatadev=/dev/loop6 &amp;</strong>
</pre></div><p>You should see something similar to the following output:</p><div><img src="img/B05468_03_16.jpg" alt="Installing Convoy"/></div><p>Now that we have Convoy running, type <code class="literal">exit</code> to leave the Docker host and return to your local machine.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec04"/>Launching containers with a Convoy volume</h3></div></div></div><p>Now<a id="id112" class="indexterm"/> that we have Convoy up and running, we can make some changes to our <code class="literal">docker-compose.yml</code> file:</p><div><pre class="programlisting">version: '2'
services:
  wordpress:
    container_name: my-wordpress-app
    image: wordpress
    ports: 
      - "80:80"
    links:
      - mysql
    environment:
      WORDPRESS_DB_HOST: "mysql:3306"
      WORDPRESS_DB_PASSWORD: "password"
    volumes:
      - "uploads:/var/www/html/wp-content/uploads/"
  mysql:
    container_name: my-wordpress-database
<strong>    image: mariadb</strong>
    environment:
      MYSQL_ROOT_PASSWORD: "password"
<strong>    command: mysqld --ignore-db-dir=lost+found</strong>
    volumes:
      - "database:/var/lib/mysql/"
<strong>volumes:</strong>
<strong>  uploads:</strong>
<strong>    driver: convoy</strong>
<strong>  database:</strong>
<strong>    driver: convoy</strong>
</pre></div><p>Put the <code class="literal">docker-compose.yml</code> file in a <code class="literal">wordpressconvoy</code> folder if don't you will find you will need change the name of the volume in some of the later steps in this section.</p><p>As you can see, I have highlighted a few changes. The first being that we have moved over to using MariaDB, the reason for this is that as we now using an actual filesystem rather just a folder on the host machine, we have a <code class="literal">lost</code> + <code class="literal">found</code> folder created, presently the official MySQL container fails to work as it believes there are already databases on the volume. To get around this, we can use the <code class="literal">--ignore-db-dir</code> directive when starting MySQL, which MariaDB supports.</p><p>Let's launch our containers and take a look at the volume that is created by running:</p><div><pre class="programlisting">
<strong>docker-compose up -d</strong>
<strong>open http://$(docker-machine ip chapter03)/</strong>
<strong>docker-compose ps</strong>
<strong>docker volume ls</strong>
<strong>docker volume inspect wordpressconvoy_database</strong>
</pre></div><p>You should see something similar to the following terminal output:</p><div><img src="img/B05468_03_17.jpg" alt="Launching containers with a Convoy volume"/></div><p>Before <a id="id113" class="indexterm"/>we do anything further, complete the WordPress installation and upload some content:</p><div><pre class="programlisting">
<strong>open http://$(docker-machine ip chapter03)/</strong>
</pre></div><p>Remember to set the correct permissions on the volume before uploading content:</p><div><pre class="programlisting">
<strong>docker exec -d my-wordpress-app chmod 777 /var/www/html/wp-content/uploads/</strong>
</pre></div></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec05"/>Creating a snapshot using Convoy</h3></div></div></div><p>So far, it's no<a id="id114" class="indexterm"/> different from the default volume driver. Let's look at creating a snapshot and then backing up of the volume, you will see why later in the chapter.</p><p>First of call, let's jump back to the Docker host:</p><div><pre class="programlisting">
<strong>docker-machine ssh chapter03</strong>
</pre></div><p>Let's create our first snapshot by running the following the commands:</p><div><pre class="programlisting">
<strong>sudo convoy snapshot create wordpressconvoy_uploads --name snap_wordpressconvoy_uploads_01</strong>
<strong>sudo convoy snapshot create wordpressconvoy_database --name snap_wordpressconvoy_database_01</strong>
</pre></div><p>Once a<a id="id115" class="indexterm"/> snapshot has been created, you will receive a unique ID. In my case, these were <code class="literal">c00caa88-087d-45ad-9498-7610844c075e</code> and <code class="literal">4e2a2a6f-887c-4692-b2a8-e1f08aa42400</code>.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec06"/>Backing up our Convoy snapshot</h3></div></div></div><p>Now that we <a id="id116" class="indexterm"/>have our snapshots, we can use these as a basis to create our backups. To do this, we must first make sure that the destination directory where we are going to store it exists:</p><div><pre class="programlisting">
<strong>sudo mkdir /opt/backup/</strong>
</pre></div><p>Now that we have somewhere to store the backup, let's create it:</p><div><pre class="programlisting">
<strong>sudo convoy backup create snap_wordpressconvoy_uploads_01 --dest vfs:///opt/backup/</strong>
<strong>sudo convoy backup create snap_wordpressconvoy_database_01 --dest vfs:///opt/backup/</strong>
</pre></div><p>Once the backup has been completed, you will receive confirmation in the form of a URL. For the uploads, the URL returned is as follows:</p><div><pre class="programlisting">
<strong>vfs:///opt/backup/?backup=34ca255e-7164-4734-8b96-579b4e79f728\u0026volume=26a5913e-4794-4df3-bbb9-7a6361c23a75</strong>
</pre></div><p>For the database, the URL was as follows:</p><div><pre class="programlisting">
<strong>vfs:///opt/backup/?backup=41731035-2760-4a1b-bba9-5e906e2471bc\u0026volume=8212de61-ea8c-4777-881e-d4bd07b800e3</strong>
</pre></div><p>It is important that you make a note of the URLs, as you will need these to restore the backups. There is one flaw, the backups we have created are being stored on our Docker host machine. What if it was to go down? All our hard work would be then lost!</p><p>Convoy supports creating backups for Amazon S3, so let's do that. First, you will need to log in to your Amazon Web Services account and create an S3 bucket to store your backups.</p><p>Once you have created a bucket, you need to add your credentials to the server:</p><div><pre class="programlisting">
<strong>mkdir ~/.aws/</strong>
<strong>cat &gt;&gt;  ~/.aws/credentials &lt;&lt; CONTENT</strong>
<strong>[default]</strong>
<strong>aws_access_key_id = JHFDIGJKBDS8639FJHDS</strong>
<strong>aws_secret_access_key = sfvjbkdsvBKHDJBDFjbfsdvlkb+JLN873JKFLSJH</strong>
<strong>CONTENT</strong>
</pre></div><div><div><h3 class="title"><a id="note11"/>Note</h3><p>For more information on how to create an Amazon S3 bucket, refer to the getting started guide at <a class="ulink" href="https://aws.amazon.com/s3/getting-started/">https://aws.amazon.com/s3/getting-started/</a>, and for details on <code class="literal">credentials</code> files, refer to <a class="ulink" href="http://blogs.aws.amazon.com/security/post/Tx3D6U6WSFGOK2H/A-New-and-Standardized-Way-to-Manage-Credentials-in-the-AWS-SDKs">http://blogs.aws.amazon.com/security/post/Tx3D6U6WSFGOK2H/A-New-and-Standardized-Way-to-Manage-Credentials-in-the-AWS-SDKs</a>.</p></div></div><p>Now your <a id="id117" class="indexterm"/>Amazon S3 bucket is created. I have named mine <code class="literal">chapter03-backup-bucket</code> and created it in the <code class="literal">us-west-2</code> region. Your Docker host has access to Amazon's API. You can make your backups again, but this time, push them to Amazon S3:</p><div><pre class="programlisting">
<strong>sudo convoy backup create snap_wordpressconvoy_uploads_01 --dest s3://chapter03-backup-bucket@us-west-2/</strong>
<strong>sudo convoy backup create snap_wordpressconvoy_database_01 --dest s3://chapter03-backup-bucket@us-west-2/</strong>
</pre></div><p>As you can see, the destination URL takes the following format:</p><div><pre class="programlisting">
<strong>s3://&lt;bucket-name&gt;@&lt;aws-region&gt;</strong>
</pre></div><p>Again, you will receive URLs once the backups has been completed. In my case, there are as follows:</p><div><pre class="programlisting">
<strong>s3://chapter03-backup-bucket@us-west-2/?backup=6cb4ed46-2084-42bc-8261-6b4da690bd5e\u0026volume=26a5913e-4794-4df3-bbb9-7a6361c23a75</strong>
</pre></div><p>For the database backup, we will see the following:</p><div><pre class="programlisting">
<strong>s3://chapter03-backup-bucket@us-west-2/?backup=75608b0b-93e7-4319-b212-7a1b0ccaf289\u0026volume=8212de61-ea8c-4777-881e-d4bd07b800e3</strong>
</pre></div><p>When running the preceding commands, your terminal output should have looked something similar to the following:</p><div><img src="img/B05468_03_18.jpg" alt="Backing up our Convoy snapshot"/></div><p>Now that we have off instance backups of our data volumes, let's terminate the Docker host and bring up a new one. If you haven't already, <code class="literal">exit</code> from the Docker host and terminate it by running the<a id="id118" class="indexterm"/> following command:</p><div><pre class="programlisting">
<strong>docker-machine stop chapter03 &amp;&amp; docker-machine rm chapter03</strong>
</pre></div></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec07"/>Restoring our Convoy backups</h3></div></div></div><p>As you <a id="id119" class="indexterm"/>can see from the following screen, we have backups of our snapshots in an Amazon S3 bucket:</p><div><img src="img/B05468_03_19.jpg" alt="Restoring our Convoy backups"/></div><p>Before we restore the backups, we need to recreate our Docker instance. Use the instructions for launching a Docker host in DigitalOcean, installing and starting Convoy, and also setting up your AWS credentials file from the previous sections of this chapter.</p><div><div><h3 class="title"><a id="tip08"/>Tip</h3><p>Remember to reassign your floating IP address to the Droplet before you continue.</p></div></div><p>Once you have everything backed up and running, you should be able to run the following commands to restore the volumes:</p><div><pre class="programlisting">
<strong>sudo convoy create wordpressconvoy_uploads --backup s3://chapter03-backup-bucket@us-west-2/?backup=6cb4ed46-2084-42bc-8261-6b4da690bd5e\u0026volume=26a5913e-4794-4df3-bbb9-7a6361c23a75 </strong>
</pre></div><p>You should also be able to run the following command:</p><div><pre class="programlisting">
<strong>sudo convoy create wordpressconvoy_database --backup s3://chapter03-backup-bucket@us-west-2/?backup=75608b0b-93e7-4319-b212-7a1b0ccaf289\u0026volume=8212de61-ea8c-4777-881e-d4bd07b800e3</strong>
</pre></div><p>The process<a id="id120" class="indexterm"/> of restoring the volumes will take several minutes, during which you will see a lot of output streamed to your terminal. The output should look similar to the following screenshot:</p><div><img src="img/B05468_03_20.jpg" alt="Restoring our Convoy backups"/></div><p>As you can see towards the end of the preceding terminal session, the restore process restores each block from the S3 bucket so that you will most see these messages scroll past.</p><p>Once you have both volumes restored, go back to your Docker Compose file and run the following command:</p><div><pre class="programlisting">
<strong>docker-compose up -d</strong>
</pre></div><p>If everything goes as planned, you should be able to open a browser and see your content intact and how you left it using the following command:</p><div><pre class="programlisting">
<strong>open http://$(docker-machine ip chapter03)/</strong>
</pre></div><div><div><h3 class="title"><a id="tip09"/>Tip</h3><p>Don't forget, if you have finished with the Docker host, you will need to stop and remove using <code class="literal">docker-machine stop chapter03 &amp;&amp; docker-machine rm chapter03</code>, otherwise you may incur unwanted costs.</p></div></div></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec08"/>Summing up Convoy</h3></div></div></div><p>Convoy <a id="id121" class="indexterm"/>is a great tool to start looking at Docker volumes, it is great to quickly move the content around different environments, which means that you can not only share your containers, but also share your volumes with fellow developers or sysadmins. It is also straightforward to install and configure, as it ships as a precompiled binary.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec09"/>Block volumes using REX-Ray</h3></div></div></div><p>So far, we <a id="id122" class="indexterm"/>have looked at drivers that use local storage with backups to remote storage. We are now going to take this one step further by looking at remote storage that is directly attached to our container.</p><p>In this example, we are you going to be launching a Docker instance in Amazon Web Services and launch our WordPress example and attach Amazon Elastic Block Store volumes to our containers using REX-Ray, a volume driver by EMC.</p><p>REX-Ray supports several storage types on both public clouds and EMC's own range, as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">AWS EC2</li><li class="listitem" style="list-style-type: disc">OpenStack</li><li class="listitem" style="list-style-type: disc">Google Compute Engine</li><li class="listitem" style="list-style-type: disc">EMC Isilon, ScaleIO, VMAX, and XtremIO</li></ul></div><p>The driver is in active development and more types of supported storage are promised soon.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec10"/>Installing REX-Ray</h3></div></div></div><p>As we<a id="id123" class="indexterm"/> are going to be using Amazon EBS volumes, we will need to launch the Docker host in AWS, as EBS volumes can not be mounted as block devices to instances in other cloud providers. As per the previous chapter, this can be accomplished using Docker Machine and the following command:</p><div><pre class="programlisting">
<strong> docker-machine create \</strong>
<strong>    --driver amazonec2 \</strong>
<strong>    --amazonec2-access-key JHFDIGJKBDS8639FJHDS \</strong>
<strong>    --amazonec2-secret-key sfvjbkdsvBKHDJBDFjbfsdvlkb+JLN873JKFLSJH \</strong>
<strong>    --amazonec2-vpc-id vpc-35c91750 \</strong>
<strong>    chapter03</strong>
</pre></div><p>Switch <a id="id124" class="indexterm"/>Docker Machine to use the newly created host:</p><div><pre class="programlisting">
<strong>eval "$(docker-machine env chapter03)"</strong>
</pre></div><p>Then, SSH into the host, as follows:</p><div><pre class="programlisting">
<strong>docker-machine ssh chapter03</strong>
</pre></div><p>Once you are on the Docker host, run the following command to install REX-Ray:</p><div><pre class="programlisting">
<strong>curl -sSL https://dl.bintray.com/emccode/rexray/install | sh -</strong>
</pre></div><p>This will download and perform the basic configuration of the latest stable release of REX-Ray:</p><div><img src="img/B05468_03_36.jpg" alt="Installing REX-Ray"/></div><p>Once REX-Ray is installed, we will need to configure it to use Amazon EBS volumes. This will need to be done as the root user, to the following to add a file called <code class="literal">config.yml</code> to <code class="literal">/etc/rexray/</code>:</p><div><pre class="programlisting">
<strong>sudo vim /etc/rexray/config.yml</strong>
</pre></div><p>The file should contain the following, remember to replace the values for AWS credentials:</p><div><pre class="programlisting">rexray:
  storageDrivers:
  - ec2
aws:
  accessKey: JHFDIGJKBDS8639FJHDS
  secretKey: sfvjbkdsvBKHDJBDFjbfsdvlkb+JLN873JKFLSJH</pre></div><p>Once<a id="id125" class="indexterm"/> you have added the configuration file, you should be able to use REX-Ray straight away, running the following command should return a list of EBS volumes:</p><div><pre class="programlisting">
<strong>sudo rexray volume ls</strong>
</pre></div><p>If you see the list of volumes, then you will need to start the process. If you don't see the volumes, check whether the user that you have provided <code class="literal">accesskey</code> and <code class="literal">secretkey</code> for has access to read and create EBS volumes. To start the process and check whether everything is OK, run the following commands:</p><div><pre class="programlisting">
<strong>sudo systemctl restart rexray</strong>
<strong>sudo systemctl status rexray</strong>
</pre></div><p>You should see something similar to the following terminal output if everything works as expected:</p><div><img src="img/B05468_03_37.jpg" alt="Installing REX-Ray"/></div><p>The final step of the installation is to restart Docker on the instance so that it picks up the new volume driver. To do this, run the following command:</p><div><pre class="programlisting">
<strong>sudo systemctl restart docker</strong>
</pre></div><p>Now its <a id="id126" class="indexterm"/>time to launch some containers. The only change we need make to the Docker Compose file from the Convoy one is to change the name of the volume driver, everything else stays the same:</p><div><pre class="programlisting">version: '2'
services:
  wordpress:
    container_name: my-wordpress-app
    image: wordpress
    ports: 
      - "80:80"
    links:
      - mysql
    environment:
      WORDPRESS_DB_HOST: "mysql:3306"
      WORDPRESS_DB_PASSWORD: "password"
    volumes:
      - "uploads:/var/www/html/wp-content/uploads/"
  mysql:
    container_name: my-wordpress-database
    image: mariadb
    environment:
      MYSQL_ROOT_PASSWORD: "password"
    command: mysqld --ignore-db-dir=lost+found
    volumes:
      - "database:/var/lib/mysql/"
volumes:
  uploads:
    driver: rexray
  database:
    driver: rexray</pre></div><p>Once the application has launched, set the permissions on the upload folder by running the following command:</p><div><pre class="programlisting">
<strong>docker exec -d my-wordpress-app chmod 777 /var/www/html/wp-content/uploads/</strong>
</pre></div><p>In the AWS Console, you will notice that now there are some additional volumes:</p><div><img src="img/B05468_03_38.jpg" alt="Installing REX-Ray"/></div><p>Open <a id="id127" class="indexterm"/>your new WordPress installation in a browser by running the following command:</p><div><pre class="programlisting">
<strong>open http://$(docker-machine ip chapter03)/</strong>
</pre></div><p>If you have a problem opening the WordPress site in your browser, find the running instance in the AWS Console and add a rule for <code class="literal">port 80</code>/<code class="literal">HTTP</code> to the <strong>DOCKER-MACHINE</strong> security group. Your rules should look similar to the following image:</p><div><img src="img/B05468_03_41.jpg" alt="Installing REX-Ray"/></div><p>You will only have to add the rule once, as Docker Machine will reassign the <code class="literal">docker-machine</code> security group whenever you launch more Docker hosts.</p><p>Once you have the page open, complete the WordPress installation and edit or upload some content. You know the drill by now, once you have added your content, it's time to stop the containers, remove them, and then terminate the Docker host:</p><div><pre class="programlisting">
<strong>docker-compose stop</strong>
<strong>docker-compose rm</strong>
</pre></div><p>Before<a id="id128" class="indexterm"/> removing the host, you can check the status of the volumes by running the following command:</p><div><pre class="programlisting">
<strong>docker volume ls</strong>
</pre></div><p>You will see something similar to the following image:</p><div><img src="img/B05468_03_39.jpg" alt="Installing REX-Ray"/></div><p>Finally, it's time to remove the Docker host:</p><div><pre class="programlisting">
<strong>docker-machine stop chapter03 &amp;&amp; docker-machine rm chapter03</strong>
</pre></div></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec11"/>Moving the REX-Ray volume</h3></div></div></div><p>Before we <a id="id129" class="indexterm"/>bring up a new Docker host with Docker Machine, it is worth pointing out that our WordPress installation will probably look a little broken.</p><p>This is because moving our containers to a new host changes the IP address that we will be accessing the WordPress site on, meaning that until you change the settings to use the second node's IP address, you will see a broken site.</p><p>This is because it is trying to load content, such as CSS and JavaScript, from the first Docker host's IP address.</p><p>For more information on how to update these settings, refer to the WordPress Codex at <a class="ulink" href="https://codex.wordpress.org/Changing_The_Site_URL">https://codex.wordpress.org/Changing_The_Site_URL</a>.</p><p>Also, if you have logged into the AWS Console, you may have noticed that your EBS volumes are not currently attached to any instance:</p><div><img src="img/B05468_03_40.jpg" alt="Moving the REX-Ray volume"/></div><p>Now that<a id="id130" class="indexterm"/> we have this out of the way, let's launch our new Docker host using Docker Machine. If you followed the instructions in the previous section to launch the host, connect, install REX-Ray, and launch the WordPress and Database containers. As we have already discussed, you could update the site's IP address by connecting to the database:</p><div><ol class="orderedlist arabic"><li class="listitem">Should you want to update the IP address, then you can run the following. First of all, connect to your database container:<div><pre class="programlisting">
<strong>docker exec -ti my-wordpress-database env TERM=xterm bash -l</strong>
</pre></div></li><li class="listitem">Then make a connection to MariaDB using the MySQL client:<div><pre class="programlisting">
<strong>mysql -uroot -ppassword --protocol=TCP -h127.0.0.1</strong>
</pre></div></li><li class="listitem">Switch to the <code class="literal">wordpress</code> database:<div><pre class="programlisting">
<strong>use wordpress;</strong>
</pre></div></li><li class="listitem">Then finally run the following SQL. In my case, <code class="literal">http://54.175.31.251</code> is the old URL and <code class="literal">http://52.90.249.56</code> is the new one:<div><pre class="programlisting">UPDATE wp_options SET option_value = replace(option_value, 'http://54.175.31.251', 'http://52.90.249.56') WHERE option_name = 'home' OR option_name = 'siteurl';
UPDATE wp_posts SET guid = replace(guid, 'http://54.175.31.251','http://52.90.249.56');
UPDATE wp_posts SET post_content = replace(post_content, 'http://54.175.31.251', 'http://52.90.249.56');
UPDATE wp_postmeta SET meta_value = replace(meta_value,'http://54.175.31.251','http://52.90.249.56');</pre></div></li></ol></div><p>Your terminal session should look similar to the following screenshot:</p><div><img src="img/B05468_03_42.jpg" alt="Moving the REX-Ray volume"/></div><p>However,<a id="id131" class="indexterm"/> we can see that the content is present, even though the site looks broken.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec12"/>Summing up REX-Ray</h3></div></div></div><p>REX-Ray<a id="id132" class="indexterm"/> is very much in early development, with more features being added all the time. Over the next few releases, I can foresee it getting more and more useful as it is slowly moving towards being a cluster-aware tool rather than the standalone tool it is at the moment.</p><p>However, even in this early stage of its development, it serves as a great introduction to using external storage with Docker Volumes.</p></div></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec23"/>Flocker and Volume Hub</h2></div></div></div><p>The next tool that we are going to look at is Flocker<a id="id133" class="indexterm"/> by ClusterHQ. It's certainly the most <a id="id134" class="indexterm"/>feature-rich of the third-party volume drivers that we are going to be looking at in this chapter. As you can see from the following list of supported storage options, it has the widest coverage of storage backends out of all of the volume drivers:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">AWS Elastic Block Storage </li><li class="listitem" style="list-style-type: disc">OpenStack Cinder with any supported backend</li><li class="listitem" style="list-style-type: disc">EMC ScaleIO, XtremeIO, and VMAX</li><li class="listitem" style="list-style-type: disc">VMware vSphere and vSan</li><li class="listitem" style="list-style-type: disc">NetApp OnTap</li><li class="listitem" style="list-style-type: disc">Dell Storage SC Series</li><li class="listitem" style="list-style-type: disc">HPE 3PAR StoreServ and StoreVirtual (with OpenStack only)</li><li class="listitem" style="list-style-type: disc">Huawei OceanStor</li><li class="listitem" style="list-style-type: disc">Hedvig</li><li class="listitem" style="list-style-type: disc">NexentaEdge</li><li class="listitem" style="list-style-type: disc">ConvergeIO</li><li class="listitem" style="list-style-type: disc">Saratoga Speed</li></ul></div><p>There is also support for the following storage options coming soon:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Ceph</li><li class="listitem" style="list-style-type: disc">Google Persistent Disk</li></ul></div><p>As most people<a id="id135" class="indexterm"/> will have access to AWS, we are going to look at launching a Flocker cluster in AWS.</p><div><div><div><div><h3 class="title"><a id="ch03lvl3sec13"/>Forming your Flock</h3></div></div></div><p>Rather than<a id="id136" class="indexterm"/> rolling our sleeves up and installing Flocker manually, we are going to take a look at how to get Flocker up and running quickly.</p><p>For this part of the <a id="id137" class="indexterm"/>chapter, we will be launching a cluster using an AWS CloudFormation template provided by ClusterHQ to get a Flocker cluster up and running quickly.</p><div><div><h3 class="title"><a id="note12"/>Note</h3><p>AWS CloudFormation is the orchestration tool provided by Amazon that allows you to define how you would like your AWS infrastructure to look and be configured. CloudFormation is free to use; however, you do pay for the resources that are launched by it. At the time of writing, the estimated cost for running the template for one month is $341.13. For more information on CloudFormation, refer to <a class="ulink" href="https://aws.amazon.com/cloudformation/">https://aws.amazon.com/cloudformation/</a>, or for a breakdown of the costs, refer to <a class="ulink" href="http://calculator.s3.amazonaws.com/index.html#r=IAD&amp;s=EC2&amp;key=calc-D96E035B-5A84-48DE-BF62-807FFE4740A8">http://calculator.s3.amazonaws.com/index.html#r=IAD&amp;s=EC2&amp;key=calc-D96E035B-5A84-48DE-BF62-807FFE4740A8</a>.</p></div></div><p>There are a few steps that we will need to perform before we launch the CloudFormation template. First of all, you will need to create a key pair to be used by the template. To do this, log in to the <a id="id138" class="indexterm"/>AWS console at <a class="ulink" href="https://console.aws.amazon.com/">https://console.aws.amazon.com/</a>, select your region, then click on EC2, and then on the left-hand side <strong>Key Pairs</strong> menu, the key pair you create should be called something like flocker-test:</p><div><img src="img/B05468_03_21.jpg" alt="Forming your Flock"/></div><p>After you<a id="id139" class="indexterm"/> click on the <strong>Create</strong> button, your key pair will be downloaded, <strong>keep this safe</strong> as you will not be able to download it again. Now that you have your key pair created and safely downloaded, it's time to create an account on the ClusterHQ Volume Hub, you<a id="id140" class="indexterm"/> can do this by going to <a class="ulink" href="https://volumehub.clusterhq.com/">https://volumehub.clusterhq.com/</a>.</p><p>The Volume Hub (at the time of writing this book, it is in Alpha testing) is a web-based interface to manage your Flocker volumes. You can either signup for an account using your e-mail address or signin using your Google ID.</p><p>Once you have signed up/in, you will be presented with a notice pointing out that <em>You don't appear to have a cluster yet</em>. and the option of either creating a new cluster or connect to an existing cluster:</p><div><img src="img/B05468_03_22.jpg" alt="Forming your Flock"/></div><p>Clicking on <strong>Create new</strong> button<a id="id141" class="indexterm"/> will open an overlay with instructions about what you need to do to create a cluster using AWS CloudFormation. As we have already actioned step one, scroll down to step two. Here, you should see a button that says <strong>Start CloudFormation Configuration Process</strong>, click on this to open a new tab that will take you directly to the AWS CloudFormation page on the AWS console:</p><div><img src="img/B05468_03_23.jpg" alt="Forming your Flock"/></div><p>The first step of launching the AWS CloudFormation stack is selecting the template, this has already been done for us, so you can click on the <strong>Next</strong> button.</p><p>You will now <a id="id142" class="indexterm"/>be asked to give some details about your stack, this includes a name for the stack, EC2 key pair name, AWS access and secret keys, and also your Volume Hub token.</p><p>To get your <a id="id143" class="indexterm"/>Volume Hub token, visit <a class="ulink" href="https://volumehub.clusterhq.com/v1/token">https://volumehub.clusterhq.com/v1/token</a> and you will be presented with a token. This token is unique to your Volume Hub account, it is important you don't share it:</p><div><img src="img/B05468_03_24.jpg" alt="Forming your Flock"/></div><p>Once you have <a id="id144" class="indexterm"/>filled in the details you can click on the <strong>Next</strong> button. On the next page, you will be asked to tag your resources, this is optional. You should follow your normal processes for tagging resources here. Once you have added your tags, click on the <strong>Next</strong> button.</p><div><div><h3 class="title"><a id="tip10"/>Tip</h3><p>Note that clicking on create will launch resources in your AWS account that will incur hourly charges. Only click on create if you are planning on working through the next steps.</p></div></div><p>The next page gives you an overview of the details that you have provided. If you are happy with these, click on the <strong>Create</strong> button.</p><p>After you click on the <strong>Create</strong> button, you will be taken back to the AWS CloudFormation page, where should see your stack with a <strong>CREATE_IN_PROGRESS</strong> status:</p><div><img src="img/B05468_03_25.jpg" alt="Forming your Flock"/></div><p>If you don't see <a id="id145" class="indexterm"/>your stack, click on the refresh icon on the right-hand top corner. Typically, it will take around 10 minutes to create your cluster. While the stack is being created, you can click on one of the <strong>Split pane</strong> icons on the bottom-right of the screen and view the events that are taking place to launch your cluster.</p><p>Also, as the cluster is launching, you should start seeing Nodes registering themselves in your Volume Hub account. It is important, however tempting, to not start using the Volume Hub until your stack has a <strong>CREATE_COMPLETE</strong> status.</p><p>Once your stack has been deployed, click on the <strong>Outputs</strong> tab. This will give you the details you will need to connect to the cluster. You should see something similar to the following:</p><div><img src="img/B05468_03_26.jpg" alt="Forming your Flock"/></div><p>The first thing <a id="id146" class="indexterm"/>we need to do is set the correct permissions on the key pair that we created earlier. In my case, it is in my <code class="literal">Downloads</code> folder:</p><div><pre class="programlisting">
<strong>chmod 0400 ~/Downloads/flocker-test.pem.txt</strong>
</pre></div><p>Once you have set the permission, you will need to log in to the client node using <code class="literal">ubuntu</code> as the username and your key pair. In my case, the client node IP address is 23.20.126.24:</p><div><pre class="programlisting">
<strong>ssh ubuntu@23.20.126.24 -i ~/Downloads/flocker-test.pem.txt</strong>
</pre></div><p>Once you are logged in, you need to run a few more commands to get the cluster ready. For this, you will need to make a note of the IP addresses of the <strong>Control Node</strong>, which in the preceding screen is <code class="literal">54.198.167.2</code>:</p><div><pre class="programlisting">
<strong>export FLOCKER_CERTS_PATH=/etc/flocker</strong>
<strong>export FLOCKER_USER=user1</strong>
<strong>export FLOCKER_CONTROL_SERVICE=54.198.167.2</strong>
</pre></div><p>Now that you have connected to the control service, you should be able to get an overview of the cluster using the <code class="literal">flockerctl</code> command:</p><div><pre class="programlisting">
<strong>flockerctl status</strong>
<strong>flockerctl ls</strong>
</pre></div><p>When running the <code class="literal">flockerctl ls </code>command, you shouldn't see any datasets listed. Now we should connect to Docker. To do this, run the following commands:</p><div><pre class="programlisting">
<strong>export DOCKER_TLS_VERIFY=1</strong>
<strong>export DOCKER_HOST=tcp://$FLOCKER_CONTROL_SERVICE:2376</strong>
<strong>docker info | grep Nodes</strong>
</pre></div><p>At the time of writing this book, the Flocker AWS CloudFormation template installs and configures Docker 1.9.1 and Docker Compose 1.5.2. This means that you will not be able to use the new Docker Compose file format. There should be, however, Docker Compose files in both<a id="id147" class="indexterm"/> the old and new formats in the GitHub repository, which accompanies this book.</p><p>You can find the repository at <a class="ulink" href="https://github.com/russmckendrick/extending-docker/">https://github.com/russmckendrick/extending-docker/</a>.</p><p>Your terminal output should look similar to the following session:</p><div><img src="img/B05468_03_27.jpg" alt="Forming your Flock"/></div><p>Now that we have everything up and running, let's launch our WordPress installation using Flocker volumes.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec14"/>Deploying into the Flock</h3></div></div></div><p>First <a id="id148" class="indexterm"/>thing we should do is create the volumes. We could let Flocker use its defaults, which is a 75 GB EBS volume, but this is a little overkill for our needs:</p><div><pre class="programlisting">
<strong>docker volume create -d flocker -o size=1G -o profile=bronze --name=database</strong>
<strong>docker volume create -d flocker -o size=1G -o profile=bronze --name=uploads</strong>
</pre></div><p>As you can see, this is a more sensible size and we are choosing the same volume names as we have done in the previous examples. Now that we have our volumes created, we can launch WordPress. To do this, we have two Docker Compose files, one will launch the containers on AgentNode1 and the other on AgentNode2. First of all, create a folder to store the files:</p><div><pre class="programlisting">
<strong>mkdir wordpress</strong>
<strong>cd wordpress</strong>
<strong>vim docker-compose-node1.yml</strong>
</pre></div><p>As already <a id="id149" class="indexterm"/>mentioned, at the time of writing this book, only the original Docker Compose file format is support, due to this, our file should have the following content:</p><div><pre class="programlisting">wordpress:
  container_name: my-wordpress-app
  image: wordpress
  ports: 
    - "80:80"
  links:
    - mysql
  environment:
<strong>    - "constraint:flocker-node==1"</strong>
    - "WORDPRESS_DB_HOST=mysql:3306"
    - "WORDPRESS_DB_PASSWORD=password"
  volume_driver: flocker
  volumes:
    - "uploads:/var/www/html/wp-content/uploads/"
mysql:
  container_name: my-wordpress-database
  image: mariadb
  environment:
<strong>     - "constraint:flocker-node==1"</strong>
     - "MYSQL_ROOT_PASSWORD=password"
  command: mysqld --ignore-db-dir=lost+found
  volume_driver: flocker
  volumes:
    - "database:/var/lib/mysql/"</pre></div><p>As you can see, it isn't too different from the new format. The important thing to note is the lines that bind the containers to a node, this has been highlighted in the preceding code.</p><p>To launch the containers, we have to pass the filename to <code class="literal">docker-compose</code>. To do this, run the following commands:</p><div><pre class="programlisting">
<strong>docker-compose -f docker-compose-node1.yml up -d</strong>
<strong>docker-compose -f docker-compose-node1.yml ps</strong>
</pre></div><p>Once the container's have launched, run the following to set the correct permissions on the <code class="literal">uploads</code> folder:</p><div><pre class="programlisting">
<strong>docker exec -d my-wordpress-app chmod 777 /var/www/html/wp-content/uploads/</strong>
</pre></div><p>Now that we have our volumes created and containers launched, let's take a quick look at the Volume Hub:</p><div><img src="img/B05468_03_28.jpg" alt="Deploying into the Flock"/></div><p>As you can <a id="id150" class="indexterm"/>see, there are two volumes being shown as attached to the node with the internal IP of <code class="literal">10.168.86.184</code>. Looking at the Volumes page gives us a lot more detail:</p><div><img src="img/B05468_03_29.jpg" alt="Deploying into the Flock"/></div><p>As you can see, we have information on the size, name, its unique ID, and which node it is attached to. We can also see the information on the containers that are running within our cluster:</p><div><img src="img/B05468_03_30.jpg" alt="Deploying into the Flock"/></div><p>Before we<a id="id151" class="indexterm"/> stop and remove the containers, you should configure WordPress and then log in and upload a file. You will be able to get the IP address you can access WordPress on by running the following command and opening the IP address where port 80 is mapped to in your browser:</p><div><pre class="programlisting">
<strong>docker-compose -f docker-compose-node1.yml ps</strong>
</pre></div><p>Once you have made these changes, you can stop and remove the containers by running the following commands:</p><div><pre class="programlisting">
<strong>docker-compose -f docker-compose-node1.yml stop</strong>
<strong>docker-compose -f docker-compose-node1.yml rm -f</strong>
</pre></div><p>Now that you have removed the containers, it's time to launch them on the second node. You will need to create a second Docker Compose file, as follows:</p><div><pre class="programlisting">
<strong>vim docker-compose-node2.yml</strong>
</pre></div><div><pre class="programlisting">wordpress:
  container_name: my-wordpress-app
  image: wordpress
  ports: 
    - "80:80"
  links:
    - mysql
  environment:
<strong>    - "constraint:flocker-node==2"</strong>
    - "WORDPRESS_DB_HOST=mysql:3306"
    - "WORDPRESS_DB_PASSWORD=password"
  volume_driver: flocker
  volumes:
    - "uploads:/var/www/html/wp-content/uploads/"
mysql:
  container_name: my-wordpress-database
  image: mariadb
  environment:
<strong>     - "constraint:flocker-node==2"</strong>
     - "MYSQL_ROOT_PASSWORD=password"
  command: mysqld --ignore-db-dir=lost+found
  volume_driver: flocker
  volumes:
    - "database:/var/lib/mysql/"</pre></div><p>As you can<a id="id152" class="indexterm"/> see, all that has changed is the node number. To launch the containers, run the following command:</p><div><pre class="programlisting">
<strong>docker-compose -f docker-compose-node2.yml up -d</strong>
</pre></div><p>It will take a little longer to launch, as Flocker has to unattach and reattach the volumes to the second node. Once the containers are running, you will see that they are now showing as being attached to the second node in the Volume Hub, as shown in the following screenshot:</p><div><img src="img/B05468_03_31.jpg" alt="Deploying into the Flock"/></div><p>This is also reflected in the other sections of the Volume Hub:</p><div><img src="img/B05468_03_32.jpg" alt="Deploying into the Flock"/></div><p>Finally, you <a id="id153" class="indexterm"/>can see your new containers on the <strong>Containers</strong> page:</p><div><img src="img/B05468_03_33.jpg" alt="Deploying into the Flock"/></div><p>Run the following command and open the IP address in a browser:</p><div><pre class="programlisting">
<strong>docker-compose -f docker-compose-node2.yml ps</strong>
</pre></div><p>As mentioned in the REX-Rey section of this chapter, opening WordPress should show you a broken-looking WordPress page, but this shouldn't matter as some content is being served out of the database volume; otherwise, you would be seeing the Install WordPress page.</p><p>So, there you have it. You have used Flocker and Volume Hub to launch and view your Docker volumes, as well as move them between hosts.</p><p>As mentioned at the start of this section, you are paying by the hour to have the cluster up and running. To remove it, you should go to the AWS Console, switch to the CloudFormation service, select <a id="id154" class="indexterm"/>your Stack, and then delete from the actions drop-down menu:</p><div><img src="img/B05468_03_34.jpg" alt="Deploying into the Flock"/></div><p>If you get an error about not being able to remove the S3 bucket, don't worry, all of the expensive stuff will have been terminated. To resolve the error, just go to the S3 bucket it is complaining about in the AWS Console and remove the content. Once you have removed the content, go back to the CloudFormation page and attempt to delete the stack again.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec15"/>Summing up Flocker</h3></div></div></div><p>Flocker is<a id="id155" class="indexterm"/> the grandfather of Docker volumes, it was one of the original solutions for managing volumes even before the volume plugin architecture was released. This means that it is both mature and easily the most complicated of the volume plugins that we have looked at.</p><p>To get an idea of its complexity, you can view the CloudFormation template<a id="id156" class="indexterm"/> at <a class="ulink" href="https://s3.amazonaws.com/installer.downloads.clusterhq.com/flocker-cluster.cloudformation.json">https://s3.amazonaws.com/installer.downloads.clusterhq.com/flocker-cluster.cloudformation.json</a>.</p><p>As you can see, there are a lot of steps. Viewing the template in the CloudFormation visualizer gives you more of an idea of how everything is linked:</p><div><img src="img/B05468_03_35.jpg" alt="Summing up Flocker"/></div><p>Add to <a id="id157" class="indexterm"/>the mix that Docker itself is regularly being updated and you have a very complex installation process. This is the reason why I have not gone into detail about how to manually install it in this chapter, as the process will no doubt have changed by the time you come to read it.</p><p>Luckily, Cluster Labs have an extremely good documentation that is regularly updated. It can be found at <a class="ulink" href="https://docs.clusterhq.com/en/latest/">https://docs.clusterhq.com/en/latest/</a>.</p><p>It's also worth pointing out that, at the time of writing this book, Volume Hub is in early alpha and more functionality is being added regularly. Eventually, I can see this being quite a powerful combination of tools.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec20"/>Summary</h1></div></div></div><p>In this chapter, we have looked at three different volume drivers that all work with Docker's plugin architecture.</p><p>While the three drivers offer three very different approaches to providing persistent storage for your containers, you may have noticed that Docker Compose files and how we interact with the volumes using the Docker client was pretty much the same experience across all three tools, probably to the point where I am sure it was starting to get a little repetitive.</p><p>This repetitiveness showcases, in my opinion, one of the best features of using Docker plugins, the consistent experience from the client's point of view. At no point, after we configured the tools, did we have to really think about or take into consideration how we were using the storage, we just got on with it.</p><p>This allows us to reuse our resources, such as Docker Compose files and containers, across multiple environments such as local VMs, cloud-based Docker hosts, or even Docker clusters.</p><p>However, at the moment, we are still bound to a single Docker host machine. In the next chapter, we will look at how to start spanning multiple Docker hosts by looking at Docker Networking plugins.</p></div></body></html>