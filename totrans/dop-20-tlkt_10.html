<html><head></head><body><div class="chapter" title="Chapter&#xA0;10.&#xA0;Implementation of the Deployment Pipeline &#x2013; The Late Stages"><div class="titlepage"><div><div><h1 class="title"><a id="ch10"/>Chapter 10. Implementation of the Deployment Pipeline – The Late Stages</h1></div></div></div><p>We had to make a break from the implementation of our deployment pipeline and explore service discovery and proxy services. Without a proxy service, our containers would not be accessible in an easy and reliable manner. To provide all the data proxy service needs, we spent some time exploring different options and came up with a few combinations that could serve as service discovery solutions.</p><p>With service discovery and proxy services in our tool-belt, we can continue where we left and finalize<a class="indexterm" id="id449"/> manual execution of the deployment pipeline:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Checkout the code – Done</li><li class="listitem">Run pre-deployment tests – Done</li><li class="listitem">Compile and/or package the code – Done</li><li class="listitem">Build the container – Done</li><li class="listitem">Push the container to the registry – Done</li><li class="listitem">Deploy the container to the production server – Done</li><li class="listitem">Integrate the container – Pending</li><li class="listitem">Run post-deployment tests – Pending</li><li class="listitem">Push the tests container to the registry – Pending<div class="mediaobject"><img alt="Implementation of the Deployment Pipeline – The Late Stages" src="graphics/B05848_10_01.jpg"/><div class="caption"><p>Figure 10-1 – The intermediate stages of the deployment pipeline with Docker</p></div></div></li></ol></div><p>We are<a class="indexterm" id="id450"/> missing three steps in our deployment pipeline. We should integrate our container and, once that is done, run post-deployment tests. Finally, we should push our tests container to the registry so that everyone can use it.</p><p>We'll start by bringing up the two nodes we're using for our deployment pipeline:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>vagrant up cd prod</strong></span>
</pre></div><p>We'll use the <code class="literal">prod2.y</code>
<code class="literal">ml</code> Ansible playbook to provision the <code class="literal">prod</code> node. It contains service discovery and proxy roles that we already discussed in the previous chapter:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>- hosts: prod</strong></span>
<span class="strong"><strong>  remote_user: vagrant</strong></span>
<span class="strong"><strong>  serial: 1</strong></span>
<span class="strong"><strong>  sudo: yes</strong></span>
<span class="strong"><strong>  roles:</strong></span>
<span class="strong"><strong>    - common</strong></span>
<span class="strong"><strong>    - docker</strong></span>
<span class="strong"><strong>    - docker-compose</strong></span>
<span class="strong"><strong>    - consul</strong></span>
<span class="strong"><strong>    - registrator</strong></span>
<span class="strong"><strong>    - consul-template</strong></span>
<span class="strong"><strong>    - nginx</strong></span>
</pre></div><p>Once run, our <code class="literal">prod</code> node will have Consul, Registrator, Consul Template and nginx up and running. They will allow us to proxy all requests to their destination services (at the moment<a class="indexterm" id="id451"/> only <code class="literal">books-ms</code>). Let us run the playbook from the <code class="literal">cd</code> node.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>vagrant ssh cd</strong></span>
<span class="strong"><strong>ansible-playbook /vagrant/ansible/prod2.yml \</strong></span>
<span class="strong"><strong>    -i /vagrant/ansible/hosts/pro</strong></span>
<span class="strong"><strong>d</strong></span>
</pre></div><div class="section" title="Starting the Containers"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec23"/>Starting the Containers</h1></div></div></div><p>Before we <a class="indexterm" id="id452"/>proceed with the integration, we should run the containers:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>wget https://raw.githubusercontent.com/vfarcic\</strong></span>
<span class="strong"><strong>/books-ms/master/docker-compose.yml</strong></span>
<span class="strong"><strong>export DOCKER_HOST=tcp://prod:2375</strong></span>
<span class="strong"><strong>docker-compose up -d app</strong></span>
</pre></div><p>Since we provisioned this node with Consul and Registrator, IPs and ports from those two containers should be available in the registry. We can confirm this by visiting the Consul UI from a browser by opening <code class="literal">http://10.100.198.201:850</code>
<code class="literal">0/ui</code>.</p><p>If we click on the <span class="strong"><strong>Nodes</strong></span> button, we can see that the <code class="literal">prod</code> node is registered. Further on, clicking the <code class="literal">prod</code> node button should reveal that it contains two services; <code class="literal">consul</code> and <code class="literal">books-ms</code>. The <code class="literal">mongo</code> container that we started is not registered because it does not expose any ports:</p><div class="mediaobject"><img alt="Starting the Containers" src="graphics/B05848_10_02.jpg"/><div class="caption"><p>Figure 10-2 – Consul screenshot with the prod node and services running on it</p></div></div><p>We can see<a class="indexterm" id="id453"/> the same information by sending a request to Consul:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>curl prod:8500/v1/catalog/services | jq '.'</strong></span>
<span class="strong"><strong>curl prod:8500/v1/catalog/service/books-ms | jq '.'</strong></span>
</pre></div><p>The first command listed all services registered in Consul. The output is as follows:</p><div class="informalexample"><pre class="programlisting">{
  "dockerui": [],
  "consul": [],
  "books-ms": []
}</pre></div><p>The second command output all the information related to the <code class="literal">books-ms</code> services:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[</strong></span>
<span class="strong"><strong>  {</strong></span>
<span class="strong"><strong>    "ModifyIndex": 27,</strong></span>
<span class="strong"><strong>    "CreateIndex": 27,</strong></span>
<span class="strong"><strong>    "Node": "prod",</strong></span>
<span class="strong"><strong>    "Address": "10.100.198.201",</strong></span>
<span class="strong"><strong>    "ServiceID": "prod:vagrant_app_1:8080",</strong></span>
<span class="strong"><strong>    "ServiceName": "books-ms",</strong></span>
<span class="strong"><strong>    "ServiceTags": [],</strong></span>
<span class="strong"><strong>    "ServiceAddress": "10.100.198.201",</strong></span>
<span class="strong"><strong>    "ServicePort": 32768,</strong></span>
<span class="strong"><strong>    "ServiceEnableTagOverride": false</strong></span>
<span class="strong"><strong>  }</strong></span>
<span class="strong"><strong>]</strong></span>
</pre></div><p>With the<a class="indexterm" id="id454"/> containers up and running and their information stored in the service registry, we can reconfigure nginx so that the <code class="literal">books-ms</code> service is accessible through the standard HTTP port <code class="literal">80</code>.</p></div></div>
<div class="section" title="Integrating the Service"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec24"/>Integrating the Service</h1></div></div></div><p>We'll start by <a class="indexterm" id="id455"/>confirming that nginx does not know about the existence of our service:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>curl http://prod/api/v1/books</strong></span>
</pre></div><p>After sending the request, nginx responded with the <code class="literal">404 Not Found</code> message. Let's change this:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Exit</strong></span>
<span class="strong"><strong>vagrant ssh prod</strong></span>
<span class="strong"><strong>wget https://raw.githubusercontent.com/vfarcic\</strong></span>
<span class="strong"><strong>/books-ms/master/nginx-includes.conf \</strong></span>
<span class="strong"><strong>    -O /data/nginx/includes/books-ms.conf</strong></span>
<span class="strong"><strong>wget https://raw.githubusercontent.com/vfarcic\</strong></span>
<span class="strong"><strong>/books-ms/master/nginx-upstreams.ctmpl \</strong></span>
<span class="strong"><strong>    -O /data/nginx/upstreams/books-ms.ctmpl</strong></span>
<span class="strong"><strong>consul-template \</strong></span>
<span class="strong"><strong>    -consul localhost:8500 \</strong></span>
<span class="strong"><strong>    -template "/data/nginx/upstreams/books-ms.ctmpl:\</strong></span>
<span class="strong"><strong>/data/nginx/upstreams/books-ms.conf:\</strong></span>
<span class="strong"><strong>docker kill -s HUP nginx" \</strong></span>
<span class="strong"><strong>    -once</strong></span>
</pre></div><p>We already did most of those steps in the previous chapter so we'll go through them very briefly. We entered the <code class="literal">prod</code> node and downloaded the includes file and upstreams template from the code repository. Then we run <code class="literal">consul-template</code> that fetched data from Consul and applied them to the template. The result is the nginx upstreams configuration file. Please note that, this time, we added the third argument <code class="literal">docker kill -s HUP nginx</code>. Not only that <code class="literal">consul-template</code> created the configuration file from the template, but it also reloaded nginx. The reason that we did those command from the <code class="literal">prod</code> server instead of doing everything remotely like in the previous chapters lies in automation. The steps we just run are much closer to the way we'll automate this part of the process in the next chapter.</p><p>Now we can test whether our service is indeed accessible through the port <code class="literal">80</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>exit</strong></span>
<span class="strong"><strong>vagrant ssh cd</strong></span>
<span class="strong"><strong>curl -H 'Content-Type: application/json' -X PUT -d \</strong></span>
<span class="strong"><strong>    "{\"_id\": 1,</strong></span>
<span class="strong"><strong>    \"title\": \"My First Book\",</strong></span>
<span class="strong"><strong>    \"author\": \"John Doe\",</strong></span>
<span class="strong"><strong>    \"description\": \"Not a very good book\"}" \</strong></span>
<span class="strong"><strong>    http://prod/api/v1/books | jq '.'</strong></span>
<span class="strong"><strong>curl http://prod/api/v1/books | jq</strong></span>
<span class="strong"><strong> '.'</strong></span>
</pre></div></div>
<div class="section" title="Running Post-Deployment Tests"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec25"/>Running Post-Deployment Tests</h1></div></div></div><p>While we<a class="indexterm" id="id456"/> did confirm that the service is accessible from nginx by sending the request and observing the proper response, this way of verification is not reliable if we are trying to accomplish full automation of the process. Instead, we should repeat the execution of our integration tests but, this time, using port <code class="literal">80</code> (or no port at all since <code class="literal">80</code> is standard <code class="literal">HTTP</code> port):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>git clone https://github.com/vfarcic/books-ms.git</strong></span>
<span class="strong"><strong>cd books-ms</strong></span>
<span class="strong"><strong>docker-compose \</strong></span>
<span class="strong"><strong>    -f docker-compose-dev.yml \</strong></span>
<span class="strong"><strong>    run --rm \</strong></span>
<span class="strong"><strong>    -e DOMAIN=http://10.100.198.201 \</strong></span>
<span class="strong"><strong>    integ</strong></span>
</pre></div><p>The output is as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[info] Loading project definition from /source/project</strong></span>
<span class="strong"><strong>[info] Set current project to books-ms (in build file:/source/)</strong></span>
<span class="strong"><strong>[info] Compiling 2 Scala sources to /source/target/scala-2.10/classes...</strong></span>
<span class="strong"><strong>[info] Compiling 2 Scala sources to /source/target/scala-2.10/test-classes...</strong></span>
<span class="strong"><strong>[info] ServiceInteg</strong></span>
<span class="strong"><strong>[info]</strong></span>
<span class="strong"><strong>[info] GET http://10.100.198.201/api/v1/books should</strong></span>
<span class="strong"><strong>[info] + return OK</strong></span>
<span class="strong"><strong>[info]</strong></span>
<span class="strong"><strong>[info] Total for specification ServiceInteg</strong></span>
<span class="strong"><strong>[info] Finished in 23 ms</strong></span>
<span class="strong"><strong>[info] 1 example, 0 failure, 0 error</strong></span>
<span class="strong"><strong>[info] Passed: Total 1, Failed 0, Errors 0, Passed 1</strong></span>
<span class="strong"><strong>[success] Total time: 27 s, completed Sep 17, 2015 7:49:28 PM</strong></span>
</pre></div><p>As expected, the output shows that integration tests passed successfully. The truth is that we have only one test that makes the same request as the <code class="literal">curl</code> command we run earlier. However, in a <code class="literal">real world</code> situation, the number of tests would increase, and using proper<a class="indexterm" id="id457"/> testing frameworks is much more reliable than running <code class="literal">curl</code> requests.</p></div>
<div class="section" title="Pushing the Tests Container to the Registry"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec26"/>Pushing the Tests Container to the Registry</h1></div></div></div><p>Truth be told, we already pushed this container to the registry to avoid building it every time we <a class="indexterm" id="id458"/>need it and, therefore, save you from waiting. However, this time, we should push it as part of the deployment pipeline process. We <a class="indexterm" id="id459"/>are trying to run tasks in order of their importance so that we get feedback as fast as possible. Pushing containers with tests is very low on our list of priorities, so we left it for the end. Now that everything else was run successfully, we can push the container and let others pull it from the registry and use it as they see fit.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>docker push 10.100.198.200:5000/books-</strong></span>
<span class="strong"><strong>ms-tests</strong></span>
</pre></div></div>
<div class="section" title="The Checklist"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec27"/>The Checklist</h1></div></div></div><p>We managed to go through the whole deployment pipeline. It took us quite a lot of time since we had to take a few brakes and explore different ways to proceed. We could not deploy to <a class="indexterm" id="id460"/>production without exploring configuration management concepts and tools. Later on, we got stuck again and had to learn about service discovery and proxy before being able to integrate the service container:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Checkout the code – Done</li><li class="listitem">Run pre-deployment tests – Done</li><li class="listitem">Compile and/or package the code – Done</li><li class="listitem">Build the container – Done</li><li class="listitem">Push the container to the registry – Done</li><li class="listitem">Deploy the container to the production server – Done</li><li class="listitem">Run post-deployment tests – Done</li><li class="listitem">Push the tests container to the registry – Done<div class="mediaobject"><img alt="The Checklist" src="graphics/B05848_10_03.jpg"/><div class="caption"><p>Figure 10-3 – The late stages of the deployment pipeline with Docker</p></div></div></li></ol></div><p>Now we are<a class="indexterm" id="id461"/> all set. We are capable of running the deployment procedure manually. The next step is to automate all those commands and start running the pipeline automatically from the beginning to the end. We'll destroy the nodes we used so that we can start over fresh and confirm that the automated procedure indeed works:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>exit</strong></span>
<span class="strong"><strong>vagrant destroy -f</strong></span>
</pre></div></div></body></html>