- en: Self-Adaptation Applied To Services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We saw how services could self-heal. It was relatively easy to set up a system
    that would make sure that the desired number of replicas of each service is (almost)
    always running. Docker Swarm does all the work. As long as there are enough available
    hardware resources, our services will (almost) always run the specified number
    of replicas. All we have to do is is specify `replicas: [NUMBER_OF_REPLICAS]`
    in the YAML file that defines our stack.'
  prefs: []
  type: TYPE_NORMAL
- en: The problem with self-healing is that it does not take into account changes
    that affect our systems. We’ll run the same number of replicas even if there is
    a huge spike in their memory utilization. The same applies if, for example, network
    traffic increases. Docker Swarm will not make sure that our system adapts to changed
    conditions. It will follow the blueprint blindly. While that is a vast improvement
    compared to how we operated the system in the past, it is, by no means, enough.
    We need the system both to self-heal and self-adapt.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll expand on the knowledge we obtained by now and start
    exploring ways we can make the system self-adapt. For now, we’ll limit ourselves
    to services and ignore that hardware needs to heal and adapt as well. That will
    come later.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing The Tool For Scaling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We already adopted a few tools. We have metrics stored in Prometheus. We deployed
    Swarm Listener that propagates information to Prometheus. We have Alertmanager
    that receives notifications whenever a certain threshold is reached. While those
    tools allowed us to move forward towards our goals, they are not enough. Now we
    need to figure out what to do with those alerts. Receiving them in Slack is only
    the last resort. We need a tool that will be capable of receiving an alert, process
    the data that comes with it, apply certain logic, and decide what to do.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, self-adaptation is all about scaling. Since we are limiting ourselves
    to services, the system, when it receives an alert, needs to be capable of deciding
    whether to scale up, or down, or do nothing. We need a tool that can accept remote
    requests, that is capable of running code that will determine what should be done,
    and that can interact with Docker.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you read [The DevOps 2.1 Toolkit: Docker Swarm: Building, testing, deploying,
    and monitoring services inside Docker Swarm clusters](https://www.amazon.com/dp/1542468914),
    you know that I suggested Jenkins for our continuous deployment processes. We
    can also use it as the tool that will perform actions that will result in self-adaptation.
    After all, the real power behind Jenkins is not for running (only) continuous
    integration/delivery/deployment pipelines but for running tasks of any kind. Its
    jobs can be triggered remotely from Alertmanager. It has a potent, yet simple
    scripting language through Pipeline DSL. If we expose Docker Socket in Jenkins
    agents, they can easily interact with Docker and execute any command available.'
  prefs: []
  type: TYPE_NORMAL
- en: Even if you prefer some other tool, the examples we’ll implement in Jenkins
    can easily be adapted to anything else as long as the before mentioned requirements
    are fulfilled.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get going.
  prefs: []
  type: TYPE_NORMAL
- en: Creating The Cluster And Deploying Services
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Just as in (almost) any other chapter, we’ll start the practical part by setting
    up a Swarm cluster and deploying the stacks that we used previously.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
