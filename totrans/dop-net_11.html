<html><head></head><body><div class="chapter" title="Chapter&#xA0;11.&#xA0;Securing the Network"><div class="titlepage"><div><div><h1 class="title"><a id="ch11"/>Chapter 11. Securing the Network</h1></div></div></div><p>With many businesses transitioning to software-defined networks and using APIs to make network changes, the importance of securing the network is a prominent concern. Security implementations need to evolve too, as the network is virtualized and modern protocols are used to build Leaf-Spine architectures to scale out multi-tenant cloud environments.</p><p>In this chapter, the following topics will be covered:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The evolution of network security and debunking myths</li><li class="listitem" style="list-style-type: disc">Securing a software-defined network</li><li class="listitem" style="list-style-type: disc">Network security and Continuous Delivery</li></ul></div><div class="section" title="The evolution of network security and debunking myths"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec55"/>The evolution of network security and debunking myths</h1></div></div></div><p>As network <a id="id962" class="indexterm"/>engineers become accustomed to a flat layer 2 network and Spanning Tree protocol as discussed in <a class="link" href="ch01.html" title="Chapter 1. The Impact of Cloud on Networking">Chapter 1</a>, <span class="emphasis"><em>The Impact of Cloud on Networking</em></span>, network security and approaches towards securing an enterprise network have become very mature and well understood by security teams over the years.</p><p>Most security engineers are well versed in the best practices that should be implemented when dealing with physical networks. A security team will normally look to implement a rigid set of security best practices on the network, which network teams must comply with, to pass necessary accreditations. But how applicable are these best practices when implementing software-defined networking?</p><p>It is fair to say that there is still a knowledge gap that exists regarding software-defined networking at the moment and there is a degree of fear and uncertainty of the unknown from security engineers and even some network engineers.</p><p>This chapter will hopefully help demystify some of those concerns. This is coming from someone that helps run a software-defined network in production, so this isn't talking about theories or <a id="id963" class="indexterm"/>aspirations, it is based on hard facts.</p><p>So first let's review some of the requests from security teams around network security and look at how these requests should be adapted when dealing with software-defined networking.</p><div class="section" title="Account management"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec133"/>Account management</h2></div></div></div><p>In terms of account <a id="id964" class="indexterm"/>management, security teams will normally stipulate that the following best practices are adhered to when setting up user access:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Two-factor authentication should be used when accessing production servers</li><li class="listitem" style="list-style-type: disc">User accounts should respect the least privileges necessary for users</li><li class="listitem" style="list-style-type: disc">Unique user accounts should be used between test and production environments</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>DenyAll</strong></span> should be default on Access Control Lists</li><li class="listitem" style="list-style-type: disc">Use <span class="strong"><strong>Terminal Access Controller Access Control System</strong></span> (<span class="strong"><strong>TACACS</strong></span>) or equivalent <a id="id965" class="indexterm"/>authentication to access network devices</li></ul></div><p>When reviewing account management, all points outlined by security practitioners remain valid. Any <span class="strong"><strong>Software-defined Networking</strong></span> (<span class="strong"><strong>SDN</strong></span>) controller or modern switch vendor <a id="id966" class="indexterm"/>should meet the account management requirements when they are being evaluated. If they don't meet these requirements, they simply should not be implemented in production.</p><p>When using software-defined networking always aligned with a Continuous Delivery model, service accounts will be used by orchestration and configuration management tools <a id="id967" class="indexterm"/>such as <span class="strong"><strong>Ansible</strong></span> to setup <a id="id968" class="indexterm"/>subnets, networks, and <span class="strong"><strong>ACL</strong></span> policies to carry out any network changes.</p><p>The user committed to the source control management system will inevitably be the person that invoked the network changes even though it will be invoked by a service account. This in itself is a cultural shift, so privileges on the source control management repository <a id="id969" class="indexterm"/>should be reviewed to set up <span class="strong"><strong>Active Directory Domain Services</strong></span> (<span class="strong"><strong>ADDS</strong></span>) or <span class="strong"><strong>Lightweight Directory Access Protocol</strong></span> (<span class="strong"><strong>LDAP</strong></span>) access <a id="id970" class="indexterm"/>so commits are tracked and can be traced back to the user that made the change. Continuous <a id="id971" class="indexterm"/>Delivery <a id="id972" class="indexterm"/>tooling such as <span class="strong"><strong>Jenkins</strong></span>, <span class="strong"><strong>ThoughtWorks</strong></span>, <span class="strong"><strong>Go</strong></span>, or a Plethora of other <a id="id973" class="indexterm"/>continuous integration build servers <a id="id974" class="indexterm"/>can cater for this requirement.</p><p>Separate service accounts can be used to orchestrate test and production environments to meet security best practices. All other user accounts in a Continuous Delivery model should be read-only, so users can view the outcome of a Continuous Delivery deployment, which is driven by automation, with a break glass account being the exception to the rule and available for use in a state of emergency.</p><p>It is important for security teams to understand that if users are manually intervening in immutable software-defined networks, then the overall Continuous Delivery model could break, so there is no appetite to do manual configuration . All desired state should be controlled via source <a id="id975" class="indexterm"/>control management systems and pushed out to systems accordingly. This, again, is a mindset change and security practitioners generally find this hard to believe, as they have spent years seeing network engineers push manual changes to devices to make any changes, but this is a new approach and a huge change for some.</p><p>This was illustrated in <a class="link" href="ch09.html" title="Chapter 9. Using Continuous Delivery Pipelines to Deploy Network Changes">Chapter 9</a>, <span class="emphasis"><em>Using Continuous Delivery Pipelines to Deploy Network Changes</em></span>, when utilizing configuration management tools such as Ansible to push out network changes to test and production environments:</p><div class="mediaobject"><img src="graphics/B05559_11_01.jpg" alt="Account management"/></div><p>This concept is initially difficult for security <a id="id976" class="indexterm"/>practitioners to grasp, but the <span class="strong"><strong>DevSecOps</strong></span> movement is helping security practitioners see the window of opportunity that an automated Continuous Delivery process brings.</p><p>Automation should mean users have fewer individual privileges and approved workflow actions are hardened and signed off, which govern what kind of interaction <a id="id977" class="indexterm"/>is allowed. All of this is controlled via the Continuous Delivery pipeline.</p></div><div class="section" title="Network device configuration"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec134"/>Network device configuration</h2></div></div></div><p>Security best practices with <a id="id978" class="indexterm"/>regards to the configuration of network devices focus on keeping an up-to-date auditable inventory of the network, with security patching being applied on a regular basis to each network <a id="id979" class="indexterm"/>device at an operating system level, and secure protocols and <span class="strong"><strong>Public Key Infrastructure</strong></span> (<span class="strong"><strong>PKI</strong></span>) certificates being applied from relevant trust stores.</p><p>As such, a common set of requirements from a security team for configuration of network devices may include:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A network <a id="id980" class="indexterm"/>hardware list should be available in an <span class="strong"><strong>IP Address Management</strong></span> (<span class="strong"><strong>IPAM</strong></span>) solution</li><li class="listitem" style="list-style-type: disc">All network devices should be patched regularly</li><li class="listitem" style="list-style-type: disc">Configure SNMP version 3 or above</li><li class="listitem" style="list-style-type: disc">Disable ports not in use</li><li class="listitem" style="list-style-type: disc">Use <span class="strong"><strong>Transport Layer Security</strong></span> (<span class="strong"><strong>TLS</strong></span>) to <a id="id981" class="indexterm"/>encrypt network traffic</li></ul></div><p>The security approaches to network device configuration should also not change in terms of setup, as SDN controllers and modern switch vendors should look to use TLS, be patched regularly, and be accessible via DNS.</p><p>An underlay network when utilizing a Leaf-Spine architecture and overlay network is still comprised of physical network devices, so the configuration and best practices associated with securing these devices are still completely valid and integral.</p><p>SDN controllers, like network switches, are deployed on the layer 2 underlay network, so should follow the same conventions as network switches, have secure protocols, and adhere to patching schedules.</p></div><div class="section" title="Firewalling"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec135"/>Firewalling</h2></div></div></div><p>One of the major sources of confusion from security teams in industry when looking at software-defined networking seems to be around firewalling and some fear and uncertainty exists as they are used to using <a id="id982" class="indexterm"/>physical <span class="strong"><strong>stateful</strong></span> firewalls in production networks.</p><p>However, as long as a virtual firewall meets security requirements, there should be no issue implementing SDN controllers and allowing them to control firewalling and segmentation of the network using virtualized micro-segmentation policies.</p><p>Security teams will traditionally mandate the following requirements from firewalls:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Use a stateful firewall</li><li class="listitem" style="list-style-type: disc">Use explicit permits and implicit denies on ACL rules</li><li class="listitem" style="list-style-type: disc">Have the ability to audit teams' ACL access</li><li class="listitem" style="list-style-type: disc">Log all denied attempts on the firewall</li></ul></div><p>Firewall best practices should always be adhered to when implementing software-defined networking; traditionally <a id="id983" class="indexterm"/>though, security teams have always pushed for stateful physical firewalls to separate three-tier models, which are segregated into frontend, business logic, and backend tiers.</p><p>With the move towards microservices and the adoption of software-defined networking, applications have tended not to fit into this structure and <span class="strong"><strong>Open vSwitch</strong></span> has allowed OpenFlow to be <a id="id984" class="indexterm"/>used to <a id="id985" class="indexterm"/>implement <span class="strong"><strong>Ingress</strong></span> and <span class="strong"><strong>Egress</strong></span> policies at the hypervisor level or operating system host level.</p><p>We have also seen that this same process can be applied to containers in <a class="link" href="ch11.html" title="Chapter 11. Securing the Network">Chapter 11</a>, <span class="emphasis"><em>The Impact of Containers on Networking, </em></span>and Open VSwitch can be installed on container hosts such as Core OS, or even on bare metal servers to control firewall polices.</p><p>As long as the same best practice principles of using explicit permits and implicit denies on ACL rules are adhered to, and a process is set up to log all denied attempts on the firewall, then there should be no reasons to argue against the merits of using virtualized firewalling.</p><p>Open vSwitch now offers stateful firewalling, which is now as secure as iptables on a Linux operating system or a physical firewall, so there is now no reason why firewalling cannot be virtualized for enterprise networks. This mirrors the debate about the use of hypervisors initially for infrastructure services, but the gains it brings a business in terms of scalability, programmability, auditability, and manageability make it hard to argue against firewall virtualization.</p></div><div class="section" title="Vulnerability detection"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec136"/>Vulnerability detection</h2></div></div></div><p>Overlay networks, in <a id="id986" class="indexterm"/>terms of the detection of vulnerabilities and attacks, should also not change in terms of security requirements, although the method for acquiring the data may need to <a id="id987" class="indexterm"/>change slightly, as protocols such as <span class="strong"><strong>Border Gateway Protocol</strong></span> (<span class="strong"><strong>BGP</strong></span>) and <span class="strong"><strong>Virtual Extensible LAN</strong></span> (<span class="strong"><strong>VXLAN</strong></span>) need different<a id="id988" class="indexterm"/> tooling to track packets in the network.</p><p>When looking at vulnerability detection and data sampling, the following activities should be scheduled on a regular basis:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Regular vulnerability scanning</li><li class="listitem" style="list-style-type: disc">Deep packet inspection</li></ul></div><p>In terms of vulnerability scanning, scanning of the network and network devices should be carried out frequently. Ideally security scanners themselves should have separate responsibilities in a software-defined network. A security scanner should have access to the underlay to do a full scan and another profile of the scanner should be used for the overlay. If a scanner <a id="id989" class="indexterm"/>has access to the underlay and overlay, it becomes an attack vector, which if compromised would allow an attacker complete access to the network. So this is an important point often ignored; the overlay and underlay network devices and compute should not be routable to one another if possible.</p><p>It is often a requirement of a security team to be able to inspect network packets using deep packet inspection to make sure that there is no malicious activity. This has been done on flat layer 2 networks by inspecting packets that are transmitted between VLANs.</p><p>However, with overlay transporting packets using VXLAN encapsulation, networks can scale out network and alleviate the 4096 VLAN limit. This means that network and security teams will require tools that can de-encapsulate VXLAN packets so they can able to inspect packets, as they have with VLAN packets, otherwise security tools will see data is being transmitted but it won't be able to be read it.</p><p>Setting up tooling that does VXLAN de-encapsulation is by no means an insurmountable challenge. Tooling is available to do this, it will just require that network and security teams alter the tools they are currently used to using.</p></div><div class="section" title="Network segmentation"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec137"/>Network segmentation</h2></div></div></div><p>One of the biggest changes when implementing a software-defined overlay network is a shift away from the principles of a flat layer 2 network and VLAN segregation between networks.</p><p>Security teams are <a id="id990" class="indexterm"/>used to dealing with physical networks, so they will normally stipulate that the following requirements need to be met:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Use VLANs to segregate traffic types (frontend, business logic, and backend)</li><li class="listitem" style="list-style-type: disc">Ability to segregate <span class="strong"><strong>Test</strong></span> and <span class="strong"><strong>Production</strong></span></li><li class="listitem" style="list-style-type: disc">Use firewalls between different network tiers</li></ul></div><p>However, SDN controllers create VXLAN tunnels between hardware <span class="strong"><strong>Virtual Tunnel End Points</strong></span> (<span class="strong"><strong>VTEPs</strong></span>) on <a id="id991" class="indexterm"/>network switches and stretches them to each hardware compute node to build a virtualized overlay underlay network over the network.</p><p>SDN controllers <a id="id992" class="indexterm"/>are used to translate the <span class="strong"><strong>Open vSwitch Database</strong></span> (<span class="strong"><strong>OVSDB</strong></span>) information from switch vendors and push the flow data down to <a id="id993" class="indexterm"/>each compute node (hypervisor, container, or bare metal server), which is dictated by the SDN controller's policy engine to create firewalls and micro-segmentation.</p><p>It is a differing approach; firewalling <a id="id994" class="indexterm"/>per microservice application is dictated by <span class="strong"><strong>OpenFlow</strong></span> and used to control Ingress and Egress policies. Using overlay networks, applications can communicate with another application's micro-segmented <a id="id995" class="indexterm"/>zone as illustrated by the <span class="strong"><strong>Nuage Networks</strong></span> <span class="strong"><strong>Virtual Service Platform</strong></span> (<span class="strong"><strong>VSP</strong></span>) in <a class="link" href="ch02.html" title="Chapter 2. The Emergence of Software-defined Networking">Chapter 2</a>, <span class="emphasis"><em>The Emergence Of Software, Defined Networking</em></span>.</p><p>In the following example, we can see the <span class="strong"><strong>Application 1</strong></span> micro-subnet communicating with <span class="strong"><strong>Application 2</strong></span> by communicating subnet to zone:</p><div class="mediaobject"><img src="graphics/B05559_11_02.jpg" alt="Network segmentation"/></div><p>Using micro-segmentation of firewall rules per application moves away from having physical, stateful firewalls segmenting zones for all applications. Instead, individual firewalls are created per application to govern segmentation between the network, with layer 3 domains segmenting <span class="strong"><strong>Test</strong></span> and <span class="strong"><strong>Production</strong></span> from each other at a layer above.</p><p>Each application has their own policy in this micro-segmentation model, which means security teams have the ability to audit firewall policies and understand what each application is communicating with.</p><p>Overlay networks for this reason should bring security gains, as it becomes completely clear the connectivity requirements for an application and connectivity topologies are not lost in a set of monolithic ACL rules on a physical stateful firewall, which aren't clearly mapped to each application.</p><p>Software-defined networking should me<a id="id996" class="indexterm"/>an that each application has an initial deny all and opens up only the minimum amount of explicit access so they can access other applications or services in the network.</p><p>This is far more secure than opening up port ranges on a stateful firewall, so overlay networks should, in theory, improve complex network security when implemented correctly. If immutable networks are used as highlighted by A/B subnets in <a class="link" href="ch06.html" title="Chapter 6. Orchestrating SDN Controllers Using Ansible">Chapter 6</a>, <span class="emphasis"><em>Orchestrating SDN Controllers Using Ansible,</em></span> then automatic cleanup of old ACL rules is also implemented by default, which has been a challenge for network and security teams as they are afraid to remove old policies in the fear of creating an outage for a particular application.</p><p>Security teams can audit that policy with development teams and advise on any changes that need to be made, safe in the knowledge that as far as a development team is concerned, all of the ACL policies they are implementing are required to deploy their application with the bare minimum amount of explicit Ingress and Egress ACL rules being used.</p></div></div></div>
<div class="section" title="Securing a software-defined network"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec56"/>Securing a software-defined network</h1></div></div></div><p>So far in this chapter, we have focused on a set of minimal network security requirements to make sure that a software-defined network is secure.</p><p>But to maximize <a id="id997" class="indexterm"/>the security of a software-defined network, we should look at how overlay and underlay networks could potentially be exploited in new ways by attackers and look at different mechanisms that can be put in place to prevent this from happening.</p><p>Software-defined Networks are split into the overlay (which holds all the virtualized networks that houses virtual, physical machines, and containers) and the underlay (which holds all bare metal machines such as hypervisors, network devices, and SDN controllers).</p><div class="section" title="Attacks at Overlay"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec138"/>Attacks at Overlay</h2></div></div></div><p>
<span class="strong"><strong>Overlay</strong></span> networks are <a id="id998" class="indexterm"/>created to allow networks to be automated <a id="id999" class="indexterm"/>programmatically via APIs and increase the speed of change by simplifying the network in software.</p><p>Within the remit of Continuous Delivery, self-service ACL rules can be set up by developers to govern north to south and east to west ACL policies.</p><p>It is important to have implicit controls that make sure that common workflow actions only allow teams to set ACL rules from their micro-subnet to different locations in the network, and that they can't compromise the integrity of any other network in the overlay except their own. So this should be demonstrable by testing the self-service automation to security teams.</p><p>Micro-segmentation is powerful in the following example:</p><p>When using implicit allows, team A with application 1 can only communicate with application 2, which is maintained by team B, if team B allows explicit Ingress rules that allow application 1 to communicate with it. So teams will have to coordinate between themselves, and their applications will only be able to communicate with one another if there is both an Egress and Ingress rule on each microservice application's firewall.</p><p>Aside from this, some applications may need northbound Internet access, so it is important that network teams put in place a mechanism to proxy out to the Internet and not give teams the ability to directly access it. A controlled proxy mechanism should be implemented by the network team so that there is a fixed mechanism to govern northbound Internet access.</p><p>Attackers may try and compromise a virtual machine or physical server that is part of the overlay network. Once they gain access to a machine, they could attempt to download software and compromise the network. An <a id="id1000" class="indexterm"/>attacker could potentially attempt a <span class="strong"><strong>Denial of Service</strong></span> (<span class="strong"><strong>DoS</strong></span>) on a particular micro-subnet, which could be used to compromise a key service by compromising all virtual machines in the micro-subnet.</p><p>A benefit of micro-segmentation over a layer 2 network is that if one box was compromised in production, an attacker could have access to the whole frontend, business logic, or backend zone, while with micro-segmentation they would be isolated to the particular application.</p><p>With regards to outbound Internet access and setting up a proxy, it is imperative that upstream repositories used to download software packages to hosts go via a controlled proxy <a id="id1001" class="indexterm"/>server, using an artifact repository with <span class="strong"><strong>Role Based Access Control</strong></span> (<span class="strong"><strong>RBAC</strong></span>) using Active Directory Domain Services or <a id="id1002" class="indexterm"/>LDAP <a id="id1003" class="indexterm"/>such as <span class="strong"><strong>Artifactory</strong></span> or <span class="strong"><strong>Nexus</strong></span>.</p><p>This means that servers within the overlay network can only access a set of approved third-party software repositories that have been given the blessing of the infrastructure team. Repositories not on the approved list cannot be accessed via the overlay network servers, as they are not proxied by the artifact repository, thus preventing the installation of dubious packages onto servers in the overlay network.</p><p>Proxying via an artifact repository means network and security teams can take measures to prevent packet sniffing software being downloaded onto a server to discover adjacent services or open ports dictated by the Ingress and Egress flow data.</p><p>It may also be <a id="id1004" class="indexterm"/>desirable to disable <span class="strong"><strong>Internet Control Message Protocol</strong></span> (<span class="strong"><strong>ICMP</strong></span>) in the overlay network so that an attacker cannot work out the IP addresses of adjacent servers in a micro-subnet or underlay network devices <a id="id1005" class="indexterm"/>such as top-of-rack switches and SDN controllers by doing a trace route.</p><p>If a server in the overlay network is logging drops, then appropriate alerting should be set up to notify the network or security team that some illicit activity is occurring within a micro-subnet.</p><p>Mechanisms can be put in place to tag compromised boxes with metadata in this case and use tools such as Ansible dynamic inventory to target them altogether by issuing a shut down or moving them to a quarantined network using live migration, which will stop a potential network attacker from gaining access to other servers in the network.</p></div><div class="section" title="Attacks on the underlay network?"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec139"/>Attacks on the underlay network?</h2></div></div></div><p>The <span class="strong"><strong>underlay</strong></span> network <a id="id1006" class="indexterm"/>could be targeted by potential attackers by gaining access to a hypervisor and looking to compromise Open vSwitch. This would allow <a id="id1007" class="indexterm"/>them to directly instantiate new flows into the Open vSwitches flow-table, allowing access to multiple different locations in the network.</p><p>The attacker <a id="id1008" class="indexterm"/>could sniff traffic and perform a <span class="strong"><strong>Man in the Middle</strong></span> (<span class="strong"><strong>MitM</strong></span>) attack on different network components as a result, so hypervisors should ideally be on a separate network, which will isolate access to compute servers and not allow them to be directly routable from the overlay network.</p><p>In the underlay network, switches now utilize centralized management systems to push updates to switches. For <a id="id1009" class="indexterm"/>example, the <span class="strong"><strong>Arista CloudVision</strong></span> platform <span class="strong"><strong>CloudVision eXchange</strong></span> (<span class="strong"><strong>CVX</strong></span>) servers are used to push configuration to all Arista switches, so it is imperative <a id="id1010" class="indexterm"/>that access control to its API endpoints is done over HTTPs and that the management of switches is done on a completely dedicated network.</p><p>An attacker could potentially drop the whole configuration of every switch if the CVX cluster was compromised to create a DoS attack on the network, which would also mean that all routing would be dropped by the SDN controller.</p><p>An <span class="strong"><strong>Out Of Band</strong></span> (<span class="strong"><strong>OoB</strong></span>) network <a id="id1011" class="indexterm"/>should ideally be implemented to govern access to network appliances with access provided via TACCs accounts. Using an OOB network for the northbound and southbound communications can help secure network devices and provide an extra degree of security for network devices.</p><p>The underlay and overlay network should be on completely different networks and not routable; this means that if a hypervisor is compromised in the underlay network, then an attacker will not be <a id="id1012" class="indexterm"/>able to directly jump from an underlay box to the overlay. Underlay boxes should ideally be protected using bastion servers with two-factor authentication so no servers are directly accessible.</p><p>SDN controllers are typically x86 compute, and talk via REST API calls, so it should be mandatory to implement TLS on the SDN controllers and if possible issue a PKI CA to manage trust, authenticity, and revocation of access.</p><p>In the following example, we <a id="id1013" class="indexterm"/>can see that the <span class="strong"><strong>Arista CVX</strong></span> platform communicates with <a id="id1014" class="indexterm"/>the Nuage <span class="strong"><strong>VSC</strong></span> SDN <a id="id1015" class="indexterm"/>controller using <span class="strong"><strong>OVSDB</strong></span> with <span class="strong"><strong>TLS</strong></span> on the <a id="id1016" class="indexterm"/>underlay:</p><div class="mediaobject"><img src="graphics/B05559_11_03.jpg" alt="Attacks on the underlay network?"/></div><p>If underlay devices communicate using HTTP sessions, it will make the network susceptible to attacks in the Overlay network not just the underlay network.</p><p>Taking the <span class="strong"><strong>OpenStack</strong></span> platform <a id="id1017" class="indexterm"/>as an example, an SDN controller communicating with the OpenStack Neutron plug in will exchange all Ingress and Egress information for the entire overlay network. If this connection is using unencrypted REST API calls, it would mean that an attacker could intercept or track all flow information, and this can be used to compromise any number of tenant networks within the overlay.</p></div><div class="section" title="Attacks on the SDN controller"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec140"/>Attacks on the SDN controller</h2></div></div></div><p>The northbound <a id="id1018" class="indexterm"/>API on an SDN controller is a desirable attack vector that could be used to compromise the whole overlay network.</p><p>To prevent this, RBAC should be put in place with sufficient password best practices adhered to. If the SDN controller's northbound API is compromised, then attackers could create new flow data programmatically against the overlay.</p><p>This would allow an attacker to traverse the network and target multiple services, allowing the attacker to bypass denying firewall policies and access multiple tenant networks.</p><p>Default admin accounts should have their passwords changed from day one, to avoid attackers guessing default accounts passwords. Complex passwords should be used at all times.</p><p>Audit trails should be set up on the SDN <a id="id1019" class="indexterm"/>controller and logged to a <span class="strong"><strong>syslog</strong></span> server, which will allow network and security engineers to check for unauthorized changes by attackers. If any irregular behavior occurs, then subsequent alerts should be triggered and the account should be disabled immediately.</p><p>On SDN controllers, SNMPv3 should be enabled as opposed to earlier versions and LDAP accounts, or SSH keys set up to allow access to Linux-based operating systems as opposed to using single service accounts or root access for underlay changes.</p></div></div>
<div class="section" title="Network security and Continuous Delivery"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec57"/>Network security and Continuous Delivery</h1></div></div></div><p>Network security should be improved when using automation to push network changes out to network <a id="id1020" class="indexterm"/>devices, or to change the desired state of overlay networks. It should increase the visibility of changes, as all changes are done from a centralized process, with no exceptions.</p><p>Continuous delivery <a id="id1021" class="indexterm"/>processes, by design, should allow security teams to see clearly which user committed a network change. When a change is pushed to network devices or SDN controllers using the Continuous Delivery process, it will allow easy roll back to a previous version if the security team don't approve of the changes. However, this is still very reactive and continuous integration  and delivery processes should include compliance and security checks as part of the continuous integration and delivery process.</p><p>Having compliance <a id="id1022" class="indexterm"/>checks as part of Continuous Delivery provides a <a id="id1023" class="indexterm"/>lot of flexibility for network and security teams. This will enable security teams to utilize some of the continuous integration and delivery best practices to help secure a network, such as continual testing and validation of changes integrated as part of the deployment pipeline.</p><div class="section" title="Application connectivity topology"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec141"/>Application connectivity topology</h2></div></div></div><p>In a software-defined network, each application is micro-segmented, so they have individual <a id="id1024" class="indexterm"/>application policies that can be audited by <a id="id1025" class="indexterm"/>security or network teams. This will help with security compliance, as it allows security practitioners to see all the Ingress or Egress rules for a particular application in the overlay network.</p><p>This was highlighted in <a class="link" href="ch02.html" title="Chapter 2. The Emergence of Software-defined Networking">Chapter 2</a>, <span class="emphasis"><em>The Emergence Of Software-defined Networking,</em></span> showing micro-segmented policies per application with egress policies for <span class="strong"><strong>Application1</strong></span> defined as shown:</p><div class="mediaobject"><img src="graphics/B05559_11_04.jpg" alt="Application connectivity topology"/></div><p>The applications Ingress and Egress ACL rules should be readable and auditable in source control management systems using YAML files, or any other chosen configuration file used to control the SDN controller's desired state.</p><p>The live state of the system will also be present on SDN controller GUIs, which can be observed to make sure it matches what is defined in source control management systems.</p><p>It is important for security practitioners to be able to read and understand the configuration files that are being used to determine the current connectivity and state of the network.</p><p>Network and security teams have unique goals such as passing security audits to keep the business operational. It is important for Security teams to be able to see the application connectivity matrix and be able to have full visibility over connectivity.</p><p>For instance, <a id="id1026" class="indexterm"/>when processing credit card transactions, <a id="id1027" class="indexterm"/>only specific users should have access to that particular tenant network. Having the ability to enforce this via the SDN and demonstrate this is the case with an easy to understand SDN policy makes the network and security team's jobs easier as they have a real-time connectivity matrix for each application.</p></div><div class="section" title="Wrapping security checks into continuous integration"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec142"/>Wrapping security checks into continuous integration</h2></div></div></div><p>Security checks should ideally be built into continuous integration processes, a concept covered in depth in <a class="link" href="ch07.html" title="Chapter 7. Using Continuous Integration Builds for Network Configuration">Chapter 7</a>, <span class="emphasis"><em>Using Continuous Integration Builds for Network Configuration</em></span>. Otherwise, security teams would not be able to keep up with the daily changes <a id="id1028" class="indexterm"/>being made to dynamic <a id="id1029" class="indexterm"/>overlay networks <a id="id1030" class="indexterm"/>and ever-changing network policies.</p><p>Compliance can be integrated with continuous integration processes by disallowing an allow-all policy when applied by a developer on their self-service ACL file for an application.</p><p>When a user commits this <a id="id1031" class="indexterm"/>change to a source control management system, the <span class="strong"><strong>CI Build Server</strong></span> starts a new continuous integration build. A validation on the continuous integration build for the SDN configuration build could be set up by the security team to reject this configuration and provide instant feedback to the user, as this breaks compliance.</p><p>The user would instead have to alter the self-service ACL policy rules to be implicit, so compliance then becomes just another validation of the continuous integration process, as shown here:</p><div class="mediaobject"><img src="graphics/B05559_11_05.jpg" alt="Wrapping security checks into continuous integration"/></div><p>This is opposed<a id="id1032" class="indexterm"/> to security teams <a id="id1033" class="indexterm"/>auditing the ACL rules as a separate manual check, which would of course let ACL rules that breach security policy, slip through into production environments <a id="id1034" class="indexterm"/>and allow attackers the potential to compromise a particular application, as its ACL rules are too open. This validation could even be done prior to a <span class="strong"><strong>CI Build Server</strong></span> by <a id="id1035" class="indexterm"/>running a simple Git hook, which would reject the commit after detecting an allow-all on the ACL policies by parsing the YAML file.</p></div><div class="section" title="Using Cloud metadata"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec143"/>Using Cloud metadata</h2></div></div></div><p>The use of cloud metadata is commonplace in public and private clouds such as AWS, Microsoft Azure, Google Cloud, and <a id="id1036" class="indexterm"/>OpenStack as well as other cloud providers.</p><p>Tagging boxes with <a id="id1037" class="indexterm"/>specific metadata has a variety of different use cases, and a subset of those use cases could greatly benefit a network or security team when dealing with particular network security challenges.</p><p>Cloud metadata, as covered already in this book, is a series of key-value pairs that are applied to a cloud server. If we take the example of a security vulnerability such as shell shock, which caused a series of DoS attacks when exploited in 2014, it is important that security vulnerabilities such as these are fixed immediately, to prevent attackers exploiting Linux boxes.</p><p>Within the remits of Continuous Delivery, it is important to make sure that if an issue occurs, then the mean time to recover is quick.</p><p>Take the scenario of vulnerability scanning. Each week, the whole overlay and underlay network will be scanned on a daily, or at worst, a weekly basis, using a security scanner.</p><p>Every time that the weekly network security scan runs on all boxes, it generates a report documenting a list of vulnerabilities for each server. This is subsequently reviewed by the service owners, and the <a id="id1038" class="indexterm"/>security team will recommend specific patches or <a id="id1039" class="indexterm"/>remediation over a number of days, so the mean time to resolve is high if important vulnerabilities are highlighted.</p><p>If instead of generating a separate report, the network security scan tagged the servers with a specific list of vulnerability IDs on their cloud metadata, then a complete inventory of vulnerabilities for the whole network would be available that could be acted upon to make real-time updates.</p><p>Using OpenStack as an example, the following command line could be executed to set metadata against a server when vulnerabilities are detected by using the <code class="literal">qualys_vul_ids</code> key value pair:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>nova meta-data (instance-uuid) set qualys_vul_ids (qualys_id_list)</strong></span>
</pre></div><p>The following example would be executed as part of a script that would be run against all servers:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>nova meta-data 061e8820-3abf-4151-83c8-13408923eb16 set qualys_vul_ids 23,122</strong></span>
</pre></div><p>This key value pair is then passed to the OpenStack metadata service, which will tag the OpenStack instance <a id="id1040" class="indexterm"/>with all the relevant vulnerabilities that have been discovered as part of the <span class="strong"><strong>Qualys</strong></span> vulnerability scan.</p><p>This will result in the OpenStack instance containing the following metadata:</p><div class="mediaobject"><img src="graphics/B05559_11_06.jpg" alt="Using Cloud metadata"/></div><p>If a vulnerability such as shell shock was exposed by the security scan, then the network and security team could identify all servers with that vulnerability. In this case, <code class="literal">Qualys ID</code> <code class="literal">122</code> relates to shell shock, and targets the servers affected with an immediate patch.</p><p>Ansible dynamic inventory <a id="id1041" class="indexterm"/>could be used to target the vulnerable boxes using a <a id="id1042" class="indexterm"/>bespoke <code class="literal">ad_hoc_patch.yml</code> playbook with a when condition only, which executes patch commands to Linux servers if <code class="literal">Qualys ID</code> <code class="literal">122</code> is tagged on the <code class="literal">qualys_vul_ids</code> metadata tag on the server.</p><p>The <code class="literal">ad_hoc_patch.yml</code> playbook would have the following steps to set a fact from the metadata and execute the commands only when the metadata tag contains the correct metadata:</p><div class="mediaobject"><img src="graphics/B05559_11_07.jpg" alt="Using Cloud metadata"/></div><p>This playbook can be used to<a id="id1043" class="indexterm"/> fix the shell shock <span class="strong"><strong>Bashdoor</strong></span> bug immediately by executing following command:</p><div class="informalexample"><pre class="programlisting">
<code class="literal">ansible-playbook –i inventories/openstack.py –l Prod playbooks/ad_hoc_patch.yml</code>
</pre></div><p>which would execute the playbook against all customer-facing servers in the <code class="literal">Prod</code> availability zone that contain the vulnerability, so target only production servers.</p><p>The playbook would only execute against servers in the production availability zone that match the metadata value of <code class="literal">122</code> as an active vulnerability using <code class="literal">Ansible jinja2</code> when filters, which would allow infrastructure engineers to remove the vulnerability in minutes. Imagine if security scanners did this metadata tagging as a feature of their scanner; it would help security massively.</p><p>Cloud metadata has many other <a id="id1044" class="indexterm"/>use cases such as using an owner metadata tag on <a id="id1045" class="indexterm"/>servers to send targeted e-mails or alerts if security teams detect any suspicious activity, or flag servers for re-deployment to install new patches when using immutable infrastructure.</p><p>Compromised servers can also be<a id="id1046" class="indexterm"/> tagged as <span class="strong"><strong>quarantined</strong></span> using metadata by security monitoring tools. Put simply, metadata allows teams to set server profiles using metadata, so a variety of actions can be carried out on them.</p><p>If a server is tagged as quarantined, a trigger could be set up to power down the server and migrate it to a quarantined micro-subnet in the Overlay network with no external access. This would allow a security team to carry out root cause analysis to ascertain how the box was compromised and mitigate the attack.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note07"/>Note</h3><p>The important point to note is all these security processes can be automated to help maximize the features provided by public and private clouds. They should be looked upon as tools that can help automate and facilitate security processes rather than inhibit security.</p></div></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec58"/>Summary</h1></div></div></div><p>In this chapter, we have looked at network security and ways in which security practices need to evolve to meet the demands of modern software-defined networks, as the industry has started to move away from flat layer 2 networks and instead utilize virtualized overlay networks.</p><p>This chapter has also hopefully debunked some of the fear and uncertainty associated with securing software-defined networks, while tackling hot topics such as the separation of test and production environments and the use of virtual firewalling for micro-segmentation as opposed to physical firewalls.</p><p>The focus of the chapter then shifted to strategies that can be adopted above and beyond minimum security requirements and looked at ways to secure SDN controllers and minimize the attack vectors. This can be achieved by isolating networks, creating out of band networks for network devices, appropriate authentication, and using TLS for inter-network device communication.</p><p>The chapter has also looked at the gains brought by implementing software-defined networking, such as the transparency and auditability of application to application connectivity. It has also explored opportunities to automate compliance checks by utilizing continuous integration best practices to validate ACL policies as part of continuous integration builds, rather than being a completely separate process. It has also explored leveraging cloud metadata to carry out emergency patching as opposed to it being a manual overhead, and covered other use casesfor using cloud metadata such as quarantining servers and sending security notifications to teams.</p><p>This chapter brings us to the end of the book, which has looked at applying DevOps and Continuous Delivery principles to networking. The book has hopefully showed readers that networking does not need to be a manual set of tasks that slow down the whole Continuous Delivery process.</p><p>This book has covered a wide variety of topics that should hopefully give some food for thought and ideas that can be taken and implemented to improve network operations. Network automation is still relatively sparse in industry, but it doesn't need to be; the same automation principles that were applied to development, infrastructure, and testing are equally applicable to network operations.</p><p>Network teams shouldn't settle or accept the status quo, instead, be bold and, initiate real cultural change, and help improve network operations in the industry by embracing change and learning new skills.</p><p>More information:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Blog: <a class="ulink" href="http://devarmstrongops.blogspot.co.uk/">http://devarmstrongops.blogspot.co.uk/</a></li><li class="listitem" style="list-style-type: disc">LinkedIn: <a class="ulink" href="https://uk.linkedin.com/in/steven-armstrong-918629b1">https://uk.linkedin.com/in/steven-armstrong-918629b1</a></li><li class="listitem" style="list-style-type: disc">What is a Software-defined Network: <a class="ulink" href="https://www.youtube.com/watch?v=lPL_oQT9tmc">https://www.youtube.com/watch?v=lPL_oQT9tmc</a></li><li class="listitem" style="list-style-type: disc">SDN Fundamentals: <a class="ulink" href="https://www.youtube.com/watch?v=Np4p1CDIuzc">https://www.youtube.com/watch?v=Np4p1CDIuzc</a></li><li class="listitem" style="list-style-type: disc">SDN and OpenFlow: <a class="ulink" href="https://www.youtube.com/watch?v=l-DcbQhFAQs">https://www.youtube.com/watch?v=l-DcbQhFAQs</a></li></ul></div></div></body></html>