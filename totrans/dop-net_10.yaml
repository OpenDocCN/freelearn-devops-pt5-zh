- en: Chapter 10. The Impact of Containers on Networking
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章 容器对网络的影响
- en: No modern IT book would be complete without a chapter on containers. In this
    chapter, we will look at the history of containers and the options currently available
    to deploy them. This chapter will look at the changes required to support running
    containers from a networking perspective. We will then focus on some of the technologies
    used to package containers, and how they can be incorporated into a Continuous
    Delivery process. Finally, we will focus on some of the orchestration tools that
    are being used to deploy containers.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现代IT书籍中没有一章关于容器的内容是 incomplete 的。在这一章中，我们将回顾容器的历史以及当前可以部署容器的选项。本章将探讨从网络角度支持容器运行所需的变化。接着，我们将重点讨论用于打包容器的一些技术，以及它们如何融入持续交付流程。最后，我们将重点讨论一些用于部署容器的编排工具。
- en: 'In this chapter, the following topics will be covered:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Overview of containers
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器概述
- en: Packaging containers
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器打包
- en: Container orchestration tools
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器编排工具
- en: How containers fit into continuous integration and delivery
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器如何适应持续集成和持续交付
- en: Overview of containers
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器概述
- en: There has been a lot of hype about containers in the IT industry of late; you
    could be forgiven for thinking that containers alone will solve every application
    deployment problem possible. There have been a lot of marketing campaigns from
    vendors stating that implementing containers will make a business more agile or
    that they mean a business is implementing *DevOps* simply by deploying their applications
    in containers. This is undoubtedly the case if you listen to software vendors
    promoting their container technology or container orchestration software.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，IT行业对容器的宣传非常多；你可能会认为，仅凭容器就能解决所有应用程序部署的问题。许多供应商的营销活动声称，实施容器会让企业更加敏捷，或者仅仅通过将应用程序部署到容器中，企业就已经在实施*DevOps*。如果你听到软件供应商在推广其容器技术或容器编排软件时这样说，那这无疑是他们的观点。
- en: 'Containers are not a new concept, though. Far from it: Solaris 10 introduced
    the concept of Solaris Zones as far back as 2005, which allowed users to segregate
    the operating system into different components and run isolated processes. Modern
    technologies such as **Docker** or **Rocket** provide a container workflow that
    allows users to package and deploy containers.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，容器并不是一个新概念。远不是：Solaris 10早在2005年就引入了Solaris Zones的概念，这使得用户能够将操作系统分割为不同的组件并运行隔离的进程。现代技术如**Docker**或**Rocket**提供了一个容器工作流，允许用户打包和部署容器。
- en: However, like all infrastructure concepts, containers are simply facilitators
    of process, and implementing containers as a standalone initiative for the wrong
    reasons will likely bring no business value to a company. It seems it has become
    almost mandatory for large software vendors to have a container-based solution
    as part of their portfolio, given their recent popularity.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，像所有基础设施概念一样，容器只是流程的促进者，错误地将容器作为独立项目实施通常不会为公司带来业务价值。鉴于容器的近期流行，似乎大型软件供应商将容器解决方案作为其产品组合的一部分几乎已成必然。
- en: Containers, like all tools, can be very beneficial for certain use cases. It
    is important when considering containers to consider the benefits that they bring
    to microservice architectures. It is fair to say that containers have been seen
    by some **Platform as a Service** (**PaaS**) companies as being the bridge between
    development and operations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 容器，像所有工具一样，对于某些使用场景是非常有益的。在考虑容器时，重要的是要考虑它们对微服务架构带来的好处。可以公平地说，容器已被一些**平台即服务**（**PaaS**）公司视为开发与运维之间的桥梁。
- en: Container technologies have allowed developers to package their applications
    in containers in a consistent way, while at the same time describing the way in
    which they wish to run their microservice application in production using PaaS
    technology. This construct can be understood by development and operations staff,
    as they are both familiar with the same container technology and constructs they
    use to deploy applications. This means that the container that is deployed on
    a development workstation will behave in the same way as it would on a production
    system.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 容器技术使得开发人员能够以一致的方式将应用程序打包在容器中，同时描述他们希望如何使用PaaS技术在生产环境中运行微服务应用程序。开发和运维人员都能理解这一构建，因为他们都熟悉相同的容器技术和他们用于部署应用程序的构建方式。这意味着在开发工作站上部署的容器与在生产系统上运行时的行为是相同的。
- en: This has allowed developers to define their application topology and load balancing
    requirements more consistently, so that they are deployed identically to test
    and production environments using a common suite of tooling.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得开发人员能够更加一致地定义应用程序拓扑和负载均衡需求，以便在测试和生产环境中通过共同的工具集进行相同的部署。
- en: Famous success stories such as Netflix have shown that containerizing their
    whole microservice architecture is possible and can be a success. With the rise
    in popularity of microservice applications, a common requirement is to package
    and deploy a microservice application across multiple hybrid clouds. This gives
    organizations real choice over which private or public cloud provider they use.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 像Netflix这样的著名成功案例表明，将整个微服务架构容器化是可行的，并且能够取得成功。随着微服务应用的流行，常见的需求是将微服务应用程序打包并部署到多个混合云中。这为组织提供了选择使用哪家私有或公有云服务提供商的真实选择。
- en: In microservice architectures, cloud-native microservice applications can be
    scaled up or down quickly to deal with busy or quiet periods for a business. When
    using a public cloud, it is desirable to only utilize what is required, which
    can often mean that microservices can be scaled up and scaled down throughout
    the day to save running costs.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在微服务架构中，云原生微服务应用可以根据业务的繁忙或安静时段快速扩展或缩减。当使用公有云时，理想的做法是只利用所需的资源，这通常意味着微服务可以在一天中随时扩展或缩减，以节省运行成本。
- en: Elastic scaling based on utilization is a common use case when deploying cloud-native
    microservices so that microservices can scale up and down based on reading data
    from their monitoring systems or from the cloud provider.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 基于利用率的弹性扩展是部署云原生微服务时的常见用例，这样微服务可以根据其监控系统或云服务提供商提供的数据进行动态扩展或缩减。
- en: Microservices have followed the lead of service-oriented architectures and can
    be seen as the modern implementation of this concept of **service-oriented architectures**
    (**SOA**). Microservices such as SOA allow multiple different components to communicate
    via a network of services and common set of protocols. Microservices aim to decouple
    services from one another into specific functions, so they can be tested in isolation
    and joined together to create the overall system and, as illustrated, scaled up
    or down as required.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务沿袭了面向服务架构（**SOA**）的理念，并且可以被视为这一理念的现代实现。像SOA这样的微服务允许多个不同的组件通过服务网络和通用协议集进行通信。微服务旨在将服务解耦成具体的功能，使其可以单独进行测试，并将它们组合起来以创建整体系统，并且如所示，根据需求进行扩展或缩减。
- en: When using microservice architectures, instead of having to deploy the whole
    system each time, different component versions can be deployed independently of
    each other without causing system downtime.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用微服务架构时，不需要每次都部署整个系统，不同的组件版本可以独立部署，而不会导致系统停机。
- en: Containers in some ways can be seen as the perfect solution for microservice
    applications as they can be used to carry out specific functions in isolation.
    Each microservice application can be deployed within the constructs of an individual
    container and networked together to provide an overall service to the end user.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 从某种程度上看，容器可以被视为微服务应用程序的完美解决方案，因为它们可以用来独立执行特定功能。每个微服务应用可以在单独的容器构建中部署，并通过网络连接在一起，以便为最终用户提供整体服务。
- en: 'Containers already natively run on any Linux operating system and are lightweight
    by nature, meaning they can be deployed, maintained, and updated easily when utilizing
    popular container technology such as:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 容器本身已经原生支持在任何 Linux 操作系统上运行，并且具有轻量级的特点，这意味着在使用流行的容器技术时，如下所示，它们可以轻松部署、维护和更新：
- en: Docker ([https://www.docker.com/](https://www.docker.com/))
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker ([https://www.docker.com/](https://www.docker.com/))
- en: Google Kubernetes ([http://kubernetes.io/](http://kubernetes.io/))
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Kubernetes ([http://kubernetes.io/](http://kubernetes.io/))
- en: Apache Mesos ([http://mesos.apache.org/](http://mesos.apache.org/))
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Mesos ([http://mesos.apache.org/](http://mesos.apache.org/))
- en: IBM Bluemix ([http://www.ibm.com/cloud-computing/bluemix/containers/](http://www.ibm.com/cloud-computing/bluemix/containers/))
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IBM Bluemix ([http://www.ibm.com/cloud-computing/bluemix/containers/](http://www.ibm.com/cloud-computing/bluemix/containers/))
- en: Rackspace Catrina ([http://thenewstack.io/rackspace-carina-bare-metal-caas-based-openstack/](http://thenewstack.io/rackspace-carina-bare-metal-caas-based-openstack/))
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rackspace Catrina ([http://thenewstack.io/rackspace-carina-bare-metal-caas-based-openstack/](http://thenewstack.io/rackspace-carina-bare-metal-caas-based-openstack/))
- en: CoreOS Rocket ([https://coreos.com/blog/rocket/](https://coreos.com/blog/rocket/))
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoreOS Rocket ([https://coreos.com/blog/rocket/](https://coreos.com/blog/rocket/))
- en: Oracle Solaris Zones ([https://docs.oracle.com/cd/E18440_01/doc.111/e18415/chapter_zones.htm#OPCUG426](https://docs.oracle.com/cd/E18440_01/doc.111/e18415/chapter_zones.htm#OPCUG426))
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oracle Solaris Zones ([https://docs.oracle.com/cd/E18440_01/doc.111/e18415/chapter_zones.htm#OPCUG426](https://docs.oracle.com/cd/E18440_01/doc.111/e18415/chapter_zones.htm#OPCUG426))
- en: Microsoft Azure Nano Server ([https://technet.microsoft.com/en-us/windows-server-docs/get-started/getting-started-with-nano-server](https://technet.microsoft.com/en-us/windows-server-docs/get-started/getting-started-with-nano-server))
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Microsoft Azure Nano Server ([https://technet.microsoft.com/en-us/windows-server-docs/get-started/getting-started-with-nano-server](https://technet.microsoft.com/en-us/windows-server-docs/get-started/getting-started-with-nano-server))
- en: VMware Photon ([http://blogs.vmware.com/cloudnative/introducing-photon/](http://blogs.vmware.com/cloudnative/introducing-photon/))
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VMware Photon ([http://blogs.vmware.com/cloudnative/introducing-photon/](http://blogs.vmware.com/cloudnative/introducing-photon/))
- en: '**Containerization** in essence is virtualizing processes on the operating
    system and isolating them from one another into manageable components. Container
    orchestration technologies then create network interfaces to allow multiple containers
    to be connected to each other across the operating systems, or in more complex
    scenarios, create full overlay networks to connect containers running on multiple
    physical or virtual servers using programmatic APIs and key-value stores for service
    discovery.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**容器化** 本质上是在操作系统上虚拟化进程，并将它们相互隔离成可管理的组件。容器编排技术随后创建网络接口，使多个容器能够跨操作系统相互连接，或者在更复杂的场景中，创建完整的覆盖网络，利用程序化
    API 和键值存储进行服务发现，以连接运行在多个物理或虚拟服务器上的容器。'
- en: Solaris Zones
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Solaris Zones
- en: In 2005, Solaris introduced the notion of **Solaris Zones**, and from it came
    the concept of containment. After a user logged in to a fresh Solaris operating
    system, they would find themselves in a global Solaris Zone.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 2005 年，Solaris 引入了 **Solaris Zones** 的概念，并由此产生了容器化的概念。在用户登录到全新的 Solaris 操作系统后，他们会发现自己处于一个全局的
    Solaris 区域中。
- en: Solaris then gave users the option to create new zones, configure them, install
    the packages to run them, and finally, boot them so they could be used. This allowed
    each isolated zone to be used as a contained segment within the confines of a
    single Solaris operating system.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Solaris 随后为用户提供了创建新区域、配置它们、安装运行它们的包，并最终启动它们以便使用的选项。这使得每个隔离的区域能够作为单一 Solaris
    操作系统内的独立部分使用。
- en: Solaris allowed zones to run as a completely isolated set of processes, all
    from the default global zone in terms of permissions, disk, and network configuration.
    Different persistent storage or raw devices could be exported to the zones and
    mounted to make external file systems accessible to a zone. This meant that multiple
    different applications could run within their own unique zone and communicate
    with external shared storage.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Solaris 允许区域作为完全隔离的一组进程运行，这些进程在权限、磁盘和网络配置方面都来自默认的全局区域。不同的持久存储或原始设备可以被导出到区域并挂载，以使外部文件系统对区域可访问。这意味着多个不同的应用程序可以在各自独立的区域内运行，并与外部共享存储进行通信。
- en: 'In terms of networking, the global Solaris Zone would have an IP address and
    be connected to the default router. All new zones would have their own unique
    IP address on the same subnet using the same default router. Each zone could even
    have their own unique DNS entry if required. The networking setup for Solaris
    Zones is shown in the following figure, with two zones connected to the router
    by accessing the network configuration on the `/zones` file system:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络方面，全球Solaris Zone将具有一个IP地址，并连接到默认路由器。所有新区域将具有相同子网内的唯一IP地址，并使用相同的默认路由器。如果需要，每个区域甚至可以有自己独特的DNS条目。Solaris
    Zones的网络配置如图所示，通过访问`/zones`文件系统上的网络配置，两个区域连接到路由器：
- en: '![Solaris Zones](img/B05559_10_01.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![Solaris Zones](img/B05559_10_01.jpg)'
- en: .
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: Linux namespaces
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Linux命名空间
- en: A **Linux namespace** creates an abstraction layer for a system process and
    changes to that system process only affect other processes in the same namespace.
    Linux namespaces can be used to isolate processes on the Linux operating system;
    by default, when a Linux operating system is booted, all resources run under the
    default namespace so have the ability to view all the processes that are running.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**Linux命名空间**为系统进程创建了一个抽象层，对该进程的更改仅会影响同一命名空间中的其他进程。Linux命名空间可用于隔离Linux操作系统上的进程；默认情况下，当Linux操作系统启动时，所有资源都运行在默认命名空间下，因此能够查看所有正在运行的进程。'
- en: 'The namespace API has the following system calls:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间API包含以下系统调用：
- en: '`clone`'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clone`'
- en: '`setns`'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setns`'
- en: '`unshare`'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unshare`'
- en: The `clone` system call creates a new process and links all specified processes
    to it; the `setns` system call, on the other hand, is used to join namespaces
    together, and the `unshare` system call moves a process out of a namespace to
    a new namespace.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`clone`系统调用创建一个新进程，并将所有指定的进程与之关联；而`setns`系统调用用于将命名空间连接在一起，`unshare`系统调用则将进程从一个命名空间移出并移至新的命名空间。'
- en: 'The following namespaces are available on Linux:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是Linux上可用的命名空间：
- en: Mounts
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挂载
- en: Process ID
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程ID
- en: Interprocess communication
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程间通信
- en: UTS
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UTS
- en: Network
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络
- en: User
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户
- en: The mounts namespace is used to isolate the Linux operating system's file system
    so specific mount points are only seen by a certain group of processes belonging
    to the same namespace. This allows different processes to have access to different
    mount points, depending on what namespace they are part of, which can be used
    to secure specific files.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: mounts命名空间用于隔离Linux操作系统的文件系统，使得特定的挂载点仅对属于同一命名空间的进程组可见。这使得不同的进程可以根据其所属的命名空间访问不同的挂载点，从而可以用于保护特定的文件。
- en: The **Process ID** (**PID**) namespace allows the reuse of PID processes on
    a Linux machine as each set of PIDs is unique to a namespace. This allows containers
    to be migrated between hosts while keeping the same PIDs, so the operation does
    not interrupt the container. This also allows each container to have its own unique
    `init` process and makes containers extremely portable.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**进程ID**（**PID**）命名空间允许在Linux机器上重用PID进程，因为每组PID都是唯一的，并且属于特定命名空间。这允许容器在主机之间迁移，同时保持相同的PID，从而确保操作不会中断容器。这也允许每个容器拥有独特的`init`进程，并使容器具有极高的可移植性。'
- en: The **interprocess communication** (**IPC**) namespace is used to isolate certain
    specific resources, such as system objects and message queues between processes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**进程间通信**（**IPC**）命名空间用于隔离特定的资源，如进程之间的系统对象和消息队列。'
- en: The UTS namespace allows containers to have their own domain and host name;
    this is very useful when using containers, as orchestration scripts can target
    specific host names as opposed to IPs.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: UTS命名空间允许容器拥有自己的域名和主机名；这在使用容器时非常有用，因为编排脚本可以针对特定的主机名，而不是IP进行操作。
- en: The network namespace creates a layer of isolation around network resources
    such as the IP space, IP tables, and routing tables. This means that each container
    can have its own unique networking rules.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 网络命名空间在网络资源（如IP空间、IP表和路由表）周围创建了一个隔离层。这意味着每个容器可以有其独特的网络规则。
- en: The user namespace is used to manage user permissions to namespaces.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 用户命名空间用于管理用户对命名空间的权限。
- en: So, from a networking perspective, namespaces allow multiple different routing
    tables to coexist on the same Linux operating system, as they have complete process
    isolation. This means each container can have its own unique networking rules
    applied if desired.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从网络角度来看，命名空间允许多个不同的路由表在同一Linux操作系统上共存，因为它们具有完全的进程隔离。这意味着每个容器可以根据需要应用其独特的网络规则。
- en: Linux control groups
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Linux控制组
- en: 'The use of **control groups** (**cgroups**) allows users to control Linux operating
    system resources that are part of a namespace. The following cgroups can be used
    to control Linux resources:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**控制组**（**cgroups**）的使用使用户能够控制属于命名空间的一部分的 Linux 操作系统资源。以下控制组可用于控制 Linux 资源：'
- en: CPU
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU
- en: Memory
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存
- en: Freezer
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冰冻
- en: Block I/O
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 块 I/O
- en: Devices
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设备
- en: 'The CPU cgroup can use two different types of scheduler: either the **Completely
    Fair Scheduler** (**CFS**), which is based on distributing CPU based on a weighting
    system. The **Real-Time Scheduler** (**RTS**) is the other alternative, and is
    a task scheduler that caps tasks based on their real-time utilization.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: CPU 控制组可以使用两种不同类型的调度器：一种是**完全公平调度器**（**CFS**），基于加权系统分配 CPU。另一种是**实时调度器**（**RTS**），它是一种任务调度器，根据任务的实时使用情况来限制任务的执行。
- en: The memory cgroup is used to generate reports on memory utilization used by
    the tasks in a cgroup. It sets limits on the memory use of processes associated
    with the cgroup can use.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 内存控制组用于生成与控制组中的任务相关的内存利用率报告。它对与控制组相关的进程的内存使用设置限制。
- en: The freezer cgroup is used to control the process status of all processes associated
    with the freezer cgroup. The freezer cgroup can be used to control batches of
    jobs and issue the `FREEZE` command, which will stop all processes in the user
    space; the `THAW` command can be used to restart them again.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 冰冻控制组（freezer cgroup）用于控制与冰冻控制组相关的所有进程的状态。冰冻控制组可用于控制一批任务并发出`FREEZE`命令，这将停止用户空间中的所有进程；`THAW`命令则可以用来重新启动这些进程。
- en: The **Block I/O** (**blkio**) cgroup monitors access to I/O on block devices
    and introduces limits on I/O bandwidth or access to resources. Blkio uses an I/O
    scheduler and can assign weights to distribute I/O or provide I/O throttling by
    setting maximum limits to throttle the amount of read or writes that a process
    can do on a device.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**块 I/O**（**blkio**）控制组监控对块设备的 I/O 访问，并对 I/O 带宽或对资源的访问引入限制。Blkio 使用 I/O 调度程序，并可以分配权重来分配
    I/O，或通过设置最大限制来对进程在设备上读取或写入的数量进行限制，从而实现 I/O 限速。'
- en: The devices' cgroup allows or denies access to devices by defining tasks under
    `devices.allow` and `devices.deny`, and can list device access using `devices.list`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 设备控制组通过在`devices.allow`和`devices.deny`下定义任务来允许或拒绝访问设备，并可以通过`devices.list`列出设备访问。
- en: Benefits of containers
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器的好处
- en: Containers have many benefits, with a focus on portability, agility, security,
    and as touched upon earlier in this chapter, have helped many organizations such
    as Netflix deploy their microservice architectures.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 容器具有许多优势，特别是在可移植性、敏捷性、安全性方面，正如本章前面所提到的，它们帮助了许多组织（如 Netflix）部署微服务架构。
- en: Containers also allow users to allocate different resources on an operating
    system using namespaces and limit CPU, memory, network block I/O, and network
    bandwidth using cgroups.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 容器还允许用户通过使用命名空间在操作系统上分配不同的资源，并通过控制组限制 CPU、内存、网络块 I/O 和网络带宽。
- en: Containers are very quick to provision so can be scaled up and scaled down rapidly
    to allow elastic scaling in cloud environments. They can be scaled up rapidly
    to meet demand and containers can be migrated from one server to another using
    numerous techniques.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 容器的配置非常快速，因此可以迅速进行横向扩展和缩减，以支持云环境中的弹性扩展。它们可以迅速扩大以满足需求，并且容器可以通过多种技术从一台服务器迁移到另一台服务器。
- en: Cgroups can be configured quickly based on system changes, which gives users
    complete control over the low-level scheduling features of an operating system,
    which are normally delegated to the base operating system when using virtual machines
    or bare-metal servers. Containers can be tweaked to give greater fine-grained
    control over performance.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 控制组可以根据系统的变化迅速进行配置，赋予用户对操作系统低级调度特性的完全控制，而这些通常是在使用虚拟机或裸金属服务器时交由基础操作系统来处理的。容器可以进行微调，以提供对性能的更精细控制。
- en: In some scenarios, not all resources on a bare-metal server will be utilized,
    which can be wasteful, so containers can be utilized to use all of the CPU and
    RAM available on a guest operating system by running multiple instances of the
    same application isolated by namespaces at a kernel level. This means that to
    each process, they appear to be functioning on their own unique operating system.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些场景下，裸金属服务器上的所有资源并不会被充分利用，这可能会导致浪费，因此可以通过容器来利用客户操作系统上所有的 CPU 和内存，方法是在内核级别通过命名空间隔离运行多个相同应用程序的实例。这意味着对于每个进程，它们看起来像是在自己独特的操作系统上运行。
- en: One of the main drawbacks with containers up until now has been that they have
    been notoriously low-level and hard to manage at scale. So, tooling such as for
    large implementation, and orchestration engines such as Docker Swarm, Google Kubernetes,
    and Apache Mesos alleviate that pain by creating abstraction layers to manage
    containers at scale.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，容器的主要缺点之一是它们通常是低级别的，并且在大规模管理时非常困难。因此，像大规模实施和协调引擎（例如 Docker Swarm、Google
    Kubernetes 和 Apache Mesos）等工具通过创建抽象层来管理容器，从而减轻了这种痛苦。
- en: Another benefit of containers is that they are very secure as they limit the
    attack surface area with additional layers of security added to the operating
    system through the use of different namespaces. If an operating system was compromised,
    an attacker would still need to compromise the system at the namespace level as
    opposed to having access to all processes.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 容器的另一个好处是它们非常安全，因为它们通过使用不同的命名空间，限制了攻击面，并为操作系统增加了额外的安全层。如果操作系统被攻击，攻击者仍然需要在命名空间级别攻破系统，而不是直接访问所有进程。
- en: Containers can be very useful when running multiple flavors of the same process;
    an example is a business that wants to run multiple versions of the same application
    for different customers. They want to prevent a spike in logins and transactions
    from one customer affecting another at the application level. Containers in this
    scenario would be a feasible solution.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行多个相同进程的不同版本时，容器非常有用；例如，一个企业希望为不同的客户运行同一个应用程序的多个版本。他们希望防止一个客户的登录和交易激增影响到其他客户的应用层。容器在这种情况下是一个可行的解决方案。
- en: Deploying containers
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署容器
- en: With the growing popularity of containers, traditional Linux distributions have
    been found to be sub-optimal and clunky when running a pure container platform.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 随着容器的日益流行，传统的 Linux 发行版在运行纯容器平台时被发现表现不佳且笨重。
- en: As a result, very minimal operating systems have been created to host containers,
    such as CoreOS and Red Hat Atomic, which have been developed specifically to run
    containers.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，已经创建了非常精简的操作系统来托管容器，例如 CoreOS 和 Red Hat Atomic，这些操作系统专门设计用于运行容器。
- en: Sharing information across operating systems is also a challenge for containers,
    as by design they are isolated by namespaces and cgroups to a particular host
    operating system. Key-value stores such as **etcd**, **Consul**, and **Zookeeper**
    can be used to cluster and cluster and share information across hosts.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在操作系统之间共享信息对于容器来说也是一个挑战，因为按照设计，它们通过命名空间（namespaces）和控制组（cgroups）被隔离到特定的主机操作系统上。**etcd**、**Consul**
    和 **Zookeeper** 等键值存储可以用于跨主机群集和共享信息。
- en: CoreOS
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CoreOS
- en: '**CoreOS** is a Linux-based operating system specifically created to provide
    a minimal operating system to run clusters of containers. It is the widest-used
    container operating system today and designed to run at massive scale without
    the need to frequently patch and update the software on the operating system manually.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**CoreOS** 是一个基于 Linux 的操作系统，专门设计用于提供一个最小化的操作系统来运行容器集群。它是目前最广泛使用的容器操作系统，旨在以大规模运行而无需频繁手动修补和更新操作系统上的软件。'
- en: Any application that runs on CoreOS will run in container format; CoreOS can
    run on bare-metal or virtual machines, on public and private clouds such as AWS
    and OpenStack.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 任何在 CoreOS 上运行的应用程序都将以容器格式运行；CoreOS 可以在裸机或虚拟机上运行，支持 AWS 和 OpenStack 等公共和私有云。
- en: CoreOS works by automatically pulling frequent security updates without affecting
    the containers running on the operating system. This means CoreOS doesn't need
    Linux admins to intervene and patch servers, as CoreOS automatically takes care
    of this by patching using its zero downtime security updates.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 通过自动拉取频繁的安全更新而不影响操作系统上运行的容器来工作。这意味着 CoreOS 不需要 Linux 管理员干预和修补服务器，因为 CoreOS
    会通过零停机安全更新自动处理这些修补。
- en: CoreOS focuses on moving application dependencies out of the application and
    into the container layer, so containers are dependent on other containers for
    their dependency management.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 通过将应用程序依赖性从应用程序中剥离并转移到容器层来工作，因此容器依赖于其他容器来进行依赖管理。
- en: etcd
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: etcd
- en: CoreOS uses etcd, which is a distributed key-value store that allows multiple
    containers across multiple machines to connect to it for data and state.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 使用 etcd，这是一种分布式键值存储，允许跨多台机器的多个容器连接到它，以获取数据和状态信息。
- en: Etcd uses the **Raft algorithm** to elect a leader and uses followers to maintain
    consistency. When multiple etcd hosts are running, the state is pulled from the
    instance with the majority and propagated to the followers, so it is used to keep
    clusters consistent and up to date.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Etcd 使用**Raft 算法**来选举领导者，并通过跟随者来保持一致性。当多个 etcd 主机运行时，状态从大多数实例中拉取并传播到跟随者，因此它用于保持集群的一致性和实时更新。
- en: Applications can read and write data into etcd and it is designed to deal with
    fault and failure conditions. Etcd can be used to store connection strings to
    endpoints or other environment-specific data stores.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序可以读取和写入数据到 etcd，并且它被设计用来处理故障和故障条件。Etcd 可以用来存储到端点的连接字符串或其他特定环境的数据存储。
- en: Docker
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker
- en: It would be impossible to talk about containers without mentioning Docker. In
    2013, Docker was released as an open-source initiative that could be used to package
    and distribute containers. Docker was originally based on Linux LXC containers,
    but the Docker project has since drifted away from that standard as it has become
    more opinionated and mature.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不提到 Docker，谈容器将是不可能的。2013 年，Docker 作为一个开源项目发布，可以用来打包和分发容器。Docker 最初是基于 Linux
    LXC 容器的，但随着项目的发展，它已经逐渐脱离了这一标准，并变得更加有主张和成熟。
- en: Docker works on the principle of isolating a single process per container in
    the Linux kernel. Docker uses a union-capable file system, cgroups, and kernel
    namespaces to run containers and isolate processes. It has a command-line interface
    and a well thought out workflow.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 基于在 Linux 内核中将每个容器进程隔离的原则工作。Docker 使用支持联合的文件系统、cgroups 和内核命名空间来运行容器并隔离进程。它具有命令行界面和经过深思熟虑的工作流。
- en: Docker registry
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker 镜像仓库
- en: When container images are packaged, they need to be pushed to Docker's container
    registry server, which is an image repository for containers.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当容器镜像被打包时，它们需要被推送到 Docker 的容器镜像仓库服务器，这是一个容器的镜像存储库。
- en: The **Docker registry** is used to store containers, which can be tagged and
    versioned much like a package repository. This allows different container versions
    to be stored for roll-forward and roll-back purposes.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**Docker 镜像仓库**用于存储容器，容器可以像软件包仓库一样进行标记和版本管理。这允许存储不同版本的容器，以便进行向前滚动和回滚。'
- en: By default, the Docker registry is a file-system volume and persists data on
    a local file system. Artifact repositories such as Artifactory and Nexus now support
    Docker registry as a repository type. The Docker registry can be set up with authentication
    and SSL certificates to secure container images.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Docker 镜像仓库是一个文件系统卷，并在本地文件系统上持久化数据。像 Artifactory 和 Nexus 这样的工件仓库现在也支持
    Docker 镜像仓库作为一种仓库类型。Docker 镜像仓库可以通过身份验证和 SSL 证书来确保容器镜像的安全。
- en: Docker daemon
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker 守护进程
- en: During installation, Docker deploys a daemon on the target operating system
    that has been chosen to run containers. The **Docker daemon** is used to communicate
    with the Docker image registry and issue pull commands to pull down the latest
    container images or a specific tagged version. The Docker command line can then
    be used to schedule the start-up of the containers using the container image that
    has been pulled from the registry. Docker daemons, by default, run as a constant
    process on target operating systems, but can be started or stopped using a process
    manager such as `systemd`.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装过程中，Docker 会在目标操作系统上部署一个守护进程，用来运行容器。**Docker 守护进程**用于与 Docker 镜像仓库通信，并发出拉取命令以拉取最新的容器镜像或特定标签版本。然后，Docker
    命令行可以用来调度启动容器，使用从仓库中拉取的容器镜像。默认情况下，Docker 守护进程会作为常驻进程运行在目标操作系统上，但可以通过 `systemd`
    等进程管理器来启动或停止。
- en: Packaging containers
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 打包容器
- en: Containers can be packaged in various different ways; two of the most popular
    ways of packaging containers is using Dockerfiles, and one of the lesser known
    ways is using a tool from **HashiCorp** called Packer. Both have slightly different
    approaches to packaging container images.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 容器可以以多种方式打包；其中两种最常见的打包方式是使用 Dockerfile，另外一种较少为人所知的方式是使用 **HashiCorp** 提供的工具
    Packer。这两者在打包容器镜像时有略微不同的方法。
- en: Dockerfile
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Dockerfile
- en: Docker allows users to package containers using its very own configuration-management
    tool called **Dockerfile**. Dockerfile will state the intent of the container
    by outlining the packages that should be installed on it using package managers
    at build time.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 允许用户使用其自有的配置管理工具 **Dockerfile** 来打包容器。Dockerfile 会通过列出在构建时使用包管理器安装的包来说明容器的意图。
- en: 'The following Dockerfile shows NGINX being installed on CentOS by issuing `yum`
    `install` commands and exposing port `80` to the guest operating system from the
    packaged container. Port `80` is exposed so NGINX can be accessed externally:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 以下Dockerfile展示了通过执行`yum` `install`命令在CentOS上安装NGINX，并将端口`80`暴露给来自打包容器的客户操作系统。暴露端口`80`是为了让NGINX能够外部访问：
- en: '![Dockerfile](img/B05559_10_02.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![Dockerfile](img/B05559_10_02.jpg)'
- en: 'Once the Dockerfile has been created, Docker''s command-line interface allows
    users to issue the following command to build a container:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了Dockerfile，Docker的命令行界面允许用户发出以下命令来构建容器：
- en: '[PRE0]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The one downside is that applications are typically installed using configuration
    management tools such as Puppet, Chef, Ansible, and Salt. The Dockerfile is very
    brittle, which means that packaging scripts need to be completely re-written.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的缺点是，应用程序通常使用配置管理工具，如Puppet、Chef、Ansible和Salt来安装。Dockerfile非常脆弱，这意味着打包脚本需要完全重写。
- en: Packer-Docker integration
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Packer-Docker集成
- en: '**Packer** from HashiCorp is a command-line tool which uses multiple drivers
    to package virtual machine images and also supports creating Docker image files.
    Packer can be used to package **Amazon Machine Image** (**AMI**) images for AWS
    or **QEMU Copy On Write** (**QCOW**) images, which can be uploaded to OpenStack
    Glance.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**Packer** 是HashiCorp的一个命令行工具，使用多个驱动程序来打包虚拟机镜像，也支持创建Docker镜像文件。Packer可用于打包**Amazon
    Machine Image**（**AMI**）镜像，用于AWS，或**QEMU Copy On Write**（**QCOW**）镜像，这些镜像可以上传到OpenStack
    Glance。'
- en: When utilizing Packer, it skips the need for using Dockerfiles to create Docker
    images; instead, existing configuration-management tools such as Puppet, Chef,
    Ansible, and Salt can be used to provision and package Docker container images.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Packer时，省去了使用Dockerfile来创建Docker镜像的需求；相反，可以使用现有的配置管理工具，如Puppet、Chef、Ansible和Salt，来配置和打包Docker容器镜像。
- en: 'Packer has the following high-level architecture and uses a JSON file to describe
    the Packer workflow, with three main parts:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Packer具有以下高级架构，并使用一个JSON文件来描述Packer工作流，主要分为三部分：
- en: Builders
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建器
- en: Provisioners
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置管理工具
- en: Post-processors
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后处理器
- en: '**Builders** are used to boot an ISO, virtual machine on a Cloud platform,
    or in this case, start a Docker container from an image file on a build server.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**构建器**用于启动一个ISO、虚拟机在云平台上，或者在此情况下，从构建服务器上的镜像文件启动一个Docker容器。'
- en: Once booted, the configuration management **provisioner** will run a set of
    installation steps. This will create the desired state for the image, emulating
    what the Dockerfile would carry out. Once complete, the image will be stopped
    and packaged.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦启动，配置管理**配置器**将运行一组安装步骤。这将创建镜像所需的状态，模拟Dockerfile将执行的操作。完成后，镜像将停止并被打包。
- en: A set of **post-processors** will then be executed to push the image to an artifact
    repository or Docker registry, where it is tagged and versioned.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 一组**后处理器**将被执行，将镜像推送到一个工件库或Docker注册表，在那里它会被标记并版本化。
- en: Using Packer means existing configuration management tools can be used to package
    virtual machines and containers in the same way rather than using a completely
    different configuration-management mechanism for containers. The Docker daemon
    will need to be installed as a prerequisite on the build server that is being
    used to package the container.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Packer意味着可以使用现有的配置管理工具来打包虚拟机和容器，而不是为容器使用完全不同的配置管理机制。Docker守护进程需要作为前提条件安装在用于打包容器的构建服务器上。
- en: In the following example, an `nginx.json` Packer file is created; the `builders`
    section has the type `docker` defined, which lets Packer know to use the Docker
    builder.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，创建了一个`nginx.json` Packer文件；`builders`部分定义了类型为`docker`，这让Packer知道使用Docker构建器。
- en: The `export_path` is where the final Docker image will be exported to and `image`
    is the name of the Docker image file that will be pulled from the Docker registry
    and started.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '`export_path`是最终Docker镜像导出的位置，`image`是将从Docker注册表中拉取并启动的Docker镜像文件的名称。'
- en: One provisioner of the `ansible-local` type will then execute the `install_nginx.yml`
    playbook to install NGINX on the Docker image, using an Ansible playbook as opposed
    to the Dockerfile.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`ansible-local`类型的配置管理器将执行`install_nginx.yml`剧本，以便使用Ansible剧本而不是Dockerfile来安装NGINX到Docker镜像中。
- en: 'Finally, the post-processors will then import the packed image, complete with
    NGINX installed, into the Docker registry with the tag `1.1`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，后处理器将把打包的镜像（包含安装的NGINX）导入到Docker注册表，并使用标签`1.1`：
- en: '![Packer-Docker integration](img/B05559_10_03.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![Packer-Docker 集成](img/B05559_10_03.jpg)'
- en: 'To execute the Packer build, simply execute the following command passing the
    `nginx.json` file:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行 Packer 构建，只需执行以下命令并传入 `nginx.json` 文件：
- en: '[PRE1]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Docker workflow
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker 工作流
- en: The **Docker workflow** fits nicely into the continuous integration process
    that we covered as part of [Chapter 7](ch07.html "Chapter 7. Using Continuous
    Integration Builds for Network Configuration"), *Using Continuous Integration
    Builds for Network Configuration* and the Continuous Delivery workflow we covered
    in [Chapter 9](ch09.html "Chapter 9. Using Continuous Delivery Pipelines to Deploy
    Network Changes"), *Using Continuous Delivery Pipelines to Deploy Network Changes*.
    After a developer pushes a new code commit, compiling and potentially packaging
    new code, the continuous integration process can be extended to execute a Dockerfile
    to package a new Docker image as a post-deployment step.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**Docker 工作流** 很好地融入了我们在 [第 7 章](ch07.html "第 7 章. 使用持续集成构建进行网络配置") 中讲解的持续集成过程，*使用持续集成构建进行网络配置*，以及我们在
    [第 9 章](ch09.html "第 9 章. 使用持续交付流水线部署网络变更") 中讲解的持续交付工作流，*使用持续交付流水线部署网络变更*。在开发人员推送新的代码提交后，编译并可能打包新的代码，持续集成过程可以扩展为执行
    Dockerfile，以作为部署后的步骤打包新的 Docker 镜像。'
- en: A Docker daemon is configured on each downstream test environment and production
    as part of the base operating system. At deployment time, the Docker daemon is
    scheduled to pull down the newly packaged Docker image and create a new set of
    containers doing a rolling update.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 每个下游测试环境和生产环境都配置了 Docker 守护进程，作为基础操作系统的一部分。在部署时，Docker 守护进程会被调度拉取新打包的 Docker
    镜像并创建一组新的容器进行滚动更新。
- en: 'This process flow can be seen as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 该流程图可以如下所示：
- en: '![Docker workflow](img/B05559_10_04.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![Docker 工作流](img/B05559_10_04.jpg)'
- en: Default Docker networking
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 默认 Docker 网络
- en: 'In terms of networking, when Docker is installed, it creates three default
    networks; the networks created are the `bridge`, `none`, and `host` networks,
    as shown in the following screenshot:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络方面，当安装 Docker 时，它会创建三个默认网络；创建的网络是 `bridge`、`none` 和 `host` 网络，如下图所示：
- en: '![Default Docker networking](img/B05559_10_05.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![默认 Docker 网络](img/B05559_10_05.jpg)'
- en: The Docker daemon creates containers against the bridge (`docker0`) network
    by default; this occurs when a `docker create` and `docker start` are issued on
    the target operating system, or alternatively, just a `docker run` command can
    be issued. These commands will create and start new containers on the host operating
    system from the defined Docker image.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 守护进程默认情况下使用桥接（`docker0`）网络来创建容器；当在目标操作系统上执行 `docker create` 和 `docker
    start` 命令时，或者可以只执行 `docker run` 命令。这些命令将根据定义的 Docker 镜像在主机操作系统上创建并启动新的容器。
- en: The `none` network is used to create a container-specific network, which allows
    containers to be launched and left to run; it doesn't have a network interface,
    though. The `host` network adds containers to the same network as the guest operating
    system.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`none` 网络用于创建特定于容器的网络，这允许容器启动并持续运行；但是它没有网络接口。`host` 网络将容器添加到与客户操作系统相同的网络中。'
- en: 'When containers are launched on it, Docker''s bridge network assigns each container
    a unique IP address on the bridge network''s subnet range. The containers can
    be viewed by issuing the following `docker network inspect` command:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当容器在其上启动时，Docker 的桥接网络会为每个容器分配一个在桥接网络子网范围内唯一的 IP 地址。可以通过执行以下 `docker network
    inspect` 命令查看容器：
- en: '[PRE2]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Docker allows users to inspect container configuration by using the `docker
    attach` command; in this instance, the `nginx` container can be inspected:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 允许用户通过 `docker attach` 命令检查容器配置；在这种情况下，可以检查 `nginx` 容器：
- en: '[PRE3]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Once attached, the `/etc/hosts` file can be inspected to show the network configuration.
    Docker bridge uses a NAT network and can use port forwarding using the following
    `–p` command-line argument. For example, `-p 8080:8080` forwards port `8080` from
    the host to the container. This allows all containers that are running on an operating
    system to be accessed directly by the localhost by their IPs, using port forwarding.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦连接，可以检查 `/etc/hosts` 文件以查看网络配置。Docker 桥接使用 NAT 网络，并且可以使用以下 `–p` 命令行参数进行端口转发。例如，`-p
    8080:8080` 将主机的端口 `8080` 转发到容器的端口 `8080`。这使得所有在操作系统上运行的容器都可以通过它们的 IP 地址直接通过 localhost
    访问，使用端口转发。
- en: In its default networking mode, Docker allows containers to be interconnected
    using a `--links` command-line argument, which is used to connect containers,
    which writes entries into the `/etc/hosts` file of containers.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在其默认网络模式下，Docker允许使用`--links`命令行参数将容器互联，该参数用于连接容器，写入容器的`/etc/hosts`文件。
- en: The default network setup is now not recommended for use, and more sophisticated
    networking is present, but the concepts it covers are still important.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在不建议使用默认的网络设置，而是有更复杂的网络配置，但它覆盖的概念仍然很重要。
- en: Docker allows user-defined networks to be defined to host containers, using
    network drivers to create custom networks such as custom `bridge`, `overlay`,
    or layer 2 `MACVlLAN` network.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Docker允许定义用户定义网络来托管容器，使用网络驱动程序创建自定义网络，如自定义`bridge`、`overlay`或层2`MACVlLAN`网络。
- en: Docker user-defined bridge network
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker用户定义的桥接网络
- en: A user-defined bridge network is much like the default Docker network, but it
    means that each container can talk to each of the other containers on the same
    bridge network; there is no need for linking as with the default Docker networking.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 用户定义的桥接网络与默认的Docker网络非常相似，但意味着每个容器可以在同一桥接网络上与其他容器通信；与默认的Docker网络不同，无需链接。
- en: 'To place containers on a user-defined network, containers can be launched on
    the `devops_for_networking_bridge` user-defined bridge network using the following
    command, with the `–net` option set:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 要将容器放置在用户定义的网络上，可以使用以下命令在`devops_for_networking_bridge`用户定义的桥接网络上启动容器，并设置`--net`选项：
- en: '[PRE4]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Each container that is launched will reside on the same operating system guest.
    Publish is used to expose specific using of the `-p 8080-8081:8080/tcp` command.
    Therefore, ranges can be published so that portions of the network can be exposed.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 每个启动的容器将驻留在同一操作系统客户机上。`Publish`用于暴露特定使用`-p 8080-8081:8080/tcp`命令的。因此，可以发布范围以便暴露网络的部分。
- en: Docker Swarm
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker Swarm
- en: Overlay networks, can also be used with Docker and have already been covered
    at length in this book, are a virtualized abstraction layer for the network. Docker
    can create an overlay network for containers, which is used to create a network
    of containers that belong to multiple different operating system hosts.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本书已经详细介绍了可以与Docker一起使用的Overlay网络，它们是网络的虚拟化抽象层。Docker可以为容器创建Overlay网络，用于创建属于多个不同操作系统主机的容器网络。
- en: Instead of isolating each container to a unique network existing on one host,
    Docker instead allows its overlay network to join multiple different clusters
    of containers that are deployed on separate hosts together.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Docker不是将每个容器隔离到一个唯一网络的主机上，而是允许其Overlay网络将部署在不同主机上的多个容器群组连接在一起。
- en: This means that each container that shares an overlay network will have a unique
    IP address and name. To create an overlay network, Docker uses its own orchestration
    engine, called **Docker Swarm**.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着每个共享Overlay网络的容器将拥有唯一的IP地址和名称。要创建Overlay网络，Docker使用其自己的编排引擎，称为**Docker Swarm**。
- en: To run Docker in swarm mode, an external key-value store such as etcd, Consul,
    or Zookeeper needs to be used with Docker. This key-value store allows Docker
    to share information between different hosts, including the shared overlay network.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Swarm模式下运行Docker，需要使用外部键值存储，如etcd、Consul或Zookeeper与Docker一起使用。此键值存储允许Docker在不同主机之间共享信息，包括共享Overlay网络。
- en: Docker machine
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Docker machine
- en: It is worth mentioning that `docker-machine` is a useful command-line utility
    that allows virtual machines to be provisioned in VirtualBox, OpenStack, AWS,
    and many more platforms that have drivers.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker-machine` 是一个有用的命令行实用程序，它允许在VirtualBox、OpenStack、AWS等许多平台上使用驱动程序虚拟机进行配置。'
- en: 'In the following example, we can see how a machine could be booted using `docker-machine`
    in OpenStack:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们可以看到如何使用`docker-machine`在OpenStack中启动机器：
- en: '[PRE5]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: One of the more useful functions of `docker-machine` is its ability to boot
    virtual machines in cloud environments while issuing Docker Swarm commands. This
    allows machines to be set up on boot to the specific profile that is required.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker-machine`更有用的功能之一是在云环境中启动虚拟机，并发出Docker Swarm命令。这允许在启动时设置所需的特定配置文件。'
- en: Docker Compose
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Docker Compose
- en: Another helpful tool for orchestrating containers is **Docker Compose**, as
    running a command line for every container that needs to be deployed is not a
    feasible solution at scale. Therefore, Docker Compose allows users to specify
    their microservice-architecture topology in YAML format, so container dependencies
    are chained together to form a fully-fledged application.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有助于协调容器的工具是**Docker Compose**，因为对每个需要部署的容器运行命令行在大规模应用中不可行。因此，Docker Compose允许用户以YAML格式指定微服务架构拓扑，从而将容器依赖关系连接在一起，形成一个完整的应用。
- en: Microservices will be comprised of different container types, which together
    make up a full application. Docker Compose allows each of those microservices
    to be defined as YAML in the `docker-compose` file so they can be deployed together
    in a manageable way.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务将由不同类型的容器组成，这些容器共同构成一个完整的应用。Docker Compose允许将每个微服务定义为YAML格式，写入`docker-compose`文件中，从而以可管理的方式一起部署。
- en: 'In the following `docker-compose.yml` file, `web`, `nginx`, and `db` applications
    are configured and linked together, with the load balancer being exposed on port
    `8080` for public access, and load balancing `app1`, which is connected to the
    `redis` database backend:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的`docker-compose.yml`文件中，`web`、`nginx`和`db`应用被配置并相互连接，负载均衡器在`8080`端口上公开，供公众访问，负载均衡`app1`，它连接到`redis`数据库后端：
- en: '![Docker Compose](img/B05559_10_06.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![Docker Compose](img/B05559_10_06.jpg)'
- en: 'Docker Compose can be executed in the same directory as the Docker Compose
    YAML file to invoke a new deployment the following command should be issued:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose可以在与Docker Compose YAML文件相同的目录下执行，以启动新的部署，应该执行以下命令：
- en: '[PRE6]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Swarm architecture
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Swarm架构
- en: The Swarm architecture works on the principle that each host runs a Swarm agent
    and one host runs a Swarm master. The master is responsible for the orchestration
    of containers on each of the hosts where agents are running and that are a member
    of the same discovery (key-value store).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm架构的工作原理是每个主机运行一个Swarm代理程序，并且有一个主机运行Swarm主节点。主节点负责协调运行在各个主机上的容器，这些主机的代理程序都属于同一个发现组（键值存储）。
- en: An important principle for swarm is discovery, which is catered for using a
    key-value store such as etcd, Consul, or Zookeeper.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm的一个重要原则是发现机制，这可以通过使用像etcd、Consul或Zookeeper这样的键值存储来实现。
- en: 'To set up a Docker swarm, a set up Docker machine can be used to provision
    the following:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置Docker Swarm，可以使用已设置好的Docker机器来配置以下内容：
- en: Discovery server (key-value store such as etcd, Consul, or Zookeeper)
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现服务器（键值存储，如etcd、Consul或Zookeeper）
- en: Swarm master with swarm agent installed, pointing at a key-value store
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了Swarm代理的Swarm主节点，指向一个键值存储
- en: Two Swarm nodes with Swarm agent installed, pointing at a key-value store
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了Swarm代理的两个Swarm节点，指向一个键值存储
- en: 'The Docker Swarm architecture shows a master node scheduling containers on
    two Docker agents while they are all advertising to the key-value store, which
    is used for service discovery:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm架构展示了一个主节点在两个Docker代理上调度容器，同时它们都在向键值存储广播，键值存储用于服务发现：
- en: '![Swarm architecture](img/B05559_10_07.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![Swarm架构](img/B05559_10_07.jpg)'
- en: 'When setting up a Swarm agent, in this case the Swarm master, they will be
    booted with the following options: `--swarm-discovery` defines the address of
    the discovery service, while `--cluster-advertise` advertises the host machine
    on the network and `--cluster-store` points at a key-value store of choice:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置Swarm代理时，以本例中的Swarm主节点为例，它们将通过以下选项启动：`--swarm-discovery`定义了发现服务的地址，而`--cluster-advertise`在网络上广播主机机器，`--cluster-store`则指向所选的键值存储：
- en: '![Swarm architecture](img/B05559_10_08.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![Swarm架构](img/B05559_10_08.jpg)'
- en: 'Once the architecture has been set up, an overlay network needs to be created
    to run containers across the two different hosts (in this instance the overlay
    network is called `devops_for_networking_overlay`) by issuing the following command:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦架构设置完成，就需要创建一个覆盖网络来跨两个不同主机运行容器（在此示例中，覆盖网络被命名为`devops_for_networking_overlay`），可以通过以下命令执行：
- en: '[PRE7]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Containers can then be created on the network from an image using the Docker
    Swarm master to schedule the commands:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以使用Docker Swarm主节点调度命令，在网络中根据镜像创建容器：
- en: '[PRE8]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As each host is running in Swarm mode and attached to the key-value store, upon
    creation, the network information meta-data will be shared by the key-value store.
    This means that the network is visible to all hosts that use the same key-value
    store.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个主机都运行在 Swarm 模式下，并且与键值存储相连，因此在创建时，网络信息元数据将由键值存储共享。这意味着所有使用相同键值存储的主机都可以看到这个网络。
- en: Containers can then be launched from any of the Swarm masters onto the same
    overlay network, which will join the two hosts together. This will allow each
    host to communicate with other containers, via the overlay network, across hosts.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，容器可以从任何一个 Swarm 主节点启动，加入相同的覆盖网络，将两个主机连接在一起。这将允许每个主机通过覆盖网络与其他容器进行通信，跨主机互联。
- en: Multiple overlay networks can be created; though containers can only communicate
    across the same overlay network they cannot communicate between different overlay
    networks. To mitigate this, containers can be attached to multiple different networks.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 可以创建多个覆盖网络；不过容器只能在相同的覆盖网络中相互通信，不能跨不同的覆盖网络通信。为了解决这个问题，容器可以连接到多个不同的网络。
- en: Docker Swarm allows many specific containers to be assigned and exposed using
    port forwarding to load balance containers. Rolling updates can also be carried
    out to allow upgrades of the containers' application version.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 允许通过端口转发将多个特定容器分配并暴露，进行负载均衡。还可以进行滚动更新，以便升级容器中的应用版本。
- en: Due to its completely decentralized design, Docker Swarm is very flexible in
    the number of networking use cases it can solve.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其完全去中心化的设计，Docker Swarm 在可以解决的网络用例数量上非常灵活。
- en: Kubernetes
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes
- en: Kubernetes is a popular container orchestration tool from Google which was created
    in 2014 and is an open-source tool. Rather than Google coming up with their own
    container packaging tool and packaging repository, Kubernetes instead can plug
    seamlessly to use Docker registry as its container image repository.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是 Google 推出的一个流行的容器编排工具，创建于 2014 年，是一个开源工具。Kubernetes 并没有自己开发容器打包工具和打包仓库，而是可以无缝接入
    Docker 注册表作为其容器镜像仓库。
- en: Kubernetes can orchestrate containers that are created using Docker via a **Dockerfile**,
    or alternatively, using Packer aided by configuration management tools such as
    Puppet, Chef, Ansible, and Salt.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 可以通过 **Dockerfile** 协调使用 Docker 创建的容器，或者使用 Packer 并配合如 Puppet、Chef、Ansible
    和 Salt 等配置管理工具。
- en: Kubernetes can be seen as an alternative to Docker Swarm, but takes a slightly
    different approach in terms of its architectural design and has a lot of rich
    scheduling features to help with container management.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 可以看作是 Docker Swarm 的替代方案，但在架构设计上采取了略有不同的方法，并且拥有许多丰富的调度功能来帮助容器管理。
- en: Kubernetes architecture
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes 架构
- en: A Kubernetes cluster needs to be set up before a user can use Kubernetes to
    schedule containers. There is a wide variety of configuration management tools
    that can be used to create a production-grade Kubernetes cluster with notable
    solutions available from Ansible, Chef, and Puppet.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户可以使用 Kubernetes 调度容器之前，需要先设置 Kubernetes 集群。市面上有许多配置管理工具，可以用来创建生产级别的 Kubernetes
    集群，知名的解决方案有 Ansible、Chef 和 Puppet。
- en: 'Kubernetes clustering consists of the following high-level components, which
    in turn have their own subset of services. At a high level, a Kubernetes cluster
    consists of the following components:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群由以下高层组件组成，每个组件又包含一组服务。从高层次看，一个 Kubernetes 集群由以下组件构成：
- en: Kubectl
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubectl
- en: Master node
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主节点
- en: Worker node![Kubernetes architecture](img/B05559_10_09.jpg)
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作节点 ![Kubernetes 架构](img/B05559_10_09.jpg)
- en: Kubernetes master node
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Kubernetes 主节点
- en: The master node is responsible for managing the whole Kubernetes cluster and
    is used to take care of orchestrating worker nodes, which is where containers
    are scheduled.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点负责管理整个 Kubernetes 集群，用于协调工作节点，容器会在工作节点上进行调度。
- en: 'The master node, when deployed, consists of the following high-level components:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 部署后的主节点由以下高层组件组成：
- en: API server
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API 服务器
- en: Etcd key-value store
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Etcd 键值存储
- en: Scheduler
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调度器
- en: Controller manager
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制器管理器
- en: The API server has a RESTful API, which allows administrators to issue commands
    to Kubernetes.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: API 服务器提供了一个 RESTful API，允许管理员向 Kubernetes 发出命令。
- en: Etcd, as covered earlier in this chapter, is a key-value store that allows Kubernetes
    to store state and push changes to the rest of the cluster after changes have
    been made. Etcd is used by Kubernetes to hold scheduling information about pods,
    services, state, or even namespace information.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章之前所述，Etcd 是一个键值存储，允许 Kubernetes 存储状态并在更改后将更改推送到集群的其余部分。Kubernetes 使用 Etcd
    存储有关 Pod、服务、状态甚至命名空间的信息。
- en: The Kubernetes scheduler, as the name suggests, is used to schedule containers
    on Services or Pods. The Scheduler will check the availability of the Kubernetes
    cluster and make scheduling decisions based on availability of resources so it
    can schedule containers appropriately.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 调度器顾名思义，用于在服务或 Pod 上调度容器。调度器将检查 Kubernetes 集群的可用性，并根据资源的可用性做出调度决策，从而可以适当调度容器。
- en: The controller-manager is a daemon that allows a Kubernetes master to run different
    controller types. Controllers are used by Kubernetes to analyze the state of a
    cluster and make sure it is in the desired state, so if a pod fails it will be
    recreated or re-started. It adheres to the thresholds that are specified and is
    controlled by the Kubernetes' administrator.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: controller-manager 是一个守护进程，允许 Kubernetes 主节点运行不同类型的控制器。控制器用于分析集群的状态，并确保集群处于期望的状态，因此，如果某个
    Pod 失败，它将被重新创建或重启。它遵循指定的阈值，并由 Kubernetes 管理员进行控制。
- en: Kubernetes worker node
  id: totrans-210
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Kubernetes 工作节点
- en: Worker nodes are where pods run; each pod has an IP address and runs containers.
    It is the pod that determines all the networking for the containers and governs
    how they communicate across different pods.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点是 Pod 运行的地方；每个 Pod 都有一个 IP 地址并运行容器。Pod 决定容器的所有网络设置，并管理容器如何在不同的 Pod 之间进行通信。
- en: The worker node will contain all the necessary services to manage the networking
    between the containers, communicate with the master node, and are also used to
    assign resources to the scheduled containers.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点将包含管理容器间网络通信所需的所有服务，与主节点进行通信，并用于分配资源给已调度的容器。
- en: Docker also runs on each of the worker nodes and is used to pull down containers
    from the Docker registry and schedule containers.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 也在每个工作节点上运行，用于从 Docker 注册中心拉取容器并调度容器。
- en: '**Kubelet** is the worker service and is installed on worker nodes. It communicates
    with the API server on the Kubernetes master and retrieves information on the
    desired state of pods. Kubelet also reads information updates from etcd and writes
    updates about cluster events.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubelet** 是工作服务，并安装在工作节点上。它与 Kubernetes 主节点上的 API 服务器进行通信，获取 Pod 的期望状态信息。Kubelet
    还从 etcd 读取信息更新，并写入关于集群事件的更新。'
- en: The `kube-proxy` takes care of load balancing and networking functions such
    as routing packets.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-proxy` 负责负载均衡和网络功能，如路由数据包。'
- en: Kubernetes kubectl
  id: totrans-216
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Kubernetes kubectl
- en: '**Kubectl** is the Kubernetes command line, which issues commands to the master
    node to administer Kubernetes clusters. It can also be used to call YAML or JSON,
    as it is talking to the RESTful API server on the master node.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubectl** 是 Kubernetes 的命令行工具，用于向主节点发出命令来管理 Kubernetes 集群。它还可以用来调用 YAML 或
    JSON 文件，因为它与主节点上的 RESTful API 服务器进行通信。'
- en: A Kubernetes service is created as an abstraction layer above pods, which can
    be targeted using a label selector.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 服务作为 Pod 之上的抽象层创建，可以通过标签选择器进行访问。
- en: 'In the following example, kubectl can be used to create a `loadbalancing_service`
    service deployment with a selector, `app: nginx`, which is defined by the `loadbalancing_service.yml`
    file:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '在以下示例中，kubectl 可以用来创建一个带有选择器 `app: nginx` 的 `loadbalancing_service` 服务部署，该选择器由
    `loadbalancing_service.yml` 文件定义：'
- en: '![Kubernetes kubectl](img/B05559_10_10.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![Kubernetes kubectl](img/B05559_10_10.jpg)'
- en: 'Kubectl executes the YAML file by specifying:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: Kubectl 通过指定来执行 YAML 文件：
- en: '[PRE9]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Kubectl can then create four replica pods using the `ReplicationController`,
    these four pods will be managed by the service, as the labels `app: nginx` match
    the service''s selector and launch an NGINX container in each pod using the `nginx_pod.yml`
    file:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 'Kubectl 然后可以使用 `ReplicationController` 创建四个副本 Pod，这四个 Pod 将由服务进行管理，因为标签 `app:
    nginx` 与服务的选择器匹配，并使用 `nginx_pod.yml` 文件在每个 Pod 中启动一个 NGINX 容器：'
- en: '![Kubernetes kubectl](img/B05559_10_11.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![Kubernetes kubectl](img/B05559_10_11.jpg)'
- en: 'Kubectl creates the service using the following:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: Kubectl 使用以下方式创建服务：
- en: '[PRE10]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Kubernetes SDN integration
  id: totrans-227
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Kubernetes SDN 集成
- en: Kubernetes supports multiple networking techniques that could fill a whole book's
    worth of material on its own. With the Kubernetes, the pod is the major insertion
    point for networking.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 支持多种网络技术，这些技术本身足以写一本完整的书。对于 Kubernetes，Pod 是网络的主要插入点。
- en: 'Kubernetes supports the following networking options:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 支持以下网络选项：
- en: Google Compute Engine
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google 计算引擎
- en: Open vSwitch
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Open vSwitch
- en: Layer 2 Linux Bridge
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二层 Linux 桥接
- en: Project Calico
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Project Calico
- en: Romana
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Romana
- en: Contiv
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Contiv
- en: Kubernetes looks to provide a pluggable framework to control a pod's networking
    configuration and aims to give users a choice; if a flat layer 2 is required,
    Kubernetes caters for it, if a more complex layer-3 overlay network is required,
    then it can cater for this, too.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 旨在提供一个可插拔的框架来控制 Pod 的网络配置，并希望为用户提供选择；如果需要一个平坦的二层网络，Kubernetes 可以满足这个需求；如果需要更复杂的三层覆盖网络，它也能应对。
- en: With Open vSwitch being widely used with enterprise SDN controllers such as
    Nuage Networks VSP platform, which was covered in [Chapter 2](ch02.html "Chapter 2. The
    Emergence of Software-defined Networking"), *The Emergence of Software-defined
    Networking* and [Chapter 6](ch06.html "Chapter 6. Orchestrating SDN Controllers
    Using Ansible"), *Orchestrating SDN Controllers Using Ansible*. This focused upon
    how flow information could be pushed down to Open vSwitch on each hypervisor to
    create a stateful firewall and govern the ACL policies.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: Open vSwitch 广泛应用于企业 SDN 控制器，如 Nuage Networks VSP 平台，该平台在[第2章](ch02.html "第2章：软件定义网络的出现")中有所介绍，*软件定义网络的出现*，以及[第6章](ch06.html
    "第6章：使用 Ansible 编排 SDN 控制器")，*使用 Ansible 编排 SDN 控制器*。这部分内容重点讨论了如何将流信息推送到每个虚拟化服务器上的
    Open vSwitch，以创建有状态防火墙并管理 ACL 策略。
- en: A similar implementation is carried out when integrating Kubernetes, with Open
    vSwitch, being deployed onto each worker node and pod traffic being deferred to
    Open vSwitch.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在集成 Kubernetes 时，执行类似的实现，Open vSwitch 部署到每个工作节点上，Pod 流量被转发到 Open vSwitch。
- en: In Nuage's case, a version of their customized version of Open vSwitch, known
    as the VRS, is deployed on each Kubernetes worker to govern policy controlled
    by the VSD Nuage VSPs policy engine..
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Nuage 的案例中，他们定制的 Open vSwitch 版本（称为 VRS）会部署到每个 Kubernetes 工作节点上，以管理由 VSD Nuage
    VSP 的策略引擎控制的策略。
- en: 'The workflow for the Nuage SDN integration with Kubernetes is shown in the
    following figure, which shows that enterprise SDN controllers can integrate with
    orchestration engines such as Kubernetes and Docker to provide enterprise-grade
    networking:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Nuage SDN 与 Kubernetes 集成的工作流程如图所示，图中显示了企业 SDN 控制器如何与 Kubernetes 和 Docker 等编排引擎集成，以提供企业级网络：
- en: '![Kubernetes SDN integration](img/B05559_10_12.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![Kubernetes SDN 集成](img/B05559_10_12.jpg)'
- en: Impact of containers on networking
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器对网络的影响
- en: Containers have undoubtedly meant that a lot of networking has shifted into
    the application tier, so really, containers can be seen as a PaaS offering in
    its truest form.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 容器无疑意味着大量网络功能已经转移到应用层，因此，容器实际上可以被视为其最真实形式的 PaaS 提供。
- en: Infrastructure is, of course, still required to run containers, be it on bare-metal
    servers or virtual machines. The merits of virtual machines being used to run
    containers long term are debatable, as in a way it means a double set of virtualization,
    and anyone using nested virtualization will know it isn't always optimal for performance.
    So with more organizations using containers to deploy their microservice architectures,
    it will undoubtedly mean that users having a choice to run containers on either
    virtual or physical machines will be in demand.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，仍然需要基础设施来运行容器，无论是在裸机服务器上还是虚拟机上。使用虚拟机来长期运行容器的优点是有争议的，因为这在某种程度上意味着双重虚拟化，任何使用嵌套虚拟化的人都知道，这并不总是对性能最优。因此，随着更多组织使用容器来部署它们的微服务架构，这无疑意味着用户对是否在虚拟机或物理机器上运行容器的选择将会有需求。
- en: Cloud has notoriously meant virtual machines, so running containers on virtual
    machines is probably born out of necessity rather than choice. Being able to orchestrate
    containers on bare-metal servers with an overlay network on top of them is definitely
    more appealing as it pushes the container closer to the physical machine resources
    without the visualization overhead.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 云计算通常意味着虚拟机，因此在虚拟机上运行容器可能是出于必要性而非选择的结果。能够在裸机服务器上协调容器，并在其上方使用覆盖网络，肯定更具吸引力，因为这样可以将容器更接近物理机器资源，而没有虚拟化开销。
- en: This allows containers to maximize the physical machine resources, and users
    then only care about anti-infinity in terms of whether the service can run across
    multiple clouds and data centers, giving true disaster recovery.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得容器能够最大化物理机器资源，用户只需关注是否能跨多个云和数据中心运行服务，从而实现真正的灾难恢复。
- en: With hybrid cloud solutions, the industry is moving beyond thinking about rack
    redundancy. Instead it is moving toward a model which will focus on splitting
    applications across multiple cloud providers. So having the ability to orchestrate
    the networking and applications in an identical way using orchestration engines
    such as Docker Swarm or Kubernetes can be used to make that goal a reality.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 随着混合云解决方案的发展，业界正超越了仅考虑机架冗余的思维模式。相反，业界正在向一种新的模式转变，这种模式将专注于将应用程序分布到多个云提供商之间。因此，能够使用
    Docker Swarm 或 Kubernetes 等编排引擎以相同的方式编排网络和应用程序，将有助于实现这一目标。
- en: What does this mean for the network operator? It means that the role is evolving,
    it means that the network engineer's role becomes advisory, helping the developers
    architect the network in the best possible way to run their applications. Rather
    than building a network as a side project in a private cloud, network operators
    can instead focus on providing an overlay network as a service to developers while
    making the underlay network fabric fast and performant so that it can scale out
    to meet the developer's needs.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这对网络运维人员意味着什么？这意味着角色正在演变，网络工程师的角色变为顾问，帮助开发人员以最佳方式设计网络，以支持其应用程序的运行。与其在私有云中将网络建设作为副项目，网络运维人员可以专注于为开发人员提供作为服务的覆盖网络，同时使基础网络架构快速且高效，从而能扩展以满足开发人员的需求。
- en: Summary
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'Containers have been said to be a major disruptor of the virtualization market.
    Gartner have predicted the following:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 容器被认为是虚拟化市场的主要颠覆者。Gartner 已预测如下：
- en: '*"By 2018, more than 50-60% of new workloads will be deployed into containers
    in at least one stage of the application life cycle".*'
  id: totrans-251
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“到2018年，超过50-60%的新工作负载将在应用程序生命周期的某一阶段部署到容器中。”*'
- en: This is based on Gartner's analysis of the IT market, so this is a bold statement,
    but if it comes to fruition, it will prove to be a huge cultural shift in the
    way applications are deployed, in the same way virtualization was before it.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这是基于 Gartner 对 IT 市场的分析，因此这是一个大胆的声明，但如果成真，它将证明是应用程序部署方式的巨大文化转变，正如虚拟化曾经带来的变化一样。
- en: In this chapter, we showed that containers can help organizations deploy their
    microservice architectures and analyzed the internal mechanics and benefits that
    containers bring. The key benefits are portability, speed of deployment, elastic
    scalability, isolation and maximization of different resources, performance control,
    limited attack vector, and support for multiple networking types.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们展示了容器如何帮助组织部署微服务架构，并分析了容器带来的内部机制和好处。主要的好处包括可移植性、部署速度、弹性扩展、隔离和不同资源的最大化、性能控制、有限的攻击面以及对多种网络类型的支持。
- en: Aside from the benefits containers bring, this chapter looked at the Docker
    tool and illustrated how the Docker workflow can be fitted into a Continuous Delivery
    model, which is at the heart of most DevOps initiatives.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 除了容器带来的好处，本章还介绍了 Docker 工具，并说明了 Docker 工作流如何融入持续交付模型，而这一模型正是大多数 DevOps 项目的核心。
- en: The focus of the chapter then shifted to Docker networking and the layer-2 networking
    options available to network containers. We illustrated how to use overlay networks
    to join multiple hosts together to form a cluster and we showed how container
    technology can integrate with SDN controllers such as Nuage VSP Platform using
    Open vSwitch.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点随后转向了 Docker 网络和可用于网络化容器的第二层网络选项。我们展示了如何使用覆盖网络将多个主机连接起来，形成一个集群，并展示了容器技术如何通过
    Open vSwitch 与 Nuage VSP 平台等 SDN 控制器进行集成。
- en: The chapter also covered container orchestration solutions such as Docker Swarm
    and Kubernetes, their unique architectures, and ways in which they can be used
    to network containers over multiple hosts and act as a Platform as a Service layer.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还介绍了容器编排解决方案，如 Docker Swarm 和 Kubernetes，它们独特的架构，以及如何将它们用于在多个主机上网络化容器，并作为平台即服务（PaaS）层。
- en: 'The importance of containerization and its impact on Platform as a Service
    (PaaS) solutions cannot be underestimated, with Forrester stating the following:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 容器化的重要性及其对平台即服务（PaaS）解决方案的影响不容小觑，Forrester 曾表示：
- en: '*"Containers as a Service (CaaS) is becoming the new Platform as a Service
    (PaaS). With the interest in containers and micro-services skyrocketing among
    developers, cloud providers are capitalizing on the opportunity through hosted
    container management services."*'
  id: totrans-258
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“容器即服务（CaaS）正在成为新的平台即服务（PaaS）。随着开发人员对容器和微服务的兴趣激增，云服务提供商正在通过托管的容器管理服务抓住这一机遇。”*'
- en: In summary, it is fair to conclude that containerization can have many benefits
    and help aid developers in the implementation of Continuous Delivery workflows
    and PaaS solutions. Containerization also gives the added flexibility of deploying
    workloads across multiple cloud providers, be they private or public, using a
    common orchestration layer such as Kubernetes, Apache Mesos, or Docker Swarm.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，可以公正地得出结论，容器化可以带来许多好处，并帮助开发人员实现持续交付工作流和PaaS解决方案。容器化还提供了跨多个云提供商（无论是私有云还是公有云）部署工作负载的额外灵活性，使用像Kubernetes、Apache
    Mesos或Docker Swarm这样的通用编排层。
- en: In the following chapter, the focus will shift from containers toward securing
    the network when using software-defined overlay networks and a Continuous Delivery
    model. It will explore techniques that can be used to help secure a modern private
    cloud in an API-driven environment, so that software-defined networking solutions
    can be implemented without compromising security requirements.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，重点将从容器转向在使用软件定义的覆盖网络和持续交付模型时确保网络安全。它将探讨一些技术，这些技术可以帮助在API驱动的环境中保障现代私有云的安全，以便在不妥协安全要求的情况下实现软件定义网络解决方案。
