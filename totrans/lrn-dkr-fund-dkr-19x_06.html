<html><head></head><body>
        

                            
                    <h1 class="header-title">Creating and Managing Container Images</h1>
                
            
            
                
<p style="font-weight: 400">In the previous chapter, we learned what containers are and how to run, stop, remove, list, and inspect them. We extracted the logging information of some containers, ran other processes inside an already running container, and finally, we dived deep into the anatomy of containers. Whenever we ran a container, we created it using a container image. In this chapter, we will be familiarizing ourselves with these container images. We will learn in detail what they are, how to create them, and how to distribute them.</p>
<p style="font-weight: 400">This chapter will cover the following topics:</p>
<ul style="font-weight: 400">
<li>What are images?</li>
<li>Creating images</li>
<li>Lift and shift: Containerizing a legacy app</li>
<li>Sharing or shipping images</li>
</ul>
<p style="font-weight: 400">After completing this chapter, you will be able to do the following:</p>
<ul style="font-weight: 400">
<li>Name three of the most important characteristics of a container image.</li>
<li>Create a custom image by interactively changing the container layer and committing it.</li>
<li>Author a simple <kbd>Dockerfile</kbd> to generate a custom image.</li>
<li>Export an existing image using <kbd>docker image save</kbd> and import it into another Docker host using <kbd>docker image load</kbd>.</li>
<li>Write a two-step Dockerfile that minimizes the size of the resulting image by only including the resulting artifacts in the final image.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">What are images?</h1>
                
            
            
                
<p style="font-weight: 400">In Linux, everything is a file. The whole operating system is basically a filesystem with files and folders stored on the local disk. This is an important fact to remember when looking at what container images are. As we will see, an image is basically a big tarball containing a filesystem. More specifically, it contains a layered filesystem.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The layered filesystem</h1>
                
            
            
                
<p style="font-weight: 400" class="CDPAlignLeft CDPAlign">Container images are templates from which containers are created. These images are not made up of just one monolithic block but are composed of many layers. The first layer in the image is also called the base layer. We can see this in the following graphic:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-933 image-border" src="img/f648f501-f54d-4794-ae3f-c17ec8f78b6c.png" style="width:15.92em;height:13.67em;"/></p>
<p>The image as a stack of layers</p>
<p style="font-weight: 400">Each individual layer contains files and folders. Each layer only contains the changes to the filesystem with respect to the underlying layers. Docker uses a Union filesystem—as discussed in <a href="d9bb597d-2b32-4144-b068-564d85bcdf68.xhtml" target="_blank">Chapter 3</a>, <em>Mastering Containers — </em>to create a virtual filesystem out of the set of layers. A storage driver handles the details regarding the way these layers interact with each other. Different storage drivers are available that have advantages and disadvantages in different situations.</p>
<p style="font-weight: 400">The layers of a container image are all immutable. Immutable means that once generated, the layer cannot ever be changed. The only possible operation affecting the layer is its physical deletion. This immutability of layers is important because it opens up a tremendous amount of opportunities, as we will see.</p>
<p style="font-weight: 400">In the following screenshot, we can see what a custom image for a web application, using Nginx as a web server, could look like:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-934 image-border" src="img/48c83b9e-fef1-45d9-a084-c1076f3e396d.png" style="width:23.33em;height:6.92em;"/></p>
<p>A sample custom image based on Alpine and Nginx</p>
<p style="font-weight: 400">Our base layer here consists of the <strong>Alpine Linux</strong> distribution. Then, on top of that, we have an <strong>Add Nginx</strong> layer where Nginx is added on top of Alpine. Finally, the third layer contains all the files that make up the web application, such as HTML, CSS, and JavaScript files.</p>
<p style="font-weight: 400">As has been said previously, each image starts with a base image. Typically, this base image is one of the official images found on Docker Hub, such as a Linux distro, Alpine, Ubuntu, or CentOS. However, it is also possible to create an image from scratch.</p>
<p>Docker Hub is a public registry for container images. It is a central hub ideally suited for sharing public container images. </p>
<p style="font-weight: 400">Each layer only contains the delta of changes in regard to the previous set of layers. The content of each layer is mapped to a special folder on the host system, which is usually a subfolder of <kbd>/var/lib/docker/</kbd>.</p>
<p style="font-weight: 400">Since layers are immutable, they can be cached without ever becoming stale. This is a big advantage, as we will see.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The writable container layer</h1>
                
            
            
                
<p style="font-weight: 400">As we have discussed, a container image is made of a stack of immutable or read-only layers. When the Docker Engine creates a container from such an image, it adds a writable container layer on top of this stack of immutable layers. Our stack now looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-935 image-border" src="img/35fc8834-7fa6-42ad-bdd6-7979a1878438.png" style="width:18.42em;height:12.92em;"/></p>
<p>The writable container layer</p>
<p style="font-weight: 400">The <strong>Container Layer</strong> is marked as read/write. Another advantage of the immutability of image layers is that they can be shared among many containers created from this image. All that is needed is a thin, writable container layer for each container, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-936 image-border" src="img/0e32cfeb-d02b-4397-8ead-f1e066194ef3.png" style="width:30.67em;height:19.00em;"/></p>
<p>Multiple containers sharing the same image layers</p>
<p style="font-weight: 400">This technique, of course, results in a tremendous reduction in the resources that are consumed. Furthermore, this helps to decrease the loading time of a container since only a thin container layer has to be created once the image layers have been loaded into memory, which only happens for the first container.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Copy-on-write</h1>
                
            
            
                
<p style="font-weight: 400">Docker uses the copy-on-write technique when dealing with images. Copy-on-write is a strategy for sharing and copying files for maximum efficiency. If a layer uses a file or folder that is available in one of the low-lying layers, then it just uses it. If, on the other hand, a layer wants to modify, say, a file from a low-lying layer, then it first copies this file up to the target layer and then modifies it. In the following screenshot, we can see a glimpse of what this means:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-937 image-border" src="img/7129ffa2-5290-455b-847a-1ae41c2aee0f.png" style="width:36.83em;height:15.17em;"/></p>
<p>Docker image using copy-on-write</p>
<p style="font-weight: 400">The second layer wants to modify <strong>File 2</strong>, which is present in the <strong>Base Layer</strong>. Thus, it copies it up and then modifies it. Now, let's say that we're sitting in the top layer of the preceding screenshot. This layer will use <strong>File 1</strong> from the <strong>Base Layer</strong> and <strong>File 2</strong> and <strong>File 3</strong> from the second layer.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Graph drivers</h1>
                
            
            
                
<p style="font-weight: 400">Graph drivers are what enable the Union filesystem. Graph drivers are also called storage drivers and are used when dealing with layered container images. A graph driver consolidates multiple image layers into a root filesystem for the mount namespace of the container. Or, put differently, the driver controls how images and containers are stored and managed on the Docker host.</p>
<p style="font-weight: 400">Docker supports several different graph drivers using a pluggable architecture. The preferred driver is <kbd>overlay2</kbd>, followed by <kbd>overlay</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating images</h1>
                
            
            
                
<p style="font-weight: 400">There are three ways to create a new container image on your system. The first one is by interactively building a container that contains all the additions and changes one desires, and then committing those changes into a new image. The second, and most important, way is to use a <kbd>Dockerfile</kbd> to describe what's in the new image, and then build the image using that <kbd>Dockerfile</kbd> as a manifest. Finally, the third way of creating an image is by importing it into the system from a tarball.</p>
<p style="font-weight: 400">Now, let's look at these three ways in detail.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Interactive image creation</h1>
                
            
            
                
<p style="font-weight: 400">The first way we can create a custom image is by interactively building a container. That is, we start with a base image that we want to use as a template and run a container of it interactively. Let's say that this is the Alpine image.</p>
<p>To interactively create an image follow along:</p>
<ol>
<li style="font-weight: 400">The command to run the container would be as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker container run -it \<br/>    --name sample \<br/>    alpine:3.10 /bin/sh</strong></pre>
<p style="padding-left: 60px">The preceding command runs a container based on the <kbd>alpine:3.10</kbd> image.</p>
<p style="padding-left: 60px">We run the container interactively with an attached <strong>teletypewriter</strong> (<strong>TTY</strong>) using the <kbd>-it</kbd> parameter, name it <kbd>sample</kbd> with the <kbd>--name</kbd> parameter, and—finally—run a shell inside the container using <kbd>/bin/sh</kbd>.</p>
<p style="padding-left: 60px">In the Terminal window where you run the preceding command, you should see something similar to this:</p>
<pre style="padding-left: 60px">Unable to find image 'alpine:3.10' locally<br/>3.10: Pulling from library/alpine<br/>921b31ab772b: Pull complete<br/>Digest: sha256:ca1c944a4f8486a153024d9965aafbe24f5723c1d5c02f4964c045a16d19dc54<br/>Status: Downloaded newer image for alpine:3.10<br/>/ #</pre>
<p style="font-weight: 400;padding-left: 60px">By default, the <kbd>alpine</kbd> container does not have the <kbd>ping</kbd> tool installed. Let's assume we want to create a new custom image that has <kbd>ping</kbd> installed.</p>
<ol start="2">
<li style="font-weight: 400">Inside the container, we can then run the following command:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>/ # apk update &amp;&amp; apk add iputils</strong></pre>
<p style="font-weight: 400;padding-left: 60px">This uses the <kbd>apk</kbd> Alpine package manager to install the <kbd>iputils</kbd> library, of which <kbd>ping</kbd> is a part. The output of the preceding command should look approximately like this:</p>
<div><img src="img/7095041c-9ad2-4bfc-bc0e-940fd1351b23.png" style="width:55.58em;height:16.08em;"/></div>
<p>Installing <kbd>ping</kbd> on Alpine</p>
<ol start="3">
<li style="font-weight: 400">Now, we can indeed use <kbd>ping</kbd>, as the following code snippet shows:</li>
</ol>
<div><img src="img/914c8ee9-964b-49b0-afe2-e1b0dd28d57b.png" style="width:33.08em;height:12.92em;"/></div>
<p>Using ping from within the container</p>
<ol start="4">
<li style="font-weight: 400">Once we have finished our customization, we can quit the container by typing <kbd>exit</kbd> at the prompt.</li>
</ol>
<p style="padding-left: 60px">If we now list all containers with the <kbd>ls -a</kbd> Docker container, we can see that our sample container has a status of <kbd>Exited</kbd>, but still exists on the system, as shown in the following code block:</p>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker container ls -a | grep sample</strong><br/>040fdfe889a6 alpine:3.10 "/bin/sh" 8 minutes ago Exited (0) 4 seconds ago</pre>
<ol start="5">
<li style="font-weight: 400">If we want to see what has changed in our container in relation to the base image, we can use the <kbd>docker container diff</kbd> command, as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker container diff sample</strong></pre>
<p style="font-weight: 400;padding-left: 60px">The output should present a list of all modifications done on the filesystem of the container, as follows:</p>
<pre style="padding-left: 60px" class="mce-root">C /usr<br/>C /usr/sbin<br/>A /usr/sbin/getcap<br/>A /usr/sbin/ipg<br/>A /usr/sbin/tftpd<br/>A /usr/sbin/ninfod<br/>A /usr/sbin/rdisc<br/>A /usr/sbin/rarpd<br/>A /usr/sbin/tracepath<br/>...<br/>A /var/cache/apk/APKINDEX.d8b2a6f4.tar.gz<br/>A /var/cache/apk/APKINDEX.00740ba1.tar.gz<br/>C /bin<br/>C /bin/ping<br/>C /bin/ping6<br/>A /bin/traceroute6<br/>C /lib<br/>C /lib/apk<br/>C /lib/apk/db<br/>C /lib/apk/db/scripts.tar<br/>C /lib/apk/db/triggers<br/>C /lib/apk/db/installed</pre>
<p style="font-weight: 400;padding-left: 60px">We have shortened the preceding output for better readability. In the list, <kbd>A</kbd> stands for <em>added</em>, and <kbd>C</kbd> stands for <em>changed</em>. If we had any deleted files, then those would be prefixed with a <strong><kbd>D</kbd></strong>.</p>
<ol start="6">
<li style="font-weight: 400">We can now use the <kbd>docker container commit</kbd> command to persist our modifications and create a new image from them, like this:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker container commit sample my-alpine</strong><br/>sha256:44bca4141130ee8702e8e8efd1beb3cf4fe5aadb62a0c69a6995afd49c2e7419</pre>
<p style="font-weight: 400;padding-left: 60px">With the preceding command, we have specified that the new image will be called <kbd>my-alpine</kbd>. The output generated by the preceding command corresponds to the ID of the newly generated image.</p>
<ol start="7">
<li style="font-weight: 400">We can verify this by listing all images on our system, as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker image ls</strong></pre>
<p style="font-weight: 400;padding-left: 60px">We can see this image ID (shortened) as follows:</p>
<pre style="padding-left: 60px" class="mce-root">REPOSITORY   TAG      IMAGE ID       CREATED              SIZE<br/>my-alpine    latest   44bca4141130   About a minute ago   7.34MB<br/>...</pre>
<p style="font-weight: 400;padding-left: 60px">We can see that the image named <kbd>my-alpine</kbd> has the expected ID of <kbd>44bca4141130</kbd> and automatically got a <kbd>latest</kbd> tag assigned. This happens since we did not explicitly define a tag ourselves. In this case, Docker always defaults to the <kbd>latest</kbd> tag.</p>
<p class="mce-root"/>
<ol start="8">
<li style="font-weight: 400">If we want to see how our custom image has been built, we can use the <kbd>history </kbd>command as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker image history my-alpine</strong></pre>
<p style="font-weight: 400;padding-left: 60px">This will print a list of the layers our image consists of, as follows:</p>
<div><img src="img/c399a38d-20a1-48b9-8210-4831f035b78e.png"/></div>
<p>History of the my-alpine Docker image </p>
<p style="font-weight: 400;padding-left: 60px">The first layer in the preceding output is the one that we just created by adding the <kbd>iputils</kbd> package.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using Dockerfiles</h1>
                
            
            
                
<p style="font-weight: 400">Manually creating custom images, as shown in the previous section of this chapter, is very helpful when doing exploration, creating prototypes, or authoring feasibility studies. But it has a serious drawback: it is a manual process and thus is not repeatable or scalable. It is also as error-prone as any other task executed manually by humans. There must be a better way.</p>
<p style="font-weight: 400">This is where the so-called <kbd>Dockerfile</kbd> comes into play. A <kbd>Dockerfile</kbd> is a text file that is usually literally called <kbd>Dockerfile</kbd>. It contains instructions on how to build a custom container image. It is a declarative way of building images.</p>
<div><strong>De</strong><strong>clarative versus imperative</strong>:<br/>
In computer science, in general, and with Docker specifically, one often uses a declarative way of defining a task. One describes the expected outcome and lets the system figure out how to achieve this goal, rather than giving step-by-step instructions to the system on how to achieve this desired outcome. The latter is an imperative approach.</div>
<p style="font-weight: 400">Let's look at a sample <kbd>Dockerfile</kbd>, as follows:</p>
<pre class="mce-root">FROM python:2.7<br/>RUN mkdir -p /app<br/>WORKDIR /app<br/>COPY ./requirements.txt /app/<br/>RUN pip install -r requirements.txt<br/>CMD ["python", "main.py"]</pre>
<p style="font-weight: 400">This is a <kbd>Dockerfile</kbd> as it is used to containerize a Python 2.7 application. As we can see, the file has six lines, each starting with a keyword such as <kbd>FROM</kbd>, <kbd>RUN</kbd>, or <kbd>COPY</kbd>. It is a convention to write the keywords in all caps, but that is not a must.</p>
<p style="font-weight: 400">Each line of the <kbd>Dockerfile</kbd> results in a layer in the resulting image. In the following screenshot, the image is drawn upside down compared to the previous illustrations in this chapter, showing an image as a stack of layers. Here, the <strong>Base Layer</strong> is shown on top. Don't let yourself be confused by this. In reality, the base layer is always the lowest layer in the stack:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-938 image-border" src="img/3f4c11dd-4fed-478b-b229-cdc834633c62.png" style="width:33.25em;height:14.50em;"/></p>
<div><p>The relation of Dockerfile and layers in an image</p>
</div>
<p style="font-weight: 400">Now, let's look at the individual keywords in more detail.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The FROM keyword</h1>
                
            
            
                
<p style="font-weight: 400">Every <kbd>Dockerfile</kbd> starts with the <kbd>FROM</kbd> keyword. With it, we define which base image we want to start building our custom image from. If we want to build starting with CentOS 7, for example, we would have the following line in the <kbd>Dockerfile</kbd>:</p>
<pre class="mce-root">FROM centos:7</pre>
<p style="font-weight: 400">On Docker Hub, there are curated or official images for all major Linux distros, as well as for all important development frameworks or languages, such as Python, Node.js, Ruby, Go, and many more. Depending on our needs, we should select the most appropriate base image.</p>
<p style="font-weight: 400">For example, if I want to containerize a Python 3.7 application, I might want to select the relevant official <kbd>python:3.7</kbd> image.</p>
<p style="font-weight: 400">If we really want to start from scratch, we can also use the following statement:</p>
<pre class="mce-root">FROM scratch</pre>
<p style="font-weight: 400">This is useful in the context of building super-minimal images that only—for example—contain a single binary: the actual statically linked executable, such as <kbd>Hello-World</kbd>. The <kbd>scratch</kbd> image is literally an empty base image.</p>
<p style="font-weight: 400"><kbd>FROM scratch</kbd> is a <kbd>no-op</kbd> in the <kbd>Dockerfile</kbd>, and as such does not generate a layer in the resulting container image.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The RUN keyword</h1>
                
            
            
                
<p style="font-weight: 400">The next important keyword is <kbd>RUN</kbd>. The argument for <kbd>RUN</kbd> is any valid Linux command, such as the following:</p>
<pre class="mce-root"><strong>RUN yum install -y wget</strong></pre>
<p style="font-weight: 400">The preceding command is using the <kbd>yum</kbd> CentOS package manager to install the <kbd>wget</kbd> package into the running container. This assumes that our base image is CentOS or <strong>Red Hat Enterprise Linux</strong> (<strong>RHEL</strong>). If we had Ubuntu as our base image, then the command would look similar to the following:</p>
<pre class="mce-root"><strong>RUN apt-get update &amp;&amp; apt-get install -y wget</strong></pre>
<p style="font-weight: 400">It would look like this because Ubuntu uses <kbd>apt-get</kbd> as a package manager. Similarly, we could define a line with <kbd>RUN</kbd>, like this:</p>
<pre class="mce-root"><strong>RUN mkdir -p /app &amp;&amp; cd /app</strong></pre>
<p style="font-weight: 400">We could also do this:</p>
<pre class="mce-root"><strong>RUN tar -xJC /usr/src/python --strip-components=1 -f python.tar.xz</strong></pre>
<p style="font-weight: 400">Here, the former creates an <kbd>/app</kbd> folder in the container and navigates to it, and the latter untars a file to a given location. It is completely fine, and even recommended, for you to format a Linux command using more than one physical line, such as this:</p>
<pre class="mce-root"><strong>RUN apt-get update \</strong><br/><strong>  &amp;&amp; apt-get install -y --no-install-recommends \</strong><br/><strong>    ca-certificates \</strong><br/><strong>    libexpat1 \</strong><br/><strong>    libffi6 \</strong><br/><strong>    libgdbm3 \</strong><br/><strong>    libreadline7 \</strong><br/><strong>    libsqlite3-0 \</strong><br/><strong>    libssl1.1 \</strong><br/><strong>  &amp;&amp; rm -rf /var/lib/apt/lists/*</strong></pre>
<p style="font-weight: 400">If we use more than one line, we need to put a backslash (<kbd>\</kbd>) at the end of the lines to indicate to the shell that the command continues on the next line.</p>
<p>Try to find out what the preceding command does.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The COPY and ADD keywords</h1>
                
            
            
                
<p style="font-weight: 400">The <kbd>COPY</kbd> and <kbd>ADD</kbd> keywords are very important since, in the end, we want to add some content to an existing base image to make it a custom image. Most of the time, these are a few source files of—say—a web application, or a few binaries of a compiled application.</p>
<p style="font-weight: 400">These two keywords are used to copy files and folders from the host into the image that we're building. The two keywords are very similar, with the exception that the <kbd>ADD</kbd> keyword also lets us copy and unpack TAR files, as well as providing a URL as a source for the files and folders to copy.</p>
<p style="font-weight: 400">Let's look at a few examples of how these two keywords can be used, as follows:</p>
<pre class="mce-root"><strong>COPY . /app</strong><br/><strong>COPY ./web /app/web</strong><br/><strong>COPY sample.txt /data/my-sample.txt</strong><br/><strong>ADD sample.tar /app/bin/</strong><br/><strong>ADD http://example.com/sample.txt /data/</strong></pre>
<p style="font-weight: 400">In the preceding lines of code, the following applies:</p>
<ul style="font-weight: 400">
<li>The first line copies all files and folders from the current directory recursively to the <kbd>app</kbd> folder inside the container image.</li>
<li>The second line copies everything in the <kbd>web</kbd> subfolder to the target folder, <kbd>/app/web</kbd>. </li>
<li>The third line copies a single file, <kbd>sample.txt</kbd>, into the target folder, <kbd>/data</kbd>, and at the same time, renames it to <kbd>my-sample.txt</kbd>. </li>
<li>The fourth statement unpacks the <kbd>sample.tar </kbd>file into the target folder, <kbd>/app/bin</kbd> . </li>
<li>Finally, the last statement copies the remote file, <kbd>sample.txt</kbd>, into the target file, <kbd>/data</kbd>. </li>
</ul>
<p style="font-weight: 400">Wildcards are allowed in the source path. For example, the following statement copies all files starting with <kbd>sample</kbd> to the <kbd>mydir</kbd> folder inside the image:</p>
<pre class="mce-root"><strong>COPY ./sample* /mydir/</strong></pre>
<p style="font-weight: 400">From a security perspective, it is important to know that, by default, all files and folders inside the image will have a <strong>user ID</strong> (<strong>UID</strong>) and a <strong>group ID</strong> (<strong>GID</strong>) of <kbd>0</kbd>. The good thing is that for both <kbd>ADD</kbd> and <kbd>COPY</kbd>, we can change the ownership that the files will have inside the image using the optional <kbd>--chown</kbd> flag, as follows:</p>
<pre class="mce-root"><strong>ADD --chown=11:22 ./data/web* /app/data/</strong></pre>
<p style="font-weight: 400">The preceding statement will copy all files starting with the name <kbd>web</kbd> and put them into the <kbd>/app/data</kbd> folder in the image, and at the same time assign user <kbd>11</kbd> and group <kbd>22</kbd> to these files.</p>
<p style="font-weight: 400">Instead of numbers, one could also use names for the user and group, but then these entities would have to be already defined in the root filesystem of the image at <kbd>/etc/passwd</kbd> and <kbd>/etc/group</kbd> respectively; otherwise, the build of the image would fail.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The WORKDIR keyword</h1>
                
            
            
                
<p style="font-weight: 400">The <kbd>WORKDIR</kbd> keyword defines the working directory or context that is used when a container is run from our custom image. So, if I want to set the context to the <kbd>/app/bin</kbd> folder inside the image, my expression in the <kbd>Dockerfile</kbd> would have to look as follows:</p>
<pre class="mce-root"><strong>WORKDIR /app/bin</strong></pre>
<p style="font-weight: 400">All activity that happens inside the image after the preceding line will use this directory as the working directory. It is very important to note that the following two snippets from a <kbd>Dockerfile</kbd> are not the same:</p>
<pre class="mce-root"><strong>RUN cd /app/bin</strong><br/><strong>RUN touch sample.txt</strong></pre>
<p style="font-weight: 400">Compare the preceding code with the following code:</p>
<pre class="mce-root"><strong>WORKDIR /app/bin</strong><br/><strong>RUN touch sample.txt</strong></pre>
<p style="font-weight: 400">The former will create the file in the root of the image filesystem, while the latter will create the file at the expected location in the <kbd>/app/bin</kbd> folder. Only the <kbd>WORKDIR</kbd> keyword sets the context across the layers of the image. The <kbd>cd</kbd> command alone is not persisted across layers.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The CMD and ENTRYPOINT keywords</h1>
                
            
            
                
<p style="font-weight: 400">The <kbd>CMD</kbd> and <kbd>ENTRYPOINT</kbd> keywords are special. While all other keywords defined for a <kbd>Dockerfile</kbd> are executed at the time the image is built by the Docker builder, these two are actually definitions of what will happen when a container is started from the image we define. When the container runtime starts a container, it needs to know what the process or application will be that has to run inside that container. That is exactly what <kbd>CMD</kbd> and <kbd>ENTRYPOINT</kbd> are used for—to tell Docker what the start process is and how to start that process.</p>
<p style="font-weight: 400">Now, the differences between <kbd>CMD</kbd> and <kbd>ENTRYPOINT</kbd> are subtle, and honestly, most users don't fully understand them or use them in the intended way. Luckily, in most cases, this is not a problem and the container will run anyway; it's just the handling of it that is not as straightforward as it could be.</p>
<p style="font-weight: 400">To better understand how to use the two keywords, let's analyze what a typical Linux command or expression looks like. Let's take the <kbd>ping</kbd> utility as an example, as follows:</p>
<pre class="mce-root"><strong>$ ping -c 3 8.8.8.8</strong></pre>
<p style="font-weight: 400">In the preceding expression, <kbd>ping</kbd> is the command and <kbd>-c 3 8.8.8.8</kbd> are the parameters to this command. Let's look at another expression here:</p>
<pre class="mce-root"><strong>$ wget -O - http://example.com/downloads/script.sh</strong></pre>
<p style="font-weight: 400">Again, in the preceding expression, <kbd>wget</kbd> is the command and <kbd>-O - http://example.com/downloads/script.sh </kbd>are the parameters.</p>
<p style="font-weight: 400">Now that we have dealt with this, we can get back to <kbd>CMD</kbd> and <kbd>ENTRYPOINT</kbd>. <kbd>ENTRYPOINT</kbd> is used to define the command of the expression, while <kbd>CMD</kbd> is used to define the parameters for the command. Thus, a <kbd>Dockerfile</kbd> using Alpine as the base image and defining <kbd>ping</kbd> as the process to run in the container could look like this:</p>
<pre class="mce-root"><strong>FROM alpine:3.10</strong><br/><strong>ENTRYPOINT ["ping"]</strong><br/><strong>CMD ["-c","3","8.8.8.8"]</strong></pre>
<p style="font-weight: 400">For both <kbd>ENTRYPOINT</kbd> and <kbd>CMD</kbd>, the values are formatted as a JSON array of strings, where the individual items correspond to the tokens of the expression that are separated by whitespace. This is the preferred way of defining <kbd>CMD</kbd> and <kbd>ENTRYPOINT</kbd>. It is also called the <em>exec</em> form.</p>
<p style="font-weight: 400">Alternatively, one can also use what's called the shell form, as shown here:</p>
<pre class="mce-root"><strong>CMD command param1 param2</strong></pre>
<p style="font-weight: 400">We can now build an image called <kbd>pinger</kbd> from the preceding <kbd>Dockerfile</kbd>, as follows:</p>
<pre class="mce-root"><strong>$ docker image build -t pinger .</strong></pre>
<p style="font-weight: 400">Then, we can run a container from the <kbd>pinger</kbd> image we just created, like this:</p>
<pre class="mce-root"><strong>$ docker container run --rm -it pinger</strong><br/>PING 8.8.8.8 (8.8.8.8): 56 data bytes<br/>64 bytes from 8.8.8.8: seq=0 ttl=37 time=19.298 ms<br/>64 bytes from 8.8.8.8: seq=1 ttl=37 time=27.890 ms<br/>64 bytes from 8.8.8.8: seq=2 ttl=37 time=30.702 ms</pre>
<p style="font-weight: 400">The beauty of this is that I can now override the <kbd>CMD</kbd> part that I have defined in the <kbd>Dockerfile</kbd> (remember, it was <kbd>["-c", "3","8.8.8.8"]</kbd>) when I create a new container by adding the new values at the end of the <kbd>docker container run</kbd> expression, like this:</p>
<pre class="mce-root"><strong>$ docker container run --rm -it pinger -w 5 127.0.0.1</strong></pre>
<p style="font-weight: 400">This will now cause the container to ping the loopback for 5 seconds.</p>
<p style="font-weight: 400">If we want to override what's defined in the <kbd>ENTRYPOINT</kbd> in the <kbd>Dockerfile</kbd>, we need to use the <kbd>--entrypoint</kbd> parameter in the <kbd>docker container run</kbd> expression. Let's say we want to execute a shell in the container instead of the <kbd>ping</kbd> command. We could do so by using the following command:</p>
<pre class="mce-root"><strong>$ docker container run --rm -it --entrypoint /bin/sh pinger</strong></pre>
<p style="font-weight: 400">We will then find ourselves inside the container. Type <kbd>exit</kbd> to leave the container.</p>
<p style="font-weight: 400">As I already mentioned, we do not necessarily have to follow best practices and define the command through <kbd>ENTRYPOINT</kbd> and the parameters through <kbd>CMD</kbd>; we can instead enter the whole expression as a value of <kbd>CMD</kbd> and it will work, as shown in the following code block:</p>
<pre class="mce-root">FROM alpine:3.10<br/>CMD wget -O - http://www.google.com</pre>
<p style="font-weight: 400">Here, I have even used the shell form to define the <kbd>CMD</kbd>. But what does really happen in this situation where <kbd>ENTRYPOINT</kbd> is undefined? If you leave <kbd>ENTRYPOINT</kbd> undefined, then it will have the default value of <kbd>/bin/sh -c</kbd>, and whatever the value of <kbd>CMD</kbd> is will be passed as a string to the shell command. The preceding definition would thereby result in entering the following code to run the process inside the container:</p>
<pre class="mce-root"><strong>/bin/sh -c "wget -O - http://www.google.com"</strong></pre>
<p style="font-weight: 400">Consequently, <kbd>/bin/sh</kbd> is the main process running inside the container, and it will start a new child process to run the <kbd>wget</kbd> utility.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">A complex Dockerfile</h1>
                
            
            
                
<p style="font-weight: 400">We have discussed the most important keywords commonly used in Dockerfiles. Let's look at a realistic, and somewhat complex example of a <kbd>Dockerfile</kbd>. The interested reader might note that it looks very similar to the first <kbd>Dockerfile</kbd> that we presented in this chapter. Here is the content:</p>
<pre class="mce-root">FROM node:12.5-stretch<br/>RUN mkdir -p /app<br/>WORKDIR /app<br/>COPY package.json /app/<br/>RUN npm install<br/>COPY . /app<br/>ENTRYPOINT ["npm"]<br/>CMD ["start"]</pre>
<p style="font-weight: 400">OK; so, what is happening here? Evidently, this is a <kbd>Dockerfile</kbd> that is used to build an image for a Node.js application; we can deduce this from the fact that the <kbd>node:12.5-stretch</kbd> base image is used. Then, the second line is an instruction to create an <kbd>/app</kbd> folder in the filesystem of the image. The third line defines the working directory or context in the image to be this new <kbd>/app</kbd> folder. Then, on line four, we copy a <kbd>package.json</kbd> file into the <kbd>/app</kbd> folder inside the image. After this, on line five, we execute the <kbd>npm install</kbd> command inside the container; remember, our context is the <kbd>/app</kbd> folder, and thus, <kbd>npm</kbd> will find the <kbd>package.json</kbd> file there that we copied on line four.</p>
<p style="font-weight: 400">After all the Node.js dependencies are installed, we copy the rest of the application files from the current folder of the host into the <kbd>/app</kbd> folder of the image.</p>
<p style="font-weight: 400">Finally, on the last two lines, we define what the startup command will be when a container is run from this image. In our case, it is <kbd>npm start</kbd>, which will start the Node.js application.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Building an image</h1>
                
            
            
                
<p>Let's look at a concrete example and build a simple Docker image, as follows:</p>
<ol>
<li style="font-weight: 400">In your home directory, create a <kbd>fod </kbd>folder (short for <strong>Fundamentals of Docker</strong>) with a  <kbd>ch04</kbd> subfolder in it, and navigate to this folder, like this:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ mkdir -p ~/fod/ch04 &amp;&amp; </strong><strong>cd ~/fod/ch04</strong></pre>
<ol start="2">
<li style="font-weight: 400">In the preceding folder, create a <kbd>sample1</kbd> subfolder and navigate to it, like this:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ mkdir sample1 &amp;&amp; cd sample1</strong></pre>
<ol start="3">
<li style="font-weight: 400">Use your favorite editor to create a file called <kbd>Dockerfile</kbd> inside this sample folder, with the following content:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>FROM centos:7</strong><br/><strong>RUN yum install -y wget</strong></pre>
<p style="padding-left: 60px">4. Save the file and exit your editor.</p>
<p style="padding-left: 60px">5. Back in the Terminal window, we can now build a new container image using the preceding <kbd>Dockerfile</kbd> as a manifest or construction plan, like this:</p>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker image build -t my-centos .</strong></pre>
<p style="font-weight: 400;padding-left: 60px">Please note that there is a period at the end of the preceding command. This command means that the Docker builder is creating a new image called <kbd>my-centos</kbd> using the <kbd>Dockerfile</kbd> that is present in the current directory. Here, the period at the end of the command stands for <em>current directory</em>. We could also write the preceding command as follows, with the same result:</p>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker image build -t my-centos -f Dockerfile .</strong></pre>
<p style="font-weight: 400;padding-left: 60px">But we can omit the <kbd>-f </kbd> parameter, since the builder assumes that the <kbd>Dockerfile</kbd> is literally called <kbd>Dockerfile</kbd>. We only ever need the <kbd>-f</kbd> parameter if our <kbd>Dockerfile</kbd> has a different name or is not located in the current directory.</p>
<p style="font-weight: 400;padding-left: 60px">The preceding command gives us this (shortened) output:</p>
<pre style="padding-left: 60px" class="mce-root">Sending build context to Docker daemon 2.048kB<br/>Step 1/2 : FROM centos:7<br/>7: Pulling from library/centos<br/>af4b0a2388c6: Pull complete<br/>Digest: sha256:2671f7a3eea36ce43609e9fe7435ade83094291055f1c96d9d1d1d7c0b986a5d<br/>Status: Downloaded newer image for centos:7<br/>---&gt; ff426288ea90<br/>Step 2/2 : RUN yum install -y wget<br/>---&gt; Running in bb726903820c<br/>Loaded plugins: fastestmirror, ovl<br/>Determining fastest mirrors<br/>* base: mirror.dal10.us.leaseweb.net<br/>* extras: repos-tx.psychz.net<br/>* updates: pubmirrors.dal.corespace.com<br/>Resolving Dependencies<br/>--&gt; Running transaction check<br/>---&gt; Package wget.x86_64 0:1.14-15.el7_4.1 will be installed<br/>...<br/>Installed:<br/>  wget.x86_64 0:1.14-15.el7_4.1<br/>Complete!<br/>Removing intermediate container bb726903820c<br/>---&gt; bc070cc81b87<br/>Successfully built bc070cc81b87<br/>Successfully tagged my-centos:latest</pre>
<p style="font-weight: 400;padding-left: 60px">Let's analyze this output, as follows:</p>
<ol style="font-weight: 400">
<li>First, we have the following line:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">Sending build context to Docker daemon 2.048kB</pre>
<p style="padding-left: 60px">The first thing the builder does is package the files in the current build context, excluding the files and folder mentioned in the <kbd>.dockerignore</kbd> file (if present), and sends the resulting <kbd>.tar</kbd> file to the <kbd>Docker daemon</kbd>.</p>
<ol style="font-weight: 400" start="2">
<li>Next, we have the following lines:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">Step 1/2 : FROM centos:7<br/>7: Pulling from library/centos<br/>af4b0a2388c6: Pull complete<br/>Digest: sha256:2671f7a...<br/>Status: Downloaded newer image for centos:7<br/>---&gt; ff426288ea90</pre>
<p style="padding-left: 60px">The first line tells us which step of the <kbd>Dockerfile</kbd> the builder is currently executing. Here, we only have two statements in the <kbd>Dockerfile</kbd>, and we are on S<em>tep 1</em> of <em>2</em>. We can also see what the content of that section is. Here, it is the declaration of the base image, on top of which we want to build our custom image. What the builder then does is pull this image from Docker Hub, if it is not already available in the local cache. The last line of the preceding code snippet indicates which ID the just-built image layer gets assigned by the builder.</p>
<ol style="font-weight: 400" start="3">
<li>Now, follow the next step. I have shortened it even more than the preceding one to concentrate on the essential part:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>Step 2/2 : RUN yum install -y wget</strong><br/><strong>---&gt; Running in bb726903820c</strong><br/><strong>...</strong><br/><strong>...</strong><br/><strong>Removing intermediate container bb726903820c</strong><br/><strong>---&gt; bc070cc81b87</strong></pre>
<p style="padding-left: 60px">Here, again, the first line indicates to us that we are in S<em>tep 2</em> of <em>2</em>. It also shows us the respective entry from the <kbd>Dockerfile</kbd>. On line two, we can see <kbd>Running in bb726903820c</kbd>, which tells us that the builder has created a container with ID <kbd>bb726903820c</kbd>, inside which it executes the <kbd>RUN </kbd>command.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">We have omitted the output of the <kbd>yum install -y wget </kbd>command in the snippet since it is not important in this section. When the command is finished, the builder stops the container, commits it to a new layer, and then removes the container. The new layer has ID <kbd>bc070cc81b87</kbd>, in this particular case.</p>
<ol style="font-weight: 400" start="4">
<li>At the very end of the output, we encounter the following two lines:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>Successfully built bc070cc81b87</strong><br/><strong>Successfully tagged my-centos:latest</strong></pre>
<p style="padding-left: 60px">This tells us that the resulting custom image has been given the ID <kbd>bc070cc81b87</kbd>, and has been tagged with the name <kbd>my-centos:latest</kbd>.</p>
<p style="font-weight: 400">So, how does the builder work, exactly? It starts with the base image. From this base image, once downloaded into the local cache, the builder creates a container and runs the first statement of the <kbd>Dockerfile</kbd> inside this container. Then, it stops the container and persists the changes made in the container into a new image layer. The builder then creates a new container from the base image and the new layer and runs the second statement inside this new container. Once again, the result is committed to a new layer. This process is repeated until the very last statement in the <kbd>Dockerfile</kbd> is encountered. After having committed the last layer of the new image, the builder creates an ID for this image and tags the image with the name we provided in the <kbd>build </kbd>command, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-939 image-border" src="img/13c9e699-35e5-40dc-b064-d64472d15f03.png" style="width:29.50em;height:23.83em;"/></p>
<p>The image build process visualized</p>
<p>Now that we have analyzed how the build process of a Docker image works and what steps are involved, let's talk about how to further improve this by introducing multi-step builds.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Multi-step builds</h1>
                
            
            
                
<p style="font-weight: 400">To demonstrate why a <kbd>Dockerfile</kbd> with multiple build steps is useful, let's make an example <kbd>Dockerfile</kbd>. Let's take a Hello World application written in C. Here is the code found inside the <kbd>hello.c</kbd> file:</p>
<pre class="mce-root">#include &lt;stdio.h&gt;<br/>int main (void)<br/>{<br/>    printf ("Hello, world!\n");<br/>    return 0;<br/>}</pre>
<p class="mce-root">Follow along to experience the advantages of a multi-step build:</p>
<ol>
<li style="font-weight: 400">To containerize this application we first write a <kbd>Dockerfile</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">FROM alpine:3.7<br/>RUN apk update &amp;&amp;<br/>apk add --update alpine-sdk<br/>RUN mkdir /app<br/>WORKDIR /app<br/>COPY . /app<br/>RUN mkdir bin<br/>RUN gcc -Wall hello.c -o bin/hello<br/>CMD /app/bin/hello</pre>
<ol start="2">
<li style="font-weight: 400">Next, let's build this image:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker image build -t hello-world .</strong></pre>
<p style="font-weight: 400;padding-left: 60px">This gives us a fairly long output since the builder has to install the Alpine <strong>Software Development Kit</strong> (<strong>SDK</strong>), which, among other tools, contains the C++ compiler we need to build the application.</p>
<ol start="3">
<li style="font-weight: 400">Once the build is done, we can list the image and see its size shown, as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker image ls | grep hello-world</strong><br/>hello-world   latest   e9b...   2 minutes ago   176MB</pre>
<p style="font-weight: 400;padding-left: 60px">With a size of 176 MB, the resulting image is way too big. In the end, it is just a Hello World application. The reason for it being so big is that the image not only contains the Hello World binary but also all the tools to compile and link the application from the source code. But this is really not desirable when running the application, say, in production. Ideally, we only want to have the resulting binary in the image and not a whole SDK.</p>
<p style="font-weight: 400">It is precisely for this reason that we should define Dockerfiles as multi-stage. We have some stages that are used to build the final artifacts, and then a final stage, where we use the minimal necessary base image and copy the artifacts into it. This results in very small Docker images. Have a look at this revised <kbd>Dockerfile</kbd>:</p>
<pre class="mce-root">FROM alpine:3.7 AS build<br/>RUN apk update &amp;&amp; \<br/>    apk add --update alpine-sdk<br/>RUN mkdir /app<br/>WORKDIR /app<br/>COPY . /app<br/>RUN mkdir bin<br/>RUN gcc hello.c -o bin/hello<br/> <br/>FROM alpine:3.7<br/>COPY --from=build /app/bin/hello /app/hello<br/>CMD /app/hello</pre>
<p style="font-weight: 400">Here, we have the first stage with a <kbd>build</kbd> alias that is used to compile the application, and then the second stage uses the same <kbd>alpine:3.7</kbd> base image but does not install the SDK, and only copies the binary from the <kbd>build</kbd> stage, using the <kbd>--from</kbd> parameter, into this final image:</p>
<ol>
<li style="font-weight: 400">Let's build the image again, as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker image build -t hello-world-small .</strong></pre>
<ol start="2">
<li style="font-weight: 400">When we compare the sizes of the images, we get the following output:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker image ls | grep hello-world</strong><br/>hello-world-small  latest   f98...   20 seconds ago   4.16MB<br/>hello-world        latest   469...   10 minutes ago   176MB</pre>
<p style="font-weight: 400;padding-left: 60px">We have been able to reduce the size from 176 MB down to 4 MB. This is a reduction in size by a factor of 40. A smaller image has many advantages, such as a smaller attack surface area for hackers, reduced memory and disk consumption, faster startup times of the corresponding containers, and a reduction of the bandwidth needed to download the image from a registry, such as Docker Hub.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Dockerfile best practices</h1>
                
            
            
                
<p style="font-weight: 400">There are a few recommended best practices to consider when authoring a <kbd>Dockerfile</kbd>, which are as follows:</p>
<ul style="font-weight: 400">
<li>First and foremost, we need to consider that containers are meant to be ephemeral. By ephemeral, we mean that a container can be stopped and destroyed, and a new one built and put in place with an absolute minimum of setup and configuration. That means that we should try hard to keep the time that is needed to initialize the application running inside the container at a minimum, as well as the time needed to terminate or clean up the application.</li>
<li>The next best practice tells us that we should order the individual commands in the <kbd>Dockerfile</kbd> so that we leverage caching as much as possible. Building a layer of an image can take a considerable amount of time—sometimes many seconds, or even minutes. While developing an application, we will have to build the container image for our application multiple times. We want to keep the build times at a minimum.</li>
</ul>
<p>When we're rebuilding a previously built image, the only layers that are rebuilt are the ones that have changed, but if one layer needs to be rebuilt, all subsequent layers also need to be rebuilt. This is very important to remember. Consider the following example:</p>
<pre class="mce-root">FROM node:9.4<br/>RUN mkdir -p /app<br/>WORKIR /app<br/>COPY . /app<br/>RUN npm install<br/>CMD ["npm", "start"]</pre>
<p>In this example, the <kbd>npm install</kbd> command on line five of the <kbd>Dockerfile</kbd> usually takes the longest. A classical Node.js application has many external dependencies, and those are all downloaded and installed in this step. This can take minutes until it is done. Therefore, we want to avoid running <kbd>npm install </kbd>each time we rebuild the image, but a developer changes their source code all the time during the development of an application. That means that line four, the result of the <kbd>COPY </kbd>command, changes every time, and thus this layer has to be rebuilt. But as we discussed previously, that also means that all subsequent layers have to be rebuilt, which—in this case—includes the <kbd>npm install</kbd> command. To avoid this, we can slightly modify the <kbd>Dockerfile</kbd> and have the following:</p>
<pre class="mce-root">FROM node:9.4<br/>RUN mkdir -p /app<br/>WORKIR /app<br/>COPY package.json /app/<br/>RUN npm install<br/>COPY . /app<br/>CMD ["npm", "start"]</pre>
<p>What we have done here is, on line four, we only copied the single file that the <kbd>npm install</kbd> command needs as a source, which is the <kbd>package.json </kbd>file. This file rarely changes in a typical development process. As a consequence, the <kbd>npm install </kbd>command also has to be executed only when the <kbd>package.json</kbd> file changes. All the remaining, frequently changed content is added to the image after the <kbd>npm install</kbd> command.</p>
<ul style="font-weight: 400">
<li>A further best practice is to keep the number of layers that make up your image relatively small. The more layers an image has, the more the graph driver needs to work to consolidate the layers into a single root filesystem for the corresponding container. Of course, this takes time, and thus the fewer layers an image has, the faster the startup time for the container can be.</li>
</ul>
<p>But how can we keep our number of layers low? Remember that in a <kbd>Dockerfile</kbd>, each line that starts with a keyword such as <kbd>FROM</kbd>, <kbd>COPY</kbd>, or <kbd>RUN</kbd> creates a new layer. The easiest way to reduce the number of layers is to combine multiple individual <kbd>RUN</kbd> commands into a single one. For example, say that we had the following in a <kbd>Dockerfile</kbd>:</p>
<pre class="mce-root"><strong>RUN apt-get update</strong><br/><strong>RUN apt-get install -y ca-certificates</strong><br/><strong>RUN rm -rf /var/lib/apt/lists/*</strong></pre>
<p>We could combine these into a single concatenated expression, as follows:</p>
<pre class="mce-root"><strong>RUN apt-get update \</strong><br/>    <strong>&amp;&amp; apt-get install -y ca-certificates \</strong><br/>    <strong>&amp;&amp; rm -rf /var/lib/apt/lists/*</strong></pre>
<p>The former will generate three layers in the resulting image, while the latter only creates a single layer.</p>
<p style="font-weight: 400">The next three best practices all result in smaller images. Why is this important? Smaller images reduce the time and bandwidth needed to download the image from a registry. They also reduce the amount of disk space needed to store a copy locally on the Docker host and the memory needed to load the image. Finally, smaller images also mean a smaller attack surface for hackers. Here are the best practices mentioned:</p>
<ul style="font-weight: 400">
<li>The first best practice that helps to reduce the image size is to use a <kbd>.dockerignore</kbd> file. We want to avoid copying unnecessary files and folders into an image, to keep it as lean as possible. A <kbd>.dockerignore</kbd> file works in exactly the same way as a <kbd>.gitignore</kbd> file, for those who are familiar with Git. In a <kbd>.dockerignore</kbd> file, we can configure patterns to exclude certain files or folders from being included in the context when building the image.</li>
<li>The next best practice is to avoid installing unnecessary packages into the filesystem of the image. Once again, this is to keep the image as lean as possible.</li>
<li>Last but not least, it is recommended that you use multi-stage builds so that the resulting image is as small as possible and only contains the absolute minimum needed to run your application or application service.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Saving and loading images</h1>
                
            
            
                
<p style="font-weight: 400">The third way to create a new container image is by importing or loading it from a file. A container image is nothing more than a tarball. To demonstrate this, we can use the <kbd>docker image save </kbd> command to export an existing image to a tarball, like this:</p>
<pre class="mce-root"><strong>$ docker image save -o ./backup/my-alpine.tar my-alpine</strong></pre>
<p style="font-weight: 400">The preceding command takes our <kbd>my-alpine</kbd> image that we previously built and exports it into a file called  <kbd>./backup/my-alpine.tar</kbd>.</p>
<p class="mce-root"/>
<p style="font-weight: 400">If, on the other hand, we have an existing tarball and want to import it as an image into our system, we can use the <kbd>docker image load</kbd> command, as follows:</p>
<pre class="mce-root"><strong>$ docker image load -i ./backup/my-alpine.tar<br/></strong></pre>
<p>In the next section, we will discuss how we can create Docker images for existing legacy applications, and thus run them in a container, and profit from this.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Lift and shift: Containerizing a legacy app</h1>
                
            
            
                
<p>We can't always start from scratch and develop a brand new application. More often than not, we find ourselves with a huge portfolio of traditional applications that are up and running in production and provide mission-critical value to the company or the customers of the company. Often, those applications are organically grown and very complex. Documentation is sparse, and nobody really wants to touch such an application. Often, the saying <em>Never touch a running system</em> applies. Yet, market needs change, and with that arises the need to update or rewrite those apps. Often, a complete rewrite is not possible due to the lack of resources and time, or due to the excessive cost. What are we going to do about those applications? Could we possibly Dockerize them and profit from benefits introduced by containers?</p>
<p>It turns out we can. In 2017, Docker introduced a program called <strong>Modernize Traditional Apps</strong> (<strong>MTA</strong>) to their enterprise customers, which in essence promised to help those customers to take their existing or traditional Java and .NET applications and containerize them, without the need to change a single line of code. The focus of MTA was on Java and .NET applications since those made up the lion's share of the traditional applications in a typical enterprise. But the same is possible for any application that was written in—say—C, C++, Python, Node.js, Ruby, PHP, or Go, to just name a few other languages and platforms.</p>
<p>Let's imagine such a legacy application for a moment. Assume we have an old Java application written 10 years ago, and continuously updated during the following 5 years. The application is based on Java SE 6, which came out in December 2006. It uses environment variables and property files for configuration. Secrets such as username and passwords used in the database connection strings are pulled from a secrets keystore, such as HashiCorp's Vault. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Analysis of external dependencies</h1>
                
            
            
                
<p>One of the first steps in the modernization process is to discover and list all external dependencies of the legacy application.</p>
<p>We need to ask ourselves questions like the following:</p>
<ol>
<li>Does it use a database? If yes, which one? What does the connection string look like?</li>
<li>Does it use external APIs such as credit card approval or geo-mapping APIs? What are the API keys and key secrets?</li>
<li>Is it consuming from or publishing to an <strong>Enterprise Service Bus</strong> (<strong>ESB</strong>)?</li>
</ol>
<p>These are just a few possible dependencies that come to mind. Many more exist. These are the seams of the application to the outer world, and we need to be aware of them and create an inventory.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Source code and build instructions</h1>
                
            
            
                
<p>The next step is to locate all the source code and other assets, such as images and CSS and HTML files that are part of the application. Ideally, they should be located in a single folder. This folder will be the root of our project and can have as many subfolders as needed. This project root folder will be the context during the build of the container image we want to create for our legacy application. Remember, the Docker builder only includes files in the build that are part of that context; in our case, that is the root project folder.</p>
<p>There is, though, an option to download or copy files during the build from different locations, using the <kbd>COPY</kbd> or <kbd>ADD</kbd> commands. Please refer to the online documentation for the exact details on how to use these two commands. This option is useful if the sources for your legacy application cannot be easily contained in a single, local folder.</p>
<p>Once we are aware of all the parts that are contributing to the final application, we need to investigate how the application is built and packaged. In our case, this is most probably done by using Maven. Maven is the most popular build automation tool for Java, and has been—and still is—used in most enterprises that are developing Java applications. In the case of a legacy .NET application, it is most probably done by using the MSBuild tool; and in the case of a C/C++ application, Make would most likely be used.</p>
<p>Once again, let's extend our inventory and write down the exact build commands used. We will need this information later on when authoring the <kbd>Dockerfile</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Configuration</h1>
                
            
            
                
<p>Applications need to be configured. Information provided during configuration can be—for example— the type of application logging to use, connection strings to databases, hostnames to services such as ESBs or URIs to external APIs, to name just a few.</p>
<p>We can differentiate a few types of configurations, as follows:</p>
<ul>
<li><strong>Build time</strong>: This is the information needed during the build of the application and/or its Docker image. It needs to be available when we create the Docker images.</li>
<li><strong>Environment</strong>: This is configuration information that varies with the environment in which the application is running—for example, DEVELOPMENT versus STAGING or PRODUCTION. This kind of configuration is applied to the application when a container with the app starts—for example, in production.</li>
<li><strong>Runtime</strong>: This is information that the application retrieves during runtime, such as secrets to access an external API.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Secrets</h1>
                
            
            
                
<p>Every mission-critical enterprise application needs to deal with secrets in some form or another. The most familiar secrets are part of the connection information needed to access databases that are used to persist the data produced by or used by the application. Other secrets include the credentials needed to access external APIs, such as a credit score lookup API. It is important to note that, here, we are talking about secrets that have to be provided by the application itself to the service providers the application uses or depends on, and not secrets provided by the users of the application. The actor here is our application, which needs to be authenticated and authorized by external authorities and service providers.</p>
<p>There are various ways traditional applications got their secrets. The worst and most insecure way of providing secrets is by hardcoding them or reading them from configuration files or environment variables, where they are available in cleartext. A much better way is to read the secrets during runtime from a special secrets store that persists the secrets encrypted and provides them to the application over a secure connection, such as <strong>Transport Layer Security</strong> (<strong>TLS</strong>).</p>
<p>Once again, we need to create an inventory of all secrets that our application uses and the way it procures them. Is it through environment variable or configuration files, or is it by accessing an external keystore, such as HashiCorp's Vault?</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Authoring the Dockerfile</h1>
                
            
            
                
<p>Once we have a complete inventory of all the items discussed in the previous few sections, we are ready to author our <kbd>Dockerfile</kbd>. But I want to warn you: don't expect this to be a one-shot-and-go task. You may need several iterations until you have crafted your final <kbd>Dockerfile</kbd>. The <kbd>Dockerfile</kbd> may be rather long and ugly-looking, but that's not a problem, as long as we get a working Docker image. We can always fine-tune the <kbd>Dockerfile</kbd> once we have a working version.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The base image</h1>
                
            
            
                
<p>Let's start by identifying the base image we want to use and build our image from. Is there an official Java image available that is compatible with our requirements? Remember that our imaginary application is based on Java SE 6. If such a base image is available, then let's use that one. Otherwise, we want to start with a Linux distro such as Red Hat, Oracle, or Ubuntu. In the latter case, we will use the appropriate package manager of the distro (<kbd>yum</kbd>, <kbd>apt</kbd>, or another) to install the desired versions of Java and Maven. For this, we use the <kbd>RUN</kbd> keyword in the <kbd>Dockerfile</kbd>. Remember, <kbd>RUN</kbd> gives us the possibility to execute any valid Linux command in the image during the build process.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Assembling the sources</h1>
                
            
            
                
<p>In this step, we make sure all source files and other artifacts needed to successfully build the application are part of the image. Here, we mainly use the two keywords of the <kbd>Dockerfile</kbd>: <kbd>COPY</kbd> and <kbd>ADD</kbd>. Initially, the structure of the source inside the image should look exactly the same as on the host, to avoid any build problems. Ideally, you would have a single <kbd>COPY</kbd> command that copies all of the root project folder from the host into the image. The corresponding <kbd>Dockerfile</kbd> snippet could then look as simple as this:</p>
<pre>WORKDIR /app<br/>COPY . .</pre>
<p>Don't forget to also provide a <kbd>.dockerignore</kbd> file located in the project root folder, which lists all the files and (sub-) folders of the project root folder that should not be part of the build context.</p>
<p>As mentioned earlier, you can also use the <kbd>ADD</kbd> keyword to download sources and other artifacts into the Docker image that are not located in the build context but somewhere reachable by a URI, as shown here:</p>
<pre>ADD http://example.com/foobar ./ </pre>
<p>This would create a <kbd>foobar</kbd> folder in the image's working folder and copy all the contents from the URI.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Building the application</h1>
                
            
            
                
<p>In this step, we make sure to create the final artifacts that make up our executable legacy application. Often, this is a JAR or WAR file, with or without some satellite JARs. This part of the <kbd>Dockerfile</kbd> should exactly mimic the way you traditionally used to build an application before containerizing them. Thus, if using Maven as the build automation tool, the corresponding snippet of the <kbd>Dockerfile</kbd> could look as simple as this:</p>
<pre>RUN mvn --clean install</pre>
<p>In this step, we may also want to list the environment variables the application uses, and provide sensible defaults. But never provide default values for environment variables that provide secrets to the application such as the database connection string! Use the <kbd>ENV</kbd> keyword to define your variables, like this:</p>
<pre>ENV foo=bar<br/>ENV baz=123</pre>
<p>Also, declare all ports that the application is listening on and that need to be accessible from outside of the container via the <kbd>EXPOSE</kbd> keyword, like this:</p>
<pre>EXPOSE 5000<br/>EXPOSE 15672/tcp</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Defining the start command</h1>
                
            
            
                
<p>Usually, a Java application is started with a command such as <kbd>java -jar &lt;main application jar&gt;</kbd> if it is a standalone application. If it is a WAR file, then the start command may look a bit different. We can thus either define the <kbd>ENTRYPOINT</kbd> or the <kbd>CMD</kbd> to use this command. Thus, the final statement in our <kbd>Dockerfile</kbd> could look like this:</p>
<pre>ENTRYPOINT java -jar pet-shop.war</pre>
<p>Often, though, this is too simplistic, and we need to execute a few pre-run tasks. In this case, we can craft a script file that contains the series of commands that need to be executed to prepare the environment and run the application. Such a file is often called <kbd>docker-entrypoint.sh</kbd>, but you are free to name it however you want. Make sure the file is executable— for example, with the following:</p>
<pre>chmod +x ./docker-entrypoint.sh</pre>
<p> The last line of the <kbd>Dockerfile</kbd> would then look like this:</p>
<pre>ENTRYPOINT ./docker-entrypoint.sh</pre>
<p>Now that you have been given hints on how to containerize a legacy application, it is time to recap and ask ourselves: <em>Is it really worth the whole effort?</em></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Why bother?</h1>
                
            
            
                
<p>At this point, I can see you scratching your head and asking yourself: <em>Why bother?</em> Why should you take on all this seemingly huge effort just to containerize a legacy application? What are the benefits?</p>
<p>It turns out that the <strong>return on investment</strong> (<strong>ROI</strong>) is huge. Enterprise customers of Docker have publicly disclosed at conferences such as DockerCon 2018 and 2019 that they are seeing these two main benefits of Dockerizing traditional applications:</p>
<ul>
<li>More than a 50% saving in maintenance costs.</li>
<li>Up to a 90% reduction in the time between the deployments of new releases.</li>
</ul>
<p>The costs saved by reducing the maintenance overhead can be directly reinvested and used to develop new features and products. The time saved during new releases of traditional applications makes a business more agile and able to react to changing customer or market needs more quickly.</p>
<p>Now that we have discussed at length how to build Docker images, it is time to learn how we can ship those images through the various stages of the software delivery pipeline.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Sharing or shipping images</h1>
                
            
            
                
<p style="font-weight: 400">To be able to ship our custom image to other environments, we need to first give it a globally unique name. This action is often called <em>tagging</em> an image. We then need to publish the image to a central location from which other interested or entitled parties can pull it. These central locations are called <em>image registries</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Tagging an image</h1>
                
            
            
                
<p style="font-weight: 400">Each image has a so-called <em>tag</em>. A tag is often used to version images, but it has a broader reach than just being a version number. If we do not explicitly specify a tag when working with images, then Docker automatically assumes we're referring to the <kbd>latest</kbd> tag. This is relevant when pulling an image from Docker Hub, as in the following example:</p>
<pre class="mce-root"><strong>$ docker image pull alpine</strong></pre>
<p style="font-weight: 400">The preceding command will pull the <kbd>alpine:latest</kbd> image from Docker Hub. If we want to explicitly specify a tag, we do so like this:</p>
<pre class="mce-root"><strong>$ docker image pull alpine:3.5</strong></pre>
<p style="font-weight: 400">This will now pull the <kbd>alpine </kbd>image that has been tagged with <kbd>3.5</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Image namespaces</h1>
                
            
            
                
<p style="font-weight: 400">So far, we have been pulling various images and haven't been worrying so much about where those images originated from. Your Docker environment is configured so that, by default, all images are pulled from Docker Hub. We also only pulled so-called official images from Docker Hub, such as <kbd>alpine</kbd> or <kbd>busybox</kbd>.</p>
<p style="font-weight: 400">Now, it is time to widen our horizon a bit and learn about how images are namespaced. The most generic way to define an image is by its fully qualified name, which looks as follows:</p>
<pre class="mce-root">&lt;registry URL&gt;/&lt;User or Org&gt;/&lt;name&gt;:&lt;tag&gt;</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mce-root">Let's look at this in a bit more detail:</p>
<ul style="font-weight: 400">
<li> <kbd>&lt;registry URL&gt;</kbd>: This is the URL to the registry from which we want to pull the image. By default, this is <kbd>docker.io</kbd>. More generally, this could be <kbd>https://registry.acme.com</kbd>.</li>
</ul>
<p style="padding-left: 60px">Other than Docker Hub, there are quite a few public registries out there that you could pull images from. The following is a list of some of them, in no particular order:</p>
<ul style="font-weight: 400">
<li style="list-style-type: none">
<ul>
<li>Google, at <a href="https://cloud.google.com/container-registry" target="_blank">https://cloud.google.com/container-registry</a></li>
</ul>
<ul>
<li>Amazon AWS <strong>Amazon Elastic Container Registry</strong> (<strong>ECR</strong>), at <a href="https://aws.amazon.com/ecr/" target="_blank">https://aws.amazon.com/ecr/</a></li>
<li>Microsoft Azure, at <a href="https://azure.microsoft.com/en-us/services/container-registry/" target="_blank">https://azure.microsoft.com/en-us/services/container-registry/</a></li>
<li>Red Hat, at <a href="https://access.redhat.com/containers/" target="_blank">https://access.redhat.com/containers/</a></li>
<li>Artifactory, at <a href="https://jfrog.com/integration/artifactory-docker-registry/" target="_blank">https://jfrog.com/integration/artifactory-docker-registry/</a></li>
</ul>
</li>
<li><kbd>&lt;User or Org&gt;</kbd>: This is the private Docker ID of either an individual or an organization defined on Docker Hub—or any other registry, for that matter—such as <kbd>microsoft</kbd> or <kbd>oracle</kbd>.</li>
<li><kbd>&lt;name&gt;</kbd>: This is the name of the image, which is often also called a repository.</li>
<li><kbd>&lt;tag&gt;</kbd>: This is the tag of the image.</li>
</ul>
<p style="font-weight: 400">Let's look at an example, as follows:</p>
<pre class="mce-root">https://registry.acme.com/engineering/web-app:1.0</pre>
<p style="font-weight: 400">Here, we have an image, <kbd>web-app</kbd>, that is tagged with version <kbd>1.0</kbd> and belongs to the <kbd>engineering</kbd> organization on the private registry at <kbd>https://registry.acme.com</kbd>.</p>
<p style="font-weight: 400">Now, there are some special conventions:</p>
<ul style="font-weight: 400">
<li>If we omit the registry URL, then Docker Hub is automatically taken.</li>
<li>If we omit the tag, then <kbd>latest</kbd> is taken.</li>
<li>If it is an official image on Docker Hub, then no user or organization namespace is needed.</li>
</ul>
<p style="font-weight: 400">Here are a few samples in tabular form:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr style="height: 54.5313px">
<td style="height: 54.5313px">
<p class="CDPAlignCenter CDPAlign"><strong>Image</strong></p>
</td>
<td style="height: 54.5313px">
<p class="CDPAlignCenter CDPAlign"><strong>Description</strong></p>
</td>
</tr>
<tr style="height: 65px">
<td style="height: 65px">
<p><kbd>alpine</kbd></p>
</td>
<td style="height: 65px">
<p>Official alpine image on Docker Hub with the latest tag.</p>
</td>
</tr>
<tr style="height: 98px">
<td style="height: 98px">
<p><kbd>ubuntu:19.04</kbd></p>
</td>
<td style="height: 98px">
<p>Official <kbd>ubuntu</kbd> image on Docker Hub with the <kbd>19.04</kbd> tag or version.</p>
</td>
</tr>
<tr style="height: 98px">
<td style="height: 98px">
<p><kbd>microsoft/nanoserver</kbd></p>
</td>
<td style="height: 98px">
<p><kbd>nanoserver</kbd> image of Microsoft on Docker Hub with the <kbd>latest</kbd> tag.</p>
</td>
</tr>
<tr style="height: 98px">
<td style="height: 98px">
<p><kbd>acme/web-api:12.0</kbd></p>
</td>
<td style="height: 98px">
<p><kbd>web-api</kbd> image version <kbd>12.0</kbd> associated with the <kbd>acme</kbd> org. The image is on Docker Hub.</p>
</td>
</tr>
<tr style="height: 130px">
<td style="height: 130px">
<p><kbd>gcr.io/gnschenker/sample-app:1.1</kbd></p>
</td>
<td style="height: 130px">
<p><kbd>sample-app</kbd> image with the <kbd>1.1</kbd> tag belonging to an individual with the <kbd>gnschenker</kbd> ID on Google's container registry.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Now that we know how the fully qualified name of a Docker image is defined and what its parts are, let's talk about some special images we can find on Docker Hub.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Official images</h1>
                
            
            
                
<p style="font-weight: 400">In the preceding table, we mentioned <em>official image</em> a few times. This needs an explanation. Images are stored in repositories on the Docker Hub registry. Official repositories are a set of repositories hosted on Docker Hub that are curated by individuals or organizations that are also responsible for the software packaged inside the image. Let's look at an example of what that means. There is an official organization behind the Ubuntu Linux distro. This team also provides official versions of Docker images that contain their Ubuntu distros.</p>
<p style="font-weight: 400">Official images are meant to provide essential base OS repositories, images for popular programming language runtimes, frequently used data storage, and other important services.</p>
<p style="font-weight: 400">Docker sponsors a team whose task it is to review and publish all those curated images in public repositories on Docker Hub. Furthermore, Docker scans all official images for vulnerabilities.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Pushing images to a registry</h1>
                
            
            
                
<p style="font-weight: 400">Creating custom images is all well and good, but at some point, we want to actually share or ship our images to a target environment, such as a test, <strong>quality assurance</strong> (<strong>QA</strong>), or production system. For this, we typically use a container registry. One of the most popular and public registries out there is Docker Hub. It is configured as a default registry in your Docker environment, and it is the registry from which we have pulled all our images so far.</p>
<p style="font-weight: 400">On a registry, one can usually create personal or organizational accounts. For example, my personal account at Docker Hub is <kbd>gnschenker</kbd>. Personal accounts are good for personal use. If we want to use the registry professionally, then we'll probably want to create an organizational account, such as <kbd>acme</kbd>, on Docker Hub. The advantage of the latter is that organizations can have multiple teams. Teams can have differing permissions.</p>
<p style="font-weight: 400">To be able to push an image to my personal account on Docker Hub, I need to tag it accordingly:</p>
<ol>
<li style="font-weight: 400">Let's say I want to push the latest version of Alpine to my account and give it a tag of <kbd>1.0</kbd>. I can do this in the following way:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker image tag alpine:latest gnschenker/alpine:1.0</strong></pre>
<ol start="2">
<li style="font-weight: 400">Now, to be able to push the image, I have to log in to my account, as follows:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker login -u gnschenker -p &lt;my secret password&gt;</strong></pre>
<ol start="3">
<li style="font-weight: 400">After a successful login, I can then push the image, like this:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"><strong>$ docker image push gnschenker/alpine:1.0</strong></pre>
<p style="font-weight: 400;padding-left: 60px">I will see something similar to this in the Terminal:</p>
<pre style="padding-left: 60px" class="mce-root">The push refers to repository [docker.io/gnschenker/alpine]<br/>04a094fe844e: Mounted from library/alpine<br/>1.0: digest: sha256:5cb04fce... size: 528</pre>
<p style="font-weight: 400;padding-left: 60px">For each image that we push to Docker Hub, we automatically create a repository. A repository can be private or public. Everyone can pull an image from a public repository. From a private repository, an image can only be pulled if one is logged in to the registry and has the necessary permissions configured.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p style="font-weight: 400">In this chapter, we have discussed in detail what container images are and how we can build and ship them. As we have seen, there are three different ways that an image can be created—either manually, automatically, or by importing a tarball into the system. We also learned some of the best practices commonly used when building custom images.</p>
<p style="font-weight: 400">In the next chapter, we're going to introduce Docker volumes that can be used to persist the state of a container. We'll also show how to define individual environment variables for the application running inside the container, as well as how to use files containing whole sets of configuration settings.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Questions</h1>
                
            
            
                
<p style="font-weight: 400">Please try to answer the following questions to assess your learning progress:</p>
<ol style="font-weight: 400">
<li>How would you create a Dockerfile that inherits from Ubuntu version <kbd>19.04</kbd>, and that installs <kbd>ping</kbd> and runs <kbd>ping</kbd> when a container starts? The default address to <kbd>ping</kbd> will be <kbd>127.0.0.1</kbd>.</li>
<li>How would you create a new container image that uses <kbd>alpine:latest</kbd> and installs <kbd>curl</kbd>? Name the new image <kbd>my-alpine:1.0</kbd>.</li>
<li>Create a <kbd>Dockerfile</kbd> that uses multiple steps to create an image of a Hello World app of minimal size, written in C or Go.</li>
</ol>
<p> </p>
<ol style="font-weight: 400" start="4">
<li>Name three essential characteristics of a Docker container image.</li>
<li>You want to push an image named <kbd>foo:1.0</kbd> to your <kbd>jdoe</kbd> personal account on Docker Hub. Which of the following is the right solution? </li>
</ol>
<p style="padding-left: 60px">A. <kbd>$ docker container push foo:1.0<br/></kbd>B. <kbd>$ docker image tag foo:1.0 jdoe/foo:1.0</kbd><br/>
     <kbd>$ docker image push jdoe/foo:1.0<br/></kbd>C. <kbd>$ docker login -u jdoe -p &lt;your password&gt;</kbd><br/>
     <kbd>$ docker image tag foo:1.0 jdoe/foo:1.0</kbd><br/>
     <kbd>$ docker image push jdoe/foo:1.0<br/></kbd>D. <kbd>$ docker login -u jdoe -p &lt;your password&gt;</kbd><br/>
     <kbd>$ docker container tag foo:1.0 jdoe/foo:1.0</kbd><br/>
     <kbd>$ docker container push jdoe/foo:1.0<br/></kbd> E. <kbd>$ docker login -u jdoe -p &lt;your password&gt;</kbd><br/>
     <kbd>$ docker image push foo:1.0 jdoe/foo:1.0</kbd></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Further reading</h1>
                
            
            
                
<p style="font-weight: 400">The following list of references gives you some material that dives more deeply into the topic of authoring and building container images:</p>
<ul style="font-weight: 400">
<li>Best practices for writing Dockerfiles, at<em> </em><a href="http://dockr.ly/22WiJiO" target="_blank">http://dockr.ly/22WiJiO</a></li>
<li>Using multi-stage builds, at<em> </em><a href="http://dockr.ly/2ewcUY3" target="_blank">http://dockr.ly/2ewcUY3</a></li>
<li>About storage drivers, at<em> </em><a href="http://dockr.ly/1TuWndC" target="_blank">http://dockr.ly/1TuWndC</a></li>
<li>Graphdriver plugins, at<em> </em><a href="http://dockr.ly/2eIVCab" target="_blank">http://dockr.ly/2eIVCab</a></li>
<li>User-guided caching in Docker for Mac, at<em> </em><a href="http://dockr.ly/2xKafPf" target="_blank">http://dockr.ly/2xKafPf</a></li>
</ul>


            

            
        
    </body></html>