- en: Chapter 6. Load Balancing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第六章：负载均衡
- en: No matter how we tune our Docker applications, we will reach our application's
    performance limits. Using the benchmarking techniques we discussed in the previous
    chapter, we should be able to identify the capacity of our application. In the
    near future, our Docker application's users will exceed this limit. We cannot
    turn these users away just because our Docker application cannot handle their
    requests anymore. We need to scale out our application so that it can serve our
    growing number of users.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们如何调优 Docker 应用程序，都将达到应用程序的性能极限。使用我们在上一章中讨论的基准测试技术，我们应该能够识别应用程序的容量。在不久的将来，我们的
    Docker 应用程序的用户将超过这个限制。仅仅因为我们的 Docker 应用程序无法再处理他们的请求，我们不能拒绝这些用户。我们需要扩展我们的应用程序，以便能够服务更多的用户。
- en: 'In this chapter, we will talk about how to scale out our Docker applications
    to increase our capacity. We will use load balancers, which are a key component
    in the architecture of various web scale applications. Load balancers distribute
    our application''s users to multiple Docker applications deployed in our farm
    of Docker hosts. The following steps covered in this chapter will help us accomplish
    this:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何扩展我们的 Docker 应用程序以增加容量。我们将使用负载均衡器，这是各种 Web 大规模应用程序架构中的关键组成部分。负载均衡器将我们的应用程序用户分配到多个部署在
    Docker 主机集群中的 Docker 应用程序上。本章中将介绍的以下步骤将帮助我们实现这一目标：
- en: Preparing a Docker host farm
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备 Docker 主机集群
- en: Balancing load with Nginx
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Nginx 进行负载均衡
- en: Scaling out our Docker applications
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展我们的 Docker 应用程序
- en: Managing zero downtime releases with load balancers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用负载均衡器管理零停机时间发布
- en: Preparing a Docker host farm
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备一个 Docker 主机集群
- en: A key component in load balancing our Docker application is to have a farm of
    servers to send our application's requests to. In the case of our infrastructure,
    this involves preparing a farm of Docker hosts to deploy our application to. The
    scalable way to do this is to have a common base configuration that is managed
    by configuration management software, such as Chef, as we previously covered in
    [Chapter 3,](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e "Chapter 3. Automating
    Docker Deployments with Chef") *Automating Docker Deployments with Chef*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在对 Docker 应用程序进行负载均衡时，一个关键组成部分是有一组服务器来分发应用程序的请求。在我们的基础设施中，这涉及到准备一组 Docker 主机来部署我们的应用程序。可扩展的做法是拥有一个由配置管理软件（例如
    Chef）管理的通用基础配置，正如我们在[第三章](part0022_split_000.html#KVCC1-afc4585f6623427885a0b0c8e5b2e22e
    "第三章：使用 Chef 自动化 Docker 部署")中讨论的那样，*使用 Chef 自动化 Docker 部署*。
- en: After preparing the farm of Docker hosts, it is time to prepare the application
    that we will run. In this chapter, we will scale a simple NodeJS application.
    The rest of this section will describe how this application works.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备好 Docker 主机集群后，接下来就是准备我们要运行的应用程序。在本章中，我们将扩展一个简单的 NodeJS 应用程序。接下来的部分将描述该应用程序是如何工作的。
- en: 'The web application is a small NodeJS application written in a file called
    `app.js`. For the purpose of visualizing how our application load balances, we
    will also log some information about our application and the Docker host it is
    running in. The `app.js` file will contain the following code:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 该 Web 应用程序是一个小型的 NodeJS 应用程序，代码写在名为 `app.js` 的文件中。为了可视化我们应用程序的负载均衡方式，我们还会记录一些关于应用程序和它运行的
    Docker 主机的信息。`app.js` 文件将包含以下代码：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To deploy the preceding application code, we will package it in a Docker image
    called `hubuser/app:1.0.0` with the following `Dockerfile`:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署前面的应用程序代码，我们将把它打包成一个名为 `hubuser/app:1.0.0` 的 Docker 镜像，使用以下的 `Dockerfile`：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Make sure that our Docker image is built and available at Docker Hub. This
    way, we can easily deploy it. Run this with the following command:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 确保我们的 Docker 镜像已经构建并且可以在 Docker Hub 上使用。这样，我们就可以轻松地进行部署。使用以下命令运行：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As the final step in our preparation, we will deploy our Docker application
    to three Docker hosts: `greenhost00`, `greenhost01`, and `greenhost02`. Log in
    to each of the hosts and type the following command to start the container:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作为准备工作的最后一步，我们将把 Docker 应用程序部署到三个 Docker 主机上：`greenhost00`、`greenhost01` 和 `greenhost02`。登录到每个主机，并输入以下命令以启动容器：
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Tip
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Better yet, we can write a Chef cookbook that will deploy the Docker application
    that we just wrote.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的是，我们可以编写一个 Chef 食谱，来部署我们刚才编写的 Docker 应用程序。
- en: Balancing load with Nginx
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Nginx 进行负载均衡
- en: Now that we have a pool of Docker applications to forward traffic to, we can
    prepare our load balancer. In this section, we will briefly cover Nginx, a popular
    web server that has high concurrency and performance. It is commonly used as a
    reverse proxy to forward requests to more dynamic web applications, such as the
    NodeJS one we wrote earlier. By configuring Nginx to have multiple reverse proxy
    destinations, such as our pool of Docker applications, it will balance the load
    of requests coming to it across the pool.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一个 Docker 应用池来转发流量，我们可以准备我们的负载均衡器。在本节中，我们将简要介绍 Nginx，它是一款具有高并发性和高性能的流行
    Web 服务器。它通常作为反向代理，将请求转发到更动态的 Web 应用程序，例如我们之前编写的 NodeJS 应用程序。通过配置 Nginx 使其具有多个反向代理目标（如我们的
    Docker 应用池），它将平衡发送到它的请求负载，分配到池中。
- en: In our load balancer deployment, we will deploy our Nginx Docker container in
    a Docker host called `dockerhost`. After deployment, the Nginx container will
    start forwarding to the pool of Docker hosts called `greenhost*`, which we provisioned
    in the earlier section.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的负载均衡器部署中，我们将在名为 `dockerhost` 的 Docker 主机中部署 Nginx Docker 容器。部署后，Nginx 容器将开始将流量转发到名为
    `greenhost*` 的 Docker 主机池，该池是我们在之前的章节中配置的。
- en: 'The following is a simple configuration of Nginx that will forward traffic
    to the pool of Docker applications that we deployed earlier. Save this file in
    `/root/nginx.conf` inside the `dockerhost` Docker host, as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个简单的 Nginx 配置，将流量转发到我们之前部署的 Docker 应用池。将此文件保存在 `dockerhost` Docker 主机中的
    `/root/nginx.conf`，如以下所示：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The preceding Nginx configuration file is basically composed of directives.
    Each directive has a corresponding effect on Nginx's configuration. To define
    our pool of applications, we will use the `upstream` directive to define a group
    of servers. Next, we will place the list of servers in our pool using the `server`
    directive. A server in the pool is normally defined in the `<hostname-or-ip>:<port>`
    format.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的 Nginx 配置文件基本上由指令组成。每个指令都会对 Nginx 的配置产生相应的影响。为了定义我们的应用池，我们将使用`upstream`指令来定义一组服务器。接下来，我们将使用`server`指令将服务器列表添加到我们的池中。池中的服务器通常以`<hostname-or-ip>:<port>`格式定义。
- en: Note
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The following are the references referring to the described directives mentioned
    earlier:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是提到的指令的参考文献：
- en: '`upstream`—[http://nginx.org/en/docs/http/ngx_http_upstream_module.html#upstream](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#upstream)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upstream`—[http://nginx.org/en/docs/http/ngx_http_upstream_module.html#upstream](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#upstream)'
- en: '`server`—[http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`server`—[http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server)'
- en: '`proxy_pass`—[http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proxy_pass`—[http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass)'
- en: Introductory material discussing the basics of directives can be found at [http://nginx.org/en/docs/beginners_guide.html#conf_structure](http://nginx.org/en/docs/beginners_guide.html#conf_structure).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论指令基础知识的入门材料可以在 [http://nginx.org/en/docs/beginners_guide.html#conf_structure](http://nginx.org/en/docs/beginners_guide.html#conf_structure)
    找到。
- en: 'Now that we have prepared our `nginx.conf` file, we can deploy our Nginx container
    together with this configuration. To perform this deployment, let''s run the following
    command in our `dockerhost` Docker host:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好 `nginx.conf` 文件，可以将其与 Nginx 容器一起部署。要进行此部署，请在我们的 `dockerhost` Docker
    主机中运行以下命令：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Our web application is now accessible via `http://dockerhost`. Each request
    will then be routed to one of the `hubuser/webapp:1.0.0` containers we deployed
    to our pool of Docker hosts.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 Web 应用现在可以通过 `http://dockerhost` 访问。每个请求将被路由到我们部署到 Docker 主机池中的 `hubuser/webapp:1.0.0`
    容器之一。
- en: 'To confirm our deployment, we can look at our Kibana visualization to show
    the distribution of traffic across our three hosts. To show the distribution of
    traffic, we must first generate load for our application. We can use our JMeter
    testing infrastructure described in [Chapter 5](part0035_split_000.html#11C3M2-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 5. Benchmarking"), *Benchmarking*, to achieve this. For quick testing,
    we can also generate load using a long-running command similar to the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确认我们的部署情况，我们可以查看Kibana可视化，展示流量在我们三个主机之间的分布。为了展示流量分布，我们必须首先为应用程序生成负载。我们可以使用在[第5章](part0035_split_000.html#11C3M2-afc4585f6623427885a0b0c8e5b2e22e
    "第5章。基准测试")中描述的JMeter测试基础设施，*基准测试*，来实现这一点。为了快速测试，我们还可以使用类似下面的长时间运行命令生成负载：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Recall that in the application we prepared earlier, we printed out `$HOSTNAME`
    as a part of the HTTP response. In the preceding case, the responses show the
    Docker container's hostname. Note that Docker containers get the short hash of
    their container IDs as their hostname by default. As we can note from the initial
    output of our test workload, we are getting responses from three containers.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在我们之前准备的应用程序中，我们将`$HOSTNAME`作为HTTP响应的一部分打印出来。在之前的情况下，响应显示的是Docker容器的主机名。注意，Docker容器默认将其容器ID的短哈希值作为主机名。正如我们从测试工作负载的初始输出中看到的，我们收到了来自三个容器的响应。
- en: 'We can visualize the response better in a Kibana visualization if we set up
    our logging infrastructure as we did in [Chapter 4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 4. Monitoring Docker Hosts and Containers"), *Monitoring Docker Hosts
    and Containers*. In the following screenshot, we can count the number of responses
    per minute according to the Docker host that the log entry came from:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们按照[第4章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e "第4章。监控Docker主机和容器")中所做的那样设置我们的日志基础设施，我们可以在Kibana可视化中更好地展示响应。在以下屏幕截图中，我们可以根据日志条目来自的Docker主机计算每分钟的响应数量：
- en: '![Balancing load with Nginx](img/00032.jpeg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![使用Nginx进行负载均衡](img/00032.jpeg)'
- en: 'We can note in the preceding figure that our workload gets distributed evenly
    by Nginx to our three Docker hosts: **greenhost00**, **greenhost01**, and **greenhost02**.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从前面的图中注意到，Nginx将我们的工作负载均匀地分配到三个Docker主机：**greenhost00**、**greenhost01**和**greenhost02**。
- en: Tip
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'To properly visualize our deployment in Kibana we have to annotate our Docker
    containers and filter these log entries in Logstash so that they get properly
    annotated to Elasticsearch. We can do this via the following steps:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在Kibana中正确地可视化我们的部署，我们必须对Docker容器进行注释，并在Logstash中过滤这些日志条目，以便它们能够正确地注释到Elasticsearch。我们可以通过以下步骤实现：
- en: 'First, we will make sure that we use the `syslog-tag` option when deploying
    our Docker container. This makes our application easier to filter out later in
    Logstash. Run the following code:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要确保在部署Docker容器时使用`syslog-tag`选项。这样可以使我们以后在Logstash中过滤应用程序时更容易。运行以下代码：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'With this, Logstash will receive our Docker container''s log entries with the
    `docker/webapp` tag. We can then use a Logstash `filter` as follows to get this
    information in Elasticsearch:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，Logstash将接收到带有`docker/webapp`标签的Docker容器日志条目。然后，我们可以使用Logstash的`filter`，如下所示，将这些信息导入到Elasticsearch中：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Scaling out our Docker applications
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展我们的Docker应用程序
- en: Now, suppose that the workload in the previous section starts to overload each
    of our three Docker hosts. Without a load balancer such as our preceding Nginx
    setup, our application's performance will start to degrade. This may mean a lower
    quality of service to our application's users or being paged in the middle of
    the night to perform heroic systems operations. However, with a load balancer
    managing the connections to our applications, it is very simple to add more capacity
    to scale out the performance of our application.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设前一部分中的工作负载开始超载我们三个Docker主机中的每一个。没有像我们之前设置的Nginx这样的负载均衡器时，我们的应用程序性能将开始下降。这可能意味着应用程序用户的服务质量下降，或者在半夜接到电话，进行紧急的系统操作。然而，通过负载均衡器管理应用程序的连接，我们可以很简单地增加更多的容量来扩展应用程序的性能。
- en: 'As our application is already designed to be load balanced, our scale-out process
    is very simple. The next few steps form a typical workflow on how to add capacity
    to a load-balanced application:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的应用程序已经设计为负载均衡，因此扩展过程非常简单。接下来的几步形成了一个典型的工作流，展示了如何为负载均衡的应用程序添加容量：
- en: First, provision new Docker hosts with the same base configuration as the first
    three in our Docker host pool. In this section, we will create two new Docker
    hosts, named `greenhost03` and `greenhost04`.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，提供与我们 Docker 主机池中前三个主机相同基础配置的新 Docker 主机。在本节中，我们将创建两个新 Docker 主机，分别命名为 `greenhost03`
    和 `greenhost04`。
- en: 'The next step in our scale-out process is to then deploy our applications in
    these new Docker hosts. Type the same command before for deployment as the following
    one to each of the new Docker hosts:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们扩展过程中的下一步是将我们的应用程序部署到这些新 Docker 主机中。请在每个新 Docker 主机上键入以下与之前相同的命令进行部署：
- en: '[PRE9]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'At this point, new application servers in our pool are ready to accept connections.
    It is now time to add them as destinations to our Nginx-based load balancer. To
    add them to our pool of upstream servers, first update the `/root/nginx.conf`
    file, as follows:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此时，我们池中的新应用程序服务器已经准备好接收连接。现在是时候将它们作为目标添加到基于 Nginx 的负载均衡器中。要将它们添加到我们的上游服务器池中，首先更新
    `/root/nginx.conf` 文件，如下所示：
- en: '[PRE10]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, we will notify our running Nginx Docker container to reload its configuration.
    In Nginx, this is done by sending a `HUP` Unix signal to its master process. To
    send the signal to a master process inside the Docker container, type the following
    Docker command. Send the reload signal:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将通知正在运行的 Nginx Docker 容器重新加载其配置。在 Nginx 中，重新加载是通过向其主进程发送 `HUP` Unix 信号来完成的。要向
    Docker 容器中的主进程发送信号，请键入以下 Docker 命令。发送重新加载信号：
- en: '[PRE11]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: More information on how to control Nginx with various Unix signals is documented
    at [http://nginx.org/en/docs/control.html](http://nginx.org/en/docs/control.html).
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有关如何使用各种 Unix 信号控制 Nginx 的更多信息，请参阅 [http://nginx.org/en/docs/control.html](http://nginx.org/en/docs/control.html)。
- en: 'Now that we are done scaling out our Docker application, let''s look back at
    our Kibana visualization to observe the effect. The following screenshot shows
    the distribution of traffic across the five Docker hosts we currently have:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了 Docker 应用程序的扩展，让我们回顾一下我们的 Kibana 可视化效果，观察其影响。以下截图显示了我们当前五个 Docker
    主机之间的流量分布：
- en: '![Scaling out our Docker applications](img/00033.jpeg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![扩展我们的 Docker 应用程序](img/00033.jpeg)'
- en: We can note in the preceding screenshot that after we reloaded Nginx, it started
    to distribute load across our new Docker containers. Before this, each Docker
    container received only a third of the traffic from Nginx. Now, each Docker application
    in the pool only receives a fifth of the traffic.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在前面的截图中看到，在重新加载 Nginx 后，它开始在新的 Docker 容器之间分配负载。在此之前，每个 Docker 容器仅接收 Nginx
    的三分之一流量。而现在，池中的每个 Docker 应用程序只接收五分之一的流量。
- en: Deploying with zero downtime
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零停机部署
- en: Another advantage of having our Docker application load balanced is that we
    can use the same load balancing techniques to update our application. Normally,
    operations engineers have to schedule downtime or a maintenance window in order
    to update an application deployed in production. However, as our application's
    traffic goes to a load balancer before it reaches our application, we can use
    this intermediate step to our advantage. In this section, we will employ a technique
    called blue-green deployments to update our running application with zero downtime.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有 Docker 应用程序负载均衡的另一个优势是，我们可以使用相同的负载均衡技术来更新我们的应用程序。通常，运维工程师需要安排停机时间或维护窗口才能更新生产环境中部署的应用程序。然而，由于我们的应用程序流量首先会流向负载均衡器，再到达我们的应用程序，我们可以利用这一中间步骤来为自己谋利。在本节中，我们将采用一种名为蓝绿部署的技术，以零停机时间更新我们的正在运行的应用程序。
- en: 'Our current pool of `hubuser/app:1.0.0` Docker containers is called our *green*
    Docker host pool because it actively receives requests from our Nginx load balancer.
    We will update the application being served by our Nginx load balancer to pool
    of `hubuser/app:2.0.0` Docker containers. The following are the steps to perform
    the update:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当前的`hubuser/app:1.0.0` Docker 容器池被称为我们的*绿色* Docker 主机池，因为它会主动接收来自 Nginx 负载均衡器的请求。我们将把
    Nginx 负载均衡器服务的应用程序更新为 `hubuser/app:2.0.0` Docker 容器池。以下是执行更新的步骤：
- en: 'First, let''s update our application by changing the version string in our
    `app.js` file, as follows:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们通过修改 `app.js` 文件中的版本字符串来更新我们的应用程序，如下所示：
- en: '[PRE12]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After updating the content, we will prepare a new version of our Docker image
    called `hubuser/app:2.0.0` and publish it to Docker Hub via the following command:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在更新内容后，我们将准备一个新的 Docker 镜像版本，名为 `hubuser/app:2.0.0`，并通过以下命令将其发布到 Docker Hub：
- en: '[PRE13]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Next, we will provision a set of Docker hosts called `bluehost01`, `bluehost02`,
    and `bluehost03`, either through our cloud provider or by buying actual hardware.
    This will become our *blue* Docker host pool.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将通过我们的云服务提供商或购买实际硬件来配置一组 Docker 主机，命名为 `bluehost01`、`bluehost02` 和 `bluehost03`。这将成为我们的*蓝色*
    Docker 主机池。
- en: 'Now that our Docker hosts are prepared, we will deploy our new Docker application
    on each of the new hosts. Type the following commands on each Docker host to perform
    the deployment:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们的 Docker 主机已经准备好，我们将在每个新主机上部署新的 Docker 应用程序。请在每个 Docker 主机上输入以下命令进行部署：
- en: '[PRE14]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Our *blue* Docker host pool is now prepared. It is called blue because although
    it is now live and running, it has yet to receive user traffic. At this point,
    we can do whatever is needed, such as performing preflight checks and tests before
    siphoning our users to the new version of our application.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的*蓝色* Docker 主机池现在已经准备好。之所以称其为蓝色，是因为尽管它现在已经在线并运行，但它还没有接收到用户流量。此时，我们可以执行必要的操作，例如在将用户转向新版本的应用程序之前，进行预飞行检查和测试。
- en: 'After we are confident that our blue Docker host pool is fully functional and
    working, it will be time to send traffic to it. As in the scaling-out process
    of our Docker host pool, we will simply add our blue Docker hosts to the list
    of servers inside our `/root/nginx.conf` configuration, as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在确认我们的蓝色 Docker 主机池完全正常并投入使用后，就该开始将流量发送到它了。与扩展 Docker 主机池的过程类似，我们只需将蓝色 Docker
    主机添加到 `/root/nginx.conf` 配置中的服务器列表中，如下所示：
- en: '[PRE15]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To complete the activation, reload our Nginx load balancer by sending it the
    `HUP` signal through the following command:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为完成激活，重新加载我们的 Nginx 负载均衡器，通过以下命令向其发送 `HUP` 信号：
- en: '[PRE16]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: At this point, Nginx sends traffic to both the old version (`hubuser/app:1.0.0`)
    and the new version (`hubuser/app:2.0.0`) of our Docker application. With this,
    we can completely verify that our new application is indeed working as expected
    because it now serves live traffic from our application's users. In the cases
    when it does not work properly, we can safely roll back by removing the `bluehost*`
    Docker hosts in the pool and resending the `HUP` signal to our Nginx container.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，Nginx 将流量同时发送到旧版本（`hubuser/app:1.0.0`）和新版本（`hubuser/app:2.0.0`）的 Docker 应用程序。通过这种方式，我们可以完全验证新应用程序是否按预期工作，因为它现在正在处理来自我们应用程序用户的实时流量。如果在某些情况下它没有正常工作，我们可以通过删除池中的
    `bluehost*` Docker 主机并向我们的 Nginx 容器重新发送 `HUP` 信号来安全回滚。
- en: 'However, suppose we are already satisfied with our new application. We can
    then safely remove the old Docker application from our load balancer''s configuration.
    In our `/root/nginx.conf` file, we can perform this by removing all the `greenhost*`
    lines, as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，假设我们已经对新应用程序感到满意。我们可以安全地从负载均衡器的配置中移除旧的 Docker 应用程序。在我们的 `/root/nginx.conf`
    文件中，我们可以通过删除所有 `greenhost*` 行来完成此操作，如下所示：
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now, we can complete our zero-downtime deployment with another `HUP` signal
    to Nginx. At this point, our blue Docker host pool serves all the production traffic
    of our application. This, therefore, becomes our new green Docker host pool. Optionally,
    we can deprovision our old green Docker host pool to save on resource usage.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过向 Nginx 发送另一个 `HUP` 信号来完成零停机时间部署。此时，我们的蓝色 Docker 主机池处理我们应用程序的所有生产流量。因此，它成为了我们的新绿色
    Docker 主机池。我们也可以选择停用旧的绿色 Docker 主机池，以节省资源使用。
- en: 'The whole blue-green deployment process we did earlier can be summarized in
    the following Kibana visualization:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前做的整个蓝绿部署过程可以通过以下 Kibana 可视化进行总结：
- en: '![Deploying with zero downtime](img/00034.jpeg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![零停机时间部署](img/00034.jpeg)'
- en: Note that in the preceding graph, our application still serves traffic even
    though we updated our application. Note also that before this, all of the traffic
    was distributed to our five **1.0.0** applications. After activating the blue
    Docker host pool, three-eighths of the traffic started going to version **2.0.0**
    of our application. In the end, we deactivated all the endpoints in our old green
    Docker host pool, and all of the application's traffic is now served by version
    **2.0.0** of our application.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在上面的图表中，尽管我们更新了应用程序，但我们的应用仍然在处理流量。还请注意，在此之前，所有的流量都分配给了我们的五个**1.0.0**版本的应用程序。启用蓝色
    Docker 主机池后，三分之八的流量开始转向我们应用程序的**2.0.0**版本。最终，我们停用了旧的绿色 Docker 主机池中的所有端点，所有应用的流量现在都由**2.0.0**版本的应用程序处理。
- en: Note
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: More information about blue-green deployments and other types of zero-downtime
    release techniques can be found in a book called *Continuous Delivery* by Jez
    Humble and Dave Farley. The book's website can be found at [http://continuousdelivery.com](http://continuousdelivery.com).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 关于蓝绿部署和其他零停机发布技术的更多信息，可以参考Jez Humble和Dave Farley的书《*持续交付*》。该书的网站可以在[http://continuousdelivery.com](http://continuousdelivery.com)找到。
- en: Other load balancers
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他负载均衡器
- en: There are other tools that can be used to load balance applications. Some are
    similar to Nginx, where configuration is defined through external configuration
    files. Then, we can send a signal to the running process to reload the updated
    configuration. Some have their pool configurations stored in an outside store,
    such as Redis, etcd, and even regular databases, so that the list is dynamically
    loaded by the load balancer itself. Even Nginx has some of these functionalities
    with its commercial offering. There are also other open source projects that extend
    Nginx with third-party modules.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他可以用于负载均衡应用程序的工具。一些工具类似于Nginx，其中配置通过外部配置文件进行定义。然后，我们可以向正在运行的进程发送信号，以重新加载更新后的配置。有些工具将其池配置存储在外部存储中，如Redis、etcd，甚至是常规数据库，以便负载均衡器本身动态加载该列表。即便是Nginx，其商业版本也具有一些此类功能。还有一些开源项目通过第三方模块扩展了Nginx。
- en: 'The following is a short list of load balancers that we can deploy as some
    form of Docker containers in our infrastructure:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们可以以某种形式作为Docker容器部署到基础设施中的负载均衡器简短列表：
- en: Redx ([https://github.com/rstudio/redx](https://github.com/rstudio/redx))
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redx ([https://github.com/rstudio/redx](https://github.com/rstudio/redx))
- en: HAProxy ([http://www.haproxy.org](http://www.haproxy.org))
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HAProxy ([http://www.haproxy.org](http://www.haproxy.org))
- en: Apache HTTP Server ([http://httpd.apache.org](http://httpd.apache.org))
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache HTTP Server ([http://httpd.apache.org](http://httpd.apache.org))
- en: Vulcand ([http://vulcand.github.io/](http://vulcand.github.io/))
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vulcand ([http://vulcand.github.io/](http://vulcand.github.io/))
- en: CloudFoundry's GoRouter ([https://github.com/cloudfoundry/gorouter](https://github.com/cloudfoundry/gorouter))
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CloudFoundry的GoRouter ([https://github.com/cloudfoundry/gorouter](https://github.com/cloudfoundry/gorouter))
- en: dotCloud's Hipache ([https://github.com/hipache/hipache](https://github.com/hipache/hipache))
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: dotCloud的Hipache ([https://github.com/hipache/hipache](https://github.com/hipache/hipache))
- en: There are also hardware-based load balancers that we can procure ourselves and
    configure via their own proprietary formats or APIs. If we use cloud providers,
    some of their own load balancer offerings would have their own cloud APIs that
    we can use as well.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 也有基于硬件的负载均衡器，我们可以自行采购并通过它们自己专有的格式或API进行配置。如果我们使用云服务提供商，它们的一些负载均衡器服务将会有自己的云API，我们也可以使用。
- en: Summary
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned the benefits of using load balancers and how to
    use them. We deployed and configured Nginx as a load balancer in a Docker container
    so that we can scale out our Docker application. We also used the load balancer
    to perform zero-downtime releases to update our application to a new version.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了使用负载均衡器的好处以及如何使用它们。我们在Docker容器中部署并配置了Nginx作为负载均衡器，以便扩展我们的Docker应用程序。我们还使用负载均衡器执行了零停机发布，将我们的应用程序更新为新版本。
- en: In the next chapter, we will continue to improve our Docker optimization skills
    by debugging inside the Docker containers we deploy.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将继续通过调试我们部署的Docker容器来提升Docker优化技能。
