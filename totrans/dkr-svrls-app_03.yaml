- en: Serverless Frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter discusses serverless frameworks. What are they? What are the current
    limitations of pure serverless frameworks? How could Docker partially solve the
    limitations of serverless frameworks. We will start by taking a look at AWS Lambda,
    then Azure Functions, and Google Cloud Functions. We will touch briefly on IBM
    Cloud Functions, but actually its engine is OpenWhisk, which will be discussed
    in detail in the next couple of chapters.
  prefs: []
  type: TYPE_NORMAL
- en: We will also discuss serverless framework, a toolkit that helps us develop cloud-independent
    serverless applications, in the last section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Lambda
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Among serverless architectures offered by cloud providers, AWS Lambda is the
    most popular and has some advanced features.
  prefs: []
  type: TYPE_NORMAL
- en: FaaS/serverless is a natural evolution from microservices, or we may think of
    it as an extension to the microservices architecture. In many scenarios, we can
    complement our microservices architecture with functions or Lambda. If you are
    already an AWS customer, it is completely natural to move your codes from EC2
    to Lambda and save a lot of money. The following diagram illustrates a simple
    use case that uses **AWS Lambda** together with **S3 Buckets** and **DynamoDB:**
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/74d0ca23-fdea-4bd8-9e59-6a724c4b27cd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: A simple use case of using Lambda function on AWS'
  prefs: []
  type: TYPE_NORMAL
- en: In S3, there is a way to trigger the event to a specific endpoint. We put the
    endpoint of our Lambda function there. After users upload or make changes to the
    S3 bucket, it will trigger to send an invocation request to the Lambda function.
    This could be thought of as a form of WebHooks. After that, the Lambda function
    receives the event and starts to compute its application logic. After it has finished,
    the Lambda will transfer the results and store them into a DynamoDB instance.
  prefs: []
  type: TYPE_NORMAL
- en: We will demonstrate a similar scenario in [Chapter 8](0d30ef75-34b4-4a72-9b0a-71a8e335d494.xhtml),
    *Putting Them All Together*.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lambda supports several language runtimes; for example, Node.js, Go, Java, Python,
    and C#. Each AWS Lambda has a number of limitations to cap the resources it may
    use per invocation. In terms of memory, the range of RAM supported for Lambda
    is between 128 MB to 3,008 MB with 64 MB, increments. The function will be automatically
    terminated if its memory usage is exceeded.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of disk space, a Lambda function is allowed to use the `/tmp` directory
    up to 512 MB. This kind of disk volume is ephemeral, so it is expected to be wiped
    out after the Lambda has finished its work. Also, the number of file descriptors
    allowed in Lambda functions are limited to 1,024, while the number of processes
    and threads that could be forked within a single invocation is limited to 1,024
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: For each request, the size of the request body is capped at 6 MB for synchronous
    HTTP calls, and at 128 KB for asynchronous, event-triggered calls.
  prefs: []
  type: TYPE_NORMAL
- en: The most important aspect here is *time limits*. AWS Lambda allows a function
    to run no longer than 5 minutes (or 300 seconds). If the execution time exceeds
    5 minutes, the function will be automatically killed.
  prefs: []
  type: TYPE_NORMAL
- en: Lambda termination
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The technology behind Lambda is actually container-based, which means it isolates
    a function from other instances. The container's sandbox provides resources specific
    to each configuration for them.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Lambda function can be terminated in a number of ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Timeout**: As previously mentioned, when the 5-minute limitation is reached,
    the current execution of the function will be stopped no matter what it is doing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Controlled termination**: If the function provides a callback and the callback
    is executed to invoke the `context.done()` method, the function will be terminated,
    no matter what it is doing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Default termination**: The function ends and terminates normally. Also, there
    is no callback to invoke the `context.done()` method. This case will be considered
    as the default termination.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Function crashes** **or `process.exit()` is called**: If the function panics
    or generates segmentation faults, the function will terminate and therefore the
    container is stopped.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container reuse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is a scenario where the function container that has just terminated could
    be reused.
  prefs: []
  type: TYPE_NORMAL
- en: This ability to reuse a finished function container can greatly reduce the spinning
    up time, as the initialization process will be completely skipped. Also, there
    is a drawback where, if a container is reused, the file written to the `/tmp`
    directory from the previous execution may still be there.
  prefs: []
  type: TYPE_NORMAL
- en: Native executables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lambda is actually designed to run code in any language, as Lambda's sandbox
    is just a container. The trick is that we could use a Node.js program to execute
    any binary shipped with the ZIP file before uploading.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that when preparing our own binary for Lambda, it must be
    statically compiled or matched with the shared libraries provided by Amazon Linux
    (as the containers used on Lambda are all Amazon Linux-based). It is our responsibility
    to track the Amazon Linux version by ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: A project such as LambCI ([http://github.com/lambci/docker-lambda](http://github.com/lambci/docker-lambda))
    can help to solve this problem. LambCI provides a local sandbox environment, as
    Docker containers, that mimics the AWS Lambda environment by installing the same
    software and libraries, file structure, and permissions. It also defines the same
    set of environment variables, and other behaviors. Also, the username and group
    are defined to match the Lambda, for example, `sbx_user1051`.
  prefs: []
  type: TYPE_NORMAL
- en: With this local environment, we are allowed to safely test our codes inside
    this Docker container and can be sure that it will be running fine on Lambda.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Azure Functions is a serverless computing platform offered by Microsoft as a
    part of Azure Cloud. All design goals are the same as other serverless/FaaS services,
    and Azure Functions enables us to execute our application logic without managing
    our own infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Functions runs a program in the form of scripts when it is triggered by
    events. The current version of Azure Functions supports language runtimes such
    as C#, F#, PHP, Node.js or Java. It is natural for Azure to support C# and F#
    as first-class languages for their functions because they are Microsoft-owned
    programming languages. In any case, the only GA-supported languages are C#, F#,
    and JavaScript (Node.js) anyway.
  prefs: []
  type: TYPE_NORMAL
- en: With C#, F#, or .NET languages, Azure Functions allows us to install dependencies
    via NuGet, the infamous package manager for .NET. In case we are writing JavaScript
    with Node.js, Azure also provides access to NPM for package management.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to other cloud providers, Azure Functions has an advantage when accessing
    other Azure services, for example, Azure Cosmos DB, Azure Event Hubs, Azure Storage
    and Azure Service Bus.
  prefs: []
  type: TYPE_NORMAL
- en: It is really interesting to note that the pricing model of Azure Functions is
    somewhat different from the offering of Amazon or Google. In Azure, there are
    two kind of pricing plans that may fit different needs.
  prefs: []
  type: TYPE_NORMAL
- en: The first one is the *consumption plan*. It is a similar plan offered by other
    cloud providers, where you pay only for the time that our codes are executed.
    The second one is the *app service plan*. Functions in this context are considered
    part of the app service for other applications. If functions fall into this category,
    we do not need to incur additional cost.
  prefs: []
  type: TYPE_NORMAL
- en: An interesting feature of Azure Functions is its triggering and binding mechanism.
    Azure Functions allows a definition of how to trigger a function and how to perform
    data binding of the input and the output for each function, in a separated configuration.
    These mechanisms help to avoid hardcoding when we call functions and when we transform
    data in and out through the calling chain of functions.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Azure, there is a component to monitor the number of requests made to each
    Azure Function in real time. This component is called the **scale controller**.
    It collects data and then later makes a decision to scale the number of instances
    up or down for that function. Azure has the concept of an app service. A function
    app may contain many instances of a function.
  prefs: []
  type: TYPE_NORMAL
- en: All decision making is based on heuristic-based algorithms for different types
    of event triggers. When the function is scaled out, all resources related to that
    function will also be scaled out. The number of function instances will be automatically
    scaled down to zero, if there is no request made to the function app.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each function instance will be limited to a memory of 1.5 GB by the host of
    the function app, a group-like semantic for multiple function instances. All functions
    within a function app share the same resources.
  prefs: []
  type: TYPE_NORMAL
- en: A function app holds a maximum of 200 instances of a function at the same time.
    But there is no concurrency limitation. In practice, a function instance can accept
    one or more requests.
  prefs: []
  type: TYPE_NORMAL
- en: Each event trigger, for example, Azure Service Bus has its own heuristic way
    to scale the underlying function.
  prefs: []
  type: TYPE_NORMAL
- en: Durable functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the most advanced extensions to the Azure Functions are **durable functions**.
    A durable function is a technique to implement stateful functions inside a serverless
    computing environment. There are additional concepts for state management, checkpoints,
    and restarts provided by this durable extension. What we get from this kind of
    function is a stateful workflow, and there will be a driver that acts as the orchestrator
    to call other functions, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/76ad2f42-1a69-4442-bec0-1df67ba324e9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.2: An orchestrator function with the durable function extension in
    Azure'
  prefs: []
  type: TYPE_NORMAL
- en: When it has finished calling other functions, both in synchronous or asynchronous
    ways, the orchestrator function will be allowed to save states as local variables.
    There is also a *checkpointing technique* to continue/resume the orchestrator's
    states when the calling process has to start over, or the virtual machine running
    this orchestrator function gets rebooted.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The serverless computing service offered by Google Inc is called **Google Cloud
    Functions **(**GCF**).
  prefs: []
  type: TYPE_NORMAL
- en: 'We basically refer to it as GCF in this section. Like other serverless platforms,
    GCF provides both execution environment and the SDK to help us develop and manage
    the entire life cycle of our function. It provides an SDK to help us get started
    with the framework. The main language supported by GCF is JavaScript and there
    is a Node.js Docker image for us to use. With Docker, it is convenient to build
    a function. When about to deploy, it is relatively easy to deploy it with the
    Google Cloud CLI tool. It is natural that GCF will allow us to connect to other
    Google-based services efficiently:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06039659-fd8e-42a9-a986-0d4e2c94134b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.3: A common IoT use case implemented with Google Cloud Functions'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram demonstrates one of the common use cases implemented on
    Google Cloud. It is an example of an IoT pipeline using all Google Cloud services.
    A Google Cloud Function is used to compute data from the message queue and divert
    it to both the big data stack and Firebase. The Firebase service acts as a **Backend
    as a Service** (**BaaS**) for mobile applications. In a later chapter, we will
    demonstrate a similar BaaS using the **Parse platform**.
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The definition of a function in the FaaS or the serverless platform is that
    it should focus on only one objective. Due to the nature of the function, it should
    not be too complex. As we described in [Chapter 1](e9b10056-7288-4daf-b2e4-033682fa9185.xhtml),
    *Serverless and Docker*, serverless FaaS is actually a subset of the event-driven
    programming model. All cloud functions on GCF behave that way. Every single component
    of our application pipeline is connected by sending events to another. Also, events
    can be monitored. When we receive an event from the source, a cloud function associated
    with that mechanism will be triggered to run.
  prefs: []
  type: TYPE_NORMAL
- en: The function supported by GCF must be written in JavaScript, or languages that
    are able to transpile to JavaScript. At the time of writing, the environment for
    executing functions is a Node.js v6.11.5\. Basically, developers would use any
    Node.js runtime that matches the same version. Using JavaScript and Node.js yields
    good portability and it allows developers to test the function locally. In addition,
    using Node.js allows access to the vast numbers of Node.js libraries, including
    APIs offered by the platform ([https://cloud.google.com/nodejs/apis](https://cloud.google.com/nodejs/apis)),
    that help simplify development and integration.
  prefs: []
  type: TYPE_NORMAL
- en: GCF is designed to be a connection or a glue layer that links services together.
    In some use cases, we use functions to extend the existing cloud services.
  prefs: []
  type: TYPE_NORMAL
- en: With the event-driven model, functions can listen and wait until the file uploading
    event is triggered, when some files are put into cloud storage. We can also listen
    to log changing in a remote blockchain environment. Or maybe we subscribe to a
    Pub/Sub topics and get a notification to trigger the functions.
  prefs: []
  type: TYPE_NORMAL
- en: We usually put some complex business logic inside a function. Cloud functions
    owned by Google have the ability to access the credential system of the GCP, therefore,
    it could authenticate with the large set of GCP services. This feature usually
    makes the cloud functions very useful on their own platform.
  prefs: []
  type: TYPE_NORMAL
- en: All infrastructure and the system software layers are fully managed by Google's
    platform, so we need to care only for our codes. Autoscaling is also the normal
    feature of this kind of platform. Provisioning additional computing resources
    just works automatically when the number of triggers becomes large. Deployed functions
    will autoscale to serve millions of requests without any further configuration
    from us.
  prefs: []
  type: TYPE_NORMAL
- en: The fine-grained concept of an FaaS function makes this kind of computing fit
    nicely to implement self-contained APIs and WebHooks (we will demonstrate this
    in later chapters). Google Cloud Functions supports many aspects of workloads,
    for example, data processing/ELT, WebHooks, implementing APIs, acting as a backend
    for mobile applications, and accepting streaming data from IoT devices.
  prefs: []
  type: TYPE_NORMAL
- en: GCF supports many aspects of serverless computing. An obvious limitation at
    the moment is that it supports only Node.js as a programming language. GCF uses
    containers internally to wrap around the Node.js codes and deploy onto its internal
    orchestration FaaS system. A part of this engineering has been open sourced as
    a project called **distroless**. We can accomplish similar things with the concept
    of declarative containers, proposed in the final chapter. Using this concept allows
    us to deploy a workload containing only the application in the same way GCF does.
  prefs: []
  type: TYPE_NORMAL
- en: All of these use cases allowed by GCF will be demonstrated with different approaches
    using Docker and FaaS platforms in a later chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Execution model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google takes care of everything for us, including the hardware level, the OS,
    networking, and the application runtimes. A function deployed there on the GCF
    will run in an automatically managed platform. Each cloud function will be executed
    separately in a container-based isolation, which is a secure execution context.
    Running independently, each function will not interfere with others while sharing
    the same host. This is the same concept used by Docker and other container implementations.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, Google Cloud Functions chooses to support only JavaScript
    running on Node.js v6.11.5; however, the document says that they will keep the
    version of Node.js updated by going closely with the **Long-Term Support** (**LTS**)
    releases, as quickly as possible. We can be confident that all patch versions
    for security and minor updates of the Node.js runtime will match the upstream
    releases.
  prefs: []
  type: TYPE_NORMAL
- en: 'As previously mentioned, a cloud function is also put into a container. In
    the case of Google Cloud Functions, its root filesystem is based on *Debian*.
    The base image of GCF is updated regularly and available as Docker images. It
    could be pulled from `gcr.io/google-appengine/nodejs`. Here''s the way the system
    prepares the base image by inheriting the image and installing Node.js version
    6.11.5 to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Statelessness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stateless is the preferred model when writing a serverless FaaS function. Why?
    Because in the fully managed execution environment, which can be scaled up and
    down at anytime, we cannot expect our function state to be preserved. So it is
    best to not save anything to the function's local storage. If we need memory,
    such as global variables that may be shared across instances of the function,
    these variables must be managed explicitly by external storage services.
  prefs: []
  type: TYPE_NORMAL
- en: In some situations, saying a function is completely stateless makes us underutilize
    the execution context of that function. As we already know, our function is actually
    running inside a container isolation. And it is completely fine for our function
    to write some things onto the local storage during execution, of course, without
    the expectation to share states outside this isolation. When saying *stateless*
    in the container's context, it is likely to be the *share-nothing* model rather
    than being *stateless*. The share-nothing model, is the better word to generally
    describe the statelessness of container-based FaaS.
  prefs: []
  type: TYPE_NORMAL
- en: Timeout
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In general, a serverless platform usually caps the execution time of a cloud
    function to prevent overuse of the platform's computing resources. For Google
    Cloud Functions, the default timeout is set to be 1 minute and can be extended
    to 9 minutes if the user prefers. When a function is timed out, its running codes
    are terminated. For example, if a function is scheduled to run at the 3 minutes
    after it starts, and if the timeout is set to be 2, that function will never run.
  prefs: []
  type: TYPE_NORMAL
- en: Execution guarantees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An error can occur anytime during the execution of a function. A function might
    not be executed only once if it failed. The model of execution depends on the
    type of function.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a simple synchronous HTTP request will be invoked once, at most.
    This means that the function invocation will be failed and never retried. The
    caller side is responsible for error handling and the retry strategy on its own.
  prefs: []
  type: TYPE_NORMAL
- en: While asynchronous functions will be invoked at least once, as is the nature
    of these asynchronous calls, so we need to prepare for a situation that this kind
    of function will be invoked multiple times. Also, the state to be modified by
    these functions should be idempotent and robust. For example, we may need to implement
    a state machine to control the states of the system.
  prefs: []
  type: TYPE_NORMAL
- en: IBM Cloud Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: IBM Cloud Functions is a service provided by IBM Cloud. It is powered by Apache
    OpenWhisk; actually, it's IBM who donated OpenWhisk to the Apache Foundation.
    We have a chapter dedicated to OpenWhisk later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: The Cloud Functions service provided by IBM is, of course, very similar to other
    function services in terms of concepts. Functions wrap around the application
    business logic and run in the event-driven FaaS environment managed by IBM.
  prefs: []
  type: TYPE_NORMAL
- en: Functions are designed to respond to a direct HTTP invocation from other Web
    or mobile apps, or to events triggered by other supported systems, for example,
    Cloudant. IBM Cloud provides Cloudant, a commercially supported JSON data store
    built on top of CouchDB.  We can prepare a trigger in the Cloudant system, and
    let it fire events to invoke functions defined in the IBM Cloud Functions, when
    the data in Cloudant is changed.
  prefs: []
  type: TYPE_NORMAL
- en: The design goal of functions is generally the same among cloud providers. They
    provide a way for us developers to focus only on writing application business
    logic, then uploading codes to their cloud as cloud functions.
  prefs: []
  type: TYPE_NORMAL
- en: To further explore the concepts behind OpenWhisk, the engine behind IBM Cloud,
    please feel free to jump to [Chapter 6](c78cb885-6836-493a-8fd9-d98e85bf40c4.xhtml),
    *OpenWhisk on Docker*, to learn more about OpenWhisk.
  prefs: []
  type: TYPE_NORMAL
- en: The Serverless Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Serverless Framework is an application development framework and tool for
    the serverless computing paradigm. The framework only shares the same name with
    serverless. Please do not be confused.
  prefs: []
  type: TYPE_NORMAL
- en: The authors of the Serverless Framework consider that a serverless application
    is the next evolution of application development in the cloud native ecosystem.
    And this kind of application needs a certain level of automation. This idea was
    the stem of the framework.
  prefs: []
  type: TYPE_NORMAL
- en: The design idea views managed services and functions as coupled entities. To
    make an application around them, a tool should provide build, test, and deploy
    commands to make the whole development life cycle fully automated.
  prefs: []
  type: TYPE_NORMAL
- en: 'There also should be a consistent way of building, testing, and deploying a
    serverless application to multiple cloud providers, while minimizing code changes.
    The framework should help configure the setting for each cloud provider based
    on the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The language runtime
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cloud provider selected by the application developer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this level of abstraction, the framework yields real advantages and lets
    developers focus on application business logic, rather than keep changing cloud
    configurations to match each provider.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are four benefits of the Serverless Framework described by its creators:'
  prefs: []
  type: TYPE_NORMAL
- en: The Serverless Framework helps speed up the development process because the
    framework contains CLI-based commands to create a project, build, and also helps
    to test applications from the same development environment. It saves time because
    the Serverless Framework is independent from any cloud providers. There is also
    a mechanism to deploy a new version to the cloud and allow rollback for the previous
    one, if it fails.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the Serverless Framework, it allows us to develop codes independently to
    any cloud providers. So, the code with a good writing style would be migrated
    across the providers. For example, we can simply move our functions deployed as
    AWS Lambda by just changing the provider in the YAML file to Google Cloud and
    re-deploy again. But actually this is only a part of the whole problem. It is
    actually not the codes that could lock you to the vendor, it's the services provided
    by the vendor that make you stay with them. So choose the supported service wisely
    and this problem could be effectively solved.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Serverless Framework helps to enable **Infrastructure as Code** (**IaC**).
    With deployment that could be done via the set of APIs, we enable a certain level
    of automation. This makes us able to fully deploy the system as multi-cloud applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the framework is widely used and has a very vibrant community. This
    is also an important key for choosing a tool. The framework extensions are actively
    developed by the community because of the base language, JavaScript on Node.js,
    that they chose for the framework. So, it is relatively easy to add a new provider
    to the framework. A notable community-based provider is Kubeless.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s do some revision by trying to answer the questions without reviewing
    the contents:'
  prefs: []
  type: TYPE_NORMAL
- en: How long is the time limitation for an AWS Lambda?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why do you think the cloud providers limit computational time for FaaS functions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are Azure's durable functions? Do they have any benefit?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we test an AWS Lambda program just with Docker?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the engine behind IBM Cloud Functions? What do you think is the reason
    behind IBM open sourcing it?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the Serverless Framework? Why is it important?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How could we make a FaaS function work across cloud providers? Do you think
    it is really possible?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Please explain the difference between stateless and share-nothing models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we have discussed four major serverless computing platforms,
    some of their characteristics and limitations. We have also discussed the Serverless
    Framework, a framework and tool designed to help build, test, and deploy applications
    to multiple serverless computing platforms.
  prefs: []
  type: TYPE_NORMAL
- en: In the next three chapters, we will see the truly different aspects of the serverless
    platforms provided by cloud providers and serverless/FaaS platforms that allow
    us to deploy them on our own with Docker technologies.
  prefs: []
  type: TYPE_NORMAL
