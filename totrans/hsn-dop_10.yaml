- en: DevOps for Digital Transformation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will explore the digital transformation journey in the light
    of DevOps adoption by systems of big data migration, cloud migration, microservices
    migration, data sciences, authentication security, and the **Internet of Things**
    (**IoT**).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Digital transformation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DevOps for big data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DevOps for Cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DevOps for microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DevOps for data sciences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DevOps for authentication systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DevOps for IoT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Digital transformation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Journey to digital transformation is unique for every company; hence, the very
    definition will vary. On a broad note, it's about the adoption and integration
    of digital technology making the fundamental shift of business operations to deliver
    value to customers.
  prefs: []
  type: TYPE_NORMAL
- en: To accomplish this, companies need to adopt a culture to challenge continuously
    the status quo of the long standing established processes, and experiment often
    in favor of relatively new practices that are evolving.
  prefs: []
  type: TYPE_NORMAL
- en: 'The incentives for this digital journey are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: According to a Forrester Research report, executives predict that nearly half
    of their revenue will be driven by digital by the year 2020.
  prefs: []
  type: TYPE_NORMAL
- en: According to the MIT Center for Digital Business, *companies that have embraced
    digital transformation are 26 percent more profitable than their average industry
    competitors and enjoy a 12 percent higher market valuation*.
  prefs: []
  type: TYPE_NORMAL
- en: Research shows, *nine out of ten IT decision-makers claim legacy systems are
    preventing them from harnessing the digital technologies they need to grow and
    become more efficient.*
  prefs: []
  type: TYPE_NORMAL
- en: Their customers and internal employees will whole-heartedly support them as
    digital practices have made inroads into people's lives for all facets, such as
    shopping online via mobile devices and remotely adjusting their home heating systems.
  prefs: []
  type: TYPE_NORMAL
- en: Digital strategy adoption should be considered as a long-lasting cultural, technological
    change and not a tactical means. It's re-evaluation of the software platform and
    architecture, development methodologies, technologies, business processes, roles,
    and responsibilities. It's evolutionary, incremental, and iterative and not meant
    to be revolutionary or disruptive. It's about the alignment of organization to
    the change rather than a push from **Chief Information Officers** (**CIOs**) alone
    to match the competition.
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps to a successful digital journey are:'
  prefs: []
  type: TYPE_NORMAL
- en: Formulating digital strategy for organization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: People involvement as important as technology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Legacy architecture transformation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Legacy processes and attitudes modernize
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using mobile as a catalyst for change
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Harnessing  power **application programming interfaces** (**APIs**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Planning to stay secure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Digital transformation framework varies widely as per organizations'' specific
    challenges and demands. The common themes for business and technology leaders
    as they embark on digital transformation are often cited to aid in developing
    their own digital transformation strategy, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Customer experience
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operational agility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Culture and leadership
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Workforce enablement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Digital technology integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Digital transformation cultural shift for organizations is enabled by the fundamental
    shift in the role of IT.
  prefs: []
  type: TYPE_NORMAL
- en: A recent report from Harvey Nash and advisory firm KPMG found that, *CEOs are
    focused on IT projects that can make money (63 percent), rather than those that
    save money (37 percent)*.
  prefs: []
  type: TYPE_NORMAL
- en: Research from Forrester suggests, on average, CIOs spend an average of 72 percent
    of their budgets on existing IT concerns, whereas only 28 percent goes to new
    projects and innovation.
  prefs: []
  type: TYPE_NORMAL
- en: In the past 4 years, long-standing CIO priorities have seen the biggest change
    in priorities of relative importance. For example, increasing operational efficiencies
    has dropped 16 percent, and delivering stable IT performance has dropped 27 percent.
  prefs: []
  type: TYPE_NORMAL
- en: Bryson Koehler, CIO of The Weather Company, says, *There is a very different
    mindset at work when you take IT out of an operating mode of, 'Let's run a bunch
    of packaged solutions that we've bought and stood up' to 'Let's build and create
    new capabilities that didn't exist before'*.
  prefs: []
  type: TYPE_NORMAL
- en: '*Marc Carrel-Billiard*, global tech R&D lead on digital transformation at Accenture,
    is quoted as saying in an article for TechCrunch that *Finding ways to help people
    across this digital divide and the culture shock that rapid change brings is going
    to be just as important as the technology we use to get there*.'
  prefs: []
  type: TYPE_NORMAL
- en: Dr. David Bray, CIO of the U.S. Federal Communication Commission, speaks on
    how this cultural shift sets the stage for transformation: *Throughout human history,
    the things that we could do with tools changed what we could do as humans, and
    as a result, changed what we could do as cultures*. Bray says, *Our species is
    'smart' because we know how to use tools collaboratively together. At the end
    of the day, when we talk about technology change - whether it's the Internet of
    Everything, big data, or machine learning - it's really about people and organizational
    cultures, first and foremost. Then, it's about how those people get stuff done
    together - and that's really what it comes down to when you talk about transforming
    organizational cultures*.
  prefs: []
  type: TYPE_NORMAL
- en: Nextgov reports, *Around three-quarters of the $80 billion the federal government
    spends on information technology each year is used just to keep legacy systems
    running*.
  prefs: []
  type: TYPE_NORMAL
- en: According to a study by Tiger Text and using research conducted by HIMSS Analytics,
    in the healthcare industry, *Despite widespread use of smartphones and other mobile
    devices among healthcare providers, 90 percent of hospitals still use pagers and
    overpay by 45 percent to maintain legacy paging services*.
  prefs: []
  type: TYPE_NORMAL
- en: Companies are no longer building software or managing IT for cost savings and
    operations, but rather IT has become the primary enabler and driver for business
    innovation. To embrace adopt the shift company roles need realignment with the
    impact of IT in day-to-day experience. In driving digital transformation strategy,
    though IT will play an important role, the massive changes that go along with
    digital transformation implementation and adaption is everyone's responsibility.
    Digital transformation is primarily related to people, such as shedding of outdated
    processes and legacy technology to adopting agile principles and modernization
    across the business.
  prefs: []
  type: TYPE_NORMAL
- en: Big data and DevOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Organizations that tend to consider DevOps as pure process maturity versus big
    data as technology stream tend to treat them in silos, leading to inefficiencies.
    DevOps' goal is to make software production and delivery more efficient, and including
    data subjects within the scope of continuous delivery processes to embrace DevOps
    will be a big asset for accomplishing organizations. Many IT leaders are now under
    increased pressure to produce results for investments in big data and data science
    projects. Big data projects are becoming more challenging. Applications are now
    showing up in big data projects forcing analytics scientists to revamp their algorithms.
    Major changes in analytic models cascades to revised resources and infrastructure
    in short duration. The entire process slows down if the operations team is kept
    out of the loop, negating the competitive advantage that big data analytics provide
    and warranting the need for DevOps collaboration.
  prefs: []
  type: TYPE_NORMAL
- en: 'In big data projects, the three big components to consider are:'
  prefs: []
  type: TYPE_NORMAL
- en: Making sure that things are reliable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making sure that things are scalable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making sure that they perform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The most challenging thing for big data projects is performance, dealing with
    hundreds and thousands of computers, dealing with huge volumes of data sets, dealing
    with rapid data changes, and simultaneously dealing with multiple things and people.
    That combination of variables makes performance critical for big data systems.
  prefs: []
  type: TYPE_NORMAL
- en: By integrating big data and DevOps, organizations can achieve the following
    benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Planning effectively on software updates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software invariably interacts with data, so while updating, redesigning an app
    includes understanding of the types of data sources. Collaborating with data experts
    along with programmers and writing new code can help plan updates effectively
    from a data perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Lower error rates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data handling issues account for a major share of errors with software development
    and testing, which compounds the complexity of application and the variety volume
    of data it handles, increasing the chance of errors. DevOps principle of *shift
    left testing*, which emphasizes to enable testing of code changes early in the
    cycle, referred as *left* part of the development cycle. This is enabled with
    DevOps practice to drive further automation with continuous integration processes.
    Strong collaboration between data teams and the DevOps team is crucial to avoid
    data-related errors in an application, during continuous delivery and deployment
    processes.
  prefs: []
  type: TYPE_NORMAL
- en: Consistency of development and production environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Big data and DevOps teams working together and being part of the software delivery
    process can help understand the types of data challenges involved in building
    apps quickly to mimic real-world behavior in development and testing environments.
    Types and diversity of data in the real world can vary enormously; DevOps recommends
    non-data specialists be involved in the process.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt feedback from production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A continuous delivery process includes gathering metrics from production environments
    after software release to analyze the strengths and weaknesses and plan further
    updates. Involving data teams to monitor and maintain software in production,
    to analyze production-related data such as app health statistics (CPU time, memory
    usage, and so on), can help the organization better understand the DevOps chain
    for continuous delivery.
  prefs: []
  type: TYPE_NORMAL
- en: Agility of big data projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An agile environment facilitates adaptive streaming, and evolutionary development
    facilitates streaming between the software streams. Enterprises are moving their
    big data and data science projects to public cloud services for more agility to
    spin up virtual Hadoop or Spark clusters within minutes. DevOps adoption brings
    agility to projects and businesses, as we have seen in previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Big Data as a service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The benefits of DevOps to big data can be extended using Docker containers to
    provide big data as a service. Data scientists, through self-service, can spin
    up instant clusters with big data tools, Hadoop, Spark, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Big data processes to be adopted for DevOps are:'
  prefs: []
  type: TYPE_NORMAL
- en: ETL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security/Kerbos
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data sciences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Big data involves migration of a large quantity of data from source systems
    to destination systems; it needs proper design, data extraction, data loading,
    data verification, and data cleansing to accomplish the process. The upcoming
    discussed methodologies, along with the DevOps process, aid the expected migration
    in a short time even with huge data.
  prefs: []
  type: TYPE_NORMAL
- en: Big data formats and varieties can be structured, semi-structured, and unstructured
    data contributed by social media, machine data, server logs, and so on, encompassing
    multiple domains including medicine, biology, physics, healthcare monitoring,
    astrometry, transportation, and manufacturing.
  prefs: []
  type: TYPE_NORMAL
- en: Big data implementations have multiple options and process methodologies, as
    discussed next, to evaluate and adopt DevOps for both applications and infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: The ETL datamodels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Extract**, **Transform**, and **Load** (**ETL**) is the process in which
    the data is extracted from source systems, transformed with business logic, and
    loaded into the system for business usage. Data models and schemas are built in
    accordance with the business rules based on input and output data.'
  prefs: []
  type: TYPE_NORMAL
- en: There is an other model named **Extract**, **Load**, and **Transform** (**ELT**),
    where the data is loaded in raw form in the staging layer, and transformation,
    business logic, rules are applied for further usage to business.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4103b1c7-8656-4cf1-83ac-42e1ef6ffa86.png)'
  prefs: []
  type: TYPE_IMG
- en: Methodology 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This methodology has the following eight steps: business impact analysis, discovery,
    mapping and design, creation of migration plan, provisioning, pre-migration test,
    migration and cutover, and migration validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Business Impact Analysis** is identifying the business and operational requirements
    for the migration process'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Discovery** is about the details of data sources, migration hardware, and
    software environment collected'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mapping and design** identifies how and where the data is to be moved'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Creation of Migration** **Plan** is the blueprint specifying customer expectations
    along with project deliverables'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Provisioning** prepares the destination storage environment for the data
    hosting'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pre-Migration** **Test** tests and validate migration components'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Migration & Cutover** is for data from source-to-destination migration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Migration Validation** confirms that all expectations are met in the post-migration
    environment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Methodology 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This methodology ensures that data is properly evaluated, reviewed, and restored
    before it is migrated to target systems.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb3bfb7b-4b82-4da9-892f-b2b682755446.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Evaluate** phase analyzes source type, state of media, and effort estimation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Review** phase evaluates customer requirements and criteria, and also the
    targeted system'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Restore** phase identifies and restores individual files and recovers data
    before the data extraction process'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Migrate** phase indexes and reduplicates the restored data and migrates data
    to target delivered to customer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Methodology 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This methodology was introduced specially to handle methods, such as the database
    migration readiness stage, migration stage, ETL stage, and application stage.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be5be495-32fc-4170-a508-b0159df7a23f.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Migration Readiness Stage** creates a business case, evaluates risk, creates
    engagement model, assesses the database environment, infrastructure planning,
    and includes hardware and software.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Migration Stage** analyzes the present database and target database design
    based on business objectives. It builds database objects, such as tables, views,
    and triggers. It transfers data; the prioritized migration roadmap verifies database
    schema and validates that data is migrated aptly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extract, Transform, and Load Stage** designs and develops ETL packages to
    handle parallel data load, validates technical accuracy, functionality, and security
    and tests data load performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application Stage** performs integration testing for the applications and
    user acceptance testing to implement in the production environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Methodology 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This was introduced by Gershon Pick with four steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/207e723a-d712-4feb-bb74-9cafa9825723.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Requirement / architecture** phase defines high-level requirements such as
    data, performance requirements, and also a detailed project plan.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Detailed Specification** phase defines transformation, validations, and structure
    changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Construction / Testing** phase builds the migration solution and tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Execution** phase ensures the target system validates results to implement
    in production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Methodology 5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This was introduced by Dell. It has five steps shown as planning, pre-production
    testing, migration, validation, and cutover.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8ee53ab9-1287-46b7-84a0-b6e8101b936f.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Planning** phase defines migration goals and requirements and creates a migration
    plan defines HW/SW and tools.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pre-Production Testing** phase tests the migration environment and collects
    and validates data. It validates HW/SW and migration tools, and updates the final
    migration plan.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Migration** phase installs migration software and performs migration based
    on the plan.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Validation** phase verifies the completion of the migration, collects migration
    statistics, and prepares a migration report.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cutover** migrates application to the target environment and creates a final
    report.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Methodology 6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This methodology has eight steps explaining the common and necessary steps involved
    in the migration process.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/83d26662-e517-412a-9a61-97fe8878e962.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Analysis of business impact**: Data is the basic and important aspect that
    should be analyzed to enhance the business process. This step analyzes customers''
    requirements for business.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Information gathering** phase collects the details about source and destination
    systems. Software and hardware information collection can be manual or an automatic
    process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mapping and designing** phase maps source and destination systems maintain
    two types of design layouts. One for source and destination layouts is the same,
    and relay layout for source and destination schemas are different.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Plan of migration** phase considers business and operational constraints
    to migrate data, along with its attributes and tools for the process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Provisioning** phase replicates the source structure of files, data volumes,
    and attributes for the environment to receive the streams of actual data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test migration** phase ensures that all the presumptions are valid, and tools
    are appropriate to minimize the risk of time and money wasted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Migration** phase determines data movement from source to destination with
    two possibilities of moving data out of path and into path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Validation** phases checks data access, file permissions, and structure of
    directories to validate working of applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we have discussed, every phase of big data migration process from ETL, analytics,
    and visualization can be analyzed as a process methodology to apply DevOps maturity
    and tools at every stage for performance enhancement and productivity improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud migration - DevOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud migrations can be very expensive if they are not done correctly. Applications
    perform differently in the cloud versus on-premise, especially if it's a complex
    application where matured testing strategy makes the difference. DevOps methodology
    incorporation at each stage of the migration process will surely add multi-facet
    value. Each stage of cloud migration is detailed here for adopting DevOps strategy
    for applications, infrastructure, and tools as per the organization's needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several aspects are to be considered for an application migration to the cloud,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/09deb3aa-03d5-4780-aa34-7fa8cc564e3c.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Application feasibility**: This is architectural compatibility of the application
    for cloud hosting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**External/internal dependencies**: Applications accessibility of internal
    and external dependencies from cloud to be understood.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application class**: High-demand applications from a business perspective
    classified as business-critical and LOB applications require high availability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application integration**: This validates application performance with other
    on-premise applications and shared services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability/elasticity**: Application design supports scalability on cloud.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance adherence**: This safeguards enterprise-level compliance, regulations,
    and governance for data moved/stored outside the enterprise''s premises.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Return on investments**: This helps hosting applications on cloud to be more
    cost-effective for the enterprise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: The same level of security can be provided after migrating to
    cloud as:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data security
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Authentication
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Authorization
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Database compatibility**: The existing database is supported, and it is compatible
    with cloud. Here are ways to maintain application data while migrating an application
    to cloud:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Residing database on-premise
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating database on VM
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows database (PaaS)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Migration strategy/approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Multiple factors are considered for the migration decision:'
  prefs: []
  type: TYPE_NORMAL
- en: '**UI analysis**: UI interface to be analyzed for migration to cloud in the
    PaaS model. On-premise web-based applications and services can be mapped to cloud
    with re-engineering to be compatible with cloud services, the non-web applications
    at on-premise are to be rebuilt to move to cloud on as-per-need basis. In addition,
    third-party framework / class library to be compatible with cloud might require
    some modifications or may have to be re-written. With the IaaS model, the entire
    server image will be migrated with minimal code changes between the clouds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Authentication and authorization**: The authentication mechanism in the application
    to be analyzed for compatibility such as using forms-based authentication and
    an access control service, or ACS with integration with enterprise on-premise
    active directory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interaction with other modules/applications**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Web services**: These can be hosted either as a web role or worker role,
    left as on-premise services, and can be exposed through APIs'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Native code**: A managed wrapper package can be created and deployed'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Third-party dependency**: These dependencies are validated to be consumed
    directly from web services'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Diagnostics support**: This implements custom logging and saves the log information
    to storage tables:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Push event logs to diagnostics store
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Push failed request logs to diagnostic store
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Push performance counter data to diagnostics store
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Miscellaneous**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Message queues**: Subscriptions used for message publish and subscribe model'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configuration changes**: Applications should not have any hardcoded physical
    disk or network access values'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Check for any third-party library or content references
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace static values and application states to handle scalability applications
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application log**: This is the management of custom logs'' capture and storage'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data migration strategy**: Application migration strategy should go hand-in-hand
    with data migration strategy, as most of the applications are data-centric. Applications
    can store data onto disk, or into a database or network storage; however migrating
    applications from on-premise to Cloud demands that users do not see any discrepancy
    in their data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cloud provides the flexibility to persist data in the same way they are stored;
    in the on-premise application. Cloud-hosted applications data can be saved in
    multiple ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Data from on-premise database to cloud-based database
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Static content to cloud storage
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Message queues to cloud queue storage / service bus queue
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Migration execution**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The web application migration from on-premise to cloud is planned component-wise
    in an incremental, independent fashion
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The section that follows explains the migration process for the PaaS and IaaS
    options
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Acronym Description**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Access Control Service** (**ACS**)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Active Directory Federation Service** (**ADFS**)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Infrastructure as a Service** (**IaaS**)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Platform as a Service** (**PaaS**)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/d35238e7-14ea-4be3-8314-cca2677baf31.png)'
  prefs: []
  type: TYPE_IMG
- en: Migration to microservices - DevOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DevOps principles and methodology are very appropriate for microservices while
    the latter migration involves architecture, API's, and code development. All of
    them would be under code version system, continuous integration, build, test systems
    till continuous deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Refactoring to microservices from monolithic architecture can be pursued in
    multiple ways. Here are three prime strategies listed.
  prefs: []
  type: TYPE_NORMAL
- en: Strategy 1 - standalone microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Implementing new functionality to the monolithic application should be put
    up as new code in addition to a standalone microservice, instead of adding to
    monolith application making it more bulky. The following diagram shows the system
    architecture after applying this approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a30a585d-5c63-4616-ac1e-1f89152a6ddd.png)'
  prefs: []
  type: TYPE_IMG
- en: In the new architecture, both the new service and the legacy monolith co-exist.
    There are two communication components. A request router handles incoming (HTTP)
    requests similar to the API gateway; the router sends requests corresponding to
    new functionality to the new service routing the legacy requests to the monolith.
  prefs: []
  type: TYPE_NORMAL
- en: The glue code is the second component to integrate the service with the monolith.
    The service needs to access data to read and write to the data owned and processed
    by the monolith application, and the glue code could reside in the monolith application,
    service, or both.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three strategies to access the monolith''s data by the service:'
  prefs: []
  type: TYPE_NORMAL
- en: Monolith applications remote API invoked
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Directly access the monolith's database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The service maintains its own data copy to synchronize regularly with the monolith's
    database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The glue code is an important function to translate between the two different
    models. The glue code maintains its own pristine domain model. The glue code has
    to prevent its own model from getting polluted by the concepts of the legacy monolith's
    domain model; hence, it's also referred to as an anti-corruption layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'This method of implementing new functionality as a lightweight service offers
    the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: The new functionality/service can be independently developed, deployed, and
    scaled, and not linked with the monolith
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new services created extend the benefits of the microservices architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It prevents the monolith from becoming bulkier and unmanageable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strategy 2 - separate frontend and backend
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This strategy is to separate the presentation layer from the business logic
    and data access layers in the monolithic application.
  prefs: []
  type: TYPE_NORMAL
- en: 'An enterprise application comprises at least three different layers, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Presentation layer**: This is a sophisticated user interface with a substantial
    body of code; it handles HTTP requests with HTML-based web UI or a (REST) API,
    and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Business logic layer**: This contains the core business rules components
    for the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data-access layer**: This accesses infrastructure components of databases
    and message brokers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the monolithic model, the division of roles and responsibilities between
    the layers is presentation logic and the business and data-access logic. The business
    tier encapsulates business-logic components with coarse-grained API's. This is
    a natural process to extend for microservices architecture by splitting the monolith
    into two segments. One segment contains the presentation layer and the other contains
    the business and data-access logic layer. Then, the presentation logic segment
    or application makes remote calls to the business logic application or segment,
    as shown in the following diagram for the architecture before and after the change.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ee987ed-10e4-4d8f-9295-95ebcd346b1f.png)'
  prefs: []
  type: TYPE_IMG
- en: The main benefits accrued are to enable, develop, deploy, and scale the two
    application segments independent of one another, such as the user interface from
    the presentation layer, so they can be iteratively and rapidly developed and tested;
    an other benefit of this approach is to expose a remote API for consumption by
    microservices.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, all the three layers are bulky monolith components. This strategy
    is only a partial solution, so the next strategy will be explored.
  prefs: []
  type: TYPE_NORMAL
- en: Strategy 3 - extraction of services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Turning existing modules within the monolith into standalone microservices is
    the third refactoring strategy. In this process, every time a module is extracted
    and turned into a service, the monolith gradually shrinks. With adequate conversion
    of modules, the monolith ceases to be an issue, disappears entirely, or becomes
    small enough to be another service.
  prefs: []
  type: TYPE_NORMAL
- en: Prioritizing the modules for conversion to services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A few factors that will facilitate this are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Initiating with a few modules that are easy to extract
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying the modules that will provide maximum benefit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying modules that change frequently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ranking the modules by benefit or frequency of change
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modules with unique resource requirements compared with other modules in a monolithic
    application, for example, those needing in-memory speed or computationally expensive
    algorithms, to be run on dedicated machines to scale the application quickly and
    easily
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modules with existing coarse-grained boundaries are easier and cheaper to turn
    into services; for example, as a module that communicates with the rest of the
    application only via asynchronous messages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adopting this approach, a complex monolithic application with tens or hundreds
    of modules can be conveniently extracted to microservices module after module,
    and thereafter the service can be developed and deployed independent of the monolith
    to accelerate development.
  prefs: []
  type: TYPE_NORMAL
- en: The process to extract a module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The initial phase to extract a module involves creating a coarse-grained interaction
    between the module and the monolith application, to be a bidirectional API for
    the data exchange between the monolith and the service. As per the tangled dependencies
    and fine-grained interaction patterns, it will be challenging to implement between
    the module and the rest of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Domain model pattern-based business logic with numerous associations of domain
    model class dependencies can be altered with code changes. A coarse-grained module
    conversion into a free-standing service to communicate through **inter-process
    communication** (**IPC**) API enables the monolith and the service.
  prefs: []
  type: TYPE_NORMAL
- en: 'The architecture before, during, and after the refactoring is listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9da582f4-8444-4cd6-8b0d-3ba8110a357b.png)'
  prefs: []
  type: TYPE_IMG
- en: In the initial architecture, as seen in the top left of the preceding figure,
    the input process flow is from **Module X** to **Module Z**. Then, **Module Y**
    uses inputs from **Module Z**.
  prefs: []
  type: TYPE_NORMAL
- en: Stage 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The refactoring stage defines a pair of coarse-grained APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The initial interface is an inbound input from **Module X** to invoke **Module
    Z**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The outbound interface from **Module Z** is consumed to invoke **Module Y**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stage 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this refactoring stage, the module is rebased as a standalone service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The inbound and outbound interactions are implemented using an IPC mechanism
    code-based service by combining **Module Z** with a microservice chassis framework
    that handles service discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After extracting the module, the service can be developed, deployed, and scaled
    independent of the monolith and other services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The service can be rewritten from scratch with API code as an anticorruption
    layer that translates between the two domain models to integrate the service with
    the monolith
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every extracted service is an advance in direction of microservices; eventually
    the monolith will shrink over time with the increasing number of microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apps modernization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adoption of microservices is a form of application modernization for migrating
    an existing application into modern platforms. This is incrementally planned,
    and not attempted from scratch, by rewriting the code. As we have seen, the strategies
    involves separating the presentation layer components from the business and data
    access components converting existing modules into services, and implementing
    new features and functionality as microservices to improve the application agility
    and performance.
  prefs: []
  type: TYPE_NORMAL
- en: Architecture migration approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Forrester Research and InfoWorld propose a four-tier engagement/architecture
    platform toward microservices. This architecture model adopts the changes in computing
    and penetration of mobile devices for application development.
  prefs: []
  type: TYPE_NORMAL
- en: The foremost consideration is to decide on microservices architecture and design
    the services interaction before optimizing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The four-tier approach to microservices is broken down into the following different
    layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Client tier**: This is customer experience based on mobile clients and IoT'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Delivery tier**: This optimizes user experience based on the device personalizing
    content by monitoring user choices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Aggregation tier**: This aggregates data from the services tier a long with
    data protocol translation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Services tier**: This is the usage of existing data services in-house, or
    external services, such as Twilio and Box'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The biggest difference is the separation of the client tier; based on real-time
    interaction with users the layers underneath can be constantly changing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The strategy to adopt microservices can be summarized as the following three
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Componentized**: Identifying components from existing applications and creating
    a microservices implementation on a pilot basis'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collaborate**: New processes and initiatives based on the lessons learned
    from the pilot stage to evaluate with stakeholders, programmers, and developers
    on the team'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Connect**: Adopting microservices application to real-world scenarios'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data coupling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices architecture is loosely coupled where the data is often communicated
    through APIs. A microservice could even run with small code, but be focused to
    manage a single task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Loose coupling is based on following aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: Scope boundary is defined and intelligence built-in.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intelligence is separated from the messaging function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compatible with similar functions' microservices, and tolerance for a wide variety
    of modifications; changes are not forced or coordinated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Services are decoupled with APIs giving them freedom and flexibility. An API
    is a contract for services with specifications on what the services provide and
    also the way programs rely on them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservices scalability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As per this listed architecture scalability model, these can include:'
  prefs: []
  type: TYPE_NORMAL
- en: Functional decomposition (Y-axis scaling)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data partitioning (X-axis scaling)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Horizontal scaling of individual services (X-axis scaling)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/0dd60b22-5b2c-4ca5-a82f-e7bd5e3923ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Best practices for architectural and implementation considerations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Migrating to microservices is a strategy, and it needs step-by-step planning,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Separating classes in a monolithic app
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying classes that have CRUD-style interfaces with other business methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying isolated classes with no dependencies on other classes, apart from
    the code needed to interact with external services, such as Memcache, Cloud Datastore,
    or Task Queue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying sections of code isolated from others with static code analysis
    tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refactor code to remove unwanted dependencies, as circular dependencies are
    the most difficult to address
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As prerequisite to the move to microservices, refactor legacy codebase in production:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Identify common areas for microservices as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Account and user information
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Authorization and session management
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration or preferences settings
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Notifications and communications services
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Photos and media, especially metadata
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The next steps for porting to microservices, post identification of classes
    set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rollback option by retaining the existing code operational in the legacy application
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: New code repository creation, and copying the classes into it
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Create HTTP API through view layer to provide the hook to format appropriately
    the response documents
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: New code creation as a separate application (`exampleapp.yaml`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: New microservice deployed as a service or separate project
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Functional testing of the code
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Data migration from the legacy app to the new microservice
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Legacy application modified to make use of the new microservice application
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Altered legacy application to be deployed
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure adequate verifications in functionality and performance
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Dead code if any from the legacy application is removed
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Domain modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the heart of designing coherent and loosely coupled microservices is domain
    modeling, to ensure isolation and insulation of microservices and their reusability.
    Each application's microservices should be adequately isolated from runtime side
    effects, and also insulated from changes during the implementation of other microservices
    in the system. Proper domain modeling helps avoid the modeling shortcomings in
    the system based on technological or organizational boundaries, resulting in separation
    of services for data, business logic, presentation logic, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: An example could be extraction of promotions services from a monolithic e-commerce
    system to be consumed by various clients using mobile Web, iOS, or Android apps.
    So, the domain model of *promotions,* along with its state entities and logic,
    are to be insulated, and not polluted with cross-domain logic or entities from
    other domains of the system, such as products, customers, or orders.
  prefs: []
  type: TYPE_NORMAL
- en: Service size
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The right service size for a microservice based on the *Single Responsibility
    Principle* is a driving force for independent operation, and testing advocates
    as small a service size as appropriate, possibly similar to Unix-based utilities
    for small code bases that are easy to maintain and upgrade.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on product type, and based on different business logic, encapsulating
    can become overwhelming, so the better approach is to consider adding more boundaries
    inside the product domains and create further services. Another option is to consider
    the time to replace the microservice with a new implementation or technology and
    accordingly plan for size reworking.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing plays an important role while a monolithic system is progressively transformed
    into a microservice-enabled system; integration testing of the services with the
    monolithic system to be executed and also business operations spanning the pre-existing
    monolithic system continue to perform with new microservices systems. The system-provided
    consumer-driven contracts can be translated into test cases for testing the new
    microservices, in which case automated tests ensure expectations from the system
    are met.
  prefs: []
  type: TYPE_NORMAL
- en: 'A few automated test suites are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Pact`, a consumer-driven contract testing library, which creates a reusable
    test environment to deploy a test copy of the entire system for testing the microservices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using an automation tool such as Docker compose, which can containerize the
    entire system in the form of Docker containers orchestrated to quickly deploy
    the test infrastructure of the system to perform integration tests locally
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A service discovery system enables services to know of each other while accomplishing
    a business function. Each service refers to an external registry with details
    of the other services. This can be accomplished with environment variables for
    a small number of services; service discovery for more sophisticated systems rely
    commonly on Consul and Apache Zookeeper.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The deployment of each microservice should be self-enabled through a runtime
    container or by embedding a container in itself similar to how a JVM-based microservice
    Tomcat can container be embedded eliminating the need for a standalone web application
    server. At any instance, a number of microservices of the similar type (reference
    scale cube X-axis scaling) exist to allow more reliable handling of requests.
    A software load balancer to act as a service registry is included in implementations
    for failover and transparent balancing of requests, such as Netflix Eureka.
  prefs: []
  type: TYPE_NORMAL
- en: Build and release pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuous integration and deployment pipelines are highly valuable for implementing
    microservice-based systems with on-demand, build and release, exclusive pipeline
    for each microservice reducing the cost of building and releasing the whole application.
  prefs: []
  type: TYPE_NORMAL
- en: Rolling upgrades (or blue-green deployment) should be part of release practices,
    which means if its green the upgrade is successful, otherwise a rollback strategy
    should be implemented. This can also be achieved by maintaining concurrent versions
    of the same microservice running in the production environment at any point in
    time (existing versions along with new builds) to quickly swap as needed. In this
    scenario, an active percentage of the user load can be routed to the new microservice
    version to test its operation, while gradually phasing out the older versions.
    This builds redundancy in the system against failed changes in a microservice
    crippling the system.
  prefs: []
  type: TYPE_NORMAL
- en: Feature flags
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservice patterns include feature flags. It's a configuration parameter
    added to the system to allow toggling on or off to a feature. This pattern in
    the system facilitates to trigger the use of the requisite microservice for the
    feature associated with the flag option (say, turned on). For example, the same
    feature can coexist both in a new microservice and production, the traffic can
    be routed with the feature flag; this enables delivery teams to expedite the build
    cycle time.
  prefs: []
  type: TYPE_NORMAL
- en: Developer productivity with microservices adoption
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monolithic architectures allow quick turnaround of new business features on
    a tight schedule, whereas the overall system is small. However, as the system
    becomes bulkier, both development and operations are cumbersome.
  prefs: []
  type: TYPE_NORMAL
- en: Building new features or systems with the microservices' first approach is complicated,
    with many moving parts. Although it demands strong disciplines around architecture
    and automation, investing is rewarding in terms of creating an environment for
    teams to build microservices quickly and cleanly. One method is to create a standard
    boilerplate project that encapsulates key microservice design principles with
    project structure, test automation, integration with monitoring and instrumentation
    infrastructures, patterns of circuit breakers and timeouts, documentation hooks,
    API frameworks, and so on. These kinds of project templates help focus on building
    business functionality in a microservices-based distributed environment rather
    than scaffolding and glue code. A few interesting approaches are projects such
    as Dropwizard, Spring Boot, and Netflix Karyon, with choices based on architecture
    and developer skill level.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monitoring of coexisting features in both monolithic systems and microservices
    enables better visibility of the performance gains of implementing the new microservice
    implementation. This requires collecting statistics for comprehensive monitoring
    of performance of systems and resources to improve confidence in pursuing further
    migration.
  prefs: []
  type: TYPE_NORMAL
- en: Organizational considerations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Organizational changes are the most challenging components of migrating from
    monolithic systems to microservices, such as building service teams to own all
    aspects of their microservices. To embrace more collective code, ownership requires
    creating multidisciplinary units with developers, testers, and operations staff
    who care about software craftsmanship.
  prefs: []
  type: TYPE_NORMAL
- en: DevOps for data science
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data science projects involve majorly the multiple streams of roles performing
    different functions of big data engineers, data scientists, and operations teams.
    For data engineers, primary activities include ETL, preparing data sets for analysis,
    and coding for the models developed by data scientists into scripts. Data scientists
    are involved in developing the models, evaluating different algorithms and models
    based on sample test data and validating them with real data.
  prefs: []
  type: TYPE_NORMAL
- en: In this silo-working scenario, the team output may be confined to Poc's and
    not extend to big projects. However, even the minor tasks require overlap of skills
    as well as multiple interactions and design sessions with big data engineers,
    data scientists, and operations teams.
  prefs: []
  type: TYPE_NORMAL
- en: 'DevOps can bridge the gap between the streams for collaborative working by
    adopting best practices:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tools and platforms evolution**: Engineers and data scientists should continuously
    evaluate and contribute to the creation of new tools and open source project,
    and base lining Apache Spark/Hadoop ecosystem to be stable and user-friendly for
    day-to-day operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cross-skills education**: Data scientists should collaboratively consider
    the realistic, rational, and practical possibility rather than be confined to
    writing code with abstractions, such as the time duration for query and extracted
    data suffices into the storage system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Process improvement**: DevOps is the way forward not just limited tools implementation
    such as writing Ansible scripts or installing Jenkins. DevOps should aid in invent
    of new tools of self-service for enhanced productivity and reduce hand-off between
    teams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The DevOps continuous analytics environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With maturity of continuous analytics and self-service, data scientist ownership
    extends from the original idea all the way to production for the data project.
    Being autonomous  helps us to dedicate more time to producing actual insights.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data scientists operate through the following multiple phases:'
  prefs: []
  type: TYPE_NORMAL
- en: Start with the original business idea and work on data exploration and preparation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Invest in model development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment and validation of the environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deployment to production: with proper tools, they are equipped to run complete
    iteration multiple times a day themselves, with quicker turnaround'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Big data engineers focus on developing and contributing to tools, such as Spark,
    scalability, and storage optimization, enabling streaming architectures, and providing
    APIs and DSLs needed for the data scientist.
  prefs: []
  type: TYPE_NORMAL
- en: Product engineers can build smart applications for business users based on bundled
    services of analytical models developed by data scientists.
  prefs: []
  type: TYPE_NORMAL
- en: Each person is working with their own abstractions and contributing to the overall
    success in this collaborative mode.
  prefs: []
  type: TYPE_NORMAL
- en: DevOps for authentication and security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data security with Kerberos is listed as the the following process
  prefs: []
  type: TYPE_NORMAL
- en: An authentication protocol
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tickets to authenticate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid locally storing passwords or sending them over the internet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A trusted third-party validation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Symmetric-key cryptography
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kerberos realm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kerberos realm is based on policy management definitions; it encompasses all
    that is available to access such as clients, services, hosts, and a **Key Distribution
    Center** (**KDC**) (Authentication Server and the **Ticket Granting Server** (**TGS**)).
    Proof of identity is user/password credentials encrypted with a secret key for
    the particular service requested, and **single sign-on** (**SSO**) authenticates
    ticket created with a new login or with a cache on the system.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8de5cc5b-2dec-494e-aa88-8a4fc8332ffc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Accessing request to a service or host happens through the following interactions:'
  prefs: []
  type: TYPE_NORMAL
- en: The authentication server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ticket granting server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The service or host machine needed to access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: KDC stores all of the secret keys for user machines and services in its database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The secret keys are passwords along with the hash algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A key is generated during initial setup and memorized on the service/host machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secret keys are all stored in the KDC database, based on symmetric-key cryptography
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kerberos can also use public-key cryptography instead of symmetrical key encryption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user and the authentication server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The service request authentication between user and server is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Access to an HTTP service needs authentication with the server through TGT
    from the host terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/58d9e047-876d-4092-be6f-d4bdae78a24f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The authentication server will check validity in the KDC database, but not
    for the credentials:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/50642f78-5b41-44d9-b48e-ba4be67d4c76.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the validity is established, a session key is created between the user
    and the **Ticket Granting Server** (**TGS**):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ab924282-4d31-412e-97ae-f3ed2dfa2b87.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A client secret key (password) validates and authorizes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f40d7d2e-74c4-4f91-b72b-6e8a0eb3d0ab.png)'
  prefs: []
  type: TYPE_IMG
- en: 'HTTP service requests also follow the similar process of encrypted authentication:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/db5eee95-528b-40ca-91a7-2cb65812ebbb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The TGS will check the KDC database for HTTP service availability:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/db4c57c1-b0ce-4740-9aae-633d9503ff35.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To render the web service page, TGS decrypts the TGT with its secret key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ab924282-4d31-412e-97ae-f3ed2dfa2b87.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The TGS randomly generates the HTTP service session key, prepares the HTTP
    service ticket, and encrypts it with the HTTP service secret key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/db5eee95-528b-40ca-91a7-2cb65812ebbb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'TGS sends the encrypted HTTP service ticket; however, the machine waits for
    the HTTP service secret key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/69b0d7b4-df1f-4551-8a85-4a6ab1834875.png)'
  prefs: []
  type: TYPE_IMG
- en: Client and the HTTP service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The service request between HTTP service and client node is as following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To access the HTTP service, the client machine prepares another authenticator
    message and is encrypted with the HTTP service session key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c47e79a6-15bf-4ed8-8727-7fac58f4e64e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The HTTP service then decrypts the ticket with its secret key to obtain the
    HTTP service session key and decrypt the authenticator message is shared:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7a8d4009-f9d5-4030-b9ff-0d59151eff86.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similar to the TGS and the HTTP server sends an authenticator message encrypted
    with the HTTP service session key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8eb2fd42-d4fc-43ec-b404-1e92212bf3d1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The client machine reads the authenticator message by decrypting with the cached
    HTTP service session key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/beba1687-8b7b-46d0-95a3-6090575fa677.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Future requests use the cached HTTP service ticket, so long as it has not expired
    as defined within the lifetime attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ea98c2ea-078d-4603-90eb-b762259203b3.png)'
  prefs: []
  type: TYPE_IMG
- en: The security authentication process involves multiple servers, policy, and credentials
    management, which when enabled with DevOps are highly effective for automated
    upgrades, deployments, and so on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: DevOps for IoT systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback drives the value. The fundamental aspect of DevOps is to gain insights
    into performance and usage quickly, which translates to feedback for further refinement
    to design and automate delivery pipelines to improve the quality of our software
    delivery, and to drive the most value for our customers and business. Closer customer
    contacts to solicit feedback and usage metrics analysis, followed by continuous
    improvement, helps agile organizations respond promptly to emerging requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'In IoT, we gather feedback about device performance and usage that can help
    us with:'
  prefs: []
  type: TYPE_NORMAL
- en: Preventive maintenance by predicting the need for repair based on actual usage
    characteristics, which reduces the duration of periodic maintenance and improves
    overall maintenance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatically adjusting settings to improve energy consumption and to improve
    the quality of the service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Insights gained from devices that can improve the behaviors of all the connected
    devices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement to products and services over time, based on customers' unique needs
    and actions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consumer IoT; constant feedback on devices wearable devices can help improve
    their performance such as battery life span, for example, smartphones, watches,
    fridges, and cars.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Industrial IoT; consumer, and industrial IoT drive value through the feedback
    loop. Businesses can thus ensure a reliable, compelling, and profitable offering
    that requires the operator and manufacturer have intimate knowledge of device
    performance based on metrics; for example, embedded microprocessors in your thermostat,
    sprinkler systems, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vital to the business value chain is listening to the feedback from customers,
    systems, and devices. DevOps agility helps smart organizations address IoT software
    challenges.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IoT is more than hardware and connectivity. It needs software to be able to
    develop and update it quickly while ensuring its performance securely and efficiently.
    Continuous delivery and continuous deployment are only feasible through automation
    on a wider scale. Mixing agile practices into DevOps accelerates development cycles
    with incremental builds, and frequent releases of small batches of code makes
    for faster and safer releases.
  prefs: []
  type: TYPE_NORMAL
- en: Security by design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The new feedback mechanism comes at a cost in terms of security; connected products,
    and systems now expose additional risk from hackers and malware. Safety-critical
    systems are to be developed with *Secure by design* methodology. For example,
    in mobile devices, **trusted platform modules** (**TPMs**) provide a restrictive
    area within the device to handle things, such as encryption, certificates, and
    keys. This impacts battery power, considered a non-functional requirement in DevOps
    parlance. Security is not siloed; it's part of the development cycle, in the similar
    way that product, quality, and performance are in-built. Addressing these significant
    concerns means organizations that use modern development practices are well set
    up to cope with the challenges of IoT.
  prefs: []
  type: TYPE_NORMAL
- en: DevOps adoption is more than science; it is an art for the digital transformation
    journey in the light of DevOps adoption to systems of big data, Cloud, microservices,
    data sciences, authentication security, and IoT.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the digital transformation journey with DevOps
  prefs: []
  type: TYPE_NORMAL
- en: adoption for complex enterprise systems of big data migration, cloud migration,
    microservices migration, data science, authentication systems, and Internet of
    Things.
  prefs: []
  type: TYPE_NORMAL
