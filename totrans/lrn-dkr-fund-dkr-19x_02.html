<html><head></head><body>
        

                            
                    <h1 class="header-title">What Are Containers and Why Should I Use Them?</h1>
                
            
            
                
<p class="p1">This first chapter will introduce you to the world of containers and their orchestration. This book starts from the very beginning, in that it assumes that you have no prior knowledge of containers, and will give you a very practical introduction to the topic.</p>
<p class="p1">In this chapter, we will focus on the software supply chain and the friction within it. Then, we'll present containers, which are used to reduce this friction and add enterprise-grade security on top of it. We'll also look into how containers and the ecosystem around them are assembled. We'll specifically point out the distinction between the upstream <strong>Open Source Software</strong> (<strong>OSS</strong>) components, united under the code name Moby, that form the building blocks of the downstream products of Docker and other vendors.</p>
<p class="p1">The chapter covers the following topics:</p>
<ul>
<li class="p1">What are containers?</li>
<li class="p1">Why are containers important?</li>
<li class="p1">What's the benefit for me or for my company?</li>
<li class="p1">The Moby project</li>
<li class="p1">Docker products</li>
<li class="p1">Container architecture</li>
</ul>
<p class="mce-root"/>
<p class="p1">After completing this module, you will be able to do the following:</p>
<ul>
<li class="p1">Explain what containers are, using an analogy such as physical containers, in a few simple sentences to an interested layman</li>
<li class="p1">Justify why containers are so important using an analogy such as physical containers versus traditional shipping or apartment homes versus single-family homes, and so on, to an interested lay person</li>
<li class="p1">Name at least four upstream open source components that are used by Docker products, such as Docker for Desktop</li>
<li class="p1">Identify at least three Docker products</li>
</ul>
<p class="p2"/>


            

            
        
    

        

                            
                    <h1 class="header-title">What are containers?</h1>
                
            
            
                
<p class="p2">A software container is a pretty abstract thing, so it might help if we start with an analogy that should be pretty familiar to most of you. The analogy is a shipping container in the transportation industry. Throughout history, people have been transporting goods from one location to another by various means. Before the invention of the wheel, goods would most probably have been transported in bags, baskets, or chests on the shoulders of the humans themselves, or they might have used animals such as donkeys, camels, or elephants to transport them.</p>
<p class="p2">With the invention of the wheel, transportation became a bit more efficient as humans built roads that they could move their carts along. Many more goods could be transported at a time. When the first steam-driven machines, and later gasoline-driven engines, were introduced, transportation became even more powerful. We now transport huge amounts of goods on trains, ships, and trucks. At the same time, the types of goods became more and more diverse, and sometimes complex to handle.</p>
<p class="p1">In all these thousands of years, one thing didn't change, and that was the necessity to unload goods at a target location and maybe load them onto another means of transportation. Take, for example, a farmer bringing a cart full of apples to a central train station where the apples are then loaded onto a train, together with all the apples from many other farmers. Or think of a winemaker bringing his barrels of wine with a truck to the port where they are unloaded, and then transferred to a ship that will transport them overseas.</p>
<p class="mce-root"/>
<p class="p1">This unloading from one means of transportation and loading onto another means of transportation was a really complex and tedious process. Every type of product was packaged in its own way and thus had to be handled in its own particular way. Also, loose goods faced the risk of being stolen by unethical workers or damaged in the process of being handled.</p>
<p class="p1">Then, there came containers and they totally revolutionized the transportation industry. A container is just a metallic box with standardized dimensions. The length, width, and height of each container is the same. This is a very important point. Without the World agreeing on a standard size, the whole container thing would not have been as successful as it is now.</p>
<p class="p1">Now, with standardized containers, companies who want to have their goods transported from A to B package those goods into these containers. Then, they call a shipper, which comes with a standardized means for transportation. This can be a truck that can load a container or a train whose wagons can each transport one or several containers. Finally, we have ships that are specialized in transporting huge numbers of containers. Shippers never need to unpack and repackage goods. For a shipper, a container is just a black box, and they are not interested in what is in it, nor should they care in most cases. It is just a big iron box with standard dimensions. Packaging goods into containers is now fully delegated to the parties who want to have their goods shipped, and they should know how to handle and package those goods.</p>
<p class="p1">Since all containers have the same agreed-upon shape and dimensions, shippers can use standardized tools to handle containers; that is, cranes that unload containers, say from a train or a truck, and load them onto a ship and vice versa. One type of crane is enough to handle all the containers that come along over time. Also, the means of transportation can be standardized, such as container ships, trucks, and trains.</p>
<p class="p1">Because of all this standardization, all the processes in and around shipping goods could also be standardized and thus made much more efficient than they were before the age of containers.</p>
<p class="p1">Now, you should have a good understanding of why shipping containers are so important and why they revolutionized the whole transportation industry. I chose this analogy purposefully, since the software containers that we are going to introduce here fulfill the exact same role in the so-called software supply chain that shipping containers do in the supply chain of physical goods.</p>
<p class="mce-root"/>
<p class="p1">In the old days, developers would develop a new application. Once that application was completed in their eyes, they would hand that application over to the operations engineers, who were then supposed to install it on the production servers and get it running. If the operations engineers were lucky, they even got a somewhat accurate document with installation instructions from the developers. So far, so good, and life was easy.</p>
<p class="p1">But things get a bit out of hand when, in an enterprise, there are many teams of developers that create quite different types of application, yet all of them need to be installed on the same production servers and kept running there. Usually, each application has some external dependencies, such as which framework it was built on, what libraries it uses, and so on. Sometimes, two applications use the same framework but in different versions that might or might not be compatible with each other. Our operations engineer's life became much harder over time. They had to be really creative with how they could load their ship, (their servers,) with different applications without breaking something.</p>
<p class="p1">Installing a new version of a certain application was now a complex project on its own, and often needed months of planning and testing. In other words, there was a lot of friction in the software supply chain. But these days, companies rely more and more on software, and the release cycles need to become shorter and shorter. We cannot afford to just release twice a year or so anymore. Applications need to be updated in a matter of weeks or days, or sometimes even multiple times per day. Companies that do not comply risk going out of business, due to the lack of agility. So, what's the solution?</p>
<p class="p1">One of the first approaches was to use <strong>virtual machines</strong> (<strong>VMs</strong>). Instead of running multiple applications, all on the same server, companies would package and run a single application on each VM. With this, all the compatibility problems were gone and life seemed to be good again. Unfortunately, that happiness didn't last long. VMs are pretty heavy beasts on their own since they all contain a full-blown operating system such as Linux or Windows Server, and all that for just a single application. This is just as if you were in the transportation industry and were using a whole ship just to transport a single truckload of bananas. What a waste! That could never be profitable.</p>
<p class="p1">The ultimate solution to this problem was to provide something that is much more lightweight than VMs, but is also able to perfectly encapsulate the goods it needs to transport. Here, the goods are the actual application that has been written by our developers, plus – and this is important – all the external dependencies of the application, such as its framework, libraries, configurations, and more. This holy grail of a software packaging mechanism was the <em>Docker container</em>.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="p1">Developers use Docker containers to package their applications, frameworks, and libraries into them, and then they ship those containers to the testers or  operations engineers. To testers and operations engineers, a container is just a black box. It is a standardized black box, though. All containers, no matter what application runs inside them, can be treated equally. The engineers know that, if any container runs on their servers, then any other containers should run too. And this is actually true, apart from some edge cases, which always exist.</p>
<p class="p1">Thus, Docker containers are a means to package applications and their dependencies in a standardized way. Docker then coined the phrase <em>Build, ship, and run anywhere</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Why are containers important?</h1>
                
            
            
                
<p class="p2">These days, the time between new releases of an application become shorter and shorter, yet the software itself doesn't become any simpler. On the contrary, software projects increase in complexity. Thus, we need a way to tame the beast and simplify the software supply chain.</p>
<p class="p2">Also, every day, we hear that cyber-attacks are on the rise. Many well-known companies are and have been affected by security breaches. Highly sensitive customer data gets stolen during such events, such as social security numbers, credit card information, and more. But not only customer data is compromised – sensitive company secrets are stolen too.</p>
<p class="p2">Containers can help in many ways. First of all, Gartner found that applications running in a container are more secure than their counterparts not running in a container. Containers use Linux security primitives such as Linux kernel <em>namespaces</em> to sandbox different applications running on the same computers and <strong>control groups</strong> (<strong>cgroups</strong>) in order to avoid the noisy-neighbor problem, where one bad application is using all the available resources of a server and starving all other applications.</p>
<p class="p2">Due to the fact that container images are immutable, it is easy to have them scanned for <strong>common vulnerabilities and exposures</strong> (<strong>CVEs</strong>), and in doing so, increase the overall security of our applications.</p>
<p class="p1">Another way to make our software supply chain more secure is to have our containers use a content trust. A content trust basically ensures that the author of a container image is who they pretend to be and that the consumer of the container image has a guarantee that the image has not been tampered with in transit. The latter is known as a <strong>man-in-the-middle </strong>(<strong>MITM</strong>) attack.</p>
<p class="mce-root"/>
<p class="p1">Everything I have just said is, of course, technically also possible without using containers, but since containers introduce a globally accepted standard, they make it so much easier to implement these best practices and enforce them.</p>
<p class="p1">OK, but security is not the only reason why containers are important. There are other reasons too.</p>
<p class="p1">One is the fact that containers make it easy to simulate a production-like environment, even on a developer's laptop. If we can containerize any application, then we can also containerize, say, a database such as Oracle or MS SQL Server. Now, everyone who has ever had to install an Oracle database on a computer knows that this is not the easiest thing to do, and it takes up a lot of precious space on your computer. You wouldn't want to do that to your development laptop just to test whether the application you developed really works end-to-end. With containers at hand, we can run a full-blown relational database in a container as easily as saying 1, 2, 3. And when we're done with testing, we can just stop and delete the container and the database will be gone, without leaving a trace on our computer.</p>
<p class="p1">Since containers are very lean compared to VMs, it is not uncommon to have many containers running at the same time on a developer's laptop without overwhelming the laptop.</p>
<p class="p1">A third reason why containers are important is that operators can finally concentrate on what they are really good at: provisioning the infrastructure and running and monitoring applications in production. When the applications they have to run on a production system are all containerized, then operators can start to standardize their infrastructure. Every server becomes just another Docker host. No special libraries or frameworks need to be installed on those servers, just an OS and a container runtime such as Docker.</p>
<p class="p1">Also, operators do not have to have intimate knowledge of the internals of applications anymore, since those applications run self-contained in containers that ought to look like black boxes to them, similar to how shipping containers look to the personnel in the transportation industry.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">What's the benefit for me or for my company?</h1>
                
            
            
                
<p class="p2">Somebody once said that, today, every company of a certain size has to acknowledge that they need to be a software company. In this sense, a modern bank is a software company that happens to specialize in the business of finance. Software runs all businesses, period. As every company becomes a software company, there is a need to establish a software supply chain. For the company to remain competitive, their software supply chain has to be secure and efficient. Efficiency can be achieved through thorough automation and standardization. But in all three areas – security, automation, and standardization – containers have been shown to shine. Large and well-known enterprises have reported that, when containerizing existing legacy applications (many call them traditional applications) and establishing a fully automated software supply chain based on containers, they can reduce the cost for the maintenance of those mission-critical applications by a factor of 50% to 60% and they can reduce the time between new releases of these traditional applications by up to 90%.</p>
<p class="p2">That being said, the adoption of container technologies saves these companies a lot of money, and at the same time it speeds up the development process and reduces the time to market.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Moby project</h1>
                
            
            
                
<p class="p2">Originally, when Docker (the company) introduced Docker containers, everything was open source. Docker didn't have any commercial products at this time. The Docker engine that the company developed was a monolithic piece of software. It contained many logical parts, such as the container runtime, a network library, a <strong>RESTful</strong> (<strong>REST</strong>) API, a command-line interface, and much more.</p>
<p class="p2">Other vendors or projects such as Red Hat or Kubernetes were using the Docker engine in their own products, but most of the time, they were only using part of its functionality. For example, Kubernetes did not use the Docker network library for the Docker engine but provided its own way of networking. Red Hat, in turn, did not update the Docker engine frequently and preferred to apply unofficial patches to older versions of the Docker engine, yet they still called it the Docker engine.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="p1">Out of all these reasons, and many more, the idea emerged that Docker had to do something to clearly separate the Docker open source part from the Docker commercial part. Furthermore, the company wanted to prevent competitors from using and abusing the name Docker for their own gains. This was the main reason why the Moby project was born. It serves as an umbrella for most of the open source components Docker developed and continues to develop. These open source projects do not carry the name Docker in them anymore.</p>
<p class="p1">The Moby project provides components that are used for image management, secret management, configuration management, and networking and provisioning, to name just a few. Also, part of the Moby project is special Moby tools that are, for example, used to assemble components into runnable artifacts.</p>
<p class="p1">Some components that technically belong to the Moby project have been donated by Docker to the Cloud-Native Computing Foundation (CNCF) and thus do not appear in the list of components anymore. The most prominent ones are <kbd>notary</kbd>, <kbd>containerd</kbd>, and <kbd>runc</kbd>, where the first is used for content trust and the latter two form the container runtime.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Docker products</h1>
                
            
            
                
<p class="p2">Docker currently separates its product lines into two segments. There is the <strong>Community</strong> <strong>Edition</strong> (<strong>CE</strong>), which is closed-source yet completely free, and then there is the <strong>Enterprise Edition</strong> (<strong>EE</strong>), which is also closed-source and needs to be licensed on a yearly basis. These enterprise products are backed by 24/7 support and are supported by bug fixes.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Docker CE</h1>
                
            
            
                
<p class="p2">Part of the Docker Community Edition are products such as the Docker Toolbox and Docker for Desktop with its editions for Mac and Windows. All these products are mainly targeted at developers.</p>
<p class="p2">Docker for Desktop is an easy-to-install desktop application that can be used to build, debug, and test Dockerized applications or services on a macOS or Windows machine. Docker for macOS and Docker for Windows are complete development environments that are deeply integrated with their respective hypervisor framework, network, and filesystem. These tools are the fastest and most reliable way to run Docker on a Mac or Windows.</p>
<p class="p2">Under the CE umbrella, there are also two products that are more geared toward operations engineers. These products are Docker for Azure and Docker for AWS.</p>
<p class="mce-root"/>
<p class="p1">For example, with Docker for Azure, which is a native Azure application, you can set up Docker in a few clicks, optimized for and integrated with underlying Azure <strong>Infrastructure as a Service</strong> (<strong>IaaS</strong>) services. It helps operations engineers accelerate time to productivity when building and running Docker applications in Azure.</p>
<p class="p1">Docker for AWS works very similarly but for Amazon's cloud.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Docker EE</h1>
                
            
            
                
<p class="p2">The Docker Enterprise Edition consists of the <strong>Universal Control Plane</strong> (<strong>UCP</strong>) and the <strong>Docker Trusted Registry</strong> (<strong>DTR</strong>), both of which run on top of Docker Swarm. Both are swarm applications. Docker EE builds on top of the upstream components of the Moby project and adds enterprise-grade features such as <strong>role-based access control</strong> (<strong>RBAC</strong>), multi-tenancy, mixed clusters of Docker swarm and Kubernetes, web-based UI, and content trust, as well as image scanning on top.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Container architecture</h1>
                
            
            
                
<p class="p2">Now, let's discuss how a system that can run Docker containers is designed at a high level. The following diagram illustrates what a computer that Docker has been installed on looks like. Note that a computer that has Docker installed on it is often called a Docker host because it can run or host Docker containers:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-844 image-border" src="img/07669239-7cef-4bc6-ab0e-2e70c47473e4.png" style="width:30.33em;height:16.75em;"/></p>
<p>High-level architecture diagram of the Docker engine</p>
<p class="p1">In the preceding diagram, we can see three essential parts:</p>
<ul>
<li class="p1">On the bottom, we have the <strong>Linux operating system</strong></li>
<li class="p1">In the middle, in dark gray, we have the container runtime</li>
<li class="p1">On the top, we have the <strong>Docker engine</strong></li>
</ul>
<p class="p1">Containers are only possible due to the fact that the Linux OS provides some primitives, such as namespaces, control groups, layer capabilities, and more, all of which are leveraged in a very specific way by the container runtime and the Docker engine. Linux kernel namespaces, such as <strong>process ID</strong> (<strong>pid</strong>) namespaces or <strong>network</strong> (<strong>net</strong>) namespaces, allow Docker to encapsulate or sandbox processes that run inside the container. <strong>Control Groups</strong> make sure that containers cannot suffer from the noisy-neighbor syndrome, where a single application running in a container can consume most or all of the available resources of the whole Docker host. <strong>Control Groups</strong> allow Docker to limit the resources, such as CPU time or the amount of RAM, that each container is allocated.</p>
<p class="p1">The container runtime on a Docker host consists of <kbd>containerd</kbd> and <kbd>runc</kbd>. <kbd>runc</kbd> is the low-level functionality of the container runtime, while <kbd>containerd</kbd>, which is based on <kbd>runc</kbd>, provides higher-level functionality. Both are open source and have been donated by Docker to the CNCF.</p>
<p class="p1">The container runtime is responsible for the whole life cycle of a container. It pulls a container image (which is the template for a container) from a registry if necessary, creates a container from that image, initializes and runs the container, and eventually stops and removes the container from the system when asked.</p>
<p class="p1">The <strong>Docker engine</strong> provides additional functionality on top of the container runtime, such as network libraries or support for plugins. It also provides a REST interface over which all container operations can be automated. The Docker command-line interface that we will use frequently in this book is one of the consumers of this REST interface.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p class="p2">In this chapter, we looked at how containers can massively reduce friction in the software supply chain and, on top of that, make the supply chain much more secure.</p>
<p class="p2">In the next chapter, we will learn how to prepare our personal or working environment such as that we can work efficiently and effectively with Docker. So, stay tuned.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Questions</h1>
                
            
            
                
<p class="p2">Please answer the following questions to assess your learning progress:</p>
<ol>
<li class="p2">Which statements are correct (multiple answers are possible)?</li>
</ol>
<p style="padding-left: 60px">A. A container is kind of a lightweight VM<br/>
B. A container only runs on a Linux host<br/>
C. A container can only run one process<br/>
D. The main process in a container always has PID 1<br/>
E. A container is one or more processes encapsulated by Linux namespaces and restricted by cgroups</p>
<ol start="2">
<li class="p2">In your own words, maybe by using analogies, explain what a container is.</li>
<li class="p2">Why are containers considered to be a game-changer in IT? Name three or four reasons.</li>
<li class="p2">What does it mean when we claim: <em>If a container runs on a given platform, then it runs anywhere...?</em> Name two to three reasons why this is true.</li>
<li>Docker containers are only really useful for modern greenfield applications based on microservices. Please justify your answer.</li>
</ol>
<p style="padding-left: 60px">A. True<br/>
B. False</p>
<ol start="6">
<li class="p2">How much does a typical enterprise save when containerizing its legacy applications?</li>
</ol>
<p style="padding-left: 60px">A. 20%<br/>
B. 33%<br/>
C. 50%<br/>
D. 75%</p>
<ol start="7">
<li class="p2">Which two core concepts of Linux are containers based on?</li>
</ol>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Further reading</h1>
                
            
            
                
<p class="p2">The following is a list of links that lead to more detailed information regarding the topics we discussed in this chapter:</p>
<ul>
<li class="p3">Docker overview: <a href="https://docs.docker.com/engine/docker-overview/" target="_blank">https://docs.docker.com/engine/docker-overview/</a></li>
<li class="p3">The Moby project: <a href="https://mobyproject.org/" target="_blank">https://mobyproject.org/</a></li>
<li class="p3">Docker products: <a href="https://www.docker.com/get-started" target="_blank">https://www.docker.com/get-started</a></li>
<li class="p2">Cloud-Native Computing Foundation: <a href="https://www.cncf.io/">https://www.cncf.io/</a></li>
<li class="p2">containerd – an industry-standard container runtime: <a href="https://containerd.io/" target="_blank">https://containerd.io/</a></li>
</ul>


            

            
        
    </body></html>