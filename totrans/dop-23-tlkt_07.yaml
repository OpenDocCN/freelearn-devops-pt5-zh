- en: Using Ingress to Forward Traffic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Applications that are not accessible to users are useless. Kubernetes Services
    provide accessibility with a usability cost. Each application can be reached through
    a different port. We cannot expect users to know the port of each service in our
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Ingress objects manage external access to the applications running inside a
    Kubernetes cluster. While, at first glance, it might seem that we already accomplished
    that through Kubernetes Services, they do not make the applications truly accessible.
    We still need forwarding rules based on paths and domains, SSL termination and
    a number of other features. In a more traditional setup, we'd probably use an
    external proxy and a load balancer. Ingress provides an API that allows us to
    accomplish these things, in addition to a few other features we expect from a
    dynamic cluster.
  prefs: []
  type: TYPE_NORMAL
- en: We'll explore the problems and the solutions through examples. For now, we first
    need to create a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As every other chapter so far, we'll start by creating a Minikube single-node
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: All the commands from this chapter are available in the `07-ingress.sh` ([https://gist.github.com/vfarcic/54ef6592bce747ff2d1b089834fc755b](https://gist.github.com/vfarcic/54ef6592bce747ff2d1b089834fc755b))
    Gist.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The cluster should be up-and-running, and we can move on.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring deficiencies when enabling external access through Kubernetes services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We cannot explore solutions before we know what the problems are. Therefore,
    we'll re-create a few objects using the knowledge we already gained. That will
    let us see whether Kubernetes services satisfy all the needs users of our applications
    might have. Or, to be more explicit, we'll explore which features we're missing
    when making our applications accessible to users.
  prefs: []
  type: TYPE_NORMAL
- en: We already discussed that it is a bad practice to publish fixed ports through
    services. That method is likely to result in conflicts or, at the very least,
    create the additional burden of carefully keeping track of which port belongs
    to which service. We already discarded that option before, and we won't change
    our minds now. Since we've clarified that, let's go back and create the Deployments
    and the Services from the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the `get` command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, these are the same Services and Deployments we previously created.
  prefs: []
  type: TYPE_NORMAL
- en: Before we move on, we should wait until all the Pods are up and running.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: If, in your case, some of the Pods are not yet running, please wait a few moments
    and re-execute the `kubectl get pods` command. We'll continue once they're ready.
  prefs: []
  type: TYPE_NORMAL
- en: 'One obvious way to access the applications is through Services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We retrieved the Minikube IP and the port of the `go-demo-2-api` Service. We
    used that information to send a request.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the `curl` command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The application responded with the status code `200` thus confirming that the
    Service indeed forwards the requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'While publishing a random, or even a hard-coded port of a single application
    might not be so bad, if we''d apply the same principle to more applications, the
    user experience would be horrible. To make the point a bit clearer, we''ll deploy
    another application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This application follows similar logic to the first. From the latter command,
    we can see that it contains a Deployment and a Service. The details are of no
    importance since the YAML definition is very similar to those we used before.
    What matters is that now we have two applications running inside the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s check whether the new application is indeed reachable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We retrieved the port of the new Service and opened the application in a browser.
    You should see a simple front-end with *The DevOps Toolkit* books. If you don't,
    you might want to wait a bit longer until the containers are pulled, and try again.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simplified flow of requests is depicted in the *Figure 7-1*. A user sends
    a request to one of the nodes of the cluster. That request is received by a Service
    and load balanced to one of the associated Pods. It''s a bit more complicated
    than that, with iptables, kube DNS, kube proxy, and a few other things involved
    in the process. We explored them in more detail in [Chapter 5](e499b152-2e33-455d-84be-5b3d201829f9.xhtml), *Using
    Services to Enable Communication Between Pods*, and there''s probably no need
    to go through them all again. For the sake of brevity, the simplified diagram
    should do:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3a4b96e8-7b0b-4bd1-8646-e5cc1ef6736a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-1: Applications access through Services'
  prefs: []
  type: TYPE_NORMAL
- en: We cannot expect our users to know specific ports behind each of those applications.
    Even with only two, that would not be very user-friendly. If that number would
    rise to tens or even hundreds of applications, our business would be very short-lived.
  prefs: []
  type: TYPE_NORMAL
- en: What we need is a way to make all services accessible through standard HTTP
    (`80`) or HTTPS (`443`) ports. Kubernetes Services alone cannot get us there.
    We need more.
  prefs: []
  type: TYPE_NORMAL
- en: 'What we need is to grant access to our services on predefined paths and domains.
    Our `go-demo-2` service could be distinguished from others through the base path
    `/demo`. Similarly, the books application could be reachable through the `devopstoolkitseries.com`
    domain. If we could accomplish that, we could access them with the commands the
    follow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The request received the `Connection refused` response. There is no process
    listening on port `80`, so this outcome is not a surprise. We could have changed
    one of the Services to publish the fixed port `80` instead assigning a random
    one. Still, that would provide access only to one of the two applications.
  prefs: []
  type: TYPE_NORMAL
- en: We often want to associate each application with a different domain or sub-domain.
    Outside the examples we're running, the books application is accessible through
    the `devopstoolkitseries.com` ([http://www.devopstoolkitseries.com/](http://www.devopstoolkitseries.com/))
    domain. Since I'm not going to give you permissions to modify my domain's DNS
    records, we'll simulate it by adding the domain to the `Host` header.
  prefs: []
  type: TYPE_NORMAL
- en: 'The command that should verify whether the application running inside our cluster
    is accessible through the `devopstoolkitseries.com` domain is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As expected, the request is still refused.
  prefs: []
  type: TYPE_NORMAL
- en: Last, but not least, we should be able to make some, if not all, applications
    (partly) secure by enabling HTTPS access. That means that we should have a place
    to store our SSL certificates. We could put them inside our applications, but
    that would only increase the operational complexity. Instead, we should aim towards
    SSL offloading somewhere between clients and the applications.
  prefs: []
  type: TYPE_NORMAL
- en: The problems that we are facing are common, and it should come as no surprise
    that Kubernetes has a solution.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling Ingress controllers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need a mechanism that will accept requests on pre-defined ports (for example,
    `80` and `443`) and forward them to Kubernetes services. It should be able to
    distinguish requests based on paths and domains as well as to be able to perform
    SSL offloading.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes itself does not have a ready-to-go solution for this. Unlike other
    types of Controllers that are typically part of the `kube-controller-manager`
    binary, Ingress Controller needs to be installed separately. Instead of a Controller,
    `kube-controller-manager` offers *Ingress resource* that other third-party solutions
    can utilize to provide requests forwarding and SSL features. In other words, Kubernetes
    only provides an *API*, and we need to set up a Controller that will use it.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, the community already built a myriad of Ingress controllers. We
    won't evaluate all of the available options since that would require a lot of
    space, and it would mostly depend on your needs and your hosting vendor. Instead,
    we'll explore how Ingress controllers work through the one that is already available
    in Minikube.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the list of the Minikube addons:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We can see that `ingress` is available as one of the Minikube addons. However,
    it is disabled by default, so our next action will be to enable it.
  prefs: []
  type: TYPE_NORMAL
- en: If you used Minikube before, the `ingress` addon might already be enabled. If
    that's the case, please skip the command that follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that `ingress` addon is enabled, we''ll check whether it is running inside
    our cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Ignore the `-n` argument. We did not yet explore Namespaces. For now, please
    note that the output of the command should show that `nginx-ingress-controller-...`
    Pod is running.
  prefs: []
  type: TYPE_NORMAL
- en: If the output is empty, you might need to wait for a few moments until the containers
    are pulled, and re-execute the `kubectl get all --namespace ingress-nginx` command
    again.
  prefs: []
  type: TYPE_NORMAL
- en: The Ingress controller that ships with Minikube is based on the `gcr.io/google_containers/nginx-ingress-controller`
    ([https://console.cloud.google.com/gcr/images/google-containers/GLOBAL/nginx-ingress-controller?gcrImageListsize=50](https://console.cloud.google.com/gcr/images/google-containers/GLOBAL/nginx-ingress-controller?gcrImageListsize=50))
    image hosted in **Google Cloud Platform** (**GCP**) Container Registry. The image
    is based on NGINX Ingress Controller ([https://github.com/kubernetes/ingress-nginx/blob/master/README.md](https://github.com/kubernetes/ingress-nginx/blob/master/README.md)).
    It is one of the only two currently supported and maintained by the Kubernetes
    community. The other one is GLBC ([https://github.com/kubernetes/ingress-gce/blob/master/README.md](https://github.com/kubernetes/ingress-gce/blob/master/README.md))
    that comes with **Google Compute Engine** (**GCE**) ([https://cloud.google.com/compute/](https://cloud.google.com/compute/))
    Kubernetes hosted solution.
  prefs: []
  type: TYPE_NORMAL
- en: By default, the Ingress controller is configured with only two endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: If we'd like to check Controller's health, we can send a request to `/healthz`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: It responded with the status code `200 OK`, thus indicating that it is healthy
    and ready to serve requests. There's not much more to it so we'll move to the
    second endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Ingress controller has a default catch-all endpoint that is used when a
    request does not match any of the other criteria. Since we did not yet create
    any Ingress Resource, this endpoint should provide the same response to all requests
    except `/healthz`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We got the response indicating that the requested resource could not be found.
  prefs: []
  type: TYPE_NORMAL
- en: Now we're ready to create our first Ingress Resource.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Ingress Resources based on paths
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll try to make our `go-demo-2-api` service available through the port `80`.
    We'll do that by defining an Ingress resource with the rule to forward all requests
    with the path starting with `/demo` to the service `go-demo-2-api`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the Ingress'' YAML definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This time, `metadata` contains a field we haven't used before. The `annotations`
    section allows us to provide additional information to the Ingress controller.
    As you'll see soon, Ingress API specification is concise and limited. That is
    done on purpose. The specification API defines only the fields that are mandatory
    for all Ingress controllers. All the additional info an Ingress controller needs
    is specified through `annotations`. That way, the community behind the Controllers
    can progress at great speed, while still providing basic general compatibility
    and standards.
  prefs: []
  type: TYPE_NORMAL
- en: The list of general annotations and the Controllers that support them can be
    found in the Ingress Annotations page([https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md](https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md)).
    For those specific to the NGINX Ingress controller ([https://github.com/kubernetes/ingress-nginx/blob/master/README.md](https://github.com/kubernetes/ingress-nginx/blob/master/README.md)),
    please visit the NGINX Annotations ([https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md](https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md))page,
    and for those specific to GCE Ingress, visit the `ingress-gce` ([https://github.com/kubernetes/ingress-gce](https://github.com/kubernetes/ingress-gce))
    page.
  prefs: []
  type: TYPE_NORMAL
- en: You'll notice that documentation uses `nginx.ingress.kubernetes.io/` annotation
    prefixes. That is a relatively recent change that, at the time of this writing,
    applies to the beta versions of the Controller. We're combining it with `ingress.kubernetes.io/`
    prefixes so that the definitions work in all Kubernetes versions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We specified only one annotation. `nginx.ingress.kubernetes.io/ssl-redirect:
    "false"` tells the Controller that we do NOT want to redirect all HTTP requests
    to HTTPS. We''re forced to do so since we do not have SSL certificates for the
    exercises that follow.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we shed some light on the `metadata annotations`, we can move to the
    `ingress` specification.
  prefs: []
  type: TYPE_NORMAL
- en: We specified a set of `rules` in the `spec` section. They are used to configure
    Ingress resource. For now, our rule is based on `http` with a single `path` and
    a `backend`. All the requests with the `path` starting with `/demo` will be forwarded
    to the service `go-demo-2-api` on the port `8080`.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we had a short tour around some of the Ingress configuration options,
    we can proceed and create the resource.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the latter command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the Ingress resource was created. Don't panic if, in your case,
    the address is blank. It might take a while for it to obtain it.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see whether requests sent to the base path `/demo` work.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The status code `200 OK` is a clear indication that this time, the application
    is accessible through the port `80`. If that's not enough of assurance, you can
    observe the `hello, world!` response as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `go-demo-2` service we''re currently using is no longer properly configured
    for our Ingress setup. Using `type: NodePort`, it is configured to export the
    port `8080` on all of the nodes. Since we''re expecting users to access the application
    through the Ingress Controller on port `80`, there''s probably no need to allow
    external access through the port `8080` as well. We should switch to the `ClusterIP`
    type. That will allow direct access to the Service only within the cluster, thus
    limiting all external communication through Ingress.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We cannot just update the Service with a new definition. Once a Service port
    is exposed, it cannot be un-exposed. We''ll delete the `go-demo-2` objects we
    created and start over. Besides the need to change the Service type, that will
    give us an opportunity to unify everything in a single YAML file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We removed the objects related to `go-demo-2`, and now we can take a look at
    the unified definition.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We won''t go into details of the new definition since it does not have any
    significant changes. It combines `ingress/go-demo-2-ingress.yml` and `ingress/go-demo-2-deploy.yml`
    into a single file, and it removes `type: NodePort` from the `go-demo-2` Service.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We created the objects from the unified definition and sent a request to validate
    that everything works as expected. The response should be `200 OK` indicating
    that everything (still) works as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that Kubernetes needs a few seconds until all the objects are running
    as expected. If you were too fast, you might have received the response `404 Not
    Found` instead `200 OK`. If that was the case, all you have to do is send the
    `curl` request again.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see, through a sequence diagram, what happened when we created the Ingress
    resource.
  prefs: []
  type: TYPE_NORMAL
- en: The Kubernetes client (`kubectl`) sent a request to the API server requesting
    the creation of the Ingress resource defined in the `ingress/go-demo-2.yml` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The ingress controller is watching the API server for new events. It detected
    that there is a new Ingress resource.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The ingress controller configured the load balancer. In this case, it is nginx
    which was enabled by `minikube addons enable ingress` command. It modified `nginx.conf`
    with the values of all `go-demo-2-api` endpoints.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f97fc587-e82a-4442-be25-8b4464320e11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-2: The sequence of events followed by the request to create an Ingress
    resource'
  prefs: []
  type: TYPE_NORMAL
- en: Now that one of the applications is accessible through Ingress, we should apply
    the same principles to the other.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at the full definition of all the objects behind the `devops-toolkit`
    application.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The output, limited to the Ingress object, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The `devops-toolkit` Ingress resource is very similar to `go-demo-2`. The only
    significant difference is that the `path` is set to `/`. It will serve all requests.
    It would be a much better solution if we'd change it to a unique base path (for
    example, `/devops-toolkit`) since that would provide a unique identifier. However,
    this application does not have an option to define a base path, so an attempt
    to do so in Ingress would result in a failure to retrieve resources. We'd need
    to write `rewrite` rules instead. We could, for example, create a rule that rewrites
    path base `/devops-toolkit` to `/`. That way if, for example, someone sends a
    request to `/devops-toolkit/something`, Ingress would rewrite it to `/something`
    before sending it to the destination Service. While such an action is often useful,
    we'll ignore it for now. I have better plans for this application. Until I decide
    to reveal them, `/` as the base `path` should do.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from adding Ingress to the mix, the definition removed `type: NodePort`
    from the Service. This is the same type of action we did previously with the `go-demo-2`
    service. We do not need external access to the Service.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s remove the old objects and create those defined in the `ingress/devops-toolkit.yml`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We removed the old `devops-toolkit` and created new ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the Ingresses running inside the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: We can see that now we have multiple Ingress resources. The Ingress controller
    (in this case NGINX) configured itself taking both of those resources into account.
  prefs: []
  type: TYPE_NORMAL
- en: We can define multiple Ingress resources that will configure a single Ingress
    controller.
  prefs: []
  type: TYPE_NORMAL
- en: Let's confirm that both applications are accessible through HTTP (port `80`).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The first command opened one of the applications in a browser, while the other
    returned the already familiar `hello, world!` message.
  prefs: []
  type: TYPE_NORMAL
- en: Ingress is a (kind of) Service that runs on all nodes of a cluster. A user can
    send requests to any and, as long as they match one of the rules, they will be
    forwarded to the appropriate Service.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e7cc7cb0-6848-4f69-b323-a82bb583d64e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-3: Applications accessed through Ingress controller'
  prefs: []
  type: TYPE_NORMAL
- en: Even though we can send requests to both applications using the same port (`80`),
    that is often a sub-optimal solution. Our users would probably be happier if they
    could access those applications through different domains.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Ingress resources based on domains
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll try to refactor our `devops-toolkit` Ingress definition so that the Controller
    forwards requests coming from the `devopstoolkitseries.com` domain. The change
    should be minimal, so we'll get down to it right away.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'When compared with the previous definition, the only difference is in the additional
    entry `host: devopstoolkitseries.com`. Since that will be the only application
    accessible through that domain, we also removed the `path: /` entry.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s `apply` the new definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'What would happen if we send a similar domain-less request to the Application?
    I''m sure you already know the answer, but we''ll check it out anyways:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: There is no Ingress resource defined to listen to `/`. The updated Ingress will
    forward requests only if they come from `devopstoolkitseries.com`.
  prefs: []
  type: TYPE_NORMAL
- en: 'I own the `devopstoolkitseries.com` domain, and I''m not willing to give you
    the access to my DNS registry to configure it with the IP of your Minikube cluster.
    Therefore, we won''t be able to test it by sending a request to `devopstoolkitseries.com`.
    What we can do is to "fake" it by adding that domain to the request header:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Now that Ingress received a request that looks like it's coming from the domain
    `devopstoolkitseries.com`, it forwarded it to the `devops-toolkit` Service which,
    in turn, load balanced it to one of the `devops-toolkit` Pods. As a result, we
    got the response `200 OK`.
  prefs: []
  type: TYPE_NORMAL
- en: Just to be on the safe side, we'll verify whether `go-demo-2` Ingress still
    works.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: We got the famous `hello, world!` response, thus confirming that both Ingress
    resources are operational. Even though we "faked" the last request as if it's
    coming from `acme.com`, it still worked. Since the `go-demo-2` Ingress does not
    have any `host` defined, it accepts any request with the `path` starting with
    `/demo`.
  prefs: []
  type: TYPE_NORMAL
- en: We're still missing a few things. One of those is a setup of a default backend.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Ingress resource with default backends
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In some cases, we might want to define a default backend. We might want to forward
    requests that do not match any of the Ingress rules.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: So far, we have two sets of Ingress rules in our cluster. One accepts all requests
    with the base path `/demo`. The other forwards all requests coming from the `devopstoolkitseries.com`
    domain. The request we just sent does not match either of those rules, so the
    response was once again 404 Not Found.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s imagine that it would be a good idea to forward all requests with the
    wrong domain to the `devops-toolkit` application. Of course, by "wrong domain",
    I mean one of the domains we own, and not one of those that are already included
    in Ingress rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: There's no Deployment, nor is there a Service. This time, we're creating only
    an Ingress resource.
  prefs: []
  type: TYPE_NORMAL
- en: The `spec` has no rules, but only a single `backend`.
  prefs: []
  type: TYPE_NORMAL
- en: When an Ingress `spec` is without rules, it is considered a default backend.
    As such, it will forward all requests that do not match paths and/or domains set
    as rules in the other Ingress resources.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the default backend as a substitute for the default `404` pages or
    for any other occasion that is not covered by other rules.
  prefs: []
  type: TYPE_NORMAL
- en: You'll notice that the `serviceName` is `devops-toolkit`. The example would
    be much better if I created a separate application for this purpose. At the risk
    of you calling me lazy, I'll say that it does not matter for this example. All
    we want, at the moment, is to see something other than `404 Not Found` response.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We created the Ingress resource with the default backend, and now we can test
    whether it truly works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: This time, the output is different. We got `200 OK` instead of the `404 Not
    Found` response.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: What now?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We explored some of the essential functions of Ingress resources and Controllers.
    To be more concrete, we examined almost all those that are defined in the Ingress
    API.
  prefs: []
  type: TYPE_NORMAL
- en: One notable feature we did not explore is TLS configuration. Without it, our
    services cannot serve HTTPS requests. To enable it, we'd need to configure Ingress
    to offload SSL certificates.
  prefs: []
  type: TYPE_NORMAL
- en: There are two reasons we did not explore TLS. For one, we do not have a valid
    SSL certificate. On top of that, we did not yet study Kubernetes Secrets. I'd
    suggest you explore SSL setup yourself once you make a decision which Ingress
    controller to use. Secrets, on the other hand, will be explained soon.
  prefs: []
  type: TYPE_NORMAL
- en: We'll explore other Ingress controllers once we move our cluster to "real" servers
    that we'll create with one of the hosting vendors. Until then, you might benefit
    from reading NGINX Ingress controller ([https://github.com/kubernetes/ingress-nginx/blob/master/README.md](https://github.com/kubernetes/ingress-nginx/blob/master/README.md))
    documentation in more detail. Specifically, I suggest you pay close attention
    to its annotations ([https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md](https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md)).
  prefs: []
  type: TYPE_NORMAL
- en: Now that another chapter is finished, we'll destroy the cluster and let your
    laptop rest for a while. It deserves a break.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: If you'd like to know more about Ingress, please explore Ingress v1beta1 extensions
    ([https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#ingress-v1beta1-extensions](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#ingress-v1beta1-extensions))
    API documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Before we move into the next chapter, we'll explore the differences between
    Kubernetes Ingress and its Docker Swarm equivalent.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7da80e08-4e4f-49b8-ae73-d32018eebff9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-4: The components explored so far'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Ingress compared to Docker Swarm equivalent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Both Kubernetes and Docker Swarm have Ingress, and it might sound compelling
    to compare them and explore the differences. While that, at first glance, might
    seem like the right thing to do, there is a problem. Ingress works quite differently
    across the two.
  prefs: []
  type: TYPE_NORMAL
- en: Swarm Ingress networking is much more similar to Kubernetes services. Both can,
    and should, be used to expose ports to clients both inside and outside a cluster.
    If we compare the two products, we'll discover that Kubernetes services are similar
    to a combination of Docker Swarm's Overlay and Ingress networking. The Overlay
    is used to provide communication between applications inside a cluster, and Swarm's
    Ingress is a flavor of Overlay network that publishes ports to the outside world.
    The truth is that Swarm does not have an equivalent to Kubernetes Ingress controllers.
    That is, *if we do not include Docker Enterprise Edition to the mix*.
  prefs: []
  type: TYPE_NORMAL
- en: The fact that a Kubernetes Ingress equivalent does not ship with Docker Swarm
    does not mean that similar functionality cannot be accomplished through other
    means. It can. [Traefik](https://traefik.io/), for example, can act both as a
    Kubernetes Ingress Controller, as well as a dynamic Docker Swarm proxy. It provides,
    more or less, the same functionality no matter which scheduler you choose. If
    you're looking for a Swarm specific alternative, you might choose Docker Flow
    Proxy ([http://proxy.dockerflow.com/](http://proxy.dockerflow.com/)) (written
    by yours truly).
  prefs: []
  type: TYPE_NORMAL
- en: All in all, as soon as we stop comparing Ingress on both platforms and start
    looking for a similar set of functionality, we can quickly conclude that both
    Kubernetes and Docker Swarm allow a similar set of features. We can use paths
    and domains to route traffic from a single set of ports (for example, `80` and
    `443`) to a specific application that matches the rules. Both allow us to offload
    SSL certificates, and both provide solutions that make all the necessary configurations
    dynamically.
  prefs: []
  type: TYPE_NORMAL
- en: If on the functional level both platforms provide a very similar set of features,
    can we conclude that there is no essential difference between the two schedulers
    when taking into account only dynamic routing and load balancing? *I would say
    no*. Some important differences might not be of functional nature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes provides a well-defined Ingress API that third-party solutions can
    utilize to deliver a seamless experience. Let''s take a look at one example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: This definition can be used with many different solutions. Behind this Ingress
    resource could be nginx, voyager, haproxy, or trafficserver Ingress controller.
    All of them use the same Ingress API to deduce which Services should be used by
    forwarding algorithms. Even Traefik, known for its incompatibility with commonly
    used Ingress annotations, would accept that YAML definition.
  prefs: []
  type: TYPE_NORMAL
- en: Having a well-defined API still leaves a lot of room for innovation. We can
    use `annotations` to provide the additional information our Ingress controller
    of choice might need. Some of the same annotations are used across different solutions,
    while the others are specific to a controller.
  prefs: []
  type: TYPE_NORMAL
- en: All in all, Kubernetes Ingress controller combines a well-defined (and simple)
    specification that all Ingress controllers must accept and, at the same time,
    it leaves ample room for innovation through custom `annotations` specified in
    `metadata`.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm does not have anything resembling an Ingress API. Functionality
    similar to Kubernetes Ingress controllers can be accomplished either by using
    Swarm Kit or using the Docker API. The problem is that there is no defined API
    that third-party solutions should follow, so each is a world in itself. For example,
    understanding how Traefik works will not help you much when trying to switch to
    Docker Flow Proxy. Each is operated differently in isolation. There is no standard
    because Docker did not focus on making one.
  prefs: []
  type: TYPE_NORMAL
- en: Docker's approach to scheduling is based entirely on the features baked into
    Docker Server. There is only one way to do things. Often, that provides a very
    user-friendly and reliable experience. If Swarm does what you need it to do, it
    is an excellent choice. However, the problem occurs when you need more. In that
    case, you might experience difficulties finding a solution with Docker Swarm.
  prefs: []
  type: TYPE_NORMAL
- en: When we compared Kubernetes ReplicaSets, Services, and Deployments with their
    Docker Swarm equivalents, the result was the same set of features. There was no
    substantial difference on the functional level. From the user experience perspective,
    Swarm provided much better results. Its YAML file was much more straightforward
    and more concise. With only those features in mind, Swarm had the edge over Kubernetes.
    This time it's different.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes strategy is primarily based on API. Once a specific type of a resource
    is defined, any solution can utilize it to provide the given functionality. That
    is especially true with Ingress. We can choose among a myriad of solutions. Some
    of them are developed and maintained by the Kubernetes community (for example,
    GLBC and NGINX Ingress controllers), while others are provided by third-parties.
    No matter where the solution comes from, it adheres to the same API and, therefore,
    to the same YAML definition. As a result, we have a more substantial number of
    solutions to choose from, without sacrificing consistency in how we define resources.
  prefs: []
  type: TYPE_NORMAL
- en: If we limit the comparison to Kubernetes Ingress controllers and their equivalents
    in Docker Swarm, the former is a clear winner. Assuming that the current strategy
    continues, Docker would need to add layer 7 forwarding into Docker Server if it
    is to get back in the game on this front. If we limit ourselves only to this set
    of features, Kubernetes wins through its Ingress API that opened the door, not
    only to internal solutions, but also to third-party Controllers.
  prefs: []
  type: TYPE_NORMAL
- en: We are still at the beginning. There are many more features worth comparing.
    We only scratched the surface. Stay tuned for more.
  prefs: []
  type: TYPE_NORMAL
