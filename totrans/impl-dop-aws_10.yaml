- en: Chapter 10. AWS Tips and Tricks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, I would like to provide you with a selection of random bits
    of advice. Some of them are derived from my own experience with using AWS; others
    are found in the AWS whitepapers or related blogs.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**A few links on the subject**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://d0.awsstatic.com/whitepapers/AWS_Cloud_Best_Practices.pdf](https://d0.awsstatic.com/whitepapers/AWS_Cloud_Best_Practices.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://wblinks.com/notes/aws-tips-i-wish-id-known-before-i-started/](https://wblinks.com/notes/aws-tips-i-wish-id-known-before-i-started/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://launchbylunch.com/posts/2014/Jan/29/aws-tips/](https://launchbylunch.com/posts/2014/Jan/29/aws-tips/)'
  prefs: []
  type: TYPE_NORMAL
- en: Using VPCs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apart from the initial, minor setup overhead, it is generally accepted that
    you are better off deploying your infrastructure inside a VPC. AWS even provides
    you one by default and tends to deploy resources in it unless you ask otherwise.
    A VPC gives you more flexibility when operating EC2 instances, better control
    of your networking, and enhanced security. Also, it is free.
  prefs: []
  type: TYPE_NORMAL
- en: Keep the Main route table as a fallback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you follow the previous tip, you will notice that a new VPC comes with a
    route table marked as **Main**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Keep the Main route table as a fallback](img/image_10_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: I would recommend that it is left as it is, with a single, local route, and
    create additional route tables for any custom routing needs instead.
  prefs: []
  type: TYPE_NORMAL
- en: This way, the main or default route table becomes a sort of a safety net for
    any subnets that get created but remain unassociated, be it by mistake or intent.
  prefs: []
  type: TYPE_NORMAL
- en: Staying within the VPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As tempting as it may be, try to avoid exposing your VPC resources, as this
    defeats the purpose. This is to say, instead of assigning public IPs to your EC2
    instances, which might give you quick and easy access, use a designated ssh-gateway
    host (also known as a bastion or a jump host) to hop through.
  prefs: []
  type: TYPE_NORMAL
- en: You would assign a public (Elastic) IP only this single machine, ensure its
    security group is locked down to the static IPs of your home and/or work place,
    and use it to connect (say over ssh) to any other instances within your VPC.
  prefs: []
  type: TYPE_NORMAL
- en: Creating IAM roles in advance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already discussed EC2 instance roles as a much better way of providing
    credentials to your application.
  prefs: []
  type: TYPE_NORMAL
- en: A good practice is to always create and assign an IAM role to your instances,
    even if it is not needed at the time and holds no permissions.
  prefs: []
  type: TYPE_NORMAL
- en: This is because IAM roles can only be assigned when an EC2 instance is being
    launched.
  prefs: []
  type: TYPE_NORMAL
- en: Groups over users
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you create your first deployment, you might not necessarily have that many
    users needing access to your AWS account.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, it is still a good idea to assign permissions to an IAM group
    and make your IAM users members of it, as opposed to granting privileges to each
    user as they come.
  prefs: []
  type: TYPE_NORMAL
- en: In the long term, it is often the case that team members tend to require (reuse)
    the same list of permissions.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing the AWS service limits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An AWS account comes with certain limits that can be found in the AWS console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Knowing the AWS service limits](img/image_10_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'These are meant to protect the customer as well as the provider against any
    unintentional use. The following are examples:'
  prefs: []
  type: TYPE_NORMAL
- en: A coding error in your CloudFormation template, resulting in an unexpected amount
    of storage or other resources being provisioned
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A misconfigured Auto Scaling Group, launching tens or hundreds of instances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your user making an API call to request an unusual number of instances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we can see, the said limits are an overall good idea, most of the time.
  prefs: []
  type: TYPE_NORMAL
- en: If you find yourself in a production environment, getting ready for a major
    event and the traffic spike that comes with it, you certainly want to be aware
    of your current AWS service limits. Most instance types are initially limited
    to 20, VPC EIPs to 5, and storage types to 20 TB.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, you would review these as soon as you get an idea of your expected
    usage baseline (allowing for bursting) and contact AWS Support requesting a limit
    increase where needed.
  prefs: []
  type: TYPE_NORMAL
- en: Pre-warm ELBs if needed
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On the subject of traffic spikes, while ELBs are impressively performant, there
    might be occasions where you will need to pre-warm them.
  prefs: []
  type: TYPE_NORMAL
- en: As you probably already know, an ELB is a collection of EC2 instances managed
    by AWS, running proprietary load balancing software.
  prefs: []
  type: TYPE_NORMAL
- en: An algorithm ensures that the number of ELB EC2 instances grows or shrinks in
    response to the traffic pattern of your application. This process of adaptive
    scaling is done based on averaged traffic measurements taken over time and as
    such is not very rapid.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure that this feature does not become a problem, AWS allows you to request
    an ELB to be pre-warmed, that is to say, scaled-up ahead of time.
  prefs: []
  type: TYPE_NORMAL
- en: If you are on the premium support plan, you could probably wait until a few
    hours prior to the event; otherwise, you should contact the support team sooner
    to account for the extra response time.
  prefs: []
  type: TYPE_NORMAL
- en: You will be asked a series of questions relating to the expected requests per
    second, average payload size, event duration, and other traffic properties, which
    will help AWS Support determine whether pre-warming is necessary at all.
  prefs: []
  type: TYPE_NORMAL
- en: Using termination protection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![Using termination protection](img/image_10_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It goes without saying that one should not keep state on machines if it can
    be helped.
  prefs: []
  type: TYPE_NORMAL
- en: After all, the beauty of AWS is that it allows you to not focus so much on individual
    instances any more. It promotes a cluster or service culture where the health
    of the endpoint is of importance.
  prefs: []
  type: TYPE_NORMAL
- en: For the rare cases where we must have one of those management or similar type
    of non-autoscaling node, however, you have nothing but to gain from protecting
    yourself against accidentally making the wrong API call or a console click.
  prefs: []
  type: TYPE_NORMAL
- en: Tagging what you can
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This sounds like a chore, but it does indeed pay back later. Whether for the
    much better clarity on your AWS bill or the extra flexibility you get when managing
    your resources, tags are always useful.
  prefs: []
  type: TYPE_NORMAL
- en: Instrument your tools to apply tags whenever an asset is provisioned, then start
    scanning your estate regularly for any untagged resources.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying across multiple zones
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unarguably, deploying within the same physical location should yield the lowest
    latency.
  prefs: []
  type: TYPE_NORMAL
- en: In the majority of use cases however, the added few milliseconds in return for
    a multiple increase in resilience are worth it.
  prefs: []
  type: TYPE_NORMAL
- en: Try to span your deployment across two availability zones at least.
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing your ELB health-checks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The stock ELB health checks allow you to check raw TCP responses or go higher
    in the stack and look for an HTTP/200 response.
  prefs: []
  type: TYPE_NORMAL
- en: Either is good. A basic check should get you started but as your application
    and its dependencies evolve, you might need to enrich your health checks too.
  prefs: []
  type: TYPE_NORMAL
- en: Let us suppose that you were serving a web application that relies on a cache
    and a database backend.
  prefs: []
  type: TYPE_NORMAL
- en: If the ELB was checking `TCP:80` then as long as your HTTP daemon is running,
    it will receive an OK. If you were checking for an HTTP/200, instead that would
    verify access to the application's file(s) on disk but likely not much more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, you could benefit much more from pointing the ELB at a dedicated health
    check endpoint within your application, which verifies all its dependencies (disk:
    OK, cache: OK, db: OK) before returning a green light. But beware of impacting
    the overall application performance: the more frequently the health check is called,
    the more lightweight it ought to be.'
  prefs: []
  type: TYPE_NORMAL
- en: Offloading SSL onto the ELB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS now issues free SSL certificates as part of the **Certificate Manager service** which
    also takes care of renewals. This seems like a pretty good reason on its own.
  prefs: []
  type: TYPE_NORMAL
- en: Managing certificates on the ELB itself is much more convenient in comparison
    to doing the same across a number of EC2 backend instances. Also, there must be
    at least a small amount of CPU performance to be gained by delegating the SSL
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: EIP versus public IP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A few points about the two types, in case you have not used these much.
  prefs: []
  type: TYPE_NORMAL
- en: 'Public IPs:'
  prefs: []
  type: TYPE_NORMAL
- en: You choose whether an instance should have a public IP at the time you are launching
    it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The address will persist across reboots but not a stop/start
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These come at no extra cost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Elastic IPs:'
  prefs: []
  type: TYPE_NORMAL
- en: You can associate/disassociate an EIP with an instance at any time after it
    has been launched
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An EIP remains associated across reboots or start/stop operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EIPs incur cost (when kept unused)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EIPs can be migrated between EC2 instances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In light of the IPv4 deficit we are facing today, AWS is cleverly trying to
    incentivize sensible provisioning by charging for any dormant EIP resources.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Be a gentleman/lady and release your IPs when you are done with them.
  prefs: []
  type: TYPE_NORMAL
- en: Mind the full-hour billing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is great that AWS allows you to pay-for-what-you-use and as-you-go. Something
    to keep in mind, however, is that AWS meters usage in hourly increments.
  prefs: []
  type: TYPE_NORMAL
- en: So, say you were running a number of batch jobs, launching and terminating an
    instance every 10 minutes. After an hour and 10 minutes, you would have launched
    and terminated six instances (6x smallest increment of 1h) resulting in 6 hours
    of billable usage despite the fact the neither of them lasted more than 10 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: At any rate, to avoid surprises, it is highly recommended you to set up billing
    alerts. These are simple CloudWatch alarms which can notify you when your estimated
    bill has reached a threshold.
  prefs: []
  type: TYPE_NORMAL
- en: Using Route53 ALIAS records
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a special in-house type of DNS record specific to the Route53 service.
  prefs: []
  type: TYPE_NORMAL
- en: For an AWS user an Alias record is a great alternative to a CNAME (for supported
    resources).
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the main advantages are:'
  prefs: []
  type: TYPE_NORMAL
- en: Aliases resolve directly to an IP address, saving the extra lookup which a CNAME
    would require
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alias records are supported at the zone apex, so you could create an alias which
    uses the top of a domain (for example `mydomain.com`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alias records allow advanced Route53 features such as weighted/latency/geo routing
    and failovers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no AWS cost associated with Alias lookups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'NB: A Route53 Alias record can currently only point to a limited set of AWS
    resources. For more information please see: [http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html)'
  prefs: []
  type: TYPE_NORMAL
- en: The S3 bucket namespace is global
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This means that if you get a name conflict when creating a bucket, it is likely
    because somebody else in the AWS universe has beaten you to it.
  prefs: []
  type: TYPE_NORMAL
- en: Devise a naming schema that offers some uniqueness; perhaps, use your organization's
    name or a random prefix/suffix to the bucket name.
  prefs: []
  type: TYPE_NORMAL
- en: S3 bucket deletion tends to propagate slowly. Pay attention to the region in
    which you are creating your bucket. If you get it wrong, you will need to delete
    then wait for 20-30 minutes in my experience before you can recreate it in the
    right place.
  prefs: []
  type: TYPE_NORMAL
- en: '- versus . in the S3 bucket name'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It seems that there is often the question of whether one should name buckets
    as `images-example-com` or `images.example.com`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two things to consider are:'
  prefs: []
  type: TYPE_NORMAL
- en: Would you like to use S3 over HTTPS?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Would you like to use a custom domain name instead of the default S3 bucket
    URL?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strictly speaking, buckets with dots in the name will show an SSL mismatch warning
    when you address them over HTTPS using the default bucket URI.
  prefs: []
  type: TYPE_NORMAL
- en: This is due to the fact that S3 operates on the `.amazonaws.com` domain, and
    any extra dots will make it seem as if a bucket is a subdomain (not covered by
    the SSL certificate).
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, you have to use dots if you want to have a custom domain
    (CNAME) pointed at your bucket. That is to say, the bucket name has to match the
    said custom URL in order for S3's virtual-host style service to work.
  prefs: []
  type: TYPE_NORMAL
- en: For example, we call our bucket `images.example.com` and add a DNS record of
    `images.example.com` CNAME `images.example.com.s3.amazonaws.com`.
  prefs: []
  type: TYPE_NORMAL
- en: S3 would then forward incoming request to any bucket with a name matching the
    host in the HTTP headers (refer to [http://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html](http://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html)).
  prefs: []
  type: TYPE_NORMAL
- en: 'So, it would seem that based on the name we chose, we can use either one of
    the features or the other (HTTPS vs CNAME). But there is a solution to this dilemma:
    CloudFront.'
  prefs: []
  type: TYPE_NORMAL
- en: Placing a CloudFront distribution in front of our bucket allows a custom domain,
    plus a custom SSL certificate, to be specified.
  prefs: []
  type: TYPE_NORMAL
- en: Randomizing S3 filenames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An important fact is that S3 takes filenames (object keys) into consideration
    when distributing data. You are likely to get better performance when your content
    does not use a sequential naming convention. For more details on the distribution
    mechanism please refer to [http://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html](http://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html)
  prefs: []
  type: TYPE_NORMAL
- en: Initializing (pre-warm) EBS volumes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It used to be the case that all EBS storage was meant to be initialized to
    avoid the first-time-access penalty, which becomes a noticeable overhead as you
    start dealing with larger and larger volumes. Nowadays, the situation has improved
    as new volumes need no pre-warming (ref: [http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html));
    however, one should still consider the added delay to the boot process (if the
    volume is needed at boot time) against any potential performance gains.'
  prefs: []
  type: TYPE_NORMAL
- en: For very large volumes, initialization might be prohibitive, but in any other
    case, it is certainly worth doing. Or if you run your own database servers on
    EC2, then you should definitely consider pre-warming volumes regardless of size.
  prefs: []
  type: TYPE_NORMAL
- en: You could use the suggested command-line steps to measure time spent performing
    this type of optimization (refer to [http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html)).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at some tips, tricks, facts, and general information,
    which are useful to keep in mind when using AWS.
  prefs: []
  type: TYPE_NORMAL
- en: This is naturally just a small selection of such public secrets, and if you
    are also excited about the peculiarities of the AWS environment plus the creative
    hacks that users come up with to work around them – I would recommend you to check
    out [https://aws.amazon.com/blogs/aws/](https://aws.amazon.com/blogs/aws/).
  prefs: []
  type: TYPE_NORMAL
