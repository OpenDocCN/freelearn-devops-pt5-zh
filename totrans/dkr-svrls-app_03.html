<html><head></head><body>
        

                            
                    <h1 class="header-title">Serverless Frameworks</h1>
                
            
            
                
<p class="mce-root">This chapter discusses serverless frameworks. What are they? What are the current limitations of pure serverless frameworks? How could Docker partially solve the limitations of serverless frameworks. We will start by taking a look at AWS Lambda, then Azure Functions, and Google Cloud Functions. We will touch briefly on IBM Cloud Functions, but actually its engine is OpenWhisk, which will be discussed in detail in the next couple of chapters.</p>
<p>We will also discuss serverless framework, a toolkit that helps us develop cloud-independent serverless applications, in the last section of this chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">AWS Lambda</h1>
                
            
            
                
<p>Among serverless architectures offered by cloud providers, AWS Lambda is the most popular and has some advanced features.</p>
<p class="mce-root">FaaS/serverless is a natural evolution from microservices, or we may think of it as an extension to the microservices architecture. In many scenarios, we can complement our microservices architecture with functions or Lambda. If you are already an AWS customer, it is completely natural to move your codes from EC2 to Lambda and save a lot of money. The following diagram illustrates a simple use case that uses <strong>AWS Lambda</strong> together with <strong>S3 Buckets</strong> and <strong>DynamoDB:</strong></p>
<div><img src="img/74d0ca23-fdea-4bd8-9e59-6a724c4b27cd.png" style="border: 1em solid black;color: #333333;text-align: center;width:34.17em;height:29.58em;"/></div>
<p>Figure 3.1: A simple use case of using Lambda function on AWS</p>
<p>In S3, there is a way to trigger the event to a specific endpoint. We put the endpoint of our Lambda function there. After users upload or make changes to the S3 bucket, it will trigger to send an invocation request to the Lambda function. This could be thought of as a form of WebHooks. After that, the Lambda function receives the event and starts to compute its application logic. After it has finished, the Lambda will transfer the results and store them into a DynamoDB instance.</p>
<p>We will demonstrate a similar scenario in <a href="0d30ef75-34b4-4a72-9b0a-71a8e335d494.xhtml" target="_blank">Chapter 8</a>, <em>Putting Them All Together</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Limitations</h1>
                
            
            
                
<p>Lambda supports several language runtimes; for example, Node.js, Go, Java, Python, and C#. Each AWS Lambda has a number of limitations to cap the resources it may use per invocation. In terms of memory, the range of RAM supported for Lambda is between 128 MB to 3,008 MB with 64 MB, increments. The function will be automatically terminated if its memory usage is exceeded.</p>
<p class="mce-root">In terms of disk space, a Lambda function is allowed to use the <kbd>/tmp</kbd> directory up to 512 MB. This kind of disk volume is ephemeral, so it is expected to be wiped out after the Lambda has finished its work. Also, the number of file descriptors allowed in Lambda functions are limited to 1,024, while the number of processes and threads that could be forked within a single invocation is limited to 1,024 as well.</p>
<p class="mce-root">For each request, the size of the request body is capped at 6 MB for synchronous HTTP calls, and at 128 KB for asynchronous, event-triggered calls.</p>
<p>The most important aspect here is <em>time limits</em>. AWS Lambda allows a function to run no longer than 5 minutes (or 300 seconds). If the execution time exceeds 5 minutes, the function will be automatically killed.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Lambda termination</h1>
                
            
            
                
<p>The technology behind Lambda is actually container-based, which means it isolates a function from other instances. The container's sandbox provides resources specific to each configuration for them.</p>
<p class="mce-root">A Lambda function can be terminated in a number of ways:</p>
<ul>
<li class="mce-root"><strong>Timeout</strong>: As previously mentioned, when the 5-minute limitation is reached, the current execution of the function will be stopped no matter what it is doing.</li>
<li class="mce-root"><strong>Controlled termination</strong>: If the function provides a callback and the callback is executed to invoke the <kbd>context.done()</kbd> method, the function will be terminated, no matter what it is doing.</li>
<li class="mce-root"><strong>Default termination</strong>: The function ends and terminates normally. Also, there is no callback to invoke the <kbd>context.done()</kbd> method. This case will be considered as the default termination.</li>
<li class="mce-root"><strong>Function crashes</strong> <strong>or <kbd>process.exit()</kbd> is called</strong>: If the function panics or generates segmentation faults, the function will terminate and therefore the container is stopped.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Container reuse</h1>
                
            
            
                
<p class="mce-root">There is a scenario where the function container that has just terminated could be reused.</p>
<p class="mce-root">This ability to reuse a finished function container can greatly reduce the spinning up time, as the initialization process will be completely skipped. Also, there is a drawback where, if a container is reused, the file written to the <kbd>/tmp</kbd> directory from the previous execution may still be there.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Native executables</h1>
                
            
            
                
<p>Lambda is actually designed to run code in any language, as Lambda's sandbox is just a container. The trick is that we could use a Node.js program to execute any binary shipped with the ZIP file before uploading.</p>
<p class="mce-root">It is worth noting that when preparing our own binary for Lambda, it must be statically compiled or matched with the shared libraries provided by Amazon Linux (as the containers used on Lambda are all Amazon Linux-based). It is our responsibility to track the Amazon Linux version by ourselves.</p>
<p class="mce-root">A project such as LambCI (<a href="http://github.com/lambci/docker-lambda">http://github.com/lambci/docker-lambda</a>) can help to solve this problem. LambCI provides a local sandbox environment, as Docker containers, that mimics the AWS Lambda environment by installing the same software and libraries, file structure, and permissions. It also defines the same set of environment variables, and other behaviors. Also, the username and group are defined to match the Lambda, for example, <kbd>sbx_user1051</kbd>.</p>
<p class="mce-root">With this local environment, we are allowed to safely test our codes inside this Docker container and can be sure that it will be running fine on Lambda.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Azure Functions</h1>
                
            
            
                
<p>Azure Functions is a serverless computing platform offered by Microsoft as a part of Azure Cloud. All design goals are the same as other serverless/FaaS services, and Azure Functions enables us to execute our application logic without managing our own infrastructure.</p>
<p class="mce-root">Azure Functions runs a program in the form of scripts when it is triggered by events. The current version of Azure Functions supports language runtimes such as C#, F#, PHP, Node.js or Java. It is natural for Azure to support C# and F# as first-class languages for their functions because they are Microsoft-owned programming languages. In any case, the only GA-supported languages are C#, F#, and JavaScript (Node.js) anyway.</p>
<p class="mce-root">With C#, F#, or .NET languages, Azure Functions allows us to install dependencies via NuGet, the infamous package manager for .NET. In case we are writing JavaScript with Node.js, Azure also provides access to NPM for package management.</p>
<p class="mce-root">Similar to other cloud providers, Azure Functions has an advantage when accessing other Azure services, for example, Azure Cosmos DB, Azure Event Hubs, Azure Storage and Azure Service Bus.</p>
<p>It is really interesting to note that the pricing model of Azure Functions is somewhat different from the offering of Amazon or Google. In Azure, there are two kind of pricing plans that may fit different needs.</p>
<p class="mce-root">The first one is the <em>consumption plan</em>. It is a similar plan offered by other cloud providers, where you pay only for the time that our codes are executed. The second one is the <em>app service plan</em>. Functions in this context are considered part of the app service for other applications. If functions fall into this category, we do not need to incur additional cost.</p>
<p class="mce-root">An interesting feature of Azure Functions is its triggering and binding mechanism. Azure Functions allows a definition of how to trigger a function and how to perform data binding of the input and the output for each function, in a separated configuration. These mechanisms help to avoid hardcoding when we call functions and when we transform data in and out through the calling chain of functions.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Scaling</h1>
                
            
            
                
<p>In Azure, there is a component to monitor the number of requests made to each Azure Function in real time. This component is called the <strong>scale controller</strong>. It collects data and then later makes a decision to scale the number of instances up or down for that function. Azure has the concept of an app service. A function app may contain many instances of a function.</p>
<p class="mce-root">All decision making is based on heuristic-based algorithms for different types of event triggers. When the function is scaled out, all resources related to that function will also be scaled out. The number of function instances will be automatically scaled down to zero, if there is no request made to the function app.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Limitations</h1>
                
            
            
                
<p>Each function instance will be limited to a memory of 1.5 GB by the host of the function app, a group-like semantic for multiple function instances. All functions within a function app share the same resources.</p>
<p>A function app holds a maximum of 200 instances of a function at the same time. But there is no concurrency limitation. In practice, a function instance can accept one or more requests.</p>
<p>Each event trigger, for example, Azure Service Bus has its own heuristic way to scale the underlying function.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Durable functions</h1>
                
            
            
                
<p>One of the most advanced extensions to the Azure Functions are <strong>durable functions</strong>. A durable function is a technique to implement stateful functions inside a serverless computing environment. There are additional concepts for state management, checkpoints, and restarts provided by this durable extension. What we get from this kind of function is a stateful workflow, and there will be a driver that acts as the orchestrator to call other functions, as shown in the following diagram:</p>
<div><img src="img/76ad2f42-1a69-4442-bec0-1df67ba324e9.png" style="width:37.92em;height:19.83em;"/></div>
<p>Figure 3.2: An orchestrator function with the durable function extension in Azure</p>
<p class="mce-root">When it has finished calling other functions, both in synchronous or asynchronous ways, the orchestrator function will be allowed to save states as local variables. There is also a <em>checkpointing technique</em> to continue/resume the orchestrator's states when the calling process has to start over, or the virtual machine running this orchestrator function gets rebooted.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Google Cloud Functions</h1>
                
            
            
                
<p>The serverless computing service offered by Google Inc is called <strong>Google Cloud Functions </strong>(<strong>GCF</strong>).</p>
<p>We basically refer to it as GCF in this section. Like other serverless platforms, GCF provides both execution environment and the SDK to help us develop and manage the entire life cycle of our function. It provides an SDK to help us get started with the framework. The main language supported by GCF is JavaScript and there is a Node.js Docker image for us to use. With Docker, it is convenient to build a function. When about to deploy, it is relatively easy to deploy it with the Google Cloud CLI tool. It is natural that GCF will allow us to connect to other Google-based services efficiently:</p>
<div><img src="img/06039659-fd8e-42a9-a986-0d4e2c94134b.png" style="width:43.17em;height:21.33em;"/></div>
<p>Figure 3.3: A common IoT use case implemented with Google Cloud Functions</p>
<p>The preceding diagram demonstrates one of the common use cases implemented on Google Cloud. It is an example of an IoT pipeline using all Google Cloud services. A Google Cloud Function is used to compute data from the message queue and divert it to both the big data stack and Firebase. The Firebase service acts as a <strong>Backend as a Service</strong> (<strong>BaaS</strong>) for mobile applications. In a later chapter, we will demonstrate a similar BaaS using the <strong>Parse platform</strong>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Overview</h1>
                
            
            
                
<p class="mce-root">The definition of a function in the FaaS or the serverless platform is that it should focus on only one objective. Due to the nature of the function, it should not be too complex. As we described in <a href="e9b10056-7288-4daf-b2e4-033682fa9185.xhtml" target="_blank">Chapter 1</a>, <em>Serverless and Docker</em>, serverless FaaS is actually a subset of the event-driven programming model. All cloud functions on GCF behave that way. Every single component of our application pipeline is connected by sending events to another. Also, events can be monitored. When we receive an event from the source, a cloud function associated with that mechanism will be triggered to run.</p>
<p class="mce-root">The function supported by GCF must be written in JavaScript, or languages that are able to transpile to JavaScript. At the time of writing, the environment for executing functions is a Node.js v6.11.5. Basically, developers would use any Node.js runtime that matches the same version. Using JavaScript and Node.js yields good portability and it allows developers to test the function locally. In addition, using Node.js allows access to the vast numbers of Node.js libraries, including APIs offered by the platform (<a href="https://cloud.google.com/nodejs/apis">https://cloud.google.com/nodejs/apis</a>), that help simplify development and integration.</p>
<p>GCF is designed to be a connection or a glue layer that links services together. In some use cases, we use functions to extend the existing cloud services.</p>
<p class="mce-root">With the event-driven model, functions can listen and wait until the file uploading event is triggered, when some files are put into cloud storage. We can also listen to log changing in a remote blockchain environment. Or maybe we subscribe to a Pub/Sub topics and get a notification to trigger the functions.</p>
<p class="mce-root">We usually put some complex business logic inside a function. Cloud functions owned by Google have the ability to access the credential system of the GCP, therefore, it could authenticate with the large set of GCP services. This feature usually makes the cloud functions very useful on their own platform.</p>
<p>All infrastructure and the system software layers are fully managed by Google's platform, so we need to care only for our codes. Autoscaling is also the normal feature of this kind of platform. Provisioning additional computing resources just works automatically when the number of triggers becomes large. Deployed functions will autoscale to serve millions of requests without any further configuration from us.</p>
<p>The fine-grained concept of an FaaS function makes this kind of computing fit nicely to implement self-contained APIs and WebHooks (we will demonstrate this in later chapters). Google Cloud Functions supports many aspects of workloads, for example, data processing/ELT, WebHooks, implementing APIs, acting as a backend for mobile applications, and accepting streaming data from IoT devices.</p>
<p>GCF supports many aspects of serverless computing. An obvious limitation at the moment is that it supports only Node.js as a programming language. GCF uses containers internally to wrap around the Node.js codes and deploy onto its internal orchestration FaaS system. A part of this engineering has been open sourced as a project called <strong>distroless</strong>. We can accomplish similar things with the concept of declarative containers, proposed in the final chapter. Using this concept allows us to deploy a workload containing only the application in the same way GCF does.</p>
<p>All of these use cases allowed by GCF will be demonstrated with different approaches using Docker and FaaS platforms in a later chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Execution model</h1>
                
            
            
                
<p>Google takes care of everything for us, including the hardware level, the OS, networking, and the application runtimes. A function deployed there on the GCF will run in an automatically managed platform. Each cloud function will be executed separately in a container-based isolation, which is a secure execution context. Running independently, each function will not interfere with others while sharing the same host. This is the same concept used by Docker and other container implementations.</p>
<p>At the time of writing, Google Cloud Functions chooses to support only JavaScript running on Node.js v6.11.5; however, the document says that they will keep the version of Node.js updated by going closely with the <strong>Long-Term Support</strong> (<strong>LTS</strong>) releases, as quickly as possible. We can be confident that all patch versions for security and minor updates of the Node.js runtime will match the upstream releases.</p>
<p>As previously mentioned, a cloud function is also put into a container. In the case of Google Cloud Functions, its root filesystem is based on <em>Debian</em>. The base image of GCF is updated regularly and available as Docker images. It could be pulled from <kbd>gcr.io/google-appengine/nodejs</kbd>. Here's the way the system prepares the base image by inheriting the image and installing Node.js version 6.11.5 to it:</p>
<pre><strong>FROM gcr.io/google-appengine/nodejs</strong><br/><strong>RUN install_node v6.11.5</strong></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Statelessness</h1>
                
            
            
                
<p>Stateless is the preferred model when writing a serverless FaaS function. Why? Because in the fully managed execution environment, which can be scaled up and down at anytime, we cannot expect our function state to be preserved. So it is best to not save anything to the function's local storage. If we need memory, such as global variables that may be shared across instances of the function, these variables must be managed explicitly by external storage services.</p>
<p>In some situations, saying a function is completely stateless makes us underutilize the execution context of that function. As we already know, our function is actually running inside a container isolation. And it is completely fine for our function to write some things onto the local storage during execution, of course, without the expectation to share states outside this isolation. When saying <em>stateless</em> in the container's context, it is likely to be the <em>share-nothing</em> model rather than being <em>stateless</em>. The share-nothing model, is the better word to generally describe the statelessness of container-based FaaS.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Timeout</h1>
                
            
            
                
<p>In general, a serverless platform usually caps the execution time of a cloud function to prevent overuse of the platform's computing resources. For Google Cloud Functions, the default timeout is set to be 1 minute and can be extended to 9 minutes if the user prefers. When a function is timed out, its running codes are terminated. For example, if a function is scheduled to run at the 3 minutes after it starts, and if the timeout is set to be 2, that function will never run.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Execution guarantees</h1>
                
            
            
                
<p>An error can occur anytime during the execution of a function. A function might not be executed only once if it failed. The model of execution depends on the type of function.</p>
<p>For example, a simple synchronous HTTP request will be invoked once, at most. This means that the function invocation will be failed and never retried. The caller side is responsible for error handling and the retry strategy on its own.</p>
<p>While asynchronous functions will be invoked at least once, as is the nature of these asynchronous calls, so we need to prepare for a situation that this kind of function will be invoked multiple times. Also, the state to be modified by these functions should be idempotent and robust. For example, we may need to implement a state machine to control the states of the system.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">IBM Cloud Functions</h1>
                
            
            
                
<p>IBM Cloud Functions is a service provided by IBM Cloud. It is powered by Apache OpenWhisk; actually, it's IBM who donated OpenWhisk to the Apache Foundation. We have a chapter dedicated to OpenWhisk later in this book.</p>
<p class="mce-root">The Cloud Functions service provided by IBM is, of course, very similar to other function services in terms of concepts. Functions wrap around the application business logic and run in the event-driven FaaS environment managed by IBM.</p>
<p class="mce-root">Functions are designed to respond to a direct HTTP invocation from other Web or mobile apps, or to events triggered by other supported systems, for example, Cloudant. IBM Cloud provides Cloudant, a commercially supported JSON data store built on top of CouchDB.  We can prepare a trigger in the Cloudant system, and let it fire events to invoke functions defined in the IBM Cloud Functions, when the data in Cloudant is changed.</p>
<p class="mce-root">The design goal of functions is generally the same among cloud providers. They provide a way for us developers to focus only on writing application business logic, then uploading codes to their cloud as cloud functions.</p>
<p>To further explore the concepts behind OpenWhisk, the engine behind IBM Cloud, please feel free to jump to <a href="c78cb885-6836-493a-8fd9-d98e85bf40c4.xhtml">Chapter 6</a><a href="c78cb885-6836-493a-8fd9-d98e85bf40c4.xhtml" target="_blank"/>, <em>OpenWhisk on Docker</em>, to learn more about OpenWhisk.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Serverless Framework</h1>
                
            
            
                
<p class="mce-root">The Serverless Framework is an application development framework and tool for the serverless computing paradigm. The framework only shares the same name with serverless. Please do not be confused.</p>
<p class="mce-root">The authors of the Serverless Framework consider that a serverless application is the next evolution of application development in the cloud native ecosystem. And this kind of application needs a certain level of automation. This idea was the stem of the framework.</p>
<p class="mce-root">The design idea views managed services and functions as coupled entities. To make an application around them, a tool should provide build, test, and deploy commands to make the whole development life cycle fully automated.</p>
<p class="mce-root">There also should be a consistent way of building, testing, and deploying a serverless application to multiple cloud providers, while minimizing code changes. The framework should help configure the setting for each cloud provider based on the following:</p>
<ul>
<li class="mce-root">The language runtime</li>
<li class="mce-root">The cloud provider selected by the application developer</li>
</ul>
<p class="mce-root">With this level of abstraction, the framework yields real advantages and lets developers focus on application business logic, rather than keep changing cloud configurations to match each provider.</p>
<p class="mce-root">There are four benefits of the Serverless Framework described by its creators:</p>
<ul>
<li class="mce-root">The Serverless Framework helps speed up the development process because the framework contains CLI-based commands to create a project, build, and also helps to test applications from the same development environment. It saves time because the Serverless Framework is independent from any cloud providers. There is also a mechanism to deploy a new version to the cloud and allow rollback for the previous one, if it fails.</li>
<li class="mce-root">With the Serverless Framework, it allows us to develop codes independently to any cloud providers. So, the code with a good writing style would be migrated across the providers. For example, we can simply move our functions deployed as AWS Lambda by just changing the provider in the YAML file to Google Cloud and re-deploy again. But actually this is only a part of the whole problem. It is actually not the codes that could lock you to the vendor, it's the services provided by the vendor that make you stay with them. So choose the supported service wisely and this problem could be effectively solved.</li>
<li class="mce-root">The Serverless Framework helps to enable <strong>Infrastructure as Code</strong> (<strong>IaC</strong>). With deployment that could be done via the set of APIs, we enable a certain level of automation. This makes us able to fully deploy the system as multi-cloud applications.</li>
<li class="mce-root">Finally, the framework is widely used and has a very vibrant community. This is also an important key for choosing a tool. The framework extensions are actively developed by the community because of the base language, JavaScript on Node.js, that they chose for the framework. So, it is relatively easy to add a new provider to the framework. A notable community-based provider is Kubeless.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Exercise</h1>
                
            
            
                
<p>Let's do some revision by trying to answer the questions without reviewing the contents:</p>
<ol>
<li>How long is the time limitation for an AWS Lambda?</li>
<li>Why do you think the cloud providers limit computational time for FaaS functions?</li>
<li>What are Azure's durable functions? Do they have any benefit?</li>
<li>How can we test an AWS Lambda program just with Docker?</li>
<li>What's the engine behind IBM Cloud Functions? What do you think is the reason behind IBM open sourcing it?</li>
<li>What is the Serverless Framework? Why is it important?</li>
<li>How could we make a FaaS function work across cloud providers? Do you think it is really possible?</li>
<li>Please explain the difference between stateless and share-nothing models.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this section, we have discussed four major serverless computing platforms, some of their characteristics and limitations. We have also discussed the Serverless Framework, a framework and tool designed to help build, test, and deploy applications to multiple serverless computing platforms.</p>
<p>In the next three chapters, we will see the truly different aspects of the serverless platforms provided by cloud providers and serverless/FaaS platforms that allow us to deploy them on our own with Docker technologies.</p>


            

            
        
    </body></html>