- en: Universal Control Plane
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn everything about Docker's **Universal Control
    Plane** (**UCP**) that's required for the Docker Certified Associate exam. Universal
    Control Plane is the Docker Enterprise component in charge of managing clusters.
    First, we will introduce UCP's components and their features. It is important
    to know that UCP has changed a lot in recent years. The Docker Enterprise platform
    was previously known as Docker Datacenter. Docker changed its name when version
    2.0 was released. That version was also important because it was the first one
    to include Kubernetes as a second orchestrator. In this chapter, we will learn
    how Kubernetes is integrated and how to deploy a production-ready platform.
  prefs: []
  type: TYPE_NORMAL
- en: In November 2019, Mirantis Inc. acquired the Docker Enterprise platform business,
    including its products, customers, and employees. Therefore, Docker Enterprise
    is currently a Mirantis Inc. product.
  prefs: []
  type: TYPE_NORMAL
- en: We will discover UCP's main components and learn how to deploy a production-ready
    environment with high availability. Enterprise environments have many security
    requirements and UCP includes its own authentication and authorization systems
    based on RBAC, all of which can be easily integrated with an enterprise's user
    management platform. Docker Enterprise is based on Docker Swarm but also includes
    an enterprise-ready Kubernetes environment within the cluster. We will learn about
    UCP's administration tasks, security configurations, special features, and how
    to provide a disaster recovery strategy based on backup and restore features.
    We will finish this chapter by reviewing what should be monitored on this platform
    to ensure its health.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding UCP components and features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying UCP with high availability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing Docker UCP's environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Role-based access control and isolation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: UCP's Kubernetes integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: UCP administration and security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backup strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upgrades, health checks, and troubleshooting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can find the code for this chapter in the GitHub repository: [https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git](https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '"[https://bit.ly/34BHHdj](https://bit.ly/34BHHdj)"'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding UCP components and features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Docker''s UCP provides the control plane for the Docker Enterprise platform.
    It is based on Docker Swarm but also integrates the Kubernetes orchestrator. The
    following is a quick list of its current features:'
  prefs: []
  type: TYPE_NORMAL
- en: A centralized cluster management interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A cluster resource environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Role-based access control
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A client environment via WebGUI or the CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we mentioned previously, UCP is based on Docker Swarm orchestration. We will
    deploy a Docker Swarm cluster with managers and worker roles.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will install a manager node. This will be the leader during the installation
    process. All the components will be deployed as containers, so we only require
    a Docker Enterprise Engine to run them.
  prefs: []
  type: TYPE_NORMAL
- en: Once the first manager has been installed, and with all the UCP components up
    and running, we will continue adding nodes to the cluster. This is a really simple
    process.
  prefs: []
  type: TYPE_NORMAL
- en: All the components will be managed by a master agent process called `ucp-agent`.
    This process will deploy all the other components according to the role of the
    installed node.
  prefs: []
  type: TYPE_NORMAL
- en: Let's review the different components that are deployed on manager and worker
    role nodes.
  prefs: []
  type: TYPE_NORMAL
- en: UCP components on manager nodes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [Chapter 8](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml), *Orchestration Using
    Docker Swarm*, we learned how these clusters work. Manager nodes run all management
    processes. We will deploy an odd number of manager nodes to provide high availability
    because Docker Swarm is based on the Raft protocol and requires consensus or quorum
    in the management plane.
  prefs: []
  type: TYPE_NORMAL
- en: 'Manager nodes run all UCP core services, including the web UI and data stores
    that persist the state of UCP. These are the UCP services running on manager nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Component** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-agent` | This component is the agent running on each node to monitor
    and ensure the required services are running. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-swarm-manager` | To provide compatibility with a Docker Swarm environment,
    this component runs on manager nodes. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-proxy` | This component provides secure access to each Docker Engine
    on the platform using TLS and forwarding requests to a local socket. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-auth-api` | Authentication is managed with this component running on
    manager nodes, exposing its API to authorize access. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-auth-store` | This component stores data and the configurations of users,
    organizations, and teams on the UCP platform. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-auth-worker` | An authentication worker periodically runs synchronization
    tasks with external authentication backends. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-client-root-ca` | This component provides a certificate authority to
    sign users'' bundles on the platform. Bundles are packages issued by the management
    platform to provide users with access. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-cluster-root-ca` | To ensure secure communication between platform components,
    this component provides a CA for signing TLS certificates. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-kv` | This component provides a key-value database to store cluster
    configurations. It was only used for Legacy Swarm (we have not seen how Docker
    Swarm was deployed in the past, but it is similar to Kubernetes these days) but
    currently, it is also used as a Kubernetes key value. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-controller` | The UCP web UI is key for management. `ucp-controller`
    provides this feature. It is the first point of failure when users cannot access
    the cluster. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-reconcile` | To monitor components'' health, UCP runs `ucp-agent`, and
    if some of them fail, it will try to restart them. This component will just run
    when something goes wrong. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-dsinfo` | UCP can run troubleshooting reports. It executes this component
    to retrieve all available information. We use support dumps to send information
    to support services. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-metrics` | This component recovers node metrics. This data can be used
    in other monitoring environments. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-interlock`/`ucp-interlock-proxy` | Interlock components allow advanced
    users to publish applications deployed in the cluster. `ucp-interlock` queries
    the UCP API for changes to be configured to publish services in the `ucp-interlock-proxy`
    component, as well as a reverse proxy to be deployed and configured automatically
    for you by UCP. |'
  prefs: []
  type: TYPE_TB
- en: 'The following processes also run on master nodes but are separated into a different
    table because they are related to Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Process** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-kube-apiserver` | This is the Kubernetes master API component. All Kubernetes
    processes will be deployed as containers in our host. Using containers to deploy
    applications helps us to maintain applications'' components and their upgrades.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-kube-controller-manager` | This Kubernetes process will manage all controllers
    required to control, replicate, and monitor Pods. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-kube-scheduler` | `kube-scheduler` schedules workloads within cluster
    nodes. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-kubelet` | `kubelet` is the Kubernetes agent. It is the endpoint used
    by Kubernetes to manage nodes and their interactions. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-kube-proxy` | `kube-proxy` manages a Pod''s publishing and communications.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `k8s_ucp-kube-dns`/`k8s_ucp-kubedns-sidecar`/`k8s_ucp-dnsmasq-nanny` | These
    containers manage and monitor DNS procedures and the resolution required for UCP
    and Kubernetes. |'
  prefs: []
  type: TYPE_TB
- en: '| `k8s_calico-node`/`k8s_install-cni_calico-node`/`k8s_calico-kube-controllers`
    | Calico is the default **container network interface** (**CNI**) for Kubernetes
    and it is automatically deployed during UCP installation. |'
  prefs: []
  type: TYPE_TB
- en: 'There is also an important component on newer releases to help with the interaction
    between Docker Swarm and Kubernetes interactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Process** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `k8s_ucp-kube-compose` | `kube-compose` allows us to deploy Docker Compose''s
    workloads either on Docker Swarm as stacks or Kubernetes. |'
  prefs: []
  type: TYPE_TB
- en: These are the components that can be deployed on manager nodes. We will usually
    deploy at least three manager nodes because either Docker Swarm or Kubernetes
    requires an odd number of nodes for a distributed consensus.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's review worker components.
  prefs: []
  type: TYPE_NORMAL
- en: UCP components on worker nodes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following are the components that are deployed on worker nodes once they
    are joined to the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Components** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-agent`, `ucp-proxy`, `ucp-dsinfo`, and `ucp-reconcile` | These processes
    have the same functionality that was described for manager nodes. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-interlock-extension` | `interlock-extension` prepares configurations
    for `interlock-proxy` based on changes retrieved from Docker Swarm service configurations.
    This process is based on templates reconfigured dynamically to accomplish all
    updates that happen within cluster-wide published workloads. |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-interlock-proxy` | `interlock-proxy` runs a proxy process configured
    dynamically thanks to all other Interlock processes. These prepare a configuration
    file for the proxy component with all the running backends required for each published
    service. |'
  prefs: []
  type: TYPE_TB
- en: 'For Kubernetes to work, worker nodes also execute the following processes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Processes** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `ucp-kubelet` and `ucp-kube-proxy` | Only these two processes are required
    for Kubernetes on worker nodes. |'
  prefs: []
  type: TYPE_TB
- en: '| `k8s_calico-node` and `k8s_install-cni_calico-node` | Networking within cluster
    nodes requires Calico, so its processes are also deployed on worker nodes. |'
  prefs: []
  type: TYPE_TB
- en: From these lists, it is easy to understand how Kubernetes is deployed on Docker
    Enterprise. Manager nodes run Kubernetes' control plane while workers receive
    workloads. Notice that managers run `kube-proxy` and `kubelet`, so they are also
    able to receive workloads. This is also true for Docker Swarm, as we learned in
    [Chapter 8](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml), *Orchestration Using
    Docker Swarm*. Docker Enterprise allows managers to execute application workloads
    by default.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also review the volumes that are deployed on UCP. We will divide them
    into two categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Volumes for certificates**: All these volumes are associated with certificate
    management within the cluster. Take care of them because if we lose them, we will
    have serious authentication problems between UCP/Kubernetes processes:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-auth-api-certs`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-auth-store-certs`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-auth-worker-certs`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-client-root-ca`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-cluster-root-ca`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-controller-client-certs`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-controller-server-certs`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-kv-certs`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-node-certs`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Volumes for data**: These are data volumes and are used to store different
    databases deployed within the cluster, as well as the metrics that have been retrieved
    from different components:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-auth-store-data`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-auth-worker-data`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-kv`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-metrics-data`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ucp-metrics-inventory`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All these volumes are important for the cluster. Key-value pairs, common certificates,
    and authentication data volumes are replicated on control plane nodes. They are
    created using the default local volume driver unless we have already created them
    using a different driver. Keep in mind that they should be created before deploying
    the cluster if we want to store data in a non-standard location (`/var/lib/docker/volumes`
    or the defined `data-root` path in your environment).
  prefs: []
  type: TYPE_NORMAL
- en: This section is very important for the Docker Certified Associate exam because
    we need to know where components are distributed and their functionality on the
    platform.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know what components will be deployed on each cluster role, we will
    learn how to install production-ready environments.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying UCP with high availability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we will take a look at the hardware and software requirements for the
    platform. We will use version 3.0 – the current version at the time of writing
    this book. It is known that the DCA exam was prepared even before Docker Enterprise
    version 2.0 was released. Neither Docker Desktop nor Kubernetes were part of the
    Docker Enterprise platform on that release. We will deploy the current version
    because the exam has evolved to cover important topics in newer versions. Let''s
    quickly review the current maintenance life cycle:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Docker Enterprise 2.1** | **Docker Enterprise 3.0** |'
  prefs: []
  type: TYPE_TB
- en: '| End of life on 2020-11-06 | End of life on 2021-07-21 |'
  prefs: []
  type: TYPE_TB
- en: '| Components:- Enterprise Engine 18.09.z - Universal Control Plane 3.1.z'
  prefs: []
  type: TYPE_NORMAL
- en: '- Docker Trusted Registry 2.6.z | Components:- Enterprise Engine 19.03.z- Universal
    Control Plane 3.2.z- Docker Trusted Registry 2.7.z |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker provides 2 years of support from the release date. We recommend taking
    a look at Docker''s website for updated information on the maintenance life cycle
    and compatibility matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://success.docker.com/article/maintenance-lifecycle](https://success.docker.com/article/maintenance-lifecycle)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://success.docker.com/article/compatibility-matrix](https://success.docker.com/article/compatibility-matrix)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of the listed versions include Kubernetes, but the deployed version will
    be different. At the time of writing this book, Docker Enterprise deploys Kubernetes
    v1.14.8.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can deploy the Docker Enterprise platform on-premises or on cloud providers.
    Before deploying the first node, let''s review the minimum node requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: 8 GB and 4 GB of RAM for the manager and worker nodes, respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2 vCPUs for manager nodes. Worker nodes' vCPUs will depend on the applications
    to be deployed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10 GB of free disk space for the `/var` partition for manager nodes (a minimum
    of 6 GB is recommended because Kubernetes will verify disk space before installation)
    and at least 500 MB of free disk space for the `/var` partition for worker nodes.
    Worker node space will depend on the applications to be deployed, how big their
    images are, and how many image releases should be present on our nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A more realistic approach to resources for control plane and image management
    would probably be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 16 GB of RAM for manager nodes and workers with DTR (we will learn about DTR
    in [Chapter 13](108b5948-15a9-40fb-b8dd-5a44c54efd7d.xhtml), *Implementing an
    Enterprise-Grade Registry with DTR*).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Four vCPUs for manager nodes and workers with DTR. Control plane CPU and image
    scanning can take forever if there is not enough CPU available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep in mind that a cluster's size will really depend on the applications being
    deployed. It is usually recommended to distribute application components in several
    nodes because clusters with fewer nodes are harder to maintain. A few nodes with
    many resources is worse than having the same resources distributed on many nodes.
    It gives you better cluster life cycle management and a better workload distribution
    when some nodes fail.
  prefs: []
  type: TYPE_NORMAL
- en: On control plane nodes, we will deploy Docker Enterprise Engine version 19.03
    (the latest release at the time of writing). These nodes should be deployed with
    static IP addresses and Linux kernel version 3.10 or higher. Because we will deploy
    more than one replica, we will require an external load balancer to route control
    plane requests to any of the available manager nodes. We will use a virtual IP
    address and a **Fully Qualified Domain Name** (**FQDN**) associated with this
    load balancer. We will add them as **Subject Alternative Names** (**SANs**) to
    ensure valid certificates. Certificates should be associated (as a SAN) with any
    node that can be reached as part of UCP's service. In this case, manager nodes
    will run control plane components, so certificates should be valid for any of
    them, including all possible FQDN names associated with UCP's management endpoints
    (ports `443` and `6443` by default for Docker Swarm and Kubernetes, respectively).
  prefs: []
  type: TYPE_NORMAL
- en: We will expose TCP ports `443` and `6443` to users by default. Both can be changed
    to other ones more appropriate for our environment. The first port allows user
    interaction with UCP's control plane either using the web browser, the API, or
    the Docker command line. The second port described publishes the Kubernetes API
    server. It allows us to interact directly with the Kubernetes orchestrator.
  prefs: []
  type: TYPE_NORMAL
- en: Worker nodes do not require static IP addresses but they should be accessible
    by their names using DNS.
  prefs: []
  type: TYPE_NORMAL
- en: We cannot deploy user namespaces within UCP. (We learned about the user namespaces
    that are used to improve host security in [Chapter 3](c2dd78c4-066f-40b4-94e7-a7e2904d7ec2.xhtml),
    *Running Docker Containers*.) It is not easy to use this feature under UCP conditions,
    which is why it is not supported.
  prefs: []
  type: TYPE_NORMAL
- en: 'A minimum environment with high availability will include three managers and
    at least two workers. The following diagram shows the smallest environment (DTR
    nodes are not included). We can say that UCP has three major logical components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/47319578-6162-481e-9844-036acbb22ea9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, as a summary, we will need the following logical requirements for
    the deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: Static IP addresses for manager nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A VIP address and FQDN for the control plane
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An external load balancer owning a VIP and TCP pass through to managers on ports
    `443` and `6443` (by default)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following ports and protocols should be permitted (TCP ports unless explicitly
    described):'
  prefs: []
  type: TYPE_NORMAL
- en: 'On managers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Port `443` for the UCP web UI and API
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Port `6443` for the Kubernetes API server
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ports `2376` and `2377` for Docker Swarm communication
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ports ranging from `12379` to `12388` for internal UCP component communication
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On workers and managers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Port `7946` (TCP and UDP) for Docker Swarm gossip
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Port `4789` (UDP) for overlay networking
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Port `12376` for TLS authentication proxy to access Docker Engine
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Port `6444` for the Kubernetes API reverse proxy
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Port `179` for BGP peers for Kubernetes networking
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Port `9099` for Calico health checks
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Port `10250` for Kubernetes Kubelet
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Users will use ports `443` and `6443` to access UCP services via the HTTPS protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 'All cluster nodes will run containers. Some of these nodes will act as managers
    and they will run management components while others just run a few worker components
    and workloads. But there are two common elements on managers and workers: UCP
    agent and Docker Engine.'
  prefs: []
  type: TYPE_NORMAL
- en: Docker Engine is always required because we need to run containers. Docker Enterprise
    requires Docker Enterprise Engine. The installation process is easy and it will
    be based on the license key file and the specific packages available for each
    customer at `https://hub.docker.com/u/<YOUR_USER_OR_ORGANIZATION>/content`. First,
    we will go to `https://hub.docker.com/` and register for a Docker Hub account.
    Docker provides a 1-month trial of the Docker Enterprise platform, available at
    [https://hub.docker.com/editions/enterprise/docker-ee-trial](https://hub.docker.com/editions/enterprise/docker-ee-trial).
    In [Chapter 11](1879ea92-ae47-4230-ac84-784d4bc73185.xhtml), *Universal Control
    Plane*, [Chapter 12](ab131f1f-ca6e-4815-9a3a-8c92c93c9dbc.xhtml), *Publishing
    Applications in Docker Enterprise*, and [Chapter 13](108b5948-15a9-40fb-b8dd-5a44c54efd7d.xhtml),
    *Implementing an Enterprise-Grade Registry with DTR*, we will show my own account
    (`frjaraur`) for example purposes, as well as the different steps and pictures
    to help you understand this.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the `frjaraur` content URL. You will have your
    own content once you log into the Docker Hub website. We will find the required
    license and our package repository URL on this page after signing up for a Docker
    Enterprise 30-day trial:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/56d1cce9-3d94-453a-aa50-ae233b1cd2b4.png)'
  prefs: []
  type: TYPE_IMG
- en: At the bottom right, we will read our package's URL. Click on the copy button
    and follow the next procedure to install Docker Enterprise Engine. This procedure
    will be different for each Linux distribution. In this book, we will follow Ubuntu's
    procedure. The process is described at the previously provided customer content
    URL. Microsoft Windows nodes are also supported within the Docker Enterprise platform,
    although they can just be used as workers at the time of writing this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the steps to follow to install UCP with high availability on Ubuntu
    nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Export the Docker Engine version and the previously shown URL on the `DOCKER_EE_VERSION`
    and `DOCKER_EE_URL` variables, respectively. At the time of writing this book,
    the latest Docker Enterprise Engine version is 19.03:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Notice that your `DOCKER_EE_URL` will be completely different. You can ask for
    a trial license to follow these steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we need to add the Docker customer''s package repository to our environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will install the required packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: These procedures must be applied to all cluster nodes before installing UCP.
    As we mentioned previously, we will have different procedures for different Linux
    flavors, but we will also be able to include Microsoft Windows nodes in the cluster.
    Microsoft Windows Docker Engine's installation is completely different and is
    shown at `https://hub.docker.com/u/<YOUR_USER_OR_ORGANIZATION>/content`.
  prefs: []
  type: TYPE_NORMAL
- en: Always review your Docker customer's content page before installing Docker Enterprise
    Engine because the installation procedure may change.
  prefs: []
  type: TYPE_NORMAL
- en: When all the cluster nodes have Docker Engine installed, we can continue with
    Docker UCP's installation. This workflow is not required but it is recommended
    because we can avoid any problems before installing UCP. This is because its components
    will run as containers in your hosts.
  prefs: []
  type: TYPE_NORMAL
- en: Docker provides support for different infrastructures and also certifies running
    the Docker Enterprise platform on them. Amazon Web Services and Microsoft Azure
    are the certified environments at the time of writing this book. In both cases,
    Docker also provides infrastructure scripts and/or step-by-step documentation
    for successfully deploying the Docker Enterprise platform on them.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker Enterprise platform is based on Docker Swarm, although Kubernetes
    is also deployed. Therefore, we will create a Docker Swarm cluster using the UCP
    installer, and then we will add other nodes as managers or workers.
  prefs: []
  type: TYPE_NORMAL
- en: The installation will require launching a container named `ucp`. This is very
    important because it ensures just one installation at once. We will also use Docker
    Engine's local socket as the volume inside the installation container. The UCP
    installation process has many options – we will cover the most important ones
    here.
  prefs: []
  type: TYPE_NORMAL
- en: To install UCP, we will launch `docker container run --name ucp docker/ucp:<RELEASE_TO_INSTALL>`.
    It is important to install a specific release because the `docker/ucp` container
    will also be used for backup/recovery and other tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write down and execute a usual installation command line for the first
    manager in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: After 35 steps, your UCP's environment will be installed on the first Linux
    node. Take care and use DNS resolution and an external load balancer. As we mentioned
    in the previous sections, all the managers will run the same control plane components.
    Therefore, an external load balancer is required to guide requests to any of them.
    This can be done by following the round-robin algorithm, for example (it does
    not matter which UCP manager node receives the requests, but at least one should
    be reachable).
  prefs: []
  type: TYPE_NORMAL
- en: The external load balancer will provide a virtual IP address to the UCP control
    plane and we will also provide pass-through port-routing for ports `443` and `6443`
    (or customized ones if you changed them). We will add this external load balancer's
    virtual IP address and the associated fully qualified domain name as a SAN. In
    fact, we will add as many SANs as required for our environment using the `--san`
    argument.
  prefs: []
  type: TYPE_NORMAL
- en: These steps are key for your organization access and **Docker Trusted Registry**
    (**DTR**) because it is usual to integrate both within UCP. In this case, DTR
    will ask UCP for user authentication, so it has to have access and resolution
    to UCP's FQDN and ports.
  prefs: []
  type: TYPE_NORMAL
- en: We will use a pass-through or transparent proxy on external load balancers to
    allow UCP's backends to manage TLS certificates and connections.
  prefs: []
  type: TYPE_NORMAL
- en: 'The UCP image will allow us to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Install and uninstall UCP using the `install` and `uninstall-ucp` actions. The
    uninstall option will remove all UCP components from all cluster nodes. We do
    not have to execute any other procedure to completely remove UCP from our nodes.
    Docker Engine will not be removed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Download the required Docker images from Docker Hub using the `images` option.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backup and restore UCP manager nodes using the `backup` and `restore` actions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide a UCP cluster ID and its certificates using the `id` and `dump-certs`
    options. Dumping certificates allows us to store them securely to avoid certificate
    problems if we accidentally remove any required volume.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a support-dump using the `support` action. These dumps will contain all
    the useful information about our environment, including application/container
    logs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upgrade the UCP platform by executing the `upgrade` option. This option will
    upgrade all UCP components and may impact our services. It is preferred to add
    the `--manual-worker-upgrade` argument to avoid worker nodes from being auto-upgraded.
    We will need to take care of our workloads and move them within worker nodes and
    manually upgrade UCP on them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Create an example UCP configuration file and verify the required port status.
    UCP can be configured using either the provided web UI or using configuration
    files. Using configuration files will allow us to maintain reproducibility, and
    changes can be managed with any configuration management application. This method
    can be achieved once UCP is installed or during installation by customizing the
    example config file generated with the `example-config` option and using `docker/ucp
    install --existing-config` with this modified file. The available options are
    described at the following link: [https://docs.docker.com/ee/ucp/admin/configure/ucp-configuration-file](https://docs.docker.com/ee/ucp/admin/configure/ucp-configuration-file).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following are the most commonly used UCP installation options:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Options** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `--swarm-grpc-port`,`--controller-port`,`--kube-apiserver-port`, and `--swarm-port`
    | These options allow us to modify the default ports used in several services.
    The most important ones, probably customized in your environment, will be `kube-apiserver-port`
    (defaults to `6443`) and `controller-port` (defaults to `443`). They publish Kubernetes
    and UCP user endpoints to allow us to interact with the cluster. |'
  prefs: []
  type: TYPE_TB
- en: '| `--host-address` and`--data-path-addr` | The first option sets which node''s
    IP address will be allocated for publishing the control plane. The second option
    allows us to isolate the control plane from the data plane. We set a different
    interface or IP address for the data plane. |'
  prefs: []
  type: TYPE_TB
- en: '| `--pod-cidr`, `--service-cluster-ip-range` and `--nodeport-range` | These
    options allow us to customize Kubernetes Pods'' and Services'' IP address ranges
    and publishing ports for `NodePort` services. |'
  prefs: []
  type: TYPE_TB
- en: '| `--external-server-cert` | With this option, we configure our own certificate
    within the UCP cluster. |'
  prefs: []
  type: TYPE_TB
- en: '| `--san` | We include as many SANs as required to add these aliases to UCP
    certificates. Ask yourself how users and admins will consume the UCP cluster and
    add the FQDN names related to these services. |'
  prefs: []
  type: TYPE_TB
- en: '| `--admin-username` and `--admin-password` | It is recommended to set up an
    admin username and password during installation to provide a reproducible workflow.
    We will avoid the `--interactive` option to have an **Infrastructure-as-Code**
    (**IaC**) UCP installation process. |'
  prefs: []
  type: TYPE_TB
- en: Once UCP is installed on the first manager node, we will just join other manager
    nodes and workers to the cluster, as we learned in [Chapter 8](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml),
    *Orchestration Using Docker Swarm*. To get the required `docker join` command
    line, we just execute `docker swarm join-token manager` for manager nodes and
    `docker swarm join-token worker` for worker nodes. We just copy their output and
    execute the `docker join` command on each manager and worker node. It is quite
    easy.
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible to obtain the required joining instructions from the web
    UI by going to the Shared Resources | Nodes menu.
  prefs: []
  type: TYPE_NORMAL
- en: Nodes in a UCP cluster can work with either Docker Swarm or Kubernetes, or even
    in mixed mode. This allows nodes to run Docker Swarm and Kubernetes workloads
    at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Mixed mode is not recommended in production because orchestrators do not share
    their load information. Therefore, a node can be almost full for one orchestrator
    and empty for another. In this situation, it can continue receiving new workloads
    for a non-full orchestrator, hence impacting other orchestrator's application
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: As a summary, we installed Docker Engine and then we installed UCP. We reviewed
    this process and the main arguments required to install the Docker Enterprise
    platform in our environment.
  prefs: []
  type: TYPE_NORMAL
- en: If you plan to install Docker Enterprise on Amazon AWS or the Microsoft Azure
    cloud, you should read the specific instructions and options in the Docker documentation
    (for AWS, [https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-aws](https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-aws);
    for Azure, [https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-azure](https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-azure)).
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will review the UCP environment.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the Docker UCP environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will review the Docker UCP environment. We will be able
    to use either the web UI, the command line, or its published REST API. In this
    book, we will cover the web application interface and how to integrate our `docker`
    client command line with UCP.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will introduce the web UI.
  prefs: []
  type: TYPE_NORMAL
- en: The web UI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The web UI will run on all manager nodes. We will use UCP's fully qualified
    domain name, which is associated with its virtual IP address. Port `443` will
    be used unless you manually configured a different one. If we open `https://<UCP_FQDN>:<UCP_PORT>`
    on our browser, we will access the UCP login page. If we have used autogenerated
    certificates, the browser will warn us about an untrusted CA. This is normal because
    UCP generates an internal CA automatically for us to sign all internal and external
    certificates. We can upload our corporate or private certificates into UCP.
  prefs: []
  type: TYPE_NORMAL
- en: Remember to apply a passthrough (or transparent proxy) configuration on your
    external load balancer to access UCP backends. We will use `https://<MANAGER_IP>:<UCP_PORT>/_ping`
    for the backend's health check.
  prefs: []
  type: TYPE_NORMAL
- en: Let's have a quick review of UCP's web UI. The following screenshot shows the
    main login interface. We set the admin's password during installation, either
    executing this process interactively with the `--interactive` argument or automating
    these settings by adding the `--admin-username` and `--admin-password` arguments.
    The username and password that are used during installation should be used to
    log into UCP.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main page will also ask us to add a license file if we have not applied
    it during installation. This can be done using the `--license` argument for `docker
    run docker/ucp:<RELEASE> install`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8a593cc8-4833-4389-b117-c518e784dd92.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following screenshot shows the UCP Dashboard. Each user will have access
    to their own. The left panel will provide access to the user''s profile, Dashboard,
    Access Control, Shared Resources, and resources specific to Kubernetes and Swarm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/df34de10-6b1d-4d8f-87ae-cb4dcf15d115.png)'
  prefs: []
  type: TYPE_IMG
- en: The Dashboard screen shows us a quick review of the cluster's components' status.
    It also provides a summary of the Swarm and Kubernetes workloads and an overview
    of the cluster's load. Do not think this is enough for monitoring as this is too
    simple. We should add monitoring tools to improve alerting, performance reporting,
    and capacity planning features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Access Control will only appear when UCP administrators access the cluster''s
    Web UI. Administrators will be able to manage all of RBAC''s behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: Orgs & Teams provides an interface to create organizations and teams and we
    will integrate users into them from these entries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Users endpoint will allow us to manage users as expected. We will learn
    how to create and manage users in the next topic.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roles provides an interface for Kubernetes and UCP roles. Kubernetes resources
    should be managed using declarative methods using YAML resource files, while Docker
    Swarm's resources (managed by UCP) will be created using the web UI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grants helps us manage Kubernetes role bindings and Swarm roles and collection
    integrations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shared Resources provides access to resources for either Kubernetes or Docker
    Swarm. We will manage collections, stacks, containers, images, and nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/208027ae-f984-4e25-b748-f8cbf662233b.png)'
  prefs: []
  type: TYPE_IMG
- en: Nodes can be managed from the Nodes entry point. We will set node properties
    and the orchestrator mode. Adding new nodes is easy, as we have seen. The Add
    Node option shows us the cluster's `docker join` command line. We will just copy
    this instruction to the new node's Terminal. This will also apply to Microsoft
    Windows nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Stacks will show either multi-container or multi-service applications deployed
    on a Docker Swarm cluster. This view also shows Kubernetes workloads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes and Swarm endpoints show us each orchestrator''s specific resources:'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes shows namespaces, service accounts, controllers, services, ingress
    resources, Pod configurations, and storage. We will be able to change which namespace
    will be used for all users' web UI endpoints. We will also review and create Kubernetes
    resources using the declarative method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Swarm allows us to create and review services, volumes, networks, secrets, and
    configurations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can review the UCP documentation as well as Kubernetes' and the UCP API.
    This will help us implement automation procedures based on REST API integrations.
  prefs: []
  type: TYPE_NORMAL
- en: The command line using the UCP bundle
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The UCP bundle is probably the most important part to access for your users
    and administrators. Although every user can have access to UCP's web UI, CI/CD,
    monitoring tools, and DevOps, users will review and launch their workloads using
    the Docker command line. Therefore, this access should be secure. Remember that
    Docker Swarm deploys an encrypted control plane. All its internal communications
    will be secured by TLS. Users' access is not secured. UCP, on the other hand,
    provides a completely secure solution. Security is ensured using TLS for users
    and admin access. This is managed using personalized certificates. Each user will
    get their own group of certificates. Kubernetes access is also secured using the
    UCP user bundle.
  prefs: []
  type: TYPE_NORMAL
- en: 'To obtain this UCP bundle, users will use either the web UI or a simple `curl`
    command – or any command-line web client – to download this package file, compressed
    as a ZIP folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/612e0ee9-344c-4c0f-8733-e1cb3353672d.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding screenshot shows web GUI access to the user bundle file. We will
    just download it using a web browser. Once it is on our computer, we will decompress
    it. This file contains certificates, configuration, and scripts to load the client
    environment on our computer, regardless of whether it is running Linux, Mac, or
    Windows operating systems. There is an environment file for each one. We will
    look at its content and the procedure in Linux, but it is similar in Windows (the
    commands will vary).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use `curl` and `jq` to download the user bundle from the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If we decompress the admin bundle file, `ucp-bundle-admin.zip`, using `unzip`,
    we will obtain all the files required to connect to our cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then load this environment. We will use `env.ps1` in Microsoft Windows
    PowerShell or the `env.cmd` Command Prompt. On Linux hosts, we will use `env.sh`.
    When we load the environment on our shell, we will be able to connect remotely
    to the UCP cluster using the `docker` or `kubectl` client software:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the Kubernetes context has also been set. Therefore, we will be
    able to manage the cluster and deploy workloads on either Kubernetes or Docker
    Swarm. Each user's UCP bundle must be stored securely. We can generate a new one
    if we remove it, but keep it safe; someone could potentially use it and obtain
    access to your environment files.
  prefs: []
  type: TYPE_NORMAL
- en: UCP provides client software for Microsoft Windows and Linux on our manager
    nodes at `https://<UCP_FQDN>:<UCP_PORT>/manage/dashboard/dockercli`. We can download
    them to connect to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: It is key to use the UCP bundle instead of connecting to the cluster using SSH
    or any other local access. We will never allow local access to cluster nodes.
    Everyone must access the cluster either using the command line or the web UI.
  prefs: []
  type: TYPE_NORMAL
- en: UCP's REST API is also secured using certificates. We will require the UCP bundle's
    certificate files to access the cluster using its API.
  prefs: []
  type: TYPE_NORMAL
- en: We will review UCP's access control in the next section and provide a simple
    example that will help us understand RBAC concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Role-based access control and isolation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Role-based access control** (**RBAC**) manages authorization for Docker Swarm
    and Kubernetes. Docker Enterprise lets us manage users'' access to resources.
    We use roles to allow users to view, edit, and use cluster resources.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Authorization is based on the following concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Subjects**: We manage users, teams, and service accounts within organizations.
    Users are part of teams, included in organizations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resources**: These are the groups of Docker objects we were talking about
    in [Chapter 1](c5ecd7bc-b7ed-4303-89a8-e487c6a220ed.xhtml), *Modern Infrastructures
    and Applications with Docker*. As Kubernetes is also integrated into the UCP cluster,
    Kubernetes resources are also part of these groupings. UCP manages resources grouped
    in collections.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collections**: These are sets of resources, including different kinds of
    objects, such as volumes, secrets, configs, networks, services, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Roles**: These group sets of permissions and we assign them to different
    subjects. Roles define what can be done by whom.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Grants**: Combining subjects with roles and resource sets, we obtain grants.
    They are effective user permissions applied to groups of resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service accounts are only valid for Kubernetes. These are not user accounts;
    they are associated with applications or APIs assigned to manage their access.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some predefined roles but we can create our own. This is a list of
    the default ones included with Docker Enterprise''s UCP:'
  prefs: []
  type: TYPE_NORMAL
- en: 'None: This role does not provide access to any Docker Swarm resources. This
    should be the default role for new users.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'View Only: Users with this role can view resources such as services, volumes,
    and networks but they cannot create new resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Restricted Control: Users with this role can view and edit resources but they
    cannot use bind mounts (hosts'' directories) or execute new processes within containers
    using `docker exec`. They cannot run privileged containers or with enhanced capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Scheduler: This role allows users to view nodes so that they can schedule workloads
    on them. By default, all users get a grant with the `Scheduler` role against the
    `/Shared` collection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Full Control: This role should be restricted to advanced users only. These
    can view and edit volumes, networks, and images. They also can create privileged
    containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Users will only be able to manage their own containers or Pods. This behavior
    allows integrating namespaces (Kubernetes) and collections (Docker Swarm) in this
    equation. Therefore, users with full control access to a set of resources included
    in a collection will have all privileges on them in Docker Swarm. The same will
    happen if we add resources within a namespace and the user is included in a fully
    privileged role in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: There is also a more advanced role that's assigned to Docker Enterprise administrators.
    They will have full control and management privileges for the UCP environment.
    This can be managed using the Is Admin checkbox on the user's properties page.
  prefs: []
  type: TYPE_NORMAL
- en: Grants interconnect users and permissions with the set of resources where they
    should be applied. The grants management workflow includes their creation, user
    assignment, the role that should be applied, and resource association. This way,
    we ensure that the appropriate privileges are applied to a collection of resources
    assigned to a group of users (or just one user).
  prefs: []
  type: TYPE_NORMAL
- en: 'Collections are hierarchical and contain resources. They are represented by
    using a directory-like structure and every user has their own private collection,
    along with the user''s default permissions. Using this, we can nest collections.
    Once a user has been granted access to a collection, they will have access to
    all its hierarchical children. There are three main collections: `/`, `/System`,
    and `/Shared`.'
  prefs: []
  type: TYPE_NORMAL
- en: Under the `/System` collection, we will find UCP's manager nodes and UCP's and
    DTR's system services. By default, only administrators will have access to this
    collection. On the other hand, the `/Shared` collection will contain all the worker
    nodes ready for running workloads. We can add additional collections and move
    some workers to isolate them and provide multi-tenant features. Distributing workers
    on different collections will also distribute workload execution for different
    groups or tenants.
  prefs: []
  type: TYPE_NORMAL
- en: Each user has a private collection by default under `/Collections/Swarm/Shared/Private/<USER_NAME>`.
    This ensures that users' workloads are secure by default and only administrators
    will have access. Therefore, users have to deploy workloads on their team-shared
    collections.
  prefs: []
  type: TYPE_NORMAL
- en: Labels associated with collections manage users' access to resources, which
    makes it easy to allow or disallow a user's visibility dynamically.
  prefs: []
  type: TYPE_NORMAL
- en: Let's review these concepts with a short example.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have two projects in our organization (`myorganization`): `projectA` and
    `projectB`. We will also assume that we have three teams in our organization:
    developers, quality and assurance, and DevOps. Let''s describe some users and
    their roles within our organization:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Developers**: `dev1` and `dev2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quality and assurance:** `qa1` and `qa2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DevOps:** `devops1` and `devops2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**UCP Admin**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following image shows some screenshots of the user creation process. First,
    we create an organization and then teams and users inside the previously created
    organization:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/63c62974-88fc-4628-b990-2d220a8445c9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Each user will have their own user account in UCP. We will create developers,
    quality and assurance, and DevOps teams and we will add their users. We will also
    create three main collections as stages and child collections for each project.
    Therefore, we will have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`development/projectA` and `development/projectB`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`certification/projectA` and `certification/projectB`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`production/projectA` and `production/projectB`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's suppose that each developer works on one project at a time. They should
    have full access to their projects during the development stage but they should
    have view-only access in the certification stage. Quality and assurance users
    will only have access to create and modify their deployments in the certification
    stage. DevOps will have access to create and modify resources in production and
    they will allow view-only access to developers, but only on `projectA`. In fact,
    `projectB` should be secure and only a `devops2` user should be able to modify
    resources for this project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshots show the process of adding grants to allow a user
    access to collections. First, we create a collection, and then we add that collection
    to a new role:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e10abfc9-b802-4ef5-9ee3-855379fe31e0.png)'
  prefs: []
  type: TYPE_IMG
- en: We will launch two deployments with different users and will review how they
    view these deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will assume that all the required users have been created and that each
    user''s `ucp-bundle` has been downloaded. As user `dev1`, we will create a simple
    `nginx` deployment for `projectB`, using `com.docker.ucp.access.label=/development/projectB`
    as the label:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'If we now impersonate user `qa1`, we will get different results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'User `qa1` will not list any services because it does not have access to the
    `dev1` collection. But if we review this list with the `devops2` user, we will
    obtain a list that includes the `dev1` user''s services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If we try to modify this resource (the `nginx-dev` service), we will obtain
    an access error because we only have view authorization. On the other hand, the
    `dev2` user can scale up the number of replicas because they are in the developer
    group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'To finish off this example, we will create two different services as user `devops2`.
    We will deploy secure and unsecured services from `projectB` and `projectA`, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the `devops1` user should only be able to manage `nginx-prod-unsecure`,
    which is associated with `projectA`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This was a simple example of authorization management using labels. In this
    case, we manually added these labels, but we can set a default collection for
    each user if we wish. This will provide a default label associated with their
    workflows, instead of us using the out-of-the-box `/Collections/Swarm/Shared/Private/<USER>`
    collection. We can also associate constraints with collections to ensure specific
    locations. This is very important in multi-tenant environments.
  prefs: []
  type: TYPE_NORMAL
- en: UCP's Kubernetes integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have learned, Kubernetes is deployed alongside Docker Swarm when installing
    UCP. If we take a look at all the required Kubernetes components, we will notice
    that all of them run as containers within our cluster. The required key-value
    store will also be provided. Port `6443` (by default) will provide Kubernetes
    access, and users and administrators will use this port to manage the cluster
    or execute their workloads.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the Docker bundle's certificates and configuration file, `kube.yml`.
    As we learned in this chapter, we will load our user's bundle environment and
    then get access to the Kubernetes cluster using the `kubectl` command line.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once `env.sh` has been loaded using `source env.sh`, we will have the required
    environment variables and access to our certificates. If we get Kubernetes cluster
    nodes using `kubectl get nodes`, we will obtain their status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'If we review the running Pods in the `kube-system` namespace using `kubectl
    get pods -n kube-system`, we will notice that `calico` and `compose` for Kubernetes
    are also deployed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: These components are very important because Calico is the default CNI deployed
    with UCP. This allows us to deploy applications distributed cluster-wide. Pods
    and services are able to communicate within the cluster even if they do not run
    on the same host. This is not required in Docker Swarm because overlay networking
    is included by default. Calico allows us also to improve Kubernetes security because
    it can deploy network policies to isolate and manage Pods' and services' communications.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, Compose for Kubernetes provides a standard interface for
    Docker Swarm and Kubernetes. Docker stacks could be deployed either on Docker
    Swarm or Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also notice that `ucp-metrics` also runs Kubernetes workloads as other
    system-related deployments, obtained using `kubectl get deployments -A`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Kubernetes roles and role bindings are managed from the command line and the
    web UI. All Kubernetes features from the 1.14.8 release are available. This is
    also very important. Docker Enterprise provides a vanilla Kubernetes release and
    product releases also upgrade Kubernetes, but you cannot upgrade Kubernetes manually.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will review the main administration tasks and security
    improvements.
  prefs: []
  type: TYPE_NORMAL
- en: UCP administration and security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: UCP administrators manage Docker Swarm and Kubernetes clusters. They integrate
    external LDAP/AD authentication. Authentication can be delegated but UCP manages
    authorizations, as we learned in the *Role-based access control and isolation*
    section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the Admin Settings endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4236eb4d-0505-4dc0-ba92-9ea1cfa7eee4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Docker Enterprise license can be introduced during installation, but it also
    can be manage from the web UI in Admin Settings. This endpoint also allow us to
    do the following administration tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Rotate Docker Swarm's tokens to improve a cluster's security. Tokens are only
    used to join nodes to the cluster; we can change them whenever we need to.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manage Interlock's ports and enable publishing applications using this feature.
    We will talk about Interlock in [Chapter 12](ab131f1f-ca6e-4815-9a3a-8c92c93c9dbc.xhtml),
    *Publishing Applications in Docker Enterprise*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure some cluster configurations such as UCP's port and key-value database
    snapshots.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrate external LDAP and configure the default role to apply for new users
    and some session settings. This option delegates authentication to external LDAP/AD
    systems and UCP will just be used as an authentication cache if it is not available.
    We set user filters using attributes to only integrate subsets of users in the
    UCP environment. UCP synchronizes LDAP changes periodically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change UCP's application and audit logging levels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Execute and configure backups from the web UI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrate Docker Trusted Registry and Docker Content Trust to allow only signed
    images. This will be applied to all the nodes within the cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set the default orchestrator for new nodes. We can choose between Docker Swarm,
    Kubernetes, and mixed mode.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authorize administrators or users to execute workloads on UCP managers or worker
    nodes running DTR. We will decide who can run workloads on management nodes. It
    is recommended to avoid any non-control-plane workload on managers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customize and launch platform upgrades. This will allow us to decide between
    a completely automated process and deploying manual upgrades to worker nodes to
    avoid impacting an application's service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is recommended to disallow application workloads on UCP managers. These nodes
    should only run on the UCP system and DTR containers. This will avoid any application
    performance issues due to UCP's control plane. On the other hand, if any application
    component consumes too many resources, this will not affect the control plane.
  prefs: []
  type: TYPE_NORMAL
- en: Allowing only signed images in production is key. This will ensure image provenance
    and a CI/CD workflow. It is also possible to require some specific signs for images.
    For example, we can ensure that only images signed by `Operations Team`, `Developer's
    Chief`, and `IT manager` will run in production. This will apply to all the nodes
    in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Many of UCP's and Kubernetes' features can be queried or modified via UCP's
    REST API. We should review the documentation at `https://<UCP_FQDN>[:443]/apidocs/`
    and `https://<UCP_FQDN>[:443]/kubernetesdocs/`.
  prefs: []
  type: TYPE_NORMAL
- en: 'UCP also provides some Pod security policies that are applied by default on
    a Kubernetes cluster. These Pod security policies will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Manage privileged containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure the host's namespaces (IPC, PID, network, and ports)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manage the host's paths and their permissions and volume types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manage users and groups for the container process execution and `setuid` capabilities
    inside the container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the default container's capabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrate Linux security modules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allow host kernel configurations using `sysctl`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By default, only administrators will be able to deploy privileged containers
    in UCP''s Kubernetes. This is configured on a privileged Pod security policy.
    By default, UCP just provides two special policies, as we can see in the `kubectl
    get PodSecurityPolicies` output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You can read more about the Pod security policies included with Docker Enterprise
    and how to create new ones in the Kubernetes documentation or by going to this
    blog post: [https://www.mirantis.com/blog/understanding-kubernetes-security-on-docker-enterprise-3-0/](https://www.mirantis.com/blog/understanding-kubernetes-security-on-docker-enterprise-3-0/).'
  prefs: []
  type: TYPE_NORMAL
- en: Admission controllers are other valuable pieces in Kubernetes' security. They
    intercept Kubernetes API requests to allow or modify them before scheduling or
    executing any action. This allows us to enforce default security on resources,
    even if users try to execute an action that isn't allowed. Admission controllers
    are applied to the Kubernetes API process. Therefore, we should inspect the `ucp-kube-apiserver`
    container's command-line options to verify which admission controllers have been
    applied to our environment. As Kubernetes is not part of the DCA exam yet, we
    will stop here regarding this topic. But it is important to understand that Docker
    Enterprise applies security in Kubernetes using well-known Kubernetes mechanisms.
    UCP applies three special admission controllers to prevent anyone from removing
    core Kubernetes roles required by UCP, to ensure image signing if required, and
    to manage the execution of non-system Kubernetes Pods only on non-mixed nodes.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will review how to create and restore UCP's backups.
  prefs: []
  type: TYPE_NORMAL
- en: Backup strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will learn how to backup and restore the Docker Enterprise
    UCP platform.
  prefs: []
  type: TYPE_NORMAL
- en: As UCP runs on top of Docker Swarm, this is the first component to review when
    preparing a good backup strategy.
  prefs: []
  type: TYPE_NORMAL
- en: We should run periodic backups of Docker Swarm. These backups will allow us
    to recover cluster configuration and workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm's backup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We introduced how to execute a Docker Swarm backup in [Chapter 8](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml),
    *Orchestration Using Docker Swarm*. In that chapter, we described the content
    we should take care of. Let's learn about the steps to follow to implement a production-ready
    backup of Docker Swarm for the Docker Enterprise platform.
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you have applied the auto-lock feature to improve secure access to
    Docker Swarm data as we will need it. The lock key will not be stored with a backup.
    You should store it in a safe place.
  prefs: []
  type: TYPE_NORMAL
- en: We will execute the backup steps on all non-leader manager nodes. This will
    ensure that any of the managers except the leader (at that moment) can be restored.
    In fact, it should not be easy to completely destroy a cluster, so backing up
    just a node should be fine. If all the clusters are completely lost, we will recover
    that node and then add others, as we did during the installation process. Your
    cluster health should not rely on backup-restore features. That is why we run
    the Raft protocol for cluster components syncing and running more than one manager
    node.
  prefs: []
  type: TYPE_NORMAL
- en: Application deployments and their configuration should be stored in code repositories,
    as we have recommended a couple of times in this book. Sometimes, it is even easier
    to deploy a new cluster and launch all the applications again using automation
    tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps are recommended to create a good backup of Docker Swarm
    orchestrator data:'
  prefs: []
  type: TYPE_NORMAL
- en: Verify that the platform is healthy before executing this backup procedure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will stop Docker Engine on the non-leader manager by executing `systemctl
    stop docker`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a `.tar` file with `/var/lib/docker/swarm` directory content: `tar -cvzf
    "<DIRECTORY_FOR_YOUR_BACKUPS>/swarm-backup-$(hostname -s)-$(date +%y%m%d).tgz"
    /var/lib/docker/swarm/`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start Docker Engine again executing `systemctl start docker`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can execute this procedure on other non-leader manager nodes, although we
    will be able to restore Docker Swarm with one node only if the backup was successful.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: UCP runs on top of Docker Swarm. Let's review the required steps for backing
    up UCP.
  prefs: []
  type: TYPE_NORMAL
- en: Backing up UCP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Unlike in Docker Swarm, in UCP, there is no need to pause or stop any platform
    components to execute a backup. This feature is quite new. In older releases,
    components had to be paused on nodes while performing a backup. We will just execute
    this backup on a single node because UCP data will allow us to recover the entire
    cluster. But there are a few important notes about this backup:'
  prefs: []
  type: TYPE_NORMAL
- en: This backup does not include Docker Swarm deployed workloads, networks, configurations,
    or secrets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We cannot recover an updated UCP using a backup from an older release.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neither `ucp-metrics-data` nor `ucp-node-certs` volumes are included.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes data will be covered in a UCP backup.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neither Router Mesh's nor Interlock settings will be stored. Once the restored
    components have been redeployed, configurations will also be recovered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backup content will be stored in a `.tar` file in a user-defined location. It
    can be secured using a passphrase.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can create UCP backups using the web UI, command line, or its API (on the
    latest releases).
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the command line, we will need to use the `ucp` release container. For
    the current version at the time of writing this book, we will use the `docker/ucp:3.2.4`
    image. To create a backup from the command line, we will execute `docker container
    run docker/ucp:<RELEASE> backup`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we are not including UCP platform logs (they will be included
    by default). If SELinux is enabled, which is recommended, we will also add `--security-opt
    label=disable`.
  prefs: []
  type: TYPE_NORMAL
- en: Using the web UI, we will first navigate to Admin Settings. Then, we'll select
    Backup Admin, and finally, we'll click on Backup Now to immediately launch the
    backup execution.
  prefs: []
  type: TYPE_NORMAL
- en: We will not cover the API method in this book and how to verify backup content
    when the process has finished, but it is described on the Docker documentation
    website. It is also recommended to review the latest backup information provided
    at [https://docs.docker.com/ee/admin/backup/back-up-ucp/](https://docs.docker.com/ee/admin/backup/back-up-ucp/).
  prefs: []
  type: TYPE_NORMAL
- en: 'To restore a UCP backup, we can start from one of these situations:'
  prefs: []
  type: TYPE_NORMAL
- en: We can start from scratch, restoring a UCP backup on a new, recently installed
    Docker Enterprise Engine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can also recover a UCP backup on an initiated Docker Swarm, restoring UCP
    so that it has a new, fully functional cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can restore UCP on the Docker Swarm cluster where it was created. We will
    just choose one of its manager nodes and run the recovery process after the previous
    UCP deployment is completely uninstalled. This is the only case where the previously
    created user's bundle will continue to work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If recovery is started from scratch or using a new Docker Swarm cluster, the
    IP addresses and SAN that were used will not be valid. Therefore, we will need
    to regenerate server certificates after the UCP restore.
  prefs: []
  type: TYPE_NORMAL
- en: After you have successfully restored UCP, you can add new managers and workers
    the same way you would after a fresh installation.
  prefs: []
  type: TYPE_NORMAL
- en: 'To restore a previously created backup, we will execute `docker container run
    docker/ucp:<RELEASE> restore`. We need to use the same image release that was
    used to create the backup. This is very important because we cannot restore from
    a different release:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: It is important to know that backup and restore are processes that you should
    execute when everything else is not working. We deploy UCP environments with high
    availability to avoid unexpected situations. You have to actively monitor your
    cluster environments and not leave unattended errors or alarms on monitoring systems.
    In the event of a manager node failure, a cluster will continue working, but we
    must reestablish a healthy status as soon as possible. From my experience, most
    of the issues found in production Docker Enterprise environments are related to
    filesystems growing without control, processes eating all the resources, or communication
    problems. Take care of these possible issues, monitor cluster health, and do periodic
    backups (and update their processes) to ensure you are able to recover your environment
    if everything fails.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn what to monitor and how to check different
    components' statuses to avoid unnoticed failures.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrades, monitoring, and troubleshooting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will review how cluster upgrades must be deployed. We will
    work in a cluster environment. There are some steps to follow in order to execute
    platform updates without service interruption. Monitoring and troubleshooting
    are critical in production. We will learn about what important keys and values
    we should review to ensure a cluster's health and what steps we should follow
    to troubleshoot a degraded or faulty environment.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading your environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We must review the Docker UCP release notes and upgrade procedure for each
    version. At the time of writing this book, the current release documentation is
    available on Docker''s website: [https://docs.docker.com/reference/ucp/3.2/cli/upgrade](https://docs.docker.com/reference/ucp/3.2/cli/upgrade).'
  prefs: []
  type: TYPE_NORMAL
- en: We should always perform a backup before any procedure, and we usually start
    by upgrading Docker Engine. You should review the Docker documentation to ensure
    that these steps are not changed between releases. Node upgrades should be done
    one at time. We will begin with non-leader manager nodes. Once all the managers
    have been upgraded, we will move the running services between different worker
    nodes to ensure minimal service interruption between upgrades.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once all the Docker Engine instances have been updated, we will start with
    the UCP upgrade. We can execute this process from the web UI and from the command
    line. We recommend following the command-line steps because the process will give
    you more information. We can execute this process offline if all the required
    images have been previously downloaded on all the nodes. We can check the required
    images at this link: [https://docs.docker.com/ee/ucp/admin/install/upgrade-offline/](https://docs.docker.com/ee/ucp/admin/install/upgrade-offline/).
    We will pre-load all the images using `docker image load -i <PACKAGE_WITH_ALL_IMAGES>.tar.gz`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will run `docker container run docker/ucp upgrade` with the appropriate
    arguments to upgrade our UCP environment. Docker Engine should be upgraded before
    executing this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: If your nodes work with more than one interface, we will also add `--host-address`
    with an appropriate IP address.
  prefs: []
  type: TYPE_NORMAL
- en: We can run and upgrade the process with the debug option, `--debug`, which is
    very useful for identifying errors if something goes wrong.
  prefs: []
  type: TYPE_NORMAL
- en: There is an interesting option on the current release because we can upgrade
    workers manually using `--manual-worker-upgrade`. This helps us control the impact
    we have on services that are deployed in the environment.
  prefs: []
  type: TYPE_NORMAL
- en: All UCP processes will be upgraded in all nodes unless the `--manual-worker-upgrade`
    option is used. Once the upgrade process ends, the environment will be completely
    upgraded to the new release. At that moment, it is important to verify the health
    of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring a cluster's health
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can use either the command line or the web UI to review the environment's
    health. We will use common Docker Swarm commands because we are running the environment
    on top of this orchestrator. We can review the node status with `docker node ls`.
    If we use the Docker UCP bundle to connect to the environment, we might miss some
    components. Make sure you are using an administrator user in the environment to
    be able to retrieve its health. Using the bundle, we can list all the control
    plane processes and use `docker container ls` to verify their statuses.
  prefs: []
  type: TYPE_NORMAL
- en: We can retrieve a manager's status from the `https://<ucp-manager-url>/_ping`
    endpoint, on each manager node's IP address or FQDN name. Requests to this URL
    can give us a `200` code if a node is healthy and a `500` code if there are some
    faulty components.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand that this endpoint must be verified on each node
    because we are accessing the cluster through a load balancer to each manager.
    This configuration helps us provide high availability to the environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The web UI also provides cluster status information. The Dashboard page shows
    us a clear status overview of the environment. This page includes counters for
    errors, warnings, or pending states for managers and workers. We will quickly
    notice errors on platform nodes. A performance summary for managers and worker
    nodes allows us to verify cluster sizing and its usage. We will also see information
    about deployed services on Docker Swarm and Kubernetes. This way, we can drill
    down to different UCP sections to deep dive into encountered errors. The following
    screenshot shows how the UCP Dashboard looks when showing the described platform
    overview:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ef9dd82-827f-469c-a2ec-279470806946.png)'
  prefs: []
  type: TYPE_IMG
- en: In each UCP resource section, we will see the resources' statuses, along with
    their properties. To monitor the cluster node's health, we will review the Nodes
    section, which can be found under Shared Resources. In this section, we will review
    the CPU and memory usage per node. This view will also help us find possible service
    degradation when node resource usage is too high.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting UCP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout this chapter, we have been reviewing the main monitoring endpoints
    for UCP components. There are some critical endpoints in the cluster. We also
    described some database processes that manage important clusters' persistent data.
    These components run on managers and they replicate their data between them. It
    should be enough for the UCP environment, but sometimes, things can go wrong and
    they lose node synchronization. Network latency and performance problems can lead
    to these situations.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting UCP-KV
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If we lose some manager nodes, `ucp-kv` can show the incorrect number of nodes.
    We can check the number of configured nodes with `etcdctl`. We can execute `etcdctl`
    on the `ucp-kv` container directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This will show us `cluster is healthy` messages if the configured number of
    managers are healthy. If `ucp-kv` is unhealthy, we should review whether all the
    manager nodes are fine. If we deleted one manager but this change was not correctly
    updated on the other nodes, we could end up with an unhealthy cluster. To recover
    from this situation, we would need to remove the deleted node from the `etcd`
    database using `etcdctl member remove` (check the `etcd` documentation at [https://etcd.io/docs/v3.4.0/op-guide/runtime-configuration/](https://etcd.io/docs/v3.4.0/op-guide/runtime-configuration/)).
  prefs: []
  type: TYPE_NORMAL
- en: Update the component configurations and their states (deleting nodes, for example)
    one by one. Wait until the changes are synced in the cluster before executing
    a new update command.
  prefs: []
  type: TYPE_NORMAL
- en: We can also have problems with the authentication database. In the next section,
    we will learn how to correct the number of nodes if we lose one manager node.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting UCP-Auth
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, we will review the current number of healthy manager nodes. If some
    of them are still unhealthy, we should correct that situation first. Once the
    managers are healthy, if the authentication database continues to be in an inconsistent
    state, we will follow this procedure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This command will run a `docker/ucp-auth` container using the RethinkDB `reconfigure-db`
    command to fix the right number of managers.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting nodes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we mentioned previously, network latency and performance can lead you to
    problematic situations. Take care of node resources and filesystems. If manager
    nodes become exhausted, the cluster will end up in an unhealthy state.
  prefs: []
  type: TYPE_NORMAL
- en: We can observe heartbeat failures if nodes cannot be contacted in 10 seconds.
    Worker nodes will reach a pending state if they cannot contact a manager node.
    We check these nodes locally. We also take a look at possible network or performance
    issues.
  prefs: []
  type: TYPE_NORMAL
- en: Managers can also become unhealthy. If other managers cannot reach them, `ucp-controller`
    processes will be impacted. We can check container logs for network issues.
  prefs: []
  type: TYPE_NORMAL
- en: These are some of the most common issues found on the Docker UCP platform. We
    usually start by reviewing the web UI dashboard and the `ucp-controller` container
    logs. If any other component seems unhealthy, we review its logs.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to publish applications deployed within
    the Docker Enterprise platform using the Interlock feature.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covered the main Docker UCP features. We learned how to deploy
    a cluster with high availability and how to manage and deploy workloads using
    either UCP's web UI or the user bundle with the Docker and Kubernetes command
    line. We also introduced UCP's role-based access control, which helps us provide
    fine-grained access to cluster resources. We also took a look at the web UI and
    the main configurations available for managing Docker Enterprise's control plane.
  prefs: []
  type: TYPE_NORMAL
- en: We also learned about UCP's components and how to deploy and manage Docker Enterprise's
    control plane and user resources in production. Finally, we learned how to ensure
    platform availability by verifying a cluster's components' status and executing
    backups.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to publish a deployed application using
    Docker's integrated tools and features.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Which of these sentences are true?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) The Docker UCP installation process will also install the Docker Enterprise
    Engine on our hosts.
  prefs: []
  type: TYPE_NORMAL
- en: b) UCP provides an integrated RBAC system that will help us to authenticate
    and authorize our users against its database.
  prefs: []
  type: TYPE_NORMAL
- en: 'c) Docker UCP provides two kinds of access: the web UI and the UCP bundle.'
  prefs: []
  type: TYPE_NORMAL
- en: d) All of the above sentences are true.
  prefs: []
  type: TYPE_NORMAL
- en: Which of these sentences is not true about a `docker`/`ucp` image?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) This image will provide UCP's backup and restore.
  prefs: []
  type: TYPE_NORMAL
- en: b) We should always use the latest `docker`/`ucp` release version in our environment.
  prefs: []
  type: TYPE_NORMAL
- en: c) Docker UCP can be completely removed using a `docker`/`ucp` image.
  prefs: []
  type: TYPE_NORMAL
- en: d) The upgrade process must be executed manually on each cluster's node.
  prefs: []
  type: TYPE_NORMAL
- en: What have we learned about the UCP installation process (which of the following
    is true)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) We can change the UCP controller and Kubernetes ports using special arguments.
  prefs: []
  type: TYPE_NORMAL
- en: b) We can isolate the control plane using `--data-path-addr` to specify an interface
    or an IP address for the data plane.
  prefs: []
  type: TYPE_NORMAL
- en: c) We can only have one subject alias name for the UCP environment and, by default,
    this will be the manager's IP address.
  prefs: []
  type: TYPE_NORMAL
- en: d) We will install UCP on the manager using the `docker/ucp install` procedure
    and then we will join worker nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Which of the following is true about high availability in UCP?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) UCP is deployed on top of a Docker Swarm cluster, so we will need an odd
    number of nodes to provide high availability.
  prefs: []
  type: TYPE_NORMAL
- en: b) We will need to deploy Kubernetes with high availability once UCP is installed.
  prefs: []
  type: TYPE_NORMAL
- en: c) An external load balancer is required to distribute client requests between
    different nodes using a transparent-proxy (passthrough) to allow managers to provide
    end-to-end TLS tunnels.
  prefs: []
  type: TYPE_NORMAL
- en: d) We can check a manager's availability using the `https://<ucp-manager-url>/_ping`
    endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Which one of these roles is not included in UCP by default?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `Privileged`
  prefs: []
  type: TYPE_NORMAL
- en: b) `Full Control`
  prefs: []
  type: TYPE_NORMAL
- en: c) `Administrator`
  prefs: []
  type: TYPE_NORMAL
- en: d) `Scheduler`
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Refer to the following links for more information regarding the topics that
    were covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Universal Control Plane overview: [https://docs.docker.com/ee/ucp/](https://docs.docker.com/ee/ucp/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Docker Enterprise architecture: [https://docs.docker.com/ee/docker-ee-architecture/](https://docs.docker.com/ee/docker-ee-architecture/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Docker Enterprise products: [https://docs.docker.com/ee/supported-platforms/](https://docs.docker.com/ee/supported-platforms/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'UCP''s access control mode: [https://docs.docker.com/ee/ucp/authorization/](https://docs.docker.com/ee/ucp/authorization/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deploying applications on UCP''s Kubernetes: [https://docs.docker.com/ee/ucp/kubernetes/](https://docs.docker.com/ee/ucp/kubernetes/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'UCP access using the command line: [https://docs.docker.com/ee/ucp/user-access/cli/](https://docs.docker.com/ee/ucp/user-access/cli/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Troubleshooting UCP node states: [https://docs.docker.com/ee/ucp/admin/monitor-and-troubleshoot/troubleshoot-node-messages/](https://docs.docker.com/ee/ucp/admin/monitor-and-troubleshoot/troubleshoot-node-messages/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Docker UCP''s API: [https://docs.docker.com/reference/ucp/3.2/api/](https://docs.docker.com/reference/ucp/3.2/api/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Docker Enterprise best practices and design considerations: [https://success.docker.com/article/docker-enterprise-best-practices](https://success.docker.com/article/docker-enterprise-best-practices)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Designing a disaster recovery strategy: [https://success.docker.com/article/dr-failover-strategy](https://success.docker.com/article/dr-failover-strategy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
