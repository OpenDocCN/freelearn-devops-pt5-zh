- en: Universal Control Plane
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: Universal Control Plane
- en: In this chapter, we will learn everything about Docker's **Universal Control
    Plane** (**UCP**) that's required for the Docker Certified Associate exam. Universal
    Control Plane is the Docker Enterprise component in charge of managing clusters.
    First, we will introduce UCP's components and their features. It is important
    to know that UCP has changed a lot in recent years. The Docker Enterprise platform
    was previously known as Docker Datacenter. Docker changed its name when version
    2.0 was released. That version was also important because it was the first one
    to include Kubernetes as a second orchestrator. In this chapter, we will learn
    how Kubernetes is integrated and how to deploy a production-ready platform.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习所有与 Docker 的 **Universal Control Plane** (**UCP**) 相关的内容，这些内容是 Docker
    认证助理考试所需的。Universal Control Plane 是 Docker 企业版中负责管理集群的组件。首先，我们将介绍 UCP 的组件及其功能。值得注意的是，UCP
    在近年来发生了很多变化。Docker 企业平台之前被称为 Docker Datacenter。在 2.0 版本发布时，Docker 更改了名称。这个版本也很重要，因为它是第一个将
    Kubernetes 作为第二个编排工具引入的版本。在本章中，我们将学习 Kubernetes 如何集成，以及如何部署一个生产就绪的平台。
- en: In November 2019, Mirantis Inc. acquired the Docker Enterprise platform business,
    including its products, customers, and employees. Therefore, Docker Enterprise
    is currently a Mirantis Inc. product.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 2019年11月，Mirantis 公司收购了 Docker 企业平台业务，包括其产品、客户和员工。因此，Docker 企业版目前是 Mirantis
    公司的产品。
- en: We will discover UCP's main components and learn how to deploy a production-ready
    environment with high availability. Enterprise environments have many security
    requirements and UCP includes its own authentication and authorization systems
    based on RBAC, all of which can be easily integrated with an enterprise's user
    management platform. Docker Enterprise is based on Docker Swarm but also includes
    an enterprise-ready Kubernetes environment within the cluster. We will learn about
    UCP's administration tasks, security configurations, special features, and how
    to provide a disaster recovery strategy based on backup and restore features.
    We will finish this chapter by reviewing what should be monitored on this platform
    to ensure its health.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探索 UCP 的主要组件，并学习如何部署一个高可用的生产环境。企业环境有许多安全需求，UCP 包括基于 RBAC 的身份验证和授权系统，所有这些都可以轻松与企业的用户管理平台集成。Docker
    企业版基于 Docker Swarm，但还包括集群中的企业级 Kubernetes 环境。我们将学习 UCP 的管理任务、安全配置、特殊功能，以及如何基于备份和恢复功能提供灾难恢复策略。本章将通过回顾在该平台上应监控的内容来确保其健康状态。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding UCP components and features
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 UCP 组件和功能
- en: Deploying UCP with high availability
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署具有高可用性的 UCP
- en: Reviewing Docker UCP's environment
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回顾 Docker UCP 的环境
- en: Role-based access control and isolation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于角色的访问控制与隔离
- en: UCP's Kubernetes integration
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UCP 的 Kubernetes 集成
- en: UCP administration and security
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UCP 管理和安全
- en: Backup strategies
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备份策略
- en: Upgrades, health checks, and troubleshooting
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 升级、健康检查和故障排除
- en: Let's get started!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You can find the code for this chapter in the GitHub repository: [https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git](https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 GitHub 仓库中找到本章的代码：[https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git](https://github.com/PacktPublishing/Docker-Certified-Associate-DCA-Exam-Guide.git)
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，观看代码实践：
- en: '"[https://bit.ly/34BHHdj](https://bit.ly/34BHHdj)"'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '"[https://bit.ly/34BHHdj](https://bit.ly/34BHHdj)"'
- en: Understanding UCP components and features
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 UCP 组件和功能
- en: 'Docker''s UCP provides the control plane for the Docker Enterprise platform.
    It is based on Docker Swarm but also integrates the Kubernetes orchestrator. The
    following is a quick list of its current features:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 的 UCP 提供了 Docker 企业平台的控制平面。它基于 Docker Swarm，但还集成了 Kubernetes 编排器。以下是其当前功能的快速列表：
- en: A centralized cluster management interface
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集中式集群管理界面
- en: A cluster resource environment
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群资源环境
- en: Role-based access control
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于角色的访问控制
- en: A client environment via WebGUI or the CLI
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 WebGUI 或 CLI 的客户端环境
- en: As we mentioned previously, UCP is based on Docker Swarm orchestration. We will
    deploy a Docker Swarm cluster with managers and worker roles.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，UCP 基于 Docker Swarm 编排。我们将部署一个包含管理节点和工作节点角色的 Docker Swarm 集群。
- en: First, we will install a manager node. This will be the leader during the installation
    process. All the components will be deployed as containers, so we only require
    a Docker Enterprise Engine to run them.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将安装一个管理节点。在安装过程中，这将是领导节点。所有组件将作为容器部署，因此我们只需要一个Docker企业版引擎来运行它们。
- en: Once the first manager has been installed, and with all the UCP components up
    and running, we will continue adding nodes to the cluster. This is a really simple
    process.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了第一个管理节点，并且所有UCP组件都启动并运行，我们将继续向集群中添加节点。这个过程非常简单。
- en: All the components will be managed by a master agent process called `ucp-agent`.
    This process will deploy all the other components according to the role of the
    installed node.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 所有组件将由一个名为`ucp-agent`的主代理进程进行管理。该进程将根据已安装节点的角色部署其他所有组件。
- en: Let's review the different components that are deployed on manager and worker
    role nodes.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下部署在管理节点和工作节点角色上的不同组件。
- en: UCP components on manager nodes
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理节点上的UCP组件
- en: In [Chapter 8](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml), *Orchestration Using
    Docker Swarm*, we learned how these clusters work. Manager nodes run all management
    processes. We will deploy an odd number of manager nodes to provide high availability
    because Docker Swarm is based on the Raft protocol and requires consensus or quorum
    in the management plane.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第8章](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml)《使用Docker Swarm进行编排》中，我们学习了这些集群是如何工作的。管理节点运行所有管理进程。我们将部署奇数个管理节点，以提供高可用性，因为Docker
    Swarm基于Raft协议，需要在管理平面中达成共识或法定人数。
- en: 'Manager nodes run all UCP core services, including the web UI and data stores
    that persist the state of UCP. These are the UCP services running on manager nodes:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 管理节点运行所有UCP核心服务，包括Web UI和持久化UCP状态的数据存储。这些是运行在管理节点上的UCP服务：
- en: '| **Component** | **Description** |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| **组件** | **描述** |'
- en: '| `ucp-agent` | This component is the agent running on each node to monitor
    and ensure the required services are running. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-agent` | 该组件是运行在每个节点上的代理，用于监控并确保所需的服务正在运行。 |'
- en: '| `ucp-swarm-manager` | To provide compatibility with a Docker Swarm environment,
    this component runs on manager nodes. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-swarm-manager` | 为了与Docker Swarm环境兼容，该组件运行在管理节点上。 |'
- en: '| `ucp-proxy` | This component provides secure access to each Docker Engine
    on the platform using TLS and forwarding requests to a local socket. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-proxy` | 该组件使用TLS提供对平台上每个Docker引擎的安全访问，并将请求转发到本地套接字。 |'
- en: '| `ucp-auth-api` | Authentication is managed with this component running on
    manager nodes, exposing its API to authorize access. |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-auth-api` | 该组件运行在管理节点上，提供身份验证API，用于授权访问。 |'
- en: '| `ucp-auth-store` | This component stores data and the configurations of users,
    organizations, and teams on the UCP platform. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-auth-store` | 该组件存储UCP平台上用户、组织和团队的数据及配置。 |'
- en: '| `ucp-auth-worker` | An authentication worker periodically runs synchronization
    tasks with external authentication backends. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-auth-worker` | 一个身份验证工作进程定期与外部身份验证后台进行同步任务。 |'
- en: '| `ucp-client-root-ca` | This component provides a certificate authority to
    sign users'' bundles on the platform. Bundles are packages issued by the management
    platform to provide users with access. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-client-root-ca` | 该组件提供一个证书颁发机构，用于签署平台上用户的包。包是由管理平台颁发的，旨在为用户提供访问权限。
    |'
- en: '| `ucp-cluster-root-ca` | To ensure secure communication between platform components,
    this component provides a CA for signing TLS certificates. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-cluster-root-ca` | 为了确保平台组件之间的安全通信，该组件提供一个证书颁发机构（CA）用于签署TLS证书。 |'
- en: '| `ucp-kv` | This component provides a key-value database to store cluster
    configurations. It was only used for Legacy Swarm (we have not seen how Docker
    Swarm was deployed in the past, but it is similar to Kubernetes these days) but
    currently, it is also used as a Kubernetes key value. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-kv` | 该组件提供一个键值数据库，用于存储集群配置。它曾仅用于传统Swarm（我们尚未看到Docker Swarm过去是如何部署的，但它今天与Kubernetes类似），但目前它也被用作Kubernetes的键值存储。
    |'
- en: '| `ucp-controller` | The UCP web UI is key for management. `ucp-controller`
    provides this feature. It is the first point of failure when users cannot access
    the cluster. |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-controller` | UCP Web UI是管理的关键。`ucp-controller`提供此功能。当用户无法访问集群时，它是第一个发生故障的组件。
    |'
- en: '| `ucp-reconcile` | To monitor components'' health, UCP runs `ucp-agent`, and
    if some of them fail, it will try to restart them. This component will just run
    when something goes wrong. |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-reconcile` | 为了监控组件的健康状况，UCP 运行 `ucp-agent`，如果某些组件出现故障，它会尝试重新启动它们。此组件仅在出现问题时运行。
    |'
- en: '| `ucp-dsinfo` | UCP can run troubleshooting reports. It executes this component
    to retrieve all available information. We use support dumps to send information
    to support services. |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-dsinfo` | UCP 可以运行故障排除报告。它执行此组件以检索所有可用的信息。我们使用支持转储将信息发送到支持服务。 |'
- en: '| `ucp-metrics` | This component recovers node metrics. This data can be used
    in other monitoring environments. |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-metrics` | 该组件用于恢复节点指标。这些数据可以在其他监控环境中使用。 |'
- en: '| `ucp-interlock`/`ucp-interlock-proxy` | Interlock components allow advanced
    users to publish applications deployed in the cluster. `ucp-interlock` queries
    the UCP API for changes to be configured to publish services in the `ucp-interlock-proxy`
    component, as well as a reverse proxy to be deployed and configured automatically
    for you by UCP. |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-interlock`/`ucp-interlock-proxy` | Interlock 组件允许高级用户发布在集群中部署的应用程序。`ucp-interlock`
    查询 UCP API 以获取要配置以发布服务的更改，并在 `ucp-interlock-proxy` 组件中配置反向代理，UCP 会为您自动部署和配置该反向代理。
    |'
- en: 'The following processes also run on master nodes but are separated into a different
    table because they are related to Kubernetes:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以下进程也会在主节点上运行，但由于它们与 Kubernetes 相关，因此被单独列在不同的表格中：
- en: '| **Process** | **Description** |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| **进程** | **描述** |'
- en: '| `ucp-kube-apiserver` | This is the Kubernetes master API component. All Kubernetes
    processes will be deployed as containers in our host. Using containers to deploy
    applications helps us to maintain applications'' components and their upgrades.
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-kube-apiserver` | 这是 Kubernetes 主 API 组件。所有 Kubernetes 进程都将作为容器部署在我们的主机中。使用容器来部署应用程序有助于我们维护应用程序的组件及其升级。
    |'
- en: '| `ucp-kube-controller-manager` | This Kubernetes process will manage all controllers
    required to control, replicate, and monitor Pods. |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-kube-controller-manager` | 这个 Kubernetes 进程将管理所有控制器，用于控制、复制和监控 Pods。
    |'
- en: '| `ucp-kube-scheduler` | `kube-scheduler` schedules workloads within cluster
    nodes. |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-kube-scheduler` | `kube-scheduler` 在集群节点中调度工作负载。 |'
- en: '| `ucp-kubelet` | `kubelet` is the Kubernetes agent. It is the endpoint used
    by Kubernetes to manage nodes and their interactions. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-kubelet` | `kubelet` 是 Kubernetes 代理。它是 Kubernetes 用来管理节点及其交互的端点。 |'
- en: '| `ucp-kube-proxy` | `kube-proxy` manages a Pod''s publishing and communications.
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-kube-proxy` | `kube-proxy` 管理 Pod 的发布和通信。 |'
- en: '| `k8s_ucp-kube-dns`/`k8s_ucp-kubedns-sidecar`/`k8s_ucp-dnsmasq-nanny` | These
    containers manage and monitor DNS procedures and the resolution required for UCP
    and Kubernetes. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| `k8s_ucp-kube-dns`/`k8s_ucp-kubedns-sidecar`/`k8s_ucp-dnsmasq-nanny` | 这些容器管理和监控
    DNS 过程及 UCP 和 Kubernetes 所需的解析。 |'
- en: '| `k8s_calico-node`/`k8s_install-cni_calico-node`/`k8s_calico-kube-controllers`
    | Calico is the default **container network interface** (**CNI**) for Kubernetes
    and it is automatically deployed during UCP installation. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| `k8s_calico-node`/`k8s_install-cni_calico-node`/`k8s_calico-kube-controllers`
    | Calico 是 Kubernetes 的默认**容器网络接口**（**CNI**），并且在 UCP 安装过程中会自动部署。 |'
- en: 'There is also an important component on newer releases to help with the interaction
    between Docker Swarm and Kubernetes interactions:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在较新的版本中，还有一个重要组件用于帮助 Docker Swarm 和 Kubernetes 之间的交互：
- en: '| **Process** | **Description** |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| **进程** | **描述** |'
- en: '| `k8s_ucp-kube-compose` | `kube-compose` allows us to deploy Docker Compose''s
    workloads either on Docker Swarm as stacks or Kubernetes. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| `k8s_ucp-kube-compose` | `kube-compose` 允许我们将 Docker Compose 的工作负载部署到 Docker
    Swarm 上作为堆栈或 Kubernetes 中。 |'
- en: These are the components that can be deployed on manager nodes. We will usually
    deploy at least three manager nodes because either Docker Swarm or Kubernetes
    requires an odd number of nodes for a distributed consensus.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是可以部署在管理节点上的组件。我们通常会部署至少三个管理节点，因为无论是 Docker Swarm 还是 Kubernetes 都需要奇数个节点来进行分布式一致性。
- en: Now, let's review worker components.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回顾一下工作节点的组件。
- en: UCP components on worker nodes
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作节点上的 UCP 组件
- en: 'The following are the components that are deployed on worker nodes once they
    are joined to the cluster:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是工作节点加入集群后部署的组件：
- en: '| **Components** | **Description** |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| **组件** | **描述** |'
- en: '| `ucp-agent`, `ucp-proxy`, `ucp-dsinfo`, and `ucp-reconcile` | These processes
    have the same functionality that was described for manager nodes. |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-agent`、`ucp-proxy`、`ucp-dsinfo` 和 `ucp-reconcile` | 这些进程具有与管理节点相同的功能。
    |'
- en: '| `ucp-interlock-extension` | `interlock-extension` prepares configurations
    for `interlock-proxy` based on changes retrieved from Docker Swarm service configurations.
    This process is based on templates reconfigured dynamically to accomplish all
    updates that happen within cluster-wide published workloads. |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-interlock-extension` | `interlock-extension` 根据从 Docker Swarm 服务配置中获取的更改，为
    `interlock-proxy` 准备配置。这一过程基于动态重新配置的模板，以完成集群范围内发布工作负载中发生的所有更新。 |'
- en: '| `ucp-interlock-proxy` | `interlock-proxy` runs a proxy process configured
    dynamically thanks to all other Interlock processes. These prepare a configuration
    file for the proxy component with all the running backends required for each published
    service. |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-interlock-proxy` | `interlock-proxy` 运行一个代理进程，这一进程是通过所有其他 Interlock
    进程动态配置的。它为代理组件准备一个配置文件，包含每个发布服务所需的所有运行后端。 |'
- en: 'For Kubernetes to work, worker nodes also execute the following processes:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 Kubernetes 正常工作，工作节点还会执行以下进程：
- en: '| **Processes** | **Description** |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| **进程** | **描述** |'
- en: '| `ucp-kubelet` and `ucp-kube-proxy` | Only these two processes are required
    for Kubernetes on worker nodes. |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| `ucp-kubelet` 和 `ucp-kube-proxy` | 这两个过程仅在工作节点上需要用于 Kubernetes。 |'
- en: '| `k8s_calico-node` and `k8s_install-cni_calico-node` | Networking within cluster
    nodes requires Calico, so its processes are also deployed on worker nodes. |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| `k8s_calico-node` 和 `k8s_install-cni_calico-node` | 集群节点之间的网络需要 Calico，因此它的进程也会在工作节点上部署。
    |'
- en: From these lists, it is easy to understand how Kubernetes is deployed on Docker
    Enterprise. Manager nodes run Kubernetes' control plane while workers receive
    workloads. Notice that managers run `kube-proxy` and `kubelet`, so they are also
    able to receive workloads. This is also true for Docker Swarm, as we learned in
    [Chapter 8](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml), *Orchestration Using
    Docker Swarm*. Docker Enterprise allows managers to execute application workloads
    by default.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些列表中，我们可以轻松理解 Kubernetes 如何在 Docker 企业版上部署。管理节点运行 Kubernetes 的控制平面，而工作节点接收工作负载。请注意，管理节点运行
    `kube-proxy` 和 `kubelet`，因此它们也能够接收工作负载。这对于 Docker Swarm 也同样适用，正如我们在[第 8 章](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml)《使用
    Docker Swarm 进行编排》中所学到的，*使用 Docker Swarm 进行编排*。Docker 企业版默认允许管理节点执行应用程序工作负载。
- en: 'We will also review the volumes that are deployed on UCP. We will divide them
    into two categories:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将回顾在 UCP 上部署的卷，并将其分为两类：
- en: '**Volumes for certificates**: All these volumes are associated with certificate
    management within the cluster. Take care of them because if we lose them, we will
    have serious authentication problems between UCP/Kubernetes processes:'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**证书卷**：所有这些卷与集群中的证书管理相关。请小心处理它们，因为如果我们丢失它们，将会导致 UCP/Kubernetes 进程之间出现严重的身份验证问题：'
- en: '`ucp-auth-api-certs`'
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-auth-api-certs`'
- en: '`ucp-auth-store-certs`'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-auth-store-certs`'
- en: '`ucp-auth-worker-certs`'
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-auth-worker-certs`'
- en: '`ucp-client-root-ca`'
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-client-root-ca`'
- en: '`ucp-cluster-root-ca`'
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-cluster-root-ca`'
- en: '`ucp-controller-client-certs`'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-controller-client-certs`'
- en: '`ucp-controller-server-certs`'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-controller-server-certs`'
- en: '`ucp-kv-certs`'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-kv-certs`'
- en: '`ucp-node-certs`'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-node-certs`'
- en: '**Volumes for data**: These are data volumes and are used to store different
    databases deployed within the cluster, as well as the metrics that have been retrieved
    from different components:'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据卷**：这些是数据卷，用于存储集群内部署的不同数据库以及从不同组件获取的度量数据：'
- en: '`ucp-auth-store-data`'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-auth-store-data`'
- en: '`ucp-auth-worker-data`'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-auth-worker-data`'
- en: '`ucp-kv`'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-kv`'
- en: '`ucp-metrics-data`'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-metrics-data`'
- en: '`ucp-metrics-inventory`'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-metrics-inventory`'
- en: All these volumes are important for the cluster. Key-value pairs, common certificates,
    and authentication data volumes are replicated on control plane nodes. They are
    created using the default local volume driver unless we have already created them
    using a different driver. Keep in mind that they should be created before deploying
    the cluster if we want to store data in a non-standard location (`/var/lib/docker/volumes`
    or the defined `data-root` path in your environment).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些卷对于集群非常重要。键值对、常见证书和身份验证数据卷会在控制平面节点上进行复制。除非我们已经使用不同的驱动程序创建它们，否则它们会使用默认的本地卷驱动程序创建。请记住，如果我们希望将数据存储在非标准位置（`/var/lib/docker/volumes`
    或环境中定义的 `data-root` 路径），它们应该在部署集群之前创建。
- en: This section is very important for the Docker Certified Associate exam because
    we need to know where components are distributed and their functionality on the
    platform.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分对于 Docker 认证助理考试非常重要，因为我们需要了解组件如何分布以及它们在平台上的功能。
- en: Now that we know what components will be deployed on each cluster role, we will
    learn how to install production-ready environments.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道每个集群角色将部署哪些组件，接下来我们将学习如何安装生产就绪的环境。
- en: Deploying UCP with high availability
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署高可用的 UCP
- en: 'First, we will take a look at the hardware and software requirements for the
    platform. We will use version 3.0 – the current version at the time of writing
    this book. It is known that the DCA exam was prepared even before Docker Enterprise
    version 2.0 was released. Neither Docker Desktop nor Kubernetes were part of the
    Docker Enterprise platform on that release. We will deploy the current version
    because the exam has evolved to cover important topics in newer versions. Let''s
    quickly review the current maintenance life cycle:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将查看平台的硬件和软件要求。我们将使用版本 3.0——这是写本书时的当前版本。众所周知，DCA 考试甚至是在 Docker Enterprise
    2.0 版本发布之前就已经准备好了。当时 Docker Desktop 和 Kubernetes 并不属于 Docker Enterprise 平台的一部分。我们将部署当前版本，因为考试已经发展到涵盖新版本中的重要主题。让我们快速回顾一下当前的维护生命周期：
- en: '| **Docker Enterprise 2.1** | **Docker Enterprise 3.0** |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| **Docker Enterprise 2.1** | **Docker Enterprise 3.0** |'
- en: '| End of life on 2020-11-06 | End of life on 2021-07-21 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 2020-11-06 停止支持 | 2021-07-21 停止支持 |'
- en: '| Components:- Enterprise Engine 18.09.z - Universal Control Plane 3.1.z'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '| 组件：- 企业引擎 18.09.z - 通用控制平面 3.1.z'
- en: '- Docker Trusted Registry 2.6.z | Components:- Enterprise Engine 19.03.z- Universal
    Control Plane 3.2.z- Docker Trusted Registry 2.7.z |'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '- Docker 受信任注册表 2.6.z | 组件：- 企业引擎 19.03.z - 通用控制平面 3.2.z - Docker 受信任注册表 2.7.z
    |'
- en: 'Docker provides 2 years of support from the release date. We recommend taking
    a look at Docker''s website for updated information on the maintenance life cycle
    and compatibility matrix:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 提供从发布之日起 2 年的支持。我们建议查看 Docker 网站，获取有关维护生命周期和兼容性矩阵的最新信息：
- en: '[https://success.docker.com/article/maintenance-lifecycle](https://success.docker.com/article/maintenance-lifecycle)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://success.docker.com/article/maintenance-lifecycle](https://success.docker.com/article/maintenance-lifecycle)'
- en: '[https://success.docker.com/article/compatibility-matrix](https://success.docker.com/article/compatibility-matrix)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://success.docker.com/article/compatibility-matrix](https://success.docker.com/article/compatibility-matrix)'
- en: All of the listed versions include Kubernetes, but the deployed version will
    be different. At the time of writing this book, Docker Enterprise deploys Kubernetes
    v1.14.8.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 所有列出的版本都包含 Kubernetes，但部署的版本会有所不同。写本书时，Docker Enterprise 部署的是 Kubernetes v1.14.8。
- en: 'We can deploy the Docker Enterprise platform on-premises or on cloud providers.
    Before deploying the first node, let''s review the minimum node requirements:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在本地或云提供商上部署 Docker Enterprise 平台。在部署第一个节点之前，让我们回顾一下最小节点要求：
- en: 8 GB and 4 GB of RAM for the manager and worker nodes, respectively.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理节点需要 8 GB 的 RAM，工作节点需要 4 GB 的 RAM。
- en: 2 vCPUs for manager nodes. Worker nodes' vCPUs will depend on the applications
    to be deployed.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理节点需要 2 个 vCPU。工作节点的 vCPU 数量将取决于将要部署的应用程序。
- en: 10 GB of free disk space for the `/var` partition for manager nodes (a minimum
    of 6 GB is recommended because Kubernetes will verify disk space before installation)
    and at least 500 MB of free disk space for the `/var` partition for worker nodes.
    Worker node space will depend on the applications to be deployed, how big their
    images are, and how many image releases should be present on our nodes.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理节点的 `/var` 分区需要 10 GB 的可用磁盘空间（推荐至少 6 GB，因为 Kubernetes 会在安装之前检查磁盘空间），工作节点的
    `/var` 分区需要至少 500 MB 的可用磁盘空间。工作节点的空间将取决于将要部署的应用程序，它们的镜像大小，以及需要在节点上存在的镜像发布数量。
- en: 'A more realistic approach to resources for control plane and image management
    would probably be the following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于控制平面和镜像管理，可能更为实际的资源配置如下：
- en: 16 GB of RAM for manager nodes and workers with DTR (we will learn about DTR
    in [Chapter 13](108b5948-15a9-40fb-b8dd-5a44c54efd7d.xhtml), *Implementing an
    Enterprise-Grade Registry with DTR*).
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理节点和带有 DTR 的工作节点需要 16 GB 的 RAM（我们将在[第 13 章](108b5948-15a9-40fb-b8dd-5a44c54efd7d.xhtml)，*实现企业级注册表与
    DTR* 中学习有关 DTR 的内容）。
- en: Four vCPUs for manager nodes and workers with DTR. Control plane CPU and image
    scanning can take forever if there is not enough CPU available.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理节点和带有 DTR 的工作节点需要 4 个 vCPU。如果没有足够的 CPU 可用，控制平面 CPU 和镜像扫描可能会永远进行下去。
- en: Keep in mind that a cluster's size will really depend on the applications being
    deployed. It is usually recommended to distribute application components in several
    nodes because clusters with fewer nodes are harder to maintain. A few nodes with
    many resources is worse than having the same resources distributed on many nodes.
    It gives you better cluster life cycle management and a better workload distribution
    when some nodes fail.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，集群的规模实际上取决于要部署的应用程序。通常建议将应用程序组件分布在多个节点上，因为节点较少的集群更难维护。拥有多个资源的少数节点比将相同的资源分布在多个节点上更糟糕。当某些节点出现故障时，将资源分散到多个节点上可以提供更好的集群生命周期管理和负载分配。
- en: On control plane nodes, we will deploy Docker Enterprise Engine version 19.03
    (the latest release at the time of writing). These nodes should be deployed with
    static IP addresses and Linux kernel version 3.10 or higher. Because we will deploy
    more than one replica, we will require an external load balancer to route control
    plane requests to any of the available manager nodes. We will use a virtual IP
    address and a **Fully Qualified Domain Name** (**FQDN**) associated with this
    load balancer. We will add them as **Subject Alternative Names** (**SANs**) to
    ensure valid certificates. Certificates should be associated (as a SAN) with any
    node that can be reached as part of UCP's service. In this case, manager nodes
    will run control plane components, so certificates should be valid for any of
    them, including all possible FQDN names associated with UCP's management endpoints
    (ports `443` and `6443` by default for Docker Swarm and Kubernetes, respectively).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在控制平面节点上，我们将部署 Docker 企业版引擎版本 19.03（写作时的最新版本）。这些节点应该部署静态 IP 地址并且 Linux 内核版本应为
    3.10 或更高版本。由于我们将部署多个副本，因此我们需要一个外部负载均衡器，将控制平面的请求路由到任何可用的管理节点。我们将使用一个虚拟 IP 地址和与此负载均衡器关联的**完全限定域名**（**FQDN**）。我们将它们作为**主题备用名称**（**SAN**）添加，以确保证书有效。证书应该与可以作为
    UCP 服务一部分访问的任何节点相关联（作为 SAN）。在这种情况下，管理节点将运行控制平面组件，因此证书应对它们中的任何一个有效，包括与 UCP 管理端点相关联的所有可能的
    FQDN 名称（默认情况下，Docker Swarm 和 Kubernetes 的端口分别为 `443` 和 `6443`）。
- en: We will expose TCP ports `443` and `6443` to users by default. Both can be changed
    to other ones more appropriate for our environment. The first port allows user
    interaction with UCP's control plane either using the web browser, the API, or
    the Docker command line. The second port described publishes the Kubernetes API
    server. It allows us to interact directly with the Kubernetes orchestrator.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将默认公开 TCP 端口 `443` 和 `6443`，也可以将它们更改为更适合我们环境的其他端口。第一个端口允许用户通过 Web 浏览器、API
    或 Docker 命令行与 UCP 的控制平面进行交互。第二个端口则公开 Kubernetes API 服务器，使我们可以直接与 Kubernetes 调度器交互。
- en: Worker nodes do not require static IP addresses but they should be accessible
    by their names using DNS.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点不需要静态 IP 地址，但它们应该能够通过 DNS 使用其名称进行访问。
- en: We cannot deploy user namespaces within UCP. (We learned about the user namespaces
    that are used to improve host security in [Chapter 3](c2dd78c4-066f-40b4-94e7-a7e2904d7ec2.xhtml),
    *Running Docker Containers*.) It is not easy to use this feature under UCP conditions,
    which is why it is not supported.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能在 UCP 中部署用户命名空间。（我们在[第 3 章](c2dd78c4-066f-40b4-94e7-a7e2904d7ec2.xhtml)中了解了用于提高主机安全性的用户命名空间，*运行
    Docker 容器*。）在 UCP 环境下使用此功能并不容易，因此不支持该功能。
- en: 'A minimum environment with high availability will include three managers and
    at least two workers. The following diagram shows the smallest environment (DTR
    nodes are not included). We can say that UCP has three major logical components:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 高可用性环境的最低配置将包括三个管理节点和至少两个工作节点。下图显示了最小环境（不包括 DTR 节点）。我们可以说，UCP 具有三个主要的逻辑组件：
- en: '![](img/47319578-6162-481e-9844-036acbb22ea9.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/47319578-6162-481e-9844-036acbb22ea9.jpg)'
- en: 'Therefore, as a summary, we will need the following logical requirements for
    the deployment:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总结来说，我们将需要以下逻辑要求来进行部署：
- en: Static IP addresses for manager nodes
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理节点的静态 IP 地址
- en: A VIP address and FQDN for the control plane
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制平面的 VIP 地址和 FQDN
- en: An external load balancer owning a VIP and TCP pass through to managers on ports
    `443` and `6443` (by default)
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个外部负载均衡器，拥有 VIP，并通过 TCP 将请求转发到管理节点的 `443` 和 `6443` 端口（默认情况下）
- en: 'The following ports and protocols should be permitted (TCP ports unless explicitly
    described):'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 应该允许以下端口和协议（除非明确说明，否则为 TCP 端口）：
- en: 'On managers:'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在管理节点上：
- en: Port `443` for the UCP web UI and API
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端口 `443` 用于 UCP Web UI 和 API
- en: Port `6443` for the Kubernetes API server
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端口 `6443` 用于 Kubernetes API 服务器
- en: Ports `2376` and `2377` for Docker Swarm communication
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`2376`和`2377`端口用于 Docker Swarm 通信'
- en: Ports ranging from `12379` to `12388` for internal UCP component communication
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`12379`到`12388`的端口用于 UCP 组件之间的内部通信
- en: 'On workers and managers:'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在工作节点和管理节点上：
- en: Port `7946` (TCP and UDP) for Docker Swarm gossip
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`7946`端口（TCP 和 UDP）用于 Docker Swarm 的gossip协议'
- en: Port `4789` (UDP) for overlay networking
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`4789`端口（UDP）用于覆盖网络'
- en: Port `12376` for TLS authentication proxy to access Docker Engine
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`12376`端口用于 TLS 认证代理，以访问 Docker 引擎'
- en: Port `6444` for the Kubernetes API reverse proxy
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`6444`端口用于 Kubernetes API 反向代理'
- en: Port `179` for BGP peers for Kubernetes networking
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`179`端口用于 Kubernetes 网络的 BGP 对等连接'
- en: Port `9099` for Calico health checks
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`9099`端口用于 Calico 健康检查'
- en: Port `10250` for Kubernetes Kubelet
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`10250`端口用于 Kubernetes Kubelet'
- en: Users will use ports `443` and `6443` to access UCP services via the HTTPS protocol.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 用户将通过 HTTPS 协议使用`443`和`6443`端口访问 UCP 服务。
- en: 'All cluster nodes will run containers. Some of these nodes will act as managers
    and they will run management components while others just run a few worker components
    and workloads. But there are two common elements on managers and workers: UCP
    agent and Docker Engine.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 所有集群节点都会运行容器。这些节点中的一些将作为管理节点运行管理组件，而另一些则仅运行少量的工作组件和负载。但是，管理节点和工作节点有两个共同点：UCP
    代理和 Docker 引擎。
- en: Docker Engine is always required because we need to run containers. Docker Enterprise
    requires Docker Enterprise Engine. The installation process is easy and it will
    be based on the license key file and the specific packages available for each
    customer at `https://hub.docker.com/u/<YOUR_USER_OR_ORGANIZATION>/content`. First,
    we will go to `https://hub.docker.com/` and register for a Docker Hub account.
    Docker provides a 1-month trial of the Docker Enterprise platform, available at
    [https://hub.docker.com/editions/enterprise/docker-ee-trial](https://hub.docker.com/editions/enterprise/docker-ee-trial).
    In [Chapter 11](1879ea92-ae47-4230-ac84-784d4bc73185.xhtml), *Universal Control
    Plane*, [Chapter 12](ab131f1f-ca6e-4815-9a3a-8c92c93c9dbc.xhtml), *Publishing
    Applications in Docker Enterprise*, and [Chapter 13](108b5948-15a9-40fb-b8dd-5a44c54efd7d.xhtml),
    *Implementing an Enterprise-Grade Registry with DTR*, we will show my own account
    (`frjaraur`) for example purposes, as well as the different steps and pictures
    to help you understand this.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 引擎始终是必需的，因为我们需要运行容器。Docker Enterprise 需要 Docker Enterprise 引擎。安装过程很简单，并将基于许可证密钥文件以及每个客户在`https://hub.docker.com/u/<YOUR_USER_OR_ORGANIZATION>/content`可用的特定软件包。首先，我们将访问`https://hub.docker.com/`并注册
    Docker Hub 账户。Docker 提供了 Docker Enterprise 平台的 1 个月试用，试用详情请访问 [https://hub.docker.com/editions/enterprise/docker-ee-trial](https://hub.docker.com/editions/enterprise/docker-ee-trial)。在[第11章](1879ea92-ae47-4230-ac84-784d4bc73185.xhtml)
    *通用控制平面*、[第12章](ab131f1f-ca6e-4815-9a3a-8c92c93c9dbc.xhtml) *在 Docker Enterprise
    中发布应用程序* 和 [第13章](108b5948-15a9-40fb-b8dd-5a44c54efd7d.xhtml) *使用 DTR 实现企业级注册表*
    中，我们将以我自己的账户（`frjaraur`）为例，并通过不同的步骤和图片帮助你理解。
- en: 'The following screenshot shows the `frjaraur` content URL. You will have your
    own content once you log into the Docker Hub website. We will find the required
    license and our package repository URL on this page after signing up for a Docker
    Enterprise 30-day trial:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了`frjaraur`内容的 URL。登录 Docker Hub 网站后，你将获得自己的内容。在注册 Docker Enterprise 30
    天试用版后，我们将在此页面找到所需的许可证和我们的软件包仓库 URL：
- en: '![](img/56d1cce9-3d94-453a-aa50-ae233b1cd2b4.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/56d1cce9-3d94-453a-aa50-ae233b1cd2b4.png)'
- en: At the bottom right, we will read our package's URL. Click on the copy button
    and follow the next procedure to install Docker Enterprise Engine. This procedure
    will be different for each Linux distribution. In this book, we will follow Ubuntu's
    procedure. The process is described at the previously provided customer content
    URL. Microsoft Windows nodes are also supported within the Docker Enterprise platform,
    although they can just be used as workers at the time of writing this book.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在右下角，我们将看到软件包的 URL。点击复制按钮，并按照接下来的步骤安装 Docker Enterprise 引擎。这个过程对于每个 Linux 发行版来说会有所不同。在本书中，我们将遵循
    Ubuntu 的安装步骤。该过程已在之前提供的客户内容 URL 中进行了描述。Microsoft Windows 节点也可以在 Docker Enterprise
    平台中使用，尽管在撰写本书时，它们只能作为工作节点使用。
- en: 'These are the steps to follow to install UCP with high availability on Ubuntu
    nodes:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在 Ubuntu 节点上安装 UCP 高可用性配置的步骤：
- en: 'Export the Docker Engine version and the previously shown URL on the `DOCKER_EE_VERSION`
    and `DOCKER_EE_URL` variables, respectively. At the time of writing this book,
    the latest Docker Enterprise Engine version is 19.03:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 Docker Engine 的版本和之前显示的 URL 分别导出到 `DOCKER_EE_VERSION` 和 `DOCKER_EE_URL` 变量中。在本书编写时，最新的
    Docker 企业版引擎版本是 19.03：
- en: '[PRE0]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Notice that your `DOCKER_EE_URL` will be completely different. You can ask for
    a trial license to follow these steps.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，你的 `DOCKER_EE_URL` 将完全不同。你可以申请试用许可证以便遵循这些步骤。
- en: 'Then, we need to add the Docker customer''s package repository to our environment:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要将 Docker 客户端的包仓库添加到我们的环境中：
- en: '[PRE1]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Finally, we will install the required packages:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将安装所需的包：
- en: '[PRE2]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: These procedures must be applied to all cluster nodes before installing UCP.
    As we mentioned previously, we will have different procedures for different Linux
    flavors, but we will also be able to include Microsoft Windows nodes in the cluster.
    Microsoft Windows Docker Engine's installation is completely different and is
    shown at `https://hub.docker.com/u/<YOUR_USER_OR_ORGANIZATION>/content`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装 UCP 之前，必须将这些步骤应用于所有集群节点。正如我们之前提到的，我们将为不同的 Linux 发行版提供不同的操作步骤，但我们也可以将 Microsoft
    Windows 节点包含在集群中。Microsoft Windows Docker Engine 的安装完全不同，具体过程请参见`https://hub.docker.com/u/<YOUR_USER_OR_ORGANIZATION>/content`。
- en: Always review your Docker customer's content page before installing Docker Enterprise
    Engine because the installation procedure may change.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装 Docker 企业版引擎之前，始终查看 Docker 客户端的内容页面，因为安装过程可能会发生变化。
- en: When all the cluster nodes have Docker Engine installed, we can continue with
    Docker UCP's installation. This workflow is not required but it is recommended
    because we can avoid any problems before installing UCP. This is because its components
    will run as containers in your hosts.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有集群节点都安装了 Docker Engine 后，我们可以继续安装 Docker UCP。这个工作流程并非强制要求，但建议使用，因为它可以在安装
    UCP 之前避免出现任何问题。这是因为 UCP 的组件将在你的主机上以容器形式运行。
- en: Docker provides support for different infrastructures and also certifies running
    the Docker Enterprise platform on them. Amazon Web Services and Microsoft Azure
    are the certified environments at the time of writing this book. In both cases,
    Docker also provides infrastructure scripts and/or step-by-step documentation
    for successfully deploying the Docker Enterprise platform on them.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 提供对不同基础设施的支持，并且认证可以在这些基础设施上运行 Docker 企业版平台。在本书编写时，亚马逊 Web 服务（AWS）和 Microsoft
    Azure 是认证的环境。在这两种情况下，Docker 还提供了基础设施脚本和/或逐步文档，用于成功部署 Docker 企业版平台。
- en: The Docker Enterprise platform is based on Docker Swarm, although Kubernetes
    is also deployed. Therefore, we will create a Docker Swarm cluster using the UCP
    installer, and then we will add other nodes as managers or workers.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 企业版平台基于 Docker Swarm，尽管也有部署 Kubernetes。因此，我们将使用 UCP 安装程序创建一个 Docker Swarm
    集群，然后将其他节点添加为管理员或工作节点。
- en: The installation will require launching a container named `ucp`. This is very
    important because it ensures just one installation at once. We will also use Docker
    Engine's local socket as the volume inside the installation container. The UCP
    installation process has many options – we will cover the most important ones
    here.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 安装过程将需要启动一个名为 `ucp` 的容器。这非常重要，因为它确保一次只进行一次安装。我们还将使用 Docker Engine 的本地套接字作为安装容器内的卷。UCP
    安装过程有许多选项——我们将在这里介绍最重要的几个。
- en: To install UCP, we will launch `docker container run --name ucp docker/ucp:<RELEASE_TO_INSTALL>`.
    It is important to install a specific release because the `docker/ucp` container
    will also be used for backup/recovery and other tasks.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 UCP，我们将启动 `docker container run --name ucp docker/ucp:<RELEASE_TO_INSTALL>`。安装特定版本非常重要，因为
    `docker/ucp` 容器也将用于备份/恢复和其他任务。
- en: 'Let''s write down and execute a usual installation command line for the first
    manager in the cluster:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为集群中的第一个管理员节点写下并执行一个常规安装命令：
- en: '[PRE3]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: After 35 steps, your UCP's environment will be installed on the first Linux
    node. Take care and use DNS resolution and an external load balancer. As we mentioned
    in the previous sections, all the managers will run the same control plane components.
    Therefore, an external load balancer is required to guide requests to any of them.
    This can be done by following the round-robin algorithm, for example (it does
    not matter which UCP manager node receives the requests, but at least one should
    be reachable).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在35个步骤之后，UCP的环境将安装在第一个Linux节点上。请小心使用DNS解析和外部负载均衡器。如前所述，所有管理节点将运行相同的控制平面组件。因此，需要一个外部负载均衡器来引导请求到其中的任何一个。可以按照轮询算法进行，例如（无论哪个UCP管理节点接收请求都无所谓，但至少应有一个节点可以访问）。
- en: The external load balancer will provide a virtual IP address to the UCP control
    plane and we will also provide pass-through port-routing for ports `443` and `6443`
    (or customized ones if you changed them). We will add this external load balancer's
    virtual IP address and the associated fully qualified domain name as a SAN. In
    fact, we will add as many SANs as required for our environment using the `--san`
    argument.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 外部负载均衡器将为UCP控制平面提供一个虚拟IP地址，我们还将为端口`443`和`6443`（如果你更改了它们，使用自定义端口）提供端口透传路由。我们将添加此外部负载均衡器的虚拟IP地址以及关联的完全限定域名（FQDN）作为SAN。实际上，我们将根据环境的需要，使用`--san`参数添加所需的多个SAN。
- en: These steps are key for your organization access and **Docker Trusted Registry**
    (**DTR**) because it is usual to integrate both within UCP. In this case, DTR
    will ask UCP for user authentication, so it has to have access and resolution
    to UCP's FQDN and ports.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤对于你的组织访问和**Docker可信注册表**（**DTR**）至关重要，因为通常将两者集成到UCP中。在这种情况下，DTR将请求UCP进行用户身份验证，因此必须能够访问和解析UCP的FQDN和端口。
- en: We will use a pass-through or transparent proxy on external load balancers to
    allow UCP's backends to manage TLS certificates and connections.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在外部负载均衡器上使用透传或透明代理，允许UCP的后端管理TLS证书和连接。
- en: 'The UCP image will allow us to do the following:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: UCP镜像将允许我们执行以下操作：
- en: Install and uninstall UCP using the `install` and `uninstall-ucp` actions. The
    uninstall option will remove all UCP components from all cluster nodes. We do
    not have to execute any other procedure to completely remove UCP from our nodes.
    Docker Engine will not be removed.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`install`和`uninstall-ucp`操作安装和卸载UCP。卸载选项将从所有集群节点中移除所有UCP组件。我们无需执行其他程序即可完全从节点中删除UCP。Docker引擎不会被移除。
- en: Download the required Docker images from Docker Hub using the `images` option.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`images`选项从Docker Hub下载所需的Docker镜像。
- en: Backup and restore UCP manager nodes using the `backup` and `restore` actions.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`backup`和`restore`操作备份和恢复UCP管理节点。
- en: Provide a UCP cluster ID and its certificates using the `id` and `dump-certs`
    options. Dumping certificates allows us to store them securely to avoid certificate
    problems if we accidentally remove any required volume.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`id`和`dump-certs`选项提供UCP集群ID及其证书。转储证书使我们能够安全地存储它们，以避免如果我们不小心删除任何必要的卷时出现证书问题。
- en: Create a support-dump using the `support` action. These dumps will contain all
    the useful information about our environment, including application/container
    logs.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`support`操作创建支持转储。这些转储将包含关于我们环境的所有有用信息，包括应用程序/容器日志。
- en: Upgrade the UCP platform by executing the `upgrade` option. This option will
    upgrade all UCP components and may impact our services. It is preferred to add
    the `--manual-worker-upgrade` argument to avoid worker nodes from being auto-upgraded.
    We will need to take care of our workloads and move them within worker nodes and
    manually upgrade UCP on them.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行`upgrade`选项来升级UCP平台。此选项将升级所有UCP组件，可能会影响我们的服务。建议添加`--manual-worker-upgrade`参数，以避免工作节点被自动升级。我们需要处理工作负载并将其移动到工作节点上，然后手动升级UCP。
- en: 'Create an example UCP configuration file and verify the required port status.
    UCP can be configured using either the provided web UI or using configuration
    files. Using configuration files will allow us to maintain reproducibility, and
    changes can be managed with any configuration management application. This method
    can be achieved once UCP is installed or during installation by customizing the
    example config file generated with the `example-config` option and using `docker/ucp
    install --existing-config` with this modified file. The available options are
    described at the following link: [https://docs.docker.com/ee/ucp/admin/configure/ucp-configuration-file](https://docs.docker.com/ee/ucp/admin/configure/ucp-configuration-file).'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个示例 UCP 配置文件并验证所需的端口状态。UCP 可以通过提供的 Web UI 或使用配置文件进行配置。使用配置文件将允许我们保持可重复性，且可以通过任何配置管理应用来管理更改。此方法可以在
    UCP 安装完成后使用，或者在安装过程中通过自定义 `example-config` 选项生成的示例配置文件，并使用 `docker/ucp install
    --existing-config` 来应用这个修改后的文件。可用的选项在以下链接中描述：[https://docs.docker.com/ee/ucp/admin/configure/ucp-configuration-file](https://docs.docker.com/ee/ucp/admin/configure/ucp-configuration-file)。
- en: 'The following are the most commonly used UCP installation options:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是最常用的 UCP 安装选项：
- en: '| **Options** | **Description** |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| **选项** | **描述** |'
- en: '| `--swarm-grpc-port`,`--controller-port`,`--kube-apiserver-port`, and `--swarm-port`
    | These options allow us to modify the default ports used in several services.
    The most important ones, probably customized in your environment, will be `kube-apiserver-port`
    (defaults to `6443`) and `controller-port` (defaults to `443`). They publish Kubernetes
    and UCP user endpoints to allow us to interact with the cluster. |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| `--swarm-grpc-port`,`--controller-port`,`--kube-apiserver-port` 和 `--swarm-port`
    | 这些选项允许我们修改多个服务使用的默认端口。最重要的端口，可能会在你的环境中进行定制，分别是 `kube-apiserver-port`（默认值为 `6443`）和
    `controller-port`（默认值为 `443`）。它们发布 Kubernetes 和 UCP 用户端点，允许我们与集群进行交互。 |'
- en: '| `--host-address` and`--data-path-addr` | The first option sets which node''s
    IP address will be allocated for publishing the control plane. The second option
    allows us to isolate the control plane from the data plane. We set a different
    interface or IP address for the data plane. |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| `--host-address` 和 `--data-path-addr` | 第一个选项设置哪个节点的 IP 地址将用于发布控制平面。第二个选项允许我们将控制平面与数据平面隔离开来。我们为数据平面设置一个不同的接口或
    IP 地址。 |'
- en: '| `--pod-cidr`, `--service-cluster-ip-range` and `--nodeport-range` | These
    options allow us to customize Kubernetes Pods'' and Services'' IP address ranges
    and publishing ports for `NodePort` services. |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| `--pod-cidr`, `--service-cluster-ip-range` 和 `--nodeport-range` | 这些选项允许我们自定义
    Kubernetes Pods 和 Services 的 IP 地址范围以及 `NodePort` 服务的发布端口。 |'
- en: '| `--external-server-cert` | With this option, we configure our own certificate
    within the UCP cluster. |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| `--external-server-cert` | 使用此选项，我们可以在 UCP 集群内配置自己的证书。 |'
- en: '| `--san` | We include as many SANs as required to add these aliases to UCP
    certificates. Ask yourself how users and admins will consume the UCP cluster and
    add the FQDN names related to these services. |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| `--san` | 我们根据需要在 UCP 证书中添加这些别名的 SAN（主题备用名称）。考虑用户和管理员如何使用 UCP 集群，并添加与这些服务相关的
    FQDN 名称。 |'
- en: '| `--admin-username` and `--admin-password` | It is recommended to set up an
    admin username and password during installation to provide a reproducible workflow.
    We will avoid the `--interactive` option to have an **Infrastructure-as-Code**
    (**IaC**) UCP installation process. |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| `--admin-username` 和 `--admin-password` | 建议在安装过程中设置管理员用户名和密码，以提供可重复的工作流程。我们将避免使用
    `--interactive` 选项，从而实现 **基础设施即代码** (**IaC**) 的 UCP 安装过程。 |'
- en: Once UCP is installed on the first manager node, we will just join other manager
    nodes and workers to the cluster, as we learned in [Chapter 8](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml),
    *Orchestration Using Docker Swarm*. To get the required `docker join` command
    line, we just execute `docker swarm join-token manager` for manager nodes and
    `docker swarm join-token worker` for worker nodes. We just copy their output and
    execute the `docker join` command on each manager and worker node. It is quite
    easy.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 UCP 安装在第一个管理节点上，我们只需要将其他管理节点和工作节点加入集群，正如我们在[第8章](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml)《使用
    Docker Swarm 的编排》中所学到的那样。为了获取所需的 `docker join` 命令行，我们只需执行 `docker swarm join-token
    manager` 用于管理节点，执行 `docker swarm join-token worker` 用于工作节点。然后我们复制它们的输出，并在每个管理节点和工作节点上执行
    `docker join` 命令。这个过程非常简单。
- en: It is also possible to obtain the required joining instructions from the web
    UI by going to the Shared Resources | Nodes menu.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以通过访问共享资源 | 节点菜单，从 Web UI 获取所需的加入指令。
- en: Nodes in a UCP cluster can work with either Docker Swarm or Kubernetes, or even
    in mixed mode. This allows nodes to run Docker Swarm and Kubernetes workloads
    at the same time.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: UCP 集群中的节点可以与 Docker Swarm 或 Kubernetes 一起工作，甚至可以使用混合模式。这允许节点同时运行 Docker Swarm
    和 Kubernetes 工作负载。
- en: Mixed mode is not recommended in production because orchestrators do not share
    their load information. Therefore, a node can be almost full for one orchestrator
    and empty for another. In this situation, it can continue receiving new workloads
    for a non-full orchestrator, hence impacting other orchestrator's application
    performance.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 不推荐在生产环境中使用混合模式，因为协调器不会共享其负载信息。因此，一个协调器的节点可能几乎满载，而另一个协调器的节点可能为空。在这种情况下，非满载的协调器仍然可以继续接收新的工作负载，从而影响其他协调器的应用性能。
- en: As a summary, we installed Docker Engine and then we installed UCP. We reviewed
    this process and the main arguments required to install the Docker Enterprise
    platform in our environment.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们安装了 Docker Engine，然后安装了 UCP。我们回顾了这个过程以及在我们的环境中安装 Docker Enterprise 平台所需的主要参数。
- en: If you plan to install Docker Enterprise on Amazon AWS or the Microsoft Azure
    cloud, you should read the specific instructions and options in the Docker documentation
    (for AWS, [https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-aws](https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-aws);
    for Azure, [https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-azure](https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-azure)).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你计划在 Amazon AWS 或 Microsoft Azure 云上安装 Docker Enterprise，你应该阅读 Docker 文档中的具体说明和选项（AWS
    版本：[https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-aws](https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-aws);
    Azure 版本：[https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-azure](https://docs.docker.com/ee/ucp/admin/install/cloudproviders/install-on-azure)）。
- en: Now, we will review the UCP environment.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将回顾 UCP 环境。
- en: Reviewing the Docker UCP environment
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾 Docker UCP 环境
- en: In this section, we will review the Docker UCP environment. We will be able
    to use either the web UI, the command line, or its published REST API. In this
    book, we will cover the web application interface and how to integrate our `docker`
    client command line with UCP.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将回顾 Docker UCP 环境。我们可以使用 Web UI、命令行或者其发布的 REST API。在本书中，我们将覆盖 Web 应用界面以及如何将我们的
    `docker` 客户端命令行与 UCP 集成。
- en: First, we will introduce the web UI.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将介绍 Web UI。
- en: The web UI
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Web UI
- en: The web UI will run on all manager nodes. We will use UCP's fully qualified
    domain name, which is associated with its virtual IP address. Port `443` will
    be used unless you manually configured a different one. If we open `https://<UCP_FQDN>:<UCP_PORT>`
    on our browser, we will access the UCP login page. If we have used autogenerated
    certificates, the browser will warn us about an untrusted CA. This is normal because
    UCP generates an internal CA automatically for us to sign all internal and external
    certificates. We can upload our corporate or private certificates into UCP.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Web UI 将在所有管理节点上运行。我们将使用 UCP 的完全限定域名，该域名与其虚拟 IP 地址相关联。默认使用端口 `443`，除非你手动配置了不同的端口。如果我们在浏览器中打开
    `https://<UCP_FQDN>:<UCP_PORT>`，我们将访问 UCP 登录页面。如果我们使用的是自动生成的证书，浏览器会提醒我们存在不受信任的
    CA。这是正常现象，因为 UCP 会自动为我们生成一个内部 CA，用于签署所有内部和外部证书。我们可以将公司的或私人证书上传到 UCP。
- en: Remember to apply a passthrough (or transparent proxy) configuration on your
    external load balancer to access UCP backends. We will use `https://<MANAGER_IP>:<UCP_PORT>/_ping`
    for the backend's health check.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 请记得在外部负载均衡器上应用直通（或透明代理）配置，以访问 UCP 后端。我们将使用 `https://<MANAGER_IP>:<UCP_PORT>/_ping`
    来进行后端健康检查。
- en: Let's have a quick review of UCP's web UI. The following screenshot shows the
    main login interface. We set the admin's password during installation, either
    executing this process interactively with the `--interactive` argument or automating
    these settings by adding the `--admin-username` and `--admin-password` arguments.
    The username and password that are used during installation should be used to
    log into UCP.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速回顾一下 UCP 的 Web UI。以下截图显示了主要的登录界面。在安装过程中，我们设置了管理员密码，可以通过执行该过程并使用 `--interactive`
    参数进行交互，或者通过添加 `--admin-username` 和 `--admin-password` 参数来自动化这些设置。安装过程中使用的用户名和密码应当用于登录
    UCP。
- en: 'The main page will also ask us to add a license file if we have not applied
    it during installation. This can be done using the `--license` argument for `docker
    run docker/ucp:<RELEASE> install`:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 主页面还会提示我们，如果在安装过程中没有应用许可证文件，需要添加一个。可以使用 `--license` 参数来完成 `docker run docker/ucp:<RELEASE>
    install`：
- en: '![](img/8a593cc8-4833-4389-b117-c518e784dd92.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8a593cc8-4833-4389-b117-c518e784dd92.png)'
- en: 'The following screenshot shows the UCP Dashboard. Each user will have access
    to their own. The left panel will provide access to the user''s profile, Dashboard,
    Access Control, Shared Resources, and resources specific to Kubernetes and Swarm:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了UCP仪表盘。每个用户都可以访问自己的仪表盘。左侧面板将提供访问用户个人资料、仪表盘、访问控制、共享资源以及与Kubernetes和Swarm相关的资源：
- en: '![](img/df34de10-6b1d-4d8f-87ae-cb4dcf15d115.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](img/df34de10-6b1d-4d8f-87ae-cb4dcf15d115.png)'
- en: The Dashboard screen shows us a quick review of the cluster's components' status.
    It also provides a summary of the Swarm and Kubernetes workloads and an overview
    of the cluster's load. Do not think this is enough for monitoring as this is too
    simple. We should add monitoring tools to improve alerting, performance reporting,
    and capacity planning features.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Dashboard屏幕展示了集群组件状态的快速回顾。它还提供了Swarm和Kubernetes工作负载的摘要以及集群负载的概览。不要认为这就足够进行监控，因为这太简单了。我们应添加监控工具来增强警报、性能报告和容量规划功能。
- en: 'Access Control will only appear when UCP administrators access the cluster''s
    Web UI. Administrators will be able to manage all of RBAC''s behavior:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Access Control仅在UCP管理员访问集群的Web UI时出现。管理员将能够管理RBAC的所有行为：
- en: Orgs & Teams provides an interface to create organizations and teams and we
    will integrate users into them from these entries.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Orgs & Teams提供了一个接口，用于创建组织和团队，并将用户集成到其中。
- en: The Users endpoint will allow us to manage users as expected. We will learn
    how to create and manage users in the next topic.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Users端点将允许我们按预期管理用户。我们将在下一个主题中学习如何创建和管理用户。
- en: Roles provides an interface for Kubernetes and UCP roles. Kubernetes resources
    should be managed using declarative methods using YAML resource files, while Docker
    Swarm's resources (managed by UCP) will be created using the web UI.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roles提供了一个用于Kubernetes和UCP角色的接口。Kubernetes资源应使用声明性方法（使用YAML资源文件）进行管理，而Docker
    Swarm的资源（由UCP管理）将通过Web UI创建。
- en: Grants helps us manage Kubernetes role bindings and Swarm roles and collection
    integrations.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grants帮助我们管理Kubernetes角色绑定和Swarm角色及集合集成。
- en: 'Shared Resources provides access to resources for either Kubernetes or Docker
    Swarm. We will manage collections, stacks, containers, images, and nodes:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Shared Resources提供了对Kubernetes或Docker Swarm资源的访问。我们将管理集合、堆栈、容器、镜像和节点：
- en: '![](img/208027ae-f984-4e25-b748-f8cbf662233b.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/208027ae-f984-4e25-b748-f8cbf662233b.png)'
- en: Nodes can be managed from the Nodes entry point. We will set node properties
    and the orchestrator mode. Adding new nodes is easy, as we have seen. The Add
    Node option shows us the cluster's `docker join` command line. We will just copy
    this instruction to the new node's Terminal. This will also apply to Microsoft
    Windows nodes.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 节点可以通过Nodes入口点进行管理。我们将设置节点属性和编排器模式。正如我们所看到的，添加新节点非常简单。Add Node选项向我们展示了集群的`docker
    join`命令行。我们只需将此指令复制到新节点的终端中即可。这同样适用于Microsoft Windows节点。
- en: Stacks will show either multi-container or multi-service applications deployed
    on a Docker Swarm cluster. This view also shows Kubernetes workloads.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Stacks将显示部署在Docker Swarm集群上的多容器或多服务应用程序。此视图还显示Kubernetes工作负载。
- en: 'Kubernetes and Swarm endpoints show us each orchestrator''s specific resources:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes和Swarm端点显示了每个编排器的特定资源：
- en: Kubernetes shows namespaces, service accounts, controllers, services, ingress
    resources, Pod configurations, and storage. We will be able to change which namespace
    will be used for all users' web UI endpoints. We will also review and create Kubernetes
    resources using the declarative method.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes显示命名空间、服务账户、控制器、服务、入口资源、Pod配置和存储。我们将能够更改所有用户Web UI端点所使用的命名空间。我们还将使用声明性方法回顾和创建Kubernetes资源。
- en: Swarm allows us to create and review services, volumes, networks, secrets, and
    configurations.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm允许我们创建和查看服务、卷、网络、机密和配置。
- en: We can review the UCP documentation as well as Kubernetes' and the UCP API.
    This will help us implement automation procedures based on REST API integrations.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看UCP文档以及Kubernetes和UCP API文档。这将帮助我们基于REST API集成实现自动化流程。
- en: The command line using the UCP bundle
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用UCP包的命令行
- en: The UCP bundle is probably the most important part to access for your users
    and administrators. Although every user can have access to UCP's web UI, CI/CD,
    monitoring tools, and DevOps, users will review and launch their workloads using
    the Docker command line. Therefore, this access should be secure. Remember that
    Docker Swarm deploys an encrypted control plane. All its internal communications
    will be secured by TLS. Users' access is not secured. UCP, on the other hand,
    provides a completely secure solution. Security is ensured using TLS for users
    and admin access. This is managed using personalized certificates. Each user will
    get their own group of certificates. Kubernetes access is also secured using the
    UCP user bundle.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: UCP包可能是访问您用户和管理员最重要的部分。虽然每个用户都可以访问UCP的Web UI、CI/CD、监控工具和DevOps，但用户将使用Docker命令行查看和启动他们的工作负载。因此，这种访问应该是安全的。请记住，Docker
    Swarm部署了加密的控制平面。其所有内部通信将通过TLS进行加密保护。然而，用户的访问是没有加密的。另一方面，UCP提供了一个完全安全的解决方案。通过使用TLS保护用户和管理员访问来确保安全。这个安全是通过个性化证书来管理的。每个用户都会获得一组属于他们自己的证书。Kubernetes访问同样通过UCP用户包来加密保护。
- en: 'To obtain this UCP bundle, users will use either the web UI or a simple `curl`
    command – or any command-line web client – to download this package file, compressed
    as a ZIP folder:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取此UCP包，用户可以使用Web UI，或者通过一个简单的`curl`命令——或任何命令行Web客户端——下载这个压缩为ZIP文件的包：
- en: '![](img/612e0ee9-344c-4c0f-8733-e1cb3353672d.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](img/612e0ee9-344c-4c0f-8733-e1cb3353672d.png)'
- en: The preceding screenshot shows web GUI access to the user bundle file. We will
    just download it using a web browser. Once it is on our computer, we will decompress
    it. This file contains certificates, configuration, and scripts to load the client
    environment on our computer, regardless of whether it is running Linux, Mac, or
    Windows operating systems. There is an environment file for each one. We will
    look at its content and the procedure in Linux, but it is similar in Windows (the
    commands will vary).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图展示了通过Web GUI访问用户包文件。我们只需通过浏览器下载它。一旦文件下载到我们的计算机上，我们将解压它。此文件包含证书、配置和脚本，用于在我们的计算机上加载客户端环境，无论它是运行Linux、Mac还是Windows操作系统。每个操作系统都有一个对应的环境文件。我们将查看Linux系统中的内容和过程，但在Windows系统中也类似（只是命令不同）。
- en: 'We can use `curl` and `jq` to download the user bundle from the command line:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`curl`和`jq`从命令行下载用户包：
- en: '[PRE4]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If we decompress the admin bundle file, `ucp-bundle-admin.zip`, using `unzip`,
    we will obtain all the files required to connect to our cluster:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用`unzip`解压缩管理员包文件`ucp-bundle-admin.zip`，将获得连接到集群所需的所有文件：
- en: '[PRE5]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will then load this environment. We will use `env.ps1` in Microsoft Windows
    PowerShell or the `env.cmd` Command Prompt. On Linux hosts, we will use `env.sh`.
    When we load the environment on our shell, we will be able to connect remotely
    to the UCP cluster using the `docker` or `kubectl` client software:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将加载此环境。我们将在Microsoft Windows PowerShell中使用`env.ps1`，或者在命令提示符中使用`env.cmd`。在Linux主机上，我们将使用`env.sh`。当我们在Shell中加载此环境时，就可以使用`docker`或`kubectl`客户端软件远程连接到UCP集群：
- en: '[PRE6]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Notice that the Kubernetes context has also been set. Therefore, we will be
    able to manage the cluster and deploy workloads on either Kubernetes or Docker
    Swarm. Each user's UCP bundle must be stored securely. We can generate a new one
    if we remove it, but keep it safe; someone could potentially use it and obtain
    access to your environment files.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Kubernetes上下文也已经设置好。因此，我们将能够管理集群并在Kubernetes或Docker Swarm上部署工作负载。每个用户的UCP包必须安全存储。如果我们删除它，可以生成一个新的，但要保持安全；否则，可能会有人利用它获取对您的环境文件的访问权限。
- en: UCP provides client software for Microsoft Windows and Linux on our manager
    nodes at `https://<UCP_FQDN>:<UCP_PORT>/manage/dashboard/dockercli`. We can download
    them to connect to the cluster.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: UCP为我们的管理节点提供了适用于Microsoft Windows和Linux的客户端软件，网址为`https://<UCP_FQDN>:<UCP_PORT>/manage/dashboard/dockercli`。我们可以下载这些软件以连接到集群。
- en: It is key to use the UCP bundle instead of connecting to the cluster using SSH
    or any other local access. We will never allow local access to cluster nodes.
    Everyone must access the cluster either using the command line or the web UI.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 使用UCP包连接集群，而不是通过SSH或其他本地访问方式，是至关重要的。我们绝不会允许本地访问集群节点。每个人必须通过命令行或Web UI访问集群。
- en: UCP's REST API is also secured using certificates. We will require the UCP bundle's
    certificate files to access the cluster using its API.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: UCP的REST API也使用证书进行安全保护。我们需要UCP包中的证书文件才能使用其API访问集群。
- en: We will review UCP's access control in the next section and provide a simple
    example that will help us understand RBAC concepts.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中审查 UCP 的访问控制，并提供一个简单的示例，帮助我们理解 RBAC 概念。
- en: Role-based access control and isolation
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于角色的访问控制与隔离
- en: '**Role-based access control** (**RBAC**) manages authorization for Docker Swarm
    and Kubernetes. Docker Enterprise lets us manage users'' access to resources.
    We use roles to allow users to view, edit, and use cluster resources.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于角色的访问控制**（**RBAC**）管理 Docker Swarm 和 Kubernetes 的授权。Docker Enterprise 让我们管理用户对资源的访问权限。我们使用角色来允许用户查看、编辑和使用集群资源。'
- en: 'Authorization is based on the following concepts:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 授权基于以下概念：
- en: '**Subjects**: We manage users, teams, and service accounts within organizations.
    Users are part of teams, included in organizations.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主题**：我们在组织中管理用户、团队和服务账户。用户是团队的一部分，包含在组织中。'
- en: '**Resources**: These are the groups of Docker objects we were talking about
    in [Chapter 1](c5ecd7bc-b7ed-4303-89a8-e487c6a220ed.xhtml), *Modern Infrastructures
    and Applications with Docker*. As Kubernetes is also integrated into the UCP cluster,
    Kubernetes resources are also part of these groupings. UCP manages resources grouped
    in collections.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源**：这些是我们在[第 1 章](c5ecd7bc-b7ed-4303-89a8-e487c6a220ed.xhtml)中讨论的 Docker
    对象组，*现代基础设施与应用程序使用 Docker*。由于 Kubernetes 也集成到了 UCP 集群中，因此 Kubernetes 资源也属于这些组。UCP
    管理按集合分组的资源。'
- en: '**Collections**: These are sets of resources, including different kinds of
    objects, such as volumes, secrets, configs, networks, services, and so on.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集合**：这些是资源的集合，包括不同种类的对象，如卷、密钥、配置、网络、服务等。'
- en: '**Roles**: These group sets of permissions and we assign them to different
    subjects. Roles define what can be done by whom.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**角色**：这些是权限的集合，我们将其分配给不同的主题。角色定义了谁可以做什么。'
- en: '**Grants**: Combining subjects with roles and resource sets, we obtain grants.
    They are effective user permissions applied to groups of resources.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**授权**：将主题与角色和资源集结合，我们获得了授权。这些是应用于资源组的有效用户权限。'
- en: Service accounts are only valid for Kubernetes. These are not user accounts;
    they are associated with applications or APIs assigned to manage their access.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 服务账户仅对 Kubernetes 有效。这些不是用户账户；它们与分配管理访问权限的应用程序或 API 相关联。
- en: 'There are some predefined roles but we can create our own. This is a list of
    the default ones included with Docker Enterprise''s UCP:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些预定义的角色，但我们可以创建自己的角色。以下是 Docker Enterprise 的 UCP 中包含的默认角色列表：
- en: 'None: This role does not provide access to any Docker Swarm resources. This
    should be the default role for new users.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无：此角色不提供任何 Docker Swarm 资源的访问权限。此角色应为新用户的默认角色。
- en: 'View Only: Users with this role can view resources such as services, volumes,
    and networks but they cannot create new resources.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅查看：拥有此角色的用户可以查看服务、卷和网络等资源，但无法创建新资源。
- en: 'Restricted Control: Users with this role can view and edit resources but they
    cannot use bind mounts (hosts'' directories) or execute new processes within containers
    using `docker exec`. They cannot run privileged containers or with enhanced capabilities.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制控制：拥有此角色的用户可以查看和编辑资源，但不能使用绑定挂载（主机目录）或通过 `docker exec` 在容器中执行新进程。他们不能运行特权容器或具有增强功能的容器。
- en: 'Scheduler: This role allows users to view nodes so that they can schedule workloads
    on them. By default, all users get a grant with the `Scheduler` role against the
    `/Shared` collection.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调度员：此角色允许用户查看节点，从而能够在节点上调度工作负载。默认情况下，所有用户都对 `/Shared` 集合获得 `Scheduler` 角色授权。
- en: 'Full Control: This role should be restricted to advanced users only. These
    can view and edit volumes, networks, and images. They also can create privileged
    containers.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全控制：此角色应仅限于高级用户。这些用户可以查看和编辑卷、网络和镜像，也可以创建特权容器。
- en: Users will only be able to manage their own containers or Pods. This behavior
    allows integrating namespaces (Kubernetes) and collections (Docker Swarm) in this
    equation. Therefore, users with full control access to a set of resources included
    in a collection will have all privileges on them in Docker Swarm. The same will
    happen if we add resources within a namespace and the user is included in a fully
    privileged role in Kubernetes.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 用户将只能管理自己的容器或 Pods。这种行为使得可以将命名空间（Kubernetes）和集合（Docker Swarm）结合在一起。因此，具有对集合中一组资源完全控制访问权限的用户，将在
    Docker Swarm 中对这些资源拥有所有权限。如果我们在命名空间中添加资源，并且该用户包含在 Kubernetes 中的完全特权角色中，同样的情况也会发生。
- en: There is also a more advanced role that's assigned to Docker Enterprise administrators.
    They will have full control and management privileges for the UCP environment.
    This can be managed using the Is Admin checkbox on the user's properties page.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个更高级的角色是分配给 Docker Enterprise 管理员的。他们将拥有对 UCP 环境的完全控制和管理权限。可以通过用户属性页面上的“Is
    Admin”复选框进行管理。
- en: Grants interconnect users and permissions with the set of resources where they
    should be applied. The grants management workflow includes their creation, user
    assignment, the role that should be applied, and resource association. This way,
    we ensure that the appropriate privileges are applied to a collection of resources
    assigned to a group of users (or just one user).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 授权将用户和权限与应应用的资源集合相互连接。授权管理工作流包括它们的创建、用户分配、应应用的角色以及资源关联。通过这种方式，我们确保为分配给一组用户（或单个用户）的资源集合应用适当的权限。
- en: 'Collections are hierarchical and contain resources. They are represented by
    using a directory-like structure and every user has their own private collection,
    along with the user''s default permissions. Using this, we can nest collections.
    Once a user has been granted access to a collection, they will have access to
    all its hierarchical children. There are three main collections: `/`, `/System`,
    and `/Shared`.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 集合是分层的，并包含资源。它们通过类似目录的结构来表示，每个用户都有自己的私人集合，并且拥有默认的用户权限。通过此方法，我们可以嵌套集合。一旦授予用户对某个集合的访问权限，他们将可以访问该集合的所有层级子集合。主要有三个集合：`/`、`/System`
    和 `/Shared`。
- en: Under the `/System` collection, we will find UCP's manager nodes and UCP's and
    DTR's system services. By default, only administrators will have access to this
    collection. On the other hand, the `/Shared` collection will contain all the worker
    nodes ready for running workloads. We can add additional collections and move
    some workers to isolate them and provide multi-tenant features. Distributing workers
    on different collections will also distribute workload execution for different
    groups or tenants.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `/System` 集合下，我们将找到 UCP 的管理节点以及 UCP 和 DTR 的系统服务。默认情况下，只有管理员才能访问此集合。另一方面，`/Shared`
    集合将包含所有准备好运行工作负载的工作节点。我们可以添加额外的集合并将一些工作节点移动到这些集合中，以便将它们隔离并提供多租户功能。将工作节点分布在不同的集合中，还可以为不同的团队或租户分配工作负载执行。
- en: Each user has a private collection by default under `/Collections/Swarm/Shared/Private/<USER_NAME>`.
    This ensures that users' workloads are secure by default and only administrators
    will have access. Therefore, users have to deploy workloads on their team-shared
    collections.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 每个用户默认都有一个私人集合，位于`/Collections/Swarm/Shared/Private/<USER_NAME>`。这确保用户的工作负载默认是安全的，只有管理员才能访问。因此，用户必须在他们团队共享的集合中部署工作负载。
- en: Labels associated with collections manage users' access to resources, which
    makes it easy to allow or disallow a user's visibility dynamically.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 与集合关联的标签管理用户对资源的访问，这使得动态地允许或禁止用户的可见性变得容易。
- en: Let's review these concepts with a short example.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个简短的示例来回顾这些概念。
- en: 'We have two projects in our organization (`myorganization`): `projectA` and
    `projectB`. We will also assume that we have three teams in our organization:
    developers, quality and assurance, and DevOps. Let''s describe some users and
    their roles within our organization:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的组织（`myorganization`）中有两个项目：`projectA` 和 `projectB`。我们还假设在我们的组织中有三个团队：开发人员、质量保证和
    DevOps。让我们描述一些用户及其在组织中的角色：
- en: '**Developers**: `dev1` and `dev2`'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开发人员**：`dev1` 和 `dev2`'
- en: '**Quality and assurance:** `qa1` and `qa2`'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**质量保证：** `qa1` 和 `qa2`'
- en: '**DevOps:** `devops1` and `devops2`'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DevOps：** `devops1` 和 `devops2`'
- en: '**UCP Admin**'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**UCP 管理员**'
- en: 'The following image shows some screenshots of the user creation process. First,
    we create an organization and then teams and users inside the previously created
    organization:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片展示了用户创建过程的一些截图。首先，我们创建一个组织，然后在之前创建的组织内创建团队和用户：
- en: '![](img/63c62974-88fc-4628-b990-2d220a8445c9.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](img/63c62974-88fc-4628-b990-2d220a8445c9.png)'
- en: 'Each user will have their own user account in UCP. We will create developers,
    quality and assurance, and DevOps teams and we will add their users. We will also
    create three main collections as stages and child collections for each project.
    Therefore, we will have the following:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 每个用户将在 UCP 中拥有自己的用户账户。我们将创建开发人员、质量保证和 DevOps 团队，并添加他们的用户。我们还将创建三个主要的集合作为阶段，并为每个项目创建子集合。因此，我们将有以下内容：
- en: '`development/projectA` and `development/projectB`'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`development/projectA` 和 `development/projectB`'
- en: '`certification/projectA` and `certification/projectB`'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`certification/projectA` 和 `certification/projectB`'
- en: '`production/projectA` and `production/projectB`'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`production/projectA` 和 `production/projectB`'
- en: Let's suppose that each developer works on one project at a time. They should
    have full access to their projects during the development stage but they should
    have view-only access in the certification stage. Quality and assurance users
    will only have access to create and modify their deployments in the certification
    stage. DevOps will have access to create and modify resources in production and
    they will allow view-only access to developers, but only on `projectA`. In fact,
    `projectB` should be secure and only a `devops2` user should be able to modify
    resources for this project.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 假设每个开发者一次只负责一个项目。在开发阶段，他们应该对自己的项目拥有完全访问权限，但在认证阶段，他们只能拥有查看权限。质量保证用户在认证阶段只能创建和修改他们的部署。DevOps可以在生产环境中创建和修改资源，并允许开发者仅对`projectA`进行查看权限访问。实际上，`projectB`应该是安全的，只有`devops2`用户才能修改此项目的资源。
- en: 'The following screenshots show the process of adding grants to allow a user
    access to collections. First, we create a collection, and then we add that collection
    to a new role:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了为用户添加权限以允许其访问集合的过程。首先，我们创建一个集合，然后将该集合添加到新角色中：
- en: '![](img/e10abfc9-b802-4ef5-9ee3-855379fe31e0.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e10abfc9-b802-4ef5-9ee3-855379fe31e0.png)'
- en: We will launch two deployments with different users and will review how they
    view these deployments.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将启动两个部署，并使用不同的用户查看这些部署的情况。
- en: 'We will assume that all the required users have been created and that each
    user''s `ucp-bundle` has been downloaded. As user `dev1`, we will create a simple
    `nginx` deployment for `projectB`, using `com.docker.ucp.access.label=/development/projectB`
    as the label:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设所有所需的用户已经创建，并且每个用户的`ucp-bundle`已经下载。作为`dev1`用户，我们将为`projectB`创建一个简单的`nginx`部署，使用`com.docker.ucp.access.label=/development/projectB`作为标签：
- en: '[PRE7]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If we now impersonate user `qa1`, we will get different results:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在模拟`qa1`用户，我们将得到不同的结果：
- en: '[PRE8]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'User `qa1` will not list any services because it does not have access to the
    `dev1` collection. But if we review this list with the `devops2` user, we will
    obtain a list that includes the `dev1` user''s services:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 用户`qa1`将无法列出任何服务，因为它没有访问`dev1`集合的权限。但是，如果我们使用`devops2`用户查看这个列表，我们将获得一个包含`dev1`用户服务的列表：
- en: '[PRE9]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If we try to modify this resource (the `nginx-dev` service), we will obtain
    an access error because we only have view authorization. On the other hand, the
    `dev2` user can scale up the number of replicas because they are in the developer
    group:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试修改这个资源（`nginx-dev`服务），我们将遇到访问错误，因为我们只有查看权限。另一方面，`dev2`用户可以扩展副本数，因为他们属于开发者组：
- en: '[PRE10]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To finish off this example, we will create two different services as user `devops2`.
    We will deploy secure and unsecured services from `projectB` and `projectA`, respectively:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这个示例，我们将作为`devops2`用户创建两个不同的服务。我们将分别从`projectB`和`projectA`部署安全和不安全的服务：
- en: '[PRE11]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In this case, the `devops1` user should only be able to manage `nginx-prod-unsecure`,
    which is associated with `projectA`:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`devops1`用户应该只能管理与`projectA`关联的`nginx-prod-unsecure`服务：
- en: '[PRE12]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This was a simple example of authorization management using labels. In this
    case, we manually added these labels, but we can set a default collection for
    each user if we wish. This will provide a default label associated with their
    workflows, instead of us using the out-of-the-box `/Collections/Swarm/Shared/Private/<USER>`
    collection. We can also associate constraints with collections to ensure specific
    locations. This is very important in multi-tenant environments.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用标签进行授权管理的一个简单示例。在这个示例中，我们手动添加了这些标签，但如果需要，我们可以为每个用户设置默认集合。这将提供一个与他们的工作流相关联的默认标签，而不是使用开箱即用的`/Collections/Swarm/Shared/Private/<USER>`集合。我们还可以将约束与集合关联，以确保特定位置的设置。这在多租户环境中非常重要。
- en: UCP's Kubernetes integration
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: UCP的Kubernetes集成
- en: As we have learned, Kubernetes is deployed alongside Docker Swarm when installing
    UCP. If we take a look at all the required Kubernetes components, we will notice
    that all of them run as containers within our cluster. The required key-value
    store will also be provided. Port `6443` (by default) will provide Kubernetes
    access, and users and administrators will use this port to manage the cluster
    or execute their workloads.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所学，Kubernetes 在安装 UCP 时与 Docker Swarm 一起部署。如果我们查看所有必需的 Kubernetes 组件，我们会注意到它们都作为容器在集群中运行。所需的键值存储也会提供。端口
    `6443`（默认）将提供 Kubernetes 访问，用户和管理员将使用此端口来管理集群或执行工作负载。
- en: We will use the Docker bundle's certificates and configuration file, `kube.yml`.
    As we learned in this chapter, we will load our user's bundle environment and
    then get access to the Kubernetes cluster using the `kubectl` command line.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Docker 包中的证书和配置文件 `kube.yml`。正如我们在本章中学到的，我们将加载用户的包环境，然后使用 `kubectl` 命令行访问
    Kubernetes 集群。
- en: 'Once `env.sh` has been loaded using `source env.sh`, we will have the required
    environment variables and access to our certificates. If we get Kubernetes cluster
    nodes using `kubectl get nodes`, we will obtain their status:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦使用 `source env.sh` 加载了 `env.sh`，我们就会获得所需的环境变量并访问我们的证书。如果使用 `kubectl get nodes`
    获取 Kubernetes 集群节点，我们将得到它们的状态：
- en: '[PRE13]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'If we review the running Pods in the `kube-system` namespace using `kubectl
    get pods -n kube-system`, we will notice that `calico` and `compose` for Kubernetes
    are also deployed:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用 `kubectl get pods -n kube-system` 查看 `kube-system` 命名空间中运行的 Pods，我们会注意到
    Kubernetes 的 `calico` 和 `compose` 也已部署：
- en: '[PRE14]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: These components are very important because Calico is the default CNI deployed
    with UCP. This allows us to deploy applications distributed cluster-wide. Pods
    and services are able to communicate within the cluster even if they do not run
    on the same host. This is not required in Docker Swarm because overlay networking
    is included by default. Calico allows us also to improve Kubernetes security because
    it can deploy network policies to isolate and manage Pods' and services' communications.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件非常重要，因为 Calico 是 UCP 默认部署的 CNI。它允许我们在集群范围内部署分布式应用。即使 Pods 和服务没有在同一主机上运行，它们仍然能够在集群内进行通信。在
    Docker Swarm 中不需要这个，因为覆盖网络默认包含在内。Calico 还允许我们提高 Kubernetes 的安全性，因为它可以部署网络策略来隔离和管理
    Pods 和服务之间的通信。
- en: On the other hand, Compose for Kubernetes provides a standard interface for
    Docker Swarm and Kubernetes. Docker stacks could be deployed either on Docker
    Swarm or Kubernetes.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Compose for Kubernetes 为 Docker Swarm 和 Kubernetes 提供了一个标准接口。Docker 堆栈可以部署在
    Docker Swarm 或 Kubernetes 上。
- en: 'We can also notice that `ucp-metrics` also runs Kubernetes workloads as other
    system-related deployments, obtained using `kubectl get deployments -A`:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以注意到，`ucp-metrics` 也运行着 Kubernetes 工作负载，作为其他与系统相关的部署，使用 `kubectl get deployments
    -A` 可以获得：
- en: '[PRE15]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Kubernetes roles and role bindings are managed from the command line and the
    web UI. All Kubernetes features from the 1.14.8 release are available. This is
    also very important. Docker Enterprise provides a vanilla Kubernetes release and
    product releases also upgrade Kubernetes, but you cannot upgrade Kubernetes manually.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 角色和角色绑定可以通过命令行和 Web UI 进行管理。所有 1.14.8 版本发布中的 Kubernetes 功能都可以使用。这一点也非常重要。Docker
    Enterprise 提供的是原生 Kubernetes 版本，并且产品发布也会升级 Kubernetes，但你不能手动升级 Kubernetes。
- en: In the next section, we will review the main administration tasks and security
    improvements.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将回顾主要的管理任务和安全性改进。
- en: UCP administration and security
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: UCP 管理和安全性
- en: UCP administrators manage Docker Swarm and Kubernetes clusters. They integrate
    external LDAP/AD authentication. Authentication can be delegated but UCP manages
    authorizations, as we learned in the *Role-based access control and isolation*
    section.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: UCP 管理员管理 Docker Swarm 和 Kubernetes 集群。他们集成外部 LDAP/AD 认证。认证可以委托，但 UCP 管理授权，正如我们在
    *基于角色的访问控制和隔离* 部分中学到的那样。
- en: 'The following screenshot shows the Admin Settings endpoint:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了管理员设置端点：
- en: '![](img/4236eb4d-0505-4dc0-ba92-9ea1cfa7eee4.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4236eb4d-0505-4dc0-ba92-9ea1cfa7eee4.png)'
- en: 'Docker Enterprise license can be introduced during installation, but it also
    can be manage from the web UI in Admin Settings. This endpoint also allow us to
    do the following administration tasks:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Enterprise 许可证可以在安装过程中引入，但也可以在管理员设置的 Web UI 中进行管理。此端点还允许我们执行以下管理任务：
- en: Rotate Docker Swarm's tokens to improve a cluster's security. Tokens are only
    used to join nodes to the cluster; we can change them whenever we need to.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮换 Docker Swarm 的令牌以提高集群的安全性。令牌仅用于将节点加入集群；我们可以在需要时更改它们。
- en: Manage Interlock's ports and enable publishing applications using this feature.
    We will talk about Interlock in [Chapter 12](ab131f1f-ca6e-4815-9a3a-8c92c93c9dbc.xhtml),
    *Publishing Applications in Docker Enterprise*.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理 Interlock 的端口并启用使用此功能发布应用程序。我们将在[第12章](ab131f1f-ca6e-4815-9a3a-8c92c93c9dbc.xhtml)中讨论
    Interlock，*Docker 企业版中的应用程序发布*。
- en: Configure some cluster configurations such as UCP's port and key-value database
    snapshots.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置一些集群配置，如 UCP 的端口和键值数据库快照。
- en: Integrate external LDAP and configure the default role to apply for new users
    and some session settings. This option delegates authentication to external LDAP/AD
    systems and UCP will just be used as an authentication cache if it is not available.
    We set user filters using attributes to only integrate subsets of users in the
    UCP environment. UCP synchronizes LDAP changes periodically.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成外部 LDAP 并配置新用户的默认角色和一些会话设置。此选项将身份验证委托给外部 LDAP/AD 系统，如果该系统不可用，UCP 将仅作为身份验证缓存。我们使用属性设置用户筛选器，以便仅集成
    UCP 环境中的部分用户。UCP 会定期同步 LDAP 更改。
- en: Change UCP's application and audit logging levels.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改 UCP 的应用程序和审计日志级别。
- en: Execute and configure backups from the web UI.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 Web UI 执行和配置备份。
- en: Integrate Docker Trusted Registry and Docker Content Trust to allow only signed
    images. This will be applied to all the nodes within the cluster.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成 Docker 受信注册表和 Docker 内容信任，只允许签名镜像。这将应用于集群中的所有节点。
- en: Set the default orchestrator for new nodes. We can choose between Docker Swarm,
    Kubernetes, and mixed mode.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为新节点设置默认编排器。我们可以选择 Docker Swarm、Kubernetes 或混合模式。
- en: Authorize administrators or users to execute workloads on UCP managers or worker
    nodes running DTR. We will decide who can run workloads on management nodes. It
    is recommended to avoid any non-control-plane workload on managers.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 授权管理员或用户在 UCP 管理节点或运行 DTR 的工作节点上执行工作负载。我们将决定谁可以在管理节点上运行工作负载。推荐避免在管理节点上运行非控制平面工作负载。
- en: Customize and launch platform upgrades. This will allow us to decide between
    a completely automated process and deploying manual upgrades to worker nodes to
    avoid impacting an application's service.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义并启动平台升级。这将允许我们在完全自动化的流程和部署手动升级到工作节点之间做出选择，以避免影响应用程序服务。
- en: It is recommended to disallow application workloads on UCP managers. These nodes
    should only run on the UCP system and DTR containers. This will avoid any application
    performance issues due to UCP's control plane. On the other hand, if any application
    component consumes too many resources, this will not affect the control plane.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐禁止在 UCP 管理节点上运行应用程序工作负载。这些节点应仅运行 UCP 系统和 DTR 容器。这样可以避免由于 UCP 控制平面导致的应用程序性能问题。另一方面，如果某个应用组件消耗了过多资源，控制平面也不会受到影响。
- en: Allowing only signed images in production is key. This will ensure image provenance
    and a CI/CD workflow. It is also possible to require some specific signs for images.
    For example, we can ensure that only images signed by `Operations Team`, `Developer's
    Chief`, and `IT manager` will run in production. This will apply to all the nodes
    in the cluster.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中只允许签名镜像至关重要。这将确保镜像的来源和 CI/CD 工作流。还可以要求某些特定的签名来标识镜像。例如，我们可以确保只有由 `运营团队`、`开发主管`
    和 `IT 经理` 签名的镜像才能在生产环境中运行。这将适用于集群中的所有节点。
- en: Many of UCP's and Kubernetes' features can be queried or modified via UCP's
    REST API. We should review the documentation at `https://<UCP_FQDN>[:443]/apidocs/`
    and `https://<UCP_FQDN>[:443]/kubernetesdocs/`.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: UCP 和 Kubernetes 的许多功能可以通过 UCP 的 REST API 查询或修改。我们应查看文档 `https://<UCP_FQDN>[:443]/apidocs/`
    和 `https://<UCP_FQDN>[:443]/kubernetesdocs/`。
- en: 'UCP also provides some Pod security policies that are applied by default on
    a Kubernetes cluster. These Pod security policies will do the following:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: UCP 还提供了一些在 Kubernetes 集群中默认应用的 Pod 安全策略。这些 Pod 安全策略将执行以下操作：
- en: Manage privileged containers
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理特权容器。
- en: Configure the host's namespaces (IPC, PID, network, and ports)
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置主机的命名空间（IPC、PID、网络和端口）。
- en: Manage the host's paths and their permissions and volume types
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理主机的路径及其权限和卷类型。
- en: Manage users and groups for the container process execution and `setuid` capabilities
    inside the container
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理容器进程执行的用户和组，以及容器内的`setuid`权限。
- en: Change the default container's capabilities
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改默认容器的权限。
- en: Integrate Linux security modules
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成 Linux 安全模块
- en: Allow host kernel configurations using `sysctl`
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许使用 `sysctl` 配置主机内核
- en: 'By default, only administrators will be able to deploy privileged containers
    in UCP''s Kubernetes. This is configured on a privileged Pod security policy.
    By default, UCP just provides two special policies, as we can see in the `kubectl
    get PodSecurityPolicies` output:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，只有管理员才能在 UCP 的 Kubernetes 中部署特权容器。这是在特权 Pod 安全策略中配置的。默认情况下，UCP 提供了两个特殊的策略，如我们在
    `kubectl get PodSecurityPolicies` 输出中看到的：
- en: '[PRE16]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You can read more about the Pod security policies included with Docker Enterprise
    and how to create new ones in the Kubernetes documentation or by going to this
    blog post: [https://www.mirantis.com/blog/understanding-kubernetes-security-on-docker-enterprise-3-0/](https://www.mirantis.com/blog/understanding-kubernetes-security-on-docker-enterprise-3-0/).'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 Kubernetes 文档中阅读更多关于 Docker Enterprise 包含的 Pod 安全策略及如何创建新策略的内容，或者访问此博客文章：[https://www.mirantis.com/blog/understanding-kubernetes-security-on-docker-enterprise-3-0/](https://www.mirantis.com/blog/understanding-kubernetes-security-on-docker-enterprise-3-0/)。
- en: Admission controllers are other valuable pieces in Kubernetes' security. They
    intercept Kubernetes API requests to allow or modify them before scheduling or
    executing any action. This allows us to enforce default security on resources,
    even if users try to execute an action that isn't allowed. Admission controllers
    are applied to the Kubernetes API process. Therefore, we should inspect the `ucp-kube-apiserver`
    container's command-line options to verify which admission controllers have been
    applied to our environment. As Kubernetes is not part of the DCA exam yet, we
    will stop here regarding this topic. But it is important to understand that Docker
    Enterprise applies security in Kubernetes using well-known Kubernetes mechanisms.
    UCP applies three special admission controllers to prevent anyone from removing
    core Kubernetes roles required by UCP, to ensure image signing if required, and
    to manage the execution of non-system Kubernetes Pods only on non-mixed nodes.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: Admission controllers（准入控制器）是 Kubernetes 安全性中的其他重要组件。它们拦截 Kubernetes API 请求，在调度或执行任何操作之前允许或修改这些请求。这样，我们可以强制在资源上应用默认的安全策略，即使用户尝试执行不被允许的操作。Admission
    controllers 被应用于 Kubernetes API 进程。因此，我们应该检查 `ucp-kube-apiserver` 容器的命令行选项，以验证哪些
    Admission controllers 已应用于我们的环境。由于 Kubernetes 目前尚未包含在 DCA 考试中，我们将在这个话题上停止讨论。但重要的是要理解，Docker
    Enterprise 使用公认的 Kubernetes 机制在 Kubernetes 中应用安全性。UCP 应用三个特殊的 Admission controllers，以防止任何人删除
    UCP 所需的核心 Kubernetes 角色，确保在需要时进行镜像签名，并仅在非混合节点上管理非系统 Kubernetes Pods 的执行。
- en: In the next section, we will review how to create and restore UCP's backups.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将回顾如何创建和恢复 UCP 的备份。
- en: Backup strategies
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 备份策略
- en: In this section, we will learn how to backup and restore the Docker Enterprise
    UCP platform.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将学习如何备份和恢复 Docker Enterprise UCP 平台。
- en: As UCP runs on top of Docker Swarm, this is the first component to review when
    preparing a good backup strategy.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 UCP 运行在 Docker Swarm 之上，因此在准备良好的备份策略时，这是第一个需要回顾的组件。
- en: We should run periodic backups of Docker Swarm. These backups will allow us
    to recover cluster configuration and workloads.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该定期备份 Docker Swarm。这些备份将允许我们恢复集群配置和工作负载。
- en: Docker Swarm's backup
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker Swarm 的备份
- en: We introduced how to execute a Docker Swarm backup in [Chapter 8](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml),
    *Orchestration Using Docker Swarm*. In that chapter, we described the content
    we should take care of. Let's learn about the steps to follow to implement a production-ready
    backup of Docker Swarm for the Docker Enterprise platform.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第8章](78af3b70-773d-4f5d-9835-71d1c15a104a.xhtml)中介绍了如何执行 Docker Swarm 备份，*使用
    Docker Swarm 进行编排*。在那一章中，我们描述了需要关注的内容。接下来，让我们了解实施 Docker Swarm 生产级备份的步骤，以便为 Docker
    Enterprise 平台做好准备。
- en: Make sure you have applied the auto-lock feature to improve secure access to
    Docker Swarm data as we will need it. The lock key will not be stored with a backup.
    You should store it in a safe place.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 确保已启用自动锁定功能，以提高对 Docker Swarm 数据的安全访问，因为我们将需要它。锁定密钥不会与备份一起存储。你应该将其存放在安全的地方。
- en: We will execute the backup steps on all non-leader manager nodes. This will
    ensure that any of the managers except the leader (at that moment) can be restored.
    In fact, it should not be easy to completely destroy a cluster, so backing up
    just a node should be fine. If all the clusters are completely lost, we will recover
    that node and then add others, as we did during the installation process. Your
    cluster health should not rely on backup-restore features. That is why we run
    the Raft protocol for cluster components syncing and running more than one manager
    node.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在所有非领导管理节点上执行备份步骤。这将确保除领导节点外的任何管理节点都可以恢复。事实上，完全摧毁一个集群不应该容易，因此仅备份一个节点应该是足够的。如果所有集群完全丢失，我们将恢复该节点，然后添加其他节点，就像安装过程中一样。你的集群健康状况不应依赖于备份恢复功能。这就是为什么我们运行
    Raft 协议来同步集群组件并运行多个管理节点。
- en: Application deployments and their configuration should be stored in code repositories,
    as we have recommended a couple of times in this book. Sometimes, it is even easier
    to deploy a new cluster and launch all the applications again using automation
    tools.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序部署及其配置应存储在代码库中，正如我们在本书中提到的几次一样。有时，使用自动化工具重新部署一个新的集群并再次启动所有应用程序更加容易。
- en: 'The following steps are recommended to create a good backup of Docker Swarm
    orchestrator data:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤建议用于创建 Docker Swarm 调度器数据的良好备份：
- en: Verify that the platform is healthy before executing this backup procedure.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在执行此备份过程之前，请验证平台是否健康。
- en: We will stop Docker Engine on the non-leader manager by executing `systemctl
    stop docker`.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将通过执行 `systemctl stop docker` 来停止非领导管理节点上的 Docker 引擎。
- en: 'Create a `.tar` file with `/var/lib/docker/swarm` directory content: `tar -cvzf
    "<DIRECTORY_FOR_YOUR_BACKUPS>/swarm-backup-$(hostname -s)-$(date +%y%m%d).tgz"
    /var/lib/docker/swarm/`.'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `/var/lib/docker/swarm` 目录内容创建一个 `.tar` 文件：`tar -cvzf "<DIRECTORY_FOR_YOUR_BACKUPS>/swarm-backup-$(hostname
    -s)-$(date +%y%m%d).tgz" /var/lib/docker/swarm/`。
- en: Start Docker Engine again executing `systemctl start docker`.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行 `systemctl start docker` 再次启动 Docker 引擎。
- en: We can execute this procedure on other non-leader manager nodes, although we
    will be able to restore Docker Swarm with one node only if the backup was successful.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以在其他非领导管理节点上执行此过程，但如果备份成功，我们将仅能通过一个节点来恢复 Docker Swarm。
- en: UCP runs on top of Docker Swarm. Let's review the required steps for backing
    up UCP.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: UCP 运行在 Docker Swarm 之上。让我们回顾一下备份 UCP 所需的步骤。
- en: Backing up UCP
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 备份 UCP
- en: 'Unlike in Docker Swarm, in UCP, there is no need to pause or stop any platform
    components to execute a backup. This feature is quite new. In older releases,
    components had to be paused on nodes while performing a backup. We will just execute
    this backup on a single node because UCP data will allow us to recover the entire
    cluster. But there are a few important notes about this backup:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Docker Swarm 不同，在 UCP 中，执行备份时无需暂停或停止任何平台组件。这个功能相当新。在旧版本中，备份执行时必须暂停节点上的组件。我们将只在单个节点上执行备份，因为
    UCP 数据将允许我们恢复整个集群。但关于这个备份有一些重要的注意事项：
- en: This backup does not include Docker Swarm deployed workloads, networks, configurations,
    or secrets.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该备份不包括 Docker Swarm 部署的工作负载、网络、配置或秘密。
- en: We cannot recover an updated UCP using a backup from an older release.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不能使用旧版本的备份来恢复更新后的 UCP。
- en: Neither `ucp-metrics-data` nor `ucp-node-certs` volumes are included.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ucp-metrics-data` 和 `ucp-node-certs` 卷不包含在备份中。'
- en: Kubernetes data will be covered in a UCP backup.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 数据将包含在 UCP 备份中。
- en: Neither Router Mesh's nor Interlock settings will be stored. Once the restored
    components have been redeployed, configurations will also be recovered.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无论是 Router Mesh 还是 Interlock 设置都不会被存储。一旦恢复的组件重新部署，配置也将被恢复。
- en: Backup content will be stored in a `.tar` file in a user-defined location. It
    can be secured using a passphrase.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备份内容将存储在一个 `.tar` 文件中，位置由用户定义。它可以通过密码短语进行保护。
- en: We can create UCP backups using the web UI, command line, or its API (on the
    latest releases).
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过 Web UI、命令行或其 API（在最新版本中）来创建 UCP 备份。
- en: 'Using the command line, we will need to use the `ucp` release container. For
    the current version at the time of writing this book, we will use the `docker/ucp:3.2.4`
    image. To create a backup from the command line, we will execute `docker container
    run docker/ucp:<RELEASE> backup`:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 使用命令行时，我们需要使用 `ucp` 发布容器。针对本书写作时的当前版本，我们将使用 `docker/ucp:3.2.4` 镜像。要通过命令行创建备份，我们将执行
    `docker container run docker/ucp:<RELEASE> backup`：
- en: '[PRE17]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In this example, we are not including UCP platform logs (they will be included
    by default). If SELinux is enabled, which is recommended, we will also add `--security-opt
    label=disable`.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们没有包括 UCP 平台日志（默认情况下会包括）。如果启用了 SELinux（推荐启用），我们还需要添加 `--security-opt
    label=disable`。
- en: Using the web UI, we will first navigate to Admin Settings. Then, we'll select
    Backup Admin, and finally, we'll click on Backup Now to immediately launch the
    backup execution.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Web UI，我们首先导航到管理员设置。然后，我们选择备份管理员，最后点击立即备份以立刻启动备份执行。
- en: We will not cover the API method in this book and how to verify backup content
    when the process has finished, but it is described on the Docker documentation
    website. It is also recommended to review the latest backup information provided
    at [https://docs.docker.com/ee/admin/backup/back-up-ucp/](https://docs.docker.com/ee/admin/backup/back-up-ucp/).
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中不会涉及 API 方法以及如何在流程完成后验证备份内容，但在 Docker 文档网站上有相关描述。建议查阅 [https://docs.docker.com/ee/admin/backup/back-up-ucp/](https://docs.docker.com/ee/admin/backup/back-up-ucp/)
    上提供的最新备份信息。
- en: 'To restore a UCP backup, we can start from one of these situations:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 要恢复 UCP 备份，我们可以从以下几种情况开始：
- en: We can start from scratch, restoring a UCP backup on a new, recently installed
    Docker Enterprise Engine.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以从头开始，在新安装的 Docker 企业引擎上恢复 UCP 备份。
- en: We can also recover a UCP backup on an initiated Docker Swarm, restoring UCP
    so that it has a new, fully functional cluster.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还可以在已启动的 Docker Swarm 上恢复 UCP 备份，从而恢复一个新的、完全功能的集群。
- en: We can restore UCP on the Docker Swarm cluster where it was created. We will
    just choose one of its manager nodes and run the recovery process after the previous
    UCP deployment is completely uninstalled. This is the only case where the previously
    created user's bundle will continue to work.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以在创建 UCP 的 Docker Swarm 集群上恢复 UCP。只需选择其中一个管理节点，在先前的 UCP 部署完全卸载后运行恢复过程。这是唯一一种先前创建的用户包仍然有效的情况。
- en: If recovery is started from scratch or using a new Docker Swarm cluster, the
    IP addresses and SAN that were used will not be valid. Therefore, we will need
    to regenerate server certificates after the UCP restore.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 如果从头开始恢复或使用新的 Docker Swarm 集群，之前使用的 IP 地址和 SAN 将无效。因此，我们需要在 UCP 恢复后重新生成服务器证书。
- en: After you have successfully restored UCP, you can add new managers and workers
    the same way you would after a fresh installation.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 成功恢复 UCP 后，您可以像全新安装后那样添加新的管理节点和工作节点。
- en: 'To restore a previously created backup, we will execute `docker container run
    docker/ucp:<RELEASE> restore`. We need to use the same image release that was
    used to create the backup. This is very important because we cannot restore from
    a different release:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 要恢复先前创建的备份，我们将执行 `docker container run docker/ucp:<RELEASE> restore`。我们需要使用与创建备份时相同的镜像版本。这一点非常重要，因为我们不能从不同版本恢复：
- en: '[PRE18]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: It is important to know that backup and restore are processes that you should
    execute when everything else is not working. We deploy UCP environments with high
    availability to avoid unexpected situations. You have to actively monitor your
    cluster environments and not leave unattended errors or alarms on monitoring systems.
    In the event of a manager node failure, a cluster will continue working, but we
    must reestablish a healthy status as soon as possible. From my experience, most
    of the issues found in production Docker Enterprise environments are related to
    filesystems growing without control, processes eating all the resources, or communication
    problems. Take care of these possible issues, monitor cluster health, and do periodic
    backups (and update their processes) to ensure you are able to recover your environment
    if everything fails.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要知道，备份和恢复是当其他一切都无法正常工作时需要执行的操作。我们部署高可用的 UCP 环境以避免突发情况。您必须积极监控集群环境，避免监控系统上出现未处理的错误或警报。如果发生管理节点故障，集群将继续工作，但我们必须尽快恢复健康状态。根据我的经验，生产环境中的大多数问题都与文件系统无限增长、进程消耗所有资源或通信问题有关。要关注这些潜在问题，监控集群健康，并定期备份（并更新备份流程），以确保在一切失败时能恢复环境。
- en: In the next section, we will learn what to monitor and how to check different
    components' statuses to avoid unnoticed failures.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习如何监控以及如何检查不同组件的状态，以避免未被察觉的故障。
- en: Upgrades, monitoring, and troubleshooting
  id: totrans-360
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级、监控与故障排除
- en: In this section, we will review how cluster upgrades must be deployed. We will
    work in a cluster environment. There are some steps to follow in order to execute
    platform updates without service interruption. Monitoring and troubleshooting
    are critical in production. We will learn about what important keys and values
    we should review to ensure a cluster's health and what steps we should follow
    to troubleshoot a degraded or faulty environment.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾集群升级必须如何部署。我们将在集群环境中进行操作。为了执行平台更新而不发生服务中断，需要遵循一些步骤。在生产环境中，监控和故障排除至关重要。我们将学习哪些重要的键和值应该进行检查，以确保集群的健康，并且我们应该遵循哪些步骤来排查降级或故障的环境。
- en: Upgrading your environment
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 升级你的环境
- en: 'We must review the Docker UCP release notes and upgrade procedure for each
    version. At the time of writing this book, the current release documentation is
    available on Docker''s website: [https://docs.docker.com/reference/ucp/3.2/cli/upgrade](https://docs.docker.com/reference/ucp/3.2/cli/upgrade).'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须查看每个版本的 Docker UCP 发布说明和升级程序。在编写本书时，当前版本的文档可以在 Docker 网站上找到：[https://docs.docker.com/reference/ucp/3.2/cli/upgrade](https://docs.docker.com/reference/ucp/3.2/cli/upgrade)。
- en: We should always perform a backup before any procedure, and we usually start
    by upgrading Docker Engine. You should review the Docker documentation to ensure
    that these steps are not changed between releases. Node upgrades should be done
    one at time. We will begin with non-leader manager nodes. Once all the managers
    have been upgraded, we will move the running services between different worker
    nodes to ensure minimal service interruption between upgrades.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何操作之前，我们应始终执行备份，通常我们会从升级 Docker 引擎开始。你应该查看 Docker 文档，以确保这些步骤在不同版本之间没有变化。节点的升级应逐个进行。我们将从非领导管理节点开始。一旦所有管理节点都完成升级，我们将把正在运行的服务在不同的工作节点之间迁移，以确保在升级过程中尽量减少服务中断。
- en: 'Once all the Docker Engine instances have been updated, we will start with
    the UCP upgrade. We can execute this process from the web UI and from the command
    line. We recommend following the command-line steps because the process will give
    you more information. We can execute this process offline if all the required
    images have been previously downloaded on all the nodes. We can check the required
    images at this link: [https://docs.docker.com/ee/ucp/admin/install/upgrade-offline/](https://docs.docker.com/ee/ucp/admin/install/upgrade-offline/).
    We will pre-load all the images using `docker image load -i <PACKAGE_WITH_ALL_IMAGES>.tar.gz`.'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有 Docker 引擎实例都已更新，我们将开始进行 UCP 升级。我们可以通过 Web UI 或命令行执行此过程。我们建议遵循命令行步骤，因为此过程将提供更多的信息。如果所有必需的镜像已事先下载到所有节点，我们可以离线执行此过程。我们可以通过以下链接查看所需镜像：[https://docs.docker.com/ee/ucp/admin/install/upgrade-offline/](https://docs.docker.com/ee/ucp/admin/install/upgrade-offline/)。我们将使用
    `docker image load -i <PACKAGE_WITH_ALL_IMAGES>.tar.gz` 预加载所有镜像。
- en: 'We will run `docker container run docker/ucp upgrade` with the appropriate
    arguments to upgrade our UCP environment. Docker Engine should be upgraded before
    executing this command:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用适当的参数运行 `docker container run docker/ucp upgrade` 来升级我们的 UCP 环境。在执行此命令之前，Docker
    引擎应该已经升级。
- en: '[PRE19]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: If your nodes work with more than one interface, we will also add `--host-address`
    with an appropriate IP address.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的节点使用多个接口，我们还需要添加 `--host-address` 并提供适当的 IP 地址。
- en: We can run and upgrade the process with the debug option, `--debug`, which is
    very useful for identifying errors if something goes wrong.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `--debug` 调试选项运行并升级该过程，如果出现问题，这非常有助于识别错误。
- en: There is an interesting option on the current release because we can upgrade
    workers manually using `--manual-worker-upgrade`. This helps us control the impact
    we have on services that are deployed in the environment.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 当前版本有一个有趣的选项，因为我们可以使用 `--manual-worker-upgrade` 手动升级工作节点。这帮助我们控制对环境中已部署服务的影响。
- en: All UCP processes will be upgraded in all nodes unless the `--manual-worker-upgrade`
    option is used. Once the upgrade process ends, the environment will be completely
    upgraded to the new release. At that moment, it is important to verify the health
    of the cluster.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 除非使用 `--manual-worker-upgrade` 选项，否则所有 UCP 进程将在所有节点上进行升级。升级过程结束后，环境将完全升级到新版本。此时，验证集群的健康状态非常重要。
- en: Monitoring a cluster's health
  id: totrans-372
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控集群健康状态
- en: We can use either the command line or the web UI to review the environment's
    health. We will use common Docker Swarm commands because we are running the environment
    on top of this orchestrator. We can review the node status with `docker node ls`.
    If we use the Docker UCP bundle to connect to the environment, we might miss some
    components. Make sure you are using an administrator user in the environment to
    be able to retrieve its health. Using the bundle, we can list all the control
    plane processes and use `docker container ls` to verify their statuses.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用命令行或 Web UI 来检查环境的健康状况。我们将使用常见的 Docker Swarm 命令，因为我们是在该调度器上运行环境的。我们可以通过
    `docker node ls` 来查看节点状态。如果我们使用 Docker UCP 包连接到环境，可能会错过一些组件。确保您使用的是管理员用户，以便能够获取其健康状况。使用该包时，我们可以列出所有控制平面进程，并使用
    `docker container ls` 来验证它们的状态。
- en: We can retrieve a manager's status from the `https://<ucp-manager-url>/_ping`
    endpoint, on each manager node's IP address or FQDN name. Requests to this URL
    can give us a `200` code if a node is healthy and a `500` code if there are some
    faulty components.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过每个管理节点的 IP 地址或 FQDN 名称，从 `https://<ucp-manager-url>/_ping` 端点获取管理节点的状态。对该
    URL 的请求可以返回 `200` 状态码表示节点健康，若有故障组件则返回 `500` 状态码。
- en: It is important to understand that this endpoint must be verified on each node
    because we are accessing the cluster through a load balancer to each manager.
    This configuration helps us provide high availability to the environment.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 需要理解的是，必须在每个节点上验证该端点，因为我们是通过负载均衡器访问每个管理节点的。此配置有助于为环境提供高可用性。
- en: 'The web UI also provides cluster status information. The Dashboard page shows
    us a clear status overview of the environment. This page includes counters for
    errors, warnings, or pending states for managers and workers. We will quickly
    notice errors on platform nodes. A performance summary for managers and worker
    nodes allows us to verify cluster sizing and its usage. We will also see information
    about deployed services on Docker Swarm and Kubernetes. This way, we can drill
    down to different UCP sections to deep dive into encountered errors. The following
    screenshot shows how the UCP Dashboard looks when showing the described platform
    overview:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: Web UI 还提供集群状态信息。仪表板页面为我们提供环境的清晰状态概览。此页面包括管理节点和工作节点的错误、警告或挂起状态计数器。我们可以快速发现平台节点的错误。管理节点和工作节点的性能摘要可以帮助我们验证集群的规模及其使用情况。我们还可以看到在
    Docker Swarm 和 Kubernetes 上部署的服务信息。通过这种方式，我们可以深入到不同的 UCP 部分，详细查看遇到的错误。以下截图展示了
    UCP 仪表板显示描述的平台概览时的样子：
- en: '![](img/5ef9dd82-827f-469c-a2ec-279470806946.png)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ef9dd82-827f-469c-a2ec-279470806946.png)'
- en: In each UCP resource section, we will see the resources' statuses, along with
    their properties. To monitor the cluster node's health, we will review the Nodes
    section, which can be found under Shared Resources. In this section, we will review
    the CPU and memory usage per node. This view will also help us find possible service
    degradation when node resource usage is too high.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个 UCP 资源部分，我们将看到资源的状态及其属性。为了监控集群节点的健康状况，我们将查看“节点”部分，该部分位于共享资源下。在此部分，我们将检查每个节点的
    CPU 和内存使用情况。此视图还将帮助我们在节点资源使用过高时发现可能的服务降级。
- en: Troubleshooting UCP
  id: totrans-379
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故障排除 UCP
- en: Throughout this chapter, we have been reviewing the main monitoring endpoints
    for UCP components. There are some critical endpoints in the cluster. We also
    described some database processes that manage important clusters' persistent data.
    These components run on managers and they replicate their data between them. It
    should be enough for the UCP environment, but sometimes, things can go wrong and
    they lose node synchronization. Network latency and performance problems can lead
    to these situations.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们一直在回顾 UCP 组件的主要监控端点。集群中有一些关键端点。我们还描述了一些管理重要集群持久数据的数据库过程。这些组件运行在管理节点上，并在它们之间复制数据。这些应该足够支持
    UCP 环境，但有时，可能会发生一些问题，导致节点之间的同步丢失。网络延迟和性能问题可能会导致这种情况的发生。
- en: Troubleshooting UCP-KV
  id: totrans-381
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 故障排除 UCP-KV
- en: 'If we lose some manager nodes, `ucp-kv` can show the incorrect number of nodes.
    We can check the number of configured nodes with `etcdctl`. We can execute `etcdctl`
    on the `ucp-kv` container directly:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们丢失了一些管理节点，`ucp-kv` 可能会显示不正确的节点数量。我们可以使用 `etcdctl` 检查配置的节点数量。我们可以直接在 `ucp-kv`
    容器上执行 `etcdctl`：
- en: '[PRE20]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This will show us `cluster is healthy` messages if the configured number of
    managers are healthy. If `ucp-kv` is unhealthy, we should review whether all the
    manager nodes are fine. If we deleted one manager but this change was not correctly
    updated on the other nodes, we could end up with an unhealthy cluster. To recover
    from this situation, we would need to remove the deleted node from the `etcd`
    database using `etcdctl member remove` (check the `etcd` documentation at [https://etcd.io/docs/v3.4.0/op-guide/runtime-configuration/](https://etcd.io/docs/v3.4.0/op-guide/runtime-configuration/)).
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 如果配置的管理节点数量健康，它将显示`cluster is healthy`消息。如果`ucp-kv`不健康，我们应检查所有管理节点是否正常。如果我们删除了一个管理节点，但该更改未能正确更新到其他节点，可能会导致集群不健康。要恢复此状态，我们需要使用`etcdctl
    member remove`从`etcd`数据库中删除已删除的节点（请参见[https://etcd.io/docs/v3.4.0/op-guide/runtime-configuration/](https://etcd.io/docs/v3.4.0/op-guide/runtime-configuration/)的`etcd`文档）。
- en: Update the component configurations and their states (deleting nodes, for example)
    one by one. Wait until the changes are synced in the cluster before executing
    a new update command.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 逐一更新组件配置及其状态（例如，删除节点）。在执行新的更新命令之前，等待更改在集群中同步。
- en: We can also have problems with the authentication database. In the next section,
    we will learn how to correct the number of nodes if we lose one manager node.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可能遇到认证数据库的问题。在下一部分，我们将学习如何在丢失一个管理节点的情况下，修正节点数量。
- en: Troubleshooting UCP-Auth
  id: totrans-387
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 故障排除UCP-Auth
- en: 'First, we will review the current number of healthy manager nodes. If some
    of them are still unhealthy, we should correct that situation first. Once the
    managers are healthy, if the authentication database continues to be in an inconsistent
    state, we will follow this procedure:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们会检查当前健康的管理节点数量。如果其中一些节点仍然不健康，我们应首先解决这个问题。管理节点恢复健康后，如果认证数据库仍处于不一致状态，我们将按照以下步骤进行操作：
- en: '[PRE21]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This command will run a `docker/ucp-auth` container using the RethinkDB `reconfigure-db`
    command to fix the right number of managers.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将使用RethinkDB的`reconfigure-db`命令运行一个`docker/ucp-auth`容器，以修复正确数量的管理节点。
- en: Troubleshooting nodes
  id: totrans-391
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 故障排除节点
- en: As we mentioned previously, network latency and performance can lead you to
    problematic situations. Take care of node resources and filesystems. If manager
    nodes become exhausted, the cluster will end up in an unhealthy state.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，网络延迟和性能问题可能会导致问题的出现。请注意节点资源和文件系统。如果管理节点资源耗尽，集群将会进入不健康状态。
- en: We can observe heartbeat failures if nodes cannot be contacted in 10 seconds.
    Worker nodes will reach a pending state if they cannot contact a manager node.
    We check these nodes locally. We also take a look at possible network or performance
    issues.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 如果节点无法在10秒内联系到，则会出现心跳失败的情况。如果工作节点无法联系到管理节点，它们将进入挂起状态。我们在本地检查这些节点，也会查看是否存在网络或性能问题。
- en: Managers can also become unhealthy. If other managers cannot reach them, `ucp-controller`
    processes will be impacted. We can check container logs for network issues.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 管理节点也可能变得不健康。如果其他管理节点无法访问它们，`ucp-controller`进程将会受到影响。我们可以检查容器日志以排查网络问题。
- en: These are some of the most common issues found on the Docker UCP platform. We
    usually start by reviewing the web UI dashboard and the `ucp-controller` container
    logs. If any other component seems unhealthy, we review its logs.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是Docker UCP平台上最常见的一些问题。我们通常从查看Web UI仪表板和`ucp-controller`容器日志开始。如果其他组件看起来不健康，我们会检查它们的日志。
- en: In the next chapter, we will learn how to publish applications deployed within
    the Docker Enterprise platform using the Interlock feature.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习如何使用Interlock功能发布部署在Docker Enterprise平台上的应用。
- en: Summary
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter covered the main Docker UCP features. We learned how to deploy
    a cluster with high availability and how to manage and deploy workloads using
    either UCP's web UI or the user bundle with the Docker and Kubernetes command
    line. We also introduced UCP's role-based access control, which helps us provide
    fine-grained access to cluster resources. We also took a look at the web UI and
    the main configurations available for managing Docker Enterprise's control plane.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了Docker UCP的主要功能。我们学习了如何部署具有高可用性的集群，并通过UCP的Web UI或用户捆绑包结合Docker和Kubernetes命令行来管理和部署工作负载。我们还介绍了UCP的基于角色的访问控制，它帮助我们精细化地管理集群资源的访问。我们还查看了Web
    UI和用于管理Docker Enterprise控制平面的主要配置。
- en: We also learned about UCP's components and how to deploy and manage Docker Enterprise's
    control plane and user resources in production. Finally, we learned how to ensure
    platform availability by verifying a cluster's components' status and executing
    backups.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还了解了 UCP 的组件，以及如何在生产中部署和管理 Docker Enterprise 的控制平面和用户资源。最后，我们学习了如何通过验证集群组件的状态和执行备份来确保平台的可用性。
- en: In the next chapter, we will learn how to publish a deployed application using
    Docker's integrated tools and features.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习如何使用 Docker 的集成工具和功能发布已部署的应用程序。
- en: Questions
  id: totrans-401
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Which of these sentences are true?
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪些句子是正确的？
- en: a) The Docker UCP installation process will also install the Docker Enterprise
    Engine on our hosts.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: a) Docker UCP 安装过程还将安装 Docker Enterprise Engine 到我们的主机上。
- en: b) UCP provides an integrated RBAC system that will help us to authenticate
    and authorize our users against its database.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: b) UCP 提供一个集成的 RBAC 系统，帮助我们在其数据库中进行用户身份验证和授权。
- en: 'c) Docker UCP provides two kinds of access: the web UI and the UCP bundle.'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: c) Docker UCP 提供两种访问方式：Web UI 和 UCP 套件。
- en: d) All of the above sentences are true.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: d) 上述所有句子都是正确的。
- en: Which of these sentences is not true about a `docker`/`ucp` image?
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪些句子关于 `docker`/`ucp` 镜像是错误的？
- en: a) This image will provide UCP's backup and restore.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: a) 该镜像将提供 UCP 的备份和恢复功能。
- en: b) We should always use the latest `docker`/`ucp` release version in our environment.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: b) 我们应该始终在我们的环境中使用最新的 `docker`/`ucp` 版本。
- en: c) Docker UCP can be completely removed using a `docker`/`ucp` image.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: c) 可以使用 `docker`/`ucp` 镜像完全删除 Docker UCP。
- en: d) The upgrade process must be executed manually on each cluster's node.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: d) 升级过程必须在每个集群节点上手动执行。
- en: What have we learned about the UCP installation process (which of the following
    is true)?
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从 UCP 安装过程学到了什么（以下哪项是正确的）？
- en: a) We can change the UCP controller and Kubernetes ports using special arguments.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: a) 我们可以使用特殊参数更改 UCP 控制器和 Kubernetes 端口。
- en: b) We can isolate the control plane using `--data-path-addr` to specify an interface
    or an IP address for the data plane.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: b) 我们可以使用 `--data-path-addr` 来指定数据平面使用的接口或 IP 地址，从而隔离控制平面。
- en: c) We can only have one subject alias name for the UCP environment and, by default,
    this will be the manager's IP address.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: c) 我们只能为 UCP 环境设置一个主题别名，默认情况下，这将是管理节点的 IP 地址。
- en: d) We will install UCP on the manager using the `docker/ucp install` procedure
    and then we will join worker nodes.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: d) 我们将在管理节点上使用 `docker/ucp install` 过程安装 UCP，然后加入工作节点。
- en: Which of the following is true about high availability in UCP?
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪项关于 UCP 高可用性是正确的？
- en: a) UCP is deployed on top of a Docker Swarm cluster, so we will need an odd
    number of nodes to provide high availability.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: a) UCP 部署在 Docker Swarm 集群之上，因此我们需要一个奇数个节点来提供高可用性。
- en: b) We will need to deploy Kubernetes with high availability once UCP is installed.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: b) 安装 UCP 后，我们需要部署高可用性的 Kubernetes。
- en: c) An external load balancer is required to distribute client requests between
    different nodes using a transparent-proxy (passthrough) to allow managers to provide
    end-to-end TLS tunnels.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: c) 需要外部负载均衡器，通过透明代理（passthrough）将客户端请求分配到不同的节点，以允许管理节点提供端到端的 TLS 隧道。
- en: d) We can check a manager's availability using the `https://<ucp-manager-url>/_ping`
    endpoint.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: d) 我们可以通过 `https://<ucp-manager-url>/_ping` 端点检查管理节点的可用性。
- en: Which one of these roles is not included in UCP by default?
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个角色在 UCP 中默认未包含？
- en: a) `Privileged`
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: a) `Privileged`
- en: b) `Full Control`
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: b) `Full Control`
- en: c) `Administrator`
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: c) `Administrator`
- en: d) `Scheduler`
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: d) `Scheduler`
- en: Further reading
  id: totrans-427
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Refer to the following links for more information regarding the topics that
    were covered in this chapter:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 有关本章所涵盖主题的更多信息，请参考以下链接：
- en: 'Universal Control Plane overview: [https://docs.docker.com/ee/ucp/](https://docs.docker.com/ee/ucp/)'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Universal Control Plane 概览：[https://docs.docker.com/ee/ucp/](https://docs.docker.com/ee/ucp/)
- en: 'Docker Enterprise architecture: [https://docs.docker.com/ee/docker-ee-architecture/](https://docs.docker.com/ee/docker-ee-architecture/)'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 企业架构：[https://docs.docker.com/ee/docker-ee-architecture/](https://docs.docker.com/ee/docker-ee-architecture/)
- en: 'Docker Enterprise products: [https://docs.docker.com/ee/supported-platforms/](https://docs.docker.com/ee/supported-platforms/)'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 企业产品：[https://docs.docker.com/ee/supported-platforms/](https://docs.docker.com/ee/supported-platforms/)
- en: 'UCP''s access control mode: [https://docs.docker.com/ee/ucp/authorization/](https://docs.docker.com/ee/ucp/authorization/)'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UCP 的访问控制模式：[https://docs.docker.com/ee/ucp/authorization/](https://docs.docker.com/ee/ucp/authorization/)
- en: 'Deploying applications on UCP''s Kubernetes: [https://docs.docker.com/ee/ucp/kubernetes/](https://docs.docker.com/ee/ucp/kubernetes/)'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在 UCP 的 Kubernetes 上部署应用程序: [https://docs.docker.com/ee/ucp/kubernetes/](https://docs.docker.com/ee/ucp/kubernetes/)'
- en: 'UCP access using the command line: [https://docs.docker.com/ee/ucp/user-access/cli/](https://docs.docker.com/ee/ucp/user-access/cli/)'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用命令行访问 UCP: [https://docs.docker.com/ee/ucp/user-access/cli/](https://docs.docker.com/ee/ucp/user-access/cli/)'
- en: 'Troubleshooting UCP node states: [https://docs.docker.com/ee/ucp/admin/monitor-and-troubleshoot/troubleshoot-node-messages/](https://docs.docker.com/ee/ucp/admin/monitor-and-troubleshoot/troubleshoot-node-messages/)'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '排查 UCP 节点状态问题: [https://docs.docker.com/ee/ucp/admin/monitor-and-troubleshoot/troubleshoot-node-messages/](https://docs.docker.com/ee/ucp/admin/monitor-and-troubleshoot/troubleshoot-node-messages/)'
- en: 'Docker UCP''s API: [https://docs.docker.com/reference/ucp/3.2/api/](https://docs.docker.com/reference/ucp/3.2/api/)'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Docker UCP 的 API: [https://docs.docker.com/reference/ucp/3.2/api/](https://docs.docker.com/reference/ucp/3.2/api/)'
- en: 'Docker Enterprise best practices and design considerations: [https://success.docker.com/article/docker-enterprise-best-practices](https://success.docker.com/article/docker-enterprise-best-practices)'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Docker Enterprise 最佳实践与设计考虑因素: [https://success.docker.com/article/docker-enterprise-best-practices](https://success.docker.com/article/docker-enterprise-best-practices)'
- en: 'Designing a disaster recovery strategy: [https://success.docker.com/article/dr-failover-strategy](https://success.docker.com/article/dr-failover-strategy)'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '设计灾难恢复策略: [https://success.docker.com/article/dr-failover-strategy](https://success.docker.com/article/dr-failover-strategy)'
