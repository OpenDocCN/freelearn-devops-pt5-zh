<html><head></head><body><div class="chapter" title="Chapter&#xA0;6.&#xA0;Continuous Deployment - A Fully Automated Workflow"><div class="titlepage"><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Continuous Deployment - A Fully Automated Workflow</h1></div></div></div><p>Welcome to the final stage of the CI workflow - the <span class="strong"><strong>Continuous Deployment</strong></span>.</p><p>We are now ready to take the AMI we produced during the Continuous Delivery step and deploy that to production.</p><p>For this process, we are going to use <span class="strong"><strong>blue/green deployment</strong></span> approach. Our production environment is going to consist of ELB and two Auto scaling Groups (blue and green):</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_001.jpg" alt="Continuous Deployment - A Fully Automated Workflow"/></div><p>
</p><p>If we assume that the blue group holds our current production nodes, then upon deployment, we do the following:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Attach ELB to the green group</li><li class="listitem">Scale the green group up using the new AMI</li><li class="listitem">Check for errors</li><li class="listitem">Scale the blue group down, effectively shifting traffic to the instances of the new AMI</li></ol></div><p>As we are building on top of our existing CI pipelines, there are only a few changes we need to make to the code from the previous chapter. We need to add a few extra Terraform resources; let us take a look at those.</p><div class="section" title="Terraform code (resources.tf)"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec22"/>Terraform code (resources.tf)</h1></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note58"/>Note</h3><p>Please refer to: <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_06_CodeFiles/Terraform/resources.tf">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_06_CodeFiles/Terraform/resources.tf</a> .</p></div></div><p>We add a second public and a matching private subnet so that we can distribute the production instances across multiple availability zones.</p><p>The <code class="literal">aws_subnet</code> resource creates a subnet named <code class="literal">public-2</code>. It takes attributes such as a VPC ID, CIDR BLOCK and AZs, the values of which we pull from variables. To compute the CIDR and AZ values we use Terraform's interpolation functions (ref: <a class="ulink" href="https://www.terraform.io/docs/configuration/interpolation.html">https://www.terraform.io/docs/configuration/interpolation.html</a>):</p><pre class="programlisting">resource "aws_subnet" "public-2" { &#13;
  vpc_id = "${aws_vpc.terraform-vpc.id}" &#13;
  cidr_block = "${cidrsubnet(var.vpc-cidr, 8, 3)}" &#13;
  availability_zone = "${element(split(",",var.aws-availability-zones), count.index + 1)}" &#13;
  map_public_ip_on_launch = true &#13;
 &#13;
  tags { &#13;
    Name = "Public" &#13;
  } &#13;
} &#13;
 &#13;
</pre><p>Next, we associate the newly created subnet with a routing table:</p><pre class="programlisting">resource "aws_route_table_association" "public-2" { &#13;
  subnet_id = "${aws_subnet.public-2.id}" &#13;
  route_table_id = "${aws_route_table.public.id}" &#13;
} &#13;
</pre><p>Then repeat for the <code class="literal">Private</code> subnet:</p><pre class="programlisting"> &#13;
resource "aws_subnet" "private-2" { &#13;
  vpc_id = "${aws_vpc.terraform-vpc.id}" &#13;
  cidr_block = "${cidrsubnet(var.vpc-cidr, 8, 4)}" &#13;
  availability_zone = "${element(split(",",var.aws-availability-zones), count.index +1)}" &#13;
  map_public_ip_on_launch = false &#13;
 &#13;
  tags { &#13;
    Name = "Private" &#13;
  } &#13;
} &#13;
 &#13;
resource "aws_route_table_association" "private-2" { &#13;
  subnet_id = "${aws_subnet.private-2.id}" &#13;
  route_table_id = "${aws_route_table.private.id}" &#13;
} &#13;
</pre><p>In this VPC, we are going to end up with subnets 1 and 3 public, and 2 and 4 private.</p><p>The next change is the addition of a prod ELB and a security group for it:</p><pre class="programlisting">resource "aws_security_group" "demo-app-elb-prod" { &#13;
  name = "demo-app-elb-prod" &#13;
  description = "ELB security group" &#13;
  vpc_id = "${aws_vpc.terraform-vpc.id}" &#13;
 &#13;
  ingress { &#13;
    from_port = "80" &#13;
    to_port = "80" &#13;
    protocol = "tcp" &#13;
    cidr_blocks = ["0.0.0.0/0"] &#13;
  } &#13;
 &#13;
</pre><p>Note the protocol value of <code class="literal">"-1"</code>, meaning "all":</p><pre class="programlisting">  egress { &#13;
    from_port = 0 &#13;
    to_port = 0 &#13;
    protocol = "-1" &#13;
    cidr_blocks = ["0.0.0.0/0"] &#13;
  } &#13;
 &#13;
} &#13;
 &#13;
resource "aws_elb" "demo-app-elb-prod" { &#13;
  name = "demo-app-elb-prod" &#13;
  security_groups = ["${aws_security_group.demo-app-elb-prod.id}"] &#13;
  subnets = ["${aws_subnet.public-1.id}", "${aws_subnet.public-2.id}"] &#13;
  cross_zone_load_balancing = true &#13;
  connection_draining = true &#13;
  connection_draining_timeout = 30 &#13;
 &#13;
  listener { &#13;
    instance_port = 80 &#13;
    instance_protocol = "http" &#13;
    lb_port = 80 &#13;
    lb_protocol = "http" &#13;
  } &#13;
 &#13;
  tags { &#13;
    Name = "demo-app-elb-prod" &#13;
  } &#13;
} &#13;
</pre><p>Let us also update the <code class="literal">demo-app</code> security group Ingress rules to allow traffic from the ELB. To help visualize, here is our earlier diagram with more labels:</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_002.jpg" alt="Terraform code (resources.tf)"/></div><p>
</p><p>And in code:</p><pre class="programlisting">resource "aws_security_group" "demo-app" { &#13;
  name = "demo-app" &#13;
  description = "ec2 instance security group" &#13;
  vpc_id = "${aws_vpc.terraform-vpc.id}" &#13;
 &#13;
  ingress { &#13;
    from_port = "80" &#13;
    to_port = "80" &#13;
    protocol = "tcp" &#13;
    security_groups = ["${aws_security_group.demo-app-elb.id}", "${aws_security_group.demo-app-elb-prod.id}"] &#13;
  }  &#13;
</pre><p>Then we introduce our blue/green <span class="strong"><strong>Auto Scaling Groups</strong></span> (<span class="strong"><strong>ASG</strong></span>) and a temporary launch configuration:</p><pre class="programlisting">resource "aws_launch_configuration" "demo-app-lcfg" { &#13;
    name = "placeholder_launch_config" &#13;
    image_id = "${var.jenkins-ami-id}" &#13;
    instance_type = "${var.jenkins-instance-type}" &#13;
    iam_instance_profile = "${aws_iam_instance_profile.demo-app.id}" &#13;
    security_groups = ["${aws_security_group.demo-app.id}"] &#13;
} &#13;
 &#13;
resource "aws_autoscaling_group" "demo-app-blue" { &#13;
  name = "demo-app-blue" &#13;
  launch_configuration = "${aws_launch_configuration.demo-app-lcfg.id}" &#13;
  vpc_zone_identifier = ["${aws_subnet.private-1.id}", "${aws_subnet.private-2.id}"] &#13;
  min_size = 0 &#13;
  max_size = 0 &#13;
 &#13;
  tag { &#13;
    key = "ASG" &#13;
    value = "demo-app-blue" &#13;
    propagate_at_launch = true &#13;
  } &#13;
} &#13;
 &#13;
resource "aws_autoscaling_group" "demo-app-green" { &#13;
  name = "demo-app-green" &#13;
  launch_configuration = "${aws_launch_configuration.demo-app-lcfg.id}" &#13;
  vpc_zone_identifier = ["${aws_subnet.private-1.id}", "${aws_subnet.private-2.id}"] &#13;
  min_size = 0 &#13;
  max_size = 0 &#13;
 &#13;
  tag { &#13;
    key = "ASG" &#13;
    value = "demo-app-green" &#13;
    propagate_at_launch = true &#13;
  } &#13;
} &#13;
</pre><p>The launch configuration here is really only a placeholder, so that we can define the Auto Scaling Groups (which is why we reuse the Jenkins variables). We are going to create a new, real launch configuration to serve the <code class="literal">demo-app</code> later on as part of the pipeline.</p><div class="section" title="outputs.tf"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec43"/>outputs.tf</h2></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note59"/>Note</h3><p>Please refer to: <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_06_CodeFiles/Terraform/outputs.tf">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_06_CodeFiles/Terraform/outputs.tf</a>.</p></div></div><p>A minor addition to the outputs, to give us the Production ELB endpoint:</p><pre class="programlisting">output "ELB URI PROD" { &#13;
  value = "${aws_elb.demo-app-elb-prod.dns_name}" &#13;
} &#13;
</pre><div class="section" title="Deployment"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec29"/>Deployment</h3></div></div></div><p>It is time for exercise. Using the earlier-mentioned templates and the rest of the familiar code from <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_06_CodeFiles">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_06_CodeFiles</a> plus your previous experience you should be able to bring up a VPC plus a Jenkins instance with two pipelines, exactly as we did in the chapter on Continuous Delivery. Do not forget to update any deployment-specific details such as the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The SSH public key in <code class="literal">salt:states:users:files</code></li><li class="listitem" style="list-style-type: disc">The authorized key in the <code class="literal">serverspec</code> test specification</li><li class="listitem" style="list-style-type: disc">The S3 URI in <code class="literal">salt:states:yum-s3:files:s3.repo</code></li><li class="listitem" style="list-style-type: disc">The S3 bucket name in <code class="literal">demo-app/Jenkinsfile</code></li><li class="listitem" style="list-style-type: disc">The variables in <code class="literal">packer:demo-app_vars.json</code></li><li class="listitem" style="list-style-type: disc">The variables in <code class="literal">demo-app-cdelivery/Jenkinsfile</code></li></ul></div><p>I would recommend you to disable the SCM Polling in the <span class="strong"><strong>demo-app</strong></span> job so that we don't trigger a run before all our downstream jobs have been configured.</p><p>Assuming that all went well, we are back where we left off:</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_003.jpg" alt="Deployment"/></div><p>
</p></div></div></div></div>
<div class="section" title="Jenkins pipelines"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec23"/>Jenkins pipelines</h1></div></div></div><p>Earlier we have our Integration and Delivery pipelines chained together, taking code and producing and AMI artifact. Our next task is to design a third pipeline to take that AMI and deploy it into our production environment.</p><p>Before we can create the new job in Jenkins, we need to make the code for it available via Git:</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note60"/>Note</h3><p>Please refer to: <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_06_CodeFiles/CodeCommit/demo-app-cdeployment">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/tree/master/5585_06_CodeFiles/CodeCommit/demo-app-cdeployment</a>.</p></div></div><p>We will examine the files in detail shortly, for now just create and populate a <code class="literal">demo-app-cdeployment</code> CodeCommit repository. Similar to our other repositories, the new one would have an URL such as <a class="ulink" href="https://git-codecommit.us-east-1.amazonaws.com/v1/repos/demo-app-cdeployment">https://git-codecommit.us-east-1.amazonaws.com/v1/repos/demo-app-cdeployment</a>.</p><p>With that in hand, we proceed to create the pipeline:</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_004.jpg" alt="Jenkins pipelines"/></div><p>
</p><p>It will need to take an <code class="literal">AMI ID</code> parameter (to be passed on from the Delivery job):</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_005.jpg" alt="Jenkins pipelines"/></div><p>
</p><p>Then of course, it needs the <code class="literal">Jenkinsfile</code> location (<a class="ulink" href="https://git-codecommit.us-east-1.amazonaws.com/v1/repos/demo-app-cdeployment">https://git-codecommit.us-east-1.amazonaws.com/v1/repos/demo-app-cdeployment</a>):</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_006.jpg" alt="Jenkins pipelines"/></div><p>
</p><p>With that final job ready, our Jenkins dashboard looks like this:</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_007.jpg" alt="Jenkins pipelines"/></div><p>
</p><div class="section" title="Continuous Deployment pipeline"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec44"/>Continuous Deployment pipeline</h2></div></div></div><p>Back to the code, as promised:</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note61"/>Note</h3><p>Please refer to <a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_06_CodeFiles/CodeCommit/demo-app-cdeployment/Jenkinsfile">https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_06_CodeFiles/CodeCommit/demo-app-cdeployment/Jenkinsfile</a>.</p></div></div><p>Our Jenkinsfile is rather simple:</p><pre class="programlisting">#!groovy &#13;
 &#13;
node { &#13;
   &#13;
  step([$class: 'WsCleanup']) &#13;
 &#13;
  stage "Checkout Git repo" { &#13;
    checkout scm &#13;
  } &#13;
 &#13;
  stage "Deploy AMI" { &#13;
   sh returnStdout: false, script: "bash ./cdeployment.sh ${AMI_ID}" &#13;
  } &#13;
 &#13;
} &#13;
</pre><p>We simply check out the associated repository and execute a shell script. Naturally, we could have coded the whole task in Groovy, but I personally am more used to Bash, hence the resulting <code class="literal">cdeployment.sh</code>.</p><p>We briefly described the deployment task in the beginning of this chapter. Generally speaking, we are going to be serving the application code from two separate clusters of instances and swap traffic from one to the other. We will use the extensive and user friendly AWS CLI to carry out most operations plus Bash to process any input/output data.</p><p>Let us dive into the script for more details.</p><div class="section" title="cdeployment.sh"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec30"/>cdeployment.sh</h3></div></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note62"/>Note</h3><p>Please refer to<a class="ulink" href="https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_06_CodeFiles/CodeCommit/demo-app-cdeployment/cdeployment.sh"> https://github.com/PacktPublishing/Implementing-DevOps-on-AWS/blob/master/5585_06_CodeFiles/CodeCommit/demo-app-cdeployment/cdeployment.sh</a>.</p></div></div><p>At the top, we define the names of our Auto Scaling Groups, the Production ELB, and the ID of the AMI, which we will be working with (passed on from the upstream pipeline):</p><pre class="programlisting">#!/bin/bash &#13;
set -ef -o pipefail &#13;
 &#13;
blueGroup="demo-app-blue" &#13;
greenGroup="demo-app-green" &#13;
elbName="demo-app-elb-prod" &#13;
AMI_ID=${1} &#13;
</pre><p>A couple of helper functions:</p><pre class="programlisting">function techo() {  &#13;
  echo "[$(date +%s)] " ${1} &#13;
} &#13;
 &#13;
function Err() { &#13;
  techo "ERR: ${1}" &#13;
  exit 100 &#13;
} &#13;
</pre><p>Namely, the <code class="literal">techo</code> (timestamped echo) for a more informative output and <code class="literal">ERR</code> for when we encounter problems.</p><p>If we need to abort a deployment and restore our infrastructure to its original state, we will use this:</p><pre class="programlisting">function rollback() { &#13;
  techo "Metrics check failed, rolling back" &#13;
  aws autoscaling update-auto-scaling-group --auto-scaling-group-name ${newActiveGroup} \ &#13;
  --min-size 0 &#13;
  techo "Instances ${1} entering standby in group ${newActiveGroup}" &#13;
  aws autoscaling enter-standby --should-decrement-desired-capacity \ &#13;
    --auto-scaling-group-name ${newActiveGroup} --instance-ids ${1} &#13;
  techo "Detaching ${elbName} from ${newActiveGroup}" &#13;
  aws autoscaling detach-load-balancers --auto-scaling-group-name ${newActiveGroup} \ &#13;
    --load-balancer-names ${elbName} &#13;
  Err "Deployment rolled back. Please check instances in StandBy." &#13;
} &#13;
</pre><p>In our case, we would abort if we detect an increase in the error count of certain metrics. We would put the newly deployed instances in <span class="strong"><strong>Standby</strong></span> mode then detach the ELB from the given Auto Scaling Group.</p><p>Every time we launch new instances, we should pause to allow those to fully initialize then verify what they have done so far and the following <code class="literal">wait_for_instances()</code>function will help us with this task.</p><p>Wait for the expected number of instances to launch:</p><pre class="programlisting">techo "&gt;&gt;&gt; Waiting for instances to launch" &#13;
asgInstances=() &#13;
 &#13;
while [ ${#asgInstances[*]} -ne ${1} ];do &#13;
  sleep 10 &#13;
  asgInstances=($(aws autoscaling describe-auto-scaling-groups \ &#13;
    --auto-scaling-group-name ${newActiveGroup} | jq .AutoScalingGroups[0].Instances[].InstanceId | tr -d '"' )) &#13;
  techo "Launched ${#asgInstances[*]} out of ${1}" &#13;
done &#13;
</pre><p>Wait for them to become available:</p><pre class="programlisting">techo "&gt;&gt;&gt; Waiting for instances to become available" &#13;
asgInstancesReady=0 &#13;
iterList=(${asgInstances[*]}) &#13;
 &#13;
while [ ${asgInstancesReady} -ne ${#asgInstances[*]} ];do &#13;
  sleep 10 &#13;
  for i in ${iterList[*]};do &#13;
    asgInstanceState=$(aws autoscaling describe-auto-scaling-instances \ &#13;
      --instance-ids ${i} | jq .AutoScalingInstances[0].LifecycleState | tr -d '"') &#13;
 &#13;
    if [[ ${asgInstanceState} == "InService" ]];then &#13;
      asgInstancesReady="$((asgInstancesReady+1))" &#13;
      iterList=(${asgInstances[*]/${i}/}) &#13;
    fi &#13;
  done &#13;
  techo "Available ${asgInstancesReady} out of ${#asgInstances[*]}" &#13;
done &#13;
</pre><p>Let the ELB declare them <code class="literal">InService</code>:</p><pre class="programlisting">techo "&gt;&gt;&gt; Waiting for ELB instances to become InService" &#13;
elbInstancesReady=0 &#13;
iterList=(${asgInstances[*]}) &#13;
 &#13;
while [ ${elbInstancesReady} -ne ${#asgInstances[*]} ];do &#13;
  sleep 10 &#13;
  for i in ${iterList[*]};do &#13;
    elbInstanceState=$(aws elb describe-instance-health \ &#13;
      --load-balancer-name ${elbName} --instances ${i} | jq .InstanceStates[].State | tr -d '"') &#13;
 &#13;
    if [[ ${elbInstanceState} == "InService" ]];then &#13;
      elbInstancesReady=$((elbInstancesReady+1)) &#13;
      iterList=(${asgInstances[*]/${i}/}) &#13;
    fi &#13;
  done &#13;
  techo "InService ${elbInstancesReady} out of ${#asgInstances[*]}"  &#13;
done &#13;
</pre><p>Next, since we know the region we will be working with, we set it in advance to avoid having to append it to each AWS CLI command:</p><pre class="programlisting">export AWS_DEFAULT_REGION="us-east-1" &#13;
</pre><p>Before going any further, we make sure that there is a valid <code class="literal">AMI ID</code> to work with:</p><pre class="programlisting">[[ ${AMI_ID} = ami-* ]] || Err "AMI ID ${AMI_ID} is invalid" &#13;
</pre><p>We will be working with two Auto Scaling Groups and one ELB, we check the properties of each group and extract the ELB name:</p><pre class="programlisting">blueElb=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names ${blueGroup} | \ &#13;
  jq .AutoScalingGroups[0].LoadBalancerNames[0] | tr -d '"') &#13;
greenElb=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names ${greenGroup} | \ &#13;
  jq .AutoScalingGroups[0].LoadBalancerNames[0] | tr -d '"') &#13;
</pre><p>Next, we ensure that only one of the groups has the Production ELB associated with it:</p><pre class="programlisting">[[ "${blueElb}" != "${greenElb}" ]] || Err "Identical ELB value for both groups" &#13;
 &#13;
if [[ "${blueElb}" == "${elbName}" ]]; then &#13;
  activeGroup=${blueGroup} &#13;
  newActiveGroup=${greenGroup} &#13;
elif [[ "${greenElb}" == "${elbName}" ]]; then &#13;
  activeGroup=${greenGroup} &#13;
  newActiveGroup=${blueGroup} &#13;
fi &#13;
 &#13;
[ -n "${activeGroup}" ] || Err "Missing activeGroup" &#13;
[ -n "${newActiveGroup}" ] || Err "Missing newActiveGroup" &#13;
 &#13;
techo "Active group: ${activeGroup}" &#13;
techo "New active group: ${newActiveGroup}" &#13;
</pre><p>At this point, we have established which of the two groups is currently serving traffic (<code class="literal">Active</code>) and the one to take over from it (<code class="literal">newActive</code>).</p><p>Ideally, the <code class="literal">newActive</code> will be empty, before we deploy any instances within it:</p><pre class="programlisting">asgInstances=($(aws autoscaling describe-auto-scaling-groups \ &#13;
    --auto-scaling-group-name ${newActiveGroup} | jq .AutoScalingGroups[0].Instances[].InstanceId | tr -d '"' )) &#13;
[ ${#asgInstances[*]} -eq 0 ] || Err "Found instances attached to ${newActiveGroup}!" &#13;
</pre><p>If that is so, we can proceed to get some stats from the <code class="literal">Active</code> group:</p><pre class="programlisting">activeDesired=$(aws autoscaling describe-auto-scaling-groups \ &#13;
  --auto-scaling-group-name ${activeGroup} | jq .AutoScalingGroups[0].DesiredCapacity) &#13;
activeMin=$(aws autoscaling describe-auto-scaling-groups \ &#13;
  --auto-scaling-group-name ${activeGroup} | jq .AutoScalingGroups[0].MinSize) &#13;
activeMax=$(aws autoscaling describe-auto-scaling-groups \ &#13;
  --auto-scaling-group-name ${activeGroup} | jq .AutoScalingGroups[0].MaxSize) &#13;
scaleStep=$(( (30 * ${activeDesired}) /100 )) &#13;
</pre><p>
<code class="literal">Desired</code>/<code class="literal">Min</code>/<code class="literal">Max</code> are the standard Auto Scaling values that we will end up transferring onto the <code class="literal">newActive</code> group. The <code class="literal">scaleStep</code>, in this case, 30% of the instances presumably in service, is the initial number of instances we would like to introduce (allowing them to receive live traffic) during the deployment.</p><p>It would be rather strange if our <code class="literal">Active</code> group is empty, otherwise should it have a low count, we round up the <code class="literal">scaleStep</code> to at least 1:</p><pre class="programlisting">[ ${activeDesired} -gt 0 ] || Err "Active group ${activeGroup} is set to 0 instances!" &#13;
 &#13;
[ ${scaleStep} -gt 0 ] || scaleStep=1 &#13;
</pre><p>Those were the prerequisites; now let us start the deployment by slowly scaling up the <code class="literal">newActive</code> group.</p><p>We would need a launch configuration. To create one, we can either pass all needed parameters ourselves or let EC2 copy most of those by providing an example instance from our <code class="literal">Active</code> group:</p><pre class="programlisting">activeInstance=$(aws autoscaling describe-auto-scaling-groups \ &#13;
  --auto-scaling-group-name ${activeGroup} | jq .AutoScalingGroups[0].Instances[0].InstanceId | tr -d '"') &#13;
 &#13;
[[ ${activeInstance} = i-* ]] || Err "activeInstance ${activeInstance} is invalid" &#13;
 &#13;
launchConf="demo-app-${AMI_ID}-$(date +%s)"  &#13;
 &#13;
aws autoscaling create-launch-configuration --launch-configuration-name ${launchConf} \ &#13;
  --image-id ${AMI_ID} --instance-id ${activeInstance} &#13;
</pre><p>Attach the newly created launch configuration to the group as follows:</p><pre class="programlisting">techo "&gt;&gt;&gt; Attaching ${launchConf} to ${newActiveGroup}" &#13;
aws autoscaling update-auto-scaling-group --auto-scaling-group-name ${newActiveGroup} \ &#13;
  --launch-configuration-name ${launchConf} &#13;
</pre><p>Add ELB as follows:</p><pre class="programlisting">techo "&gt;&gt;&gt; Attaching ${elbName} to ${newActiveGroup}" &#13;
aws autoscaling attach-load-balancers --auto-scaling-group-name ${newActiveGroup} \ &#13;
  --load-balancer-names ${elbName} &#13;
</pre><p>Start scaling up as follows:</p><pre class="programlisting">techo "&gt;&gt;&gt; Increasing ${newActiveGroup} capacity (min/max/desired) to ${scaleStep}" &#13;
aws autoscaling update-auto-scaling-group --auto-scaling-group-name ${newActiveGroup} \ &#13;
  --min-size ${scaleStep} --max-size ${scaleStep} --desired-capacity ${scaleStep} &#13;
</pre><p>Wait for a moment or two, for the instances to boot:</p><pre class="programlisting">wait_for_instances ${scaleStep} &#13;
</pre><p>Our initial batch of instances should now have been deployed, attached to the Production ELB, and started serving traffic. Before we launch even more copies of the new AMI, we ought to check that we have not caused any issues so far. One way to do this is to pause the deployment for a few minutes and examine metrics, such as number of non-200 responses, exceptions, or requests per second. For simplicity, in this example, we assume that this has been done; in real life, you would query your monitoring system(s) or perhaps pull samples of CloudWatch ELB/EC2 statistics.</p><p>If we do not detect any anomalies, we scale the <code class="literal">newActive</code> group further to match the size of the <code class="literal">Active</code> one:</p><pre class="programlisting">techo "&gt;&gt;&gt; Checking error metrics" &#13;
sleep 5 &#13;
doRollback=false &#13;
${doRollback} &amp;&amp; rollback "${asgInstances[*]}" &#13;
 &#13;
techo "&gt;&gt;&gt; Matching ${newActiveGroup} capacity (min/max/desired) to that of ${activeGroup}" &#13;
aws autoscaling update-auto-scaling-group --auto-scaling-group-name ${newActiveGroup} \ &#13;
  --min-size ${activeMin} --max-size ${activeMax} --desired-capacity ${activeDesired} &#13;
</pre><p>As you would expect, another check is in order:</p><pre class="programlisting">wait_for_instances ${activeDesired} &#13;
</pre><p>This time, we could simulate a problem and trigger a rollback:</p><pre class="programlisting">techo "&gt;&gt;&gt; Checking error metrics" &#13;
sleep 5 &#13;
doRollback=true &#13;
${doRollback} &amp;&amp; rollback "${asgInstances[*]}"</pre><p>The <code class="literal">rollback</code> function should take care of the rest. If we keep <code class="literal">doRollback</code> as <code class="literal">false</code>, our deployment continues as planned and we shift traffic completely from the <code class="literal">Active</code> to the <code class="literal">newActive</code> group by scaling the former down:</p><pre class="programlisting">techo "&gt;&gt;&gt; Reducing ${activeGroup} size to 0" &#13;
aws autoscaling update-auto-scaling-group --auto-scaling-group-name ${activeGroup} \ &#13;
  --min-size 0 --max-size 0 --desired-capacity 0 &#13;
</pre><p>And detach ELB from it:</p><pre class="programlisting">techo "&gt;&gt;&gt; Detaching ${elbName} from ${activeGroup}" &#13;
aws autoscaling detach-load-balancers --auto-scaling-group-name ${activeGroup} \ &#13;
  --load-balancer-names ${elbName} &#13;
</pre><p>Now, let us see our script in action. First, we should simulate an <code class="literal">Active</code> group by manually scaling up, say the blue one, and attach the Production ELB to it:</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_008.jpg" alt="cdeployment.sh"/></div><p>
</p><p>In a few moments, you should have three instances and ELB in blue:</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_009.jpg" alt="cdeployment.sh"/></div><p>
</p><p>Now, let us re-enable SCM polling for the <code class="literal">demo-app</code> job and trigger a run by pushing a code change to its CodeCommit repo. You should see the pipeline running, invoking the two downstream ones along the way.</p><p>If you choose to simulate a metrics problem and cause a rollback, then the deployed instances should end up in the <span class="strong"><strong>Standby</strong></span> mode:</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_010.jpg" alt="cdeployment.sh"/></div><p>
</p><p>In this case, the <code class="literal">rollback</code> was triggered after the initial deployment of one instance (<code class="literal">scaleStep=1</code>). Theoretically, the next step would be to investigate the instance looking for a possible cause for the error metrics.</p><p>If the instance is deemed healthy, then we would need to complete the deployment manually by bringing the instance into service, scaling the group up further, then scaling the other group down (essentially completing the remaining steps in the <code class="literal">cdeployment</code> script).</p><p>Otherwise, the instance can be put into service, then the group scaled down to zero, bringing the infrastructure back to its original state with the blue group remaining as <code class="literal">Active</code>.</p><p>Should you have chosen not to cause any rollbacks, the deployment ought to proceed as planned and in the end the green group would have taken over the blue one, indicating a successful deployment:</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_011.jpg" alt="cdeployment.sh"/></div><p>
</p><p>At this point, if you load the ELB URI in your browser, you should get a response from our <code class="literal">demo-app</code> as served from the newly deployed AMI.</p><p>Congratulations!</p></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec24"/>Summary</h1></div></div></div><p>In this chapter, we finalized our Jenkins CI solution by adding the Deployment component to it. We made extensive use of the AWS CLI to orchestrate a blue/green deployment process. The resulting pipeline or a collection of such allows us to continuously integrate our application's code changes and build an AMI containing those, which is then deployed to a given environment after certain tests have been passed and criteria met.</p><p>The next chapter takes us in a new direction, introducing the topic of monitoring, metrics, and log collection. We will take a look at tools that can help us stay aware of the state of our infrastructure at any given time, visualize performance, and react to issues.</p></div></body></html>