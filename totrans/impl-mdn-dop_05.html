<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Infrastructure as Code</h1>
                </header>
            
            <article>
                
<p>In the previous chapters, we demonstrated how the new cloud data centers can help us create online resources (virtual machines, Docker repositories, cryptographic keys) in a very easy way, shortening the hardware provisioning cycle from weeks (buying, shipping, and installing new computers) to seconds. We have also seen that there are different providers in the market that can offer us very similar features with different strong points that we can take advantage of when building our systems.</p>
<p>You learned how to create resources through the web interface that they offer, but how scalable is that? Creating resources manually prevents us from keeping an automated inventory of resources that can be used for security purposes as well as manage our infrastructure as if it were software components.<br/>
In this chapter, you are going to learn how to build resources in the cloud first, through the SDK provided by the cloud data center vendor and then by a software component called <strong>Terraform</strong>, which is an industry standard for managing online resources. We are going to focus on <strong>Google Cloud Platform</strong> for several reasons:<br/>
The command-line interface, in my opinion, is easier to use.<br/>
The Google Cloud Platform trial covers a good bunch of resources that you can use to experiment with throughout this book as you can create pretty much any resource in the full set of products.  <br/>
At the time of writing this (April 2017), Google Cloud Platform is the best value for money when it comes to cloud data centers.</p>
<p>That said, AWS, Azure or any other provider also offer a very interesting range of trial accounts, but unfortunately, we cannot cover everything in a single book.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Google Cloud Platform SDK -  gcloud</h1>
                </header>
            
            <article>
                
<p>Google offers us a very comprehensive SDK that can be used for operating Google Cloud Platform as well as  installing software components related to cloud operations.<br/>
The first thing we need to do is install <kbd>gcloud</kbd>.<br/>
There are installers for Windows but, in general, for Unix-based systems (Linux and Mac mainly), we have an interactive installer that can be executed from the command line and the unattended mode (for automatic provisioning).<br/>
The different options can be found at <a href="https://cloud.google.com/sdk/downloads">https://cloud.google.com/sdk/downloads</a>.<br/>
In order to install it (in my case, on Mac), the first thing we need to do is run the following command:</p>
<pre><strong>curl https://sdk.cloud.google.com | bash</strong></pre>
<p>This will initiate the interactive installed in the online mode: we will be asked a number of questions during the installation process.</p>
<p>The first one is the installation directory. By default, this is the home of the user, but you can change it to the folder of your choice. Once you have selected the folder, it will start downloading and installing the required base components.</p>
<p>The question is whether you want to help improve the Google Cloud SDK through the collection of anonymized data. Just answer as per your preferences.</p>
<p>Now, Google Cloud SDK will start installing the core components.</p>
<div class="CDPAlignCenter CDPAlign"><img height="262" width="443" class="image-border" src="assets/13becb56-24c0-43c8-9d40-e14659b503b0.png"/></div>
<p>As you can see in the preceding figure, <span>Google SDK</span> installs few packages that will be used to operate the basic services on Google Cloud Platform. Once it is finished (no need to do anything), it will ask you whether you want to modify the <kbd>PATH</kbd> variable of your system or not. Just reply <kbd>Y</kbd> and press <em>Enter</em> so that the <kbd>gcloud</kbd> command is available from the console. It will ask you in which file you want to modify the <kbd>PATH</kbd> variable. Usually, the default option that the installer provides you with is good enough. Before changing the file, the Google Cloud SDK installer will create a backup of the file with the same name with the <kbd>.backup</kbd> <span>extension</span> so you can revert the changes.<br/>
And we are done. It will ask you to start a new shell for the changes to take effect. Close your Terminal and open it again to check whether the <kbd>gcloud</kbd> command is available.<br/>
Now that we have installed Google Cloud SDK, it is time to configure the authentication. Execute the following command:</p>
<pre><strong>gcloud init</strong></pre>
<p>It will ask you to log in, so reply yes, which will open a browser window asking you to enter your Google credentials. Enter the ones associated with your trial account (if you didn't sign for the trial, do it before configuring your credentials). If you had a project already created in the Google Cloud Platform, it will ask you in the console to choose which one to use. In my case, I had one configured from <a href="6b4e8014-1c44-495b-b22b-e84fb1b944b8.xhtml" target="_blank">Chapter 2</a>, <em>Cloud Data Centers – The New Reality,</em> so I selected the one called <kbd>implementing-modern-devops</kbd> in my case.<br/>
The next topic is configuring the Google Compute Engine. Reply yes and select your availability zone. In my case, anywhere in Europe will work for me.<br/>
After this step, we are done. The prompt will tell us that we have a configuration called 'default' created. This means that the Google Cloud SDK can work with multiple credentials but, in this case, we are going to work with just one set of credentials and a single project.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating resources with Google Cloud SDK</h1>
                </header>
            
            <article>
                
<p>Once we are set up, it is time to start creating resources. As you can guess, the commands for creating resources can be <span>quite</span> complicated or extremely simple depending on your requirements. Luckily,  Google engineers have thought about it when creating the interface for Google Cloud Platform.</p>
<p>The first thing you need to do is log in to your Google Cloud Platform account. Once you are there, go to  <span class="packt_screen">Compute Engine</span> and fill the form to create a new resource. Enter the name of the instance, choose your closest region (Europe in my case), machine type (the default one will do), API access (we don't need that but the default is OK) and <span class="packt_screen">Allow HTTP traffic</span> and <span class="packt_screen">Allow HTTPS traffic</span>. Before clicking on create, take a look at the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img height="570" width="801" class="image-border" src="assets/a670c321-1e61-48ca-a059-276d7a0236ad.png"/></div>
<p>If you take a look at the very bottom, below the <span class="packt_screen">Create</span> button, there are two links:</p>
<ul>
<li><span class="packt_screen">REST</span> equivalent</li>
<li><span class="packt_screen">Command line</span></li>
</ul>
<p>For now, we are going to focus on the <span class="packt_screen">command line</span> link. Click on it and you should get a window with a few commands. Let's explain them:</p>
<pre><span>gcloud compute --project "implementing-modern-devops" instances create "test-instance" \<br/>               --zone "europe-west1-c" --machine-type "n1-standard-1" --subnet "default" \<br/>               --maintenance-policy "MIGRATE" \<br/>               --service-account "1085359944086-compute@developer.gserviceaccount.com"<br/>               --scopes \                     <br/>                    "https://www.googleapis.com/auth/devstorage.read_only", \<br/>                    "https://www.googleapis.com/auth/logging.write", \<br/>                    "https://www.googleapis.com/auth/monitoring.write", \<br/>                    "https://www.googleapis.com/auth/servicecontrol", \<br/>                    "https://www.googleapis.com/auth/service.management.readonly", \<br/>                    "https://www.googleapis.com/auth/trace.append" \ <br/>               --tags "http-server","https-server" --image "debian-8-jessie-v20170327" \<br/>               --image-project "debian-cloud" --boot-disk-size "10" --boot-disk-type "pd-standard" \<br/>               --boot-disk-device-name "test-instance"</span></pre>
<p>The first command creates the VM. As you can see, no one can expect to learn to create this command easily, but luckily, Google Cloud Platform provides it to you for every single resource that will be created for you so you can use the UI to generate the commands. That said, the preceding command sets every single potential setting that <strong>Google Cloud</strong> provides, so in other words, we will be able to run the preceding command with the same results no matter what settings we change in our cloud account.</p>
<p>There is a shorter version:</p>
<pre><strong>gcloud compute --project "implementing-modern-devops" instances create "test-instance"</strong></pre>
<p>This command does exactly the same as the very long command from earlier but assuming that the settings are the default (remember, you have <span>already</span> chosen some parameters, such as the default zone).</p>
<p>The other two commands are simpler:</p>
<pre><strong>gcloud compute --project "implementing-modern-devops" firewall-rules create "default-allow-http" --allow tcp:80 --network "default" --source-ranges "0.0.0.0/0" --target-tags "http-server"</strong></pre>
<p>Take a look at this too:</p>
<pre><strong>gcloud compute --project "implementing-modern-devops" firewall-rules create "default-allow-https" --allow tcp:443 --network "default" --source-ranges "0.0.0.0/0" --target-tags "https-server"</strong></pre>
<p>As you can guess, these commands allow the HTTP and the HTTPS traffic into our host as described in the UI form.</p>
<p>These are the basics of infrastructure as code. We could potentially write those commands on a bash script and off we go; our infrastructure is created automatically for us. In the same way, if we don't want to depend on Google Cloud SDK, we could choose the REST option that will show us the list of HTTP requests that we need to issue to Google Cloud in order to create the same resources. If you are familiar with languages such as Python, JavaScript (Node.js), and others, you know how easy is to issue HTTP requests in order to create the resources so you could manage your infrastructure as if it were code following the same life cycle.</p>
<p>This is a massive step forward in managing resources on the cloud, but it is still incomplete. Imagine this situation: you work in a company with a fairly complex setup, say, a few machines across different time zones and a fairly entangled network setup. How can you know at first glance which machines are running and what are the firewall rules are?</p>
<p>The answer is simple: it is not possible with what we know today. In the next section, you are going to learn how to use something called <strong>Terraform</strong> from HashiCorp in order to manage not only the creation, but also the complete life cycle of online resources on different cloud providers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Terraform</h1>
                </header>
            
            <article>
                
<p><strong>Terraform</strong> is a product developed by <strong>HashiCorp</strong>. HashiCorp is a company with a strong focus on DevOps tools such as Consul, a highly available distributed key value storage, or Vagrant, a tool to reproduce development environments using the same provisioners as production.</p>
<p>Terraform, as the name hints, allows you to create infrastructure in cloud data centers in a declarative way, keeping track of what was created where, allowing you to apply changes to the infrastructure from the code perspective: your infrastructure is described as the code and, as such, it can follow its life cycle.</p>
<p>The first thing we need to do is download and install Terraform. Just open the <a href="https://www.terraform.io/downloads.html">https://www.terraform.io/downloads.html</a> <span>URL</span> in a browser and select your platform, in my case, Mac. Terraform is a single binary compressed in a ZIP file (as far as I am aware, it is the same for every platform) that I unzip and place somewhere in my path, in my case, <kbd>in /usr/local/bin/terraform</kbd>.</p>
<div class="packt_tip">Be careful as some OSX setups do not include <kbd>/usr/local/bin/</kbd> in the PATH environment variable, so you might need to do it before being able to execute Terraform from any path.</div>
<p>Once it is installed and the <kbd>PATH</kbd> variable includes <kbd>/usr/local/bin/</kbd> as one of the values separated by semi colons, we can check whether everything works as expected:</p>
<pre><strong>terraform version</strong></pre>
<p>This should return the following output:</p>
<pre><strong>Terraform v0.9.4</strong></pre>
<p>This confirms that everything is correct. Also, be aware that DevOps tools move very quickly nowadays as they are required to do more things day by day. We are going to use the latest available version, 0.9.4, but by the time you are reading this book, a newer version might be available with new features and even some breaking changes. Luckily, Terraform comes with a very powerful documentation embedded in it. Let's look at all the available commands. Just execute this:</p>
<pre><strong>terraform</strong></pre>
<p>This should output something similar to the following:</p>
<div class="CDPAlignCenter CDPAlign">  <img height="415" width="450" class="image-border" src="assets/bd0e57a8-c830-4445-8c86-11004c148b2f.png"/></div>
<p>Now, in order to <span>display the help dialog on</span> any of the commands, we just need to execute the command with the flag <kbd>-h</kbd>. For example, let's display the help for <kbd>apply</kbd>:</p>
<pre><strong>terraform apply -h</strong></pre>
<p>It will output the list of all the options available for the command <span>in the prompt</span>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating resources</h1>
                </header>
            
            <article>
                
<p>Now that we have all the requirements installed, we are going to create our first resource in order to help us to understand how Terraform works and how powerful it is. Create a folder called <kbd>implementing-modern-devops</kbd> somewhere in your computer and add a file called <kbd>resources.tf</kbd> with the following content:</p>
<pre>provider "google" {<br/> credentials = "${file("xxx.json")}"<br/> project = "implementing-modern-devops"<br/> region = "europe-west1-b"<br/>}<br/><br/>resource "google_compute_instance" "my-first-instance" {<br/>}</pre>
<p>As you can see, <span>the preceding snipped</span> is very similar to JSON but it is actually called HCL: <span>HashiCorp</span> Configuration Language. Let's explain what the code is doing.</p>
<p>The first section is where we configure our credentials. As you can see, Terraform is expecting a file called <kbd>xxx.json</kbd>, which we don't have at the moment. If we check the official documentation of Terraform for Google Cloud Platform, it specifies that we need to create a <span class="packt_screen">Service account</span> from the API Manager section of the Google Cloud Platform, as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img height="342" width="618" class="image-border" src="assets/4bbdb6ed-997e-4caa-a022-cd899ba70420.png"/></div>
<p>Once we create it by choosing JSON as a format, a file will <span>automatically</span> be saved on our computer, containing the credentials that we need in order to operate Google Cloud Platform.</p>
<div class="packt_tip">Be careful. If you leak these credentials, someone could create or destroy resources on your behalf, which may lead to significant charges or data loss.</div>
<p>Copy the file to the previously created <span>folder</span> <em>(</em><kbd>implementing-modern-devops</kbd>) and rename it to <kbd>xxx.json</kbd> so it matches our configuration.</p>
<p>The second section is the description of our virtual machine, the instance to be created in Google Cloud. In this case, we are creating a resource called <kbd>my-first-instance</kbd> of the type <kbd>google_compute_instance</kbd>. We did not specify any configuration on purpose as I want to show you how to troubleshoot problems with Terraform, which, due to the high-quality error logs produced, is rather simple.</p>
<p>Let's see what happens. From the root of our project, the <kbd>implementing-modern-devops</kbd> <span>folder,</span> we run the following command:</p>
<pre><strong>terraform plan</strong></pre>
<p>This command will describe the steps required to create our infrastructure in Google Cloud. In this case, it is rather simple as we have only one machine, but it is going to be helpful to learn about Terraform.</p>
<p>Let's look at what happened and and how it has been explained in the output:</p>
<pre><strong>Errors:</strong><br/><br/><strong> * google_compute_instance.my-first-instance: "disk": required field is not set</strong><br/><strong> * google_compute_instance.my-first-instance: "name": required field is not set</strong><br/><strong> * google_compute_instance.my-first-instance: "machine_type": required field is not set</strong><br/><strong> * google_compute_instance.my-first-instance: "zone": required field is not set</strong></pre>
<p>The preceding command failed. Basically, our compute instance requires four fields that we did not specify: <kbd>machine_type</kbd>, <kbd>name</kbd>, <kbd>zone</kbd>, and <kbd>disk</kbd>. In this case, we can specify them, but if you need to check extra parameters, all the documentation for the resource <kbd>google_compute_instance</kbd> can be found at <a href="https://www.terraform.io/docs/providers/google/r/compute_instance.html">https://www.terraform.io/docs/providers/google/r/compute_instance.html</a>.</p>
<p>Visit it and read around to get familiar with it.</p>
<p>We are also going to specify the network interface (basically the network we want to connect to our machine) as it will fail later on in the <kbd>apply</kbd> command if we don't do it now.</p>
<p>Now, we are going to fix the problems that we found on the first run. Replace the <kbd>google_compute_instance</kbd> block with the following one:</p>
<pre>resource "google_compute_instance" "my-first-instance" {<br/> name = "my-first-instance"<br/> machine_type = "n1-standard-1"<br/> zone = "europe-west1-b"<br/> disk {<br/> image = "ubuntu-os-cloud/ubuntu-1704-zesty-v20170413"<br/> }<br/><br/> network_interface {<br/>   network = "default"<br/>   access_config {<br/>    // Ephemeral IP<br/>   }<br/> }<br/>}</pre>
<p>Go back to the Terminal and execute <kbd>terraform</kbd> plan' again. The output will be similar to this:</p>
<pre>+ google_compute_instance.my-first-instance<br/> can_ip_forward: "false"<br/> disk.#: "1"<br/> disk.0.auto_delete: "true"<br/> disk.0.image: "ubuntu-os-cloud/ubuntu-1704-zesty-v20170413"<br/> machine_type: "n1-standard-1"<br/> metadata_fingerprint: "&lt;computed&gt;"<br/> name: "my-first-instance"<br/> network_interface.#: "1"<br/> network_interface.0.access_config.#: "1"<br/> network_interface.0.access_config.0.assigned_nat_ip: "&lt;computed&gt;"<br/> network_interface.0.address: "&lt;computed&gt;"<br/> network_interface.0.name: "&lt;computed&gt;"<br/> network_interface.0.network: "default"<br/> self_link: "&lt;computed&gt;"<br/> tags_fingerprint: "&lt;computed&gt;"<br/> zone: "europe-west1-b"<br/><br/><br/>Plan: 1 to add, 0 to change, 0 to destroy.</pre>
<p>For space reasons, I have omitted an explanatory text that comes before the resource explanation but basically tells us that we can save this plan in a file in order to pass it as a parameter to the apply the command that we are going to run next.</p>
<p>This enables us to ensure that what is executed is what we have seen in the plan just in case someone else has modified the online infrastructure before calculating what needs to change, Terraform syncs the configuration in the resources files with the existing infrastructure in Google Cloud. So, it might be the case that we can execute <kbd>terraform plan</kbd>  and someone changes our cloud infrastructure (with another Terraform script or manually) and then our <kbd>terraform apply</kbd> command differs from the plan calculated.</p>
<p>Now once we have verified that our Terraform plan is to create a VM, execute the following command:</p>
<pre><strong>terraform apply</strong></pre>
<p>After a few seconds, the script should finish presenting the output of what was created, changed, or destroyed:</p>
<pre>google_compute_instance.my-first-instance: Creating...<br/> can_ip_forward: "" =&gt; "false"<br/><span>... (lines omitted: they should match the ones in the plan) ...</span><br/> zone: "" =&gt; "europe-west1-b"<br/>google_compute_instance.my-first-instance: Still creating... (10s elapsed)<br/>google_compute_instance.my-first-instance: Still creating... (20s elapsed)<br/>google_compute_instance.my-first-instance: Still creating... (30s elapsed)<br/>google_compute_instance.my-first-instance: Creation complete<br/><br/>Apply complete! Resources: 1 added, 0 changed, 0 destroyed.<br/><br/>The state of your infrastructure has been saved to the path<br/>below. This state is required to modify and destroy your<br/>infrastructure, so keep it safe. To inspect the complete state<br/>use the `terraform show` command.<br/><br/>State path: terraform.tfstate</pre>
<p>If everything went as per plan, we should have a file called <kbd>terraform.tfstate</kbd> in our folder which is the state of our virtual infrastructure created in the cloud. We also have the same file with the extension <kbd>backup</kbd>, which is the status of our infrastructure before running our last <kbd>apply</kbd> command.</p>
<p>This file is important. Terraform is able to refresh it with changes made on the cloud, but it is not able to rebuild it. Some people keep this file alongside the Terraform scripts and some other people prefer to use a backend to store this file and manage the Terraform state.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Remote state management</h1>
                </header>
            
            <article>
                
<p>A backend is a system that is going to store our status in a shared environment where everyone using the same configuration can quickly access it. Let's look at how is this done using <strong>Google Cloud Storage</strong>. Just execute the following command:</p>
<pre><strong>terraform remote config -backend=gcs -backend-config="bucket=my-terraform" -backend-config="path=terraform/infrastructure"</strong></pre>
<p>Here are a few considerations: we need to create a bucket called <kbd>my-terraform</kbd> in the Google Cloud Storage interface and we need to configure Application default credentials for Google Cloud. The easiest way to do this is by setting an environment variable called <span><kbd>GOOGLE_APPLICATION_CREDENTIALS</kbd> to the path where the <kbd>xxx.json</kbd> file that we have used to authenticate agai</span>nst GCP wh<span>en running our infrastructure is. If you are in the same folder, just run the following command:</span></p>
<pre><strong>export GOOGLE_APPLICATION_CREDENTIALS=./xxx.json</strong></pre>
<p>Once this is done and the Terraform command succeeds, if we check our bucket in Google Cloud Storage, we have a new item with the content of <kbd>terraform.tfstate</kbd> that we had in our local file system.</p>
<p>Now we can test that it works by altering our infrastructure and seeing how this is reflected in our bucket on Google Cloud Storage. You can do this easily by running <kbd>terraform destroy</kbd> and checking what happens to our remote state in Google Cloud.</p>
<div class="packt_tip">Be careful with the state files. They have very valuable information about your company's infrastructure and can be used as an attack vector.</div>
<p>This feature is used to share configuration across a team of engineers, and it is fully managed by Terraform: you don't need to pull or push state files as Terraform will do it for you.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Modifying your infrastructure</h1>
                </header>
            
            <article>
                
<p>Up until now, we have only created resources and stored the state of or cloud data center in an online bucket. Now you are going to learn how to modify the existing infrastructure from a project such as the one we built earlier on.</p>
<p>As you can see, we started from a very simple example: create a single virtual machine with an ephemeral IP address (the default one assigned by Google, not fixed).</p>
<p>Now, we are going to create a static IP and assign it to our machine so it always uses the same IP. The way of doing this through Terraform is creating a resource of the type <kbd>google_compute_address</kbd>, as follows:</p>
<pre>resource "google_compute_address" "my-first-ip" {<br/> name = "static-ip-address"<br/>}</pre>
<p>Now, we can execute <kbd>terraform plan</kbd> to see what will change if we apply the infrastructure change. As you can see in your new execution plan, Terraform identifies that we need to create a new resource of type <kbd>google_compute_address</kbd>, but... how do we attach this IP to our VM? Let's revisit the configuration of our VM:</p>
<pre>resource "google_compute_instance" "my-first-instance" {<br/> name = "my-first-instance"<br/> machine_type = "n1-standard-1"<br/> zone = "europe-west1-b"<br/> disk {<br/> image = "ubuntu-os-cloud/ubuntu-1704-zesty-v20170413"<br/> }<br/><br/> network_interface {<br/> network = "default"<br/> access_config {<br/><strong> nat_ip = "${google_compute_address.my-first-ip.address}"</strong><br/> } <br/>}</pre>
<p>In the highlighted line of the code, you can see how simple it is to associate our VM with the new address that we are going to create: our created resource, the address, will have computed attributes (attributes calculated at runtime) that can be used in other resources. In Terraform, the syntax for interpolating values is <kbd>${}</kbd> with the value of the attribute to interpolate between the brackets, in this case, the IP address of the resource called <kbd>my-first-ip</kbd>.</p>
<p>If you head to the Google Cloud Console and open the external IP's section, you can see something similar to what is shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/d9b35cc2-225e-44b6-b738-fd528e8d8d00.png"/></div>
<p>The IP was associated with our VM, as expected.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Terraform variables</h1>
                </header>
            
            <article>
                
<p>One thing we did not mention earlier is the fact that Terraform can work with variables. Take a look at the following definition:</p>
<pre>provider "google" {<br/> credentials = "${file("xxx.json")}"<br/> project = "implementing-modern-devops"<br/> region = "europe-west1"<br/>} </pre>
<p>This is the configuration of our provider. There are few strings that, quite likely, are going to be used in other places, such as the region or the name of the project. Terraform has the concept of variable, which is a value that is susceptible to change so we can extract it into a separated file. Up until now, we have created a file called <kbd>resources.tf</kbd>. Let's create a file called <kbd>vars.tf</kbd> with the following content:</p>
<pre>variable "project_name" {<br/> type = "string"<br/> default = "implementing-modern-devops"<br/>}<br/><br/>variable "default_region" {<br/> type = "string"<br/> default = "europe-west1"<br/>}</pre>
<p>Now, we are going to use these variables in our files. By default, <span><span>Terraform</span></span> will look into all the files with the extension <kbd>.tf</kbd> in our current folder, build the knowledge base of all the facts that have been described, and start creating our infrastructure as appropriated (internally building a graph of dependencies that can be checked with the <kbd>terraform graph</kbd> command). This means that we don't need to do anything special for Terraform to pick up our variables file:</p>
<pre>provider "google" {<br/> credentials = "${file("xxx.json")}"<br/> project = "${var.project_name}"<br/> region = "${var.default_region}"<br/>} </pre>
<p>We can use <span>variables</span> pretty much anywhere to facilitate our infrastructure creation. As you can see, the syntax is the same as the syntax used for interpolation; in fact, it is an interpolation.</p>
<p>In the variables file, we have specified the default values for the variables, but it is possible that we want to change them depending on the environment or even for tweaking the configuration. Terraform also allows you to override variables in three ways:</p>
<ul>
<li>On the command line</li>
<li>With a file called <kbd>terraform.tfvars</kbd></li>
<li>With environment variables</li>
</ul>
<p>The first way is as easy as passing extra flags to the <kbd>terraform</kbd> commands. For example, if we want to change <kbd>project_name</kbd> when applying the changes to our infrastructure, we just need to pass an extra flag with the value of the variable:</p>
<pre><strong>terraform apply -var 'project_name=my-new-name'</strong> </pre>
<p>And that's it. You can experiment by changing the project name or the zone and see how <kbd>terraform plan</kbd> creates new resources (as they don't exist <span>in a different project</span>).</p>
<p>The second method is using a file with the variable definitions. In order to test it, create a file called <kbd>terraform.tfvars</kbd> in the root of your project with the following content:</p>
<pre><strong>project_name = "my-new-project-name"</strong></pre>
<p>Now, if you run <kbd>terraform plan</kbd>, you will see how Terraform plans to create new resources as they don't exist in a project called <kbd>my-new-project-name</kbd>. <span>The filename does not need to be <kbd>terrafrom.tfvars</kbd>, but if you create it with a different name,</span> Terraform w<span>on't pick it up by default and you will need to pass the flag -var-file in order to load it.</span></p>
<div class="packt_tip">Don't forget to remove the <kbd>terraform.tfvars</kbd> <span>file</span> before continuing.</div>
<p>The third way of overriding variables is via environment variables. This is particularly interesting as it easily allows you to manage the configuration of different environments by external factors. The convention is to define an environment variable with the same name as the variable in Terraform but prefixing it with <kbd>TF_VAR_</kbd>. For example, for the variable <kbd>project_name</kbd>, we would execute the following command:</p>
<pre><strong>export TF_VAR_project_name=my-new-project-name</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Terraform outputs</h1>
                </header>
            
            <article>
                
<p>Up until now, we have worked with Terraform to create our infrastructure but we have little to no insight on what is going on in our cloud, in this case, on Google Cloud Platform. The engineers from HashiCorp have also thought about this, and they have created an element called output that allows us to print values of the resources created by our scripts.</p>
<p>So far, we have two files:</p>
<ul>
<li><kbd>resources.tf</kbd></li>
<li><kbd>variables.tf</kbd></li>
</ul>
<p>Before proceeding, make sure that your online infrastructure is created by running <kbd>terraform apply</kbd> as we did earlier.</p>
<p>Now, we are going to create another file called <kbd>outputs.tf</kbd>. This is not coincidental. In Terraform, this is the recommended layout for your projects as it facilitates the code readability as well as segregates responsibilities.</p>
<p>Add the following content to the <kbd>outputs.tf</kbd> <span>file:</span></p>
<div>
<pre><span>output</span><span> </span><span>"instance_ip"</span><span> </span><span>{<br/></span><span> </span><span>value</span><span> </span><span>=</span><span> </span><span>"</span><span>${google_compute_instance</span><span>.</span><span>my-first-instance</span><span>.</span><span>network_interface</span><span>.</span><span>0</span><span>.</span><span>access_config</span><span>.</span><span>0</span><span>.</span><span>nat_ip}</span><span>"<br/></span><span>}</span></pre></div>
<p>We will come back to this command later, but now, we need to rerun the apply <span>command</span> in order to let Terraform create the output for us. Something has changed:</p>
<pre>google_compute_address.my-first-ip: Refreshing state... (ID: static-ip-address)<br/>google_compute_instance.my-first-instance: Refreshing state... (ID: my-first-instance)<br/><br/>Apply complete! Resources: 0 added, 0 changed, 0 destroyed.<br/><br/>Outputs:<br/><br/>instance_ip = 23.251.138.171</pre>
<div class="packt_tip">Terraform apply needs to be run for your outputs for it to become available even if you did not change the infrastructure.</div>
<p>Now we can see a new section called outputs, which contain the values that we have defined in the outputs file. If you want to see it again at any time, just run the following command:</p>
<pre><strong>terraform output instance_ip</strong></pre>
<p>Alternatively, simply run this command:</p>
<pre><strong>terraform output</strong></pre>
<p>The first one will show only the IP of the instance (this is particularly handy for using it as input for other commands). The second one shows all the outputs defined in your Terraform scripts.</p>
<p>Now, let's explain how the outputs work. In this case, we have used the following string to identify what we want to output:</p>
<pre><strong>google_compute_instance.my-first-instance.network_interface.0.access_config.0.nat_ip</strong></pre>
<p>The first two keys (separated by dots) are clear: the type and the name of our resource. Then, the IP belongs to <kbd>network_interface</kbd> in the <kbd>acccess_config</kbd> <span>section</span> and the value is stored in <kbd>nat_ip</kbd><em>,</em> but what are those 0ses in there?</p>
<p>Easy; we can define more than one network interface by repeating the <kbd>network_interface</kbd> <span>block</span> as many times as you need: the first one in the code will be <kbd>0</kbd>, the second one will be <kbd>1</kbd>, and so on...</p>
<p>This attribute path can be tricky to calculate sometimes, although the majority of the time is quite obvious from the configuration file. If you experience problems finding what you want to output, here is a shortcut: When you run <kbd>terraform apply</kbd>, in the output, you will see something similar to this:</p>
<div class="CDPAlignCenter CDPAlign"><img height="377" width="930" class="image-border" src="assets/c5112bd1-3f03-4a48-9966-e10f8b3912ce.png"/></div>
<p>This is the list of all the attributes that you can show in your outputs; the key is the column on the left-hand side. For example, if we want to show the zone where our VM is created, it is as simple as this:</p>
<div>
<pre><span>output</span><span> </span><span>"instance_zone"</span><span> </span><span>{<br/></span><span> </span><span>value</span><span> </span><span>=</span><span> </span><span>"The</span><span> </span><span>zone</span><span> </span><span>is</span><span> ${google_compute_instance</span><span>.</span><span>my-first-instance</span><span>.</span><span>zone}</span><span>"<br/></span><span>}</span></pre></div>
<p>As you can see, the interpolation also works here, letting you mix strings with values of the Terraform resources.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Terraform is the basic tool that every DevOps engineer needs to master in order to work efficiently with cloud providers such as Google Cloud Platform or AWS as it allows you to manage the infrastructure as if code was, with a lifecycle the ability to deploy infrastructure.</p>
<p>In this chapter, we saw the most important aspects of Terraform regarding the creation of virtual infrastructure. You learned enough to be able to, with the help of the online documentation, create resources and connect them in order to create much bigger projects.</p>
<p>Even though the examples that we followed through this chapter were pretty basic, in the next chapter, we will create a more complex infrastructure and install the required software to run it in an automated fashion.</p>
<p>We will also use more advanced Terraform capabilities such as modules to create highly reusable components that can be shared with different teams or even as open source components.</p>
<p> </p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>