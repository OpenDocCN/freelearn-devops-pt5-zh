- en: Docker and Swarm Clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will review container technology and introduce Docker and
    its orchestration engine, as well as Docker Swarm mode. We will then discuss why
    we need a Docker infrastructure to deploy and run serverless and FaaS applications.
    The topics covered in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Containers and Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up a Docker Swarm cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing container networking with Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why Docker fits into the serverless and FaaS infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is a container?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before talking about Docker, it would be better to discuss the technology behind
    the software container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Virtual machines are a common virtualization technology and have been widely
    adopted by cloud providers and enterprise companies. Actually, a software container
    (or container for short) is also a kind of virtualization technology, but there
    is something different about them. The key difference is that every container
    shares the same kernel on the host machine, while each virtual machine has its
    own kernel. Basically, a container uses virtualization techniques at the level
    of the operating system, not the *hypervisor*. The following diagram shows a comparison
    between container and VM stacks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bc35c9d4-51bf-44b9-8e41-6e1635c6142b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: Containers versus virtual machines'
  prefs: []
  type: TYPE_NORMAL
- en: 'Linux''s container technology heavily relies on two important kernel capabilities,
    **namespace** and **cgroups**. Namespace puts a process into isolation so it has
    its own of set of global resources, such as PIDs and networks. Cgroups or control
    groups provide a mechanism for metering and limiting resources, such as CPU usage,
    memory, block I/O, and network bandwidth:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ba561123-d240-45cd-9872-c528f52bd817.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: Linux capabilities—namespaces and cgroups used by a container'
  prefs: []
  type: TYPE_NORMAL
- en: The core engine that uses the **namespaces** and **cgroups** capabilities of
    Linux is called **runC**. It is a tool for spawning and running containers in
    the **Open Container Initiative** (**OCI**) format. Docker plays a major role
    in drafting this spec, so the Docker container image is compatible with OCI specifications
    and therefore runnable by runC. The Docker Engine itself uses *runC* underneath
    to start each container.
  prefs: []
  type: TYPE_NORMAL
- en: What is Docker?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Containers in the past were quite difficult to manage and use. Docker is basically
    a set of technologies to help us prepare, manage, and execute containers. In the
    world of virtual machines, we need a hypervisor to take care of all VM instances.
    Similarly, in the world of containers, we use Docker as the *container engine* to
    take care of everything to do with containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Undeniably, Docker is the most popular container engine to date. When using
    Docker, we follow the three concepts build, ship, and run, recommended by Docker
    itself:'
  prefs: []
  type: TYPE_NORMAL
- en: The workflow of **Build**-**Ship**-**Run** is optimized by the philosophy of
    Docker. In the **Build** step, we are allowed to build and destroy container images
    rapidly. As developers, we can include the container building steps as a part
    of our development cycle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the **Ship** step, we ship container images to places, from our development
    laptops to the QA servers and to the staging servers. We send the container images
    to be stored in the public hub or to our private registry hub inside our company.
    Ultimately, we send our container images to run in the production environment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the **Run** step, Docker helps us prepare the production environment with
    Swarm clusters. We start containers from the container images. We may schedule
    containers to run at a specific part of the cluster with a certain set of constraints.
    We manage a container''s life cycle using Docker commands:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/415de6bb-86cd-47ac-893e-8972cd6a4187.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Build-ship-run'
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we follow the build-ship-run steps, we need to install Docker on our
    machine. On Linux, we use the classic installation method, **Docker Community
    Edition** (**CE** or **Docker-CE**):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Throughout the book, we will use a Debian or Ubuntu machine to demonstrate
    Docker. On a Debian/Ubuntu machine, we will get the most stable version of Docker
    (at the time of writing) via `apt-get` Docker back to version 17.06.2\. If we
    already have a newer version of Docker, such as 17.12 or 18.03, it will be downgraded
    to 17.06.2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'For macOS and Windows systems, we can download Docker from the Docker website:'
  prefs: []
  type: TYPE_NORMAL
- en: Docker for Mac: [https://www.docker.com/docker-mac](https://www.docker.com/docker-mac)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker for Windows: [https://www.docker.com/docker-windows](https://www.docker.com/docker-windows)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To check the installed version of Docker, we can use the `docker version` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The information printed out from the `docker version` is separated into two
    sections, client and server. The client section tells us information about the
    `docker` binary used to issue commands. The server section tells us the version
    of `dockerd`, the Docker Engine.
  prefs: []
  type: TYPE_NORMAL
- en: What we can see from the previous snippet is that both client and server are
    of version 17.06.2-ce*,* the second update of the stable 17.06 Community Edition.
    The server allows Docker client 1.12 as the minimum version to connect to. The *API
    version* tells us that `dockerd` implements remote API version 1.30.
  prefs: []
  type: TYPE_NORMAL
- en: If we expect to use the next stable version of Docker, we should go for the
    upcoming 17.06.3, 17.09.x, or 17.12.x versions.
  prefs: []
  type: TYPE_NORMAL
- en: Building a container image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We use Docker to prepare our software and its execution environment by packing
    them onto a file system. We call this step building a container image. OK, let's
    do this. We will build our own version of an NGINX server on Ubuntu, `my-nginx`,
    as a Docker image. Please note that the terms container image and Docker image
    will be used interchangeably throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a directory called `my-nginx` and change to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create a file named Dockerfile with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We will explain the contents of Dockerfile line by line:'
  prefs: []
  type: TYPE_NORMAL
- en: First, it says that we want to use the image named `ubuntu` as our base image.
    This `ubuntu` image is stored on the Docker Hub, a central image registry server
    hosted by Docker Inc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, it says that we want to install NGINX and related packages using the
    `apt-get` command. The trick here is that `ubuntu` is a plain Ubuntu image without
    any package information, so we need to run `apt-get update` before installing
    packages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Third, we want this image to open port `80`, *inside the container*, for our
    NGINX server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, when we start a container from this image, Docker will run the `nginx
    -g daemon off;` command inside the container for us.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We are now ready to build our first Docker image. Type the following command
    to start building an image. Please note that there is *dot* at the end of the
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You will now see something similar to the following output with different hash
    numbers, so don't worry. Steps 2 to 4 will take a couple of minutes to finish,
    as it will download and install NGINX packages into the image filesystem. Just
    make sure that there are four steps and it ends with the message `Successfully
    tagged my-nginx:latest`*:*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have a Docker image called `my-nginx:latest` locally on our machine.
    We can check that the image is really there using the `docker image ls` command
    (or `docker images` for the old-style, top-level command):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Basically, this is the *build* concept of Docker. Next, we continue with shipping
    images.
  prefs: []
  type: TYPE_NORMAL
- en: Shipping an image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We usually ship Docker images via a Docker registry. The public registry hosted
    by Docker Inc. is called **Docker Hub**. To ship a Docker image to a registry,
    we use the `docker push` command. When we start a container, its image will be
    automatically checked and downloaded to the host before running. The process of
    downloading can be explicitly done using the `docker pull` command. The following
    diagram illustrates the push/pull behavior among different environments and registries:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/307800e2-0f55-48a1-832e-0af3bdae7871.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Push and pull image workflow'
  prefs: []
  type: TYPE_NORMAL
- en: In the previous diagram, developers pull images from the Docker public registry
    (Docker Hub) then push and pull images from their own Docker private registry.
    In the development environment, each environment will be triggered by a mechanism
    to pull images there and run them.
  prefs: []
  type: TYPE_NORMAL
- en: To check that our Docker daemon is allowed to interact with a Docker registry
    insecurely over the non-encrypted HTTP, we do `docker info` then `grep` for the
    `Registries` keyword.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the insecure Docker registry is not recommended for a production
    environment. You have been warned!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: OK, seeing `127.0.0.0/8` means that we are allowed to do so. We will have a
    local Docker registry running at `127.0.0.1:5000`. Let's set it up.
  prefs: []
  type: TYPE_NORMAL
- en: 'To have a local Docker registry running, just run it from the Docker registry
    V2 image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We should check if it is now up and running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The details of `container run` and other commands will be discussed again in
    the *Running a container* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that we have built an image named `my-nginx`. We can check if it is
    still there; this time we use `--filter reference` to select only an image name
    ending with `nginx`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We can also shorten the command to `docker image ls *nginx`. It yields the same
    result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s tag the image. We will tag `my-nginx` to `127.0.0.1:5000/my-nginx` so
    it can be pushed into our private Docker registry. We can do this using the `docker
    image tag` command (`docker tag` for the old-style, top-level command):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check using `image ls` again to see that the `tag` command is done successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: OK, that looks great! We can now push the `my-nginx` image to the local repository,
    of course with `docker image push`, and the process will be very quick because
    the Docker repository is locally here on our machine.
  prefs: []
  type: TYPE_NORMAL
- en: Again, you will find that the hash number is not the same as in the following
    listing when you try the commands. It is harmless; please just ignore it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, execute the following command to push the `my-nginx` image onto the local
    private repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The hard part has already been done beautifully. We now go back to the simple
    part: pushing an image to Docker Hub. Before we continue, please sign up for your
    Docker ID at [https://hub.docker.com/](https://hub.docker.com/) if you don''t
    have one yet.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To store an image there, we have to tag the image with the `<docker id>/<image
    name>` format. For pushing `my-nginx` to the Docker Hub, we will `image tag` it
    to `<docker id>/my-nginx`. I''ll use my Docker ID there. Replace `<docker id>`
    with your registered Docker ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Before pushing, we need to log in to the Docker Hub first using the `docker
    login` command. Please use `-u` and your Docker ID to specify the account. We
    will be asked for a password; if everything is OK, the command will say `Login
    Succeeded`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Please note that our username and password are insecurely stored in `~/.docker/config.json`,
    so please do not forget to type `docker logout` whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: Running a container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let us run a container from our `my-nginx` image. We will use the `docker
    container run` command (the old, top-level command is `docker run`). This is done
    to run our container as a background process with `-d` and bind port `8080` of
    the host to port `80` of the container (`-p 8080:80`). We specified the container
    name with `--name`. If we run the container successfully, we will get a hash number,
    starting with `4382d778bcc9` in this example. It is the ID of our running container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Open the web browser and point it to `http://localhost:8080`; we will see the
    NGINX server running:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e9bd1da1-2c23-42fe-b61b-75c173ba1dca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: Example of NGINX running inside a container'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now our NGINX server is running as a background container serving on the host''s
    `8080` port. We can use the `docker container ls` command (or the old-style, top-level
    `docker ps`) to list all running containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We can control the life cycle of the container using the commands `docker container
    start`, `stop`, `pause`, or `kill`, for example.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we would like to force removal of running containers, we can use `docker
    container rm -f <container id or name>` to do so. Let''s remove all running instances
    of `my-nginx` and the private registry before continuing to play around with a
    Docker Swarm cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Docker Swarm clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A cluster is a group of machines connecting together to do work. A Docker host
    is a physical or virtual machine with the Docker Engine installed. We create a
    Docker Swarm cluster by connecting many Docker hosts together. We refer to each
    Docker host as a Docker Swarm node, simply a node.
  prefs: []
  type: TYPE_NORMAL
- en: In version 1.12, Docker introduced Swarm mode, a new orchestration engine to
    replace the old Swarm cluster, which is now referred to as **Swarm classic**.
    The main difference between Swarm classic and Swarm mode is that Swarm classic
    uses an external service, such as Consul, etcd, or Apache ZooKeeper as its key/value
    store, but Swarm mode has this key/value built in. With this, Swarm mode keeps
    orchestration latency at a minimum, and is more robust than Swarm classic because
    it does not need to interact with an external store. The monolithic nature of
    Swarm mode is good for making changes to its algorithms. For example, one of my
    research works implemented the Ant Colony optimization to improve how Swarm placing
    containers ran on non-uniform clusters.
  prefs: []
  type: TYPE_NORMAL
- en: From experiments at our laboratory, we have found that Swarm classic has limitations
    when scaling to 100–200 nodes. With Swarm mode, we have done experiments with
    the Docker community to show that it can scale to at least 4,700 nodes.
  prefs: []
  type: TYPE_NORMAL
- en: The results are publicly available at project Swarm2K ([https://github.com/swarmzilla/swarm2k](https://github.com/swarmzilla/swarm2k))
    and Swarm3K ([https://github.com/swarmzilla/swarm3k](https://github.com/swarmzilla/swarm3k))
    on GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: The key to the performance of Swarm mode is that it is built on top of the embedded
    *etcd* library. The embedded etcd library provides a mechanism for storing the
    state of a cluster in a distributed fashion. All state information is maintained
    in the Raft logs database with the Raft consensus algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we discuss how to set up a cluster in Swarm mode.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a fully functional single-node Swarm cluster, we just type the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We call this process Swarm cluster initialization. This process initializes
    the new cluster by preparing the `/var/lib/docker/swarm` directory to store all
    states related to the cluster. Here''s the contents of `/var/lib/docker/swarm`,
    which could be backed up if needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: If we have many network interfaces on the host, the previous command will fail
    as Docker Swarm requires us to specify an advertised address using an IP address,
    or a certain network interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, I use my `wlan0` IP address as the advertised address
    of the cluster. This means that any machine on the Wi-Fi network can try to join
    this cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we may advertise using the name of a network interface, for example, `eth0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Choose the style that works best for your working environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'After initialization, we get a fully working, single-node cluster. To force
    a node to leave the current cluster, we use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: If we run this command on a single-node cluster, the cluster will be destroyed.
    If you run the preceding command here, please do not forget to initialize the
    cluster again with `docker swarm init` before proceeding to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Masters and workers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recall that we used the term Docker host to refer to a machine with Docker installed.
    When we join these hosts together to form a cluster, sometimes we call each of
    them a Docker node.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Swarm cluster consists of two kinds of Docker nodes, a master and a worker.
    We say node `mg0` has the master role, and node `w01` has the worker role, for
    example. We form a cluster by joining other nodes to a master, usually the first
    master. The `docker swarm join` command requires the security tokens to be different,
    to allow a node to join as the master or as the worker. Please note that we must run
    the `docker swarm join` command on each node, not on the master node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: A master node is responsible for controlling the cluster. The best practice
    recommended by Docker is that odd numbers of master nodes are the best configurations.
    We should have an odd number of master nodes starting from three. If we have three
    masters, one of them is allowed to fail and the cluster will still work.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows the possible configurations, from one to six master
    nodes. For example, a cluster of three master nodes allows one master to fail
    and it still maintains the cluster. If two masters fail, the cluster will not
    be allowed to operate, starting or stopping services. However, in that state,
    the running containers will not die and continue to run:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Master nodes** | **Number of masters to maintain cluster** | **Failed masters
    allowed** |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 2 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 (best) | 2 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 3 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 (best) | 3 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 4 | 2 |'
  prefs: []
  type: TYPE_TB
- en: The best option to recover the cluster after losing the majority of master nodes
    is to bring the failed master nodes back online as fast as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the production cluster, we usually do not schedule running *tasks* on master
    nodes. A master node needs to have enough CPU, memory, and network bandwidth to
    properly handle node information and Raft logs. We control the cluster by commanding
    one of the master nodes. For example, we can list all nodes of a cluster by sending
    the following command to a master:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: What we see in the result is the list of all nodes in the current cluster. We
    can tell that the `mg0` node is a manager by looking at the `MANAGER STATUS` column.
    If a manager node is the primary manager of the cluster, `MANAGER STATUS` will
    say it is a `Leader`. If we have two more manager nodes here, the status will
    tell us they are a `Follower`. Here's how this leader/follower mechanism works.
    When we issue a command to the leader, the leader performs the command and the
    state of the cluster is changed. The cluster state is then updated by also sending
    this change to other manager nodes, that is, followers. If we issue a command
    to a follower, it will forward the command to the leader instead of doing that
    itself. Basically, all commands for the cluster will be performed by the leader,
    and the followers will update the changes to their internal Raft logs only.
  prefs: []
  type: TYPE_NORMAL
- en: 'If a new manager node would like to join, we require a master token for it.
    Type the `docker swarm join-token manager` command to obtain a security token
    to join a cluster in a manager role:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Although a task as a container can be running on both kinds of nodes, we usually
    do not submit tasks to run on master nodes. We only use worker nodes to run tasks
    in production. To join worker nodes to the cluster, we pass the worker token to
    the join command. Use `docker swarm join-token worker` to obtain a worker token.
  prefs: []
  type: TYPE_NORMAL
- en: Services and tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Along with the new orchestration engine, Docker introduced the new abstraction
    of services and tasks in version 1.12\. A service may consist of many instances
    of a task. We call each instance a replica. Each instance of a task runs on a
    Docker node in the form of a container.
  prefs: []
  type: TYPE_NORMAL
- en: 'A service can be created using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This web service consists of three tasks, specified with `--replicas`. These
    tasks are submitted by the orchestration engine to run on selected nodes. The
    service's name, web, can be resolved using a virtual IP address. Other services
    on the same network, in this case maybe a reverse proxy service, can refer to
    it. We use `--name` to specify the name of the service.
  prefs: []
  type: TYPE_NORMAL
- en: 'We continue the discussion of the details of this command in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/84e841b0-684c-4ebd-bd57-9b4ebb6fcad2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Swarm cluster in action'
  prefs: []
  type: TYPE_NORMAL
- en: We assume that our cluster consists of one manager node and five worker nodes.
    There is no high availability setup for the manager; this will be left as an exercise
    for the reader.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start at the manager. The manager is set to be *drained *because we do not
    want it to accept any scheduled tasks. This is the best practice, and we can drain
    a node as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This service will be published to port `80` on the routing mesh. The routing
    mesh is a mechanism to perform load balancing inside the Swarm mode. Port `80`
    will be opened on every worker node to serve this service. When a request comes
    in, the routing mesh will route the request to a certain container (a task) on
    a certain node, automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'The routing mesh relies on a Docker network with the overlay driver, namely
    `ingress`. We can use `docker network ls` to list all active networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We find a network with ID `ve7fj61ifakr` which is an `overlay` network of the
    `swarm` scope. As the information implies, this kind of network is working only
    in Docker Swarm mode. To see the details of this network, we use the `docker network
    inspect ingress` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the `ingress` network has a subnet of `10.255.0.0/16`*,* which
    means that we are allowed to use 65,536 IP addresses in this network by default.
    This number is the maximum number of tasks (containers) created by `docker service
    create -p` on a single Swarm mode cluster. This number is not affected when we
    use `docker container run -p` outside the Swarm.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a Swarm scoped overlay network, we use the `docker network create`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check again with the `docker network ls` command and see the `appnet`
    network with the `overlay` driver and `swarm` scope there. Your network''s ID
    will be different. To attach a service to a specific network, we can pass the
    network name to the `docker service create` command. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The preceding example creates the `web` service and attaches it to the `appnet`
    network. This command works if, and only if, the appnet is Swarm-scoped.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can dynamically detach or re-attach net networks to the current running
    service using the `docker service update` command with `--network-add` or `--network-rm`,
    respectively.  Try the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can observe the result with `docker inspect web`. You will find a
    chunk of JSON printed out with the last block looking as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'It means that the service has been updated and the process of updating has
    been completed. We will now have the `web` service attaching to the `appnet` network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ad6e3d1-fe1b-4f0f-b7c1-06c518a949c4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.7: The Gossip communication mechanism for Swarm-scope overlay networks'
  prefs: []
  type: TYPE_NORMAL
- en: Overlay networks rely on the **gossip** protocol implementation over port `7946`,
    for both TCP and UDP, accompanied by Linux's VXLAN over UDP port `4789`. The overlay
    network is implemented with performance in mind. A network will cover only the
    necessary hosts and gradually expand when needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can scale a service by increasing or decreasing the number of its replicas.
    Scaling the service can be done using the `docker service scale` command. For
    example, if we would like to scale the `web` service to five replicas, we could
    issue the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'When the service is scaled, and its task is scheduled on a new node, all related
    networks bound to this service will be expanded to cover the new node automatically.
    In the following diagram, we have two replicas of the app service, and we would
    like to scale it from two to three with the command `docker service scale app=3`.
    The new replica **app.3** will be scheduled on the worker node **w03**. Then the
    overlay network bound to this app service will be expanded to cover node **w03**
    too. The network-scoped gossip communication is responsible for the network expansion
    mechanism:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64ed8f48-8d3e-40e3-98fd-1605048c9fb8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.8: Swarm-scoped network expansion'
  prefs: []
  type: TYPE_NORMAL
- en: Docker and serverless
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How will Docker benefit us? When dealing with application development, Docker
    can be used to simplify the development toolchain. We can pack everything we need
    to write serverless applications into a single container image and let the whole
    team use it. This ensures consistency of tool versions and ensures they will not
    mess up our development machines.
  prefs: []
  type: TYPE_NORMAL
- en: We will then use Docker to prepare our infrastructure. Actually, the term serverless
    means developers should not maintain their own infrastructure. However, in cases
    where the public cloud is not an option, we can use Docker to simplify infrastructure
    provisioning. Using the same architecture as the third-party serverless platforms
    on our company's infrastructure, we can minimize the operation and maintenance
    costs. Later chapters will discuss how we can operate our own Docker-based FaaS
    infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: For the serverless application itself, we use Docker as a wrapper for serverless
    functions. We use Docker as a unit of work, so that any kind of binary can be
    integrated into our serverless platform, ranging from the legacy COBOL, C, or
    Pascal programs to the programs written in modern languages, such as Node.js,
    Kotlin, or Crystal. In the 17.06+ versions of Docker, it is also possible to form
    a Swarm cluster across multi-hardware architecture. We can even host Windows-based
    C# functions on the same cluster as mainframe-based COBOL programs.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To help you better remember and understand the concepts and practices of Docker
    described in this chapter, try answering the following questions without going
    back to the chapter''s contents. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: What are containers? What's the key difference between containers and virtual
    machines?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the main features inside the Linux kernel to enable container technology?
    Please name at least two of them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the key concepts of the Docker workflow?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a Dockerfile for? Which Docker command do you use to interact with it?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the ENTRYPOINT instruction inside a Dockerfile?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which command do we use to list all Docker images?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which command do we use to form a Docker Swarm cluster?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the key difference between Swarm classic and Swarm mode?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Please explain the relationship between services and tasks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we create an NGINX service with five replicas?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we scale down the number of the NGINX services to two?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the minimum number of nodes required to form a Swarm cluster with the
    high-availability property? Why?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the name for a network that is part of the routing mesh? How large is
    it?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which port numbers are used by a Swarm cluster? What are they for?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the main benefit of network-scoped Gossip communication?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter started off by discussing the concepts of containers. Then we reviewed
    what Docker is, how to install it, and the Docker build, ship, and run workflow.
    We then learnt how to form a Docker Swarm cluster and Swarm master and worker
    nodes. We learnt how to properly set up a robust Swarm cluster with an odd number
    of master nodes. We then learnt the service and task concepts of Docker Swarm.
    Finally, we learnt how Docker fits into serverless application development.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will review serverless frameworks and platforms to understand
    the overall architecture and the limitations of them.
  prefs: []
  type: TYPE_NORMAL
