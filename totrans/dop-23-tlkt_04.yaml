- en: Scaling Pods With ReplicaSets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most applications should be scalable and all must be fault tolerant. Pods do
    not provide those features, ReplicaSets do.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: We learned that Pods are the smallest unit in Kubernetes. We also learned that
    Pods are not fault tolerant. If a Pod is destroyed, Kubernetes will do nothing
    to remedy the problem. That is, if Pods are created without Controllers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The first Controller we'll explore is called *ReplicaSet*. Its primary, and
    pretty much only function, is to ensure that a specified number of replicas of
    a Pod matches the actual state (almost) all the time. That means that ReplicaSets
    make Pods scalable.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: We can think of ReplicaSets as a self-healing mechanism. As long as elementary
    conditions are met (for example, enough memory and CPU), Pods associated with
    a ReplicaSet are guaranteed to run. They provide fault-tolerance and high availability.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: It is worth mentioning ReplicaSet is the next-generation ReplicationController.
    The only significant difference is that ReplicaSet has extended support for selectors.
    Everything else is the same. ReplicationController is considered deprecated, so
    we'll focus only on ReplicaSet.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: ReplicaSet's primary function is to ensure that the specified number of replicas
    of a service are (almost) always running.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Let's explore ReplicaSet through examples and see how it works and what it does.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: The first step is to create a Kubernetes cluster.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Cluster
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll continue using Minikube to simulate a cluster locally.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: All the commands from this chapter are available in the `04-rs.sh` ([https://gist.github.com/vfarcic/f6588da3d1c8a82100a81709295d4a93](https://gist.github.com/vfarcic/f6588da3d1c8a82100a81709295d4a93))
    Gist.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We created a single-node cluster and configured `kubectl` to use it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Before we explore the first ReplicaSet example, we'll enter into the local copy
    of the `vfarcic/k8s-spec` repository and pull the latest version. Who knows, maybe
    I added some new stuff since the last time you checked it out.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now that the cluster is running and the repository with the specs is up-to-date,
    we can create our first ReplicaSet.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Creating ReplicaSets
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s take a look at a ReplicaSet based on the Pod we created in the previous
    chapter:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output is as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `apiVersion`, `kind`, and `metadata` fields are mandatory with all Kubernetes
    objects. ReplicaSet is no exception.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: We specified that the `apiVersion` is `apps/v1beta2`. At the time of this writing,
    ReplicaSet is still in beta. Soon it will be considered stable, and you'll be
    able to replace the value with `apps/v1`. The `kind` is `ReplicaSet` and `metadata`
    has the `name` key set to `go-demo-2`. We could have extended ReplicaSet `metadata`
    with labels. However, we skipped that part since they would serve only for informational
    purposes. They do not affect the behavior of the ReplicaSet.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: You should be familiar with the three fields since we already explored them
    when we worked with Pods. In addition to them, the `spec` section is mandatory
    as well.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: The first field we defined in the `spec` section is `replicas`. It sets the
    desired number of replicas of the Pod. In this case, the ReplicaSet should ensure
    that two Pods should run concurrently. If we did not specify the value of the
    `replicas`, it would default to `1`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: The next `spec` section is the `selector`. We use it to select which pods should
    be included in the ReplicaSet. It does not distinguish between the Pods created
    by a ReplicaSet or some other process. In other words, ReplicaSets and Pods are
    decoupled. If Pods that match the `selector` exist, ReplicaSet will do nothing.
    If they don't, it will create as many Pods to match the value of the `replicas`
    field. Not only that ReplicaSet creates the Pods that are missing, but it also
    monitors the cluster and ensures that the desired number of `replicas` is (almost)
    always running. In case there are already more running Pods with the matching
    `selector`, some will be terminated to match the number set in `replicas`.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: We used `spec.selector.matchLabels` to specify a few labels. They must match
    the labels defined in the `spec.template`. In our case, ReplicaSet will look for
    Pods with `type` set to `backend` and `service` set to `go-demo-2`. If Pods with
    those labels do not already exist, it'll create them using the `spec.template`
    section.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: The last section of the `spec` field is the `template`. It is the only required
    field in the `spec`, and it has the same schema as a Pod specification. At a minimum,
    the labels of the `spec.template.metadata.labels` section must match those specified
    in the `spec.selector.matchLabels`. We can set additional labels that will serve
    informational purposes only. ReplicaSet will make sure that the number of replicas
    matches the number of Pods with the same labels. In our case, we set `type` and
    `service` to the same values and added two additional ones (`db` and `language`).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'It might sound confusing that the `spec.template.spec.containers` field is
    mandatory. ReplicaSet will look for Pods with the matching labels created by other
    means. If we already created a Pod with labels `type: backend` and `service: go-demo-2`,
    this ReplicaSet would find them and would not create a Pod defined in `spec.template`.
    The main purpose of that field is to ensure that the desired number of `replicas`
    is running. If they are created by other means, ReplicaSet will do nothing. Otherwise,
    it''ll create them using the information in `spec.template`.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `spec.template.spec` section contains the same `containers` definition
    we used in the previous chapter. It defines a Pod with two containers (`db` and
    `api`).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, I claimed that those two containers should not belong
    to the same Pod. The same is true for the containers in Pods managed by the ReplicaSet.
    However, we did not yet have the opportunity to explore ways to allow containers
    running in different Pods to communicate with each other. So, for now, we'll continue
    using the same flawed Pods definition.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Let's create the ReplicaSet and experience its advantages first hand.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We got the response that the `replicaset "go-demo-2"` was `created`. We can
    confirm that by listing all the ReplicaSets in the cluster.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output is as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can see that the desired number of replicas is `2` and that it matches the
    current value. The value of the `ready` field is still `0` but, after the images
    are pulled, and the containers are running, it'll change to `2`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Instead of retrieving all the replicas in the cluster, we can retrieve those
    specified in the `rs/go-demo-2.yml` file.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The output should be the same since, in both cases, there is only one ReplicaSet
    running inside the cluster.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'All the other `kubectl get` arguments we explored in the previous chapter also
    apply to ReplicaSets or, to be more precise, to all Kubernetes objects. The same
    is true for `kubectl describe` command:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The last lines of the output are as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Judging by the events, we can see that ReplicaSet created two Pods while trying
    to match the desired state with the actual state.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, if you are not yet convinced that the ReplicaSet created the missing
    Pods, we can list all those running in the cluster and confirm it:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To be on the safe side, we used the `--show-labels` argument so that we can
    verify that the Pods in the cluster match those created by the ReplicaSet.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](img/5168d886-97b9-4c75-a86d-279f7bc93cfd.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4-1: A ReplicaSet with two replicas of a Pod'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'The sequence of events that transpired with the `kubectl create -f rs/go-demo-2.yml`
    command is as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes client (`kubectl`) sent a request to the API server requesting the
    creation of a ReplicaSet defined in the `rs/go-demo-2.yml` file.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The controller is watching the API server for new events, and it detected that
    there is a new ReplicaSet object.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The controller creates two new pod definitions because we have configured replica
    value as `2` in `rs/go-demo-2.yml` file.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since the scheduler is watching the API server for new events, it detected that
    there are two unassigned Pods.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The scheduler decided to which node to assign the Pod and sent that information
    to the API server.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kubelet is also watching the API server. It detected that the two Pods were
    assigned to the node it is running on.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kubelet sent requests to Docker requesting the creation of the containers that
    form the Pod. In our case, the Pod defines two containers based on the `mongo`
    and `api` image. So in total four containers are created.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, Kubelet sent a request to the API server notifying it that the Pods
    were created successfully.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e77ce395-1239-44a8-8b0a-d150458b7f8c.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4-2: The sequence of events followed by request to create a ReplicaSet'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: The sequence we described is useful when we want to understand everything that
    happened in the cluster from the moment we requested the creation of a new ReplicaSet.
    However, it might be too confusing so we'll try to explain the same process through
    a diagram that more closely represents the cluster.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0141d08f-50be-4132-a43b-544231eb196a.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4-3: The events followed by request to create a ReplicaSet'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Typically, we'd have a multi-node cluster, and the Pods would be distributed
    across it. For now, while we're using Minikube, there's only one server that acts
    as both the master and the node. Later on, when we start working on multi-node
    clusters, the distribution of Pods will become evident. The same can be said for
    the architecture. We'll explain different Kubernetes components in more detail
    later on.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Let's see which types of operations we can perform on ReplicaSets.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Operating ReplicaSets
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What would happen if we delete the ReplicaSet? As you might have guessed, both
    the ReplicaSet and everything it created (the Pods) would disappear with a single
    `kubectl delete -f rs/go-demo-2.yml` command. However, since ReplicaSets and Pods
    are loosely coupled objects with matching labels, we can remove one without deleting
    the other. We can, for example, remove the ReplicaSet we created while leaving
    the two Pods intact.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We used the `--cascade=false` argument to prevent Kubernetes from removing all
    the downstream objects. As a result, we got the confirmation that `replicaset
    "go-demo-2"` was `deleted`. Let's confirm that it is indeed removed from the system.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As expected, the output states that `no resources` were `found`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: If `--cascade=false` indeed prevents Kubernetes from removing the downstream
    objects, the Pods should continue running in the cluster. Let's confirm the assumption.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output is as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The two Pods created by the ReplicaSet are indeed still running in the cluster
    even though we removed the ReplicaSet.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: The Pods that are currently running in the cluster do not have any relation
    with the ReplicaSet we created earlier. We deleted the ReplicaSet, and the Pods
    are still there. Knowing that the ReplicaSet uses labels to decide whether the
    desired number of Pods is already running in the cluster, should lead us to the
    conclusion that if we create the same ReplicaSet again, it should reuse the two
    Pods that are running in the cluster. Let's confirm that.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the `kubectl create` command we executed previously, we'll also
    add the `--save-config` argument. It'll save the configuration of the ReplicaSet
    thus allowing us to perform a few additional operations later on. We'll get to
    them shortly. For now, the important thing is that we are about to create the
    same ReplicaSet we had before.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The output states that the `replicaset "go-demo-2" was created`. Let's see what
    happened with the Pods.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: If you compare the names of the Pods, you'll see that they are the same as before
    we created the ReplicaSet. It looked for matching labels, deduced that there are
    two Pods that match them, and decided that there's no need to create new ones.
    The matching Pods fulfil the desired number of replicas.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Since we saved the configuration, we can `apply` an updated definition of the
    ReplicaSet. For example, we can use `rs/go-demo-2-scaled.yml` file that differs
    only in the number of replicas set to `4`. We could have created the ReplicaSet
    with `apply` in the first place, but we didn't. The `apply` command automatically
    saves the configuration so that we can edit it later on. The `create` command
    does not do such thing by default so we had to save it with `--save-config`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This time, the output is slightly different. Instead of saying that the ReplicaSet
    was created, we can see that it was `configured`:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at the Pods.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output is as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: As expected, now there are four Pods in the cluster. If you pay closer attention
    to the names of the Pods, you'll notice that two of them are the same as before.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: When we applied the new configuration with `replicas` set to `4` instead of
    `2`, Kubernetes updated the ReplicaSet which, in turn, evaluated the current state
    of the Pods with matching labels. It found two with the same labels and decided
    to create two more so that the new desired state can match the actual state.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Let's see what happens when a Pod is destroyed.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We retrieved all the Pods and used `-o name` to retrieve only their names. The
    result was piped to `tail -1` so that only one of the names is output. The result
    is stored in the environment variable `POD_NAME`. The latter command used that
    variable to remove the Pod as a simulation of a failure.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take another look at the Pods in the cluster:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output is as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We can see that the Pod we deleted is `terminating`. However, since we have
    a ReplicaSet with `replicas` set to `4`, as soon as it discovered that the number
    of Pods dropped to `3`, it created a new one. We just witnessed self-healing in
    action. As long as there are enough available resources in the cluster, ReplicaSets
    will make sure that the specified number of Pod replicas are (almost) always up-and-running.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Let's see what happens if we remove one of the Pod labels ReplicaSet uses in
    its selector.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We used the same command to retrieve the name of one of the Pods and executed
    the command that removed the label `service`. Please note `-` at the end of the
    name of the label. It is the syntax that indicates that a label should be removed:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we described the Pod:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the last command, limited to the labels section, is as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As you can see, the label `service` is gone.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s list the Pods in the cluster and check whether there is any change:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The total number of Pods increased to five. The moment we removed the `service`
    label from one of the Pods, the ReplicaSet discovered that the number of Pods
    matching the `selector` labels is three and created a new Pod. Right now, we have
    four Pods controlled by the ReplicaSet and one running freely due to non-matching
    labels.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Pods 的总数增加到了五个。当我们从一个 Pod 中移除了`service`标签时，ReplicaSet 发现与`selector`标签匹配的 Pods
    数量为三，并创建了一个新的 Pod。现在，我们有四个由 ReplicaSet 控制的 Pods 和一个由于不匹配标签而自由运行的 Pod。
- en: What would happen if we add the label we removed?
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们添加了我们移除的标签会发生什么？
- en: '[PRE29]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We added the `service=go-demo-2` label and listed all the Pods.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了`service=go-demo-2`标签并列出了所有的Pods。
- en: 'The output of the latter command is as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 后一命令的输出如下：
- en: '[PRE30]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The moment we added the label, the ReplicaSet discovered that there are five
    Pods with matching selector labels. Since the specification states that there
    should be four replicas of the Pod, it removed one of the Pods so that the desired
    state matches the actual state.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们添加标签的那一刻，ReplicaSet 发现有五个具有匹配选择器标签的 Pods。由于规范规定应该有四个 Pod 的副本，它移除了一个 Pod，以使期望状态与实际状态匹配。
- en: The previous few examples showed, one more time, that ReplicaSets and Pods are
    loosely coupled through matching labels and that ReplicaSets are using those labels
    to maintain the parity between the actual and the desired state. So far, self-healing
    worked as expected.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 前几个示例再次表明，ReplicaSets 和 Pods 通过匹配标签松散耦合，并且 ReplicaSets 使用这些标签来维护实际状态和期望状态之间的一致性。到目前为止，自愈工作如预期般正常。
- en: What now?
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现在怎么办？
- en: The good news is that ReplicaSets are relatively straightforward. They provide
    a guarantee that the specified number of replicas of a Pod will be running in
    the system as long as there are available resources. That's the primary and, arguably,
    the only purpose.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是 ReplicaSets 相对直接。它们保证 Pod 的指定数量副本将在系统中运行，只要有可用资源。这是其主要且可以说是唯一的目的。
- en: The bad news is that ReplicaSets are rarely used independently. You will almost
    never create a ReplicaSet directly just as you're not going to create Pods. Instead,
    we tend to create ReplicaSets through Deployments. In other words, we use ReplicaSets
    to create and control Pods, and Deployments to create ReplicaSets (and a few other
    things). We'll get to Deployment soon. For now, please delete your local Minikube
    cluster. The next chapter will start from scratch.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 不好的消息是 ReplicaSets 很少单独使用。你几乎不会直接创建 ReplicaSet 就像你不会创建 Pods 一样。相反，我们倾向于通过 Deployments
    创建 ReplicaSets。换句话说，我们使用 ReplicaSets 来创建和控制 Pods，使用 Deployments 来创建 ReplicaSets（以及其他一些内容）。我们很快就会介绍
    Deployment。现在，请删除你的本地 Minikube 集群。下一章将从头开始。
- en: '[PRE31]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: If you'd like to know more about ReplicaSets, please explore ReplicaSet v1 apps
    ([https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#replicaset-v1-apps](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#replicaset-v1-apps))
    API documentation.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解更多关于 ReplicaSets 的信息，请查看 ReplicaSet v1 apps ([https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#replicaset-v1-apps](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#replicaset-v1-apps))
    API 文档。
- en: '![](img/70f75cdc-8333-4071-8b93-d73fe282608a.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/70f75cdc-8333-4071-8b93-d73fe282608a.png)'
- en: 'Figure 4-4: The components explored so far'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图4-4：迄今为止探索的组件
