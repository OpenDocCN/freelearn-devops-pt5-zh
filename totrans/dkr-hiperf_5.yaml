- en: Chapter 5. Benchmarking
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 章：基准测试
- en: In optimizing our Docker applications, it is important to validate the parameters
    that we tuned. Benchmarking is an experimental way of identifying if the elements
    we modified in our Docker containers performed as expected. Our application will
    have a wide area of options to be optimized. The Docker hosts running them have
    their own set of parameters such as memory, networking, CPU, and storage as well.
    Depending on the nature of our application, one or more of these parameters can
    become a bottleneck. Having a series of tests to validate each component with
    benchmarks is important for guiding our optimization strategy.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化我们的 Docker 应用程序时，验证我们调整的参数是非常重要的。基准测试是一种实验性的方式，用于确定我们在 Docker 容器中修改的元素是否按预期执行。我们的应用程序将有广泛的选项可以优化。运行这些应用程序的
    Docker 主机也有自己的参数集，如内存、网络、CPU 和存储等。根据我们应用程序的性质，这些参数中的一个或多个可能会成为瓶颈。进行一系列测试以通过基准测试验证每个组件对于指导我们的优化策略非常重要。
- en: Additionally, by creating proper performance tests, we can also identify the
    limits of the current configuration of our Docker-based application. With this
    information, we can start exploring infrastructure parameters such as scaling
    out our application by deploying them on more Docker hosts. We can also use this
    information to scale up the same application by moving our workload to a Docker
    host with higher storage, memory, or CPU. And when we have hybrid cloud deployments,
    we can use these measurements to identify which cloud provider gives our application
    its optimum performance.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过创建适当的性能测试，我们还可以识别当前 Docker 基础应用程序配置的极限。有了这些信息，我们可以开始探索基础设施参数，例如通过将应用程序部署到更多
    Docker 主机上来进行横向扩展。我们还可以利用这些信息，通过将工作负载迁移到内存、存储或 CPU 更强大的 Docker 主机上来纵向扩展相同的应用程序。而当我们有混合云部署时，我们可以利用这些测量数据来确定哪个云服务商能为我们的应用程序提供最佳性能。
- en: Measuring how our application responds to these benchmarks is important when
    planning the capacity needed for our Docker infrastructure. By creating a test
    workload simulating peak and normal conditions, we can predict how our application
    will perform once it is released to production.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 测量我们的应用程序如何响应这些基准测试对于规划我们 Docker 基础设施所需的容量至关重要。通过创建一个模拟峰值和正常状态的测试工作负载，我们可以预测应用程序一旦发布到生产环境中，它将如何表现。
- en: 'In this chapter, we will cover the following topics to benchmark a simple web
    application deployed in our Docker infrastructure:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容，以基准测试我们在 Docker 基础设施中部署的一个简单 Web 应用程序：
- en: Setting up Apache JMeter for benchmarking
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置 Apache JMeter 进行基准测试
- en: Creating and designing a benchmark workload
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和设计基准工作负载
- en: Analyzing application performance
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析应用性能
- en: Setting up Apache JMeter
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 Apache JMeter
- en: Apache JMeter is a popular application used to test the performance of web servers.
    Besides load testing web servers, the open source project grew to support testing
    other network protocols such as LDAP, FTP, and even raw TCP packets. It is highly
    configurable, and powerful enough to design complex workloads of different usage
    patterns. This feature can be used to simulate thousands of users suddenly visiting
    our web application thus inducing a spike in the load.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Apache JMeter 是一种流行的应用程序，用于测试 Web 服务器的性能。除了对 Web 服务器进行负载测试外，这个开源项目还支持测试其他网络协议，如
    LDAP、FTP，甚至是原始的 TCP 数据包。它具有高度的可配置性，并且足够强大，能够设计复杂的工作负载以适应不同的使用模式。这个功能可以用来模拟成千上万的用户突然访问我们的
    Web 应用程序，从而引发负载激增。
- en: Another feature expected in any load-testing software is its data capture and
    analysis functions. JMeter has such a wide variety of data recording, plotting,
    and analysis features that we can explore the results of our benchmarks right
    away. Finally, it has a wide variety of plugins that may already have the load
    pattern, analysis, or network connection that we plan to use.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 任何负载测试软件中预期的另一项功能是其数据捕获和分析功能。JMeter 具有如此多样化的数据记录、绘图和分析功能，我们可以立即查看基准测试的结果。最后，它拥有广泛的插件，可能已经具备了我们计划使用的负载模式、分析或网络连接。
- en: Note
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: More information about the features and how to use Apache JMeter can be found
    on its website at [http://jmeter.apache.org](http://jmeter.apache.org).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 Apache JMeter 的功能和使用方法的更多信息，请访问其官方网站：[http://jmeter.apache.org](http://jmeter.apache.org)。
- en: In this section, we will deploy an example application to benchmark, and prepare
    our workstation to run our first JMeter-based benchmark.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将部署一个示例应用程序进行基准测试，并准备我们的工作站运行我们的第一个基于 JMeter 的基准测试。
- en: Deploying a sample application
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署示例应用程序
- en: We can also bring our own web application we want to benchmark if we please.
    But for the rest of this chapter, we will benchmark the following application
    described in this section. The application is a simple Ruby web application deployed
    using Unicorn, a popular Ruby application server. It receives traffic via a Unix
    socket from Nginx. This setup is very typical for most Ruby applications found
    in the wild.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，我们也可以带上自己想要基准测试的 web 应用程序。但在本章的其余部分，我们将基准测试本节中描述的以下应用程序。该应用程序是一个简单的 Ruby
    web 应用程序，通过 Unicorn（一个流行的 Ruby 应用服务器）部署。它通过 Nginx 的 Unix 套接字接收流量。这个设置对于大多数现实中的
    Ruby 应用程序来说非常典型。
- en: In this section, we will deploy this Ruby application in a Docker host called
    `webapp`. We will use separate Docker hosts for the application, benchmark tools,
    and monitoring. This separation is important so that the benchmark and monitoring
    instrumentation we run doesn't affect the benchmark results.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将把这个 Ruby 应用程序部署到名为 `webapp` 的 Docker 主机上。我们将为应用程序、基准工具和监控使用不同的 Docker
    主机。这种分离非常重要，因为我们运行的基准测试和监控工具不会影响基准测试结果。
- en: 'The next few steps show us how to build and deploy our simple Ruby web application
    stack:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的几步将展示如何构建和部署我们的简单 Ruby web 应用栈：
- en: 'First, create the Ruby application by creating the following Rack `config.ru`
    file:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，通过创建以下 Rack `config.ru` 文件来创建 Ruby 应用程序：
- en: '[PRE0]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we package the application as a Docker container with the following `Dockerfile`:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用以下 `Dockerfile` 将应用程序打包为 Docker 容器：
- en: '[PRE1]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now we will create the Nginx configuration file `nginx.conf`. It will forward
    requests to our Unicorn application server through the Unix socket that we created
    in the previous step. In logging the request, we will record `$remote_addr` and
    `$response_time`. We will pay particular attention to these metrics later when
    we analyze our benchmark results:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将创建 Nginx 配置文件 `nginx.conf`。它将通过我们在前一步中创建的 Unix 套接字将请求转发到我们的 Unicorn 应用服务器。在记录请求日志时，我们将记录
    `$remote_addr` 和 `$response_time`。稍后在分析基准测试结果时，我们将特别关注这些指标：
- en: '[PRE2]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding Nginx configuration will then be packaged as a Docker container
    with the following `Dockerfile`:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述的 Nginx 配置文件将被打包为一个 Docker 容器，并使用以下 `Dockerfile`：
- en: '[PRE3]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The last component will be a `docker-compose.yml` file to tie the two Docker
    containers together for deployment:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个组件将是一个 `docker-compose.yml` 文件，用于将两个 Docker 容器连接在一起进行部署：
- en: '[PRE4]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the end, we will have the files shown in the following screenshot in our
    code base:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们的代码库中将包含如下截图所示的文件：
- en: '![Deploying a sample application](img/00022.jpeg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![部署示例应用程序](img/00022.jpeg)'
- en: 'After preparing our Dockerized web application, let us now deploy it to our
    Docker host by typing the following command:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备好我们的 Docker 化 web 应用程序后，现在通过输入以下命令将其部署到 Docker 主机上：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Docker Compose is a tool for creating multi-container applications. It has a
    schema defined in YML to describe how we want our Docker containers to run and
    link to each other.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose 是一个用于创建多容器应用程序的工具。它在 YML 文件中定义了一个模式，用于描述我们希望 Docker 容器如何运行以及如何相互连接。
- en: 'Docker Compose supports a curl | bash type of installation. To quickly install
    it on our Docker host, type the following command:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose 支持 curl | bash 类型的安装方式。为了在 Docker 主机上快速安装它，请输入以下命令：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We only covered Docker Compose in passing in this chapter. However, we can get
    more information about Docker Compose on the documentation website found at [http://docs.docker.com/compose](http://docs.docker.com/compose).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们只简单提到过 Docker Compose。然而，我们可以在 Docker Compose 的文档网站上获得更多信息：[http://docs.docker.com/compose](http://docs.docker.com/compose)。
- en: 'Finally, let us conduct a preliminary test to determine if our application
    works properly:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们进行初步测试，以确定我们的应用程序是否正常工作：
- en: '[PRE7]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now we are done preparing the application that we want to benchmark. In the
    next section, we will prepare our workstation to perform the benchmarks by installing
    Apache JMeter.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了要基准测试的应用程序。在接下来的部分，我们将通过安装 Apache JMeter 来准备我们的工作站进行基准测试。
- en: Installing JMeter
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 JMeter
- en: 'For the rest of this chapter, we will use Apache JMeter version 2.13 to perform
    our benchmarks. In this section, we will download and install it in our workstation.
    Follow the next few steps to set up JMeter properly:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将使用 Apache JMeter 2.13 版本来进行基准测试。在本节中，我们将下载并安装它到我们的工作站上。按照接下来的几步正确设置
    JMeter：
- en: To begin, go to JMeter's download web page at [http://jmeter.apache.org/download_jmeter.cgi](http://jmeter.apache.org/download_jmeter.cgi).
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，访问 JMeter 的下载网页：[http://jmeter.apache.org/download_jmeter.cgi](http://jmeter.apache.org/download_jmeter.cgi)。
- en: Select the link for **apache-jmeter-2.13.tgz** to begin downloading the binary.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 **apache-jmeter-2.13.tgz** 的链接以开始下载二进制文件。
- en: 'When the download finishes, extract the tarball by typing the following command:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载完成后，通过输入以下命令解压 tarball：
- en: '[PRE8]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, we will add the `bin/` directory to our `$PATH` so that JMeter can be
    easily launched from the command line. To do this, we will type the following
    command in our terminal:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将把 `bin/` 目录添加到我们的 `$PATH` 中，以便可以轻松地从命令行启动 JMeter。为此，我们将输入以下命令：
- en: '[PRE9]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, launch JMeter by typing the following command:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，通过输入以下命令启动 JMeter：
- en: '[PRE10]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We will now see the JMeter UI just like the following screenshot. Now we are
    finally ready to write the benchmark for our application!:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将看到 JMeter 的 UI，和以下截图一样。现在我们终于准备好为我们的应用程序编写基准测试了！：
- en: '![Installing JMeter](img/00023.jpeg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![安装 JMeter](img/00023.jpeg)'
- en: Note
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that Apache JMeter is a Java application. According to the JMeter website,
    it requires at least Java 1.6 to work. Make sure you have a **Java Runtime Environment**
    (**JRE**) properly set up before installing JMeter.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Apache JMeter 是一个 Java 应用程序。根据 JMeter 网站的信息，它至少需要 Java 1.6 才能正常运行。在安装 JMeter
    之前，确保你已经正确设置了 **Java 运行环境**（**JRE**）。
- en: 'If we were in a Mac OSX environment, we could use Homebrew and just type the
    following command:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在 Mac OSX 环境中，可以使用 Homebrew，并输入以下命令：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: For other platforms, the instructions described earlier should be sufficient
    to get started. More information on how to install JMeter can be found at [http://jmeter.apache.org/usermanual/get-started.html](http://jmeter.apache.org/usermanual/get-started.html).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他平台，前面描述的安装说明应该足够让你入门。有关如何安装 JMeter 的更多信息，可以参考 [http://jmeter.apache.org/usermanual/get-started.html](http://jmeter.apache.org/usermanual/get-started.html)。
- en: Building a benchmark workload
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建基准工作负载
- en: 'Writing benchmarks for an application is an open-ended area to explore. Apache
    JMeter can be overwhelming at first. It has several options to tune in order to
    write our benchmarks. To begin, we can use the "story" of our application as a
    start. The following are some of the questions we can ask ourselves:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为应用程序编写基准测试是一个开放的探索领域。刚开始使用 Apache JMeter 时可能会觉得有些复杂。它有许多选项需要调整，以便编写我们的基准测试。首先，我们可以使用我们应用程序的“故事”作为起点。以下是我们可以问自己的几个问题：
- en: What does our application do?
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的应用程序做了什么？
- en: What is the persona of our users?
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们用户的角色是什么？
- en: How do they interact with our application?
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们如何与我们的应用程序进行互动？
- en: Starting with these questions, we can then translate them into actual requests
    to our application.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些问题开始，我们可以将它们转化为对我们应用程序的实际请求。
- en: In the sample application that we wrote in the earlier section, we have a web
    application that displays `Hello World` to our users. In web applications, we
    are typically interested with the throughput and response time. Throughput refers
    to the number of users that can receive `Hello World` at a time. Response time
    describes the time lag before the user receives the `Hello World` message from
    the moment they requested it.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们前面写的示例应用程序中，我们有一个 Web 应用程序，它会向用户展示 `Hello World`。在 Web 应用程序中，我们通常关注的是吞吐量和响应时间。吞吐量指的是一次能有多少用户接收到
    `Hello World`。响应时间则是指从用户请求 `Hello World` 到接收到 `Hello World` 消息之间的时间延迟。
- en: In this section, we will create a preliminary benchmark in Apache JMeter. Then
    we will begin analyzing our initial results with JMeter's analysis tools and the
    monitoring stack that we deployed in [Chapter 4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 4. Monitoring Docker Hosts and Containers"), *Monitoring Docker Hosts
    and Containers*. After that, we will iterate on the benchmarks we developed, and
    tune it. This way, we know that we are benchmarking our application properly.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将创建一个初步的基准测试，在 Apache JMeter 中进行。接着，我们将使用 JMeter 的分析工具和我们在[第 4 章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "第 4 章：监控 Docker 主机和容器")，*监控 Docker 主机和容器*中部署的监控堆栈开始分析我们的初步结果。之后，我们将对我们开发的基准进行迭代并进行调整。通过这种方式，我们可以确保我们的应用程序基准测试是正确的。
- en: Creating a test plan in JMeter
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 JMeter 中创建测试计划
- en: A series of benchmarks in Apache JMeter is described in a test plan. A test
    plan describes a series of steps that JMeter will execute like performing requests
    to a web application. Each step in a test plan is called an element. These elements
    themselves can have one or more elements as well. In the end, our test plan will
    look like a tree—an hierarchy of elements to describe the benchmark we want for
    our application.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一系列的基准测试在Apache JMeter中由一个测试计划描述。测试计划描述了JMeter将执行的一系列步骤，例如对一个Web应用程序进行请求。测试计划中的每个步骤都称为一个元素。这些元素本身也可以包含一个或多个子元素。最终，我们的测试计划看起来就像一棵树——一个元素的层次结构，用来描述我们为应用程序设计的基准测试。
- en: 'To add an element into our test plan, we simply right-click on the parent element
    that we want, and then select **Add**. This opens a context menu of elements that
    can be added to the selected parent element. In the following screenshot, we add
    a **Thread Group** element to the main element, **Test Plan**:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要将元素添加到我们的测试计划中，我们只需右键单击我们想要的父元素，然后选择**添加**。这会打开一个上下文菜单，列出可以添加到选定父元素的元素。在以下截图中，我们向主元素**测试计划**添加了一个**线程组**元素：
- en: '![Creating a test plan in JMeter](img/00024.jpeg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![在JMeter中创建测试计划](img/00024.jpeg)'
- en: 'The next few steps show the way to create a test plan conducting the benchmark
    that we want:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的几个步骤展示了如何创建一个测试计划，进行我们想要的基准测试：
- en: First, let us rename the **Test Plan** to something more appropriate. Click
    on the **Test Plan** element. This will update the main JMeter window on the right.
    In the form field labeled **Name:**, set the value to **Unicorn Capacity**.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们将**测试计划**重命名为一个更合适的名称。点击**测试计划**元素。这将更新右侧的主要JMeter窗口。在标有**名称**的表单字段中，将值设置为**Unicorn
    Capacity**。
- en: 'Under the **Unicorn Capacity** test plan, create a thread group. Name this
    **Application Users**. We will configure this thread group to send 10,000 requests
    to our application from a single thread in the beginning. Use the following parameters
    for filling out the form to achieve this setting:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**Unicorn Capacity**测试计划下，创建一个线程组。将其命名为**应用程序用户**。我们将配置该线程组，初始时从单个线程发送10,000个请求到我们的应用程序。使用以下参数填写表单以实现此设置：
- en: '**Number of Threads**: 1'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线程数**: 1'
- en: '**Ramp-up Period**: 0 seconds'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ramp-up时间**: 0秒'
- en: '**Loop Count**: 120,000 times'
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**循环次数**: 120,000次'
- en: Tip
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: When we start developing our test plans, having a low loop count is useful.
    Instead of 120,000 loop counts, we can begin with 10,000 or even just 10 instead.
    Our benchmarks are shorter, but we get immediate feedback when developing it such
    as when we proceed to the next step. When we finish the whole test plan, we can
    always revert and tune it later to generate more requests.
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当我们开始制定测试计划时，使用较低的循环次数是有用的。与其设置120,000次循环，不如从10,000次甚至仅仅10次开始。我们的基准测试时间较短，但在开发过程中能立即得到反馈，比如在进行下一步时。完成整个测试计划后，我们随时可以回溯并调整它，以生成更多的请求。
- en: 'Next, under the **Application Users** thread group, we create the actual request
    by adding **Sampler, HTTP Request**. This is the configuration where we set the
    details of how we make a request to our web application:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在**应用程序用户**线程组下，我们通过添加**采样器，HTTP请求**来创建实际的请求。这是配置我们如何向Web应用程序发出请求的设置：
- en: '**Name**: Go to `http://webapp/`'
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**名称**: 访问`http://webapp/`'
- en: '**Server Name**: `webapp`'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务器名称**: `webapp`'
- en: Finally, we configure how to save the test results by adding a listener under
    the **Unicorn Capacity** test plan. For this, we will add a **Simple Data Writer,**
    and name it **Save Result**. We set the **Filename** field to `result.jtl` to
    save our benchmark results in the said file. We will refer to this file later
    when we analyze the result of the benchmark.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们通过在**Unicorn Capacity**测试计划下添加监听器来配置如何保存测试结果。为此，我们将添加一个**Simple Data Writer**，并将其命名为**保存结果**。我们将**文件名**字段设置为`result.jtl`，以便将基准测试结果保存到该文件中。稍后在分析基准测试结果时，我们会引用此文件。
- en: 'Now we have a basic benchmark workload that generates 120,000 HTTP requests
    to `http://webapp/`. Then the test plan saves the result of each request in a
    file called `result.jtl`. The following is a screenshot of JMeter after the last
    step in creating the test plan:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个基本的基准负载，它会生成120,000个HTTP请求到`http://webapp/`。然后，测试计划会将每个请求的结果保存在名为`result.jtl`的文件中。以下是创建测试计划最后一步后JMeter的屏幕截图：
- en: '![Creating a test plan in JMeter](img/00025.jpeg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![在JMeter中创建测试计划](img/00025.jpeg)'
- en: Finally, it is time to run our benchmark. Go to the **Run** menu, then select
    **Start** to begin executing the test plan. While the benchmark is running, the
    **Start** button is grayed-out and disabled. When the execution finishes, it will
    be enabled again.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，到了运行基准测试的时候了。进入**运行**菜单，然后选择**开始**以开始执行测试计划。在基准测试运行时，**开始**按钮会变灰并禁用。执行完成后，按钮会重新启用。
- en: After running the benchmark, we will analyze the results by looking at the `result.jtl`
    file using JMeter's analysis tools in the next section.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行基准测试后，我们将在下一节使用 JMeter 的分析工具查看 `result.jtl` 文件来分析结果。
- en: Note
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: There are various types of elements that can be placed in a JMeter test plan.
    Besides the three elements we used previously to create a basic benchmark for
    our application, there are several others that regulate requests, perform other
    network requests, and analyze data.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在 JMeter 测试计划中，可以放置多种类型的元素。除了我们之前用来为应用程序创建基本基准的三个元素外，还有一些其他元素可以调控请求、执行其他网络请求和分析数据。
- en: A comprehensive list of test plan elements and their description can be found
    on the JMeter page at [http://jmeter.apache.org/usermanual/component_reference.html](http://jmeter.apache.org/usermanual/component_reference.html).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 测试计划元素的全面列表及其描述可以在 JMeter 页面找到：[http://jmeter.apache.org/usermanual/component_reference.html](http://jmeter.apache.org/usermanual/component_reference.html)。
- en: Analyzing benchmark results
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析基准测试结果
- en: 'In this section, we will analyze the benchmark results, and identify how the
    120,000 requests affected our application. In creating web application benchmarks,
    there are typically two things we are usually interested in:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将分析基准测试结果，并识别 120,000 次请求如何影响我们的应用程序。在创建 Web 应用程序基准时，通常有两个我们关注的方面：
- en: How many requests can our application handle at a time?
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的应用程序一次能处理多少请求？
- en: For how long is each request being processed by our application?
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个请求在我们的应用程序中被处理的时间有多长？
- en: These two low-level web performance metrics can easily translate to the business
    implications of our application. For example, how many customers are using our
    application? Another one is, how are they perceiving the responsiveness of our
    application from a user experience perspective? We can correlate secondary metrics
    in our application such as CPU, memory, and network to determine our system capacity.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个低级 Web 性能指标可以很容易地转化为我们应用程序的业务影响。例如，有多少客户正在使用我们的应用程序？另一个是，他们如何从用户体验的角度感知我们应用程序的响应性？我们可以关联应用程序中的二级指标，如
    CPU、内存和网络，以确定我们的系统容量。
- en: Viewing the results of JMeter runs
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看 JMeter 运行结果
- en: Several listener elements of JMeter have features that render graphs. Enabling
    this when running the benchmark is useful when developing the test plan. But the
    time taken by the UI to render the results in real time, in addition to the actual
    benchmark requests, affects the performance of the test. Hence, it is better for
    us to separate the execution and analysis components of our benchmark. In this
    section, we will create a new test plan, and look at a few JMeter listener elements
    to analyze the data we acquired in `result.jtl`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: JMeter 的多个监听器元素具有渲染图形的功能。在运行基准测试时启用这一功能对于开发测试计划很有用。但 UI 渲染结果所花费的时间，加上实际基准请求的时间，会影响测试性能。因此，我们最好将基准测试的执行和分析组件分开。在本节中，我们将创建一个新的测试计划，并查看一些
    JMeter 监听器元素，用于分析我们在 `result.jtl` 中获得的数据。
- en: To begin our analysis, we first create a new test plan, and name this **Analyze
    Results**. We will add various listener elements under this test plan parent element.
    After this, follow the next few steps to add various JMeter listeners that can
    be used to analyze our benchmark result.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始分析，我们首先创建一个新的测试计划，并将其命名为**分析结果**。我们将在这个测试计划的父元素下添加各种监听器元素。接下来，按照以下步骤添加可以用来分析基准结果的
    JMeter 监听器。
- en: Calculating throughput
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算吞吐量
- en: For our first analysis, we will use the **Summary Report** listener. This listener
    will show the throughput of our application. A measurement of throughput will
    show the number of transactions our application can handle per second.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的第一次分析，我们将使用**汇总报告**监听器。这个监听器将显示我们应用程序的吞吐量。吞吐量的测量将显示我们的应用程序每秒可以处理的事务数量。
- en: 'To display the throughput, perform the following steps:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要显示吞吐量，执行以下步骤：
- en: 'After loading the listener, fill out the **Filename** field by selecting the
    `result.jtl` file that we generated when we ran our benchmark. For the run we
    did earlier, the following screenshot shows that the 120,000 HTTP requests were
    sent to `http://webapp/` at a throughput of 746.7 requests per second:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 加载监听器后，填写**文件名**字段，选择我们在运行基准测试时生成的`result.jtl`文件。对于我们之前执行的测试，以下截图显示了以每秒 746.7
    次请求的吞吐量向`http://webapp/`发送了 120,000 个 HTTP 请求：
- en: '![Calculating throughput](img/00026.jpeg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![计算吞吐量](img/00026.jpeg)'
- en: 'We can also look at how throughput evolved over the course of our benchmark
    with the **Graph Results** listener. Create this listener under the **Analyze
    Results** test plan element and name it **Throughput over time**. Make sure that
    only the **Throughput** checkbox is marked (feel free to look at the other data
    points later though). After creating the listener, load our `result.jtl` test
    result again. The following screenshot shows how the throughput evolved over time:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过**图形结果**监听器查看在基准测试过程中吞吐量的变化。在**分析结果**测试计划元素下创建这个监听器，并将其命名为**吞吐量随时间变化**。确保只选中**吞吐量**复选框（不过你也可以稍后查看其他数据点）。创建监听器后，再次加载我们的`result.jtl`测试结果。以下截图展示了吞吐量随时间的变化情况：
- en: '![Calculating throughput](img/00027.jpeg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![计算吞吐量](img/00027.jpeg)'
- en: As we can see in the preceding screenshot, the throughput started slow while
    JMeter tries to warm up its single-thread pool of requests. But after our benchmark
    continues to run, the throughput level settles at a stable level. By having a
    large number of loop counts earlier in our thread group, we were able to minimize
    the effect of the earlier ramp-up period.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在前面的截图中看到的，吞吐量在 JMeter 尝试预热其单线程请求池时起初较慢。但是当基准测试继续运行后，吞吐量水平逐渐稳定。通过在线程组中提前设置较多的循环次数，我们能够最小化早期预热期的影响。
- en: This way, the throughput displayed in the **Summary Report** earlier is more
    or less a consistent result. Take note that the **Graph Results** listener wraps
    around its data points after several samples.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，在**汇总报告**中显示的吞吐量更或多或少是一个一致的结果。请注意，**图形结果**监听器会在采样几次后将其数据点环绕。
- en: Tip
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Remember that in benchmarking, the more samples we get, the more precise our
    observations can be!
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在基准测试中，获取更多的样本数据，我们的观察结果会更加精确！
- en: Plotting response time
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 绘制响应时间
- en: Another metric we are interested in when we benchmark our application is the
    **response time**. The response time shows the duration for which JMeter has to
    wait before receiving the web page response from our application. In terms of
    real users, we can look at this as the time our users typed our web application's
    URL to the time everything got displayed in their web browser (it may not represent
    the real whole picture if our application renders some slow JavaScript, but for
    the application we made earlier, this analogy should suffice).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在基准测试应用程序时，我们感兴趣的另一个指标是**响应时间**。响应时间显示了 JMeter 在收到来自我们应用程序的网页响应之前必须等待的时间。就真实用户而言，我们可以将其视为用户从输入我们网页应用的
    URL 到一切显示在他们浏览器中的时间（如果我们的应用程序渲染了一些较慢的 JavaScript，这可能无法完全代表真实情况，但对于我们之前制作的应用程序，这种类比应该足够了）。
- en: 'To view the response time of our application, we will use the **Response Time
    Graph** listener. As an initial setting, we can set the interval to 500 milliseconds.
    This will average some of the response times along 500 milliseconds in `result.jtl`.
    In the following image, you can see that our application''s response time is mostly
    at around 1 millisecond:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了查看我们应用程序的响应时间，我们将使用**响应时间图**监听器。作为初步设置，我们可以将间隔设置为 500 毫秒。这将在`result.jtl`中对一些响应时间进行
    500 毫秒的平均处理。在下面的图片中，你可以看到我们应用程序的响应时间大部分都保持在 1 毫秒左右：
- en: '![Plotting response time](img/00028.jpeg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![绘制响应时间](img/00028.jpeg)'
- en: If we want to display the response time in finer detail, we can decrease the
    interval to as low as 1 millisecond. Take note that this will take more time to
    display as the JMeter UI tries to plot more points in the application. Sometimes,
    when there are too many samples, JMeter may crash, because our workstation doesn't
    have enough memory to display the entire graph. In case of large benchmarks, we
    would be better off observing the results with our monitoring system. We will
    look at this data in the next section.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想更精细地显示响应时间，可以将间隔减少到 1 毫秒。请注意，这会需要更多时间来显示，因为 JMeter 界面需要在应用程序中绘制更多的数据点。有时，当样本过多时，JMeter
    可能会崩溃，因为我们的工作站没有足够的内存来显示整个图表。在进行大规模基准测试时，我们最好通过监控系统来观察结果。我们将在下一节中查看这些数据。
- en: Observing performance in Graphite and Kibana
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Graphite 和 Kibana 中观察性能
- en: There might be a case when our workstation is so old that Java is not able to
    handle displaying 120,000 data points in its JMeter UI. To solve this, we can
    reduce the amount of data we have by either generating less requests in our benchmark
    or averaging out some of the data like we did earlier, when graphing response
    time. However, sometimes we want to see the full resolution of our data. This
    full view is useful when we want to inspect the finer details of how our application
    behaves. Fortunately, we already have a monitoring system in place for our Docker
    infrastructure that we built in [Chapter 4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 4. Monitoring Docker Hosts and Containers"), *Monitoring Docker Hosts
    and Containers*.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会有一种情况，我们的工作站太旧，以至于 Java 无法在 JMeter 界面中显示 120,000 个数据点。为了解决这个问题，我们可以通过减少基准测试中生成的请求量，或像之前绘制响应时间图时那样对一些数据进行平均，来减少数据量。然而，有时我们希望看到数据的完整分辨率。这种完整视图在我们想要检查应用程序行为的细节时非常有用。幸运的是，我们已经为我们的
    Docker 基础设施建立了一个监控系统，如[第 4 章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "第 4 章. 监控 Docker 主机和容器")，*监控 Docker 主机和容器*中所述。
- en: Note
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: In this section, our monitoring and logging systems are deployed in a Docker
    host called `monitoring`. Our Docker host `webapp` that runs our application containers
    will have Collected and Rsyslog send events to the Docker host `monitoring`.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们的监控和日志系统部署在名为 `monitoring` 的 Docker 主机上。运行应用程序容器的 Docker 主机 `webapp`
    将会收集事件并通过 Rsyslog 发送到 Docker 主机 `monitoring`。
- en: 'Remember the Nginx configuration mentioned when describing our benchmarks?
    The access log generated from the standard of the Nginx container is captured
    by Docker. If we use the same setup of our Docker daemon in [Chapter 4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 4. Monitoring Docker Hosts and Containers"), *Monitoring Docker Hosts
    and Containers*, these log events are captured by the local Rsyslog service. These
    Syslog entries will then be forwarded to the Logstash Syslog collector, and stored
    to Elasticsearch. We can then use the visualize feature of Kibana to look at the
    throughput of our application. The following analysis was made by counting the
    number of access log entries that Elasticsearch received per second:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们在描述基准测试时提到过 Nginx 配置吗？从 Nginx 容器标准生成的访问日志被 Docker 捕获。如果我们使用[第 4 章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "第 4 章. 监控 Docker 主机和容器")，*监控 Docker 主机和容器*中 Docker 守护进程的相同设置，这些日志事件将由本地 Rsyslog
    服务捕获。然后，这些 Syslog 条目会被转发到 Logstash Syslog 收集器，并存储到 Elasticsearch 中。接着，我们可以使用 Kibana
    的可视化功能查看我们应用的吞吐量。以下分析是通过计算 Elasticsearch 每秒收到的访问日志条目数量得出的：
- en: '![Observing performance in Graphite and Kibana](img/00029.jpeg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![在 Graphite 和 Kibana 中观察性能](img/00029.jpeg)'
- en: 'We can also plot our application''s response time during the course of the
    benchmark in Kibana. To do this, we first need to reconfigure our Logstash configuration
    to parse the data being received from the access log, and extract out the response
    time as a metric using filters. To do this, update `logstash.conf` from [Chapter
    4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e "Chapter 4. Monitoring
    Docker Hosts and Containers"), *Monitoring Docker Hosts and Containers*, to add
    the `grok {}` filter as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在基准测试过程中，在 Kibana 中绘制应用程序的响应时间。为此，我们首先需要重新配置 Logstash 配置文件，以解析从访问日志接收到的数据，并使用过滤器将响应时间提取为一个指标。为此，更新[第
    4 章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e "第 4 章. 监控
    Docker 主机和容器")，*监控 Docker 主机和容器*中的 `logstash.conf` 文件，加入 `grok {}` 过滤器，如下所示：
- en: '[PRE12]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Logstash's Filter plugins are used to intermediately process events before they
    reach our target storage endpoint such as Elasticsearch. It transforms raw data
    such as lines of text to a richer data schema in JSON that we can then use later
    for further analysis. More information about Logstash Filter plugins can be found
    at [https://www.elastic.co/guide/en/logstash/current/filter-plugins.html](https://www.elastic.co/guide/en/logstash/current/filter-plugins.html).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash的过滤器插件用于在事件到达目标存储端点（如Elasticsearch）之前进行中间处理。它将原始数据（如文本行）转换为JSON格式的更丰富数据架构，然后我们可以在后续分析中使用。关于Logstash过滤器插件的更多信息，请访问[https://www.elastic.co/guide/en/logstash/current/filter-plugins.html](https://www.elastic.co/guide/en/logstash/current/filter-plugins.html)。
- en: 'The `NGINXACCESS` pattern being referred to in the preceding code is defined
    externally in what the `grok {}` filter calls a `patterns` file. Write the following
    as its content:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中提到的`NGINXACCESS`模式是在外部定义的，称为`grok {}`过滤器所调用的`patterns`文件。将以下内容写入其中：
- en: '[PRE13]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally, rebuild our `hubuser/logstash` Docker container from [Chapter 4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 4. Monitoring Docker Hosts and Containers"), *Monitoring Docker Hosts
    and Containers*. Don''t forget to update the `Dockerfile` as follows to add the
    patterns file to our Docker context:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，从[第4章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e "第4章。监控Docker主机和容器")，*监控Docker主机和容器*中重建我们的`hubuser/logstash`
    Docker容器。别忘了按照以下方式更新`Dockerfile`，以将模式文件添加到我们的Docker上下文中：
- en: '[PRE14]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now that we extracted the response times from the Nginx access logs, we can
    plot these data points in a Kibana visualization. The following is a screenshot
    of Kibana showing the average response time per second of the benchmark we ran
    earlier:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经从Nginx访问日志中提取了响应时间，可以在Kibana可视化中绘制这些数据点。以下是Kibana的截图，显示了我们先前运行的基准测试的每秒平均响应时间：
- en: '![Observing performance in Graphite and Kibana](img/00030.jpeg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![在Graphite和Kibana中观察性能](img/00030.jpeg)'
- en: 'Another result that we can explore is the way our Docker host `webapp` responds
    with the load received from our benchmark. First we can check how our web application
    consumes the CPU of our Docker host. Let''s log in to our monitoring system''s
    graphite-web dashboard and plot the metrics `webapp.cpu-0.cpu-*` except `cpu-idle`.
    As we can see in the following image, the CPU of our Docker host goes to 100 percent
    usage the moment we start sending our application a lot of requests:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以探索的另一个结果是Docker主机`webapp`如何响应基准测试负载。首先，我们可以检查我们的Web应用程序如何消耗Docker主机的CPU。让我们登录到监控系统的graphite-web仪表板，并绘制`webapp.cpu-0.cpu-*`的度量值，排除`cpu-idle`。正如我们在以下图像中看到的，当我们开始向应用程序发送大量请求时，Docker主机的CPU使用率迅速达到100%：
- en: '![Observing performance in Graphite and Kibana](img/00031.jpeg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![在Graphite和Kibana中观察性能](img/00031.jpeg)'
- en: We can explore other system measurements of our Docker host to see how it is
    affected by the load of HTTP requests that it gets. The important point is that
    we use this data and correlate it to see how our web application behaved.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以探索Docker主机的其他系统度量，看看它是如何受到HTTP请求负载影响的。关键点是，我们使用这些数据并进行关联，看看我们的Web应用程序的表现如何。
- en: Note
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Apache JMeter version 2.13 and later include a backend listener that we can
    use to send JMeter data measurements in real time to external endpoints. By default,
    it ships with support for the Graphite wire protocol. We can use this feature
    to send benchmark results to the Graphite monitoring infrastructure that we built
    in [Chapter 4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "Chapter 4. Monitoring Docker Hosts and Containers"), *Monitoring Docker Hosts
    and Containers*. More information on how to use this feature is available at [http://jmeter.apache.org/usermanual/realtime-results.html](http://jmeter.apache.org/usermanual/realtime-results.html).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Apache JMeter版本2.13及更高版本包括一个后端监听器，我们可以使用它实时将JMeter数据度量发送到外部端点。默认情况下，它支持Graphite
    wire协议。我们可以利用这个功能将基准测试结果发送到我们在[第4章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "第4章。监控Docker主机和容器")，*监控Docker主机和容器*中构建的Graphite监控基础设施。关于如何使用此功能的更多信息，请访问[http://jmeter.apache.org/usermanual/realtime-results.html](http://jmeter.apache.org/usermanual/realtime-results.html)。
- en: Tuning the benchmark
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整基准测试
- en: At this point, we already have a basic workflow of creating a test plan in Apache
    JMeter and analyzing the preliminary results. From here, there are several parameters
    we can adjust to achieve our benchmark objectives. In this section, we will iterate
    on our test plan to identify the limits of our Docker application.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经拥有了在 Apache JMeter 中创建测试计划并分析初步结果的基本工作流程。在此基础上，我们可以调整几个参数来实现基准测试目标。在本节中，我们将迭代我们的测试计划，以识别
    Docker 应用程序的限制。
- en: Increasing concurrency
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增加并发量
- en: The first parameter that we may want to tune is increasing the **Loop Count**
    of our test plan. Driving our test plan to generate more requests will allow us
    to see the effects of the load we induced to our application. This increases the
    precision of our benchmark experiments, because outlier events such as a slow
    network connection or hardware failure (unless we are testing that specifically!)
    affect our tests.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能希望调整的第一个参数是增加 **循环次数**。推动我们的测试计划生成更多请求将帮助我们观察负载对应用程序的影响。这提高了基准实验的精度，因为网络连接缓慢或硬件故障等异常事件（除非我们专门测试这些情况！）会影响我们的测试结果。
- en: After having enough data points for our benchmarks, we may realize that the
    load being generated is not enough against our Docker application. For example,
    the current throughput we received from our first analysis may not simulate the
    behavior of real users. Let us say that we want to have 2000 requests per second.
    To increase the rate at which JMeter generates the requests, we can increase the
    number of threads in the thread group that we created earlier. This increases
    the number of concurrent requests that JMeter is creating at a time. If we want
    to simulate a gradual increase in the number of users, we can adjust the ramp-up
    period to be longer.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在为我们的基准测试收集到足够的数据点后，我们可能会发现生成的负载不足以对抗我们的 Docker 应用程序。例如，第一轮分析得到的当前吞吐量可能无法模拟真实用户的行为。假设我们希望每秒处理
    2000 个请求。为了提高 JMeter 生成请求的速率，我们可以增加先前创建的线程组中的线程数量。这将增加 JMeter 同时生成的并发请求数。如果我们想要模拟用户数的逐步增加，我们可以将
    ramp-up 时间设定得更长。
- en: Tip
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: For workloads where we want to simulate a sudden increase of users, we can stick
    with a ramp-up period of 0 to start all the threads right away. In cases where
    we want to tune other behaviors such as a constant load and then a sudden spike,
    we can use the **Stepping Thread Group** plugin.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们希望模拟用户突然增加的工作负载，可以保持 ramp-up 时间为 0，立即启动所有线程。在我们希望调整其他行为（例如恒定负载然后突然激增）时，可以使用
    **Stepping Thread Group** 插件。
- en: We may also want to limit it to precisely just 100 requests per second. Here,
    we can use `Timer` elements to control how our threads generate the request. To
    start limiting throughput, we can use the **Constant Throughput Timer**. This
    will make JMeter automatically slow down threads when it perceives that the throughput
    it is receiving from our web application is increasing too much.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可能希望将其限制为每秒仅 100 个请求。在这种情况下，我们可以使用 `Timer` 元素来控制线程生成请求的方式。为了开始限制吞吐量，我们可以使用
    **常量吞吐量定时器**。当 JMeter 发现来自我们的 web 应用程序的吞吐量增加过快时，它会自动减慢线程速度。
- en: Some of the benchmark techniques here are difficult to apply with the built-in
    Apache JMeter components. There are a variety of plugins that make it simpler
    to generate the load to drive our application. They are available as plugins.
    The Apache JMeter list of popularly used community plugins is found at [http://jmeter-plugins.org](http://jmeter-plugins.org).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的一些基准测试技术很难通过内置的 Apache JMeter 组件来应用。为了简化生成负载以驱动应用程序的过程，存在多种插件可供使用。它们作为插件提供。Apache
    JMeter 常用的社区插件列表可以在[http://jmeter-plugins.org](http://jmeter-plugins.org)找到。
- en: Running distributed tests
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行分布式测试
- en: After tuning the concurrency parameters for a while, we realize that our result
    does not change. We may set JMeter to generate 10,000 requests at a time, but
    that will most likely crash our UI! In this case, we are already reaching the
    performance limits of our workstation while building the benchmarks. From this
    point, we can start exploring using a pool of servers that run JMeter to create
    distributed tests. Distributed tests are useful, because we can grab several servers
    from the cloud with higher performance to simulate spikes. It is also useful for
    creating load coming from several sources. This distributed setup is useful for
    simulating high-latency scenarios, where our users are accessing our Docker application
    from halfway across the world.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 调整并发参数一段时间后，我们意识到结果并没有变化。我们可以设置 JMeter 一次生成 10,000 个请求，但这很可能会导致我们的 UI 崩溃！在这种情况下，我们在构建基准测试时已经达到了工作站的性能极限。从这里开始，我们可以考虑使用多个运行
    JMeter 的服务器池来创建分布式测试。分布式测试非常有用，因为我们可以从云端获取几台性能更高的服务器来模拟流量峰值。它也适用于模拟来自多个源的负载。这种分布式设置对于模拟高延迟场景非常有用，尤其是当我们的用户从世界各地访问我们的
    Docker 应用时。
- en: 'Execute the following steps for deploying Apache JMeter on several Docker hosts
    to perform a distributed benchmark:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以在多个 Docker 主机上部署 Apache JMeter，进行分布式基准测试：
- en: 'First, create the following `Dockerfile` to create a Docker image called `hubuser/jmeter`:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，创建以下 `Dockerfile` 来创建一个名为 `hubuser/jmeter` 的 Docker 镜像：
- en: '[PRE15]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Next, provision the number of Docker hosts we want according to our cloud or
    server provider. Take note of the hostname or IP address of each Docker host.
    For our case, we created two Docker hosts called `dockerhost1` and `dockerhost2`.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，根据我们的云或服务器提供商，配置所需的 Docker 主机数量。记下每个 Docker 主机的主机名或 IP 地址。在我们的案例中，我们创建了两个名为
    `dockerhost1` 和 `dockerhost2` 的 Docker 主机。
- en: 'Now, we will run the JMeter server on our Docker hosts. Log in to each of them,
    and type the following command:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将在 Docker 主机上运行 JMeter 服务器。登录到每台主机，并输入以下命令：
- en: '[PRE16]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To finalize our JMeter cluster, we will type the following command to launch
    the JMeter UI client connected to the JMeter servers:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要完成我们的 JMeter 集群，我们将输入以下命令启动 JMeter UI 客户端，并连接到 JMeter 服务器：
- en: '[PRE17]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: With an Apache JMeter cluster at our disposal, we are now ready to run distributed
    tests. Note that the number of threads in the test plan specifies the thread count
    on each JMeter server. In the case of the test plan we made in the earlier section,
    our JMeter benchmark will generate 240,000 requests. We should adjust these counts
    according to the test workload we have in mind. Some of the guidelines we mentioned
    in the previous section can be used to tune our remote tests.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 有了 Apache JMeter 集群，我们现在可以运行分布式测试了。请注意，测试计划中的线程数指定了每个 JMeter 服务器上的线程数。在我们之前章节中制作的测试计划中，我们的
    JMeter 基准测试将生成 240,000 个请求。我们应该根据预期的测试负载调整这些计数。前面章节中提到的一些指南可以用来调整我们的远程测试。
- en: 'Finally, to start the remote tests, select **Remote Start All** from the **Run**
    menu. This will spawn the thread groups we created in our test plan to our JMeter
    servers in `dockerhost1` and `dockerhost2`. When we look at our access logs of
    Nginx, we can now see that the IP sources are coming from two different sources.
    The following IP addresses come from each of our Docker hosts:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，要启动远程测试，从 **Run** 菜单中选择 **Remote Start All**。这将把我们在测试计划中创建的线程组分配到 `dockerhost1`
    和 `dockerhost2` 上的 JMeter 服务器。当我们查看 Nginx 的访问日志时，我们现在可以看到 IP 来源来自两个不同的源。以下 IP
    地址分别来自我们的两个 Docker 主机：
- en: '[PRE18]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: More information on distributed and remote testing can be found at [http://jmeter.apache.org/usermanual/remote-test.html](http://jmeter.apache.org/usermanual/remote-test.html).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 有关分布式和远程测试的更多信息，请访问 [http://jmeter.apache.org/usermanual/remote-test.html](http://jmeter.apache.org/usermanual/remote-test.html)。
- en: Other benchmarking tools
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他基准测试工具
- en: 'There are a few other benchmarking tools specifically for benchmarking web-based
    applications. The following is a short list of such tools with their links:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些专门用于基准测试基于 Web 的应用程序的工具。以下是这些工具的简短列表及其链接：
- en: '**Apache** **Bench**: [http://httpd.apache.org/docs/2.4/en/programs/ab.html](http://httpd.apache.org/docs/2.4/en/programs/ab.html)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache** **Bench**: [http://httpd.apache.org/docs/2.4/en/programs/ab.html](http://httpd.apache.org/docs/2.4/en/programs/ab.html)'
- en: '**HP Lab''s** **Httperf**: [http://www.hpl.hp.com/research/linux/httperf](http://www.hpl.hp.com/research/linux/httperf)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HP Lab''s** **Httperf**: [http://www.hpl.hp.com/research/linux/httperf](http://www.hpl.hp.com/research/linux/httperf)'
- en: '**Siege**: [https://www.joedog.org/siege-home](https://www.joedog.org/siege-home)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Siege**: [https://www.joedog.org/siege-home](https://www.joedog.org/siege-home)'
- en: Summary
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we created benchmarks for gauging the performance of our Docker
    application. By using Apache JMeter and the monitoring system we set up in [Chapter
    4](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e "Chapter 4. Monitoring
    Docker Hosts and Containers"), *Monitoring Docker Hosts and Containers,* we analyzed
    how our application behaved under various conditions. We now have an idea about
    the limitations of our application, and will use it to further optimize it or
    to scale it out.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们创建了衡量 Docker 应用程序性能的基准。通过使用 Apache JMeter 和我们在[第4章](part0028_split_000.html#QMFO1-afc4585f6623427885a0b0c8e5b2e22e
    "第4章. 监控 Docker 主机和容器")中设置的监控系统，*监控 Docker 主机和容器*，我们分析了应用程序在不同条件下的表现。现在我们对应用程序的局限性有了了解，并将利用这些信息进一步优化或扩展它。
- en: In the next chapter, we will talk about load balancers for scaling-out our application
    to increase its capacity.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论负载均衡器，如何扩展我们的应用程序以提高其容量。
