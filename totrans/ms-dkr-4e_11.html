<html><head></head><body><div><div><p id="_idParaDest-202" class="chapter-number"><a id="_idTextAnchor294"/><em class="italic">Chapter 11</em></p>
			<h1 id="_idParaDest-203"><a id="_idTextAnchor295"/>Docker and Kubernetes</h1>
			<p>In this chapter, we will be taking a look at Kubernetes. Like Docker Swarm, you can use Kubernetes to create and manage clusters that run your container-based applications.</p>
			<p>We will be discussing the following topics in this chapter:</p>
			<ul>
				<li>An introduction to Kubernetes</li>
				<li><a id="_idTextAnchor296"/><a id="_idTextAnchor297"/>Enabling Kubernetes in Docker Desktop</li>
				<li>Using Kubernetes and Docker Desktop</li>
				<li>Kubernetes and other Docker tools</li>
			</ul>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor298"/>Technical requirements</h1>
			<p>Kubernetes within Docker only supports by Docker for Mac and Docker for Windows desktop clients. If you are running Linux then in the next chapter, <a href="B15659_12_Final_JM_ePub.xhtml#_idTextAnchor394"><em class="italic">Chapter 12</em></a><em class="italic">, Discovering more Kubernetes options</em>, we are going to be looking at some options that will be |relevant to you.</p>
			<p>Like previous chapters, I will be using my preferred operating system, which is macOS. As before, some of the supporting commands, which will be few and far between, may only apply to macOS.</p>
			<p>Check out the following video to see the Code in Action: <a href="https://bit.ly/3m1WRiw">https://bit.ly/3m1WRiw</a></p>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor299"/>An introduction to Kubernetes</h1>
			<p>If you have <a id="_idIndexMarker775"/>been thinking about looking at containers, then you would have come across Kubernetes at some point on your travels, so before we enable it within our Docker desktop installation, let's take a moment to look at how Kubernetes started life.</p>
			<p><strong class="bold">Kubernetes</strong>, pronounced <strong class="bold">koo-ber-net-eez</strong>, originates from the Greek name given to a helmsman or<a id="_idIndexMarker776"/> captain of a ship. </p>
			<p class="callout-heading">Info</p>
			<p class="callout">The method of shortening the name adopted by the Kubernetes team is called a numeronym and was devised in the 80s, and is still used today. See <a href="https://en.wikipedia.org/wiki/Numeronym">https://en.wikipedia.org/wiki/Numeronym</a> for more information.</p>
			<p>Kubernetes, which is <a id="_idIndexMarker777"/>also known as <strong class="bold">K8s</strong> – the number 8 in the<a id="_idIndexMarker778"/> K8s shorthand represents the<a id="_idIndexMarker779"/> number of letters between the K and S, the 'ubernete' part – is an open source project that originated at Google and allows you to automate the deployment, management, and scaling of your containerized applications.</p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor300"/>A brief history of containers at Google</h2>
			<p>Google has been <a id="_idIndexMarker780"/>working on Linux container-based solutions for quite a long time. It took its first steps in 2006 by working on the Linux kernel feature called <strong class="bold">Control Groups</strong><strong class="bold"> </strong>(<strong class="bold">cgroups</strong>). This feature<a id="_idIndexMarker781"/> was merged into the Linux kernel in 2008 within release 2.6.24. </p>
			<p>The feature allows you to isolate resources, such as CPU, RAM, networking, and disk I/O, or one or more processes. Control Groups remains a core requirement for Linux containers and is not only used by Docker but also other container tools.</p>
			<p>Google next dipped their toes into the container waters with a container stack <a id="_idTextAnchor301"/><a id="_idTextAnchor302"/>called <strong class="bold">lmctfy</strong>, which <a id="_idIndexMarker782"/>stands for <strong class="bold">Let Me Contain That For You</strong> and was an alternative to the <strong class="bold">LXC</strong> collection of tools and libraries. It was an open sourced version of Google's internal toolset, which they used to manage containers in their applications.</p>
			<p>The next time Google hit the news about their container usage was following a talk given by <em class="italic">Joe Beda</em> at <em class="italic">Gluecon</em> in May 2014. During the presentation, Beda revealed that pretty much everything within Google was container-based and that they were launching around 2 billion containers a week. It was stated that this number did not include any long-running containers, meaning that the containers were only active for a short amount of time. However, after some quick math, on average Google was launching around 3,000 containers per second!</p>
			<p>Later in the talk, Beda mentioned that Google was using a scheduler, so they didn't have to manually manage 2 billion containers a week or even worry about where they were launched and, to a lesser extent, each container's availability.</p>
			<p>Google also published a paper called <em class="italic">Large-scale cluster management at Google with Borg</em>. This paper not only let people outside of Google know the name of the scheduler they were using, <strong class="bold">Borg</strong>, but it also went into great detail about the design decisions they made when designing the scheduler.</p>
			<p>The paper mentioned that as well as their internal tools, Google was running its customer-facing applications, such as Google Docs, Google Mail, and Google Search, in containers running clusters, which are managed by Borg.</p>
			<p><strong class="bold">Borg</strong> was named after<a id="_idIndexMarker783"/> the alien race, the Borg, from the Star Trek: The Next Generation TV show. In the TV show, the Borg are a race of cybernetic beings whose civilization is founded on a hive mind known as the collective. This gives them not only the ability to share the same thoughts but also, through a sub-space network, ensure that each member of the collective is given guidance and supervision from the collective consciousness. I am<a id="_idIndexMarker784"/> sure you will agree, the characteristics of the Borg race matches that closely how you would want your cluster of containers to run.</p>
			<p>Borg was running within Google for several years and it was eventually replaced by a more modern scheduler called Omega. It was around this time that Google announced it that it would be taking some of the core functionality of Borg and reproducing it as a new open source project. This project, known internally as <strong class="bold">Seven</strong>, was worked on by several of the core contributors to Borg. It aimed to create a friendlier version of Borg that wasn't closely tied into Google's own internal procedures and ways of working.</p>
			<p><strong class="bold">Seven</strong>, named after the <em class="italic">Star Trek: Voyager character</em> Seven of Nine, who was a Borg that broke away from the collective, would eventually be named <strong class="bold">Kubernetes</strong> by the time of its first public commit.</p>
			<p>So, now that we know how Kubernetes came to be, we can dig a little deeper into what Kubernetes is. </p>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor303"/>An overview of Kubernetes</h2>
			<p>The bulk of the<a id="_idIndexMarker785"/> project, 90.7% at the time of writing this, is written in Go, which should come as no surprise as Go is a programming language that was developed internally at Google before it was open sourced in 2011. The rest of the project files are made up of Python and Shell helper scripts and HTML documentation.</p>
			<p>A typical Kubernetes cluster is made up of servers that take on either a master or node role. You can also run a standalone installation that takes on both roles.</p>
			<p>The master role is where the magic happens, and it is the brains of the cluster. It is responsible for making decisions on where pods are launched and for monitoring the health of both the cluster itself and also of the pods running within the cluster. We will discuss pods once we have finished looking at the two roles.</p>
			<p>Typically, the core<a id="_idIndexMarker786"/> components that are deployed to a host that has been given the role of a master are as follows:</p>
			<ul>
				<li><code>kube-apiserver</code>: This component exposes the main Kubernetes API. It is designed to horizontally scale, which means that you can keep adding more instances of it to make your cluster highly available.</li>
				<li><code>etcd</code>: This is a highly available consistent key-value store. It is used to store the state of the cluster.</li>
				<li><code>kube-scheduler</code>: This component is responsible for making the decisions on where pods are launched.</li>
				<li><code>kube-controller-manager</code>: This component runs controllers. These controllers have several functions within Kubernetes, such as monitoring the nodes, keeping an eye on the replication, managing the endpoints, and generating service accounts and tokens.</li>
				<li><code>cloud-controller-manager</code>: This component takes on the management of the various controllers, which interact with third-party clouds to launch and configure supporting services.</li>
			</ul>
			<p>Now that we have our management components covered, we need to discuss what they are managing. A node is made up of the following elements:</p>
			<ul>
				<li><code>kubelet</code>: This agent runs on each node within the cluster, and it is the means by which the managers interact with the nodes. It is also responsible for managing the pods.</li>
				<li><code>kube-proxy</code>: This component manages all of the routing of requests and traffic for both the node and also the pods.</li>
				<li><code>container runtime</code>: This could be Docker, CRI-O, or any other OCI-compliant runtime.</li>
			</ul>
			<p>You may have noticed that I have not mentioned containers much so far. This is because Kubernetes doesn't<a id="_idIndexMarker787"/> actually directly interact with your containers; instead, it communicates with a pod. Think of a pod as a complete application, a little like when we looked at launching an application made up of multiple containers using Doc<a id="_idTextAnchor304"/><a id="_idTextAnchor305"/>ker Compose.</p>
			<h2 id="_idParaDest-208"><a id="_idTextAnchor306"/>How does Docker fit in with Kubernetes?</h2>
			<p>Docker's relationship <a id="_idIndexMarker788"/>with Kubernetes is varied. To start with, Docker, the<a id="_idIndexMarker789"/> container engine, powers a lot of Kubernetes installations in one form or another, for example, as Docker or ContainerD.</p>
			<p>However, Kubernetes was originally seen as a competitive technology to Docker Swarm, which was Docker's own clustering technology. However, over the last few years, Kubernetes has emerged as pretty much the de facto standard for container clustering/orchestration.</p>
			<p>All of <a id="_idIndexMarker790"/>the <a id="_idIndexMarker791"/>major<a id="_idIndexMarker792"/> cloud providers provide Kubernetes-as-a-service. We have the following:</p>
			<ul>
				<li><strong class="bold">Google Cloud</strong>: <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>)</li>
				<li><strong class="bold">Microsoft Azure</strong>: <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>)</li>
				<li><strong class="bold">Amazon Web Services</strong>: <strong class="bold">Amazon Elastic Container Service for Kubernetes</strong> (<strong class="bold">EKS</strong>)</li>
				<li><strong class="bold">IBM</strong>: <strong class="bold">IBM Cloud Kubernetes Service</strong></li>
				<li><strong class="bold">Oracle Cloud</strong>: <strong class="bold">Oracle Container Engine for Kubernetes</strong></li>
				<li><strong class="bold">DigitalOcean</strong>: <strong class="bold">Kubernetes on DigitalOcean</strong></li>
			</ul>
			<p>On the face of it, all of the major players supporting Kubernetes may not seem like that big a deal. However, consider that we now know a consistent way of deploying our containerized applications across multiple platforms. Traditionally, these platforms have been walled gardens and have very different ways of interacting with them.</p>
			<p>While Docker's announcement of Kubernetes support in its desktop versions in October 2017 at DockerCon Europe initially came as a surprise, once the dust settled the announcement made perfect sense. Providing developers with an environment where they could work on their applications locally using Docker for Mac and Docker for Windows, and <a id="_idIndexMarker793"/>then using Docker Enterprise Edition to deploy and manage their <a id="_idIndexMarker794"/>own Kubernetes clusters, or even use one of the cloud services mentioned previously, fits in with trying to solve the 'works on my machine' problem we discussed in <a href="B15659_01_Final_JM_ePub.xhtml#_idTextAnchor046"><em class="italic">Chapter 1</em></a>, <em class="italic">Docker Overview</em>.</p>
			<p>Let's now take a look at how you can enable support in the Docker software and get stuck in using it.</p>
			<p>Enabling Kubernetes in Docker Desktop</p>
			<p>Docker has<a id="_idIndexMarker795"/> made the installation process<a id="_idIndexMarker796"/> extremely simple. All you need to do to enable Kubernetes support is open <strong class="bold">Preferences</strong> and click on th<a id="_idTextAnchor307"/><a id="_idTextAnchor308"/>e <strong class="bold">Kubernetes</strong> tab:</p>
			<div><div><img src="img/image_00_0012.jpg" alt="Figure 11.1 – The Kubernetes preferences in Docker for Mac&#13;&#10;" width="851" height="606"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.1 – The Kubernetes preferences in Docker for Mac</p>
			<p>As you can see, there <a id="_idIndexMarker797"/>are three options. Tick the <strong class="bold">Enable Kubernete<a id="_idTextAnchor309"/><a id="_idTextAnchor310"/>s</strong> box <a id="_idIndexMarker798"/>and then select <strong class="bold">Deploy Docker Stacks to Kubernetes by default</strong>. Leave <strong class="bold">Show systems containers (advanced)</strong> unticked for now; we look at this in a little more detail once we have enabled the service.</p>
			<p>Clicking <strong class="bold">Apply &amp; Restart</strong> will do just that, restart Docker and enable Kubernetes:</p>
			<div><div><img src="img/image_00_0022.jpg" alt="Figure 11.2 – Enabling Kubernetes on Docker for Mac&#13;&#10;" width="929" height="549"/>
				</div>
			</div>
			<p class="figure-caption">F<a id="_idTextAnchor311"/><a id="_idTextAnchor312"/>igure 11.2 – Enabling Kubernetes on Docker for Mac</p>
			<p>It will take a short while for Docker to download, configure, and launch the cluster. Once complete, you should see Docker and Kubernetes listed in the bottom left of the settings <a id="_idIndexMarker799"/>window. Both should have a green dot next to <a id="_idIndexMarker800"/>them to indicate that the services are running:</p>
			<div><div><img src="img/image_00_0032.jpg" alt="Figure 11.3 – Kubernetes successfully enabled on Docker for Mac&#13;&#10;" width="826" height="541"/>
				</div>
			</div>
			<p class="figure-caption"> Figure 11.3 – Kubernetes successfully enabled on Docker for Mac</p>
			<p>Open Terminal and run the following command:</p>
			<pre>$ docker container ls -a</pre>
			<p>This should show you that there is nothing out of the ordinary running. Run <a id="_idTextAnchor313"/><a id="_idTextAnchor314"/><a id="_idTextAnchor315"/>the following command:</p>
			<pre>$ docker image ls</pre>
			<p>Again, this shows nothing of interest; however, as you might hav<a id="_idTextAnchor316"/><a id="_idTextAnchor317"/>e guessed, ticking the <strong class="bold">Show system containers (advanced)</strong> option in the <strong class="bold">Settings</strong> window will change this. Tick it now and then re-run the following command:</p>
			<pre>$ docker container ls -a</pre>
			<p>As there is a lot of output when running the preceding command, the following screenshot shows just the names of the containers. To do this, <a id="_idTextAnchor318"/><a id="_idTextAnchor319"/>I ran the following:</p>
			<pre>$ docker container ls --format {{.Names}}</pre>
			<p>Running the command gave me the following:</p>
			<div><div><img src="img/image_00_0042.jpg" alt="Figure 11.4 – Listing the containers that make up our Kubernetes installation&#13;&#10;" width="1254" height="666"/>
				</div>
			</div>
			<p class="figure-caption"> Figure 11.4 – Listing the containers that make up our Kubernetes installation</p>
			<p>There are 20 running <a id="_idIndexMarker801"/>containers, which is why you have the <a id="_idIndexMarker802"/>option of hiding them. As you can see, nearly all of the components we discussed in the previous section are covered as well as a few additional components, which provide the integration with Docker. </p>
			<p>Run the following command:</p>
			<pre>$ docker image ls</pre>
			<p>It still doesn't list any images, although we get a list of images that are being used by running the following:</p>
			<pre>$ docker container ls --format {{.Image}}</pre>
			<p>As you can see from the following output, the images are sourced from both Docker and also the official Kubernetes images that are available from the Goo<a id="_idTextAnchor320"/><a id="_idTextAnchor321"/>gle Container Registry (k8s.gcr.io), and there are also some images that <a id="_idTextAnchor322"/><a id="_idTextAnchor323"/>ha<a id="_idTextAnchor324"/><a id="_idTextAnchor325"/>ve been built locally:</p>
			<div><div><img src="img/image_00_0052.jpg" alt="Figure 11.5 – Viewing the images being used to power the Kubernetes installation &#13;&#10;" width="583" height="639"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.5 – Viewing the images being used to power the Kubernetes installation </p>
			<p>For now, I would<a id="_idIndexMarker803"/> recommend unticking the <strong class="bold">Show system containers (advanced)</strong> option, as we do not need to see a list of 20 containers<a id="_idIndexMarker804"/> running each time that we look at the running containers.</p>
			<p>The other thing to note at this point is that the <strong class="bold">Kubernetes</strong> menu item in the Docker app now has content in it. This menu can be used for switching between Kubernetes clusters. As we only have one cluster active at the moment, there is only one listed:</p>
			<div><div><img src="img/image_00_0062.jpg" alt="Figure 11.6 – Checking the Kubernetes menu item&#13;&#10;" width="778" height="573"/>
				</div>
			</div>
			<p class="figure-caption"> Figure 11.6 – Checking the Kubernetes menu item</p>
			<p>Now that we <a id="_idIndexMarker805"/>have our local Kubernetes cluster up and<a id="_idIndexMarker806"/> running, we can start to use it.</p>
			<h1 id="_idParaDest-209"><a id="_idTextAnchor326"/>Using Kubernetes and Docker Desktop</h1>
			<p>Now that we <a id="_idIndexMarker807"/>have our Kubernetes cluster up and running on our Docker desktop<a id="_idIndexMarker808"/> installation, we can start to interact with it. To start with, we are going to look at the command line that was installed alongside the Docker desktop component, <code>kubectl</code>.</p>
			<p>As mentioned, <code>kubectl</code> was installed alongside Docker. The following command will show some information about the client and also the cl<a id="_idTextAnchor327"/><a id="_idTextAnchor328"/>uster it is connected to:</p>
			<pre>$ kubectl version</pre>
			<p>Like when running <code>docker version</code>, this should give you information on both the client and server:</p>
			<div><div><img src="img/image_00_0072.jpg" alt="Figure 11.7 – Checking the versions of the client and server&#13;&#10;" width="1254" height="254"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.7 – Checking the versions of the client and server</p>
			<p>Next, we can run the following to see if <code>k<a id="_idTextAnchor329"/><a id="_idTextAnchor330"/>ubectl</code> can see our node:</p>
			<pre>$ kubectl get nodes</pre>
			<p>As we only <a id="_idIndexMarker809"/>have a <a id="_idIndexMarker810"/>single node, we should only see one listed:</p>
			<div><div><img src="img/image_00_0082.jpg" alt="Figure 11.8 – Listing our nodes&#13;&#10;" width="624" height="144"/>
				</div>
			</div>
			<p class="figure-caption"> Figure 11.8 – Listing our nodes</p>
			<p>Now that we have our client interacting with our node, we can view the namespaces that are configured by default within Kubernetes by runni<a id="_idTextAnchor331"/><a id="_idTextAnchor332"/>ng the following command:</p>
			<pre>$ kubectl get namespaces</pre>
			<p>Then we can view the pods within a namespace wi<a id="_idTextAnchor333"/><a id="_idTextAnchor334"/>th the following command:</p>
			<pre>$ kubectl get pods --namespace kube-system </pre>
			<p>What follows is the Terminal output I received when I ran the preceding commands:</p>
			<div><div><img src="img/image_00_0092.jpg" alt="Figure 11.9 – Checking the namespaces&#13;&#10;" width="934" height="529"/>
				</div>
			</div>
			<p class="figure-caption"> Figure 11.9 – Checking the namespaces</p>
			<p>Namespaces within Kubernetes are a great way of isolating resources within your cluster. As you can see from the Terminal output, there are four namespaces within our cluster. There<a id="_idIndexMarker811"/> is the <code>default</code> namespace, which is typically<a id="_idIndexMarker812"/> empty. There are two namespaces for the main Kubernetes services: <code>docker</code> and <code>kube-system</code>. These contain the pods that make up our cluster and the final namespace, <code>kube-public</code>, like the default namespace, is empty.</p>
			<p>Before we launch our own pod, let's take a quick look at how we can interact with the pods we have running, starting with how we can find more information about our <a id="_idTextAnchor335"/><a id="_idTextAnchor336"/>pod:</p>
			<pre>$ kubectl describe pods kube-scheduler-docker-desktop 
--namespace kube-system </pre>
			<p>The preceding command will <a id="_idTextAnchor337"/><a id="_idTextAnchor338"/>print out the details of the <code>kube-scheduler-docker-desktop</code> pod. You might notice that we had to pass the namespace using the <code>--namespace</code> flag. If we didn't, then <code>kubectl</code> would default to the default namespace where there isn't a pod called <code>kube-scheduler-docker-desktop</code> running.</p>
			<p>The full output of the command is shown here, starting with some basic information on the pod:</p>
			<pre>Name:                 kube-scheduler-docker-desktop
Namespace:            kube-system
Priority:             2000000000
Priority Class Name:  system-cluster-critical
Node:                 docker-desktop/192.168.65.3
Start Time:           Sun, 03 May 2020 12:11:02 +0100</pre>
			<p>Like Docker, you can apply labels to pods. This is shown in the following screenshot, along with some more details around the pod:</p>
			<pre>Labels:               component=kube-scheduler
                      tier=control-plane
Annotations:          kubernetes.io/config.hash: 131c3f63daec7c
0750818f64a2f75d20
                      kubernetes.io/config.mirror: 131c3f63daec
7c0750818f64a2f75d20
                      kubernetes.io/config.seen: 
2020-05-03T11:10:56.315367593Z
                      kubernetes.io/config.source: file
Status:               Running
IP:                   192.168.65.3</pre>
			<p>What follows<a id="_idIndexMarker813"/> next is information on the container running within the pod. The <a id="_idIndexMarker814"/>information here starts with basic information such as the container ID, images, and ports:</p>
			<pre>Containers:
  kube-scheduler:
    Container ID:  docker://1b7ca730cd85941a5550d816239edc14953
f07b98763751ecb1caf7dfcced087
    Image:         k8s.gcr.io/kube-scheduler:v1.15.5
    Image ID:      docker-pullable://k8s.gcr.io/kube-scheduler@
sha256:ec985e27f41e3ceec552440502dbfa723924d5e6d72fc9193d140972
e24b8b77
    Port:          &lt;none&gt;
    Host Port:     &lt;none&gt;</pre>
			<p>We then move on to the command that is being run within the container:</p>
			<pre>    Command:
      kube-scheduler
      --bind-address=127.0.0.1
      --kubeconfig=/etc/kubernetes/scheduler.conf
      --leader-elect=true</pre>
			<p>Now <a id="_idIndexMarker815"/>we see<a id="_idIndexMarker816"/> its current state:</p>
			<pre>    State:          Running
      Started:      Sun, 03 May 2020 12:11:03 +0100
    Ready:          True
    Restart Count:  0</pre>
			<p>Then we have some information on its utilization:</p>
			<pre>    Requests:
      cpu:        100m
    Liveness:     http-get http://127.0.0.1:10251/healthz 
delay=15s timeout=15s period=10s #success=1 #failure=8
    Environment:  &lt;none&gt;
    Mounts:
      /etc/kubernetes/scheduler.conf from kubeconfig (ro)</pre>
			<p>Next, we are back to information on the pod. Here, we can see the current status:</p>
			<pre>Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True</pre>
			<p>Then, we see details on the<a id="_idIndexMarker817"/> volumes mounted by the pod and some other options such as <strong class="bold">Quality of Service</strong> (<strong class="bold">QoS</strong>):</p>
			<pre>Volumes:
  kubeconfig:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/scheduler.conf
    HostPathType:  FileOrCreate
QoS Class:         Burstable
Node-Selectors:    &lt;none&gt;
Tolerations:       :NoExecute</pre>
			<p>Finally, you<a id="_idIndexMarker818"/> can <a id="_idIndexMarker819"/>see events listed:</p>
			<pre>Events:
  Type    Reason   Age   From                     Message
  ----    ------   ----  ----                     -------
  Normal  Pulled   39m   kubelet, docker-desktop  Container 
image 'k8s.gcr.io/kube-scheduler:v1.15.5' already present on 
machine
  Normal  Created  39m   kubelet, docker-desktop  Created 
container kube-scheduler
  Normal  Started  39m   kubelet, docker-desktop  Started 
container kube-scheduler</pre>
			<p>As you can see, there<a id="_idIndexMarker820"/> is a lot of information about the pod, including a list of containers; we only have one called <code>kube-scheduler</code>. We can see the container ID, the image used, the flags the container was launched with, and also the data used by the Kubernetes scheduler to launch and maintain the pod.</p>
			<p>Now that we know a container name, we can start to interact with it. For example, running the following command will print the logs for our one container:</p>
			<pre>$ kubectl logs kube-scheduler-docker-desktop -c kube-scheduler 
--namespace kube-system </pre>
			<p>I got the following output:</p>
			<div><div><img src="img/image_00_0102.jpg" alt="Figure 11.10 – Checking the logs on a container in a pod&#13;&#10;" width="1254" height="419"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.10 – Checking the logs on a container in a pod</p>
			<p>Running the<a id="_idIndexMarker821"/> following command would fetch the logs for each container in<a id="_idIndexMarker822"/> the pod:</p>
			<pre>$ kubectl logs --namespace kube-system kube-scheduler-docker-
desktop</pre>
			<p>Like Docker, you can also execute <a id="_idTextAnchor339"/><a id="_idTextAnchor340"/>commands on your pods and containers.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Please ensure you add the space after the <code>--</code> in the following two commands. Failing to do so will result in errors.</p>
			<p>For example, the following commands will run the <code>uname -a</code> command:</p>
			<pre>$ kubectl exec --namespace kube-system kube-scheduler-docker-
de<a id="_idTextAnchor341"/><a id="_idTextAnchor342"/>sktop -c kube-scheduler -- uname -a
$ kubectl exec --namespace kube-system kube-scheduler-docker-
desktop -- uname -a</pre>
			<p>Again, we have the option of running the command on a named container or across all containers within the pod:</p>
			<div><div><img src="img/image_00_0112.jpg" alt="Figure 11.11 – Running a command across all the containers in a pod&#13;&#10;" width="1143" height="116"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.11 – Running a command across all the containers in a pod</p>
			<p>Let's find out a little more about our Kubernetes cluster by installing and logging into the web-based dashboard.</p>
			<p>While this does<a id="_idIndexMarker823"/> not ship with Docker by default, installing it using the definition <a id="_idIndexMarker824"/>file provided by the Kubernetes project is simple. We just need to run the following command:</p>
			<pre>$ kubectl apply -f https://raw.githubusercontent.com/
kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml</pre>
			<p>As soon as you run the command, you should see something like the following output:</p>
			<div><div><img src="img/image_00_0122.jpg" alt="Figure 11.12 – Deploying the web-based dashboard&#13;&#10;" width="1253" height="501"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.12 – Deploying the web-based dashboard</p>
			<p>Once the services and deployments have been created, it will take a few minutes to launch. You can check on the stat<a id="_idTextAnchor343"/><a id="_idTextAnchor344"/>us by running the following<a id="_idTextAnchor345"/><a id="_idTextAnchor346"/> commands:</p>
			<pre>$ kubectl get namespaces
$ kubectl get deployments --namespace kubernetes-dashboard
$ kubectl get services --namespace kubernetes-dashboard</pre>
			<p>Once your output looks like the following, your dashboard should be installed and ready:</p>
			<div><div><img src="img/image_00_0131.jpg" alt="Figure 11.13 – Checking the status of the deployment&#13;&#10;" width="1090" height="501"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.13 – Checking the status of the deployment</p>
			<p>You may have<a id="_idIndexMarker825"/> noticed that the dashboard has its own namespace<a id="_idIndexMarker826"/> called <code>kubernetes-dashboard</code>. Now that we have our dashboard running, we will find a way to access it. We can do this using the inbuilt proxy service in <code>kubectl</code>. Just run the following command to start it up:</p>
			<pre>$ kubectl proxy</pre>
			<p>This will open a long-running foreground process:</p>
			<div><div><img src="img/image_00_0141.jpg" alt="Figure 11.14 – Starting the proxy service&#13;&#10;" width="493" height="116"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.14 – Starting the proxy service</p>
			<p>Now that the proxy service is runni<a id="_idTextAnchor347"/><a id="_idTextAnchor348"/>ng, opening your browser and going to <a href="http://127.0.0.1:8001/version/">http://127.0.0.1:8001/version/</a> will show you some information on your cluster:</p>
			<div><div><img src="img/image_00_0151.jpg" alt="Figure 11.15 – Information on the cluster&#13;&#10;" width="991" height="348"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.15 – Information on the cluster</p>
			<p>However, it's the dashboard we <a id="_idTextAnchor349"/><a id="_idTextAnchor350"/>want to see. This can be accessed at the following URL:</p>
			<p><a href="http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/">http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/</a></p>
			<p>You should see something like the following screen:</p>
			<div><div><img src="img/image_00_0161.jpg" alt="Figure 11.16 – The dashboard login screen&#13;&#10;" width="745" height="360"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.16 – The Dashboard login screen</p>
			<p>As you can<a id="_idIndexMarker827"/> see, it is asking for us to log in; however, we haven't yet created<a id="_idIndexMarker828"/> any credentials, so let's do that now.</p>
			<p class="callout-heading">Info</p>
			<p class="callout">A service account is a system account, which in most cases uses a token to authenticate against the Kubernetes API to perform an action. Service accounts can be used for both services running within your Kubernetes cluster, as well as in our case, where we as a user want to access to the Dashboard using an API token.</p>
			<p>Open a new Terminal window and en<a id="_idTextAnchor351"/><a id="_idTextAnchor352"/>ter the following command to create a service account:</p>
			<pre>$ kubectl create serviceaccount dashboard-admin-sa</pre>
			<p>The service account will be created in the default namespace; however, that is not going to be a problem as we are now going to assign the service account the <code>cluster-admin</code> role by running the following command:</p>
			<pre>$ kubectl create clusterrolebinding dashboard-admin-sa --clusterrole=cluster-admin --serviceaccount=default:dashboard-admin-sa</pre>
			<p>This should <a id="_idIndexMarker829"/>have created a secret, and we can find the name of the secret<a id="_idIndexMarker830"/> by running the following command:</p>
			<pre>$ kubectl get secrets</pre>
			<p>The following Terminal output shows the steps taken so far:</p>
			<div><div><img src="img/image_00_0171.jpg" alt="Figure 11.17 – Creating the service account, assigning permission, and viewing the secrets&#13;&#10;" width="1254" height="281"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.17 – Creating the service account, assigning permission, and viewing the secrets</p>
			<p>Now that our service account has been created, the correct permissions have been set, and we know the name of the secret (yours will differ as the secret name is affixed with a five-character random string), we can get a copy of the token we need to log in.</p>
			<p>We simply need to run the following command, making sure that you update the secret name to match your own:</p>
			<pre>$ kubectl describe secret dashboard-admin-sa-token-z9x4g</pre>
			<p>This should give you something similar to the following Terminal output:</p>
			<div><div><img src="img/image_00_018.jpg" alt="Figure 11.18 – Viewing the secret&#13;&#10;" width="1255" height="639"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.18 – Viewing the secret</p>
			<p>Make a note of<a id="_idIndexMarker831"/> the token and enter it on the dashboard login page in the <a id="_idIndexMarker832"/>space provided for the token and then click on the <strong class="bold">Sign in</strong> button. Once logged in, you will be presented with something that looks like the following page:</p>
			<div><div><img src="img/image_00_019.jpg" alt="Figure 11.19 – Dashboard first login&#13;&#10;" width="1008" height="679"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.19 – Dashboard first login</p>
			<p>As you can see, the dashboard uses the <code>default</code> namespace. Well, by default, clicking the namespace name will open a drop-down list containing all of the available namespaces. For now, select <strong class="bold">All namespaces</strong> from the top of the list, and you will notice that the view<a id="_idIndexMarker833"/> changes and a lot more information is now displayed on the <a id="_idIndexMarker834"/>overview page.</p>
			<p>Now that we have our cluster up and running, we can now look at launching a few sample applications.</p>
			<h1 id="_idParaDest-210"><a id="_idTextAnchor353"/>Kubernetes and other Docker tools</h1>
			<p>When we<a id="_idIndexMarker835"/> enabled Kubernetes, we selected the <code>docker stack</code> command to launch our Docker Compose files in Docker Swarm and, as you might have guessed, running those same commands will now launch our stack in our Kubernetes cluster.</p>
			<p>The Docker Compo<a id="_idTextAnchor354"/><a id="_idTextAnchor355"/>se file we used looked like the following:</p>
			<pre>version: '3'
services:
  cluster:
    image: russmckendrick/cluster
    ports:
      - '80:80' deploy:
    replicas: 6
    restart_policy:
      condition: on-failure
    placement:
      constraints:
        - node.role == worker</pre>
			<p>Before we launch the application on Kubernetes, we need to make a slight adjustment and remove the <code>placement</code>, which leaves our file looking like the following:</p>
			<pre>version: '3'
services:
  cluster:
    image: russmckendrick/cluster
    ports:
      - '80:80' deploy:
    replicas: 6
    restart_policy:
      condition: on-failure</pre>
			<p>Once the file <a id="_idIndexMarker837"/>has been <a id="_idIndexMarker838"/>edited, running the following command will launch the stack:</p>
			<pre>$ docker stack deploy --compose-file=docker-compose.yml cluster</pre>
			<p>As you can see, Docker waits until the stack is available before returning you to your prompt:</p>
			<div><div><img src="img/image_00_020.jpg" alt="Figure 11.20 – Launching the stack&#13;&#10;" width="1252" height="218"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.20 – Launching the stack</p>
			<p>We can also run the same commands we used to view some information about our stack as we did wh<a id="_idTextAnchor356"/><a id="_idTextAnchor357"/>en we launched our<a id="_idTextAnchor358"/><a id="_idTextAnchor359"/><a id="_idTextAnchor360"/><a id="_idTextAnchor361"/> stack on Docker Swarm:</p>
			<pre>$ docker<a id="_idTextAnchor362"/><a id="_idTextAnchor363"/> stack ls
$ docker stack services cluster
$ docker stack ps cluster</pre>
			<p>The Terminal output gives us similar output to when we launched the stack using a Docker Swarm cluster:</p>
			<div><div><img src="img/image_00_021.jpg" alt="Figure 11.21 – Running the Docker stack commands&#13;&#10;" width="1254" height="744"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.21 – Running the Docker stack commands</p>
			<p>However, please <a id="_idIndexMarker839"/>note, at the time of writing there appears to be an issue <a id="_idIndexMarker840"/>with the <code>docker stack services</code> returning an error, this issue was introduced with an update to the version of Kubernetes that ships with Dock<a id="_idTextAnchor364"/><a id="_idTextAnchor365"/>er.</p>
			<p>We can also see detail<a id="_idTextAnchor366"/><a id="_idTextAnchor367"/>s using <code>kubectl</code>:</p>
			<pre>$ kubectl get deployments
$ kubectl get services</pre>
			<p>You may have noticed that this time we did not need to provide a namespace. This is because our stack was launched in the default namespace:</p>
			<div><div><img src="img/image_00_022.jpg" alt="Figure 11.22 – Viewing details about the deployment and services&#13;&#10;" width="1255" height="309"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.22 – Viewing details about the deployment and services</p>
			<p>Also, when the <a id="_idIndexMarker841"/>services were listed, a <code>localhost</code> and that the port is <code>80</code>.</p>
			<p>Opening <code>http://localhost/</code> in our browser shows the application:</p>
			<div><div><img src="img/image_00_023.jpg" alt="Figure 11.23 – Viewing the cluster application running in Kubernetes&#13;&#10;" width="674" height="441"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.23 – Viewing the cluster application running in Kubernetes</p>
			<p>If you still have the Dashboard open, you can explore your stack and even open a Terminal to one of the containers:</p>
			<div><div><img src="img/image_00_024.jpg" alt="Figure 11.24 – Opening a Terminal to a container&#13;&#10;" width="896" height="477"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.24 – Opening a Terminal to a container</p>
			<p>This was done<a id="_idIndexMarker843"/> by selecting one of the six pods for the cluster deployment and<a id="_idIndexMarker844"/> then clicking on the <strong class="bold">Exec into pod</strong> button highlighted in the following screenshot:</p>
			<div><div><img src="img/image_00_025.jpg" alt="Figure 11.25 – Exec into pod&#13;&#10;" width="1066" height="422"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.25 – Exec into pod</p>
			<p>You can remove t<a id="_idTextAnchor370"/><a id="_idTextAnchor371"/>he stack by running the following command:</p>
			<pre>$ docker stack rm cluster</pre>
			<p>One last thing…you may be thinking to yourself, 'Great, I can run my Docker Compose files anywhere on a Kubernetes cluster.' Well, that is not strictly true.</p>
			<p>As mentioned, when we first enabled Kubernetes, there are some Docker-only components launched. These are there to make sure that Docker is integrated as tightly as possible. However, as these components won't exist in non-Docker managed clusters, you won't be able to use the <code>docker stack</code> commands.</p>
			<p>All is not lost though. There is a<a id="_idIndexMarker845"/> tool called <strong class="bold">Kompose</strong> provided as part of the Kubernetes project, which can take Docker Compose files and convert them on the fly to Kubernetes definition files.</p>
			<p>To install Kompose on macOS using Homebrew, run the following command:</p>
			<pre>$ <a id="_idTextAnchor372"/><a id="_idTextAnchor373"/>brew install kompose</pre>
			<p>Windows 10 users <a id="_idIndexMarker846"/>can use<a id="_idIndexMarker847"/> Chocolatey.</p>
			<p class="callout-heading">Info</p>
			<p class="callout"><code>yum</code> or <code>apt-get</code> on Linux machines or <code>brew</code> on macOS.</p>
			<p>To install Kompose<a id="_idIndexMarker848"/> using Chocolatey, you can run the following command:</p>
			<pre>$ choco install kubernetes-kompose</pre>
			<p>Once it's installed, you can launch your Docker Compose file by running the following command:</p>
			<pre>$ kompose up</pre>
			<p>You will get something like the following output:</p>
			<div><div><img src="img/image_00_026.jpg" alt="Figure 11.26 – Running kompose up&#13;&#10;" width="1255" height="364"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.26 – Running kompose up</p>
			<p>As suggested by the output, running the following command will give you det<a id="_idTextAnchor374"/><a id="_idTextAnchor375"/>a<a id="_idTextAnchor376"/><a id="_idTextAnchor377"/>ils on the service and pod we just launched:</p>
			<pre>$ kubectl get deployment,svc,pods,pvc</pre>
			<p>As you can see, our Docker Compose application is up and running:</p>
			<div><div><img src="img/image_00_027.jpg" alt="Figure 11.27 – Checking the status of the application&#13;&#10;" width="1254" height="333"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.27 – Checking the status of the application</p>
			<p>You can <a id="_idIndexMarker849"/>remove the servic<a id="_idTextAnchor378"/><a id="_idTextAnchor379"/>es and pods by running the following <a id="_idIndexMarker850"/>command:</p>
			<pre>$ kompose down</pre>
			<p>This should give you something like the following:</p>
			<div><div><img src="img/image_00_028.jpg" alt="Figure 11.28 – Running kompose down&#13;&#10;" width="1141" height="171"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.28 – Running kompose down</p>
			<p>While you can use <code>kompose up</code> and <code>kompose down</code>, I would recommend generating the Kubernetes definition files and tweaking them as needed. To do this, simply run the following command:</p>
			<pre>$ kompose convert</pre>
			<p>You will notice that this command generates two files:</p>
			<div><div><img src="img/image_00_029.jpg" alt="Figure 11.29 – Running kompose convert&#13;&#10;" width="1183" height="144"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.29 – Running kompose convert</p>
			<p>You will be able to see quite a <a id="_idIndexMarker851"/>difference between the Docker Compose file and the two files <a id="_idIndexMarker852"/>generated. The <code>cluster-pod.yaml</code> file looks like the following:</p>
			<pre>apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    io.kompose.service: cluster
  name: cluster
spec:
  containers:
  - image: russmckendrick/cluster
    name: cluster
    ports:
    - containerPort: 80
    resources: {}
  restartPolicy: OnFailure
status: {}
And the cluster-service.yaml file contains the following:
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert
    kompose.version: 1.21.0 ()
  creationTimestamp: null
  labels:
    io.kompose.service: cluster
  name: cluster
spec:
  ports:
  - name: '80'
    port: 80
    targetPort: 80
  selector:
    io.kompose.service: cluster
status:
  loadBalancer: {}</pre>
			<p>You can then <a id="_idIndexMarker853"/>launc<a id="_idTextAnchor380"/><a id="_idTextAnchor381"/>h<a id="_idIndexMarker854"/> these files by running the followi<a id="_idTextAnchor382"/><a id="_idTextAnchor383"/>ng command:</p>
			<pre>$ kubectl create -f cluster-p<a id="_idTextAnchor384"/><a id="_idTextAnchor385"/><a id="_idTextAnchor386"/>od.yaml
$ kubectl create -f cluster-service.yaml
$ kubectl get deployment,svc,pods,pvc</pre>
			<p>If you are not following along, the following screenshot shows the Terminal output:</p>
			<div><div><img src="img/image_00_030.jpg" alt="Figure 11.30 – Launching the application using cluster-pod.yaml and cluster-service.yaml&#13;&#10;" width="1253" height="444"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.30 – Launching the application using cluster-pod.yaml and cluster-service.yaml</p>
			<p>To remove the cluster pod and service, we just need to run the following command:</p>
			<pre>$ kubectl delete service/cluster pod/cluster</pre>
			<p>While we will continue to use this in the next two chapters, you may want to disable the Kubernetes<a id="_idIndexMarker855"/> integration within your Docker desktop installation as it does<a id="_idIndexMarker856"/> add a slight overhead to host machine when it is idle. To do this, just untick <strong class="bold">Enable Kubernetes</strong>. When you click <strong class="bold">Apply</strong>, Docker will stop all the containers it needed to run Kubernetes; it won't, however, remove the images so that when you re-enable it, it doesn't take as long.</p>
			<h1 id="_idParaDest-211"><a id="_idTextAnchor387"/>Summary</h1>
			<p>In this chapter, we looked at Kubernetes from the point of view of Docker desktop software. There is a lot more to Kubernetes than we have covered in this chapter, so please don't think th<a id="_idTextAnchor388"/><a id="_idTextAnchor389"/>is is all there is. After discussing the origins of Kubernetes, we looked at how you can enable it on your local machine using Docker for Mac or Docker for Windows.</p>
			<p>We then discussed some basic usage of kubectl before looking at running how we can use <code>docker stack</code> commands to launch our applications as we did for Docker Swarm.</p>
			<p>At the end of the chapter, we discussed Kompose, which is a tool from the Kubernetes project. It helps you convert your Docker Compose files for use with Kubernetes, allowing you to get a head start on moving your applications to pure Kubernetes.</p>
			<p>While we have referred to a Kubernetes cluster throughout this chapter, we have in actual fact been running a single node cluster, which really isn't a cluster at all.</p>
			<p>In the next chapter, we are going to take a look at a few more options on how to launch Kubernetes locally. Here, we will welcome back Linux users and also look at options for launching more than one node.</p>
			<h1 id="_idParaDest-212"><a id="_idTextAnchor390"/>Questions</h1>
			<ol>
				<li>True or false: When <code>docker image ls</code> command.</li>
				<li>Which of the four namespaces hosts the containers used to run Kubernetes and enable support within Docker?</li>
				<li>Which command would you run to find out details about a container running in a pod?</li>
				<li>Which command would you use to launch a Kubernetes definition YAML file? Typically, which port does the <code>kubectl proxy</code> command open on your local machine?</li>
				<li>What was the original name of Google container orchestration platform?</li>
			</ol>
			<h1 id="_idParaDest-213"><a id="_idTextAnchor391"/>Further reading</h1>
			<p>Some of the Google tools, presentations, and white papers mentioned at the start of the chapter can be found here:</p>
			<ul>
				<li>cgroups: <a href="http://man7.org/linux/man-pages/man7/cgroups.7.html">http://man7.org/linux/man-pages/man7/cgroups.7.html</a> </li>
				<li>lmctfy: <a href="https://github.com/google/lmctfy/">https://github.com/google/lmctfy/</a></li>
				<li>Containers at Scale, Joe Beda's slides from GluCon: <a href="http://slides.eightypercent.net/GlueCon%202014%20-%20Containers%20At%20Scale.pdf">http://slides.eightypercent.net/GlueCon%202014%20-%20Containers%20At%20Scale.pdf</a> </li>
				<li>Large-scale cluster management at Google with Borg: <a href="https://ai.google/research/pubs/pub43438">https://ai.google/research/pubs/pub43438</a> </li>
				<li>LXC: <a href="https://linuxcontainers.org/">https://linuxcontainers.org/</a></li>
			</ul>
			<p>You can find details on the cloud services mentioned in the chapter here:</p>
			<ul>
				<li><strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>): <a href="https://cloud.google.com/kubernetes-engine">https://cloud.google.com/kubernetes-engine</a></li>
				<li><strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>): <a href="https://azure.microsoft.com/en-gb/services/kubernetes-service/">https://azure.microsoft.com/en-gb/services/kubernetes-service/</a> </li>
				<li>Amazon <strong class="bold">Elastic Container Service for Kubernetes</strong> (<strong class="bold">Amazon EKS</strong>): <a href="https://aws.amazon.com/eks/">https://aws.amazon.com/eks/</a> </li>
				<li>IBM Cloud Kubernetes Service: <a href="https://www.ibm.com/cloud/container-service">https://www.ibm.com/cloud/container-service</a>  </li>
				<li>Oracle Container Engine for Kubernetes: <a href="https://cloud.oracle.com/containers/kubernetes-engine">https://cloud.oracle.com/containers/kubernetes-engine</a> </li>
				<li>Kubernetes on DigitalOcean: <a href="https://www.digitalocean.com/products/kubernetes/">https://www.digitalocean.com/products/kubernetes/</a> </li>
			</ul>
			<p>You can find Docker's announcements about Kubernetes support here:</p>
			<ul>
				<li>Docker Platform and Moby Project add Kubernetes: <a href="https://www.docker.com/blog/top-5-blogs-2017-docker-platform-moby-project-add-kubernetes/">https://www.docker.com/blog/top-5-blogs-2017-docker-platform-moby-project-add-kubernetes/</a></li>
			</ul>
			<p>Finally, the home page for Kompose can be found here:</p>
			<ul>
				<li>Kompose: <a href="http://kompose.io/">http://kompose.io/</a></li>
			</ul>
		</div>
	</div>



  </body></html>