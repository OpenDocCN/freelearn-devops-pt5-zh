- en: Dividing a Cluster into Namespaces
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将集群划分为命名空间
- en: Applications and corresponding objects often need to be separated from each
    other to avoid conflicts and other undesired effects.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序及其相应对象通常需要彼此分开，以避免冲突和其他不良影响。
- en: We might need to separate objects created by different teams. We can, for example,
    give each team a separate cluster so that they can "experiment" without affecting
    others. In other cases, we might want to create different clusters that will be
    used for various purposes. For example, we could have a production and a testing
    cluster. There are many other problems that we tend to solve by creating different
    clusters. Most of them are based on the fear that some objects will produce adverse
    effects on others. We might be afraid that a team will accidentally replace a
    production release of an application with an untested beta. Or, we might be concerned
    that performance tests will slow down the whole cluster. Fear is one of the main
    reasons why we tend to be defensive and conservative. In some cases, it is founded
    on past experiences. In others, it might be produced by insufficient knowledge
    of the tools we adopted. More often than not, it is a combination of the two.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能需要将不同团队创建的对象分开。例如，我们可以给每个团队一个单独的集群，让他们可以“实验”而不会影响其他人。在其他情况下，我们可能希望创建不同的集群，用于各种不同的目的。例如，我们可以有一个生产集群和一个测试集群。我们通常通过创建不同的集群来解决许多其他问题。大多数问题源自对某些对象可能对其他对象产生不良影响的担忧。我们可能担心某个团队会不小心将应用程序的生产版本替换为未经测试的测试版。或者，我们可能担心性能测试会拖慢整个集群的速度。恐惧是我们倾向于采取防守性和保守性措施的主要原因之一。在某些情况下，这种恐惧是基于过去的经验。在其他情况下，它可能源于对我们采用的工具了解不足。更常见的是，这两者的结合。
- en: The problem with having many Kubernetes clusters is that each has an operational
    and resource overhead. Managing one cluster is often far from trivial. Having
    a few is complicated. Having many can become a nightmare and require quite a significant
    investment in hours dedicated to operations and maintenance. If that overhead
    is not enough, we must also be aware that each cluster needs resources dedicated
    to Kubernetes. The more clusters we have, the more resources (CPU, memory, IO)
    are spent. While that can be said for big clusters as well, the fact remains that
    the resource overhead of having many smaller clusters is higher than having a
    single big one.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有多个 Kubernetes 集群的问题在于，每个集群都需要操作和资源的开销。管理一个集群通常远非简单。拥有几个集群会很复杂。拥有多个集群则可能变成一场噩梦，需要投入大量的时间来进行操作和维护。如果这种开销还不够，我们还必须注意，每个集群都需要专门的资源来运行
    Kubernetes。集群越多，消耗的资源（CPU、内存、IO）就越多。虽然大集群也有类似的问题，但事实仍然是，拥有多个小集群的资源开销高于拥有一个大集群。
- en: I am not trying to discourage you from having multiple Kubernetes clusters.
    In many cases, that is a welcome, if not a required, strategy. However, there
    is the possibility of using Kubernetes Namespaces instead. In this chapter, we'll
    explore ways to split a cluster into different segments as an alternative to having
    multiple clusters.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我并不是想阻止你拥有多个 Kubernetes 集群。在许多情况下，这是一个受欢迎的（如果不是必需的）策略。然而，也可以选择使用 Kubernetes
    命名空间。在本章中，我们将探讨将集群拆分为不同区域的方式，作为拥有多个集群的替代方案。
- en: Creating a Cluster
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建集群
- en: You know the drill, so let's get the cluster setup over and done with.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道该怎么做，所以让我们快速完成集群设置。
- en: All the commands from this chapter are available in the `11-ns.sh` ([https://gist.github.com/vfarcic/6e0a03df4c64a9248fbb68673c1ab719](https://gist.github.com/vfarcic/6e0a03df4c64a9248fbb68673c1ab719))
    Gist.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有命令都可以在 `11-ns.sh`（[https://gist.github.com/vfarcic/6e0a03df4c64a9248fbb68673c1ab719](https://gist.github.com/vfarcic/6e0a03df4c64a9248fbb68673c1ab719)）Gist
    中找到。
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now that the cluster is created (again), we can start exploring Namespaces.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在集群已经创建（再次），我们可以开始探索命名空间了。
- en: Deploying the first release
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署第一次发布
- en: We'll start by deploying the `go-demo-2` application and use it to explore Namespaces.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从部署 `go-demo-2` 应用程序开始，并使用它来探索命名空间。
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The definition is the same as the one we used before, so we'll skip the explanation
    of the YAML file. Instead, we'll jump right away into the deployment.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 定义与我们之前使用的相同，因此我们将跳过对 YAML 文件的解释。相反，我们将直接进入部署过程。
- en: Unlike previous cases, we'll deploy a specific tag of the application. If this
    would be a Docker Swarm stack, we'd define the tag of the `vfarcic/go-demo-2`
    image as an environment variable with the default value set to `latest`. Unfortunately,
    Kubernetes does not have that option. Since I don't believe that it is a good
    idea to create a different version of the YAML file for each release, we'll use
    `sed` to modify the definition before passing it to `kubectl`.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的情况不同，我们将部署应用程序的特定标签。如果这是一个 Docker Swarm 堆栈，我们会将 `vfarcic/go-demo-2` 镜像的标签定义为环境变量，默认值为
    `latest`。不幸的是，Kubernetes 并不提供这个选项。由于我认为为每个版本创建不同的 YAML 文件并不是一个好主意，因此我们将使用 `sed`
    在将定义传递给 `kubectl` 之前进行修改。
- en: 'Using `sed` to alter Kubernetes definitions is not a good solution. Heck, it''s
    a terrible one. We should use a templating solution like, for example, Helm ([https://helm.sh/](https://helm.sh/)).
    However, we are focusing purely on Kubernetes. Helm and other third-party products
    are out of the scope of this book. So, we''ll have to do with a workaround in
    the form of `sed` commands:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `sed` 来修改 Kubernetes 定义并不是一个好方法。事实上，这简直是一个糟糕的解决方案。我们应该使用像 Helm（[https://helm.sh/](https://helm.sh/)）这样的模板解决方案。然而，我们现在专注于
    Kubernetes，Helm 和其他第三方产品超出了本书的范畴。因此，我们将不得不使用 `sed` 命令作为一种变通方法：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We declared environment variables `IMG` and `TAG`. Further on, we `cat` the
    YAML file and piped the output to `sed`. It, in return, replaced `image: vfarcic/go-demo-2`
    with `image: vfarcic/go-demo-2:1.0`. Finally, the modified definition was piped
    to `kubectl`. When the `-f` argument is followed with a dash (`-`), `kubectl`
    uses standard input (`stdin`) instead of a file. In our case, that input is the
    YAML definition altered by adding the specific `tag (1.0)` to the `vfarcic/go-demo-2`
    image.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '我们声明了环境变量 `IMG` 和 `TAG`。接下来，我们用 `cat` 读取 YAML 文件并将输出通过管道传递给 `sed`。然后，它将 `image:
    vfarcic/go-demo-2` 替换为 `image: vfarcic/go-demo-2:1.0`。最后，修改后的定义被传递给 `kubectl`。当
    `-f` 参数后跟一个破折号（`-`）时，`kubectl` 会使用标准输入（`stdin`）而不是文件。在我们的例子中，这个输入是通过添加特定 `tag
    (1.0)` 到 `vfarcic/go-demo-2` 镜像而修改过的 YAML 定义。'
- en: 'Let''s confirm that the deployment rolled out successfully:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确认部署是否成功完成：
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We''ll check whether the application is deployed correctly by sending an HTTP
    request. Since the Ingress resource we just created has the `host` set to `go-demo-2.com`,
    we''ll have to "fake" it by adding `Host: go-demo-2.com` header to the request:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将通过发送 HTTP 请求来检查应用程序是否已正确部署。由于我们刚刚创建的 Ingress 资源的 `host` 被设置为 `go-demo-2.com`，因此我们需要通过在请求中添加
    `Host: go-demo-2.com` 头来“伪装”这一点：'
- en: '[PRE4]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output is as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE5]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The reason we jumped through so many hoops to deploy a specific release will
    be revealed soon. For now, we'll assume that we're running the first release in
    production.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之所以在部署特定版本时经历了这么多曲折的过程，很快就会揭晓原因。目前，我们假设我们在生产环境中运行的是第一个版本。
- en: Exploring virtual clusters
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索虚拟集群
- en: Almost all of the system services are running as Kubernetes objects. Kube DNS
    is a deployment. Minikube Addon Manager, Dashboard, Storage Controller, and nginx
    Ingress are a few of the system Pods that are currently running in our Minikube
    cluster. Still, we haven't seen them yet. Even though we executed `kubectl get
    all` quite a few times, there was not a trace of any of those objects. How can
    that be? Will we see them now if we list all the objects? Let's check it out.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有的系统服务都作为 Kubernetes 对象运行。Kube DNS 是一个部署，Minikube 插件管理器、仪表盘、存储控制器和 nginx
    Ingress 是我们当前在 Minikube 集群中运行的部分系统 Pods。尽管如此，我们还没有看到它们。尽管我们已经执行了好几次 `kubectl get
    all`，但并未看到任何这些对象。那么这是怎么回事呢？如果我们列出所有对象，是否能看到它们？让我们检查一下。
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The output shows only the objects we created. There are `go-demo-2` Deployments,
    ReplicaSets, Services, and Pods. The only system object we can observe is the
    `kubernetes` Service.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果仅显示我们创建的对象。有 `go-demo-2` 部署、ReplicaSets、服务和 Pods。唯一可以观察到的系统对象是 `kubernetes`
    服务。
- en: Judging from the current information, if we limit our observations to Pods,
    our cluster can be described through the *Figure 11-1*.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从当前信息来看，如果我们将观察范围仅限于 Pods，我们可以通过*图 11-1* 来描述我们的集群。
- en: '![](img/d10ad6a3-d890-4fed-b5e4-bfc1dcfa9e37.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d10ad6a3-d890-4fed-b5e4-bfc1dcfa9e37.png)'
- en: 'Figure 11-1: The cluster with go-demo-2 Pods'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11-1：包含 go-demo-2 Pods 的集群
- en: All in all, our cluster runs a mixture of system-level objects and the objects
    we created, but only the latter is visible. You might be compelled to execute
    `kubectl get --help` hoping that there is an argument that will allow you to retrieve
    the information about system level objects. You might think that they are hidden
    from you by default. That's not the case. They are not hidden. Instead, they do
    not live in the Namespace we're looking at.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们的集群运行的是系统级对象和我们创建的对象的混合体，但只有后者是可见的。你可能会想执行`kubectl get --help`，希望能找到一个参数来获取系统级对象的信息。你可能认为它们默认对你是隐藏的。其实并非如此。它们并没有被隐藏。相反，它们不在我们当前查看的命名空间中。
- en: Kubernetes uses Namespaces to create virtual clusters. When we created the Minikube
    cluster, we got three Namespaces. In a way, each Namespace is a cluster within
    the cluster. They provide scope for names.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes使用命名空间来创建虚拟集群。当我们创建Minikube集群时，我们得到了三个命名空间。在某种程度上，每个命名空间都是集群中的一个子集群。它们为名称提供作用域。
- en: So far our experience tells us that we cannot have two of the same types of
    objects with the same name. There cannot be, for example, two deployments named
    `go-demo-2-api`. However, that rule applies only within a Namespace. Inside a
    cluster, we can have many of same object types with the same name as long as they
    belong to different Namespaces.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的经验告诉我们，不能有两个相同类型的对象，且名称相同。例如，不能有两个名为`go-demo-2-api`的部署。然而，这个规则仅适用于命名空间。在集群内部，只要它们属于不同的命名空间，我们可以有多个相同名称的相同类型的对象。
- en: So far, we had the impression that we are operating on the level of a Minikube
    Kubernetes cluster. That was a wrong assumption. All this time we were inside
    one Namespace of all the possible Namespaces in the cluster. To be more concrete,
    all the commands we executed thus far created objects in the `default` Namespace.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的印象是我们在操作一个Minikube Kubernetes集群的层级。那是一个错误的假设。实际上，我们一直处于集群中所有可能的命名空间之一。更具体地说，我们迄今为止执行的所有命令都在`default`命名空间中创建了对象。
- en: Namespaces are so much more than scopes for object names. They allow us to split
    a cluster among different groups of users. Each of those Namespaces can have different
    permissions and resources quotas. There are quite a few other things we can do
    if we combine Namespaces with other Kubernetes services and concepts. However,
    we'll ignore permissions, quotas, policies, and other things we did not yet explore.
    We'll focus on Namespaces alone.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间不仅仅是对象名称的作用域。它们使我们能够将一个集群划分为不同的用户组。每个命名空间可以有不同的权限和资源配额。如果我们将命名空间与其他Kubernetes服务和概念结合使用，我们还能做很多其他事情。然而，我们将忽略权限、配额、策略等我们尚未探索的内容。我们将仅关注命名空间本身。
- en: We'll start by exploring the pre-defined Namespaces first.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从探索预定义的命名空间开始。
- en: Exploring the existing Namespaces
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索现有的命名空间
- en: Now that we know that our cluster has multiple Namespaces, let's explore them
    a bit.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道集群中有多个命名空间，让我们稍微探索一下它们。
- en: We can list all the Namespaces through the `kubectl get namespaces` command.
    As with the most of the other Kubernetes objects and resources, we can also use
    a shortcut `ns` instead of the full name.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过`kubectl get namespaces`命令列出所有命名空间。与大多数其他Kubernetes对象和资源一样，我们也可以使用简写`ns`来代替完整名称。
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can see that three Namespaces were set up automatically when we created the
    Minikube cluster.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在创建Minikube集群时，自动设置了三个命名空间。
- en: The `default` Namespace is the one we used all this time. If we do not specify
    otherwise, all the `kubectl` commands will operate against the objects in the
    `default` Namespace. That's where our `go-demo-2` application is running. Even
    though we were not aware of its existence, we now know that's where the objects
    we created are placed.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`default`命名空间是我们一直使用的命名空间。如果我们没有特别指定，所有的`kubectl`命令将作用于`default`命名空间中的对象。我们的`go-demo-2`应用程序就在这个命名空间中运行。虽然我们之前没有意识到它的存在，但现在我们知道，所有我们创建的对象都在这里。'
- en: '![](img/60c3a763-527e-4a1e-a93a-1f6dd7eff781.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/60c3a763-527e-4a1e-a93a-1f6dd7eff781.png)'
- en: 'Figure 11-2: The Namespaces and the go-demo-2 Pods'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图11-2：命名空间与go-demo-2 Pods
- en: There are quite a few ways to specify a Namespace. For now, we'll use the `--namespace`
    argument. It is one of the global options that is available for all `kubectl`
    commands.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多种方法可以指定一个命名空间。现在，我们将使用`--namespace`参数。它是所有`kubectl`命令都可以使用的全局选项之一。
- en: 'The command that will retrieve all the objects from the `kube-public` Namespace
    is as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 获取`kube-public`命名空间中所有对象的命令如下：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The output states that `No resources` were `found`. That's disappointing, isn't
    it? Kubernetes does not use the `kube-public` Namespace for its system-level object.
    All the objects we created are in the `default` Namespace.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示`未找到资源`。这令人失望，不是吗？Kubernetes不会使用`kube-public`命名空间来存放其系统级对象。我们创建的所有对象都在`default`命名空间中。
- en: The `kube-public` Namespace is readable by all users from all Namespaces. The
    primary reason for its existence is to provide space where we can create objects
    that should be visible throughout the whole cluster. A good example is ConfigMaps.
    When we create one in, let's say, the `default` Namespace, it is accessible only
    by the other objects in the same Namespace. Those residing somewhere else would
    be oblivious of its existence. If we'd like such a ConfigMap to be visible to
    all objects no matter where they are, we'd put it into the `kube-public` Namespace
    instead. We won't use this Namespace much (if at all).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-public`命名空间是所有命名空间的用户都可以读取的。它存在的主要原因是提供一个空间，我们可以在其中创建应该在整个集群中可见的对象。一个很好的例子是ConfigMap。当我们在例如`default`命名空间中创建一个ConfigMap时，它只对同一命名空间中的其他对象可访问。其他地方的对象根本不知道它的存在。如果我们希望这样的ConfigMap在任何地方的对象都能看到，我们会把它放到`kube-public`命名空间中。我们不太会使用这个命名空间（如果有的话）。'
- en: 'The `kube-system` Namespace is critical. Almost all the objects and resources
    Kubernetes needs are running inside it. We can check that by executing the command
    that follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-system`命名空间至关重要。Kubernetes所需的几乎所有对象和资源都在其中运行。我们可以通过执行以下命令来检查这一点：'
- en: '[PRE10]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We retrieved all the objects and resources running inside the `kube-system`
    Namespace. The output is as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检索了所有在`kube-system`命名空间中运行的对象和资源。输出如下：
- en: '[PRE11]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As we can see, quite a few things are running inside the `kube-system` Namespace.
    For example, we knew that there is an nginx Ingress controller, but this is the
    first time we saw its objects. It consists of a Replication Controller `nginx-ingress-controller`,
    and the Pod it created, `nginx-ingress-controller-fxrhn`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，`kube-system`命名空间中运行着相当多的内容。例如，我们知道有一个nginx Ingress控制器，但这是我们第一次看到它的对象。它由一个复制控制器`nginx-ingress-controller`和它创建的Pod`nginx-ingress-controller-fxrhn`组成。
- en: '![](img/c31706ce-4181-4892-91d1-65fcc0f1b824.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c31706ce-4181-4892-91d1-65fcc0f1b824.png)'
- en: 'Figure 11-3: The Namespaces and the Pods'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图11-3：命名空间和Pod
- en: As long as the system works as expected, there isn't much need to do anything
    inside the `kube-system` Namespace. The real fun starts when we create new Namespaces.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 只要系统按预期工作，就不需要在`kube-system`命名空间中做太多事情。真正有趣的部分开始于我们创建新的命名空间。
- en: Deploying to a new Namespace
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署到新命名空间
- en: Currently, we're running the release 1.0 of the `go-demo-2` application. We
    can consider it the production release. Now, let's say that the team in charge
    of the application just made a new release. They ran unit tests and built the
    binary. They produced a new Docker image and tagged it as `vfarcic/go-demo-2:2.0`.
    What they didn't do is run functional, performance, and other types of tests that
    require a running application. The new release is still not ready to be deployed
    to production so we cannot yet execute a rolling update and replace the production
    release with the new one. We need to finish running the tests, and for that we
    need the new release running in parallel with the old one.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们正在运行`go-demo-2`应用的1.0版本。我们可以把它看作是生产版本。现在，假设负责该应用的团队刚刚发布了一个新版本。他们运行了单元测试并构建了二进制文件，生产了一个新的Docker镜像并将其标记为`vfarcic/go-demo-2:2.0`。他们没有做的是运行功能性测试、性能测试以及其他需要运行应用的测试。这个新版本仍然无法部署到生产环境，所以我们还不能执行滚动更新，并用新版本替换生产版本。我们需要完成测试运行，而为此我们需要让新版本与旧版本并行运行。
- en: We could, for example, create a new cluster that would be used only for testing
    purposes. While that is indeed a good option in some situations, in others it
    might be a waste of resources. Moreover, we'd face the same challenge in the testing
    cluster. There might be multiple new releases that need to be deployed and tested
    in parallel.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以，例如，创建一个仅用于测试目的的新集群。虽然在某些情况下这是一个不错的选择，但在其他情况下可能是资源的浪费。此外，我们还会在测试集群中面临同样的挑战。可能会有多个新版本需要并行部署和测试。
- en: Another option could be to create a new cluster for each release that is to
    be tested. That would create the necessary separation and maintain the freedom
    we strive for. However, that is slow. Creating a cluster takes time. Even though
    it might not look like much, wasting ten minutes (if not more) only on that is
    too much time. Even if you disagree with me and you think that ten minutes is
    not that much, such an approach would be too expensive. Every cluster has a resource
    overhead that needs to be paid. While the overall size of a cluster affects the
    resource overhead, the number of clusters affects it even more. It's more expensive
    to have many smaller clusters than a big one. On top of all that, there is the
    operational cost. While it is often not proportional to the number of clusters,
    it still increases.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是为每个要测试的发布版本创建一个新的集群。这将创建必要的隔离并保持我们追求的自由。然而，这种方式很慢。创建一个集群需要时间。即使看起来不多，光是这十分钟（如果不是更多）就浪费了太多时间。即使你不同意我，认为十分钟不算什么，但这种做法依然成本太高。每个集群都有资源开销，这是必须支付的。虽然集群的整体大小会影响资源开销，但集群的数量对它的影响更大。拥有许多小集群比一个大集群更昂贵。更重要的是，操作成本。尽管操作成本与集群数量通常不成比例，但它依然会增加。
- en: Having a separate cluster for all our testing needs is not a bad idea. We shouldn't
    discard it, just as we should consider creating (and destroying) a new cluster
    for each new release. However, before you start creating new Kubernetes clusters,
    we'll explore how we might accomplish the same goals with a single cluster and
    with the help of Namespaces.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为我们所有的测试需求拥有一个独立的集群并非坏主意。我们不应轻易放弃它，就像我们应该考虑为每个新发布创建（并销毁）一个新的集群一样。然而，在你开始创建新的Kubernetes集群之前，我们将探讨如何利用单一集群并借助命名空间实现相同的目标。
- en: First things first. We need to create a new Namespace before we can use it.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个新的命名空间，然后才能使用它。
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output of the latter command is as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 后一个命令的输出如下：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can see that the new Namespace `testing` was created.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到新命名空间`testing`已被创建。
- en: We can continue using the `--namespace` argument to operate within the newly
    created Namespace. However, adding `--namespace` with every command is tedious.
    Instead, we'll create a new context.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续使用`--namespace`参数在新创建的命名空间中操作。然而，每个命令都添加`--namespace`参数很繁琐。相反，我们将创建一个新的上下文。
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We created a new context called `testing`. It is the same as the `minikube`
    context, except that it uses the `testing` Namespace.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个名为`testing`的新上下文。它与`minikube`上下文相同，唯一的区别是它使用了`testing`命名空间。
- en: '[PRE15]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output, limited to the relevant parts, is as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 限制为相关部分的输出如下：
- en: '[PRE16]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We can see that there are two contexts. Both are set to use the same `minikube`
    cluster with the same `minikube` user. The only difference is that one does not
    have the Namespace set, meaning that it will use the `default`. The other has
    it set to `testing`.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到有两个上下文。两者都设置为使用相同的`minikube`集群和相同的`minikube`用户。唯一的区别是一个没有设置命名空间，这意味着它将使用`default`。另一个则设置为`testing`。
- en: Now that we have two contexts, we can switch to `testing`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了两个上下文，我们可以切换到`testing`。
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We switched to the `testing` context that uses the Namespace of the same name.
    From now on, all the `kubectl` commands will be executed within the context of
    the `testing` Namespace. That is, until we change the context again, or use the
    `--namespace` argument.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们切换到了使用同名命名空间的`testing`上下文。从现在起，所有的`kubectl`命令将在`testing`命名空间的上下文中执行。也就是说，直到我们再次更改上下文或使用`--namespace`参数。
- en: To be on the safe side, we'll confirm that nothing is running in the newly created
    Namespace.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了安全起见，我们将确认新创建的命名空间中没有运行任何资源。
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The output shows that `no resources` were `found`.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示`未找到资源`。
- en: If we repeat the same command with the addition of the `--namespace=default`
    argument, we'll see that the `go-demo-2` objects we created earlier are still
    running.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在相同的命令中添加`--namespace=default`参数，再次执行该命令，我们会看到我们之前创建的`go-demo-2`对象仍在运行。
- en: 'Let''s continue and deploy a new release. As we explained before, the main
    objective of the deployment is to provide a means to test the release. It should
    remain hidden from our users. They should be oblivious to the existence of the
    new Deployment and continue using the release 1.0 until we are confident that
    2.0 works as expected:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 继续并部署新的发布版本。正如我们之前所解释的，部署的主要目标是提供测试发布版本的手段。它应该对用户保持隐藏。他们应该不知道新部署的存在，继续使用1.0版本，直到我们确认2.0版本如预期般正常：
- en: '[PRE19]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Just as before, we used `sed` to alter the image definition. This time, we're
    deploying the tag `2.0`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 就像之前一样，我们使用`sed`修改了镜像定义。这一次，我们部署的是`2.0`标签。
- en: Apart from changing the image tag, we also modified the host. This time, the
    Ingress resource will be configured with the host `2.0.go-demo-2.com`. That will
    allow us to test the new release using that domain while our users will continue
    seeing the production release 1.0 through the domain `go-demo-2.com`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 除了更改镜像标签外，我们还修改了主机。这次，Ingress资源将配置主机为`2.0.go-demo-2.com`。这将允许我们使用该域名测试新版本，同时用户将继续通过`go-demo-2.com`域名访问生产版本1.0。
- en: Let's confirm that the rollout finished.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确认部署是否完成。
- en: '[PRE20]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output is as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE21]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: As you can see, we rolled out the Deployment `go-demo-2-api`, along with some
    other resources. That means that we have two sets of the same objects with the
    same name. One is running in the `default` Namespace, while the other (release
    2.0) is running in the `testing` Namespace.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们部署了`go-demo-2-api`，以及一些其他资源。这意味着我们有两组同名的对象，一组运行在`default`命名空间中，另一组（版本2.0）运行在`testing`命名空间中。
- en: '![](img/3c63451b-d096-468e-a676-d1ff58a57423.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c63451b-d096-468e-a676-d1ff58a57423.png)'
- en: 'Figure 11-4: The cluster with the new Namespace testing'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图11-4：带有新命名空间测试的集群
- en: Before we open a new bottle of Champagne and celebrate the successful deployment
    of the new release without affecting production, we should verify that both are
    indeed working as expected.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们打开一瓶香槟庆祝新版本的成功部署且未影响生产环境之前，我们应该验证两者是否确实按预期工作。
- en: If we send a request to `go-demo-2.com`, we should receive a response from the
    release 1.0 running in the `default` Namespace.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们向`go-demo-2.com`发送请求，我们应该收到来自`default`命名空间中运行的1.0版本的响应。
- en: '[PRE22]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE23]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: If, on the other hand, we send a request to `2.0.go-demo-2.com`, we should get
    a response from the release 2.0 running in the `testing` Namespace.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们向`2.0.go-demo-2.com`发送请求，我们应该从`testing`命名空间中运行的2.0版本获得响应。
- en: '[PRE24]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE25]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The result we accomplished through different Namespaces is very similar to what
    we'd expect by using separate clusters. The main difference is that we did not
    need to complicate things by creating a new cluster. We saved time and resources
    by using a new Namespace instead.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过不同的命名空间实现的结果与使用独立集群时的预期非常相似。主要的区别在于，我们无需通过创建一个新的集群来复杂化事情，而是通过使用一个新的命名空间来节省了时间和资源。
- en: If this would be a "real world" situation, we'd run functional and other types
    of tests using the newly deployed release. Hopefully, those tests would be automated,
    and they would last for only a few minutes. We'll skip the testing part since
    it's not within the scope of this chapter (and probably not even the book). Instead,
    we'll imagine that the tests were executed and that they were successful.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一个“现实世界”的情况，我们会运行功能测试以及其他类型的测试，使用新部署的版本。希望这些测试是自动化的，且只会持续几分钟。由于测试部分不在本章的范围内（可能也不在本书的范围内），我们将跳过测试部分。我们假设这些测试已经执行，并且是成功的。
- en: Communication is an important subject when working with Namespaces, so we'll
    spend a few moments exploring it.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 通信是处理命名空间时非常重要的主题，因此我们将花一点时间来探讨它。
- en: Communicating between Namespaces
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在命名空间之间进行通信
- en: We'll create an `alpine-based` Pod that we'll use to demonstrate communication
    between Namespaces.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个基于`alpine`的Pod，用于演示命名空间之间的通信。
- en: '[PRE26]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We switched to the `minikube` context (`default` Namespace) and created a Pod
    with a container based on the `alpine` image. We let it `sleep` for a long time.
    Otherwise, the container would be without a process and would stop almost immediately.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们切换到`minikube`上下文（`default`命名空间），并创建了一个基于`alpine`镜像的Pod。我们让它`sleep`很长时间，否则容器将没有进程，几乎会立即停止。
- en: Before we proceed, we should confirm that the Pod is indeed running.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我们应该确认Pod确实正在运行。
- en: '[PRE27]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE28]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Please wait a few moments if, in your case, the Pod is not yet ready.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在你的情况下Pod尚未就绪，请稍等片刻。
- en: Before we proceed, we'll install `curl` inside the container in the `test` Pod.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我们将在`test` Pod内安装`curl`。
- en: '[PRE29]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We already explored communication between objects in the same Namespace. Since
    the `test` Pod is running in the `default` Namespace, we can, for example, reach
    the `go-demo-2-api` Service by using the Service name as a DNS name.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探讨了同一 Namespace 中对象之间的通信。由于 `test` Pod 运行在 `default` Namespace 中，我们可以通过使用服务名称作为
    DNS 名称来访问 `go-demo-2-api` 服务。
- en: '[PRE30]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output is as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE31]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We got the response from the release 1.0 because that's the one running in the
    same Namespace. Does that mean that we cannot reach Services from other Namespaces?
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了 1.0 版本的响应，因为它运行在同一 Namespace 中。这是否意味着我们无法访问其他 Namespace 中的服务？
- en: When we create a Service, it creates a few DNS entries. One of them corresponds
    to the name of the Service. So, the `go-demo-2-api` Service created a DNS based
    on that name. Actually, the full DNS entry is `go-demo-2-api.svc.cluster.local`.
    Both resolve to the same service `go-demo-2-api` which, in this case, runs in
    the `default` Namespace.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建一个服务时，它会创建几个 DNS 条目，其中一个与服务名称对应。因此，`go-demo-2-api` 服务创建了一个基于该名称的 DNS。实际上，完整的
    DNS 条目是 `go-demo-2-api.svc.cluster.local`。这两个条目都解析到相同的服务 `go-demo-2-api`，而在这种情况下，它运行在
    `default` Namespace 中。
- en: The third DNS entry we got is in the format `<service-name>.<namespace-name>.svc.cluster.local`.
    In our case, that is `go-demo-2-api.default.svc.cluster.local`. Or, if we prefer
    a shorter version, we could use `go-demo-2-api.default`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的第三个 DNS 条目采用 `<service-name>.<namespace-name>.svc.cluster.local` 格式。在我们的案例中，这是
    `go-demo-2-api.default.svc.cluster.local`。或者，如果我们更喜欢短一点的版本，也可以使用 `go-demo-2-api.default`。
- en: In most cases, there is no good reason to use the `<service-name>.<namespace-name>`
    format when communicating with Services within the same Namespace. The primary
    objective behind the existence of the DNSes with the Namespace name is when we
    want to reach services running in a different Namespace.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，当与同一 Namespace 中的服务进行通信时，使用 `<service-name>.<namespace-name>` 格式并没有太大的必要。DNS
    以 Namespace 名称存在的主要目的，是为了在我们想要访问位于不同 Namespace 中的服务时使用。
- en: If we'd like to reach `go-demo-2-api` running in the `testing` Namespace from
    the `test` Pod in the `default` Namespace, we should use the `go-demo-2-api.testing.svc.cluster.local`
    DNS or, even better, the shorter version `go-demo-2-api.testing`.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望从 `default` Namespace 中的 `test` Pod 访问在 `testing` Namespace 中运行的 `go-demo-2-api`，我们应该使用
    `go-demo-2-api.testing.svc.cluster.local` DNS，或者更好的是，使用更短的版本 `go-demo-2-api.testing`。
- en: '[PRE32]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This time, the output is different:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，输出结果不同：
- en: '[PRE33]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Kube DNS used the DNS suffix `testing` to deduce that we want to reach the Service
    located in that Namespace. As a result, we got the response from the release 2.0
    of the `go-demo-2` application.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Kube DNS 使用 DNS 后缀 `testing` 来推断我们想要访问位于该 Namespace 中的服务。因此，我们收到了 `go-demo-2`
    应用程序的 2.0 版本的响应。
- en: Deleting a Namespace and all its Objects
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除 Namespace 及其所有对象
- en: Another handy feature of the Namespaces is their cascading effect. If, for example,
    we delete the `testing` Namespace, all the objects and the resources running inside
    it will be removed as well.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Namespaces 的另一个便捷特性是它们的级联效果。例如，如果我们删除 `testing` Namespace，那么其中运行的所有对象和资源也会被一并删除。
- en: '[PRE34]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We deleted the `testing` Namespace and retrieved all the objects residing in
    it. The output is as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们删除了 `testing` Namespace，并恢复了所有其中的对象。输出如下：
- en: '[PRE35]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Please note that, in your case, the output might show more objects. If that's
    the case, you were too fast, and Kubernetes did not yet have time to remove them.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在你的情况下，输出可能会显示更多的对象。如果是这样，那是因为你操作太快，Kubernetes 还没有时间将它们删除。
- en: After a second or two, the only objects in the `testing` Namespace are the Pods
    with the status `terminating`. Once the grace period is over, they will be removed
    as well. The Namespace is gone, and everything we created in it was removed as
    well.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一两秒后，`testing` Namespace 中唯一剩下的对象是状态为 `terminating` 的 Pods。一旦宽限期结束，它们也会被删除。Namespace
    被删除，我们在其中创建的所有内容也会被移除。
- en: The ability to remove a Namespace and all the objects and the resources it hosts
    is especially useful when we want to create temporary objects. A good example
    would be **continuous deployment** (**CDP**) processes. We can create a Namespace
    to build, package, test, and do all the other tasks our pipeline requires. Once
    we're finished, we can simply remove the Namespace. Otherwise, we would need to
    keep track of all the objects we created and make sure that they are removed before
    we terminate the CDP pipeline.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 删除命名空间及其所托管的所有对象和资源的能力在我们需要创建临时对象时尤为有用。一个好的例子是**持续部署**（**CDP**）过程。我们可以创建一个命名空间来构建、打包、测试以及执行管道所需的其他任务。完成后，我们可以简单地删除该命名空间。否则，我们将需要跟踪我们创建的所有对象，并确保在终止CDP管道之前将它们删除。
- en: Now that the Namespace hosting our release 2.0 is gone, we might want to double
    check that the production release (1.0) is still running.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在托管我们2.0版本的命名空间已经消失，我们可能需要再次检查生产版本（1.0）是否仍在运行。
- en: '[PRE36]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The output should show the `go-demo-2` Deployments, ReplicaSets, Pods, and Services
    since we are still using the `default` context.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应显示`go-demo-2`的Deployments、ReplicaSets、Pods和Services，因为我们仍在使用`default`上下文。
- en: To be on the safe side, we'll check that a request coming from the `go-demo-2.com`
    domain still returns a response from the release 1.0.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 为了安全起见，我们将检查来自`go-demo-2.com`域的请求是否仍然返回来自1.0版本的响应。
- en: '[PRE37]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As expected, the response is `hello, release 1.0!`.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，响应是`hello, release 1.0!`。
- en: 'If this were a continuous deployment pipeline, the only thing left would be
    to execute rolling updates that would change the image of the production release
    to `vfarcic/go-demo-2:2.0`. The command could be as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一个持续部署管道，剩下的唯一任务就是执行滚动更新，将生产发布的镜像更改为`vfarcic/go-demo-2:2.0`。命令可以如下所示：
- en: '[PRE38]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: What now?
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现在该做什么？
- en: Deploying test releases as part of a continuous deployment process is not the
    only usage of Namespaces. There can be many other situations when they are useful.
    We could, for example, give a separate Namespace to each team in our organization.
    Or we could split the cluster into Namespaces based on the type of applications
    (for example, monitoring, continuous-deployment, back-end, and so on). All in
    all, Namespaces are a handy way to separate the cluster into different sections.
    Some of the Namespaces we'll create will be long-lasting while others, like testing
    Namespace from our examples, will be short-lived.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 将测试版本作为持续部署过程的一部分进行部署并不是命名空间的唯一用途。还有许多其他情况下它们非常有用。例如，我们可以为组织中的每个团队分配一个独立的命名空间，或者根据应用类型（例如监控、持续部署、后端等）将集群划分为多个命名空间。总的来说，命名空间是将集群分成不同部分的一个便捷方法。我们将创建的一些命名空间会长期存在，而另一些，如我们例子中的测试命名空间，将是短期的。
- en: The real power behind Namespaces comes when they are combined with authorization
    policies and constraints. However, we did not yet explore those subjects so, for
    now, we'll need to limit our Namespaces experience to their basic form.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间的真正力量体现在它们与授权策略和约束结合使用时。然而，我们尚未探索这些主题，因此目前我们将把命名空间的体验局限于其基本形式。
- en: The chapter is finished, and that means that we are about to remove the cluster.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 本章已经结束，这意味着我们即将删除集群。
- en: '[PRE39]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: If you'd like to know more about Namespaces, please explore Namespace v1 core
    ([https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#namespace-v1-core](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#namespace-v1-core))
    API documentation.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于命名空间的信息，请查看Namespace v1核心的[API文档](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#namespace-v1-core)。
- en: Kubernetes Namespaces compared to Docker Swarm equivalent (if there is any)
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes命名空间与Docker Swarm的等效项比较（如果有的话）
- en: Docker Swarm does not have anything like Kubernetes Namespaces. We cannot split
    a Swarm cluster into sections. Therefore, we can finish this comparison by saying
    that Kubernetes is a clear winner regarding this feature since Docker Swarm doesn't
    have Namespaces. But, that would not be entirely accurate.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm没有类似于Kubernetes命名空间的功能。我们无法将Swarm集群分割成多个部分。因此，我们可以通过说Kubernetes在此功能上明显优于Docker
    Swarm来结束这个比较，因为Docker Swarm没有命名空间。但这并不完全准确。
- en: Docker Swarm stacks are, in a way, similar to Kubernetes Namespaces. All the
    services in a stack are uniquely identified through a combination of a stack name
    and the names of services inside it. By default, all services within a stack can
    communicate with each other through the stack's default network. Services can
    speak with those from other stacks only if they are explicitly attached to the
    same network. All in all, each Swarm stack is separated from other stacks. They
    are, in a way, similar to Kubernetes Namespaces.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 堆栈在某种程度上类似于 Kubernetes 命名空间。堆栈中的所有服务通过堆栈名称和其中服务名称的组合唯一标识。默认情况下，堆栈内的所有服务都可以通过堆栈的默认网络互相通信。服务只有在显式附加到同一网络时，才能与来自其他堆栈的服务通信。总的来说，每个
    Swarm 堆栈都是与其他堆栈分开的。从某种程度上说，它们类似于 Kubernetes 命名空间。
- en: Even though Docker Swarm stacks do provide a functionality similar to Kubernetes
    Namespaces, their usage is limited. If, for example, we'd like to split the cluster
    into production and testing, we'd need to create two potentially large Swarm stack
    files. That would be impractical. Moreover, Kubernetes Namespaces can be associated
    with resource quotas, policies, and quite a few other things. They do act as genuinely
    separate clusters. Swarm stacks, on the other hand, are meant to group services
    into logical entities. While some of the features in Kubernetes Namespaces and
    Docker Swarm stacks coincide, this is still a clear win for Kubernetes.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Docker Swarm 堆栈提供了类似于 Kubernetes 命名空间的功能，但它们的使用受到限制。例如，如果我们希望将集群划分为生产和测试环境，我们需要创建两个潜在较大的
    Swarm 堆栈文件。这将是不切实际的。此外，Kubernetes 命名空间可以与资源配额、策略以及其他许多功能相关联。它们确实充当真正独立的集群。另一方面，Swarm
    堆栈旨在将服务分组为逻辑实体。尽管 Kubernetes 命名空间和 Docker Swarm 堆栈中的某些功能有重叠，但这仍然是 Kubernetes 的明显胜利。
- en: Some might argue that they are useful only for bigger clusters or organizations
    with many teams. I think that's an understatement. Namespaces can be applied to
    many other use-cases. For example, creating a new Namespace for every continuous
    integration, delivery, or deployment pipeline is a beneficial practice. We get
    a unique scope for names, we can mitigate potential problems through resource
    quotas, and we can increase security. At the end of the process, we can remove
    the Namespace and all the objects we created inside it.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 有人可能会争辩说，它们仅适用于更大的集群或有多个团队的大型组织。我认为这是一种轻描淡写的说法。命名空间可以应用于许多其他场景。例如，为每个持续集成、交付或部署管道创建一个新的命名空间是一种有益的实践。我们可以为名称提供独特的作用域，可以通过资源配额来减少潜在问题，还能提高安全性。在整个过程中，最终我们可以删除命名空间以及其中创建的所有对象。
- en: Kubernetes Namespaces are one of the things that make Kubernetes a more likely
    candidate for teams that are in need of big clusters as well as those relying
    heavily on automation. Among the features we compared so far, this is the first
    real differentiator between the two platforms. Kubernetes is the winner of this
    round.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 命名空间是使 Kubernetes 成为大集群需求团队以及依赖自动化的团队更可能选择的平台之一。在我们到目前为止比较的特性中，这是两个平台之间的第一个真正的区分点。Kubernetes
    在这一回合中获胜。
