- en: '*Chapter 11*: Template Code Generation and CI/CD on Kubernetes'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 11 章*：Kubernetes 上的模板代码生成与 CI/CD'
- en: This chapter discusses some easier ways to template and configure large Kubernetes
    deployments with many resources. It also details a number of methods for implementing
    **Continuous Integration**/**Continuous Deployment** (**CI**/**CD**) on Kubernetes,
    as well as the pros and cons associated with each possible method. Specifically,
    we talk about in-cluster CI/CD, where some or all of the CI/CD steps are performed
    in our Kubernetes cluster, and out-of-cluster CI/CD, where all the steps take
    place outside our cluster.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了几种更简单的方式来模板化和配置具有大量资源的 Kubernetes 部署。同时，详细介绍了在 Kubernetes 上实现 **持续集成**/**持续部署**
    (**CI**/**CD**) 的多种方法，并探讨了每种方法的优缺点。具体来说，我们讨论了集群内 CI/CD，其中一些或所有的 CI/CD 步骤在 Kubernetes
    集群中执行；以及集群外 CI/CD，其中所有步骤都在集群外部完成。
- en: The case study in this chapter will include creating a Helm chart from scratch,
    along with an explanation of each piece of a Helm chart and how it works.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的案例研究将包括从头开始创建 Helm chart，并解释 Helm chart 中的每个部分及其工作原理。
- en: To begin, we will cover the landscape of Kubernetes resource template generation,
    and the reasons why a template generation tool should be used at all. Then, we
    will cover implementing CI/CD to Kubernetes, first with AWS CodeBuild, and next
    with FluxCD.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将介绍 Kubernetes 资源模板生成的概况，以及为什么应该使用模板生成工具。接下来，我们将介绍如何将 CI/CD 实现到 Kubernetes
    中，首先使用 AWS CodeBuild，然后使用 FluxCD。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将覆盖以下主题：
- en: Understanding options for template code generation on Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 上模板代码生成的选项
- en: Implementing templates on Kubernetes with Helm and Kustomize
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Helm 和 Kustomize 在 Kubernetes 上实现模板
- en: Understanding CI/CD paradigms on Kubernetes – in-cluster and out-of-cluster
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 上的 CI/CD 模式——集群内和集群外
- en: Implementing in-cluster and out-of-cluster CI/CD with Kubernetes
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上实现集群内和集群外的 CI/CD
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In order to run the commands detailed in this chapter, you will need a computer
    that supports the `kubectl` command-line tool along with a working Kubernetes
    cluster. Refer to [*Chapter 1*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016),
    *Communicating with Kubernetes*, for several methods for getting up and running
    with Kubernetes quickly, and for instructions on how to install the kubectl tool.
    Additionally, you will need a machine that supports the Helm CLI tool, which typically
    has the same prerequisites as kubectl – for details, check out the Helm documentation
    at [https://helm.sh/docs/intro/install/](https://helm.sh/docs/intro/install/).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行本章详细介绍的命令，你需要一台支持 `kubectl` 命令行工具的计算机，并且有一个正常工作的 Kubernetes 集群。请参考 [*第 1
    章*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016)，*与 Kubernetes 通信*，了解如何快速启动
    Kubernetes 的几种方法，并获取如何安装 kubectl 工具的说明。此外，你还需要一台支持 Helm CLI 工具的计算机，它通常与 kubectl
    有相同的前提条件——详情请查看 Helm 文档：[https://helm.sh/docs/intro/install/](https://helm.sh/docs/intro/install/)。
- en: The code used in this chapter can be found in the book's GitHub repository at
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的代码可以在本书的 GitHub 仓库中找到：
- en: '[https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter11](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter11).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter11](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter11)。'
- en: Understanding options for template code generation on Kubernetes
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 上模板代码生成的选项
- en: As discussed in [*Chapter 1*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016),
    *Communicating with Kubernetes*, one of the greatest strengths of Kubernetes is
    that its API can communicate in terms of declarative resource files. This allows
    us to run commands such as `kubectl apply` and have the control plane ensure that
    whatever resources are running in the cluster match our YAML or JSON file.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 正如 [*第 1 章*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016) 中所讨论的，*与 Kubernetes
    通信*，Kubernetes 的最大优势之一是它的 API 可以通过声明式资源文件进行通信。这使得我们可以运行像 `kubectl apply` 这样的命令，并确保控制平面确保集群中运行的资源与我们的
    YAML 或 JSON 文件匹配。
- en: However, this capability introduces some unwieldiness. Since we want to have
    all our workloads declared in configuration files, any large or complex applications,
    especially if they include many microservices, could result in a large number
    of configuration files to write and maintain.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种功能引入了一些笨重性。因为我们希望所有的工作负载都在配置文件中声明，任何大型或复杂的应用程序，特别是包含多个微服务的应用，可能会导致需要编写和维护大量的配置文件。
- en: This issue is further compounded with multiple environments. Say we want development,
    staging, UAT, and production environments, this would require four separate YAML
    files per Kubernetes resource, assuming we wanted to maintain one resource per
    file for cleanliness.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题在多环境下更加复杂。假设我们有开发、预发布、UAT 和生产环境，这将需要为每个 Kubernetes 资源创建四个独立的 YAML 文件，假设我们希望保持每个资源一个文件以便清晰。
- en: One way to fix these issues is to work with templating systems that support
    variables, allowing a single template file to work for multiple applications or
    multiple environments by injecting different sets of variables.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这些问题的一种方法是使用支持变量的模板化系统，允许通过注入不同的变量集，使单个模板文件适用于多个应用程序或多个环境。
- en: 'There are several popular community-supported open source options for this
    purpose. In this book, we will focus on two of the most popular ones:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 目前有几个受社区支持的流行开源选项可供选择。在本书中，我们将重点介绍两个最流行的工具：
- en: Helm
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Helm
- en: Kustomize
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kustomize
- en: There are many other options available, including Kapitan, Ksonnet, Jsonnet,
    and more, but a full review of all of them is not within the scope of this book.
    Let's start by reviewing Helm, which is, in many ways, the most popular templating
    tool.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他可用的选项，包括 Kapitan、Ksonnet、Jsonnet 等，但对这些选项的全面评审超出了本书的范围。我们先来回顾 Helm，它在许多方面是最受欢迎的模板化工具。
- en: Helm
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Helm
- en: Helm actually plays double duty as a templating/code generation tool and a CI/CD
    tool. It allows you to create YAML-based templates that can be hydrated with variables,
    allowing for code and template reuse across applications and environments. It
    also comes with a Helm CLI tool to roll out changes to applications based on the
    templates themselves.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，Helm 充当了模板化/代码生成工具和 CI/CD 工具的双重角色。它允许你创建基于 YAML 的模板，这些模板可以通过变量填充，从而在应用程序和环境之间实现代码和模板的重用。它还配有
    Helm CLI 工具，根据模板本身推出应用程序的更改。
- en: For this reason, you are likely to see Helm all over the Kubernetes ecosystem
    as the default way to install tools or applications. We'll be using Helm for both
    of its purposes in this chapter.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你很可能会在 Kubernetes 生态系统中到处看到 Helm，作为安装工具或应用程序的默认方式。在本章中，我们将使用 Helm 的两种用途。
- en: Now, let's move on to Kustomize, which is quite different to Helm.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来看看 Kustomize，它与 Helm 有很大的不同。
- en: Kustomize
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kustomize
- en: Unlike Helm, Kustomize is officially supported by the Kubernetes project, and
    support is integrated directly into `kubectl`. Unlike Helm, Kustomize operates
    using vanilla YAML without variables, and instead recommends a *fork and patch*
    workflow where sections of YAML are replaced with new YAML depending on the patch
    chosen.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Helm 不同，Kustomize 是 Kubernetes 项目官方支持的，支持直接集成到 `kubectl` 中。与 Helm 不同，Kustomize
    使用原生 YAML 文件而不支持变量，而是推荐一种 *分支和修补* 工作流，根据选择的修补程序用新的 YAML 替换 YAML 的某些部分。
- en: Now that we have a basic understanding of how the tools differ, we can use them
    in practice.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对这些工具的区别有了基本的了解，我们可以在实践中使用它们。
- en: Implementing templates on Kubernetes with Helm and Kustomize
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上使用 Helm 和 Kustomize 实现模板化
- en: Now that we know our options, we can implement each of them with an example
    application. This will allow us to understand the specifics of how each tool handles
    variables and the process of templating. Let's start with Helm.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们了解了选项，现在可以通过一个示例应用程序来实现每个选项。这将帮助我们理解每个工具如何处理变量以及模板化的过程。我们从 Helm 开始。
- en: Using Helm with Kubernetes
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Helm 与 Kubernetes
- en: As mentioned previously, Helm is an open source project that makes it easy to
    template and deploy applications on Kubernetes. For the purposes of this book,
    we will be focused on the newest version (as of the time of writing), Helm V3\.
    A previous version, Helm V2, had more moving parts, including a controller, called
    *Tiller*, that would run on the cluster. Helm V3 is simplified and only contains
    the Helm CLI tool. It does, however, use custom resource definitions on the cluster
    to track releases, as we will see shortly.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Helm 是一个开源项目，它使得在 Kubernetes 上进行应用程序模板化和部署变得简单。为了本书的目的，我们将专注于最新版本（截至写作时），即
    Helm V3。之前的版本 Helm V2 有更多的组成部分，包括一个名为 *Tiller* 的控制器，它会在集群上运行。Helm V3 被简化，仅包含 Helm
    CLI 工具。然而，它确实使用集群中的自定义资源定义来跟踪发布，稍后我们将看到。
- en: Let's start by installing Helm.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从安装 Helm 开始。
- en: Installing Helm
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 Helm
- en: If you want to use a specific version of Helm, you can install it by following
    the specific version docs at [https://helm.sh/docs/intro/install/](https://helm.sh/docs/intro/install/).
    For our use case, we will simply use the `get helm` script, which will install
    the newest version.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想使用 Helm 的特定版本，可以按照 [https://helm.sh/docs/intro/install/](https://helm.sh/docs/intro/install/)
    上的特定版本文档进行安装。对于我们的用例，我们将仅使用 `get helm` 脚本，它将安装最新版本。
- en: 'You can fetch and run the script as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按如下方式获取并运行脚本：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, we should be able to run `helm` commands. By default, Helm will automatically
    use your existing `kubeconfig` cluster and context, so in order to switch clusters
    for Helm, you just need to use `kubectl` to change your `kubeconfig` file, as
    you would normally do.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们应该能够运行 `helm` 命令。默认情况下，Helm 将自动使用您现有的 `kubeconfig` 集群和上下文，因此，为了为 Helm 切换集群，您只需使用
    `kubectl` 更改 `kubeconfig` 文件，像平时一样操作即可。
- en: To install an application using Helm, run the `helm install` command. But how
    does Helm decide what and how to install? We'll need to discuss the concepts of
    Helm charts, Helm repositories, and Helm releases.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Helm 安装应用程序，请运行 `helm install` 命令。但是，Helm 是如何决定安装什么以及如何安装的呢？我们需要讨论 Helm
    图表、Helm 仓库和 Helm 发布的概念。
- en: Helm charts, repositories, and releases
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Helm 图表、仓库和发布
- en: Helm provides a way to template and deploy applications on Kubernetes with variables.
    In order to do this, we specify workloads via a set of templates, which is called
    a *Helm chart*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Helm 提供了一种通过变量模板和部署 Kubernetes 上的应用程序的方法。为此，我们通过一组模板来指定工作负载，这被称为 *Helm 图表*。
- en: A Helm chart consists of one or more templates, some chart metadata, and a `values`
    file that fills in the template variables with final values. In practice, you
    would then have one `values` file per environment (or app, if you are reusing
    your template for multiple apps), which would hydrate the shared template with
    a new configuration. This combination of template and values would then be used
    to install or deploy an application to your cluster.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 Helm 图表由一个或多个模板、一些图表元数据以及一个 `values` 文件组成，该文件将模板变量填充为最终值。实际上，您将为每个环境（或者应用程序，如果您将模板用于多个应用程序）准备一个
    `values` 文件，该文件将为共享模板提供新的配置。模板和值的组合将用于将应用程序安装或部署到您的集群中。
- en: So, where can you store Helm charts? You can put them in a Git repository as
    you would with any other Kubernetes YAML (which works for most use cases), but
    Helm also supports the concept of repositories. A Helm repository is represented
    by a URL and can contain multiple Helm charts. For instance, Helm has its own
    official repository at [https://hub.helm.sh/charts](https://hub.helm.sh/charts).
    Again, each Helm chart consists of a folder with a metadata file, a `Chart.yaml`
    file, one or more template files, and optionally a values file.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，Helm 图表可以存储在哪里呢？您可以像处理任何其他 Kubernetes YAML 文件一样将它们放在 Git 仓库中（这种方式适用于大多数用例），但
    Helm 还支持仓库的概念。Helm 仓库通过 URL 表示，可以包含多个 Helm 图表。例如，Helm 有自己的官方仓库，网址是 [https://hub.helm.sh/charts](https://hub.helm.sh/charts)。同样，每个
    Helm 图表由一个包含元数据文件、`Chart.yaml` 文件、一个或多个模板文件，并可选地包含一个值文件的文件夹组成。
- en: 'In order to install a local Helm chart with a local values file, you can pass
    a path for each to `helm install`, as shown in the following command:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了安装带有本地值文件的本地 Helm 图表，您可以将每个路径传递给 `helm install`，如下命令所示：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: However, for commonly installed charts, you can also install the chart directly
    from a chart repository, and you can optionally add a custom repository to your
    local Helm in order to be able to install charts easily from non-official sources.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于常见的安装图表，您也可以直接从图表仓库安装图表，您还可以选择将自定义仓库添加到本地 Helm，以便能够轻松地从非官方源安装图表。
- en: 'For instance, in order to install Drupal via the official Helm chart, you can
    run the following command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要通过官方 Helm 图表安装 Drupal，您可以运行以下命令：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This code installs charts out of the official Helm chart repository. To use
    a custom repository, you just need to add it to Helm first. For instance, to install
    `cert-manager`, which is hosted on the `jetstack` Helm repository, we can do the
    following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码从官方 Helm 图表仓库安装图表。要使用自定义仓库，您只需先将其添加到 Helm 中。例如，要安装托管在 `jetstack` Helm 仓库中的
    `cert-manager`，我们可以执行以下操作：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This code adds the `jetstack` Helm repository to your local Helm CLI tool, and
    then installs `cert-manager` via the charts hosted there. We also name the release
    as `cert-manager`. A Helm release is a concept implemented using Kubernetes secrets
    in Helm V3\. When we create a Release in Helm, it will be stored as a secret in
    the same namespace.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将 `jetstack` Helm 仓库添加到你的本地 Helm CLI 工具中，然后通过托管在该仓库中的图表安装 `cert-manager`。我们还将发布命名为
    `cert-manager`。在 Helm V3 中，发布是通过 Kubernetes 秘密来实现的。当我们在 Helm 中创建发布时，它会作为秘密存储在相同的命名空间中。
- en: 'To illustrate this, we can create a Helm release using the preceding `install`
    command. Let''s do it now:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，我们可以使用前面的 `install` 命令创建一个 Helm 发布。我们现在来执行：
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This command should result in the following output, which may be slightly different
    depending on the current version of Cert Manager. We'll split the output into
    two sections for readability.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令应该会产生以下输出，具体输出可能会根据当前的 Cert Manager 版本略有不同。为了易于阅读，我们将把输出分成两个部分。
- en: 'First, the output of the command gives us a status of the Helm release:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，命令的输出给出了 Helm 发布的状态：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As you can see, this section contains a timestamp for the deployment, namespace
    information, a revision, and a status. Next, we''ll see the notes section of the
    output:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这一部分包含了部署的时间戳、命名空间信息、版本号和状态。接下来，我们将看到输出中的注释部分：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As you can see, our Helm `install` command has resulted in a success message,
    which also gives us some information from `cert-manager` about how to use it.
    This output can be helpful to look at when installing Helm packages, as they sometimes
    include documentation such as the previous snippet. Now, to see how our release
    object looks in Kubernetes, we can run the following command:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们的 Helm `install` 命令已成功执行，并给出了来自 `cert-manager` 的一些使用信息。在安装 Helm 包时，这些输出可能非常有用，因为它们有时会包括文档，如之前的代码片段。现在，为了查看我们的发布对象在
    Kubernetes 中的样子，我们可以运行以下命令：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This results in the following output:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 11.1 – Secrets List output from kubectl](img/B14790_11_001.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.1 – 来自 kubectl 的秘密列表输出](img/B14790_11_001.jpg)'
- en: Figure 11.1 – Secrets List output from kubectl
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – 来自 kubectl 的秘密列表输出
- en: As you can see, one of the secrets has its type as `helm.sh/release.v1`. This
    is the secret that Helm is using to track the Cert Manager release.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，其中一个秘密的类型为 `helm.sh/release.v1`。这是 Helm 用来跟踪 Cert Manager 发布的秘密。
- en: 'Finally, to see the release listed in the Helm CLI, we can run the following
    command:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，要查看 Helm CLI 中列出的发布，我们可以运行以下命令：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This command will list Helm releases in all namespaces (just like `kubectl
    get pods -A` would list pods in all namespaces). The output will be as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将列出所有命名空间中的 Helm 发布（就像 `kubectl get pods -A` 会列出所有命名空间中的 Pod 一样）。输出将如下所示：
- en: '![Figure 11.2 – Helm Release List output](img/B14790_11_002.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.2 – Helm 发布列表输出](img/B14790_11_002.jpg)'
- en: Figure 11.2 – Helm Release List output
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – Helm 发布列表输出
- en: Now, Helm has more moving parts, including `upgrades`, `rollbacks` and more,
    and we'll review these in the next section. In order to show off what Helm can
    do, we will create and install a chart from scratch.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Helm 具有更多的组成部分，包括 `升级`、`回滚` 等，我们将在下一部分进行回顾。为了展示 Helm 的功能，我们将从零开始创建并安装一个图表。
- en: Creating a Helm chart
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建 Helm 图表
- en: So, we want to create a Helm chart for our application. Let's set the stage.
    Our goal is to deploy a simple Node.js application easily to multiple environments.
    To this end, we will create a chart with the component pieces of our application,
    and then combine it with three separate values files (`dev`, `staging`, and `production`)
    in order to deploy our application to our three environments.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们想为我们的应用程序创建一个 Helm 图表。让我们先设定一下场景。我们的目标是将一个简单的 Node.js 应用程序轻松部署到多个环境中。为此，我们将创建一个包含应用程序组件的图表，并将其与三个独立的值文件（`dev`、`staging`
    和 `production`）结合，目的是将应用程序部署到这三个环境中。
- en: 'Let''s start with the folder structure of our Helm chart. As we mentioned previously,
    a Helm chart consists of templates, a metadata file, and optional values. We''re
    going to inject the values when we actually install our chart, but we can structure
    our folder like this:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 Helm 图表的文件夹结构开始。正如我们之前提到的，Helm 图表由模板、元数据文件和可选的值组成。我们将在实际安装图表时注入这些值，但我们可以按照以下方式组织我们的文件夹：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: One thing we haven't yet mentioned is that you can actually have a folder of
    Helm charts inside an existing chart! These subcharts can make it easy to split
    up complex applications into components. For the purpose of this book, we will
    not be using subcharts, but if your application is getting too complex or modular
    for a singular chart, this is a valuable feature.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尚未提到的一点是，你实际上可以在现有 chart 中拥有一个 Helm charts 文件夹！这些子 chart 可以方便地将复杂的应用拆分成多个组件。出于本书的目的，我们将不会使用子
    chart，但如果你的应用变得过于复杂或模块化，不适合使用单一 chart，那么这是一个非常有用的功能。
- en: Also, you can see that we have a different environment file for each environment,
    which we will use during our installation command.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你可以看到我们为每个环境都提供了不同的环境文件，这些文件将在我们安装命令时使用。
- en: 'So, what does a `Chart.yaml` file look like? This file will contain some basic
    metadata about your chart, and typically looks something like this as a minimum:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，`Chart.yaml` 文件是什么样子的呢？这个文件将包含一些关于你的 chart 的基本元数据，通常至少包含如下内容：
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `Chart.yaml` file supports many optional fields, which you can see at [https://helm.sh/docs/topics/charts/](https://helm.sh/docs/topics/charts/),
    but for the purposes of this tutorial, we will keep it simple. The mandatory fields
    are `apiVersion`, `name`, and `version`.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`Chart.yaml` 文件支持许多可选字段，你可以在 [https://helm.sh/docs/topics/charts/](https://helm.sh/docs/topics/charts/)
    查看，但为了本教程的目的，我们将保持简单。必须字段包括 `apiVersion`、`name` 和 `version`。'
- en: In our `Chart.yaml` file, `apiVersion` corresponds to the version of Helm that
    the chart corresponds to. Somewhat confusingly, the current release of Helm, Helm
    V3, uses `apiVersion` `v2`, while older versions of Helm, including Helm V2, also
    use `apiVersion` `v2`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 `Chart.yaml` 文件中，`apiVersion` 对应于该 chart 所对应的 Helm 版本。有点让人困惑的是，当前版本的 Helm，即
    Helm V3，使用 `apiVersion` `v2`，而旧版本的 Helm，包括 Helm V2，也使用 `apiVersion` `v2`。
- en: Next, the `name` field corresponds to the name of our chart. This is pretty
    self-explanatory, although remember that we have the ability to name a specific
    release of a chart – something that comes in handy for multiple environments.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，`name` 字段对应于我们 chart 的名称。这个非常直观，尽管请记住，我们可以为一个 chart 的特定版本命名——这一点对于多个环境非常有用。
- en: Finally, we have the `version` field, which corresponds to the version of the
    chart. This field supports **SemVer** (semantic versioning).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有 `version` 字段，它对应于 chart 的版本。此字段支持 **SemVer**（语义化版本控制）。
- en: So, what do our templates actually look like? Helm charts use the Go templates
    library under the hood (see [https://golang.org/pkg/text/template/](https://golang.org/pkg/text/template/)
    for more information) and support all sorts of powerful manipulations, helper
    functions, and much, much more. For now, we will keep things extremely simple
    to give you an idea of the basics. A full discussion of Helm chart creation could
    be a book on its own!
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们的模板到底是什么样子的呢？Helm charts 在后台使用 Go 模板库（更多信息请参见 [https://golang.org/pkg/text/template/](https://golang.org/pkg/text/template/)），并支持各种强大的操作、辅助函数等等。目前，我们将保持极其简单，以便让你了解基本概念。全面讨论
    Helm chart 的创建可能本身就是一本书！
- en: 'To start, we can use a Helm CLI command to autogenerate our `Chart` folder,
    with all the previous files and folders, minus subcharts and values files, generated
    for you. Let''s try it – first create a new Helm chart with the following command:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以使用 Helm CLI 命令来自动生成我们的 `Chart` 文件夹，其中包含所有前述文件和文件夹，缺少子 chart 和值文件。让我们来试一下——首先用以下命令创建一个新的
    Helm chart：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This command will create an autogenerated chart in a folder named `myfakenodeapp`.
    Let''s check the contents of our `templates` folder with the following command:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令将在名为 `myfakenodeapp` 的文件夹中创建一个自动生成的 chart。让我们使用以下命令检查 `templates` 文件夹的内容：
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This command will result in the following output:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令将会产生如下输出：
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This autogenerated chart can help a lot as a starting point, but for the purposes
    of this tutorial, we will make these from scratch.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这个自动生成的 chart 作为起点会非常有帮助，但为了本教程的目的，我们将从头开始创建这些文件。
- en: Create a new folder called `mynodeapp` and put the `Chart.yaml` file we showed
    you earlier in it. Then, create a folder inside called `templates`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为 `mynodeapp` 的新文件夹，并将我们之前展示的 `Chart.yaml` 文件放入其中。然后，在其中创建一个名为 `templates`
    的文件夹。
- en: 'One thing to keep in mind: a Kubernetes resource YAML is, by itself, a valid
    Helm template. There is no requirement to use any variables in your templates.
    You can just write regular YAML, and Helm installs will still work.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有一点需要记住：Kubernetes 资源 YAML 本身就是一个有效的 Helm 模板。你不需要在模板中使用任何变量。你可以只写普通的 YAML，Helm
    安装依然能正常工作。
- en: 'To show this, let''s get started by adding a single template file to our templates
    folder. Call it `deployment.yaml` and include the following non-variable YAML:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示这个过程，我们先从向模板文件夹添加一个模板文件开始。命名为 `deployment.yaml`，并包含以下非变量的 YAML：
- en: 'deployment.yaml:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: deployment.yaml：
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see, this YAML is just a regular Kubernetes resource YAML. We aren't
    using any variables in our template.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个 YAML 文件只是一个常规的 Kubernetes 资源 YAML。我们在模板中并没有使用任何变量。
- en: Now, we have enough to actually install our chart. Let's do that next.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经具备了安装 chart 的足够信息。接下来我们来做这个操作。
- en: Installing and uninstalling a Helm chart
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装和卸载 Helm chart。
- en: 'To install a chart with Helm V3, you run a `helm install` command from the
    `root` directory of the chart:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Helm V3 安装一个 chart，你需要在 chart 的 `root` 目录下运行 `helm install` 命令：
- en: '[PRE15]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This installation command creates a Helm release called `frontend-app` and
    installs our chart. Right now, our chart only consists of a single deployment
    with two pods, and we should be able to see it running in our cluster with the
    following command:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这个安装命令创建了一个名为 `frontend-app` 的 Helm 发布，并安装了我们的 chart。此时，我们的 chart 仅由一个包含两个 pod
    的单一部署组成，应该能够通过以下命令在集群中看到它运行：
- en: '[PRE16]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This should result in the following output:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会产生以下输出：
- en: '[PRE17]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As you can see from the output, our Helm `install` command has successfully
    created a deployment object in Kubernetes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以看到，我们的 Helm `install` 命令已经成功地在 Kubernetes 中创建了一个部署对象。
- en: 'Uninstalling our chart is just as easy. We can install all the Kubernetes resources
    installed via our chart by running the following command:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 卸载我们的 chart 同样简单。我们可以通过运行以下命令来卸载所有通过我们的 chart 安装的 Kubernetes 资源：
- en: '[PRE18]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This `uninstall` command (`delete` in Helm V2) just takes the name of our Helm
    release.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 `uninstall` 命令（在 Helm V2 中是 `delete`）只需要我们的 Helm 发布名称。
- en: Now, so far, we have not used any of the real power of Helm – we've been using
    it as a `kubectl` alternative without any added features. Let's change this by
    implementing some variables in our chart.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们还没有使用 Helm 的真正强大功能——我们一直把它当作 `kubectl` 的替代工具，且没有添加任何新特性。让我们通过在 chart
    中实现一些变量来改变这一点。
- en: Using template variables
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用模板变量。
- en: Adding variables to our Helm chart templates is as simple as using double bracket
    – `{{ }}` – syntax. What we put in the double brackets will be taken directly
    from the values that we use when installing our chart using dot notation.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 向 Helm chart 模板中添加变量就像使用双大括号 – `{{ }}` – 语法一样简单。我们放入双大括号中的内容将直接来自我们在安装 chart
    时使用的值，并采用点表示法。
- en: Let's look at a quick example. So far, we have our app name (and container image
    name/version) hardcoded into our YAML file. This constrains us significantly if
    we want to use our Helm chart to deploy different applications or different application
    versions.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个简短的示例。到目前为止，我们已经将应用名称（和容器镜像名称/版本）硬编码进了 YAML 文件。如果我们想使用 Helm chart 部署不同的应用或不同的应用版本，这将大大限制我们。
- en: 'In order to address this, we''re going to add template variables to our chart.
    Take a look at this resulting template:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们将向 chart 添加模板变量。看一下这个生成的模板：
- en: 'Templated-deployment.yaml:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Templated-deployment.yaml：
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Let's go over this YAML file and review our variables. We're using a few different
    types of variables in this file, but they all use the same dot notation.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下这个 YAML 文件，并检查我们使用的变量。在这个文件中，我们使用了几种不同类型的变量，但它们都使用相同的点表示法。
- en: 'Helm actually supports a few different top-level objects. These are the main
    objects you can reference in your templates:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Helm 实际上支持几个不同的顶级对象。这些是你可以在模板中引用的主要对象：
- en: '`.Chart`: Used to reference metadata values in the `Chart.yaml` file'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.Chart`：用于引用 `Chart.yaml` 文件中的元数据值。'
- en: '`.Values`: Used to reference values passed into the chart from a `values` file
    at install time'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.Values`：用于引用在安装时从 `values` 文件传入的值。'
- en: '`.Template`: Used to reference some info about the current template file'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.Template`：用于引用当前模板文件的一些信息。'
- en: '`.Release`: Used to reference information about the Helm release'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.Release`：用于引用 Helm 发布的信息。'
- en: '`.Files`: Used to reference files in the chart that are not YAML templates
    (for instance, `config` files)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.Files`：用于引用 chart 中非 YAML 模板的文件（例如，`config` 文件）。'
- en: '`.Capabilities`: Used to reference information about the target Kubernetes
    cluster (in other words, version)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.Capabilities`：用于引用目标 Kubernetes 集群的信息（换句话说，版本）。'
- en: In our YAML file, we're using several of these. Firstly, we're referencing the
    `name` of our release (contained within the `.Release` object) in several places.
    Next, we are leveraging the `Chart` object to inject metadata into the `chartVersion`
    key. Finally, we are using the `Values` object to reference both the container
    image `name` and `tag`.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 YAML 文件中，我们使用了多个这样的引用。首先，我们在多个位置引用了我们发布的`name`（包含在`.Release`对象中）。接下来，我们利用`Chart`对象将元数据注入到`chartVersion`键中。最后，我们使用`Values`对象来引用容器镜像的`name`和`tag`。
- en: Now, the last thing we're missing is the actual values that we will inject via
    `values.yaml`, or in the CLI command. Everything else will be created using `Chart.yaml`,
    or values that we will inject at runtime via the `helm` command itself.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，最后一个我们缺少的就是我们将通过`values.yaml`或者 CLI 命令注入的实际值。其他所有内容都将通过 `Chart.yaml` 创建，或者我们将在运行时通过
    `helm` 命令注入的值来完成。
- en: 'With that in mind, let''s create our values file from our template that we
    will be passing in our image `name` and `tag`. So, let''s include those in the
    proper format:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，让我们从模板中创建我们的值文件，我们将传递我们的镜像`name`和`tag`。因此，让我们以正确的格式将它们包括在内：
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now we can install our app via our Helm chart! Do this with the following command:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以通过 Helm 图表安装我们的应用程序！使用以下命令来实现：
- en: '[PRE21]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: As you can see, we are passing in our values with the `-f` key (you can also
    use `--values`). This command will install the release of our application.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们正在使用`-f`键传入我们的值（您也可以使用`--values`）。该命令将安装我们的应用程序发布版本。
- en: Once we have a release, we can upgrade to a new version or roll back to an old
    one using the Helm CLI – we'll cover this in the next section.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了一个发布版本，我们可以使用 Helm CLI 升级到新版本或回滚到旧版本——我们将在下一节中介绍。
- en: Upgrades and rollbacks
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 升级与回滚
- en: 'Now that we have an active Helm release, we can upgrade it. Let''s make a small
    change to our `values.yaml`:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个活动的 Helm 发布版本，我们可以对其进行升级。让我们对`values.yaml`文件进行一些小的更改：
- en: '[PRE22]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To make this a new version of our release, we also need to change our chart
    YAML:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将其作为我们发布的新版本，我们还需要更改我们的图表 YAML 文件：
- en: '[PRE23]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, we can upgrade our release using the following command:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用以下命令升级我们的发布版本：
- en: '[PRE24]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'If, for any reason, we wanted to roll back to an earlier version, we can do
    so with the following command:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果出于任何原因，我们希望回滚到早期版本，我们可以使用以下命令进行操作：
- en: '[PRE25]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As you can see, Helm allows for seamless templating, releases, upgrades, and
    rollbacks of applications. As we mentioned previously, Kustomize hits many of
    the same points but does it in a much different way – let's see how.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，Helm 允许无缝的模板化、发布、升级和回滚应用程序。正如我们之前提到的，Kustomize 涉及许多相同的要点，但以完全不同的方式来实现——让我们看看它是如何做到的。
- en: Using Kustomize with Kubernetes
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Kustomize 与 Kubernetes
- en: While Helm charts can get quite complex, Kustomize uses YAML without any variables,
    and instead uses a patch and override-based method of applying different configurations
    to a base set of Kubernetes resources.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Helm 图表可能变得相当复杂，但 Kustomize 使用没有任何变量的 YAML，而是使用基于补丁和覆盖的方法来应用不同的配置到 Kubernetes
    资源的基础集合。
- en: Using Kustomize is extremely simple, and as we mentioned earlier in the chapter,
    there's no prerequisite CLI tool. Everything works by using the `kubectl apply
    -k /path/kustomize.yaml` command without installing anything new. However, we
    will also demonstrate the flow using the Kustomize CLI tool.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kustomize 非常简单，正如我们在本章前面提到的，使用它没有任何前置的 CLI 工具。所有操作都通过 `kubectl apply -k /path/kustomize.yaml`
    命令完成，无需安装任何新工具。然而，我们也将展示使用 Kustomize CLI 工具的流程。
- en: Important note
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In order to install the Kustomize CLI tool, you can check the installation instructions
    at [https://kubernetes-sigs.github.io/kustomize/installation](https://kubernetes-sigs.github.io/kustomize/installation).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 Kustomize CLI 工具，您可以查看安装说明：[https://kubernetes-sigs.github.io/kustomize/installation](https://kubernetes-sigs.github.io/kustomize/installation)。
- en: 'Currently, the installation uses the following command:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当前，安装使用以下命令：
- en: '[PRE26]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now that we have Kustomize installed, let''s apply Kustomize to our existing
    use case. We''re going to start from our plain Kubernetes YAML (before we started
    adding Helm variables):'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经安装了 Kustomize，让我们将 Kustomize 应用到现有的用例中。我们将从我们原始的 Kubernetes YAML 文件开始（在我们开始添加
    Helm 变量之前）：
- en: 'plain-deployment.yaml:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: plain-deployment.yaml：
- en: '[PRE27]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: With our initial `deployment.yaml` created, we can now create a Kustomization
    file, which we call `kustomize.yaml`.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建了初始的`deployment.yaml`文件后，我们现在可以创建一个 Kustomization 文件，我们称之为`kustomize.yaml`。
- en: When we later call a `kubectl` command with the `-k` parameter, `kubectl` will
    look for this `kustomize` YAML file and use it to determine which patches to apply
    to all the other YAML files passed to the `kubectl` command.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们稍后使用 `-k` 参数调用 `kubectl` 命令时，`kubectl` 将查找此 `kustomize` YAML 文件，并使用它来确定对所有其他传递给
    `kubectl` 命令的 YAML 文件应用哪些补丁。
- en: 'Kustomize lets us patch individual values or set common values to be automatically
    set. In general, Kustomize will create new lines, or update old lines if the key
    already exists in the YAML. There are three ways to apply these changes:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Kustomize 允许我们修补单个值或设置常见值以自动设置。一般来说，Kustomize 会创建新行，或者如果键已在 YAML 中存在，则更新旧行。有三种方法可以应用这些更改：
- en: Specify changes directly in a Kustomization file.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kustomization 文件中直接指定更改。
- en: Use the `PatchStrategicMerge` strategy with a `patch.yaml` file along with a
    Kustomization file.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `PatchStrategicMerge` 策略与 `patch.yaml` 文件一起使用 Kustomization 文件。
- en: Use the `JSONPatch` strategy with a `patch.yaml` file along with a Kustomization
    file.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `JSONPatch` 策略与 `patch.yaml` 文件一起使用 Kustomization 文件。
- en: Let's start with using a Kustomization file specifically to patch the YAML.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从使用一个 Kustomization 文件来专门修补 YAML 开始。
- en: Specifying changes directly in a Kustomization file
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Kustomization 文件中直接指定更改
- en: 'If we want to directly specify changes within the Kustomization file, we can
    do so, but our options are somewhat limited. The types of keys we can use for
    a Kustomization file are as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想直接在 Kustomization 文件中指定更改，我们可以这样做，但我们的选择会有些限制。我们可以在 Kustomization 文件中使用的键类型如下：
- en: '`resources` – Specifies which files are to be customized when patches are applied'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resources` – 指定在应用补丁时要自定义的文件'
- en: '`transformers` – Ways to directly apply patches from within the Kustomization
    file'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformers` – 直接从 Kustomization 文件中应用补丁的方法'
- en: '`generators` – Ways to create new resources from the Kustomization file'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generators` – 从 Kustomization 文件中创建新资源的方法'
- en: '`meta` – Sets metadata fields that can influence generators, transformers,
    and resources'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`meta` – 设置可以影响生成器、变换器和资源的元数据字段'
- en: If we want to specify direct patches in our Kustomization file, we need to use
    transformers. The aforementioned `PatchStrategicMerge` and `JSONPatch` merge strategies
    are two types of transformers. However, to directly apply changes to the Kustomization
    file, we can use one of several transformers, which include `commonLabels`, `images`,
    `namePrefix`, and `nameSuffix`.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想在 Kustomization 文件中指定直接补丁，我们需要使用变换器。前面提到的 `PatchStrategicMerge` 和 `JSONPatch`
    合并策略是两种变换器。然而，为了直接应用对 Kustomization 文件的更改，我们可以使用几种变换器，包括 `commonLabels`、`images`、`namePrefix`
    和 `nameSuffix`。
- en: In the following Kustomization file, we are applying changes to our initial
    deployment `YAML` using both `commonLabels` and `images` transformers.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下 Kustomization 文件中，我们使用 `commonLabels` 和 `images` 变换器对初始部署 `YAML` 进行更改。
- en: 'Deployment-kustomization-1.yaml:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 'Deployment-kustomization-1.yaml:'
- en: '[PRE28]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This particular `Kustomization.yaml` file updates the image tag from `1.0.0`
    to `2.0.0`, updates the name of the app from `frontend-myapp` to `frontend-app`,
    and updates the name of the container from `frontend-myapp` to `frontend-app-1`.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定的 `Kustomization.yaml` 文件将镜像标签从 `1.0.0` 更新为 `2.0.0`，将应用名称从 `frontend-myapp`
    更新为 `frontend-app`，并将容器名称从 `frontend-myapp` 更新为 `frontend-app-1`。
- en: For a full rundown of the specifics of each of these transformers, you can check
    the Kustomize docs at [https://kubernetes-sigs.github.io/kustomize/](https://kubernetes-sigs.github.io/kustomize/).
    The Kustomize file assumes that `deployment.yaml` is in the same folder as itself.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 要全面了解这些变换器的具体细节，您可以查看 Kustomize 文档，网址为 [https://kubernetes-sigs.github.io/kustomize/](https://kubernetes-sigs.github.io/kustomize/)。Kustomize
    文件假设 `deployment.yaml` 与其本身位于同一文件夹中。
- en: 'To see the result when our Kustomize file is applied to our deployment, we
    can use the Kustomize CLI tool. We will use the following command to generate
    the kustomized output:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看 Kustomize 文件应用于我们的部署时的结果，我们可以使用 Kustomize CLI 工具。我们将使用以下命令来生成经过 Kustomize
    处理的输出：
- en: '[PRE29]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This command will give the following output:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将输出以下内容：
- en: '[PRE30]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'As you can see, the customizations from our Kustomization file have been applied.
    Because a `kustomize build` command outputs Kubernetes YAML, we can easily deploy
    the output to Kubernetes as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们的 Kustomization 文件中的自定义设置已被应用。由于 `kustomize build` 命令输出 Kubernetes YAML，我们可以轻松地将输出部署到
    Kubernetes，方法如下：
- en: '[PRE31]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Next, let's see how we can patch our deployment using a YAML file with `PatchStrategicMerge`.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何使用带有 `PatchStrategicMerge` 的 YAML 文件修补我们的部署。
- en: Specifying changes using PatchStrategicMerge
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 PatchStrategicMerge 指定更改
- en: To illustrate a `PatchStrategicMerge` strategy, we once again start with our
    same `deployment.yaml` file. This time, we will issue our changes via a combination
    of the `kustomization.yaml` file and a `patch.yaml` file.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明`PatchStrategicMerge`策略，我们再次从相同的`deployment.yaml`文件开始。这一次，我们将通过结合使用`kustomization.yaml`文件和`patch.yaml`文件来发布我们的更改。
- en: 'First, let''s create our `kustomization.yaml` file, which looks like this:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建我们的`kustomization.yaml`文件，样式如下：
- en: 'Deployment-kustomization-2.yaml:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment-kustomization-2.yaml：
- en: '[PRE32]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: As you can see, our Kustomization file references a new file, `deployment-patch-1.yaml`,
    in the `patchesStrategicMerge` section. Any number of patch YAML files can be
    added here.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们的Kustomization文件在`patchesStrategicMerge`部分引用了一个新文件`deployment-patch-1.yaml`。可以在这里添加任意数量的补丁YAML文件。
- en: 'Then, our `deployment-patch-1.yaml` file is a simple file that mirrors our
    deployment with the changes we intend to make. Here is what it looks like:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们的`deployment-patch-1.yaml`文件是一个简单的文件，镜像了我们的部署并包含我们打算进行的更改。它的样式如下：
- en: 'Deployment-patch-1.yaml:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment-patch-1.yaml：
- en: '[PRE33]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This patch file is a subset of the fields in the original deployment. In this
    case, it simply updates the `replicas` from `2` to `4`. Once again, to apply the
    changes, we can use the following command:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这个补丁文件是原始部署中字段的一个子集。在这个例子中，它仅仅将`replicas`从`2`更新到`4`。同样地，要应用这些更改，我们可以使用以下命令：
- en: '[PRE34]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'However, we can also use the `-k` flag in a `kubectl` command! This is how
    it looks:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们也可以在`kubectl`命令中使用`-k`标志！它的样式如下：
- en: '[PRE35]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This command is the equivalent of the following:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令等同于以下命令：
- en: '[PRE36]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Similar to `PatchStrategicMerge`, we can also specify JSON-based patches in
    our Kustomization – let's look at that now.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于`PatchStrategicMerge`，我们也可以在Kustomization中指定基于JSON的补丁——现在我们来看看它。
- en: Specifying changes using JSONPatch
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用JSONPatch指定更改
- en: To specify changes with a JSON patch file, the process is very similar to that
    involving a YAML patch.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 使用JSON补丁文件指定更改的过程与使用YAML补丁非常相似。
- en: 'First, we need our Kustomization file. It looks like this:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要我们的Kustomization文件。它的样式如下：
- en: 'Deployment-kustomization-3.yaml:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment-kustomization-3.yaml：
- en: '[PRE37]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As you can see, our Kustomize file has a section, `patches`, which references
    a JSON patch file along with a target. You can reference as many JSON patches
    as you want in this section. `target` is used to determine which Kubernetes resource
    specified in the resources section will receive the patch.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们的Kustomize文件有一个`patches`部分，它引用了一个JSON补丁文件和一个目标。你可以在此部分引用任意数量的JSON补丁。`target`用于确定在资源部分指定的哪个Kubernetes资源将接收该补丁。
- en: 'Finally, we need our patch JSON itself, which looks like this:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要我们的补丁JSON本身，它的样式如下：
- en: 'Deployment-patch-2.json:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment-patch-2.json：
- en: '[PRE38]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This patch, when applied will perform the `replace` operation on the name of
    our first container. You can follow the path along with our original `deployment.yaml`
    file to see that it references the name of that first container. It will replace
    this name with the new value, `frontend-myreplacedapp`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这个补丁应用后将对第一个容器的名称执行`replace`操作。你可以沿着原始的`deployment.yaml`文件路径看到它引用了第一个容器的名称。它将把这个名称替换为新的值`frontend-myreplacedapp`。
- en: Now that we have a solid foundation in Kubernetes resource templating and releases
    with Kustomize and Helm, we can move on to the automation of deployments to Kubernetes.
    In the next section, we'll look at two patterns to accomplishing CI/CD with Kubernetes.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经掌握了Kubernetes资源模板和使用Kustomize与Helm发布的基础知识，我们可以继续进行自动化部署到Kubernetes的工作。在接下来的部分，我们将介绍两种实现CI/CD与Kubernetes的方法。
- en: Understanding CI/CD paradigms on Kubernetes – in-cluster and out-of-cluster
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Kubernetes上的CI/CD范式——集群内外
- en: Continuous integration and deployment to Kubernetes can take many forms.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 持续集成和部署到Kubernetes可以有多种形式。
- en: Most DevOps engineers will be familiar with tools such as Jenkins, TravisCI,
    and others. These tools are fairly similar in that they provide an execution environment
    to build applications, perform tests, and call arbitrary Bash scripts in a controlled
    environment. Some of these tools run commands inside containers, while others
    don't.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数DevOps工程师都会熟悉像Jenkins、TravisCI等工具。这些工具的共同之处在于它们提供了一个执行环境，用于构建应用程序、执行测试并在受控环境中调用任意的Bash脚本。其中一些工具在容器内运行命令，而另一些则不在容器内运行。
- en: When it comes to Kubernetes, there are multiple schools of thought in how and
    where to use these tools. There is also a newer breed of CI/CD platforms that
    are much more tightly coupled to Kubernetes primitives, and many that are architected
    to run on the cluster itself.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 的使用中，存在多种观点，关于如何以及在哪里使用这些工具。还有一种新型的 CI/CD 平台，它们与 Kubernetes 原语紧密耦合，许多这样的平台是为在集群内部运行而设计的。
- en: 'To thoroughly discuss how tooling can pertain to Kubernetes, we will split
    our pipelines into two logical steps:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面讨论工具如何与 Kubernetes 相关，我们将把管道分为两个逻辑步骤：
- en: '**Build**: Compiling, testing applications, building container images, and
    sending to image repositories'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建**：编译、测试应用程序，构建容器镜像，并发送到镜像仓库'
- en: '**Deploy**: Updating Kubernetes resources via kubectl, Helm, or a different
    tool'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**部署**：通过 kubectl、Helm 或其他工具更新 Kubernetes 资源'
- en: For the purposes of this book, we are going to focus mostly on the second deploy-focused
    step. Though many of the options available handle both build and deploy steps,
    the build step can happen just about anywhere, and is not worth our focus in a
    book relating to the specifics of Kubernetes.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的重点主要放在第二个以部署为重点的步骤上。尽管许多可用的选项都同时处理构建和部署步骤，但构建步骤几乎可以在任何地方发生，因此在涉及 Kubernetes
    细节的书中，构建步骤并不值得我们过多关注。
- en: 'With this in mind, to discuss our tooling options, we will split our set of
    tools into two categories as far as the Deploy part of our pipelines:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这一点，为了讨论我们的工具选项，我们将在管道的部署部分将我们的工具集分为两类：
- en: Out-of-cluster CI/CD
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群外 CI/CD
- en: In-cluster CI/CD
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群内 CI/CD
- en: Out-of-cluster CI/CD
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集群外 CI/CD
- en: In the first pattern, our CI/CD tool runs outside of our target Kubernetes cluster.
    We call this out-of-cluster CI/CD. There is a gray area where the tool may run
    in a separate Kubernetes cluster that is focused on CI/CD, but we will ignore
    that option for now as the difference between the two categories is still mostly
    valid.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种模式中，我们的 CI/CD 工具运行在目标 Kubernetes 集群之外。我们称之为集群外 CI/CD。有一种灰色地带，工具可能在一个专门用于
    CI/CD 的 Kubernetes 集群中运行，但我们暂时忽略这种情况，因为这两类之间的区别仍然有效。
- en: You'll often find industry standard tooling such as Jenkins used with this pattern,
    but any CI tool that has the ability to run scripts and retain secret keys in
    a secure way can work here. A few examples are `,` **CircleCI**, **TravisCI**,
    **GitHub Actions**, and **AWS CodeBuild**. Helm is also a big part of this pattern,
    as out-of-cluster CI scripts can call Helm commands in lieu of kubectl.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 你经常会看到 Jenkins 等行业标准工具与这种模式一起使用，但任何能够运行脚本并安全存储秘钥的 CI 工具都能在这里使用。一些例子包括 `,` **CircleCI**、**TravisCI**、**GitHub
    Actions** 和 **AWS CodeBuild**。Helm 也是这种模式的一个重要组成部分，因为集群外的 CI 脚本可以调用 Helm 命令来代替
    kubectl。
- en: Some of the strengths of this pattern are to be found in its simplicity and
    extensibility. This is a `push`-based pattern where changes to code synchronously
    trigger changes in Kubernetes workloads.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式的一些优点体现在其简洁性和可扩展性上。这是一种基于`push`的模式，其中代码的更改会同步触发 Kubernetes 工作负载的变化。
- en: Some of the weaknesses of out-of-cluster CI/CD are scalability when pushing
    to many clusters, and the need to keep cluster credentials in the CI/CD pipeline
    so it has the ability to call kubectl or Helm commands.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 集群外 CI/CD 的一些弱点包括在推送到多个集群时的可扩展性问题，以及需要在 CI/CD 管道中保留集群凭证，以便能够调用 kubectl 或 Helm
    命令。
- en: In-cluster CI/CD
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集群内 CI/CD
- en: In the second pattern, our tool runs on the same cluster that our applications
    run on, which means that CI/CD happens within the same Kubernetes context as our
    applications, as pods. We call this in-cluster CI/CD. This in-cluster pattern
    can still have the "build" steps occur outside the cluster, but the deploy step
    happens from within the cluster.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二种模式中，我们的工具运行在与应用程序相同的集群中，这意味着 CI/CD 在与应用程序相同的 Kubernetes 环境中进行，作为 pod 运行。我们称之为集群内
    CI/CD。这种集群内模式仍然可以在集群外进行“构建”步骤，但部署步骤则在集群内部发生。
- en: These types of tools have been gaining popularity since Kubernetes was released,
    and many use custom resource definitions and custom controllers to do their jobs.
    Some examples are **FluxCD**, **Argo CD**, **JenkinsX**, and **Tekton Pipelines**.
    The **GitOps** pattern, where a Git repository is used as the source of truth
    for what applications should be running on a cluster, is popular in these tools.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类型的工具自 Kubernetes 发布以来越来越受欢迎，许多工具使用自定义资源定义和自定义控制器来完成任务。一些示例包括**FluxCD**、**Argo
    CD**、**JenkinsX**和**Tekton Pipelines**。**GitOps**模式，其中 Git 仓库作为应用程序应运行在哪个集群上的真实来源，在这些工具中很流行。
- en: Some of the strengths of the in-cluster CI/CD pattern are scalability and security.
    By having the cluster "pull" changes from GitHub via a GitOps operating model,
    the solution can be scaled to many clusters. Additionally, it removes the need
    to keep powerful cluster credentials in the CI/CD system, instead having GitHub
    credentials on the cluster itself, which can be much better from a security standpoint.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 集群内 CI/CD 模式的一些优点包括可扩展性和安全性。通过让集群通过 GitOps 操作模型“拉取”来自 GitHub 的更改，解决方案可以扩展到多个集群。此外，它消除了在
    CI/CD 系统中保存强大集群凭证的需求，而是将 GitHub 凭证保存在集群本身，这在安全性方面更具优势。
- en: The weaknesses of the in-cluster CI/CD pattern include complexity, since this
    pull-based operation is slightly asynchronous (as `git pull` usually occurs on
    a loop, not always occurring exactly when changes are pushed).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 集群内 CI/CD 模式的缺点包括复杂性，因为这种基于拉取的操作略微是异步的（如 `git pull` 通常会循环执行，而不是在更改推送时立即发生）。
- en: Implementing in-cluster and out-of-cluster CI/CD with Kubernetes
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在集群内和集群外实现 CI/CD 与 Kubernetes
- en: Since there are so many options for CI/CD with Kubernetes, we will choose two
    options and implement them one by one so you can compare their feature sets. First,
    we'll implement CI/CD to Kubernetes on AWS CodeBuild, which is a great example
    implementation that can be reused with any external CI system that can run Bash
    scripts, including Bitbucket Pipelines, Jenkins, and others. Then, we'll move
    on to FluxCD, an in-cluster GitOps-based CI option that is Kubernetes-native.
    Let's start with the external option.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Kubernetes 的 CI/CD 有许多选项，我们将选择两种选项并逐一实现，以便你可以比较它们的功能集。首先，我们将实现 AWS CodeBuild
    到 Kubernetes 的 CI/CD，这是一个很好的示例实现，可以与任何可以运行 Bash 脚本的外部 CI 系统一起使用，包括 Bitbucket Pipelines、Jenkins
    等。然后，我们将转向 FluxCD，这是一个基于 GitOps 的集群内 CI 选项，它是 Kubernetes 原生的。让我们从外部选项开始。
- en: Implementing Kubernetes CI with AWS Codebuild
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 AWS CodeBuild 实现 Kubernetes CI
- en: As mentioned earlier, our AWS CodeBuild CI implementation will be easy to duplicate
    in any script- based CI system. In many cases, the pipeline YAML definition we'll
    use is near identical. Also, as we discussed earlier, we are going to skip the
    actual building of the container image. We will instead focus on the actual deployment
    piece.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们的 AWS CodeBuild CI 实现将在任何基于脚本的 CI 系统中都可以轻松复制。在许多情况下，我们将使用的管道 YAML 定义几乎是完全相同的。同时，正如我们之前讨论的，我们将跳过容器镜像的实际构建过程，而专注于实际的部署部分。
- en: To quickly introduce AWS CodeBuild, it is a script-based CI tool that runs Bash
    scripts, like many other similar tools. In the context of AWS CodePipeline, a
    higher-level tool, multiple separate AWS CodeBuild steps can be combined into
    larger pipelines.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速介绍 AWS CodeBuild，它是一个基于脚本的 CI 工具，运行 Bash 脚本，类似于许多其他类似工具。在 AWS CodePipeline
    这个更高层次的工具中，多个独立的 AWS CodeBuild 步骤可以组合成更大的管道。
- en: In our example, we will be using both AWS CodeBuild and AWS CodePipeline. We
    will not be discussing in depth how to use these two tools, but instead will keep
    our discussion tied specifically to how to use them for deployment to Kubernetes.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们将使用 AWS CodeBuild 和 AWS CodePipeline。我们不会深入讨论如何使用这两个工具，而是专注于如何将它们用于部署到
    Kubernetes。
- en: Important note
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We highly recommend that you read and review the documentation for both CodePipeline
    and CodeBuild, since we will not be covering all of the basics in this chapter.
    You can find the documentation at [https://docs.aws.amazon.com/codebuild/latest/userguide/welcome.html](https://docs.aws.amazon.com/codebuild/latest/userguide/welcome.html)
    for CodeBuild, and [https://docs.aws.amazon.com/codepipeline/latest/userguide/welcome.html](https://docs.aws.amazon.com/codepipeline/latest/userguide/welcome.html)
    for CodePipeline.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强烈建议你阅读和查看 CodePipeline 和 CodeBuild 的文档，因为我们在本章中不会涵盖所有基础知识。你可以在 [https://docs.aws.amazon.com/codebuild/latest/userguide/welcome.html](https://docs.aws.amazon.com/codebuild/latest/userguide/welcome.html)
    找到 CodeBuild 的文档，在 [https://docs.aws.amazon.com/codepipeline/latest/userguide/welcome.html](https://docs.aws.amazon.com/codepipeline/latest/userguide/welcome.html)
    找到 CodePipeline 的文档。
- en: In practice, you would have two CodePipelines, each with one or more CodeBuild
    steps. The first CodePipeline is triggered on a code change in either AWS CodeCommit
    or another Git repository (such as GitHub).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你将有两个 CodePipeline，每个包含一个或多个 CodeBuild 步骤。第一个 CodePipeline 在 AWS CodeCommit
    或其他 Git 仓库（例如 GitHub）中的代码更改时触发。
- en: The first CodeBuild step for this pipeline runs tests and builds the container
    image, pushing the image to AWS **Elastic Container Repository** (**ECR**). The
    second CodeBuild step for the first pipeline deploys the new image to Kubernetes.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: The second CodePipeline is triggered anytime we commit a change to our secondary
    Git repository with Kubernetes resource files (infrastructure repository). It
    will update the Kubernetes resources using the same process.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the first CodePipeline. As mentioned earlier, it contains
    two CodeBuild steps:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: First, to test and build the container image and push it to the ECR
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Second, to deploy the updated container to Kubernetes
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As we mentioned earlier in this section, we will not be spending much time
    on the code-to-container-image pipeline, but here is an example (not production
    ready) `codebuild` YAML for implementing this first step:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 'Pipeline-1-codebuild-1.yaml:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This CodeBuild pipeline consists of four phases. CodeBuild pipeline specs are
    written in YAML, and contain a `version` tag that corresponds to the version of
    the CodeBuild spec. Then, we have a `phases` section, which is executed in order.
    This CodeBuild first runs a `build` command, and then runs a `test` command in
    the test phase. Finally, the `containerbuild` phase creates the container image,
    and the `push` phase pushes the image to our container repository.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: One thing to keep in mind is that every value with a `$` in front of it in CodeBuild
    is an environment variable. These can be customized via the AWS Console or the
    AWS CLI, and some can come directly from the Git repository.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now take a look at the YAML for the second CodeBuild step of our first
    CodePipeline:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'Pipeline-1-codebuild-2.yaml:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Let''s break this file down. Our CodeBuild setup is broken down into three
    phases: `install`, `pre_deploy`, and `deploy`. In the `install` phase, we install
    the kubectl CLI tool.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Then, in the `pre_deploy` phase, we use an AWS CLI command and a couple of environment
    variables to update our `kubeconfig` file for communicating with our EKS cluster.
    In any other CI tool (or when not using EKS) you could use a different method
    for giving cluster credentials to your CI tool. It is important to use a safe
    option here, as including the `kubeconfig` file directly in your Git repository
    is not secure. Typically, some combination of environment variables would be great
    here. Jenkins, CodeBuild, CircleCI, and more have their own systems for this.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in the `deploy` phase, we use `kubectl` to update our deployment (also
    contained in an environment variable) with the new image tag specified in the
    first CodeBuild step. This `kubectl rollout restart` command will ensure that
    new pods are started for our deployment. In combination with using the `imagePullPolicy`
    of `Always`, this will result in our new application version being deployed.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we are patching our deployment with a specific image tag name
    in the ECR. The `$IMAGE_TAG` environment variable will be auto populated with
    the newest tag from GitHub so we can use that to automatically roll out the new
    container image to our deployment.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们通过ECR中的特定镜像标签名称来修补我们的部署。`$IMAGE_TAG`环境变量将自动填充为来自GitHub的最新标签，我们可以使用它来自动将新的容器镜像推出到我们的部署中。
- en: Next, let's take a look at our second CodePipeline. This one contains only one
    step – it listens to changes from a separate GitHub repository, our "infrastructure
    repository". This repository does not contain code for our applications themselves,
    but instead Kubernetes resource YAMLs. Thus, we can change a Kubernetes resource
    YAML value – for instance, the number of replicas in a deployment, and see it
    updated in Kubernetes after the CodePipeline runs. This pattern can be extended
    to use Helm or Kustomize very easily.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来看看我们的第二个CodePipeline。这个管道只有一个步骤——它监听来自一个独立GitHub仓库的更改，我们的“基础设施仓库”。这个仓库不包含应用程序本身的代码，而是包含Kubernetes资源的YAML文件。因此，我们可以更改Kubernetes资源YAML中的某个值——例如，部署中的副本数量，并在CodePipeline运行后看到Kubernetes中的更新。这个模式可以非常容易地扩展到使用Helm或Kustomize。
- en: 'Let''s take a look at the first, and only, step of our second CodePipeline:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看我们第二个CodePipeline的第一个，也是唯一的步骤：
- en: 'Pipeline-2-codebuild-1.yaml:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: Pipeline-2-codebuild-1.yaml：
- en: '[PRE41]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: As you can see, this CodeBuild spec is quite similar to our previous one. As
    before, we install kubectl and prep it for use with our Kubernetes cluster. Since
    we are running on AWS, we do it using the AWS CLI, but this could be done any
    number of ways, including by just adding a `Kubeconfig` file to our CodeBuild
    environment.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个CodeBuild规格与我们之前的规格非常相似。和之前一样，我们安装kubectl并准备它以便与Kubernetes集群一起使用。由于我们是在AWS上运行，我们通过AWS
    CLI来实现，但这也可以通过多种方式完成，包括仅仅将`Kubeconfig`文件添加到我们的CodeBuild环境中。
- en: The difference here is that instead of patching a specific deployment with a
    new version of an application, we are running an across-the-board `kubectl apply`
    command while piping in our entire infrastructure folder. This could then make
    any changes performed in Git be applied to the resources in our cluster. For instance,
    if we scaled our deployment from 2 replicas to 20 replicas by changing the value
    in the `deployment.yaml` file, it would be deployed to Kubernetes in this CodePipeline
    step and the deployment would scale up.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的区别在于，我们不是通过新版本的应用程序来修补特定的部署，而是通过运行全局的`kubectl apply`命令，并将整个基础设施文件夹通过管道传入。这样，Git中进行的任何更改都可以应用到我们集群中的资源。例如，如果我们通过更改`deployment.yaml`文件中的值，将部署从2个副本扩展到20个副本，在此CodePipeline步骤中它将被部署到Kubernetes，部署规模会增加。
- en: Now that we've covered the basics of using an out-of-cluster CI/CD environment
    to make changes to Kubernetes resources, let's take a look at a completely different
    CI paradigm, where the pipeline runs on our cluster.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了使用集群外CI/CD环境对Kubernetes资源进行更改的基础知识，接下来我们来看看一个完全不同的CI范式，在这种范式中，管道运行在我们的集群中。
- en: Implementing Kubernetes CI with FluxCD
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用FluxCD实现Kubernetes CI
- en: For our in-cluster CI tool, we will be using **FluxCD**. There are several options
    for in-cluster CI, including **ArgoCD** and **JenkinsX**, but we like **FluxCD**
    for its relative simplicity, and for the fact that it automatically updates pods
    with new container versions without any additional configuration. As an added
    twist, we will use FluxCD's Helm integration for managing deployments. Let's start
    with the installation of FluxCD (we'll assume you already have Helm installed
    from the previous parts of the chapter). These installations follow the official
    FluxCD installation instructions for Helm compatibility, as of the time of writing
    of this book.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的集群内CI工具，我们将使用**FluxCD**。集群内CI有几种选择，包括**ArgoCD**和**JenkinsX**，但我们喜欢**FluxCD**，因为它相对简单，并且能够在没有额外配置的情况下自动使用新容器版本更新pods。作为一个附加的特点，我们将使用FluxCD的Helm集成来管理部署。我们先从FluxCD的安装开始（我们假设你已经在本章前面的部分中安装了Helm）。这些安装遵循了截至本书写作时，FluxCD的官方安装说明，确保兼容Helm。
- en: The official FluxCD docs can be found at [https://docs.fluxcd.io/](https://docs.fluxcd.io/),
    and we highly recommend you give them a look! FluxCD is a very complex tool, and
    we are only scratching the surface in this book. A full review is not in scope
    – we are simply trying to introduce you to the in-cluster CI/CD pattern and relevant
    tooling.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 官方 FluxCD 文档可以在 [https://docs.fluxcd.io/](https://docs.fluxcd.io/) 找到，我们强烈建议你查看一下！FluxCD
    是一个非常复杂的工具，而在本书中我们仅仅是触及了表面。全面的评审不在本书的范围内——我们只是尝试向你介绍集群内的 CI/CD 模式和相关工具。
- en: Let's start our review by installing FluxCD on our cluster.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过在集群中安装 FluxCD 来开始我们的回顾。
- en: Installing FluxCD (H3)
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 FluxCD (H3)
- en: 'FluxCD can easily be installed using Helm in a few steps:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: FluxCD 可以通过 Helm 很容易地安装，只需几个步骤：
- en: 'First, we need to add the Flux Helm chart repository:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要添加 Flux Helm chart 仓库：
- en: '[PRE42]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Next, we need to add a custom resource definition that FluxCD requires in order
    to be able to work with Helm releases:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要添加 FluxCD 所需的自定义资源定义，以便它能够与 Helm 发布一起工作：
- en: '[PRE43]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Before we can install the FluxCD Operator (which is the core of FluxCD functionality
    on Kubernetes) and the FluxCD Helm Operator, we need to create a namespace for
    FluxCD to live in:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们可以安装 FluxCD Operator（FluxCD 在 Kubernetes 上的核心功能）和 FluxCD Helm Operator 之前，我们需要为
    FluxCD 创建一个命名空间：
- en: '[PRE44]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Now we can install the main pieces of FluxCD, but we'll need to give FluxCD
    some additional information about our Git repository.
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们可以安装 FluxCD 的主要组件，但我们需要提供一些关于 Git 仓库的额外信息给 FluxCD。
- en: Why? Because FluxCD uses a GitOps pattern for updates and deployments. This
    means that FluxCD will actively reach out to our Git repository every few minutes,
    instead of responding to Git hooks such as CodeBuild, for instance.
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为什么？因为 FluxCD 使用 GitOps 模式进行更新和部署。这意味着 FluxCD 将每隔几分钟主动连接到我们的 Git 仓库，而不是响应像 CodeBuild
    这样的 Git 钩子。
- en: FluxCD will also respond to new ECR images via a pull-based strategy, but we'll
    get to that in a bit.
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: FluxCD 还将通过拉取策略响应新的 ECR 镜像，但我们稍后会讨论这个问题。
- en: To install the main pieces of FluxCD, run the following two commands and replace
    `GITHUB_USERNAME` and `REPOSITORY_NAME` with the GitHub user and repository that
    you will be storing your workload specs (Kubernetes YAML or Helm charts) in.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要安装 FluxCD 的主要组件，运行以下两个命令，并将 `GITHUB_USERNAME` 和 `REPOSITORY_NAME` 替换为你将存储工作负载规格（Kubernetes
    YAML 或 Helm charts）的 GitHub 用户和仓库。
- en: 'This instruction set assumes that the Git repository is public, which it likely
    isn''t. Since most organizations use private repositories, FluxCD has specific
    configurations to handle this case – just check the docs at [https://docs.fluxcd.io/en/latest/tutorials/get-started-helm/](https://docs.fluxcd.io/en/latest/tutorials/get-started-helm/).
    In fact, to see the real power of FluxCD, you''ll need to give it advanced access
    to your Git repository in any case, since FluxCD can write to your Git repository
    and automatically update manifests as new container images are created. However,
    we won''t be getting into that functionality in this book. The FluxCD docs are
    definitely worth a close read as this is a complex piece of technology with many
    features. To tell FluxCD which GitHub repository to look at, you can set variables
    when installing using Helm, as in the following command:'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本指令集假设 Git 仓库是公开的，但实际上它很可能不是。由于大多数组织使用私有仓库，FluxCD 有专门的配置来处理这种情况——只需查看 [https://docs.fluxcd.io/en/latest/tutorials/get-started-helm/](https://docs.fluxcd.io/en/latest/tutorials/get-started-helm/)
    的文档。事实上，要真正发挥 FluxCD 的强大功能，你无论如何都需要给它高级权限访问你的 Git 仓库，因为 FluxCD 可以向你的 Git 仓库写入并在创建新的容器镜像时自动更新清单。然而，我们在本书中不会深入讨论这个功能。FluxCD
    的文档绝对值得认真阅读，因为这是一个功能复杂的技术，拥有许多特性。要告诉 FluxCD 要查看哪个 GitHub 仓库，你可以在使用 Helm 安装时设置变量，如以下命令所示：
- en: '[PRE45]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: As you can see, we need to pass our GitHub username, the name of our repository,
    and a name that will be used for our GitHub secret in Kubernetes.
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，我们需要提供 GitHub 用户名、仓库名称以及在 Kubernetes 中将用于 GitHub 密钥的名称。
- en: At this point, FluxCD is fully installed in our cluster and pointed at our infrastructure
    repository on Git! As mentioned before, this GitHub repository will contain Kubernetes
    YAML or Helm charts on the basis of which FluxCD will update workloads running
    in the cluster.
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此时，FluxCD 已经完全安装在我们的集群中，并且指向了我们的 Git 上的基础设施仓库！如前所述，这个 GitHub 仓库将包含 Kubernetes
    YAML 或 Helm charts，FluxCD 将根据这些内容更新运行在集群中的工作负载。
- en: 'To actually give Flux something to do, we need to create the actual manifest
    for Flux. We do so using a `HelmRelease` YAML file, which looks like the following:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了真正让 Flux 有事可做，我们需要为 Flux 创建实际的清单。我们使用一个 `HelmRelease` YAML 文件来完成这个操作，文件内容如下所示：
- en: 'helmrelease-1.yaml:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: helmrelease-1.yaml：
- en: '[PRE46]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Let's pick this file apart. We are specifying the Git repository where Flux
    will find the Helm chart for our application. We are also marking the `HelmRelease`
    with an `automated` annotation, which tells Flux to go and poll the container
    image repository every few minutes and see whether there is a new version to deploy.
    To aid this, we include a `chart-image` filter pattern, which the tagged container
    image must match in order to trigger a redeploy. Finally, in the values section,
    we have Helm values that will be used for the initial installation of the Helm
    chart.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解析一下这个文件。我们指定了 Flux 将在哪里找到我们应用的 Helm 图表的 Git 仓库。同时，我们还为 `HelmRelease` 添加了
    `automated` 注解，告诉 Flux 每隔几分钟去轮询容器镜像仓库，看看是否有新版本可供部署。为此，我们包括了一个 `chart-image` 过滤模式，只有标签匹配此模式的容器镜像才会触发重新部署。最后，在值部分，我们设置了用于初始安装
    Helm 图表的 Helm 值。
- en: To give FluxCD this information, we simply need to add this file to the root
    of our GitHub repository and push up a change.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供这些信息给 FluxCD，我们只需要将这个文件添加到 GitHub 仓库的根目录，并提交更改。
- en: Once we add this release file, `helmrelease-1.yaml`, to our Git repository,
    Flux will pick it up within a few minutes, and then look for the specified Helm
    chart in the `chart` value. There's just one problem – we haven't made it yet!
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将此发布文件 `helmrelease-1.yaml` 添加到 Git 仓库，Flux 将在几分钟内拾取它，然后查找 `chart` 值中指定的
    Helm 图表。唯一的问题是——我们还没有创建它！
- en: 'Currently, our infrastructure repository on GitHub only contains our single
    Helm release file. The folder contents look like this:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们在 GitHub 上的基础设施仓库只包含单一的 Helm 发布文件。文件夹内容如下所示：
- en: '[PRE47]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'To close the loop and allow Flux to actually deploy our Helm chart, we need
    to add it to this infrastructure repository. Let''s do so, making the final folder
    contents in our GitHub repository look like this:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 为了闭环并允许 Flux 实际部署我们的 Helm 图表，我们需要将其添加到这个基础设施仓库中。我们来做这个操作，使得 GitHub 仓库中的最终文件夹内容如下所示：
- en: '[PRE48]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Now, when FluxCD next checks the infrastructure repository on GitHub, it will
    first find the Helm release YAML file, which will then point it to our new Helm
    chart.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当 FluxCD 下次检查 GitHub 上的基础设施仓库时，它将首先找到 Helm 发布 YAML 文件，然后指向我们的新 Helm 图表。
- en: FluxCD, with a new release and a Helm chart, will then deploy our Helm chart
    to Kubernetes!
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: FluxCD 在获得新版本和 Helm 图表后，将把我们的 Helm 图表部署到 Kubernetes！
- en: Then, any time a change is made to either the Helm release YAML or any file
    in our Helm chart, FluxCD will pick it up and, within a few minutes (on its next
    loop), will deploy the change.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，每当对 Helm 发布 YAML 文件或我们 Helm 图表中的任何文件进行更改时，FluxCD 会在几分钟内（在下一个循环中）拾取这些更改并部署。
- en: In addition, any time a new container image with a matching tag to the filter
    pattern is pushed to the image repository, a new version of the app will automatically
    be deployed – it's that easy. This means that FluxCD is listening to two locations
    – the infrastructure GitHub repository and the container repository, and will
    deploy any changes to either location.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，每当带有与过滤模式匹配的标签的新容器镜像被推送到镜像仓库时，应用程序的新版本将自动部署——就是这么简单。这意味着 FluxCD 正在监听两个位置——基础设施的
    GitHub 仓库和容器仓库，并将部署这两个位置的任何更改。
- en: You can see how this maps to our out-of-cluster CI/CD implementation where we
    had one CodePipeline to deploy new versions of our App container, and another
    CodePipeline to deploy any changes to our infrastructure repository. FluxCD does
    the same thing in a pull-based way.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，这与我们在集群外部的 CI/CD 实现是如何映射的：我们有一个 CodePipeline 用来部署我们应用容器的新版本，另一个 CodePipeline
    用来部署任何对基础设施仓库的更改。FluxCD 也以拉取的方式做相同的事情。
- en: Summary
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about template code generation on Kubernetes. We
    reviewed how to create flexible resource templates using both Helm and Kustomize.
    With this knowledge, you will be able to template your complex applications using
    either solution, create, or deploy releases. Then, we reviewed two types of CI/CD
    on Kubernetes; first, external CI/CD deployment to Kubernetes via kubectl, and
    then in-cluster CI paradigms using FluxCD. With these tools and techniques, you
    will be able to set up CI/CD to Kubernetes for production applications.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了Kubernetes上的模板代码生成。我们回顾了如何使用Helm和Kustomize创建灵活的资源模板。掌握这些知识后，你将能够使用任一工具为复杂应用创建模板，发布或部署版本。接着，我们回顾了Kubernetes上的两种CI/CD方式；首先是通过kubectl将外部CI/CD部署到Kubernetes，然后是使用FluxCD的集群内CI范式。通过这些工具和技术，你将能够为生产应用设置Kubernetes的CI/CD。
- en: In the next chapter, we will review security and compliance on Kubernetes, an
    important topic in today's software environment.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将回顾Kubernetes上的安全性和合规性，这是当今软件环境中一个重要的话题。
- en: Questions
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are two differences between Helm and Kustomize templating?
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Helm和Kustomize模板之间的两种区别是什么？
- en: How should Kubernetes API credentials be handled when using an external CI/CD
    setup?
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用外部CI/CD设置时，如何处理Kubernetes API凭证？
- en: What are some of the reasons as to why an in-cluster CI setup may be preferable
    to an out-of-cluster setup? And vice versa?
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么在集群内的CI设置比集群外设置更可取？反之又如何？
- en: Further reading
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Kustomize docs: https:[https://kubernetes-sigs.github.io/kustomize/](https://kubernetes-sigs.github.io/kustomize/)'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kustomize文档：[https://kubernetes-sigs.github.io/kustomize/](https://kubernetes-sigs.github.io/kustomize/)
- en: Helm docs [https://docs.fluxcd.io/en/latest/tutorials/get-started-helm/](https://docs.fluxcd.io/en/latest/tutorials/get-started-helm/)
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Helm文档 [https://docs.fluxcd.io/en/latest/tutorials/get-started-helm/](https://docs.fluxcd.io/en/latest/tutorials/get-started-helm/)
