- en: Chapter 5. Implementation of the Deployment Pipeline – Initial Stages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us start with some basic (and minimum) steps of the continuous deployment
    pipeline. We'll check out the code, run pre-deployment tests and, if they are
    successful, build a container and push it to the Docker registry. With the container
    safely available in the registry, we'll switch to a different VM that will serve
    as an imitation of a production server, run the container and perform post-deployment
    tests to ensure that everything works as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Those steps will cover the most basic flow of what could be considered the continuous
    deployment process. Later on, in the next chapters, once we are comfortable with
    the process we did so far, we'll go ever further. We'll explore all the steps
    required for our microservice to safely and reliably reach the production servers
    with zero-downtime, in a way that allows us to scale easily, with the ability
    to rollback, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Spinning Up the Continuous Deployment Virtual Machine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll start by creating the continuous delivery server. We'll do that by creating
    a VM with Vagrant. While using VMs is useful as a mean to perform easy to follow
    exercises, in the real world scenario you should skip VM altogether and install
    everything directly on the server. Remember, containers are in many cases a better
    substitute for some of the things we are used to doing with VMs and using both,
    as we'll do throughout this book, is in most case only a waste of resources. With
    that being said, let us create the `cd` and `prod` VMs. We'll use the first one
    as a continuous deployment server and the second as an imitation of the production
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We cloned the GitHub repository, brought up the `cd` virtual machine and entered
    it.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few basic Vagrant operations you might need to know to follow this
    book. Specifically, how to stop and run the VM again. You never know when you
    might be left with an empty battery on your laptop or have a need to free your
    resources for some other tasks. I wouldn't like you to get into a situation where
    you are not able to follow the rest of the book just because you shut down your
    laptop and was not able to get back to the same situation you were before. Therefore,
    let's go through two basic operations; stopping the VM and bringing it up again
    with the provisioners.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to stop this VM, all you have to do is run the `vagrant halt` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'After this, VM will be stopped and your resources free for other things. Later
    on, you can start the VMs again with the `vagrant up`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `--provision` flag will, among other things, make sure that all the containers
    we need are indeed up and running. The `prod` VM, unlike the `cd`, does not use
    any provisioning, so the `--provision` argument is not needed.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment Pipeline Steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the VM up and running (or soon to be), let us quickly go through the process.
    We should perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Check out the code
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run pre-deployment tests
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compile and/or package the code
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the container
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the container to the registry
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the container to the production server
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Integrate the container
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run post-integration tests
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the tests container to the registry![Deployment Pipeline Steps](img/B04858_05_01.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 5-1 – The Docker deployment pipeline process
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: At the moment we'll limit ourselves to manual execution and once we're comfortable
    with the way things work we'll transfer our knowledge to one of the CI/CD tools.
  prefs: []
  type: TYPE_NORMAL
- en: Checking Out the Code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Checking out the code is easy, and we already did it a couple of times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Running Pre – Deployment Tests, Compiling, and Packaging the Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the code checked out, we should run all the tests that do not require the
    service to be deployed. We already did the procedure when we tried different things
    we could do in the development environment.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: First we built the tests container defined in the Dockerfile.test file and tagged
    it with the `-t` argument. The name (or tag) of the container is `10.100.198.200:5000/books-ms-tests`.
    That is the special syntax with the first part being the address of the local
    registry and the second part the actual name of the container. We'll discuss and
    use the Registry later on. For now, it's important to know that we use it to store
    and retrieve containers we're building.
  prefs: []
  type: TYPE_NORMAL
- en: The second command run all the pre-deployment tests and compiled the Scala code
    into a JAR file ready for the distribution. The third command is only for demonstration
    purposes so that you can confirm that the JAR file is indeed created and resides
    in the `scala-2.10` directory.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the reason for such a long time it took to build the container
    is because of a lot of things had to be downloaded for the first time. Each consecutive
    build will be much faster.
  prefs: []
  type: TYPE_NORMAL
- en: All we did up to now was running different commands without trying to understand
    what is behind them. Please note that commands to build Docker containers can
    be repeated in case of a failure. For example, you might lose your internet connection
    and, in such a case, building container would fail. If you repeat the build command,
    Docker will continue from the images that failed.
  prefs: []
  type: TYPE_NORMAL
- en: I wanted you to get a feeling of how Docker works from the perspective of those
    who just use pre-made containers or Dockerfile definitions created by others.
    Let us change this rhythm and dive into Dockerfile that is used to define containers.
  prefs: []
  type: TYPE_NORMAL
- en: Building Docker Containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With all the tests passed and the JAR file created, we can build the container
    that we''ll deploy to production later on. Before we do that, let us examine the
    Dockerfile that contains all the information Docker needs for building the container.
    Contents of the Dockerfile are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You can find the *Dockerfile* file together with the rest of the `books-ms`
    code in the [https://github.com/vfarcic/books-ms](https://github.com/vfarcic/books-ms)
    GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us go through it line by line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The first line specifies which image should be used as the base of the container
    we're building. In our case, we are using *Debian* (version *Jessie*). That means
    that we should have most of the functionality we would get with Debian OS. However,
    that is not to say that the whole OS is downloaded when we pull this container.
    Remember, Docker is using host kernel so when we specify that container should
    use, for example, Debian as its base, we are only downloading image that has things
    specific to the OS we specified, like, for instance, packaging mechanism (*apt*
    in the case of Debian). What are the differences between various base images?
    Why did we choose the *debian* image to part from?
  prefs: []
  type: TYPE_NORMAL
- en: In most cases the best choice for a base image is one of the official Docker
    images. Since Docker itself maintains those, they tend to be better controlled
    than those created by the community. The choice of the exact image one should
    use depends on the needs. Debian is my preference in many cases. Besides my liking
    of Debian-based Linux distributions, it is relatively small (~125 MB) and still
    a full distribution with everything you might need from a Debian OS. On the other
    hand, you might be familiar with RPM packaging and prefer, for example, CentOS.
    Its size is around 175 MB (approximately 50 % bigger than Debian). There are,
    however, some other cases when size is of utmost importance. That is especially
    true for images that would serve as utilities that are run once in a while to
    perform some specific actions. In such cases, Alpine might be a good start. Its
    size is 5 MB making it minuscule. However, bear in mind that, due to its minimalistic
    approach, this image might be hard to reason with when more complicated commands
    are run on top of it. Finally, in many cases, you might want to use more specific
    images as a base of your containers. For example, if you need a container with
    MongoDB but have few specific actions to perform on its initialization, you should
    use the mongo image.
  prefs: []
  type: TYPE_NORMAL
- en: In systems that host many containers, the size of the base image is less important
    than how many different base images are used. Remember, each image is cached on
    the server and reused across all containers that use it. If all your containers
    are, for example, extending from the **debian** image, the same cached copy will
    be reused in all cases meaning that it will be downloaded only once.
  prefs: []
  type: TYPE_NORMAL
- en: What we use as a base image is a container like any other. That means that you
    can use your containers as a base for others. For example, you might have many
    cases with applications that require NodeJS in combination with Gulp and few scripts
    specific to your organization. This scenario would be a good candidate for a container
    that would be extended (through the `FROM` instruction) by others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us move to the next instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The maintainer is purely informational providing information about the author;
    a person who maintains the container. Not much to do here. Moving on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The `RUN` instruction executes any set of commands that run in the same way
    as if those commands are run in the command prompt. You might have noticed that
    each but the last line in our example ends with `&& \`. We are joining several
    separate commands instead of running each of them as a separate RUN instruction.
    The same result (from the operational perspective) could be accomplished with
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: That certainly looks cleaner and easier to maintain. However, it has its set
    of problems. One of them is that each instruction in the Dockerfile generates
    a separate image. A container is a collection of images stacked one on top of
    the other. Knowing that, last two `RUN` instructions (`clean` and `rm`) do not
    provide any value. Let's illustrate it by putting (invented numbers) of the size
    of each image. First two instructions (`apt-get update` and `apt-get install`)
    are adding packages (let's say 100 MB). The second two (`apt-get clean` and `rm`)
    are removing files (let's say 10 MB). While removal of files on a normal system
    does reduce the size of what we have stored on the HD, in the case of Docker containers
    it only removes things from the current image. Since each image is *immutable*,
    previous two images continue to have the size of 100 MB thus not removing the
    overall size of the container even though files removed later on are not accessible
    within the container. The size of those four images continues being 100 MB. If
    we go back to the first example where all commands are executed within the same
    `RUN` instruction thus creating a single image, the size is smaller (100 MB -
    10 MB = 90 MB).
  prefs: []
  type: TYPE_NORMAL
- en: The important thing to note is that the size is not the only important consideration
    and we should try to balance it with maintainability. *Dockerfile* needs to be
    readable, easy to maintain and with a clear intention behind it. That means that
    in some cases the benefits of having one huge `RUN` instruction might not be the
    best option if that means that it will be hard to maintain it later on.
  prefs: []
  type: TYPE_NORMAL
- en: All that being said, the purpose of the RUN command in our example is to update
    the system with latest packages (`apt-get update`), install JDK 7 (`apt-get install`)
    and remove unnecessary files created during the process (`apt-get clean` and `rm`).
  prefs: []
  type: TYPE_NORMAL
- en: 'The next set of instructions provides the container with environment variables
    that can be changed at runtime:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In this particular case, we are declaring variables `DB_DBNAME` and `DB_COLLECTION`
    with default values. The code of the service uses those variables to create the
    connection to the *Mongo DB*. If, for some reason, we'd like to change those values,
    we could set them when executing the `docker run` command (as we'll see later
    on throughout the book).
  prefs: []
  type: TYPE_NORMAL
- en: In the container world, we are discouraged from passing environment specific
    files to containers running on different servers. Ideally, we should run a container
    without any other external files. While that is in some cases impractical (as,
    for example, with *nginx* that we'll use later on for reverse proxy), environment
    variables are a preferred way of passing environment specific information to the
    container at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, in our example, are a couple of `COPY` instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '`COPY` instruction is true to its name. It copies files from the host file
    system to the container we are building. It should be written in the `COPY <source>...
    <destination>` format. The `source` is relative to the location of the *Dockerfile*
    and must be inside the context of the build. What the latter statement means is
    that you cannot copy files that are not inside the directory where *Dockerfile*
    resides or one of its child directories. For example, `COPY ../something /something`
    is not allowed. The source can be a file or a whole directory and can accept wildcards
    matching the Go''s `filepath.Match` rules. The destination can also be a file
    or a directory. Destination matches the type of the source. If the source is a
    file, destination will be a file as well. Same is true when the source is a directory.
    To force destination to be a directory, end it with a slash (`/`).'
  prefs: []
  type: TYPE_NORMAL
- en: While we haven't used `ADD` in our example, it is worth noting that it is very
    similar to `COPY`. In most cases I encourage you to use `COPY` unless you need
    additional features that `ADD` provides (most notably `TAR` extraction and URL
    support).
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we are copying `run.sh` and making it executable through the
    `chmod RUN` instruction. Next, we are copying the rest of the files (back-end
    `JAR` and front-end *components*).
  prefs: []
  type: TYPE_NORMAL
- en: Let us go through the last two instructions from our Dockerfile.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `CMD` specifies the command that will be executed when the container starts.
    The format is [`executable`, `parameter1`, `parameter2` and so on]. In our case
    `/run.sh` will run without any parameters. At the moment, the script contains
    a single command `java -jar bs.jar` that will start the Scala/Spray server. Keep
    in mind that `CMD` provides only the default executor that can be easily overwritten
    when a container is run.
  prefs: []
  type: TYPE_NORMAL
- en: The `EXPOSE` instruction specifies which port inside the container will be available
    at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: The example *Dockerfile* we explained does not contain all the instructions
    we could use. Throughout this book, we'll work with a couple of others and get
    more familiar with the format. In the meantime, please visit the Dockerfile reference
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Equipped with this knowledge, let us build the container. The command is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Let us use the time it takes for this command run (the first build always takes
    longer than the others) and go through the arguments we used. The first argument
    is `build` used for building containers. Argument `-t` allows us to tag the container
    with a particular name. If you'd like to push this container to the public Hub,
    the tag would be using the `/` format. If you have the account on Docker Hub,
    the username is used to identify you and can be used later on to push the container
    making it available for pulling on any server connected to the internet. Since
    I'm not willing to share my password, we took a different approach and used the
    *registry* IP and port instead of the Docker Hub username. That allows us to push
    it to the private registry instead. This alternative is usually better because
    it provides us with a complete control over our containers, tends to be faster
    over the local network and won't give CEO of your company a heart attack for sending
    your applications to the cloud. Finally, the last argument is a dot (`.`) specifying
    that the Dockerfile is located in the current directory.
  prefs: []
  type: TYPE_NORMAL
- en: One important thing left to discuss is the order of instructions in the *Dockerfile*.
    On one hand, it needs to be in logical. We can not, for example, run an executable
    before installing it or, as in our example, change permissions of the `run.sh`
    file before we copy it. On the other hand, we need to take in account Docker caching.
    When a `docker build` command is run, Docker will go instruction by instruction
    and check whether some other build process already created the image. Once an
    instruction that will build a new image is found, Docker will build not only that
    instruction but of all those that follow. That means that, in most cases, `COPY`
    and `ADD` instructions should be placed near the bottom of the *Dockerfile*. Even
    within a group of `COPY` and `ADD` instructions, we should make sure to place
    higher those files that are less likely to change. In our example, we're adding
    `run.sh` before the `JAR` file and front-end components since latter are likely
    to change with every build. If you execute the `docker build` command the second
    time you'll notice that Docker outputs `---> Using cache` in all steps. Later
    on, when we change the source code, Docker will continue outputting `---> Using
    cache` only until it gets to one of the last two `COPY` instructions (which one
    it will be, depends on whether we changed the `JAR` file or the front-end components).
  prefs: []
  type: TYPE_NORMAL
- en: We'll be using Docker commands a lot, and you'll have plenty opportunity to
    get more familiar with them. In the meantime, please visit the Using the command
    line page for more information.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, by this time, the container is already built. If not, take a short
    break. We are about to run our newly built container.
  prefs: []
  type: TYPE_NORMAL
- en: Running Containers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Running containers is easy as long as you know which arguments to use. The
    container we just built can be run with the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The first command started the database container required by our service. The
    argument `-d` allows us to run a container in detached mode, meaning that it will
    run in the background. The second one, `--name books-db`, gives the container
    a name. If not specified, Docker would assign a random one. Finally, the last
    argument is the name of the image we want to use. In our case, we're using *mongo*,
    the official Docker MongoDB image.
  prefs: []
  type: TYPE_NORMAL
- en: This command shows one of very useful Docker features. Just as GitHub revolutionized
    the way we share code between different developers and projects, Docker Hub changed
    the way we deploy not only applications we are building but also those built by
    others. Please feel free to visit [https://hub.docker.com/](https://hub.docker.com/)
    and search for your favorite application, service, or a database. Chances are
    you'll find not only one (often official docker container) but many others done
    by the community. Efficient usage of Docker is often a combination of running
    images built by yourself and those built by others. Even if no image serves your
    purpose, it is often a good idea to use existing one as a base image. For example,
    you might want MongoDB with *replication set* enabled. The best way to obtain
    such an image would be to use *mongo* as the `FROM` instruction in your *Dockerfile*
    and add replication commands below it.
  prefs: []
  type: TYPE_NORMAL
- en: The second `docker run` is a little bit more complicated. Besides running in
    detached mode and giving it a name, it also exposes port 8080 and links with the
    `books-ms-db` container. Exposing port is easy. We can provide a single port,
    for example `-p 8080`. In such a case, Docker will expose its internal port `8080`
    as a random port. We'll use this approach later on when we start working with
    *service discovery tools*. In this example, we used two ports separated by a colon
    (`-p 8080:8080`). With such argument, Docker exposed its internal port 8080 to
    8080\. The next argument we used is `--link books-db:db` and allows us to link
    two containers. In this example, the name of the container we want to link to
    is *books-ms-db*. Inside the container, this link will be converted into environment
    variables. Let see how those variables look like.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can enter the running container using the `exec` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Arguments `-it` tells Docker that we want this execution to be interactive
    and with a terminal. It is followed by the name of the running container. Finally,
    we are overwriting the default command specified as the `CMD` instruction in the
    *Dockerfile* with *bash*. In other words, we entered into the running container
    by running *bash*. Once inside the container, we listed all environment variables
    and filtered them so that only those containing `DB` are output. When we run the
    container, we specified that it should link with `books-ms-db` as `db`. Since
    all environment variables are always in uppercase, Docker created quite a few
    of them with names starting with `DB`. The output of `env` was as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: All but the last two are a result of linking with the other container. We got
    the name of the link, TCP, port, and so on. The last two (`DB_COLLECTION` and
    `DB_DBNAME`) are not the result of linking but variables we defined inside the
    *Dockerfile*.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we exited the container.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are few more things we can do to ensure that everything is running correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `ps -a` command listed all (`-a`) containers. This command should output
    both `books-ms` and `books-ms-db`. The `logs` command, as the name says, outputs
    logs of the container `books-ms`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though it was very easy to run the Mongo DB and our container, `books-ms`,
    we are still required to remember all the arguments. Much easier way to accomplish
    the same result is with **Docker Compose**. Before we see it in action, let us
    remove the container we are running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The first command (`rm`) removes all listed containers. The argument `-f` forces
    that removal. Without it, only stopped containers could be removed. The `rm` command
    combined with the `-f` argument is equivalent to stopping containers with the
    `stop` command and then removing them with `rm`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us run the same two containers (`mongo` and `books-ms`) with **Docker Compose**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This time, we run both containers with a single `docker-compose` command. The
    `-f` argument specifies the specification file we want to use. I tend to define
    all development configurations in `docker-compose-dev.yml` and production in the
    default `docker-compose.yml`. When default file name is used, there is no need
    for the `-f` argument. Next is the `up` command that brought up the `app` container
    in detached mode (`-d`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the contents of the `docker-compose-dev.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The above output only displays the targets we are interested right now. There
    are others primarily dedicated to testing and compiling. We used them before when
    we set up the development environment. We'll use them again later on. For now,
    let us discuss the `app` and `db` targets. Their definition is very similar to
    Docker commands and arguments we already used and should be easy to understand.
    The interesting one is `links`. Unlike linking with manual commands where we need
    first to start the source container (in our case `mongo`) and then the one that
    links to it (`books-ms`), `docker-compose` will start all dependant containers
    automatically. We run the `app` target and Docker compose realized that it depends
    on the `db` target, so it started it first.
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, we can verify that both containers are up and running. This time,
    we''ll do it with the Docker Compose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Docker Compose, by default, names running containers using the combination of
    the project name (which default to the name of the directory), the name of the
    target (`app`) and the instance number (`1`). Later on, we'll run multiple instances
    of the same container distributed across multiple servers, and you'll have the
    chance to see this number increase.
  prefs: []
  type: TYPE_NORMAL
- en: With both containers up and running, we can check the logs of the containers
    we run with Docker Compose.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Please note that Docker Compose logs are in the `follow` mode, and you need
    to press *Ctrl* + *C* to stop it.
  prefs: []
  type: TYPE_NORMAL
- en: I prefer as much testing as possible to be automatic, but that subject is left
    for later chapters so a brief manual verification will have to do for now.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: For those unfamiliar with `curl`, it is a command line tool and library for
    transferring data with URL syntax. In our case, we're using it to send three `PUT`
    requests to the service that, in turn, stored data to the MongoDB. Last two commands
    invoked the service APIs to retrieve a list of all books, as well as data related
    to a particular book with the ID 1\. With those manual verifications, we confirmed
    that the service works and can communicate with the database. Please note that
    we used `jq` to format JSON output.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, this service also contains front-end Web components, but we won't
    try them out at this time. That is reserved for later, when we deploy this service
    to production together with the Web site that will import them.
  prefs: []
  type: TYPE_NORMAL
- en: Containers that we are running are misplaced. The VM that we're using is supposed
    to be dedicated to continuous deployment, and the containers that we built should
    run on a separate production server (or in our case a separate VM that should
    simulate such a server). Before we start deploying to production, we should go
    through *configuration management* that will allow us not only to streamline the
    deployment but also to setup the servers. We already used `Ansible` to create
    the `cd` VM, but we haven't had time to explain how it works. Even worst, we are
    yet to make a choice which tool to use.
  prefs: []
  type: TYPE_NORMAL
- en: For now, let us stop and remove the `books-ms` container and its dependencies
    thus freeing the `cd` server to do what it was intended to do in the first place;
    enable continuous deployment pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Pushing Containers to the Registry
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Docker Registry can be used to store and retrieve containers. We already run
    it with the `cd` VM we created at the beginning of this chapter. With the `books-ms`
    built, we can push it to the registry. That will allow us to pull the container
    from any place that can access the `cd` server. Please run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Earlier in this chapter, we built the container using the `10.100.198.200:5000/books-ms`
    tag. That was a special format used for pushing to private registries; `:/`. After
    the container has been tagged, we pushed it to the registry running on IP `10.100.198.200`
    and port `5000\. 10.100.198.200` is the IP of our `cd` VM.
  prefs: []
  type: TYPE_NORMAL
- en: With the container safely stored to the registry, we can run it on any server.
    Soon, once we go through configuration management, we'll have additional servers
    where we'll run containers stored in this registry.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s finish this chapter by destroying all the VMs. The next chapter will
    create those we need. That way you can take a break before continuing our adventure
    or jump into any chapter without the fear that something will fail due to tasks
    we did before. Each chapter is fully autonomous. While you will benefit from the
    knowledge obtained from previous chapters, technically, each of them works on
    its own. Before we destroy everything we did, we''ll push the tests container
    so that we do not have to re-built it again from scratch. Registry container has
    a volume that maps our host directory to the internal path where images are stored.
    That way, all pushed images are stored on the host (directory `registry`) and
    do not depend on the VM where it''s running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The Checklist
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We are still a few steps short of the basic implementation of the deployment
    pipeline. As a reminder, the steps are following:'
  prefs: []
  type: TYPE_NORMAL
- en: Checkout the code - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run pre-deployment tests - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compile and/or package the code - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the container - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the container to the registry - Done
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the container to the production server - Pending
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Integrate the container - Pending
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run post-deployment tests - Pending
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the tests container to the registry - Pending
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It is important to notice that all the steps we run by now were performed on
    the `cd` VM. We want to reduce the impact on the production environment as much
    as possible so we''ll continue running steps (or part of them) outside the destination
    server as much as possible:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Checklist](img/B04858_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-2 – The initial stages of the deployment pipeline with Docker
  prefs: []
  type: TYPE_NORMAL
- en: We did the first five steps, or, at least, their manual version. The rest will
    have to wait until we set up our production server. In the next chapter, we'll
    discuss the options we have to accomplish this task.
  prefs: []
  type: TYPE_NORMAL
