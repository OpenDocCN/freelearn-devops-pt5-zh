# 13

# 介绍容器编排

在上一章中，我们展示了如何收集容器日志并将其发送到集中位置，在那里聚合的日志可以解析出有用信息。我们还学习了如何对应用程序进行监控，使其暴露出指标，并且这些指标可以被抓取并再次发送到集中位置。最后，本章教我们如何将这些收集到的指标转换为图形化的仪表盘，来监控容器化的应用程序。

本章介绍了编排器的概念。它教我们为什么需要编排器，以及它们是如何在概念上工作的。本章还将概述一些最流行的编排器，并列出它们的优缺点。

本章将涵盖以下内容：

+   什么是编排器，我们为什么需要它们？

+   编排器的任务

+   流行的编排器概述

完成本章后，你将能够做以下事情：

+   列举三到四个编排器负责的任务

+   列出两到三个最流行的编排器

+   用你自己的话向一个感兴趣的外行解释，并通过适当的类比说明为什么我们需要容器编排器

# 什么是编排器，我们为什么需要它们？

在*第九章*《学习分布式应用架构》中，我们了解了常用的构建、运输和运行高度分布式应用的模式和最佳实践。现在，如果我们的分布式应用是容器化的，那么我们将面临与非容器化分布式应用相同的问题或挑战。这些挑战中有一些是在那一章中讨论过的，诸如服务发现、负载均衡、扩展等。

类似于 Docker 对容器所做的事情——通过引入容器标准化软件的打包和运输——我们希望有某种工具或基础设施软件来处理所有或大多数已经提到的挑战。这款软件就是我们所说的容器编排器，或者我们也称它们为编排引擎。

如果我刚才说的内容对你来说还没有太大意义，那么让我们换个角度来看。想象一下一个演奏乐器的艺术家。他们可以单独为观众演奏美妙的音乐——只是艺术家和他们的乐器。但现在，假设有一支由多位音乐家组成的管弦乐队。把他们都放在一个房间里，给他们交代交响乐的乐谱，让他们演奏，并且离开房间。如果没有指挥，这群非常有才华的音乐家将无法和谐地演奏这首曲子；它听起来更像是一种杂音。只有当管弦乐队有一个指挥，来编排这些音乐家，乐队的音乐才能让我们的耳朵享受。

现在，我们不再是音乐家，而是容器；不再是各种乐器，而是具有不同运行需求的容器主机。与音乐在不同速度下演奏不同，我们的容器也以特定的方式相互通信，并且需要根据对应用程序的负载变化进行扩展或缩减。就此而言，容器调度器的角色与乐团指挥非常相似。它确保集群中的容器和其他资源协调一致地工作。

我希望你现在能更清楚地理解容器调度器是什么，以及为什么我们需要它。假设你已经明白了这个问题，我们现在可以问自己，调度器如何实现预期的结果，即确保集群中的所有容器和谐工作。答案是，调度器必须执行非常具体的任务，类似于乐团指挥也有一套任务，用来驾驭并同时提升乐团的表现。

# 调度器的任务

那么，我们期望一个值得投资的调度器为我们执行哪些任务呢？让我们详细看看。以下列表展示了在撰写时，企业用户通常期望从调度器获得的最重要任务。

## 调整期望状态

使用调度器时，你会告诉它（最好是以声明性方式）如何运行给定的应用程序或应用服务。我们在*第十一章*《使用 Docker Compose 管理容器》中学习了什么是声明性和命令式的区别。描述我们要运行的应用服务的声明性方式包括元素，例如使用哪个容器镜像、运行多少实例、打开哪些端口等。我们称之为应用服务的声明属性，这就是所谓的期望状态。

所以，当我们首次告诉调度器基于声明创建一个新的应用服务时，调度器将确保根据请求在集群中调度足够多的容器。如果容器镜像在目标节点上尚不可用，调度器将确保从镜像仓库下载它们。接下来，容器将按照所有设置（如网络连接或暴露的端口）启动。调度器会尽力使集群的实际情况与声明完全匹配。

一旦我们的服务按要求启动并运行，也就是说，它已经在期望状态下运行，那么调度器将继续监控它。每当调度器发现服务的实际状态与期望状态不一致时，它将尽力再次调整，使实际状态与期望状态保持一致。

那么，实际状态和期望状态之间可能出现什么样的差异呢？假设服务的一个副本，也就是其中一个容器，由于 bug 等原因崩溃了；那么编排器会发现实际状态与期望状态在副本数量上有所不同：少了一个副本。编排器会立即在另一个集群节点上调度一个新的实例来替代崩溃的实例。另一种差异可能是，如果服务被缩减了规模，应用服务可能会运行过多实例。在这种情况下，编排器会随机杀死需要的实例，以实现实际实例数量和期望数量之间的平衡。还有一种差异是，当编排器发现应用服务的某个实例正在运行一个错误的（可能是旧的）底层容器镜像版本时。到现在为止，你应该能理解了，对吧？

因此，取而代之的是我们主动监控集群中运行的应用服务并纠正任何与期望状态的偏差，我们将这一繁琐的任务委托给编排器。这在我们使用声明性方式而非命令式方式描述应用服务的期望状态时效果最好。

## 复制和全局服务

在由编排器管理的集群中，我们可能会想要运行两种截然不同类型的服务。它们分别是复制服务和全局服务。**复制服务**是指要求在特定数量的实例上运行的服务，比如 10 个实例。**全局服务**则是指要求在集群中的每个工作节点上恰好运行一个实例的服务。我在这里使用了“工作节点”这个术语。在由编排器管理的集群中，通常有两种类型的节点：管理节点和工作节点。

**管理节点**通常是由编排器专门用于管理集群的，不运行任何其他工作负载。而工作节点则运行实际的应用程序。因此，编排器会确保对于全局服务，无论工作节点有多少，每个节点上都将运行一个实例。我们不关心实例的数量，而只关心每个节点上都必须保证运行一个实例。

我们可以再次完全依赖编排器来处理这个问题。在一个复制服务中，我们始终可以确保找到精确所需数量的实例，而在全局服务中，我们可以确保每个工作节点上都会运行恰好一个实例。编排器将始终尽最大努力来保证这个期望的状态。在 Kubernetes 中，全局服务也被称为**DaemonSet**。

## 服务发现

当我们以声明性方式描述一个应用服务时，我们绝不应该告诉协调器不同实例应运行在哪些集群节点上。我们将让协调器决定哪个节点最适合执行这个任务。

当然，从技术上讲，可以指示协调器使用非常确定的放置规则，但这将是一种反模式，除非在非常特殊的边缘情况下，否则根本不推荐使用。

所以，如果我们现在假设协调引擎完全自由地决定应用服务的各个实例放置的位置，而且实例可能会崩溃并由协调器重新调度到不同的节点，那么我们就会意识到，试图追踪各个实例在任何给定时刻的运行位置是徒劳的。更好的是，我们根本不应该尝试去了解这一点，因为这并不重要。

好吧，你可能会说，如果我有两个服务，A 和 B，而服务 A 依赖于服务 B；那么服务 A 的任何实例不应该知道它可以在哪里找到服务 B 的实例吗？

在这里，我必须大声而清楚地说——不，应该不了。这种知识在高度分布式和可扩展的应用程序中并不理想。相反，我们应该依赖于协调器来提供我们所需的信息，以便访问我们依赖的其他服务实例。这有点像电话时代早期，我们不能直接拨打朋友的电话，而是必须拨打电话公司的总机，由接线员将我们转接到正确的目的地。在我们的案例中，协调器充当了接线员的角色，将来自服务 A 实例的请求路由到可用的服务 B 实例。整个过程被称为服务发现。

## 路由

到目前为止，我们已经了解，在一个分布式应用程序中，我们有许多交互的服务。当服务 A 与服务 B 进行交互时，是通过数据包的交换来实现的。这些数据包需要以某种方式从服务 A 传输到服务 B。将数据包从源头传输到目的地的过程也称为*路由*。作为应用程序的作者或操作员，我们期望调度器来承担这个路由任务。正如我们在后续章节中看到的，路由可以在不同的层级上进行。这就像现实生活中的情况。假设你在一家公司的一栋办公楼里工作。现在，你有一份文件需要转交给公司里的另一位员工。内部邮政服务会将文件从你的发件箱中取走，并送到同一建筑物内的邮局。如果目标人工作在同一栋楼，那么文件可以直接转交给该人。如果目标人则工作在同一区块的另一栋楼，文件将转交给目标楼的邮局，然后由内部邮政服务将其分发给收件人。第三种情况是，如果文件是送给在不同城市甚至不同国家的公司分支机构的员工，那么文件将被转交给外部邮政服务（如 UPS），它将文件运输到目标地点，从那里，再次由内部邮政服务接管并将其送达收件人。

在容器中运行的应用服务之间路由数据包时，也会发生类似的事情。源容器和目标容器可以位于同一个集群节点上，这相当于两名员工在同一栋建筑物中工作。

目标容器可能运行在不同的集群节点上，这相当于两名员工在同一区块的不同建筑物中工作。最后，第三种情况是，当数据包来自集群外部，必须路由到集群内部运行的目标容器。

所有这些情况，以及更多的情况，都必须由调度器来处理。

## 负载均衡

在高可用的分布式应用中，所有组件都必须是冗余的。这意味着每个应用服务必须以多个实例运行，这样即使一个实例失败，整个服务仍然能够正常运行。

为确保所有服务实例都在实际工作，而不是空闲着，你需要确保服务请求被均等地分配到所有实例。将工作负载分配到服务实例的过程称为负载均衡。存在多种算法来决定如何分配工作负载。

通常，负载均衡器使用所谓的轮询算法，确保工作负载在实例间均匀分配，采用循环算法进行分配。我们再次期望调度器处理来自一个服务到另一个服务或从外部源到内部服务的负载均衡请求。

## 扩展性

当我们在由调度器管理的集群中运行容器化的分布式应用时，我们也希望能够轻松处理预期的或意外的工作负载增加。为了应对增加的工作负载，我们通常只是调度该服务的额外实例来应对增加的负载。负载均衡器随后会自动配置，以便在更多的可用目标实例上分配工作负载。

但是在实际场景中，工作负载会随时间变化。如果我们看看像亚马逊这样的购物网站，它可能在晚上的高峰时段负载很高，因为那时每个人都在家在线购物；在像“黑色星期五”这样的特殊日子，负载可能会异常巨大；而在清晨，流量可能非常少。因此，服务不仅需要能够扩展，当工作负载减少时，也需要能够缩减。

我们还期望调度器在扩展时能够合理地分配服务实例。当扩展时，将所有服务实例调度到同一个集群节点上并不是明智之举，因为如果该节点宕机，整个服务都会宕机。负责容器部署的调度器需要考虑避免将所有实例都放置在同一个计算机机架上，因为如果机架的电源供应出现故障，整个服务也会受到影响。此外，关键服务的实例应分布在多个数据中心，以避免因故障而导致服务中断。所有这些决策，以及更多的决策，都由调度器负责。

在云中，通常使用“可用区”一词，而不是计算机机架。

## 自愈

如今，调度器已经非常复杂，可以为我们维护健康的系统做很多工作。调度器监控集群中所有运行的容器，并且会自动用新的实例替换崩溃或未响应的容器。调度器监控集群节点的健康状况，如果某个节点变得不健康或宕机，它会将该节点从调度循环中移除。原本在这些节点上的工作负载会自动重新调度到其他可用节点上。

所有这些活动，调度器监控当前状态并自动修复损坏或调节到期望状态，导致了所谓的自愈系统。

在大多数情况下，我们不需要主动干预和修复损坏。调度器会自动为我们完成这一任务。然而，有一些情况是调度器在没有我们帮助的情况下无法处理的。设想一个场景，我们有一个服务实例运行在容器中。容器已经启动并运行，从外部看起来完全健康，但内部运行的应用程序处于不健康状态。应用程序没有崩溃；它只是无法按原设计正常工作了。调度器怎么可能知道这一点呢？它根本无法知道！每个应用服务的健康或无效状态意味着完全不同的事情。换句话说，健康状态是依赖于服务的。只有服务的开发者或运维人员才知道在该服务的上下文中，什么才算健康。

现在，调度器定义了接缝或探针，应用服务可以通过这些与调度器通信，告知其所处的状态。探针主要有两种基本类型：

+   服务可以告知调度器它是否健康

+   服务可以告知调度器它是否准备就绪或暂时不可用

服务如何确定前述问题的答案完全取决于该服务。调度器只定义了它将如何询问，比如通过 HTTP `GET` 请求，或它期望什么类型的答案，比如 `OK` 或 `NOT OK`。

如果我们的服务实现了逻辑来回答前述的健康或可用性问题，那么我们就拥有了一个真正的自愈系统，因为调度器可以终止不健康的服务实例，并用新的健康实例替换它们，且可以将暂时不可用的服务实例从负载均衡器的轮询中移除。

## 数据持久化和存储管理

数据持久化和存储管理是容器编排中的关键环节。它们确保数据在容器重启和故障后得以保留，使得应用能够维持其状态，并按预期继续运行。

在容器化环境中，数据存储可以分为两大类——临时存储和持久存储：

+   **临时存储**：这种存储与容器的生命周期相关。当容器终止或失败时，存储在临时存储中的数据将丢失。临时存储适用于临时数据、缓存或其他可以重新生成的非关键性信息。

+   **持久存储**：持久存储将数据与容器的生命周期解耦，使得数据即使在容器终止或失败后仍能持久存在。这种存储类型对于保存关键应用数据至关重要，比如用户生成的内容、数据库文件或配置数据。

容器编排引擎通过提供将持久存储附加到容器的机制来处理数据持久性和存储管理。这些机制通常涉及存储卷的创建和管理，存储卷可以根据需要挂载到容器中。

大多数容器编排引擎支持多种类型的存储后端，包括块存储、文件存储和对象存储。它们还提供与流行存储解决方案的集成，如基于云的存储服务、网络附加存储和分布式存储系统（如 Ceph 或 GlusterFS）。

另外，容器编排引擎处理存储的提供和管理，自动化执行如卷创建、调整大小和删除等任务。它们还允许用户定义存储类和策略，使得在分布式环境中管理存储资源变得更加容易。

总之，容器编排引擎中的数据持久性和存储管理确保应用程序在容器重启和故障期间保持其状态。它们提供将持久存储附加到容器的机制，并自动化存储提供和管理任务，从而简化了在容器化环境中管理存储资源的过程。

## 零停机时间部署

如今，对于需要更新的关键任务应用程序，停机时间越来越难以 justify。不仅意味着错失机会，还可能导致公司声誉受损。使用该应用程序的客户已不再愿意接受不便，并会迅速流失。

此外，我们的发布周期越来越短。在过去，我们每年只有一到两个新版本发布，而如今，许多公司每周甚至每天都会更新应用程序多次。

解决这个问题的方法是提出一个零停机时间的应用更新策略。编排器需要能够批量更新单个应用服务。这也被称为滚动更新。在任何给定时间，只有某个服务的一个或少数几个实例被停用，并由该服务的新版本替换。只有在新实例正常运行，且没有出现任何意外错误或不良表现的情况下，才会更新下一批实例。这个过程会一直重复，直到所有实例都被替换为新版本。如果由于某种原因更新失败，我们期望编排器能自动将更新后的实例回滚到先前的版本。

其他可能的零停机时间部署方式包括蓝绿部署和金丝雀发布。在这两种情况下，服务的新版本将与当前的活跃版本并行安装。但最初，新版本仅在内部可访问。操作人员可以对新版本进行冒烟测试，当新版本似乎运行良好时，在蓝绿部署的情况下，路由器将从当前的蓝色版本切换到新的绿色版本。在一段时间内，新的绿色版本将受到密切监控，如果一切正常，旧的蓝色版本可以被停用。另一方面，如果新的绿色版本没有按预期工作，那么只需将路由器切换回旧的蓝色版本，就可以实现完全回滚。

在金丝雀发布的情况下，路由器的配置方式是将 1%的总体流量引导到服务的新版本，而 99%的流量仍然经过旧版本。新版本的行为会被密切监控，并与旧版本的行为进行比较。如果一切正常，经过新服务的流量百分比会稍微增加。这个过程会重复，直到 100%的流量都通过新服务。如果新服务运行了一段时间且一切正常，旧服务可以被停用。

大多数编排器至少支持开箱即用的滚动更新类型的零停机时间部署。蓝绿部署和金丝雀发布通常很容易实现。

## 亲和性和位置感知

有时，某些应用服务需要在其运行的节点上有专用硬件的支持。例如，I/O 密集型服务需要附加高性能**固态硬盘**（**SSD**）的集群节点，而一些用于机器学习等服务需要**加速处理单元**（**APU**）。

编排器允许我们为每个应用服务定义节点亲和性。然后，编排器将确保其调度器仅在满足所需条件的集群节点上调度容器。

应避免在特定节点上定义亲和性；这样做会引入单点故障，从而影响高可用性。始终将多个集群节点定义为应用服务的目标。

一些调度引擎还支持所谓的定位感知或地理感知。这意味着你可以要求调度器在一组不同的位置之间均匀分配服务实例。例如，你可以定义一个数据中心标签，可能包括西部、中心和东部值，并将该标签应用于所有集群节点，标签值对应各节点所在的地理区域。然后，你可以指示调度器使用该标签来实现特定应用服务的地理感知。在这种情况下，如果你请求该服务的九个副本，调度器将确保三个副本分别部署到三个数据中心的节点——西部、中心和东部。

地理感知甚至可以分层定义；例如，你可以将数据中心作为顶级区分符，然后是可用区。

地理感知或位置感知用于减少由于电力供应故障或数据中心停机而导致的故障概率。如果应用实例分布在节点、可用区甚至数据中心之间，那么一切都同时宕机的可能性极小。总会有一个区域保持可用。

## 安全

目前，IT 安全是一个非常热门的话题。网络战争已经达到前所未有的高峰。大多数高知名度公司都曾成为黑客攻击的受害者，且代价非常高昂。

每个**首席信息官**（**CIO**）或**首席技术官**（**CTO**）最怕的噩梦之一，就是早晨醒来听到新闻报道说他们的公司成为黑客攻击的受害者，敏感信息被盗或被泄露。

为了应对大多数安全威胁，我们需要建立一个安全的软件供应链，并加强深度安全防御。让我们来看一下你可以期待企业级调度器的一些任务。

### 安全通信和加密节点身份

首先，我们要确保由调度器管理的集群是安全的。只有受信任的节点才能加入集群。每个加入集群的节点都会获得一个加密节点身份，节点之间的所有通信必须加密。为此，节点可以使用**互信传输层安全**（**MTLS**）。为了相互验证集群节点，使用证书。这些证书会定期自动轮换，或者根据请求轮换，以防止证书泄露时保护系统。

集群中发生的通信可以分为三种类型。你可以说有三种通信平面——管理平面、控制平面和数据平面：

+   管理平面由集群管理器或主节点使用，用于例如调度服务实例、执行健康检查，或创建和修改集群中的任何其他资源，如数据卷、密钥或网络。

+   控制平面用于在集群中的所有节点之间交换重要的状态信息。例如，这些信息会用来更新集群中的本地 IP 表，以便进行路由。

+   数据平面是实际的应用服务相互通信和交换数据的地方。

通常，编排器主要关注于确保管理和控制平面的安全。数据平面的安全则交由用户负责，尽管编排器可能会协助这一任务。

### 安全网络和网络策略

在运行应用服务时，并非每个服务都需要与集群中的其他所有服务进行通信。因此，我们希望能够将服务进行沙箱化，只在同一网络沙箱中运行那些必须互相通信的服务。所有其他服务以及来自集群外部的所有网络流量都应该无法访问这些沙箱化的服务。

至少有两种方式可以实现基于网络的沙箱化。我们可以使用**软件定义网络**（**SDN**）将应用服务分组，或者我们可以拥有一个平坦的网络，并使用网络策略来控制谁可以访问特定的服务或服务组。

### 基于角色的访问控制（RBAC）

编排器必须履行的最重要任务之一（仅次于安全性）是为集群及其资源提供 RBAC，以便其达到企业级的可用性。

RBAC 定义了系统中的主体、用户或用户组（按团队等组织方式）如何访问和操作系统资源。它确保未授权的人员无法对系统造成任何损害，也不能看到他们不应该知道或不应访问的系统资源。

一个典型的企业可能有如开发、QA、生产等用户组，并且每个组可能有一个或多个用户。开发人员 John Doe 是开发组的成员，因此他可以访问专属于开发团队的资源，但他不能访问生产团队的资源，比如 Ann Harbor 的资源。反过来，Ann 也无法干预开发团队的资源。

实现 RBAC 的一种方式是通过定义授权。授权是主体、角色和资源集合之间的关联。这里，角色包含一组对资源的访问权限。这些权限可以是创建、停止、删除、列出或查看容器；部署新的应用服务；列出集群节点或查看集群节点的详细信息；以及其他许多操作。

资源集合是集群中一组逻辑上相关的资源，例如应用服务、机密、数据卷或容器。

### 机密

在我们的日常生活中，我们有很多秘密。秘密是指那些不应公开的资料，比如你用来访问在线银行账户的用户名和密码组合，或者你手机的密码或健身房储物柜的密码。

在编写软件时，我们也经常需要使用秘密。例如，我们需要一个证书来认证我们的应用服务与我们想要访问的外部服务，或者我们需要一个令牌来认证和授权我们的服务在访问某些 API 时。

过去，为了方便，开发者通常会将这些值硬编码在代码中，或者放在一些外部配置文件中以明文形式存储。这样，这些非常敏感的信息就能被广泛的用户访问，而实际上，这些人根本不应该有机会看到这些秘密。

幸运的是，如今的编排工具提供了所谓的“秘密”功能，以一种高度安全的方式处理敏感信息。秘密可以由授权或信任的人员创建。这些秘密的值会被加密并存储在高可用的集群状态数据库中。由于秘密是加密的，因此它们在静态存储时是安全的。一旦授权的应用服务请求一个秘密，该秘密只会被转发到实际运行该特定服务实例的集群节点，并且秘密值永远不会存储在节点上，而是以 tmpfs 基于 RAM 的卷的形式挂载到容器中。

只有在各自的容器内部，秘密值才以明文形式可用。我们已经提到过，秘密在静态存储时是安全的。一旦服务请求它们，集群管理器（或主节点）会解密秘密并通过网络将其发送到目标节点。那么，秘密在传输过程中如何保持安全呢？好吧，我们之前学习过，集群节点使用 MTLS 进行通信，因此，虽然秘密以明文传输，但由于数据包会被 MTLS 加密，秘密依然是安全的。因此，秘密在静态存储和传输过程中都是安全的。只有被授权使用秘密的服务才能访问这些秘密值。

Kubernetes 中的秘密

请注意，尽管 Kubernetes 中使用的秘密相对安全，但文档仍然建议将其与更加安全的服务结合使用，即像 AWS Secrets Manager 或 Hashicorp 的 Vault 这样的秘密管理器。

### 内容信任

为了增强安全性，我们希望确保只有受信任的镜像在我们的生产集群中运行。一些编排器允许我们配置集群，以便它只能运行签名的镜像。内容信任和镜像签名都关乎确保镜像的作者是我们期望的人，即我们信任的开发者或者更好的情况是我们信任的 CI 服务器。此外，通过内容信任，我们希望确保我们得到的镜像是新鲜的，并且不是旧的，可能存在漏洞的镜像。最后，我们希望确保在传输过程中镜像不能被恶意黑客篡改。后者通常称为**中间人攻击**（**MITM**攻击）。

通过在源头签署镜像并在目标处验证签名，我们可以保证我们想要运行的镜像没有被篡改。

### 反向正常运行时间

在安全上下文中，我想讨论的最后一点是反向正常运行时间。这是什么意思呢？想象一下，你已经配置并确保了一个生产集群的安全性。在这个集群上，你正在运行公司的几个关键应用程序。现在，一个黑客成功找到了你软件堆栈中的一个安全漏洞，并且已经获取了对一个集群节点的根访问权限。单单这已经够糟糕的了，更糟糕的是，这个黑客现在可以掩盖他们在这个节点上的存在，并假装是机器的根用户，然后利用它作为基础攻击集群中的其他节点。

在 Linux 或任何 Unix 类型的操作系统中，根访问权限意味着你可以在该系统上执行任何操作。这是一个人能够拥有的最高级别的访问权限。在 Windows 中，相当于这个角色的是管理员角色。

但是如果我们利用容器是短暂的，集群节点可以快速配置，通常情况下只需几分钟就能完成？我们只需在每个集群节点运行一定正常运行时间后，例如一天，就杀死它们。编排器被指示排空节点，然后将其从集群中排除。一旦节点离开集群，它将被拆除并由新配置的节点替换。

这样，黑客就失去了他们的基础，问题已被消除。尽管这个概念目前还没有广泛推广，但对我来说，这似乎是提高安全性的一个巨大步骤，并且据我与在这一领域工作的工程师讨论，实施起来并不困难。

## 内省

到目前为止，我们已经讨论了很多编排器的责任和它完全自主执行的任务。然而，还需要人员操作者能够查看和分析集群上当前运行的内容，以及个别应用程序的状态或健康情况。为了做到这一点，我们需要 introspection 的可能性。编排器需要以易于消化和理解的方式展示关键信息。

协调器应当从所有集群节点收集系统指标，并使操作员可以访问这些数据。指标包括 CPU、内存和磁盘使用情况、网络带宽消耗等。这些信息应该易于在每个节点的基础上获取，也可以以聚合的形式提供。

我们还希望协调器能让我们访问由服务实例或容器生成的日志。更进一步，如果我们拥有正确的授权，协调器应该为我们提供`exec`权限，让我们可以访问每个容器。通过 exec 访问容器后，我们就可以调试表现异常的容器。

在高度分布式的应用程序中，每个请求都会通过多个服务，直到完全处理完成，追踪请求是一个非常重要的任务。

理想情况下，协调器应支持我们实施追踪策略，或者为我们提供一些良好的指南。

最后，人类操作员在监控系统时，最好能使用一个图形化展示所有收集的指标、日志和跟踪信息的界面。这里我们指的是仪表盘。每个合格的协调器都应该提供至少一个基本的仪表盘，图形化展示最关键的系统参数。

然而，人类操作员并不是唯一关注自省的人。我们还需要能够将外部系统与协调器连接，以便消耗这些信息。需要有一个可用的 API，通过它外部系统可以访问集群状态、指标和日志等数据，并使用这些信息做出自动化决策，比如创建呼叫器或电话警报、发送电子邮件，或者在系统超过某些阈值时触发警报。

# 流行编排器概述

截至目前，市面上有许多编排引擎在使用，但也有一些明显的赢家。第一的位置无疑是 Kubernetes，它遥遥领先。第二位是 Docker 的 SwarmKit，其后是 Apache Mesos、AWS 的**Elastic Container Service**（**ECS**）和微软的**Azure Container** **Service**（**ACS**）。

## Kubernetes

Kubernetes 最初由谷歌设计，后来捐赠给了**Cloud Native Computing Foundation**（**CNCF**）。Kubernetes 的设计借鉴了谷歌的专有系统 Borg，Borg 已经在超大规模的环境中运行容器多年。Kubernetes 是谷歌尝试重新开始的结果，彻底从头开始设计一个系统，结合了 Borg 中所有学到的经验教训。

与 Borg（一个专有技术）不同，Kubernetes 从一开始就开源了。谷歌做出这个选择非常明智，因为它吸引了大量来自公司外部的贡献者，并且在短短几年内，围绕 Kubernetes 形成了一个更为庞大的生态系统。你可以理直气壮地说，Kubernetes 是容器编排领域的宠儿。没有其他编排工具能够产生如此大的热度，并吸引如此多的有才华的人们，他们愿意以贡献者或早期采纳者的身份为项目的成功做出有意义的贡献。

在这方面，Kubernetes 在容器编排领域给我的感觉很像 Linux 在服务器操作系统领域的地位。Linux 已经成为服务器操作系统的事实标准。所有相关的公司，如微软、IBM、亚马逊、Red Hat，甚至 Docker，都已经接受了 Kubernetes。

有一点是不可否认的：Kubernetes 从一开始就是为大规模可扩展性而设计的。毕竟，它的设计是基于 Google Borg 的。

一个可能对 Kubernetes 提出的负面意见是，它仍然很复杂，至少在写作时是这样。对于新手来说，存在一个显著的门槛。第一步陡峭，但一旦你与这个编排工具合作了一段时间，所有一切都会变得清晰。整体设计经过深思熟虑，并且执行得非常好。

在 Kubernetes 1.10 版本中，其**正式发布**（**GA**）是在 2018 年 3 月，解决了与其他编排工具（如 Docker Swarm）相比的大多数初期不足之处。例如，安全性和保密性现在不仅仅是事后考虑，而是系统的核心部分。

新功能以惊人的速度被实现。新版本大约每三个月发布一次，确切地说，大约每 100 天发布一次。大多数新功能都是由需求驱动的，也就是说，使用 Kubernetes 编排其关键应用的公司可以提出他们的需求。这使得 Kubernetes 成为企业级可用的工具。如果认为这个编排工具仅适合初创公司，而不适合风险规避的大型企业，那就是错误的。恰恰相反。我的这个观点是基于这样的事实：像微软、Docker 和 Red Hat 这样的公司，其客户大多是大型企业，已经完全接受了 Kubernetes，并为其提供企业级支持，特别是在其产品中使用并集成 Kubernetes。

Kubernetes 支持 Linux 和 Windows 容器。

## Docker Swarm

众所周知，Docker 推广并使软件容器商品化。Docker 没有发明容器，但标准化了容器并使其广泛可用，尤其是通过提供免费的镜像仓库——Docker Hub。最初，Docker 主要关注开发者和开发生命周期。然而，开始使用并喜爱容器的公司，很快也希望不仅在新应用的开发或测试阶段使用它们，还希望在生产环境中运行这些应用。

起初，Docker 在这个领域没有什么可以提供的，因此其他公司填补了这个空白，为用户提供帮助。但不久之后，Docker 认识到，市场上对一个简单而强大的编排工具有着巨大的需求。Docker 的第一次尝试是推出名为 Classic Swarm 的产品。它是一个独立的产品，使用户能够创建一个 Docker 主机集群，用于以高度可用和自我修复的方式运行和扩展其容器化应用。

然而，Docker Classic Swarm 的设置过程非常困难，涉及很多复杂的手动步骤。客户非常喜欢这个产品，但却因其复杂性而感到困惑。因此，Docker 决定做得更好。它重新开始设计并提出了 SwarmKit。

SwarmKit 于 2016 年 DockerCon 在西雅图发布，并成为 Docker Engine 最新版本的一个组成部分。是的，你没听错，SwarmKit 曾经是并且直到今天依然是 Docker Engine 的核心组成部分。因此，如果你安装了一个 Docker 主机，那么你就自动获得了 SwarmKit。

SwarmKit 的设计考虑了简易性和安全性。它的核心理念是，设置一个 Swarm 应该几乎是微不足道的，而且 Swarm 在默认情况下必须具有高度的安全性。Docker Swarm 假设最小权限原则。

安装一个完整的、高可用性的 Docker Swarm 实际上非常简单，只需在集群中的第一个节点上运行 `docker swarm init`，该节点将成为所谓的领导节点，然后在其他所有节点上运行 `docker swarm join <join-token>`。`<join-token>` 是在初始化时由领导节点生成的。在最多 10 个节点的 Swarm 中，整个过程不到 5 分钟。如果自动化执行，所需时间更短。

正如我之前提到的，当 Docker 设计和开发 SwarmKit 时，安全性是最重要的需求之一。容器通过依赖 Linux 内核命名空间和 cgroups，以及 Linux 系统调用白名单 (**seccomp**) 和支持 Linux 能力以及 **Linux 安全模块** (**LSM**) 来提供安全性。现在，在这些基础上，SwarmKit 添加了 MTLS 和在静态和传输过程中都加密的密钥。

此外，Swarm 定义了所谓的 **容器网络模型** (**CNM**)，该模型支持软件定义网络（SDN），为运行在 Swarm 上的应用服务提供沙箱功能。Docker SwarmKit 支持 Linux 和 Windows 容器。

## Apache Mesos 和 Marathon

Apache Mesos 是一个开源项目，最初旨在让一群服务器或节点从外部看起来像一个单一的大型服务器。Mesos 是一款简化计算机集群管理的软件。Mesos 的用户不需要关心单个服务器，而只需假设他们拥有一个巨大的资源池，这些资源池对应着集群中所有节点的资源总和。

在 IT 术语中，Mesos 已经算是相当老旧了，至少与其他调度器相比是这样。它最早在 2009 年公开展示，但那时当然并没有设计用于运行容器，因为 Docker 当时还不存在。类似于 Docker 对容器的处理，Mesos 使用 Linux 的 cgroups 来隔离资源，如 CPU、内存或磁盘 I/O，以供单个应用程序或服务使用。

Mesos 实际上是其他有趣的服务的底层基础设施，许多有意思的服务都是建立在它之上的。从容器的角度来看，Marathon 非常重要。Marathon 是一个运行在 Mesos 之上的容器调度器，能够扩展到数千个节点。

Marathon 支持多种容器运行时，例如 Docker 或它自有的 Mesos 容器。它不仅支持无状态的应用服务，还支持有状态的应用服务，例如 PostgreSQL 或 MongoDB 等数据库。类似于 Kubernetes 和 Docker SwarmKit，它支持本章前面提到的许多特性，如高可用性、健康检查、服务发现、负载均衡和位置感知等，这些只是其中一些最重要的功能。

尽管 Mesos，以及在某种程度上 Marathon，是相当成熟的项目，但它们的应用范围相对有限。它似乎在大数据领域最为流行，也就是用于运行数据处理服务，如 Spark 或 Hadoop。

## 亚马逊 ECS

如果你正在寻找一个简单的调度器，并且已经深度融入 AWS 生态系统，那么亚马逊的 ECS 可能是适合你的选择。值得指出的是 ECS 有一个非常重要的限制：如果你选择了这个容器调度器，那么你就会被锁定在 AWS 平台中。你将无法轻松地将运行在 ECS 上的应用程序移植到其他平台或云端。

亚马逊将其 ECS 服务推广为一个高度可扩展、快速的容器管理服务，使得在集群中运行、停止和管理 Docker 容器变得更加容易。除了运行容器外，ECS 还提供直接访问许多其他 AWS 服务，这些服务可以从运行在容器内部的应用程序服务中访问。这种与许多流行 AWS 服务的紧密无缝集成，使得 ECS 对于那些寻找简便方法以在一个强大且高度可扩展环境中启动和运行其容器化应用的用户非常有吸引力。亚马逊还提供了其自有的私人镜像注册表。

使用 AWS ECS，您可以通过 Fargate 完全管理底层基础设施，使您能够专注于部署容器化应用程序，且无需关心如何创建和管理节点集群。ECS 支持 Linux 和 Windows 容器。

总结来说，ECS 简单易用、可扩展性强，并且与其他流行的 AWS 服务集成得很好，但它不如 Kubernetes 或 Docker SwarmKit 那样强大，而且仅在亚马逊 AWS 平台上可用。

## AWS EKS

亚马逊**弹性 Kubernetes 服务**（**EKS**）是 AWS 提供的一项托管 Kubernetes 服务。它简化了使用 Kubernetes 进行容器化应用程序的部署、管理和扩展，使开发人员和运维团队能够专注于构建和运行应用程序，而无需管理 Kubernetes 控制平面的负担。

EKS 与各种 AWS 服务无缝集成，例如弹性负载均衡、Amazon RDS 和 Amazon S3，使得构建一个完全托管、可扩展且安全的容器化应用程序基础设施变得轻而易举。它还支持 Kubernetes 生态系统，允许用户利用现有的工具、插件和扩展来管理和监控他们的应用程序。

使用亚马逊 EKS，Kubernetes 控制平面由 AWS 自动管理，确保高可用性、自动更新和安全补丁。用户只需负责管理其工作节点，这些节点可以通过 Amazon EC2 实例或 AWS Fargate 进行部署。

# 微软 ACS 和 AKS

与我们之前提到的 ECS 类似，我们可以对微软的 ACS 作出同样的评价。它是一个简单的容器编排服务，如果你已经深度投资于 Azure 生态系统，那么它是有意义的。我应该和我提到亚马逊 ECS 时一样说：如果你选择了 ACS，那么你就把自己锁定在微软的产品中。从 ACS 迁移容器化应用程序到其他平台或云环境将并非易事。

ACS 是微软的容器服务，支持多种编排器，如 Kubernetes、Docker Swarm 和 Mesos DC/OS。随着 Kubernetes 的越来越流行，微软的关注焦点显然已转向该编排器。微软甚至重新品牌化其服务，并将其命名为**Azure Kubernetes Service**（**AKS**），以便将焦点集中在 Kubernetes 上。

AKS 在 Azure 中为您管理托管的 Kubernetes、Docker Swarm 或 DC/OS 环境，使您能够专注于您希望部署的应用程序，无需担心配置基础设施。微软用自己的话说如下：

“AKS 使得部署和管理容器化应用程序变得快速且简单，无需容器编排的专业知识。它还通过按需提供、升级和扩展资源，消除了持续运营和维护的负担，而无需让您的应用程序停机。”

# 总结

本章展示了为何首先需要编排器，以及它们是如何在概念上工作的。它指出了在写作时最突出的编排器，并讨论了不同编排器之间的主要共性和差异。

下一章将介绍 Docker 的原生编排器 SwarmKit。它将详细讲解 SwarmKit 用来在集群中部署和运行分布式、弹性、稳健和高可用应用的所有概念和对象——无论是在本地还是在云中。

# 深入阅读

以下链接提供了一些关于编排相关主题的深入见解：[`kubernetes.Io/`](https://kubernetes.Io/)

+   *Kubernetes—生产级* *编排*: [`kubernetes.io/`](https://kubernetes.io/)

+   *Docker Swarm* *模式概述*: [`docs.docker.com/engine/swarm/`](https://docs.docker.com/engine/swarm/)

+   *Mesosphere—容器编排* *服务*: [`bit.ly/2GMpko3`](http://bit.ly/2GMpko3)

+   *容器和编排* *解析*: [`bit.ly/2DFoQgx`](http://bit.ly/2DFoQgx)

# 问题

回答以下问题以评估你的学习进度：

1.  什么是容器编排引擎？

1.  为什么我们需要容器编排引擎？

1.  容器编排引擎的主要任务是什么？

1.  一些流行的容器编排引擎有哪些？

1.  容器编排如何提高应用的可靠性？

1.  容器编排引擎如何帮助应用扩展？

1.  Kubernetes 和 Docker Swarm 之间的主要区别是什么？

1.  容器编排引擎如何处理服务发现？

# 答案

下面是一些问题的可能答案：

1.  容器编排引擎是一个自动化部署、扩展、管理和网络化容器的系统。它帮助开发人员和运维团队管理大量容器，确保它们在分布式环境中跨多个主机高效可靠地运行。

1.  随着应用中容器和服务数量的增加，手动管理变得越来越困难。容器编排引擎自动化了容器管理的过程，能够实现高效的资源利用、高可用性、容错能力以及容器化应用的无缝扩展。

1.  容器编排引擎的主要任务包括以下几个方面：

    +   **容器部署**：根据资源需求和约束将容器部署到合适的主机

    +   **扩展**：根据应用需求自动增加或减少容器的数量

    +   **负载均衡**：将网络流量分配到各个容器，确保最佳性能

    +   **服务发现**：使容器能够找到并与彼此通信

    +   **健康监控**：监控容器健康状况并自动替换不健康的容器

    +   **数据持久性和存储管理**：管理存储卷并确保数据在容器重启和故障后保持持久性。

    +   **安全性和访问控制**：管理容器安全、网络策略和访问控制。

1.  一些流行的容器编排引擎包括 Kubernetes、Docker Swarm、Apache Mesos、Microsoft ACS、Microsoft AKS 和 Amazon ECS。

1.  容器编排引擎通过确保容器部署在适当的主机上、监控容器健康状况，并自动替换不健康或失败的容器，从而提高应用程序的可靠性。它们还通过在容器之间分配网络流量来帮助保持应用程序的可用性，使系统能够优雅地处理故障和流量高峰。

1.  容器编排引擎可以根据需求、资源使用情况和预定义规则，自动扩展应用程序，添加或移除容器。这确保了应用程序能够处理不同级别的流量和工作负载，同时优化资源使用。

1.  Kubernetes 和 Docker Swarm 都是容器编排引擎，但它们有一些关键区别：

    +   Kubernetes 功能更丰富且灵活，提供广泛的功能和可扩展性。Docker Swarm 更简单，易于设置，注重易用性并与 Docker 生态系统的集成。

    +   Kubernetes 使用声明式方法，允许用户描述系统的期望状态，而 Docker Swarm 则使用更具命令式的方法。

    +   相比 Docker Swarm，Kubernetes 的学习曲线更陡峭，而 Docker Swarm 的学习曲线较浅，对于已经熟悉 Docker 的用户来说更加简单直接。

    +   相比 Docker Swarm，Kubernetes 拥有更大的社区、更广泛的文档和更多的第三方集成。

1.  容器编排引擎通过提供容器间发现和通信的机制来处理服务发现。它们通常为容器分配唯一的网络地址或主机名，并维护这些地址的注册表。容器可以使用这些地址与应用程序中的其他服务进行通信。一些编排引擎还提供内置的负载均衡和基于 DNS 的服务发现，简化这一过程。
